2022-11-18 00:26:39,869 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/ac009f0378bc25c1a4bc829b35d0bf5a/2022_11_17-161904",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "cat",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-18 00:26:39,878 INFO: Starting stage: BUILD FEATURIZERS
2022-11-18 00:26:39,881 INFO:   Creating esm representation model
2022-11-18 00:26:39,881 INFO:   Done esm representation model
2022-11-18 00:26:39,881 INFO: Done with stage: BUILD FEATURIZERS
2022-11-18 00:26:39,881 INFO: Starting stage: BUILDING DATASET
2022-11-18 00:26:39,938 INFO: Done with stage: BUILDING DATASET
2022-11-18 00:26:39,938 INFO: Starting stage: FEATURIZING DATA
2022-11-18 00:26:39,939 INFO:   Featurizing proteins
2022-11-18 00:26:39,940 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-18 00:26:39,958 INFO:   Loaded feature cache of size 204
2022-11-18 00:26:39,959 INFO:   Starting to pool ESM Embeddings
2022-11-18 00:26:40,071 INFO:   Featurizing molecules
2022-11-18 00:26:40,458 INFO: Done with stage: FEATURIZING DATA
2022-11-18 00:26:40,458 INFO: Starting stage: RUNNING SPLITS
2022-11-18 00:26:40,467 INFO:   Leaving out SEQ value Fold_0
2022-11-18 00:26:40,482 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 00:26:40,482 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:26:41,173 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:26:41,173 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:26:41,242 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:26:41,242 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:26:41,242 INFO:     No hyperparam tuning for this model
2022-11-18 00:26:41,242 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:26:41,242 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:26:41,243 INFO:     None feature selector for col prot
2022-11-18 00:26:41,243 INFO:     None feature selector for col prot
2022-11-18 00:26:41,244 INFO:     None feature selector for col prot
2022-11-18 00:26:41,244 INFO:     None feature selector for col chem
2022-11-18 00:26:41,244 INFO:     None feature selector for col chem
2022-11-18 00:26:41,244 INFO:     None feature selector for col chem
2022-11-18 00:26:41,245 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:26:41,245 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:26:41,246 INFO:     Number of params in model 168571
2022-11-18 00:26:41,246 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:26:41,246 INFO:   Starting stage: TRAINING
2022-11-18 00:26:42,841 INFO:     Val loss before train {'Reaction outcome loss': 1.027947064055953, 'Total loss': 1.027947064055953}
2022-11-18 00:26:42,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:42,841 INFO:     Epoch: 0
2022-11-18 00:26:43,613 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.865024175061736, 'Total loss': 0.865024175061736} | train loss {'Reaction outcome loss': 0.8721423141780447, 'Total loss': 0.8721423141780447}
2022-11-18 00:26:43,614 INFO:     Found new best model at epoch 0
2022-11-18 00:26:43,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:43,615 INFO:     Epoch: 1
2022-11-18 00:26:44,370 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.848034031169359, 'Total loss': 0.848034031169359} | train loss {'Reaction outcome loss': 0.8382241392477614, 'Total loss': 0.8382241392477614}
2022-11-18 00:26:44,370 INFO:     Found new best model at epoch 1
2022-11-18 00:26:44,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:44,371 INFO:     Epoch: 2
2022-11-18 00:26:45,135 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.865129153395808, 'Total loss': 0.865129153395808} | train loss {'Reaction outcome loss': 0.8354973885856691, 'Total loss': 0.8354973885856691}
2022-11-18 00:26:45,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:45,135 INFO:     Epoch: 3
2022-11-18 00:26:45,888 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8480221227157948, 'Total loss': 0.8480221227157948} | train loss {'Reaction outcome loss': 0.8287699727005646, 'Total loss': 0.8287699727005646}
2022-11-18 00:26:45,888 INFO:     Found new best model at epoch 3
2022-11-18 00:26:45,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:45,889 INFO:     Epoch: 4
2022-11-18 00:26:46,638 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8440694538659828, 'Total loss': 0.8440694538659828} | train loss {'Reaction outcome loss': 0.8340449473652684, 'Total loss': 0.8340449473652684}
2022-11-18 00:26:46,638 INFO:     Found new best model at epoch 4
2022-11-18 00:26:46,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:46,639 INFO:     Epoch: 5
2022-11-18 00:26:47,422 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8438642128955486, 'Total loss': 0.8438642128955486} | train loss {'Reaction outcome loss': 0.8264034307393872, 'Total loss': 0.8264034307393872}
2022-11-18 00:26:47,422 INFO:     Found new best model at epoch 5
2022-11-18 00:26:47,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:47,423 INFO:     Epoch: 6
2022-11-18 00:26:48,183 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8369773238204247, 'Total loss': 0.8369773238204247} | train loss {'Reaction outcome loss': 0.8280575938644956, 'Total loss': 0.8280575938644956}
2022-11-18 00:26:48,183 INFO:     Found new best model at epoch 6
2022-11-18 00:26:48,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:48,184 INFO:     Epoch: 7
2022-11-18 00:26:48,965 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8351916033168172, 'Total loss': 0.8351916033168172} | train loss {'Reaction outcome loss': 0.826638116089047, 'Total loss': 0.826638116089047}
2022-11-18 00:26:48,965 INFO:     Found new best model at epoch 7
2022-11-18 00:26:48,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:48,966 INFO:     Epoch: 8
2022-11-18 00:26:49,720 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8368718263714813, 'Total loss': 0.8368718263714813} | train loss {'Reaction outcome loss': 0.8151443675160408, 'Total loss': 0.8151443675160408}
2022-11-18 00:26:49,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:49,721 INFO:     Epoch: 9
2022-11-18 00:26:50,478 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8389692881772685, 'Total loss': 0.8389692881772685} | train loss {'Reaction outcome loss': 0.821310887571241, 'Total loss': 0.821310887571241}
2022-11-18 00:26:50,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:50,478 INFO:     Epoch: 10
2022-11-18 00:26:51,248 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8426863592724467, 'Total loss': 0.8426863592724467} | train loss {'Reaction outcome loss': 0.8163124727176838, 'Total loss': 0.8163124727176838}
2022-11-18 00:26:51,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:51,248 INFO:     Epoch: 11
2022-11-18 00:26:52,035 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8294392574665158, 'Total loss': 0.8294392574665158} | train loss {'Reaction outcome loss': 0.8186750961620299, 'Total loss': 0.8186750961620299}
2022-11-18 00:26:52,035 INFO:     Found new best model at epoch 11
2022-11-18 00:26:52,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:52,036 INFO:     Epoch: 12
2022-11-18 00:26:52,800 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8588588930839716, 'Total loss': 0.8588588930839716} | train loss {'Reaction outcome loss': 0.8139258300671812, 'Total loss': 0.8139258300671812}
2022-11-18 00:26:52,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:52,800 INFO:     Epoch: 13
2022-11-18 00:26:53,559 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8197148754153141, 'Total loss': 0.8197148754153141} | train loss {'Reaction outcome loss': 0.8149102062719767, 'Total loss': 0.8149102062719767}
2022-11-18 00:26:53,559 INFO:     Found new best model at epoch 13
2022-11-18 00:26:53,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:53,560 INFO:     Epoch: 14
2022-11-18 00:26:54,319 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8276153969210248, 'Total loss': 0.8276153969210248} | train loss {'Reaction outcome loss': 0.8126106962073044, 'Total loss': 0.8126106962073044}
2022-11-18 00:26:54,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:54,320 INFO:     Epoch: 15
2022-11-18 00:26:55,057 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8512837665025578, 'Total loss': 0.8512837665025578} | train loss {'Reaction outcome loss': 0.8144580629028257, 'Total loss': 0.8144580629028257}
2022-11-18 00:26:55,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:55,057 INFO:     Epoch: 16
2022-11-18 00:26:55,813 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8432925641536713, 'Total loss': 0.8432925641536713} | train loss {'Reaction outcome loss': 0.8139987850531203, 'Total loss': 0.8139987850531203}
2022-11-18 00:26:55,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:55,813 INFO:     Epoch: 17
2022-11-18 00:26:56,556 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.854389912860338, 'Total loss': 0.854389912860338} | train loss {'Reaction outcome loss': 0.8134083096854022, 'Total loss': 0.8134083096854022}
2022-11-18 00:26:56,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:56,557 INFO:     Epoch: 18
2022-11-18 00:26:57,333 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.822362176207609, 'Total loss': 0.822362176207609} | train loss {'Reaction outcome loss': 0.8151391723849735, 'Total loss': 0.8151391723849735}
2022-11-18 00:26:57,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:57,334 INFO:     Epoch: 19
2022-11-18 00:26:58,109 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.837048451567805, 'Total loss': 0.837048451567805} | train loss {'Reaction outcome loss': 0.8176083822475105, 'Total loss': 0.8176083822475105}
2022-11-18 00:26:58,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:58,110 INFO:     Epoch: 20
2022-11-18 00:26:58,877 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8310350553933964, 'Total loss': 0.8310350553933964} | train loss {'Reaction outcome loss': 0.8120852633089316, 'Total loss': 0.8120852633089316}
2022-11-18 00:26:58,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:58,878 INFO:     Epoch: 21
2022-11-18 00:26:59,625 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8252174937447836, 'Total loss': 0.8252174937447836} | train loss {'Reaction outcome loss': 0.810858279833051, 'Total loss': 0.810858279833051}
2022-11-18 00:26:59,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:26:59,625 INFO:     Epoch: 22
2022-11-18 00:27:00,405 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8346611490083296, 'Total loss': 0.8346611490083296} | train loss {'Reaction outcome loss': 0.8120369732868477, 'Total loss': 0.8120369732868477}
2022-11-18 00:27:00,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:00,406 INFO:     Epoch: 23
2022-11-18 00:27:01,171 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8248842039773631, 'Total loss': 0.8248842039773631} | train loss {'Reaction outcome loss': 0.8111259989806863, 'Total loss': 0.8111259989806863}
2022-11-18 00:27:01,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:01,171 INFO:     Epoch: 24
2022-11-18 00:27:01,942 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8204856307007545, 'Total loss': 0.8204856307007545} | train loss {'Reaction outcome loss': 0.8139419660705035, 'Total loss': 0.8139419660705035}
2022-11-18 00:27:01,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:01,943 INFO:     Epoch: 25
2022-11-18 00:27:02,690 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8135905141054198, 'Total loss': 0.8135905141054198} | train loss {'Reaction outcome loss': 0.8136489668586215, 'Total loss': 0.8136489668586215}
2022-11-18 00:27:02,690 INFO:     Found new best model at epoch 25
2022-11-18 00:27:02,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:02,691 INFO:     Epoch: 26
2022-11-18 00:27:03,457 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8300777729167494, 'Total loss': 0.8300777729167494} | train loss {'Reaction outcome loss': 0.8112554461008212, 'Total loss': 0.8112554461008212}
2022-11-18 00:27:03,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:03,457 INFO:     Epoch: 27
2022-11-18 00:27:04,262 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8173012442367021, 'Total loss': 0.8173012442367021} | train loss {'Reaction outcome loss': 0.808805662588995, 'Total loss': 0.808805662588995}
2022-11-18 00:27:04,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:04,262 INFO:     Epoch: 28
2022-11-18 00:27:05,046 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8315176845983018, 'Total loss': 0.8315176845983018} | train loss {'Reaction outcome loss': 0.8039207330248395, 'Total loss': 0.8039207330248395}
2022-11-18 00:27:05,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:05,047 INFO:     Epoch: 29
2022-11-18 00:27:05,813 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8506369881851729, 'Total loss': 0.8506369881851729} | train loss {'Reaction outcome loss': 0.8106413293080251, 'Total loss': 0.8106413293080251}
2022-11-18 00:27:05,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:05,813 INFO:     Epoch: 30
2022-11-18 00:27:06,585 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8265255218328431, 'Total loss': 0.8265255218328431} | train loss {'Reaction outcome loss': 0.8075590481767889, 'Total loss': 0.8075590481767889}
2022-11-18 00:27:06,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:06,585 INFO:     Epoch: 31
2022-11-18 00:27:07,354 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8317074526187985, 'Total loss': 0.8317074526187985} | train loss {'Reaction outcome loss': 0.8091798700758668, 'Total loss': 0.8091798700758668}
2022-11-18 00:27:07,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:07,354 INFO:     Epoch: 32
2022-11-18 00:27:08,138 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8315864357837411, 'Total loss': 0.8315864357837411} | train loss {'Reaction outcome loss': 0.807072322510305, 'Total loss': 0.807072322510305}
2022-11-18 00:27:08,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:08,138 INFO:     Epoch: 33
2022-11-18 00:27:08,896 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8191722395808197, 'Total loss': 0.8191722395808197} | train loss {'Reaction outcome loss': 0.8063433653995639, 'Total loss': 0.8063433653995639}
2022-11-18 00:27:08,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:08,896 INFO:     Epoch: 34
2022-11-18 00:27:09,683 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8291726985643076, 'Total loss': 0.8291726985643076} | train loss {'Reaction outcome loss': 0.8098892262968861, 'Total loss': 0.8098892262968861}
2022-11-18 00:27:09,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:09,684 INFO:     Epoch: 35
2022-11-18 00:27:10,425 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8197533134804216, 'Total loss': 0.8197533134804216} | train loss {'Reaction outcome loss': 0.8118758141750195, 'Total loss': 0.8118758141750195}
2022-11-18 00:27:10,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:10,426 INFO:     Epoch: 36
2022-11-18 00:27:11,174 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8196651554384897, 'Total loss': 0.8196651554384897} | train loss {'Reaction outcome loss': 0.8074929184112393, 'Total loss': 0.8074929184112393}
2022-11-18 00:27:11,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:11,174 INFO:     Epoch: 37
2022-11-18 00:27:11,940 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8234389562939488, 'Total loss': 0.8234389562939488} | train loss {'Reaction outcome loss': 0.8071652148834995, 'Total loss': 0.8071652148834995}
2022-11-18 00:27:11,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:11,940 INFO:     Epoch: 38
2022-11-18 00:27:12,704 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.820895359266636, 'Total loss': 0.820895359266636} | train loss {'Reaction outcome loss': 0.8084576846879037, 'Total loss': 0.8084576846879037}
2022-11-18 00:27:12,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:12,704 INFO:     Epoch: 39
2022-11-18 00:27:13,471 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8278895963070004, 'Total loss': 0.8278895963070004} | train loss {'Reaction outcome loss': 0.8047957028277585, 'Total loss': 0.8047957028277585}
2022-11-18 00:27:13,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:13,471 INFO:     Epoch: 40
2022-11-18 00:27:14,242 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8278549057106639, 'Total loss': 0.8278549057106639} | train loss {'Reaction outcome loss': 0.8090177395793258, 'Total loss': 0.8090177395793258}
2022-11-18 00:27:14,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:14,243 INFO:     Epoch: 41
2022-11-18 00:27:15,000 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8294642581496128, 'Total loss': 0.8294642581496128} | train loss {'Reaction outcome loss': 0.8039163630761084, 'Total loss': 0.8039163630761084}
2022-11-18 00:27:15,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:15,000 INFO:     Epoch: 42
2022-11-18 00:27:15,767 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8202108186344768, 'Total loss': 0.8202108186344768} | train loss {'Reaction outcome loss': 0.8066968022555602, 'Total loss': 0.8066968022555602}
2022-11-18 00:27:15,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:15,769 INFO:     Epoch: 43
2022-11-18 00:27:16,524 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8222124985484189, 'Total loss': 0.8222124985484189} | train loss {'Reaction outcome loss': 0.8013665045871109, 'Total loss': 0.8013665045871109}
2022-11-18 00:27:16,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:16,524 INFO:     Epoch: 44
2022-11-18 00:27:17,279 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8247438267219899, 'Total loss': 0.8247438267219899} | train loss {'Reaction outcome loss': 0.8042914298225622, 'Total loss': 0.8042914298225622}
2022-11-18 00:27:17,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:17,280 INFO:     Epoch: 45
2022-11-18 00:27:18,031 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8103922945122386, 'Total loss': 0.8103922945122386} | train loss {'Reaction outcome loss': 0.8033996612810698, 'Total loss': 0.8033996612810698}
2022-11-18 00:27:18,031 INFO:     Found new best model at epoch 45
2022-11-18 00:27:18,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:18,032 INFO:     Epoch: 46
2022-11-18 00:27:18,802 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8284390735071759, 'Total loss': 0.8284390735071759} | train loss {'Reaction outcome loss': 0.8022095007730312, 'Total loss': 0.8022095007730312}
2022-11-18 00:27:18,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:18,802 INFO:     Epoch: 47
2022-11-18 00:27:19,569 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8421791771123576, 'Total loss': 0.8421791771123576} | train loss {'Reaction outcome loss': 0.808254857043751, 'Total loss': 0.808254857043751}
2022-11-18 00:27:19,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:19,569 INFO:     Epoch: 48
2022-11-18 00:27:20,339 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8345838438632877, 'Total loss': 0.8345838438632877} | train loss {'Reaction outcome loss': 0.8041223897064318, 'Total loss': 0.8041223897064318}
2022-11-18 00:27:20,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:20,339 INFO:     Epoch: 49
2022-11-18 00:27:21,117 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.82054363641628, 'Total loss': 0.82054363641628} | train loss {'Reaction outcome loss': 0.809904513422583, 'Total loss': 0.809904513422583}
2022-11-18 00:27:21,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:21,118 INFO:     Epoch: 50
2022-11-18 00:27:21,894 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8350726282873819, 'Total loss': 0.8350726282873819} | train loss {'Reaction outcome loss': 0.8081874709393158, 'Total loss': 0.8081874709393158}
2022-11-18 00:27:21,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:21,895 INFO:     Epoch: 51
2022-11-18 00:27:22,678 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8131434501603593, 'Total loss': 0.8131434501603593} | train loss {'Reaction outcome loss': 0.8037937914983171, 'Total loss': 0.8037937914983171}
2022-11-18 00:27:22,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:22,679 INFO:     Epoch: 52
2022-11-18 00:27:23,450 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8371122936869777, 'Total loss': 0.8371122936869777} | train loss {'Reaction outcome loss': 0.8063974484312729, 'Total loss': 0.8063974484312729}
2022-11-18 00:27:23,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:23,450 INFO:     Epoch: 53
2022-11-18 00:27:24,226 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8272692173026329, 'Total loss': 0.8272692173026329} | train loss {'Reaction outcome loss': 0.8075072391599906, 'Total loss': 0.8075072391599906}
2022-11-18 00:27:24,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:24,226 INFO:     Epoch: 54
2022-11-18 00:27:24,989 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8379877181940301, 'Total loss': 0.8379877181940301} | train loss {'Reaction outcome loss': 0.8052469551807544, 'Total loss': 0.8052469551807544}
2022-11-18 00:27:24,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:24,989 INFO:     Epoch: 55
2022-11-18 00:27:25,781 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8252159384794013, 'Total loss': 0.8252159384794013} | train loss {'Reaction outcome loss': 0.8095319643616676, 'Total loss': 0.8095319643616676}
2022-11-18 00:27:25,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:25,781 INFO:     Epoch: 56
2022-11-18 00:27:26,554 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8151709575985753, 'Total loss': 0.8151709575985753} | train loss {'Reaction outcome loss': 0.8017457699189421, 'Total loss': 0.8017457699189421}
2022-11-18 00:27:26,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:26,554 INFO:     Epoch: 57
2022-11-18 00:27:27,347 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8414401301117831, 'Total loss': 0.8414401301117831} | train loss {'Reaction outcome loss': 0.8048817293077218, 'Total loss': 0.8048817293077218}
2022-11-18 00:27:27,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:27,347 INFO:     Epoch: 58
2022-11-18 00:27:28,105 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8184080830840177, 'Total loss': 0.8184080830840177} | train loss {'Reaction outcome loss': 0.8051409797101724, 'Total loss': 0.8051409797101724}
2022-11-18 00:27:28,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:28,105 INFO:     Epoch: 59
2022-11-18 00:27:28,873 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8135369184405304, 'Total loss': 0.8135369184405304} | train loss {'Reaction outcome loss': 0.8027382269501686, 'Total loss': 0.8027382269501686}
2022-11-18 00:27:28,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:28,874 INFO:     Epoch: 60
2022-11-18 00:27:29,635 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8168249421341475, 'Total loss': 0.8168249421341475} | train loss {'Reaction outcome loss': 0.7986262526179924, 'Total loss': 0.7986262526179924}
2022-11-18 00:27:29,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:29,635 INFO:     Epoch: 61
2022-11-18 00:27:30,394 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8261281529138255, 'Total loss': 0.8261281529138255} | train loss {'Reaction outcome loss': 0.8046414151054914, 'Total loss': 0.8046414151054914}
2022-11-18 00:27:30,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:30,395 INFO:     Epoch: 62
2022-11-18 00:27:31,169 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8108706141627112, 'Total loss': 0.8108706141627112} | train loss {'Reaction outcome loss': 0.8044510382365008, 'Total loss': 0.8044510382365008}
2022-11-18 00:27:31,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:31,169 INFO:     Epoch: 63
2022-11-18 00:27:31,929 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8115908087686051, 'Total loss': 0.8115908087686051} | train loss {'Reaction outcome loss': 0.8034212662548316, 'Total loss': 0.8034212662548316}
2022-11-18 00:27:31,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:31,929 INFO:     Epoch: 64
2022-11-18 00:27:32,696 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8454983185890109, 'Total loss': 0.8454983185890109} | train loss {'Reaction outcome loss': 0.8009675665468466, 'Total loss': 0.8009675665468466}
2022-11-18 00:27:32,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:32,696 INFO:     Epoch: 65
2022-11-18 00:27:33,471 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8186482371285905, 'Total loss': 0.8186482371285905} | train loss {'Reaction outcome loss': 0.8008570798107835, 'Total loss': 0.8008570798107835}
2022-11-18 00:27:33,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:33,471 INFO:     Epoch: 66
2022-11-18 00:27:34,249 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8114616628303084, 'Total loss': 0.8114616628303084} | train loss {'Reaction outcome loss': 0.8009624894036621, 'Total loss': 0.8009624894036621}
2022-11-18 00:27:34,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:34,250 INFO:     Epoch: 67
2022-11-18 00:27:34,986 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8206132442452186, 'Total loss': 0.8206132442452186} | train loss {'Reaction outcome loss': 0.8011471541201483, 'Total loss': 0.8011471541201483}
2022-11-18 00:27:34,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:34,987 INFO:     Epoch: 68
2022-11-18 00:27:35,752 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8238653734672902, 'Total loss': 0.8238653734672902} | train loss {'Reaction outcome loss': 0.8032572346388317, 'Total loss': 0.8032572346388317}
2022-11-18 00:27:35,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:35,752 INFO:     Epoch: 69
2022-11-18 00:27:36,509 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8430832132350566, 'Total loss': 0.8430832132350566} | train loss {'Reaction outcome loss': 0.7991993001005688, 'Total loss': 0.7991993001005688}
2022-11-18 00:27:36,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:36,509 INFO:     Epoch: 70
2022-11-18 00:27:37,290 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8148861569027568, 'Total loss': 0.8148861569027568} | train loss {'Reaction outcome loss': 0.8022072574154275, 'Total loss': 0.8022072574154275}
2022-11-18 00:27:37,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:37,290 INFO:     Epoch: 71
2022-11-18 00:27:38,094 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8086170713568843, 'Total loss': 0.8086170713568843} | train loss {'Reaction outcome loss': 0.8052587323501462, 'Total loss': 0.8052587323501462}
2022-11-18 00:27:38,094 INFO:     Found new best model at epoch 71
2022-11-18 00:27:38,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:38,095 INFO:     Epoch: 72
2022-11-18 00:27:38,851 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8071667441101962, 'Total loss': 0.8071667441101962} | train loss {'Reaction outcome loss': 0.8021260017498595, 'Total loss': 0.8021260017498595}
2022-11-18 00:27:38,851 INFO:     Found new best model at epoch 72
2022-11-18 00:27:38,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:38,852 INFO:     Epoch: 73
2022-11-18 00:27:39,601 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8074097439300182, 'Total loss': 0.8074097439300182} | train loss {'Reaction outcome loss': 0.8005883277195399, 'Total loss': 0.8005883277195399}
2022-11-18 00:27:39,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:39,601 INFO:     Epoch: 74
2022-11-18 00:27:40,348 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8190262477065242, 'Total loss': 0.8190262477065242} | train loss {'Reaction outcome loss': 0.7986695443997618, 'Total loss': 0.7986695443997618}
2022-11-18 00:27:40,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:40,349 INFO:     Epoch: 75
2022-11-18 00:27:41,100 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8114045497983001, 'Total loss': 0.8114045497983001} | train loss {'Reaction outcome loss': 0.7988770679860818, 'Total loss': 0.7988770679860818}
2022-11-18 00:27:41,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:41,101 INFO:     Epoch: 76
2022-11-18 00:27:41,889 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8144676387310028, 'Total loss': 0.8144676387310028} | train loss {'Reaction outcome loss': 0.803307121039414, 'Total loss': 0.803307121039414}
2022-11-18 00:27:41,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:41,889 INFO:     Epoch: 77
2022-11-18 00:27:42,700 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.818618937980297, 'Total loss': 0.818618937980297} | train loss {'Reaction outcome loss': 0.8012987729467329, 'Total loss': 0.8012987729467329}
2022-11-18 00:27:42,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:42,700 INFO:     Epoch: 78
2022-11-18 00:27:43,497 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8034230255803396, 'Total loss': 0.8034230255803396} | train loss {'Reaction outcome loss': 0.8005311934918654, 'Total loss': 0.8005311934918654}
2022-11-18 00:27:43,497 INFO:     Found new best model at epoch 78
2022-11-18 00:27:43,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:43,498 INFO:     Epoch: 79
2022-11-18 00:27:44,270 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8011686344479405, 'Total loss': 0.8011686344479405} | train loss {'Reaction outcome loss': 0.7969069112031186, 'Total loss': 0.7969069112031186}
2022-11-18 00:27:44,270 INFO:     Found new best model at epoch 79
2022-11-18 00:27:44,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:44,271 INFO:     Epoch: 80
2022-11-18 00:27:45,053 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8012733008972434, 'Total loss': 0.8012733008972434} | train loss {'Reaction outcome loss': 0.7995710156735827, 'Total loss': 0.7995710156735827}
2022-11-18 00:27:45,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:45,053 INFO:     Epoch: 81
2022-11-18 00:27:45,839 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8180452529774156, 'Total loss': 0.8180452529774156} | train loss {'Reaction outcome loss': 0.795733242127739, 'Total loss': 0.795733242127739}
2022-11-18 00:27:45,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:45,840 INFO:     Epoch: 82
2022-11-18 00:27:46,639 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8011104443738627, 'Total loss': 0.8011104443738627} | train loss {'Reaction outcome loss': 0.7961608757738208, 'Total loss': 0.7961608757738208}
2022-11-18 00:27:46,641 INFO:     Found new best model at epoch 82
2022-11-18 00:27:46,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:46,642 INFO:     Epoch: 83
2022-11-18 00:27:47,436 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7984685877034831, 'Total loss': 0.7984685877034831} | train loss {'Reaction outcome loss': 0.795483943136012, 'Total loss': 0.795483943136012}
2022-11-18 00:27:47,436 INFO:     Found new best model at epoch 83
2022-11-18 00:27:47,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:47,437 INFO:     Epoch: 84
2022-11-18 00:27:48,262 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8059173940226089, 'Total loss': 0.8059173940226089} | train loss {'Reaction outcome loss': 0.7982245687334264, 'Total loss': 0.7982245687334264}
2022-11-18 00:27:48,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:48,262 INFO:     Epoch: 85
2022-11-18 00:27:49,057 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8097855462584385, 'Total loss': 0.8097855462584385} | train loss {'Reaction outcome loss': 0.7981094071244608, 'Total loss': 0.7981094071244608}
2022-11-18 00:27:49,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:49,058 INFO:     Epoch: 86
2022-11-18 00:27:49,872 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8182992540126623, 'Total loss': 0.8182992540126623} | train loss {'Reaction outcome loss': 0.7944533225209987, 'Total loss': 0.7944533225209987}
2022-11-18 00:27:49,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:49,872 INFO:     Epoch: 87
2022-11-18 00:27:50,702 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8294327557086945, 'Total loss': 0.8294327557086945} | train loss {'Reaction outcome loss': 0.7938561799829124, 'Total loss': 0.7938561799829124}
2022-11-18 00:27:50,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:50,702 INFO:     Epoch: 88
2022-11-18 00:27:51,524 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8147380365881809, 'Total loss': 0.8147380365881809} | train loss {'Reaction outcome loss': 0.7980758437856299, 'Total loss': 0.7980758437856299}
2022-11-18 00:27:51,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:51,524 INFO:     Epoch: 89
2022-11-18 00:27:52,316 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8231645822525024, 'Total loss': 0.8231645822525024} | train loss {'Reaction outcome loss': 0.7876842924561657, 'Total loss': 0.7876842924561657}
2022-11-18 00:27:52,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:52,316 INFO:     Epoch: 90
2022-11-18 00:27:53,128 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7887911824292915, 'Total loss': 0.7887911824292915} | train loss {'Reaction outcome loss': 0.7901698206780386, 'Total loss': 0.7901698206780386}
2022-11-18 00:27:53,128 INFO:     Found new best model at epoch 90
2022-11-18 00:27:53,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:53,130 INFO:     Epoch: 91
2022-11-18 00:27:53,904 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7997765700484432, 'Total loss': 0.7997765700484432} | train loss {'Reaction outcome loss': 0.7892047368356438, 'Total loss': 0.7892047368356438}
2022-11-18 00:27:53,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:53,905 INFO:     Epoch: 92
2022-11-18 00:27:54,693 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7984878067360368, 'Total loss': 0.7984878067360368} | train loss {'Reaction outcome loss': 0.7892102026304261, 'Total loss': 0.7892102026304261}
2022-11-18 00:27:54,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:54,694 INFO:     Epoch: 93
2022-11-18 00:27:55,514 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8115706554678983, 'Total loss': 0.8115706554678983} | train loss {'Reaction outcome loss': 0.785091824585297, 'Total loss': 0.785091824585297}
2022-11-18 00:27:55,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:55,514 INFO:     Epoch: 94
2022-11-18 00:27:56,332 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8003887076710545, 'Total loss': 0.8003887076710545} | train loss {'Reaction outcome loss': 0.7872653662791995, 'Total loss': 0.7872653662791995}
2022-11-18 00:27:56,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:56,332 INFO:     Epoch: 95
2022-11-18 00:27:57,120 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7972111154434293, 'Total loss': 0.7972111154434293} | train loss {'Reaction outcome loss': 0.7823244126849487, 'Total loss': 0.7823244126849487}
2022-11-18 00:27:57,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:57,120 INFO:     Epoch: 96
2022-11-18 00:27:57,876 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7891939233901889, 'Total loss': 0.7891939233901889} | train loss {'Reaction outcome loss': 0.7897061793530573, 'Total loss': 0.7897061793530573}
2022-11-18 00:27:57,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:57,876 INFO:     Epoch: 97
2022-11-18 00:27:58,681 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.80872946561769, 'Total loss': 0.80872946561769} | train loss {'Reaction outcome loss': 0.7801418141996275, 'Total loss': 0.7801418141996275}
2022-11-18 00:27:58,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:58,681 INFO:     Epoch: 98
2022-11-18 00:27:59,481 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.82149809529615, 'Total loss': 0.82149809529615} | train loss {'Reaction outcome loss': 0.7832604768823405, 'Total loss': 0.7832604768823405}
2022-11-18 00:27:59,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:27:59,482 INFO:     Epoch: 99
2022-11-18 00:28:00,291 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8133995020112326, 'Total loss': 0.8133995020112326} | train loss {'Reaction outcome loss': 0.7788404613489011, 'Total loss': 0.7788404613489011}
2022-11-18 00:28:00,291 INFO:     Best model found after epoch 91 of 100.
2022-11-18 00:28:00,291 INFO:   Done with stage: TRAINING
2022-11-18 00:28:00,291 INFO:   Starting stage: EVALUATION
2022-11-18 00:28:00,427 INFO:   Done with stage: EVALUATION
2022-11-18 00:28:00,427 INFO:   Leaving out SEQ value Fold_1
2022-11-18 00:28:00,441 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:28:00,441 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:28:01,121 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:28:01,121 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:28:01,191 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:28:01,191 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:28:01,191 INFO:     No hyperparam tuning for this model
2022-11-18 00:28:01,191 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:28:01,191 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:28:01,192 INFO:     None feature selector for col prot
2022-11-18 00:28:01,192 INFO:     None feature selector for col prot
2022-11-18 00:28:01,192 INFO:     None feature selector for col prot
2022-11-18 00:28:01,193 INFO:     None feature selector for col chem
2022-11-18 00:28:01,193 INFO:     None feature selector for col chem
2022-11-18 00:28:01,193 INFO:     None feature selector for col chem
2022-11-18 00:28:01,193 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:28:01,193 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:28:01,195 INFO:     Number of params in model 168571
2022-11-18 00:28:01,198 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:28:01,198 INFO:   Starting stage: TRAINING
2022-11-18 00:28:01,256 INFO:     Val loss before train {'Reaction outcome loss': 1.0388482158834285, 'Total loss': 1.0388482158834285}
2022-11-18 00:28:01,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:01,256 INFO:     Epoch: 0
2022-11-18 00:28:02,052 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8950877541845496, 'Total loss': 0.8950877541845496} | train loss {'Reaction outcome loss': 0.8712424733619458, 'Total loss': 0.8712424733619458}
2022-11-18 00:28:02,052 INFO:     Found new best model at epoch 0
2022-11-18 00:28:02,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:02,053 INFO:     Epoch: 1
2022-11-18 00:28:02,853 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8821462799202312, 'Total loss': 0.8821462799202312} | train loss {'Reaction outcome loss': 0.8450805617247515, 'Total loss': 0.8450805617247515}
2022-11-18 00:28:02,853 INFO:     Found new best model at epoch 1
2022-11-18 00:28:02,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:02,854 INFO:     Epoch: 2
2022-11-18 00:28:03,672 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.850169528614391, 'Total loss': 0.850169528614391} | train loss {'Reaction outcome loss': 0.8376335028694709, 'Total loss': 0.8376335028694709}
2022-11-18 00:28:03,672 INFO:     Found new best model at epoch 2
2022-11-18 00:28:03,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:03,673 INFO:     Epoch: 3
2022-11-18 00:28:04,448 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8607344126159494, 'Total loss': 0.8607344126159494} | train loss {'Reaction outcome loss': 0.8353387784620045, 'Total loss': 0.8353387784620045}
2022-11-18 00:28:04,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:04,449 INFO:     Epoch: 4
2022-11-18 00:28:05,274 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8441559103402224, 'Total loss': 0.8441559103402224} | train loss {'Reaction outcome loss': 0.8316970537548606, 'Total loss': 0.8316970537548606}
2022-11-18 00:28:05,275 INFO:     Found new best model at epoch 4
2022-11-18 00:28:05,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:05,276 INFO:     Epoch: 5
2022-11-18 00:28:06,092 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8419593897732821, 'Total loss': 0.8419593897732821} | train loss {'Reaction outcome loss': 0.8322745953735552, 'Total loss': 0.8322745953735552}
2022-11-18 00:28:06,092 INFO:     Found new best model at epoch 5
2022-11-18 00:28:06,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:06,093 INFO:     Epoch: 6
2022-11-18 00:28:06,910 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8472365913065997, 'Total loss': 0.8472365913065997} | train loss {'Reaction outcome loss': 0.8331420456590922, 'Total loss': 0.8331420456590922}
2022-11-18 00:28:06,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:06,911 INFO:     Epoch: 7
2022-11-18 00:28:07,684 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8344737900929018, 'Total loss': 0.8344737900929018} | train loss {'Reaction outcome loss': 0.8219730747856109, 'Total loss': 0.8219730747856109}
2022-11-18 00:28:07,684 INFO:     Found new best model at epoch 7
2022-11-18 00:28:07,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:07,685 INFO:     Epoch: 8
2022-11-18 00:28:08,477 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8363408873027022, 'Total loss': 0.8363408873027022} | train loss {'Reaction outcome loss': 0.8202136262708347, 'Total loss': 0.8202136262708347}
2022-11-18 00:28:08,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:08,478 INFO:     Epoch: 9
2022-11-18 00:28:09,311 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8389788456261158, 'Total loss': 0.8389788456261158} | train loss {'Reaction outcome loss': 0.8163204473643167, 'Total loss': 0.8163204473643167}
2022-11-18 00:28:09,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:09,311 INFO:     Epoch: 10
2022-11-18 00:28:10,151 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8371096104383469, 'Total loss': 0.8371096104383469} | train loss {'Reaction outcome loss': 0.8107501129631088, 'Total loss': 0.8107501129631088}
2022-11-18 00:28:10,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:10,151 INFO:     Epoch: 11
2022-11-18 00:28:10,949 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8490914377299222, 'Total loss': 0.8490914377299222} | train loss {'Reaction outcome loss': 0.8151520268637159, 'Total loss': 0.8151520268637159}
2022-11-18 00:28:10,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:10,949 INFO:     Epoch: 12
2022-11-18 00:28:11,752 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8252052576704458, 'Total loss': 0.8252052576704458} | train loss {'Reaction outcome loss': 0.8169933737289568, 'Total loss': 0.8169933737289568}
2022-11-18 00:28:11,752 INFO:     Found new best model at epoch 12
2022-11-18 00:28:11,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:11,753 INFO:     Epoch: 13
2022-11-18 00:28:12,556 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.840887574986978, 'Total loss': 0.840887574986978} | train loss {'Reaction outcome loss': 0.8096999499479286, 'Total loss': 0.8096999499479286}
2022-11-18 00:28:12,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:12,556 INFO:     Epoch: 14
2022-11-18 00:28:13,360 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8316122862425718, 'Total loss': 0.8316122862425718} | train loss {'Reaction outcome loss': 0.812814320267936, 'Total loss': 0.812814320267936}
2022-11-18 00:28:13,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:13,360 INFO:     Epoch: 15
2022-11-18 00:28:14,140 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8275415382601998, 'Total loss': 0.8275415382601998} | train loss {'Reaction outcome loss': 0.8146846284750502, 'Total loss': 0.8146846284750502}
2022-11-18 00:28:14,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:14,140 INFO:     Epoch: 16
2022-11-18 00:28:14,911 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8520088446411219, 'Total loss': 0.8520088446411219} | train loss {'Reaction outcome loss': 0.8134150569014221, 'Total loss': 0.8134150569014221}
2022-11-18 00:28:14,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:14,911 INFO:     Epoch: 17
2022-11-18 00:28:15,705 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8317399621009827, 'Total loss': 0.8317399621009827} | train loss {'Reaction outcome loss': 0.8078266442545995, 'Total loss': 0.8078266442545995}
2022-11-18 00:28:15,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:15,705 INFO:     Epoch: 18
2022-11-18 00:28:16,520 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8727065433155407, 'Total loss': 0.8727065433155407} | train loss {'Reaction outcome loss': 0.8025366982166101, 'Total loss': 0.8025366982166101}
2022-11-18 00:28:16,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:16,521 INFO:     Epoch: 19
2022-11-18 00:28:17,336 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.846557080745697, 'Total loss': 0.846557080745697} | train loss {'Reaction outcome loss': 0.8057947750033637, 'Total loss': 0.8057947750033637}
2022-11-18 00:28:17,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:17,337 INFO:     Epoch: 20
2022-11-18 00:28:18,171 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8190811059691689, 'Total loss': 0.8190811059691689} | train loss {'Reaction outcome loss': 0.8068104047282987, 'Total loss': 0.8068104047282987}
2022-11-18 00:28:18,171 INFO:     Found new best model at epoch 20
2022-11-18 00:28:18,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:18,172 INFO:     Epoch: 21
2022-11-18 00:28:18,959 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8311995484612205, 'Total loss': 0.8311995484612205} | train loss {'Reaction outcome loss': 0.809735801417818, 'Total loss': 0.809735801417818}
2022-11-18 00:28:18,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:18,959 INFO:     Epoch: 22
2022-11-18 00:28:19,762 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8445752533999357, 'Total loss': 0.8445752533999357} | train loss {'Reaction outcome loss': 0.8134555722537794, 'Total loss': 0.8134555722537794}
2022-11-18 00:28:19,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:19,762 INFO:     Epoch: 23
2022-11-18 00:28:20,590 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8358777178959413, 'Total loss': 0.8358777178959413} | train loss {'Reaction outcome loss': 0.8036824785746061, 'Total loss': 0.8036824785746061}
2022-11-18 00:28:20,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:20,590 INFO:     Epoch: 24
2022-11-18 00:28:21,382 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8303087428212166, 'Total loss': 0.8303087428212166} | train loss {'Reaction outcome loss': 0.8065732968480963, 'Total loss': 0.8065732968480963}
2022-11-18 00:28:21,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:21,382 INFO:     Epoch: 25
2022-11-18 00:28:22,179 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8293145007707856, 'Total loss': 0.8293145007707856} | train loss {'Reaction outcome loss': 0.804706319985602, 'Total loss': 0.804706319985602}
2022-11-18 00:28:22,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:22,180 INFO:     Epoch: 26
2022-11-18 00:28:22,989 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8584175191142343, 'Total loss': 0.8584175191142343} | train loss {'Reaction outcome loss': 0.8095703389239215, 'Total loss': 0.8095703389239215}
2022-11-18 00:28:22,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:22,989 INFO:     Epoch: 27
2022-11-18 00:28:23,805 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8371943953362379, 'Total loss': 0.8371943953362379} | train loss {'Reaction outcome loss': 0.802145914389537, 'Total loss': 0.802145914389537}
2022-11-18 00:28:23,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:23,806 INFO:     Epoch: 28
2022-11-18 00:28:24,578 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8252158910036087, 'Total loss': 0.8252158910036087} | train loss {'Reaction outcome loss': 0.8062163835715669, 'Total loss': 0.8062163835715669}
2022-11-18 00:28:24,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:24,578 INFO:     Epoch: 29
2022-11-18 00:28:25,424 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8266961229118434, 'Total loss': 0.8266961229118434} | train loss {'Reaction outcome loss': 0.8111125644643297, 'Total loss': 0.8111125644643297}
2022-11-18 00:28:25,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:25,425 INFO:     Epoch: 30
2022-11-18 00:28:26,227 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8575560626658526, 'Total loss': 0.8575560626658526} | train loss {'Reaction outcome loss': 0.8047678079079037, 'Total loss': 0.8047678079079037}
2022-11-18 00:28:26,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:26,227 INFO:     Epoch: 31
2022-11-18 00:28:27,017 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8432877063751221, 'Total loss': 0.8432877063751221} | train loss {'Reaction outcome loss': 0.8070470391497439, 'Total loss': 0.8070470391497439}
2022-11-18 00:28:27,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:27,018 INFO:     Epoch: 32
2022-11-18 00:28:27,832 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8323593911799517, 'Total loss': 0.8323593911799517} | train loss {'Reaction outcome loss': 0.8068487963937072, 'Total loss': 0.8068487963937072}
2022-11-18 00:28:27,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:27,833 INFO:     Epoch: 33
2022-11-18 00:28:28,625 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8299303881146691, 'Total loss': 0.8299303881146691} | train loss {'Reaction outcome loss': 0.8137110347448573, 'Total loss': 0.8137110347448573}
2022-11-18 00:28:28,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:28,626 INFO:     Epoch: 34
2022-11-18 00:28:29,443 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8228926916014064, 'Total loss': 0.8228926916014064} | train loss {'Reaction outcome loss': 0.7978711058856988, 'Total loss': 0.7978711058856988}
2022-11-18 00:28:29,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:29,443 INFO:     Epoch: 35
2022-11-18 00:28:30,295 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8255179077386856, 'Total loss': 0.8255179077386856} | train loss {'Reaction outcome loss': 0.8042117240216567, 'Total loss': 0.8042117240216567}
2022-11-18 00:28:30,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:30,295 INFO:     Epoch: 36
2022-11-18 00:28:31,057 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8269027674740012, 'Total loss': 0.8269027674740012} | train loss {'Reaction outcome loss': 0.8040921875098457, 'Total loss': 0.8040921875098457}
2022-11-18 00:28:31,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:31,058 INFO:     Epoch: 37
2022-11-18 00:28:31,876 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8321817456321283, 'Total loss': 0.8321817456321283} | train loss {'Reaction outcome loss': 0.8023855589058718, 'Total loss': 0.8023855589058718}
2022-11-18 00:28:31,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:31,876 INFO:     Epoch: 38
2022-11-18 00:28:32,700 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8178813579407606, 'Total loss': 0.8178813579407606} | train loss {'Reaction outcome loss': 0.8080163865919537, 'Total loss': 0.8080163865919537}
2022-11-18 00:28:32,700 INFO:     Found new best model at epoch 38
2022-11-18 00:28:32,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:32,702 INFO:     Epoch: 39
2022-11-18 00:28:33,497 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8393462428992445, 'Total loss': 0.8393462428992445} | train loss {'Reaction outcome loss': 0.8097376544707218, 'Total loss': 0.8097376544707218}
2022-11-18 00:28:33,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:33,498 INFO:     Epoch: 40
2022-11-18 00:28:34,307 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8411965681747957, 'Total loss': 0.8411965681747957} | train loss {'Reaction outcome loss': 0.8077663582587532, 'Total loss': 0.8077663582587532}
2022-11-18 00:28:34,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:34,307 INFO:     Epoch: 41
2022-11-18 00:28:35,135 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8225515031001784, 'Total loss': 0.8225515031001784} | train loss {'Reaction outcome loss': 0.8033611833566596, 'Total loss': 0.8033611833566596}
2022-11-18 00:28:35,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:35,135 INFO:     Epoch: 42
2022-11-18 00:28:35,961 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8264251480048354, 'Total loss': 0.8264251480048354} | train loss {'Reaction outcome loss': 0.8075756436658774, 'Total loss': 0.8075756436658774}
2022-11-18 00:28:35,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:35,962 INFO:     Epoch: 43
2022-11-18 00:28:36,754 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.812661577354778, 'Total loss': 0.812661577354778} | train loss {'Reaction outcome loss': 0.8125499963519062, 'Total loss': 0.8125499963519062}
2022-11-18 00:28:36,755 INFO:     Found new best model at epoch 43
2022-11-18 00:28:36,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:36,755 INFO:     Epoch: 44
2022-11-18 00:28:37,583 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8571370711380785, 'Total loss': 0.8571370711380785} | train loss {'Reaction outcome loss': 0.8100781046789185, 'Total loss': 0.8100781046789185}
2022-11-18 00:28:37,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:37,584 INFO:     Epoch: 45
2022-11-18 00:28:38,401 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8676300265572288, 'Total loss': 0.8676300265572288} | train loss {'Reaction outcome loss': 0.8081191402939167, 'Total loss': 0.8081191402939167}
2022-11-18 00:28:38,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:38,401 INFO:     Epoch: 46
2022-11-18 00:28:39,221 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8415426788004962, 'Total loss': 0.8415426788004962} | train loss {'Reaction outcome loss': 0.8020432610743442, 'Total loss': 0.8020432610743442}
2022-11-18 00:28:39,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:39,221 INFO:     Epoch: 47
2022-11-18 00:28:40,011 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8285827501253649, 'Total loss': 0.8285827501253649} | train loss {'Reaction outcome loss': 0.801562842871496, 'Total loss': 0.801562842871496}
2022-11-18 00:28:40,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:40,011 INFO:     Epoch: 48
2022-11-18 00:28:40,835 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8304942372170362, 'Total loss': 0.8304942372170362} | train loss {'Reaction outcome loss': 0.8030931072136168, 'Total loss': 0.8030931072136168}
2022-11-18 00:28:40,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:40,836 INFO:     Epoch: 49
2022-11-18 00:28:41,629 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8227706416086717, 'Total loss': 0.8227706416086717} | train loss {'Reaction outcome loss': 0.8035312778795296, 'Total loss': 0.8035312778795296}
2022-11-18 00:28:41,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:41,629 INFO:     Epoch: 50
2022-11-18 00:28:42,413 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8553094349124215, 'Total loss': 0.8553094349124215} | train loss {'Reaction outcome loss': 0.8074534337530251, 'Total loss': 0.8074534337530251}
2022-11-18 00:28:42,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:42,414 INFO:     Epoch: 51
2022-11-18 00:28:43,217 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8204174888404933, 'Total loss': 0.8204174888404933} | train loss {'Reaction outcome loss': 0.8094565939867062, 'Total loss': 0.8094565939867062}
2022-11-18 00:28:43,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:43,218 INFO:     Epoch: 52
2022-11-18 00:28:43,990 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8467076583342119, 'Total loss': 0.8467076583342119} | train loss {'Reaction outcome loss': 0.8056867006819258, 'Total loss': 0.8056867006819258}
2022-11-18 00:28:43,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:43,990 INFO:     Epoch: 53
2022-11-18 00:28:44,762 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8144909035075795, 'Total loss': 0.8144909035075795} | train loss {'Reaction outcome loss': 0.8035171512167464, 'Total loss': 0.8035171512167464}
2022-11-18 00:28:44,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:44,762 INFO:     Epoch: 54
2022-11-18 00:28:45,564 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8282228918238119, 'Total loss': 0.8282228918238119} | train loss {'Reaction outcome loss': 0.8076169291729869, 'Total loss': 0.8076169291729869}
2022-11-18 00:28:45,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:45,564 INFO:     Epoch: 55
2022-11-18 00:28:46,402 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8331339833411303, 'Total loss': 0.8331339833411303} | train loss {'Reaction outcome loss': 0.8054597687111934, 'Total loss': 0.8054597687111934}
2022-11-18 00:28:46,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:46,403 INFO:     Epoch: 56
2022-11-18 00:28:47,257 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8250378207726912, 'Total loss': 0.8250378207726912} | train loss {'Reaction outcome loss': 0.8025703918234057, 'Total loss': 0.8025703918234057}
2022-11-18 00:28:47,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:47,257 INFO:     Epoch: 57
2022-11-18 00:28:48,079 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8398183245550502, 'Total loss': 0.8398183245550502} | train loss {'Reaction outcome loss': 0.8053043968523079, 'Total loss': 0.8053043968523079}
2022-11-18 00:28:48,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:48,079 INFO:     Epoch: 58
2022-11-18 00:28:48,867 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8526330400596965, 'Total loss': 0.8526330400596965} | train loss {'Reaction outcome loss': 0.8094458990251487, 'Total loss': 0.8094458990251487}
2022-11-18 00:28:48,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:48,869 INFO:     Epoch: 59
2022-11-18 00:28:49,687 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.848200187087059, 'Total loss': 0.848200187087059} | train loss {'Reaction outcome loss': 0.804916278131095, 'Total loss': 0.804916278131095}
2022-11-18 00:28:49,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:49,688 INFO:     Epoch: 60
2022-11-18 00:28:50,484 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8285422501238909, 'Total loss': 0.8285422501238909} | train loss {'Reaction outcome loss': 0.806103377810374, 'Total loss': 0.806103377810374}
2022-11-18 00:28:50,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:50,484 INFO:     Epoch: 61
2022-11-18 00:28:51,282 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8300804245201024, 'Total loss': 0.8300804245201024} | train loss {'Reaction outcome loss': 0.8055368684805356, 'Total loss': 0.8055368684805356}
2022-11-18 00:28:51,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:51,282 INFO:     Epoch: 62
2022-11-18 00:28:52,096 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8197717680172487, 'Total loss': 0.8197717680172487} | train loss {'Reaction outcome loss': 0.8010862762870093, 'Total loss': 0.8010862762870093}
2022-11-18 00:28:52,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:52,096 INFO:     Epoch: 63
2022-11-18 00:28:52,913 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.815534383058548, 'Total loss': 0.815534383058548} | train loss {'Reaction outcome loss': 0.7999253622916064, 'Total loss': 0.7999253622916064}
2022-11-18 00:28:52,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:52,914 INFO:     Epoch: 64
2022-11-18 00:28:53,703 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8467596220699224, 'Total loss': 0.8467596220699224} | train loss {'Reaction outcome loss': 0.8033239712358003, 'Total loss': 0.8033239712358003}
2022-11-18 00:28:53,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:53,703 INFO:     Epoch: 65
2022-11-18 00:28:54,533 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8406195870854638, 'Total loss': 0.8406195870854638} | train loss {'Reaction outcome loss': 0.8045927957001968, 'Total loss': 0.8045927957001968}
2022-11-18 00:28:54,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:54,533 INFO:     Epoch: 66
2022-11-18 00:28:55,363 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8199272887273268, 'Total loss': 0.8199272887273268} | train loss {'Reaction outcome loss': 0.8035504265352782, 'Total loss': 0.8035504265352782}
2022-11-18 00:28:55,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:55,364 INFO:     Epoch: 67
2022-11-18 00:28:56,202 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8360224921594966, 'Total loss': 0.8360224921594966} | train loss {'Reaction outcome loss': 0.8029340744501183, 'Total loss': 0.8029340744501183}
2022-11-18 00:28:56,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:56,202 INFO:     Epoch: 68
2022-11-18 00:28:57,011 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8410098376599225, 'Total loss': 0.8410098376599225} | train loss {'Reaction outcome loss': 0.8111123885461676, 'Total loss': 0.8111123885461676}
2022-11-18 00:28:57,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:57,011 INFO:     Epoch: 69
2022-11-18 00:28:57,847 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8461935872381384, 'Total loss': 0.8461935872381384} | train loss {'Reaction outcome loss': 0.8061500978222501, 'Total loss': 0.8061500978222501}
2022-11-18 00:28:57,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:57,847 INFO:     Epoch: 70
2022-11-18 00:28:58,624 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8497261411764405, 'Total loss': 0.8497261411764405} | train loss {'Reaction outcome loss': 0.8030964962625311, 'Total loss': 0.8030964962625311}
2022-11-18 00:28:58,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:58,624 INFO:     Epoch: 71
2022-11-18 00:28:59,439 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8218470507047393, 'Total loss': 0.8218470507047393} | train loss {'Reaction outcome loss': 0.8049016470609889, 'Total loss': 0.8049016470609889}
2022-11-18 00:28:59,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:28:59,440 INFO:     Epoch: 72
2022-11-18 00:29:00,233 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8376617336815054, 'Total loss': 0.8376617336815054} | train loss {'Reaction outcome loss': 0.8017272265092564, 'Total loss': 0.8017272265092564}
2022-11-18 00:29:00,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:00,233 INFO:     Epoch: 73
2022-11-18 00:29:01,057 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8367803658951413, 'Total loss': 0.8367803658951413} | train loss {'Reaction outcome loss': 0.8006491172410216, 'Total loss': 0.8006491172410216}
2022-11-18 00:29:01,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:01,057 INFO:     Epoch: 74
2022-11-18 00:29:01,905 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.838786321607503, 'Total loss': 0.838786321607503} | train loss {'Reaction outcome loss': 0.8050309274843347, 'Total loss': 0.8050309274843347}
2022-11-18 00:29:01,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:01,905 INFO:     Epoch: 75
2022-11-18 00:29:02,746 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.9702038101174615, 'Total loss': 0.9702038101174615} | train loss {'Reaction outcome loss': 0.801568100568254, 'Total loss': 0.801568100568254}
2022-11-18 00:29:02,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:02,746 INFO:     Epoch: 76
2022-11-18 00:29:03,531 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8265044140544805, 'Total loss': 0.8265044140544805} | train loss {'Reaction outcome loss': 0.810305341776566, 'Total loss': 0.810305341776566}
2022-11-18 00:29:03,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:03,531 INFO:     Epoch: 77
2022-11-18 00:29:04,360 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8212429359555244, 'Total loss': 0.8212429359555244} | train loss {'Reaction outcome loss': 0.8045961941302064, 'Total loss': 0.8045961941302064}
2022-11-18 00:29:04,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:04,361 INFO:     Epoch: 78
2022-11-18 00:29:05,175 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8211632594466209, 'Total loss': 0.8211632594466209} | train loss {'Reaction outcome loss': 0.8060692394310646, 'Total loss': 0.8060692394310646}
2022-11-18 00:29:05,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:05,175 INFO:     Epoch: 79
2022-11-18 00:29:06,004 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8420271047137, 'Total loss': 0.8420271047137} | train loss {'Reaction outcome loss': 0.8123323216370726, 'Total loss': 0.8123323216370726}
2022-11-18 00:29:06,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:06,004 INFO:     Epoch: 80
2022-11-18 00:29:06,804 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8289638391949914, 'Total loss': 0.8289638391949914} | train loss {'Reaction outcome loss': 0.8050758640775796, 'Total loss': 0.8050758640775796}
2022-11-18 00:29:06,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:06,804 INFO:     Epoch: 81
2022-11-18 00:29:07,610 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8252246217294172, 'Total loss': 0.8252246217294172} | train loss {'Reaction outcome loss': 0.7985223849051395, 'Total loss': 0.7985223849051395}
2022-11-18 00:29:07,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:07,611 INFO:     Epoch: 82
2022-11-18 00:29:08,409 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8449025587602095, 'Total loss': 0.8449025587602095} | train loss {'Reaction outcome loss': 0.8033916116484746, 'Total loss': 0.8033916116484746}
2022-11-18 00:29:08,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:08,409 INFO:     Epoch: 83
2022-11-18 00:29:09,218 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8255206509069963, 'Total loss': 0.8255206509069963} | train loss {'Reaction outcome loss': 0.8031541354019149, 'Total loss': 0.8031541354019149}
2022-11-18 00:29:09,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:09,218 INFO:     Epoch: 84
2022-11-18 00:29:10,019 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8420513333244757, 'Total loss': 0.8420513333244757} | train loss {'Reaction outcome loss': 0.8084164047048159, 'Total loss': 0.8084164047048159}
2022-11-18 00:29:10,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:10,019 INFO:     Epoch: 85
2022-11-18 00:29:10,863 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8299639719453725, 'Total loss': 0.8299639719453725} | train loss {'Reaction outcome loss': 0.8055417407681102, 'Total loss': 0.8055417407681102}
2022-11-18 00:29:10,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:10,864 INFO:     Epoch: 86
2022-11-18 00:29:11,683 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8686602643945001, 'Total loss': 0.8686602643945001} | train loss {'Reaction outcome loss': 0.8075736744201135, 'Total loss': 0.8075736744201135}
2022-11-18 00:29:11,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:11,683 INFO:     Epoch: 87
2022-11-18 00:29:12,506 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8347604058005593, 'Total loss': 0.8347604058005593} | train loss {'Reaction outcome loss': 0.8135843595512483, 'Total loss': 0.8135843595512483}
2022-11-18 00:29:12,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:12,507 INFO:     Epoch: 88
2022-11-18 00:29:13,277 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8479487963698127, 'Total loss': 0.8479487963698127} | train loss {'Reaction outcome loss': 0.8065209070197966, 'Total loss': 0.8065209070197966}
2022-11-18 00:29:13,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:13,277 INFO:     Epoch: 89
2022-11-18 00:29:14,093 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8359561975706707, 'Total loss': 0.8359561975706707} | train loss {'Reaction outcome loss': 0.8044934670934792, 'Total loss': 0.8044934670934792}
2022-11-18 00:29:14,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:14,093 INFO:     Epoch: 90
2022-11-18 00:29:14,882 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8611060563813556, 'Total loss': 0.8611060563813556} | train loss {'Reaction outcome loss': 0.8030848228014432, 'Total loss': 0.8030848228014432}
2022-11-18 00:29:14,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:14,882 INFO:     Epoch: 91
2022-11-18 00:29:15,659 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8223951113494959, 'Total loss': 0.8223951113494959} | train loss {'Reaction outcome loss': 0.8057467772169151, 'Total loss': 0.8057467772169151}
2022-11-18 00:29:15,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:15,659 INFO:     Epoch: 92
2022-11-18 00:29:16,440 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.816432848572731, 'Total loss': 0.816432848572731} | train loss {'Reaction outcome loss': 0.8014555120999031, 'Total loss': 0.8014555120999031}
2022-11-18 00:29:16,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:16,440 INFO:     Epoch: 93
2022-11-18 00:29:17,243 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8283143422820352, 'Total loss': 0.8283143422820352} | train loss {'Reaction outcome loss': 0.8007610648991126, 'Total loss': 0.8007610648991126}
2022-11-18 00:29:17,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:17,243 INFO:     Epoch: 94
2022-11-18 00:29:18,072 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8264014077457514, 'Total loss': 0.8264014077457514} | train loss {'Reaction outcome loss': 0.8051218734639376, 'Total loss': 0.8051218734639376}
2022-11-18 00:29:18,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:18,072 INFO:     Epoch: 95
2022-11-18 00:29:18,909 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8453326956792311, 'Total loss': 0.8453326956792311} | train loss {'Reaction outcome loss': 0.805572524847772, 'Total loss': 0.805572524847772}
2022-11-18 00:29:18,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:18,909 INFO:     Epoch: 96
2022-11-18 00:29:19,661 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8429462923244997, 'Total loss': 0.8429462923244997} | train loss {'Reaction outcome loss': 0.8037088477177176, 'Total loss': 0.8037088477177176}
2022-11-18 00:29:19,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:19,662 INFO:     Epoch: 97
2022-11-18 00:29:20,483 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8663012276996266, 'Total loss': 0.8663012276996266} | train loss {'Reaction outcome loss': 0.7949013329650226, 'Total loss': 0.7949013329650226}
2022-11-18 00:29:20,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:20,485 INFO:     Epoch: 98
2022-11-18 00:29:21,268 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8345206379890442, 'Total loss': 0.8345206379890442} | train loss {'Reaction outcome loss': 0.8110425380560068, 'Total loss': 0.8110425380560068}
2022-11-18 00:29:21,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:21,269 INFO:     Epoch: 99
2022-11-18 00:29:22,076 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8311185498129238, 'Total loss': 0.8311185498129238} | train loss {'Reaction outcome loss': 0.8013098954189162, 'Total loss': 0.8013098954189162}
2022-11-18 00:29:22,077 INFO:     Best model found after epoch 44 of 100.
2022-11-18 00:29:22,077 INFO:   Done with stage: TRAINING
2022-11-18 00:29:22,077 INFO:   Starting stage: EVALUATION
2022-11-18 00:29:22,200 INFO:   Done with stage: EVALUATION
2022-11-18 00:29:22,200 INFO:   Leaving out SEQ value Fold_2
2022-11-18 00:29:22,213 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 00:29:22,213 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:29:22,885 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:29:22,886 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:29:22,957 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:29:22,957 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:29:22,957 INFO:     No hyperparam tuning for this model
2022-11-18 00:29:22,957 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:29:22,957 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:29:22,958 INFO:     None feature selector for col prot
2022-11-18 00:29:22,958 INFO:     None feature selector for col prot
2022-11-18 00:29:22,958 INFO:     None feature selector for col prot
2022-11-18 00:29:22,959 INFO:     None feature selector for col chem
2022-11-18 00:29:22,959 INFO:     None feature selector for col chem
2022-11-18 00:29:22,959 INFO:     None feature selector for col chem
2022-11-18 00:29:22,959 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:29:22,959 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:29:22,961 INFO:     Number of params in model 168571
2022-11-18 00:29:22,964 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:29:22,964 INFO:   Starting stage: TRAINING
2022-11-18 00:29:23,021 INFO:     Val loss before train {'Reaction outcome loss': 0.930707955902273, 'Total loss': 0.930707955902273}
2022-11-18 00:29:23,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:23,021 INFO:     Epoch: 0
2022-11-18 00:29:23,777 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7791803167624907, 'Total loss': 0.7791803167624907} | train loss {'Reaction outcome loss': 0.8860623926532512, 'Total loss': 0.8860623926532512}
2022-11-18 00:29:23,778 INFO:     Found new best model at epoch 0
2022-11-18 00:29:23,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:23,778 INFO:     Epoch: 1
2022-11-18 00:29:24,595 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7955448451367292, 'Total loss': 0.7955448451367292} | train loss {'Reaction outcome loss': 0.8524602935022237, 'Total loss': 0.8524602935022237}
2022-11-18 00:29:24,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:24,596 INFO:     Epoch: 2
2022-11-18 00:29:25,355 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7896385050632737, 'Total loss': 0.7896385050632737} | train loss {'Reaction outcome loss': 0.8555976766712812, 'Total loss': 0.8555976766712812}
2022-11-18 00:29:25,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:25,355 INFO:     Epoch: 3
2022-11-18 00:29:26,215 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7786793383685026, 'Total loss': 0.7786793383685026} | train loss {'Reaction outcome loss': 0.8445330364363534, 'Total loss': 0.8445330364363534}
2022-11-18 00:29:26,215 INFO:     Found new best model at epoch 3
2022-11-18 00:29:26,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:26,215 INFO:     Epoch: 4
2022-11-18 00:29:27,039 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7782348577271808, 'Total loss': 0.7782348577271808} | train loss {'Reaction outcome loss': 0.8412164920446824, 'Total loss': 0.8412164920446824}
2022-11-18 00:29:27,039 INFO:     Found new best model at epoch 4
2022-11-18 00:29:27,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:27,041 INFO:     Epoch: 5
2022-11-18 00:29:27,869 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.796235700222579, 'Total loss': 0.796235700222579} | train loss {'Reaction outcome loss': 0.8376689339170651, 'Total loss': 0.8376689339170651}
2022-11-18 00:29:27,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:27,870 INFO:     Epoch: 6
2022-11-18 00:29:28,664 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7808105390180241, 'Total loss': 0.7808105390180241} | train loss {'Reaction outcome loss': 0.8379385529732217, 'Total loss': 0.8379385529732217}
2022-11-18 00:29:28,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:28,665 INFO:     Epoch: 7
2022-11-18 00:29:29,487 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7958810803565112, 'Total loss': 0.7958810803565112} | train loss {'Reaction outcome loss': 0.8331880312793108, 'Total loss': 0.8331880312793108}
2022-11-18 00:29:29,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:29,487 INFO:     Epoch: 8
2022-11-18 00:29:30,257 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7867681682109833, 'Total loss': 0.7867681682109833} | train loss {'Reaction outcome loss': 0.8315083969612511, 'Total loss': 0.8315083969612511}
2022-11-18 00:29:30,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:30,257 INFO:     Epoch: 9
2022-11-18 00:29:31,054 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7781782607463273, 'Total loss': 0.7781782607463273} | train loss {'Reaction outcome loss': 0.8346624964353989, 'Total loss': 0.8346624964353989}
2022-11-18 00:29:31,055 INFO:     Found new best model at epoch 9
2022-11-18 00:29:31,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:31,055 INFO:     Epoch: 10
2022-11-18 00:29:31,864 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7889590879732912, 'Total loss': 0.7889590879732912} | train loss {'Reaction outcome loss': 0.8283327428662047, 'Total loss': 0.8283327428662047}
2022-11-18 00:29:31,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:31,864 INFO:     Epoch: 11
2022-11-18 00:29:32,655 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7616691975431009, 'Total loss': 0.7616691975431009} | train loss {'Reaction outcome loss': 0.8293347440203842, 'Total loss': 0.8293347440203842}
2022-11-18 00:29:32,656 INFO:     Found new best model at epoch 11
2022-11-18 00:29:32,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:32,657 INFO:     Epoch: 12
2022-11-18 00:29:33,438 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7799611633474176, 'Total loss': 0.7799611633474176} | train loss {'Reaction outcome loss': 0.8302202375567689, 'Total loss': 0.8302202375567689}
2022-11-18 00:29:33,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:33,438 INFO:     Epoch: 13
2022-11-18 00:29:34,219 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7607037980448116, 'Total loss': 0.7607037980448116} | train loss {'Reaction outcome loss': 0.8288428344288651, 'Total loss': 0.8288428344288651}
2022-11-18 00:29:34,219 INFO:     Found new best model at epoch 13
2022-11-18 00:29:34,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:34,220 INFO:     Epoch: 14
2022-11-18 00:29:35,014 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7631839561191472, 'Total loss': 0.7631839561191472} | train loss {'Reaction outcome loss': 0.8240866754736219, 'Total loss': 0.8240866754736219}
2022-11-18 00:29:35,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:35,015 INFO:     Epoch: 15
2022-11-18 00:29:35,810 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7800435410304503, 'Total loss': 0.7800435410304503} | train loss {'Reaction outcome loss': 0.8300462518419538, 'Total loss': 0.8300462518419538}
2022-11-18 00:29:35,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:35,810 INFO:     Epoch: 16
2022-11-18 00:29:36,643 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7704919034784491, 'Total loss': 0.7704919034784491} | train loss {'Reaction outcome loss': 0.8256539689034832, 'Total loss': 0.8256539689034832}
2022-11-18 00:29:36,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:36,644 INFO:     Epoch: 17
2022-11-18 00:29:37,420 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7738998925144022, 'Total loss': 0.7738998925144022} | train loss {'Reaction outcome loss': 0.8283671345029558, 'Total loss': 0.8283671345029558}
2022-11-18 00:29:37,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:37,420 INFO:     Epoch: 18
2022-11-18 00:29:38,220 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7654648128558289, 'Total loss': 0.7654648128558289} | train loss {'Reaction outcome loss': 0.8268946154993407, 'Total loss': 0.8268946154993407}
2022-11-18 00:29:38,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:38,221 INFO:     Epoch: 19
2022-11-18 00:29:39,027 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7626589841463349, 'Total loss': 0.7626589841463349} | train loss {'Reaction outcome loss': 0.8286387840095831, 'Total loss': 0.8286387840095831}
2022-11-18 00:29:39,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:39,028 INFO:     Epoch: 20
2022-11-18 00:29:39,842 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7851738347248598, 'Total loss': 0.7851738347248598} | train loss {'Reaction outcome loss': 0.8234483580200039, 'Total loss': 0.8234483580200039}
2022-11-18 00:29:39,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:39,843 INFO:     Epoch: 21
2022-11-18 00:29:40,616 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7709099684249271, 'Total loss': 0.7709099684249271} | train loss {'Reaction outcome loss': 0.8273131222141032, 'Total loss': 0.8273131222141032}
2022-11-18 00:29:40,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:40,617 INFO:     Epoch: 22
2022-11-18 00:29:41,432 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7685382047837431, 'Total loss': 0.7685382047837431} | train loss {'Reaction outcome loss': 0.8222245093511076, 'Total loss': 0.8222245093511076}
2022-11-18 00:29:41,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:41,432 INFO:     Epoch: 23
2022-11-18 00:29:42,216 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7654374743049795, 'Total loss': 0.7654374743049795} | train loss {'Reaction outcome loss': 0.8272239607207629, 'Total loss': 0.8272239607207629}
2022-11-18 00:29:42,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:42,217 INFO:     Epoch: 24
2022-11-18 00:29:43,020 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7614667347886346, 'Total loss': 0.7614667347886346} | train loss {'Reaction outcome loss': 0.8238052419253759, 'Total loss': 0.8238052419253759}
2022-11-18 00:29:43,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:43,020 INFO:     Epoch: 25
2022-11-18 00:29:43,834 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7542241222479127, 'Total loss': 0.7542241222479127} | train loss {'Reaction outcome loss': 0.8239966796368968, 'Total loss': 0.8239966796368968}
2022-11-18 00:29:43,834 INFO:     Found new best model at epoch 25
2022-11-18 00:29:43,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:43,835 INFO:     Epoch: 26
2022-11-18 00:29:44,649 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7823749502951448, 'Total loss': 0.7823749502951448} | train loss {'Reaction outcome loss': 0.8220713276035931, 'Total loss': 0.8220713276035931}
2022-11-18 00:29:44,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:44,649 INFO:     Epoch: 27
2022-11-18 00:29:45,438 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7570703984661535, 'Total loss': 0.7570703984661535} | train loss {'Reaction outcome loss': 0.8223619827202389, 'Total loss': 0.8223619827202389}
2022-11-18 00:29:45,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:45,438 INFO:     Epoch: 28
2022-11-18 00:29:46,255 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7751990583809939, 'Total loss': 0.7751990583809939} | train loss {'Reaction outcome loss': 0.8279083030564445, 'Total loss': 0.8279083030564445}
2022-11-18 00:29:46,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:46,255 INFO:     Epoch: 29
2022-11-18 00:29:47,029 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7670669667422771, 'Total loss': 0.7670669667422771} | train loss {'Reaction outcome loss': 0.8228336985013923, 'Total loss': 0.8228336985013923}
2022-11-18 00:29:47,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:47,029 INFO:     Epoch: 30
2022-11-18 00:29:47,845 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7654392996972258, 'Total loss': 0.7654392996972258} | train loss {'Reaction outcome loss': 0.8225412203341115, 'Total loss': 0.8225412203341115}
2022-11-18 00:29:47,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:47,845 INFO:     Epoch: 31
2022-11-18 00:29:48,683 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7759773629632863, 'Total loss': 0.7759773629632863} | train loss {'Reaction outcome loss': 0.8244101150911681, 'Total loss': 0.8244101150911681}
2022-11-18 00:29:48,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:48,684 INFO:     Epoch: 32
2022-11-18 00:29:49,465 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7614307308738882, 'Total loss': 0.7614307308738882} | train loss {'Reaction outcome loss': 0.8192222265564666, 'Total loss': 0.8192222265564666}
2022-11-18 00:29:49,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:49,466 INFO:     Epoch: 33
2022-11-18 00:29:50,256 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7581812339750204, 'Total loss': 0.7581812339750204} | train loss {'Reaction outcome loss': 0.8241701293964775, 'Total loss': 0.8241701293964775}
2022-11-18 00:29:50,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:50,257 INFO:     Epoch: 34
2022-11-18 00:29:51,021 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7602093538100069, 'Total loss': 0.7602093538100069} | train loss {'Reaction outcome loss': 0.8167289907834968, 'Total loss': 0.8167289907834968}
2022-11-18 00:29:51,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:51,022 INFO:     Epoch: 35
2022-11-18 00:29:51,806 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7658070474863052, 'Total loss': 0.7658070474863052} | train loss {'Reaction outcome loss': 0.8294597640329477, 'Total loss': 0.8294597640329477}
2022-11-18 00:29:51,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:51,806 INFO:     Epoch: 36
2022-11-18 00:29:52,594 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7612694786353544, 'Total loss': 0.7612694786353544} | train loss {'Reaction outcome loss': 0.8189818614599657, 'Total loss': 0.8189818614599657}
2022-11-18 00:29:52,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:52,595 INFO:     Epoch: 37
2022-11-18 00:29:53,347 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7697841376066208, 'Total loss': 0.7697841376066208} | train loss {'Reaction outcome loss': 0.8229721693360076, 'Total loss': 0.8229721693360076}
2022-11-18 00:29:53,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:53,347 INFO:     Epoch: 38
2022-11-18 00:29:54,115 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7568392882292921, 'Total loss': 0.7568392882292921} | train loss {'Reaction outcome loss': 0.8244945968900408, 'Total loss': 0.8244945968900408}
2022-11-18 00:29:54,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:54,115 INFO:     Epoch: 39
2022-11-18 00:29:54,896 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7665054940364577, 'Total loss': 0.7665054940364577} | train loss {'Reaction outcome loss': 0.8282732712979219, 'Total loss': 0.8282732712979219}
2022-11-18 00:29:54,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:54,896 INFO:     Epoch: 40
2022-11-18 00:29:55,667 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.759699250486764, 'Total loss': 0.759699250486764} | train loss {'Reaction outcome loss': 0.8226640326636178, 'Total loss': 0.8226640326636178}
2022-11-18 00:29:55,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:55,667 INFO:     Epoch: 41
2022-11-18 00:29:56,422 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7538547414270315, 'Total loss': 0.7538547414270315} | train loss {'Reaction outcome loss': 0.8229349077964315, 'Total loss': 0.8229349077964315}
2022-11-18 00:29:56,422 INFO:     Found new best model at epoch 41
2022-11-18 00:29:56,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:56,423 INFO:     Epoch: 42
2022-11-18 00:29:57,210 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7662428373640234, 'Total loss': 0.7662428373640234} | train loss {'Reaction outcome loss': 0.8234809167531072, 'Total loss': 0.8234809167531072}
2022-11-18 00:29:57,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:57,211 INFO:     Epoch: 43
2022-11-18 00:29:57,988 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7618023726073179, 'Total loss': 0.7618023726073179} | train loss {'Reaction outcome loss': 0.8211042688817394, 'Total loss': 0.8211042688817394}
2022-11-18 00:29:57,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:57,988 INFO:     Epoch: 44
2022-11-18 00:29:58,761 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7863751555030997, 'Total loss': 0.7863751555030997} | train loss {'Reaction outcome loss': 0.8212830755175377, 'Total loss': 0.8212830755175377}
2022-11-18 00:29:58,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:58,761 INFO:     Epoch: 45
2022-11-18 00:29:59,544 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7566261535341089, 'Total loss': 0.7566261535341089} | train loss {'Reaction outcome loss': 0.8221901025090899, 'Total loss': 0.8221901025090899}
2022-11-18 00:29:59,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:29:59,544 INFO:     Epoch: 46
2022-11-18 00:30:00,317 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7943234971978448, 'Total loss': 0.7943234971978448} | train loss {'Reaction outcome loss': 0.8205831629889352, 'Total loss': 0.8205831629889352}
2022-11-18 00:30:00,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:00,317 INFO:     Epoch: 47
2022-11-18 00:30:01,124 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7734308872710575, 'Total loss': 0.7734308872710575} | train loss {'Reaction outcome loss': 0.8257152245969188, 'Total loss': 0.8257152245969188}
2022-11-18 00:30:01,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:01,124 INFO:     Epoch: 48
2022-11-18 00:30:01,916 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7752563540231098, 'Total loss': 0.7752563540231098} | train loss {'Reaction outcome loss': 0.820362332889012, 'Total loss': 0.820362332889012}
2022-11-18 00:30:01,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:01,916 INFO:     Epoch: 49
2022-11-18 00:30:02,692 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7529095529832623, 'Total loss': 0.7529095529832623} | train loss {'Reaction outcome loss': 0.821344868260987, 'Total loss': 0.821344868260987}
2022-11-18 00:30:02,692 INFO:     Found new best model at epoch 49
2022-11-18 00:30:02,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:02,693 INFO:     Epoch: 50
2022-11-18 00:30:03,448 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7599537365815856, 'Total loss': 0.7599537365815856} | train loss {'Reaction outcome loss': 0.8226646265205072, 'Total loss': 0.8226646265205072}
2022-11-18 00:30:03,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:03,449 INFO:     Epoch: 51
2022-11-18 00:30:04,209 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7549412148919973, 'Total loss': 0.7549412148919973} | train loss {'Reaction outcome loss': 0.825013428074973, 'Total loss': 0.825013428074973}
2022-11-18 00:30:04,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:04,209 INFO:     Epoch: 52
2022-11-18 00:30:04,976 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7645355618812821, 'Total loss': 0.7645355618812821} | train loss {'Reaction outcome loss': 0.8177455299971055, 'Total loss': 0.8177455299971055}
2022-11-18 00:30:04,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:04,977 INFO:     Epoch: 53
2022-11-18 00:30:05,751 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7557416063818064, 'Total loss': 0.7557416063818064} | train loss {'Reaction outcome loss': 0.8210244031584992, 'Total loss': 0.8210244031584992}
2022-11-18 00:30:05,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:05,751 INFO:     Epoch: 54
2022-11-18 00:30:06,534 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7661426328122616, 'Total loss': 0.7661426328122616} | train loss {'Reaction outcome loss': 0.8227119410524563, 'Total loss': 0.8227119410524563}
2022-11-18 00:30:06,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:06,534 INFO:     Epoch: 55
2022-11-18 00:30:07,320 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7747235501354391, 'Total loss': 0.7747235501354391} | train loss {'Reaction outcome loss': 0.8211151531764439, 'Total loss': 0.8211151531764439}
2022-11-18 00:30:07,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:07,321 INFO:     Epoch: 56
2022-11-18 00:30:08,079 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7719895081086592, 'Total loss': 0.7719895081086592} | train loss {'Reaction outcome loss': 0.8234888495231162, 'Total loss': 0.8234888495231162}
2022-11-18 00:30:08,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:08,079 INFO:     Epoch: 57
2022-11-18 00:30:08,858 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7553275532343171, 'Total loss': 0.7553275532343171} | train loss {'Reaction outcome loss': 0.8226863070410125, 'Total loss': 0.8226863070410125}
2022-11-18 00:30:08,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:08,858 INFO:     Epoch: 58
2022-11-18 00:30:09,632 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7643319232897325, 'Total loss': 0.7643319232897325} | train loss {'Reaction outcome loss': 0.8266666957310268, 'Total loss': 0.8266666957310268}
2022-11-18 00:30:09,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:09,633 INFO:     Epoch: 59
2022-11-18 00:30:10,399 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7579311376268213, 'Total loss': 0.7579311376268213} | train loss {'Reaction outcome loss': 0.8239169569648042, 'Total loss': 0.8239169569648042}
2022-11-18 00:30:10,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:10,399 INFO:     Epoch: 60
2022-11-18 00:30:11,172 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7606026076457717, 'Total loss': 0.7606026076457717} | train loss {'Reaction outcome loss': 0.8246608073614081, 'Total loss': 0.8246608073614081}
2022-11-18 00:30:11,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:11,172 INFO:     Epoch: 61
2022-11-18 00:30:11,973 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7617955979975787, 'Total loss': 0.7617955979975787} | train loss {'Reaction outcome loss': 0.8217378684452602, 'Total loss': 0.8217378684452602}
2022-11-18 00:30:11,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:11,973 INFO:     Epoch: 62
2022-11-18 00:30:12,741 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7532957731322809, 'Total loss': 0.7532957731322809} | train loss {'Reaction outcome loss': 0.8219441055035105, 'Total loss': 0.8219441055035105}
2022-11-18 00:30:12,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:12,742 INFO:     Epoch: 63
2022-11-18 00:30:13,511 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7439104178073731, 'Total loss': 0.7439104178073731} | train loss {'Reaction outcome loss': 0.8231343057690834, 'Total loss': 0.8231343057690834}
2022-11-18 00:30:13,512 INFO:     Found new best model at epoch 63
2022-11-18 00:30:13,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:13,512 INFO:     Epoch: 64
2022-11-18 00:30:14,277 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8036487989804961, 'Total loss': 0.8036487989804961} | train loss {'Reaction outcome loss': 0.8225387323875817, 'Total loss': 0.8225387323875817}
2022-11-18 00:30:14,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:14,278 INFO:     Epoch: 65
2022-11-18 00:30:15,071 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.791773871942, 'Total loss': 0.791773871942} | train loss {'Reaction outcome loss': 0.8266856840678624, 'Total loss': 0.8266856840678624}
2022-11-18 00:30:15,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:15,072 INFO:     Epoch: 66
2022-11-18 00:30:15,834 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7409986282952807, 'Total loss': 0.7409986282952807} | train loss {'Reaction outcome loss': 0.8223502707724668, 'Total loss': 0.8223502707724668}
2022-11-18 00:30:15,834 INFO:     Found new best model at epoch 66
2022-11-18 00:30:15,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:15,835 INFO:     Epoch: 67
2022-11-18 00:30:16,636 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7742271491072394, 'Total loss': 0.7742271491072394} | train loss {'Reaction outcome loss': 0.8253694944235743, 'Total loss': 0.8253694944235743}
2022-11-18 00:30:16,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:16,636 INFO:     Epoch: 68
2022-11-18 00:30:17,393 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7587325843897733, 'Total loss': 0.7587325843897733} | train loss {'Reaction outcome loss': 0.8248608978427187, 'Total loss': 0.8248608978427187}
2022-11-18 00:30:17,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:17,393 INFO:     Epoch: 69
2022-11-18 00:30:18,172 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7917356023734267, 'Total loss': 0.7917356023734267} | train loss {'Reaction outcome loss': 0.8206217827845593, 'Total loss': 0.8206217827845593}
2022-11-18 00:30:18,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:18,173 INFO:     Epoch: 70
2022-11-18 00:30:18,939 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7733179947192018, 'Total loss': 0.7733179947192018} | train loss {'Reaction outcome loss': 0.816793405888032, 'Total loss': 0.816793405888032}
2022-11-18 00:30:18,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:18,939 INFO:     Epoch: 71
2022-11-18 00:30:19,730 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7604153379797935, 'Total loss': 0.7604153379797935} | train loss {'Reaction outcome loss': 0.8284794569015503, 'Total loss': 0.8284794569015503}
2022-11-18 00:30:19,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:19,730 INFO:     Epoch: 72
2022-11-18 00:30:20,480 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7544791461391882, 'Total loss': 0.7544791461391882} | train loss {'Reaction outcome loss': 0.8206589599653166, 'Total loss': 0.8206589599653166}
2022-11-18 00:30:20,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:20,481 INFO:     Epoch: 73
2022-11-18 00:30:21,250 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7681394171985713, 'Total loss': 0.7681394171985713} | train loss {'Reaction outcome loss': 0.8229136093538635, 'Total loss': 0.8229136093538635}
2022-11-18 00:30:21,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:21,251 INFO:     Epoch: 74
2022-11-18 00:30:22,045 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.746859035031362, 'Total loss': 0.746859035031362} | train loss {'Reaction outcome loss': 0.818725124062324, 'Total loss': 0.818725124062324}
2022-11-18 00:30:22,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:22,045 INFO:     Epoch: 75
2022-11-18 00:30:22,815 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.745616960931908, 'Total loss': 0.745616960931908} | train loss {'Reaction outcome loss': 0.8206282042727179, 'Total loss': 0.8206282042727179}
2022-11-18 00:30:22,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:22,816 INFO:     Epoch: 76
2022-11-18 00:30:23,578 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7626879865472967, 'Total loss': 0.7626879865472967} | train loss {'Reaction outcome loss': 0.8256465723319929, 'Total loss': 0.8256465723319929}
2022-11-18 00:30:23,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:23,578 INFO:     Epoch: 77
2022-11-18 00:30:24,375 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7513069750910456, 'Total loss': 0.7513069750910456} | train loss {'Reaction outcome loss': 0.8187087704940718, 'Total loss': 0.8187087704940718}
2022-11-18 00:30:24,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:24,375 INFO:     Epoch: 78
2022-11-18 00:30:25,157 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7594335526227951, 'Total loss': 0.7594335526227951} | train loss {'Reaction outcome loss': 0.8171779562015923, 'Total loss': 0.8171779562015923}
2022-11-18 00:30:25,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:25,158 INFO:     Epoch: 79
2022-11-18 00:30:25,944 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7837393548000943, 'Total loss': 0.7837393548000943} | train loss {'Reaction outcome loss': 0.8218377643701982, 'Total loss': 0.8218377643701982}
2022-11-18 00:30:25,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:25,944 INFO:     Epoch: 80
2022-11-18 00:30:26,773 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7703003930774602, 'Total loss': 0.7703003930774602} | train loss {'Reaction outcome loss': 0.8230536629959029, 'Total loss': 0.8230536629959029}
2022-11-18 00:30:26,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:26,773 INFO:     Epoch: 81
2022-11-18 00:30:27,573 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7764667888933962, 'Total loss': 0.7764667888933962} | train loss {'Reaction outcome loss': 0.8224102634556439, 'Total loss': 0.8224102634556439}
2022-11-18 00:30:27,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:27,573 INFO:     Epoch: 82
2022-11-18 00:30:28,412 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.780879143286835, 'Total loss': 0.780879143286835} | train loss {'Reaction outcome loss': 0.8252423667177862, 'Total loss': 0.8252423667177862}
2022-11-18 00:30:28,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:28,412 INFO:     Epoch: 83
2022-11-18 00:30:29,230 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7650022899562662, 'Total loss': 0.7650022899562662} | train loss {'Reaction outcome loss': 0.8229282919241457, 'Total loss': 0.8229282919241457}
2022-11-18 00:30:29,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:29,231 INFO:     Epoch: 84
2022-11-18 00:30:30,072 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.765634569932114, 'Total loss': 0.765634569932114} | train loss {'Reaction outcome loss': 0.8235874332943741, 'Total loss': 0.8235874332943741}
2022-11-18 00:30:30,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:30,073 INFO:     Epoch: 85
2022-11-18 00:30:30,840 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7487129359082743, 'Total loss': 0.7487129359082743} | train loss {'Reaction outcome loss': 0.8202557931140978, 'Total loss': 0.8202557931140978}
2022-11-18 00:30:30,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:30,840 INFO:     Epoch: 86
2022-11-18 00:30:31,622 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7571024745702744, 'Total loss': 0.7571024745702744} | train loss {'Reaction outcome loss': 0.8198212730641268, 'Total loss': 0.8198212730641268}
2022-11-18 00:30:31,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:31,622 INFO:     Epoch: 87
2022-11-18 00:30:32,432 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7441364130513235, 'Total loss': 0.7441364130513235} | train loss {'Reaction outcome loss': 0.8221091943127768, 'Total loss': 0.8221091943127768}
2022-11-18 00:30:32,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:32,433 INFO:     Epoch: 88
2022-11-18 00:30:33,208 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7578839991580356, 'Total loss': 0.7578839991580356} | train loss {'Reaction outcome loss': 0.8211917318859879, 'Total loss': 0.8211917318859879}
2022-11-18 00:30:33,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:33,208 INFO:     Epoch: 89
2022-11-18 00:30:34,024 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7789173491976478, 'Total loss': 0.7789173491976478} | train loss {'Reaction outcome loss': 0.8229066073894501, 'Total loss': 0.8229066073894501}
2022-11-18 00:30:34,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:34,025 INFO:     Epoch: 90
2022-11-18 00:30:34,824 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7606559890237722, 'Total loss': 0.7606559890237722} | train loss {'Reaction outcome loss': 0.8235152373508531, 'Total loss': 0.8235152373508531}
2022-11-18 00:30:34,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:34,824 INFO:     Epoch: 91
2022-11-18 00:30:35,616 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7707835720344023, 'Total loss': 0.7707835720344023} | train loss {'Reaction outcome loss': 0.8203285334061603, 'Total loss': 0.8203285334061603}
2022-11-18 00:30:35,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:35,616 INFO:     Epoch: 92
2022-11-18 00:30:36,424 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7657698751850561, 'Total loss': 0.7657698751850561} | train loss {'Reaction outcome loss': 0.8243315195550724, 'Total loss': 0.8243315195550724}
2022-11-18 00:30:36,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:36,424 INFO:     Epoch: 93
2022-11-18 00:30:37,213 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7512362016872927, 'Total loss': 0.7512362016872927} | train loss {'Reaction outcome loss': 0.8210445136440043, 'Total loss': 0.8210445136440043}
2022-11-18 00:30:37,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:37,213 INFO:     Epoch: 94
2022-11-18 00:30:38,027 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7684281969612295, 'Total loss': 0.7684281969612295} | train loss {'Reaction outcome loss': 0.8177745800845477, 'Total loss': 0.8177745800845477}
2022-11-18 00:30:38,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:38,028 INFO:     Epoch: 95
2022-11-18 00:30:38,834 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7823101417584852, 'Total loss': 0.7823101417584852} | train loss {'Reaction outcome loss': 0.8222265923509793, 'Total loss': 0.8222265923509793}
2022-11-18 00:30:38,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:38,834 INFO:     Epoch: 96
2022-11-18 00:30:39,632 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7551932084289464, 'Total loss': 0.7551932084289464} | train loss {'Reaction outcome loss': 0.8191396011381733, 'Total loss': 0.8191396011381733}
2022-11-18 00:30:39,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:39,633 INFO:     Epoch: 97
2022-11-18 00:30:40,447 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7525083774870093, 'Total loss': 0.7525083774870093} | train loss {'Reaction outcome loss': 0.8228512430677608, 'Total loss': 0.8228512430677608}
2022-11-18 00:30:40,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:40,448 INFO:     Epoch: 98
2022-11-18 00:30:41,276 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7603372890840877, 'Total loss': 0.7603372890840877} | train loss {'Reaction outcome loss': 0.8195944340861574, 'Total loss': 0.8195944340861574}
2022-11-18 00:30:41,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:41,277 INFO:     Epoch: 99
2022-11-18 00:30:42,077 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7602866000749848, 'Total loss': 0.7602866000749848} | train loss {'Reaction outcome loss': 0.8184705206326076, 'Total loss': 0.8184705206326076}
2022-11-18 00:30:42,077 INFO:     Best model found after epoch 67 of 100.
2022-11-18 00:30:42,077 INFO:   Done with stage: TRAINING
2022-11-18 00:30:42,077 INFO:   Starting stage: EVALUATION
2022-11-18 00:30:42,207 INFO:   Done with stage: EVALUATION
2022-11-18 00:30:42,207 INFO:   Leaving out SEQ value Fold_3
2022-11-18 00:30:42,221 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 00:30:42,221 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:30:42,892 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:30:42,892 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:30:42,963 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:30:42,963 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:30:42,963 INFO:     No hyperparam tuning for this model
2022-11-18 00:30:42,963 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:30:42,963 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:30:42,964 INFO:     None feature selector for col prot
2022-11-18 00:30:42,964 INFO:     None feature selector for col prot
2022-11-18 00:30:42,964 INFO:     None feature selector for col prot
2022-11-18 00:30:42,965 INFO:     None feature selector for col chem
2022-11-18 00:30:42,965 INFO:     None feature selector for col chem
2022-11-18 00:30:42,965 INFO:     None feature selector for col chem
2022-11-18 00:30:42,965 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:30:42,965 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:30:42,967 INFO:     Number of params in model 168571
2022-11-18 00:30:42,970 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:30:42,970 INFO:   Starting stage: TRAINING
2022-11-18 00:30:43,027 INFO:     Val loss before train {'Reaction outcome loss': 0.9549242529002103, 'Total loss': 0.9549242529002103}
2022-11-18 00:30:43,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:43,028 INFO:     Epoch: 0
2022-11-18 00:30:43,803 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8269394839351828, 'Total loss': 0.8269394839351828} | train loss {'Reaction outcome loss': 0.8800519631833447, 'Total loss': 0.8800519631833447}
2022-11-18 00:30:43,803 INFO:     Found new best model at epoch 0
2022-11-18 00:30:43,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:43,804 INFO:     Epoch: 1
2022-11-18 00:30:44,615 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8144943570210175, 'Total loss': 0.8144943570210175} | train loss {'Reaction outcome loss': 0.8532705825202319, 'Total loss': 0.8532705825202319}
2022-11-18 00:30:44,615 INFO:     Found new best model at epoch 1
2022-11-18 00:30:44,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:44,616 INFO:     Epoch: 2
2022-11-18 00:30:45,442 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7999658747152849, 'Total loss': 0.7999658747152849} | train loss {'Reaction outcome loss': 0.8480853122107836, 'Total loss': 0.8480853122107836}
2022-11-18 00:30:45,442 INFO:     Found new best model at epoch 2
2022-11-18 00:30:45,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:45,443 INFO:     Epoch: 3
2022-11-18 00:30:46,251 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8035792190242897, 'Total loss': 0.8035792190242897} | train loss {'Reaction outcome loss': 0.8435686752504232, 'Total loss': 0.8435686752504232}
2022-11-18 00:30:46,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:46,251 INFO:     Epoch: 4
2022-11-18 00:30:47,043 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7961777126924559, 'Total loss': 0.7961777126924559} | train loss {'Reaction outcome loss': 0.8427842805580217, 'Total loss': 0.8427842805580217}
2022-11-18 00:30:47,043 INFO:     Found new best model at epoch 4
2022-11-18 00:30:47,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:47,044 INFO:     Epoch: 5
2022-11-18 00:30:47,824 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8317260457710787, 'Total loss': 0.8317260457710787} | train loss {'Reaction outcome loss': 0.833129771509949, 'Total loss': 0.833129771509949}
2022-11-18 00:30:47,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:47,825 INFO:     Epoch: 6
2022-11-18 00:30:48,671 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8047756796533411, 'Total loss': 0.8047756796533411} | train loss {'Reaction outcome loss': 0.8309440560486852, 'Total loss': 0.8309440560486852}
2022-11-18 00:30:48,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:48,671 INFO:     Epoch: 7
2022-11-18 00:30:49,492 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8107032152739438, 'Total loss': 0.8107032152739438} | train loss {'Reaction outcome loss': 0.8283109860760826, 'Total loss': 0.8283109860760826}
2022-11-18 00:30:49,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:49,492 INFO:     Epoch: 8
2022-11-18 00:30:50,280 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8193637484853918, 'Total loss': 0.8193637484853918} | train loss {'Reaction outcome loss': 0.832158040878724, 'Total loss': 0.832158040878724}
2022-11-18 00:30:50,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:50,280 INFO:     Epoch: 9
2022-11-18 00:30:51,091 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8218201568180864, 'Total loss': 0.8218201568180864} | train loss {'Reaction outcome loss': 0.8243542358583333, 'Total loss': 0.8243542358583333}
2022-11-18 00:30:51,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:51,091 INFO:     Epoch: 10
2022-11-18 00:30:51,895 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8197759078307585, 'Total loss': 0.8197759078307585} | train loss {'Reaction outcome loss': 0.8298665798440271, 'Total loss': 0.8298665798440271}
2022-11-18 00:30:51,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:51,896 INFO:     Epoch: 11
2022-11-18 00:30:52,681 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8030954680659554, 'Total loss': 0.8030954680659554} | train loss {'Reaction outcome loss': 0.8286892663459389, 'Total loss': 0.8286892663459389}
2022-11-18 00:30:52,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:52,682 INFO:     Epoch: 12
2022-11-18 00:30:53,463 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8239672224630009, 'Total loss': 0.8239672224630009} | train loss {'Reaction outcome loss': 0.8299012444457229, 'Total loss': 0.8299012444457229}
2022-11-18 00:30:53,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:53,465 INFO:     Epoch: 13
2022-11-18 00:30:54,309 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7962042486125772, 'Total loss': 0.7962042486125772} | train loss {'Reaction outcome loss': 0.8294568732076761, 'Total loss': 0.8294568732076761}
2022-11-18 00:30:54,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:54,309 INFO:     Epoch: 14
2022-11-18 00:30:55,106 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7969445532018488, 'Total loss': 0.7969445532018488} | train loss {'Reaction outcome loss': 0.8238279295210935, 'Total loss': 0.8238279295210935}
2022-11-18 00:30:55,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:55,106 INFO:     Epoch: 15
2022-11-18 00:30:55,868 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.792761352929202, 'Total loss': 0.792761352929202} | train loss {'Reaction outcome loss': 0.8224186054297856, 'Total loss': 0.8224186054297856}
2022-11-18 00:30:55,868 INFO:     Found new best model at epoch 15
2022-11-18 00:30:55,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:55,869 INFO:     Epoch: 16
2022-11-18 00:30:56,683 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7933875931934877, 'Total loss': 0.7933875931934877} | train loss {'Reaction outcome loss': 0.8309053255587208, 'Total loss': 0.8309053255587208}
2022-11-18 00:30:56,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:56,683 INFO:     Epoch: 17
2022-11-18 00:30:57,478 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8070616816932504, 'Total loss': 0.8070616816932504} | train loss {'Reaction outcome loss': 0.8267101370558447, 'Total loss': 0.8267101370558447}
2022-11-18 00:30:57,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:57,479 INFO:     Epoch: 18
2022-11-18 00:30:58,299 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.795401238582351, 'Total loss': 0.795401238582351} | train loss {'Reaction outcome loss': 0.829060621164283, 'Total loss': 0.829060621164283}
2022-11-18 00:30:58,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:58,300 INFO:     Epoch: 19
2022-11-18 00:30:59,089 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7988722222772512, 'Total loss': 0.7988722222772512} | train loss {'Reaction outcome loss': 0.826091310077784, 'Total loss': 0.826091310077784}
2022-11-18 00:30:59,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:59,089 INFO:     Epoch: 20
2022-11-18 00:30:59,926 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8376076153733514, 'Total loss': 0.8376076153733514} | train loss {'Reaction outcome loss': 0.82114126597132, 'Total loss': 0.82114126597132}
2022-11-18 00:30:59,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:30:59,927 INFO:     Epoch: 21
2022-11-18 00:31:00,752 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7992483980276368, 'Total loss': 0.7992483980276368} | train loss {'Reaction outcome loss': 0.8271753876793141, 'Total loss': 0.8271753876793141}
2022-11-18 00:31:00,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:00,753 INFO:     Epoch: 22
2022-11-18 00:31:01,535 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7939304160800847, 'Total loss': 0.7939304160800847} | train loss {'Reaction outcome loss': 0.8274013286950637, 'Total loss': 0.8274013286950637}
2022-11-18 00:31:01,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:01,535 INFO:     Epoch: 23
2022-11-18 00:31:02,345 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8232758749615062, 'Total loss': 0.8232758749615062} | train loss {'Reaction outcome loss': 0.826903892049984, 'Total loss': 0.826903892049984}
2022-11-18 00:31:02,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:02,346 INFO:     Epoch: 24
2022-11-18 00:31:03,174 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7894539142196829, 'Total loss': 0.7894539142196829} | train loss {'Reaction outcome loss': 0.8232734871153928, 'Total loss': 0.8232734871153928}
2022-11-18 00:31:03,175 INFO:     Found new best model at epoch 24
2022-11-18 00:31:03,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:03,175 INFO:     Epoch: 25
2022-11-18 00:31:03,943 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7955034061927687, 'Total loss': 0.7955034061927687} | train loss {'Reaction outcome loss': 0.8234543287024206, 'Total loss': 0.8234543287024206}
2022-11-18 00:31:03,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:03,944 INFO:     Epoch: 26
2022-11-18 00:31:04,763 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7769390659576113, 'Total loss': 0.7769390659576113} | train loss {'Reaction outcome loss': 0.8228087877740665, 'Total loss': 0.8228087877740665}
2022-11-18 00:31:04,763 INFO:     Found new best model at epoch 26
2022-11-18 00:31:04,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:04,764 INFO:     Epoch: 27
2022-11-18 00:31:05,583 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8286358815702525, 'Total loss': 0.8286358815702525} | train loss {'Reaction outcome loss': 0.8224878617695399, 'Total loss': 0.8224878617695399}
2022-11-18 00:31:05,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:05,583 INFO:     Epoch: 28
2022-11-18 00:31:06,401 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8232623704455115, 'Total loss': 0.8232623704455115} | train loss {'Reaction outcome loss': 0.8226383253019683, 'Total loss': 0.8226383253019683}
2022-11-18 00:31:06,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:06,402 INFO:     Epoch: 29
2022-11-18 00:31:07,209 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8197427852587267, 'Total loss': 0.8197427852587267} | train loss {'Reaction outcome loss': 0.8261185549959844, 'Total loss': 0.8261185549959844}
2022-11-18 00:31:07,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:07,209 INFO:     Epoch: 30
2022-11-18 00:31:08,014 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8173817924477838, 'Total loss': 0.8173817924477838} | train loss {'Reaction outcome loss': 0.8257323959652259, 'Total loss': 0.8257323959652259}
2022-11-18 00:31:08,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:08,014 INFO:     Epoch: 31
2022-11-18 00:31:08,812 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7924383946440436, 'Total loss': 0.7924383946440436} | train loss {'Reaction outcome loss': 0.8261322340186761, 'Total loss': 0.8261322340186761}
2022-11-18 00:31:08,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:08,812 INFO:     Epoch: 32
2022-11-18 00:31:09,628 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7911955375563015, 'Total loss': 0.7911955375563015} | train loss {'Reaction outcome loss': 0.8229237466442342, 'Total loss': 0.8229237466442342}
2022-11-18 00:31:09,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:09,628 INFO:     Epoch: 33
2022-11-18 00:31:10,413 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8086230768398806, 'Total loss': 0.8086230768398806} | train loss {'Reaction outcome loss': 0.8238090779100146, 'Total loss': 0.8238090779100146}
2022-11-18 00:31:10,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:10,413 INFO:     Epoch: 34
2022-11-18 00:31:11,229 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7951942485841837, 'Total loss': 0.7951942485841837} | train loss {'Reaction outcome loss': 0.8254392029071341, 'Total loss': 0.8254392029071341}
2022-11-18 00:31:11,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:11,230 INFO:     Epoch: 35
2022-11-18 00:31:12,016 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8212151425805959, 'Total loss': 0.8212151425805959} | train loss {'Reaction outcome loss': 0.8212912771166587, 'Total loss': 0.8212912771166587}
2022-11-18 00:31:12,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:12,017 INFO:     Epoch: 36
2022-11-18 00:31:12,843 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8023949041962624, 'Total loss': 0.8023949041962624} | train loss {'Reaction outcome loss': 0.8273067364887315, 'Total loss': 0.8273067364887315}
2022-11-18 00:31:12,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:12,843 INFO:     Epoch: 37
2022-11-18 00:31:13,644 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7806634146042846, 'Total loss': 0.7806634146042846} | train loss {'Reaction outcome loss': 0.8214502283505031, 'Total loss': 0.8214502283505031}
2022-11-18 00:31:13,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:13,645 INFO:     Epoch: 38
2022-11-18 00:31:14,464 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8250278695063158, 'Total loss': 0.8250278695063158} | train loss {'Reaction outcome loss': 0.8194230415383164, 'Total loss': 0.8194230415383164}
2022-11-18 00:31:14,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:14,464 INFO:     Epoch: 39
2022-11-18 00:31:15,266 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8287107118151404, 'Total loss': 0.8287107118151404} | train loss {'Reaction outcome loss': 0.8182812910907122, 'Total loss': 0.8182812910907122}
2022-11-18 00:31:15,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:15,267 INFO:     Epoch: 40
2022-11-18 00:31:16,043 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.837831899523735, 'Total loss': 0.837831899523735} | train loss {'Reaction outcome loss': 0.8275036060080236, 'Total loss': 0.8275036060080236}
2022-11-18 00:31:16,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:16,044 INFO:     Epoch: 41
2022-11-18 00:31:16,840 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7860269576988437, 'Total loss': 0.7860269576988437} | train loss {'Reaction outcome loss': 0.8211584613031271, 'Total loss': 0.8211584613031271}
2022-11-18 00:31:16,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:16,840 INFO:     Epoch: 42
2022-11-18 00:31:17,646 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8176802281628955, 'Total loss': 0.8176802281628955} | train loss {'Reaction outcome loss': 0.8233167870920531, 'Total loss': 0.8233167870920531}
2022-11-18 00:31:17,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:17,646 INFO:     Epoch: 43
2022-11-18 00:31:18,441 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8211951167746023, 'Total loss': 0.8211951167746023} | train loss {'Reaction outcome loss': 0.8231591758679371, 'Total loss': 0.8231591758679371}
2022-11-18 00:31:18,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:18,441 INFO:     Epoch: 44
2022-11-18 00:31:19,244 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7974166497588158, 'Total loss': 0.7974166497588158} | train loss {'Reaction outcome loss': 0.8219299132726631, 'Total loss': 0.8219299132726631}
2022-11-18 00:31:19,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:19,245 INFO:     Epoch: 45
2022-11-18 00:31:20,059 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7991256232966076, 'Total loss': 0.7991256232966076} | train loss {'Reaction outcome loss': 0.8235605596279612, 'Total loss': 0.8235605596279612}
2022-11-18 00:31:20,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:20,059 INFO:     Epoch: 46
2022-11-18 00:31:20,870 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.821542305702513, 'Total loss': 0.821542305702513} | train loss {'Reaction outcome loss': 0.8223251558080011, 'Total loss': 0.8223251558080011}
2022-11-18 00:31:20,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:20,870 INFO:     Epoch: 47
2022-11-18 00:31:21,720 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7745588719844818, 'Total loss': 0.7745588719844818} | train loss {'Reaction outcome loss': 0.8209870418723748, 'Total loss': 0.8209870418723748}
2022-11-18 00:31:21,720 INFO:     Found new best model at epoch 47
2022-11-18 00:31:21,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:21,721 INFO:     Epoch: 48
2022-11-18 00:31:22,575 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7818019031123682, 'Total loss': 0.7818019031123682} | train loss {'Reaction outcome loss': 0.8206878575743461, 'Total loss': 0.8206878575743461}
2022-11-18 00:31:22,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:22,575 INFO:     Epoch: 49
2022-11-18 00:31:23,393 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8380769951777025, 'Total loss': 0.8380769951777025} | train loss {'Reaction outcome loss': 0.8235948998100904, 'Total loss': 0.8235948998100904}
2022-11-18 00:31:23,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:23,393 INFO:     Epoch: 50
2022-11-18 00:31:24,178 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8184377686543898, 'Total loss': 0.8184377686543898} | train loss {'Reaction outcome loss': 0.8215297254980827, 'Total loss': 0.8215297254980827}
2022-11-18 00:31:24,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:24,178 INFO:     Epoch: 51
2022-11-18 00:31:25,019 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8054425323551352, 'Total loss': 0.8054425323551352} | train loss {'Reaction outcome loss': 0.8220466174641434, 'Total loss': 0.8220466174641434}
2022-11-18 00:31:25,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:25,020 INFO:     Epoch: 52
2022-11-18 00:31:25,827 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8974465565247969, 'Total loss': 0.8974465565247969} | train loss {'Reaction outcome loss': 0.8176655012734082, 'Total loss': 0.8176655012734082}
2022-11-18 00:31:25,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:25,828 INFO:     Epoch: 53
2022-11-18 00:31:26,644 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7865945480086587, 'Total loss': 0.7865945480086587} | train loss {'Reaction outcome loss': 0.8265239524598025, 'Total loss': 0.8265239524598025}
2022-11-18 00:31:26,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:26,645 INFO:     Epoch: 54
2022-11-18 00:31:27,462 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7960071204738184, 'Total loss': 0.7960071204738184} | train loss {'Reaction outcome loss': 0.8223300015439793, 'Total loss': 0.8223300015439793}
2022-11-18 00:31:27,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:27,463 INFO:     Epoch: 55
2022-11-18 00:31:28,237 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8287578286095099, 'Total loss': 0.8287578286095099} | train loss {'Reaction outcome loss': 0.8146300348700309, 'Total loss': 0.8146300348700309}
2022-11-18 00:31:28,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:28,238 INFO:     Epoch: 56
2022-11-18 00:31:29,042 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.831255279481411, 'Total loss': 0.831255279481411} | train loss {'Reaction outcome loss': 0.8256240490747958, 'Total loss': 0.8256240490747958}
2022-11-18 00:31:29,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:29,042 INFO:     Epoch: 57
2022-11-18 00:31:29,889 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7830615985122594, 'Total loss': 0.7830615985122594} | train loss {'Reaction outcome loss': 0.8242625192720063, 'Total loss': 0.8242625192720063}
2022-11-18 00:31:29,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:29,889 INFO:     Epoch: 58
2022-11-18 00:31:30,748 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7839762859723785, 'Total loss': 0.7839762859723785} | train loss {'Reaction outcome loss': 0.8180193223515335, 'Total loss': 0.8180193223515335}
2022-11-18 00:31:30,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:30,749 INFO:     Epoch: 59
2022-11-18 00:31:31,512 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8404828377745368, 'Total loss': 0.8404828377745368} | train loss {'Reaction outcome loss': 0.8201372471390939, 'Total loss': 0.8201372471390939}
2022-11-18 00:31:31,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:31,513 INFO:     Epoch: 60
2022-11-18 00:31:32,312 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8110793585127051, 'Total loss': 0.8110793585127051} | train loss {'Reaction outcome loss': 0.8211246636449074, 'Total loss': 0.8211246636449074}
2022-11-18 00:31:32,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:32,312 INFO:     Epoch: 61
2022-11-18 00:31:33,113 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7914658866145394, 'Total loss': 0.7914658866145394} | train loss {'Reaction outcome loss': 0.820844575093717, 'Total loss': 0.820844575093717}
2022-11-18 00:31:33,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:33,113 INFO:     Epoch: 62
2022-11-18 00:31:33,937 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7862954166802493, 'Total loss': 0.7862954166802493} | train loss {'Reaction outcome loss': 0.8229903075159812, 'Total loss': 0.8229903075159812}
2022-11-18 00:31:33,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:33,938 INFO:     Epoch: 63
2022-11-18 00:31:34,751 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8112855926156044, 'Total loss': 0.8112855926156044} | train loss {'Reaction outcome loss': 0.8248012238011069, 'Total loss': 0.8248012238011069}
2022-11-18 00:31:34,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:34,751 INFO:     Epoch: 64
2022-11-18 00:31:35,545 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7925920323892073, 'Total loss': 0.7925920323892073} | train loss {'Reaction outcome loss': 0.821619993083331, 'Total loss': 0.821619993083331}
2022-11-18 00:31:35,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:35,545 INFO:     Epoch: 65
2022-11-18 00:31:36,375 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7952604510567405, 'Total loss': 0.7952604510567405} | train loss {'Reaction outcome loss': 0.826249695067503, 'Total loss': 0.826249695067503}
2022-11-18 00:31:36,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:36,375 INFO:     Epoch: 66
2022-11-18 00:31:37,174 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.777321572330865, 'Total loss': 0.777321572330865} | train loss {'Reaction outcome loss': 0.8216725401732387, 'Total loss': 0.8216725401732387}
2022-11-18 00:31:37,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:37,175 INFO:     Epoch: 67
2022-11-18 00:31:37,998 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8252288333394311, 'Total loss': 0.8252288333394311} | train loss {'Reaction outcome loss': 0.8159128678088285, 'Total loss': 0.8159128678088285}
2022-11-18 00:31:37,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:37,999 INFO:     Epoch: 68
2022-11-18 00:31:38,821 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8326701061292128, 'Total loss': 0.8326701061292128} | train loss {'Reaction outcome loss': 0.8200548012645877, 'Total loss': 0.8200548012645877}
2022-11-18 00:31:38,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:38,821 INFO:     Epoch: 69
2022-11-18 00:31:39,600 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7929784201762893, 'Total loss': 0.7929784201762893} | train loss {'Reaction outcome loss': 0.8171355200057127, 'Total loss': 0.8171355200057127}
2022-11-18 00:31:39,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:39,600 INFO:     Epoch: 70
2022-11-18 00:31:40,404 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.798130682923577, 'Total loss': 0.798130682923577} | train loss {'Reaction outcome loss': 0.821470782099938, 'Total loss': 0.821470782099938}
2022-11-18 00:31:40,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:40,405 INFO:     Epoch: 71
2022-11-18 00:31:41,229 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7936254712668332, 'Total loss': 0.7936254712668332} | train loss {'Reaction outcome loss': 0.8228887033705808, 'Total loss': 0.8228887033705808}
2022-11-18 00:31:41,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:41,229 INFO:     Epoch: 72
2022-11-18 00:31:42,033 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8025220456448469, 'Total loss': 0.8025220456448469} | train loss {'Reaction outcome loss': 0.8201965889152215, 'Total loss': 0.8201965889152215}
2022-11-18 00:31:42,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:42,034 INFO:     Epoch: 73
2022-11-18 00:31:42,867 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7955734364011071, 'Total loss': 0.7955734364011071} | train loss {'Reaction outcome loss': 0.8234664608021172, 'Total loss': 0.8234664608021172}
2022-11-18 00:31:42,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:42,868 INFO:     Epoch: 74
2022-11-18 00:31:43,660 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.803557274016467, 'Total loss': 0.803557274016467} | train loss {'Reaction outcome loss': 0.8199540944731966, 'Total loss': 0.8199540944731966}
2022-11-18 00:31:43,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:43,661 INFO:     Epoch: 75
2022-11-18 00:31:44,456 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8214772953228517, 'Total loss': 0.8214772953228517} | train loss {'Reaction outcome loss': 0.8168347739443487, 'Total loss': 0.8168347739443487}
2022-11-18 00:31:44,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:44,456 INFO:     Epoch: 76
2022-11-18 00:31:45,238 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8091131106696345, 'Total loss': 0.8091131106696345} | train loss {'Reaction outcome loss': 0.8188031843730381, 'Total loss': 0.8188031843730381}
2022-11-18 00:31:45,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:45,238 INFO:     Epoch: 77
2022-11-18 00:31:46,035 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7995598783547228, 'Total loss': 0.7995598783547228} | train loss {'Reaction outcome loss': 0.8215221467066784, 'Total loss': 0.8215221467066784}
2022-11-18 00:31:46,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:46,035 INFO:     Epoch: 78
2022-11-18 00:31:46,864 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8143883245912465, 'Total loss': 0.8143883245912465} | train loss {'Reaction outcome loss': 0.8202414446947526, 'Total loss': 0.8202414446947526}
2022-11-18 00:31:46,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:46,864 INFO:     Epoch: 79
2022-11-18 00:31:47,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7993346872654828, 'Total loss': 0.7993346872654828} | train loss {'Reaction outcome loss': 0.8210743760576054, 'Total loss': 0.8210743760576054}
2022-11-18 00:31:47,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:47,695 INFO:     Epoch: 80
2022-11-18 00:31:48,523 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.832033900374716, 'Total loss': 0.832033900374716} | train loss {'Reaction outcome loss': 0.8250763168140334, 'Total loss': 0.8250763168140334}
2022-11-18 00:31:48,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:48,523 INFO:     Epoch: 81
2022-11-18 00:31:49,326 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8164918551390822, 'Total loss': 0.8164918551390822} | train loss {'Reaction outcome loss': 0.8201115014601726, 'Total loss': 0.8201115014601726}
2022-11-18 00:31:49,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:49,326 INFO:     Epoch: 82
2022-11-18 00:31:50,112 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7947765670039437, 'Total loss': 0.7947765670039437} | train loss {'Reaction outcome loss': 0.824431401369523, 'Total loss': 0.824431401369523}
2022-11-18 00:31:50,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:50,113 INFO:     Epoch: 83
2022-11-18 00:31:50,925 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.792991457337683, 'Total loss': 0.792991457337683} | train loss {'Reaction outcome loss': 0.822420311825616, 'Total loss': 0.822420311825616}
2022-11-18 00:31:50,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:50,925 INFO:     Epoch: 84
2022-11-18 00:31:51,736 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8093470246954397, 'Total loss': 0.8093470246954397} | train loss {'Reaction outcome loss': 0.8215273565175581, 'Total loss': 0.8215273565175581}
2022-11-18 00:31:51,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:51,736 INFO:     Epoch: 85
2022-11-18 00:31:52,517 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7955546521327712, 'Total loss': 0.7955546521327712} | train loss {'Reaction outcome loss': 0.822631847980071, 'Total loss': 0.822631847980071}
2022-11-18 00:31:52,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:52,517 INFO:     Epoch: 86
2022-11-18 00:31:53,320 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7828832797028802, 'Total loss': 0.7828832797028802} | train loss {'Reaction outcome loss': 0.8177373895839769, 'Total loss': 0.8177373895839769}
2022-11-18 00:31:53,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:53,320 INFO:     Epoch: 87
2022-11-18 00:31:54,083 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8032264377583157, 'Total loss': 0.8032264377583157} | train loss {'Reaction outcome loss': 0.8200337951280633, 'Total loss': 0.8200337951280633}
2022-11-18 00:31:54,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:54,084 INFO:     Epoch: 88
2022-11-18 00:31:54,869 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8006153404712677, 'Total loss': 0.8006153404712677} | train loss {'Reaction outcome loss': 0.8161061083783909, 'Total loss': 0.8161061083783909}
2022-11-18 00:31:54,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:54,869 INFO:     Epoch: 89
2022-11-18 00:31:55,691 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7955102906985716, 'Total loss': 0.7955102906985716} | train loss {'Reaction outcome loss': 0.8197277463212305, 'Total loss': 0.8197277463212305}
2022-11-18 00:31:55,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:55,691 INFO:     Epoch: 90
2022-11-18 00:31:56,499 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7941415174440905, 'Total loss': 0.7941415174440905} | train loss {'Reaction outcome loss': 0.8183832414296208, 'Total loss': 0.8183832414296208}
2022-11-18 00:31:56,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:56,501 INFO:     Epoch: 91
2022-11-18 00:31:57,300 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7958708202297037, 'Total loss': 0.7958708202297037} | train loss {'Reaction outcome loss': 0.8242145149075255, 'Total loss': 0.8242145149075255}
2022-11-18 00:31:57,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:57,301 INFO:     Epoch: 92
2022-11-18 00:31:58,122 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8011298484422944, 'Total loss': 0.8011298484422944} | train loss {'Reaction outcome loss': 0.8153528453135978, 'Total loss': 0.8153528453135978}
2022-11-18 00:31:58,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:58,123 INFO:     Epoch: 93
2022-11-18 00:31:58,919 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8037582581693475, 'Total loss': 0.8037582581693475} | train loss {'Reaction outcome loss': 0.8159619751025219, 'Total loss': 0.8159619751025219}
2022-11-18 00:31:58,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:58,919 INFO:     Epoch: 94
2022-11-18 00:31:59,699 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.783840077844533, 'Total loss': 0.783840077844533} | train loss {'Reaction outcome loss': 0.8217966028622219, 'Total loss': 0.8217966028622219}
2022-11-18 00:31:59,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:31:59,699 INFO:     Epoch: 95
2022-11-18 00:32:00,529 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7975398715246808, 'Total loss': 0.7975398715246808} | train loss {'Reaction outcome loss': 0.8168838263774405, 'Total loss': 0.8168838263774405}
2022-11-18 00:32:00,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:00,530 INFO:     Epoch: 96
2022-11-18 00:32:01,307 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8000523461536928, 'Total loss': 0.8000523461536928} | train loss {'Reaction outcome loss': 0.8227031521651209, 'Total loss': 0.8227031521651209}
2022-11-18 00:32:01,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:01,308 INFO:     Epoch: 97
2022-11-18 00:32:02,125 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8251002674753015, 'Total loss': 0.8251002674753015} | train loss {'Reaction outcome loss': 0.8217353429113116, 'Total loss': 0.8217353429113116}
2022-11-18 00:32:02,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:02,125 INFO:     Epoch: 98
2022-11-18 00:32:02,927 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7783944163132798, 'Total loss': 0.7783944163132798} | train loss {'Reaction outcome loss': 0.8246322231633323, 'Total loss': 0.8246322231633323}
2022-11-18 00:32:02,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:02,928 INFO:     Epoch: 99
2022-11-18 00:32:03,762 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8050317229195074, 'Total loss': 0.8050317229195074} | train loss {'Reaction outcome loss': 0.8170582715345889, 'Total loss': 0.8170582715345889}
2022-11-18 00:32:03,762 INFO:     Best model found after epoch 48 of 100.
2022-11-18 00:32:03,763 INFO:   Done with stage: TRAINING
2022-11-18 00:32:03,763 INFO:   Starting stage: EVALUATION
2022-11-18 00:32:03,892 INFO:   Done with stage: EVALUATION
2022-11-18 00:32:03,892 INFO:   Leaving out SEQ value Fold_4
2022-11-18 00:32:03,906 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 00:32:03,906 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:32:04,582 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:32:04,583 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:32:04,655 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:32:04,655 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:32:04,655 INFO:     No hyperparam tuning for this model
2022-11-18 00:32:04,655 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:32:04,655 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:32:04,656 INFO:     None feature selector for col prot
2022-11-18 00:32:04,656 INFO:     None feature selector for col prot
2022-11-18 00:32:04,656 INFO:     None feature selector for col prot
2022-11-18 00:32:04,657 INFO:     None feature selector for col chem
2022-11-18 00:32:04,657 INFO:     None feature selector for col chem
2022-11-18 00:32:04,657 INFO:     None feature selector for col chem
2022-11-18 00:32:04,657 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:32:04,657 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:32:04,659 INFO:     Number of params in model 168571
2022-11-18 00:32:04,662 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:32:04,662 INFO:   Starting stage: TRAINING
2022-11-18 00:32:04,720 INFO:     Val loss before train {'Reaction outcome loss': 0.9797995043071833, 'Total loss': 0.9797995043071833}
2022-11-18 00:32:04,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:04,720 INFO:     Epoch: 0
2022-11-18 00:32:05,524 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8144339214671742, 'Total loss': 0.8144339214671742} | train loss {'Reaction outcome loss': 0.87833147608504, 'Total loss': 0.87833147608504}
2022-11-18 00:32:05,525 INFO:     Found new best model at epoch 0
2022-11-18 00:32:05,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:05,525 INFO:     Epoch: 1
2022-11-18 00:32:06,325 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7923115681518208, 'Total loss': 0.7923115681518208} | train loss {'Reaction outcome loss': 0.8442322884287153, 'Total loss': 0.8442322884287153}
2022-11-18 00:32:06,325 INFO:     Found new best model at epoch 1
2022-11-18 00:32:06,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:06,326 INFO:     Epoch: 2
2022-11-18 00:32:07,124 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7841169061985883, 'Total loss': 0.7841169061985883} | train loss {'Reaction outcome loss': 0.8389488254274641, 'Total loss': 0.8389488254274641}
2022-11-18 00:32:07,124 INFO:     Found new best model at epoch 2
2022-11-18 00:32:07,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:07,125 INFO:     Epoch: 3
2022-11-18 00:32:07,939 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8067281022667885, 'Total loss': 0.8067281022667885} | train loss {'Reaction outcome loss': 0.8283665344423178, 'Total loss': 0.8283665344423178}
2022-11-18 00:32:07,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:07,939 INFO:     Epoch: 4
2022-11-18 00:32:08,764 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8035146844657984, 'Total loss': 0.8035146844657984} | train loss {'Reaction outcome loss': 0.8247050623504483, 'Total loss': 0.8247050623504483}
2022-11-18 00:32:08,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:08,764 INFO:     Epoch: 5
2022-11-18 00:32:09,572 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.774962150237777, 'Total loss': 0.774962150237777} | train loss {'Reaction outcome loss': 0.8289592194313906, 'Total loss': 0.8289592194313906}
2022-11-18 00:32:09,572 INFO:     Found new best model at epoch 5
2022-11-18 00:32:09,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:09,573 INFO:     Epoch: 6
2022-11-18 00:32:10,363 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7808758277784694, 'Total loss': 0.7808758277784694} | train loss {'Reaction outcome loss': 0.8225442540888883, 'Total loss': 0.8225442540888883}
2022-11-18 00:32:10,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:10,363 INFO:     Epoch: 7
2022-11-18 00:32:11,168 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8020140298388221, 'Total loss': 0.8020140298388221} | train loss {'Reaction outcome loss': 0.8185896608294273, 'Total loss': 0.8185896608294273}
2022-11-18 00:32:11,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:11,169 INFO:     Epoch: 8
2022-11-18 00:32:11,986 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.778432044793259, 'Total loss': 0.778432044793259} | train loss {'Reaction outcome loss': 0.8191896377777567, 'Total loss': 0.8191896377777567}
2022-11-18 00:32:11,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:11,986 INFO:     Epoch: 9
2022-11-18 00:32:12,779 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7823881689797748, 'Total loss': 0.7823881689797748} | train loss {'Reaction outcome loss': 0.8137632837100904, 'Total loss': 0.8137632837100904}
2022-11-18 00:32:12,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:12,780 INFO:     Epoch: 10
2022-11-18 00:32:13,635 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.791143926707181, 'Total loss': 0.791143926707181} | train loss {'Reaction outcome loss': 0.8197886072859473, 'Total loss': 0.8197886072859473}
2022-11-18 00:32:13,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:13,635 INFO:     Epoch: 11
2022-11-18 00:32:14,435 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7867244610732252, 'Total loss': 0.7867244610732252} | train loss {'Reaction outcome loss': 0.8136609972739707, 'Total loss': 0.8136609972739707}
2022-11-18 00:32:14,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:14,436 INFO:     Epoch: 12
2022-11-18 00:32:15,230 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7688920667225664, 'Total loss': 0.7688920667225664} | train loss {'Reaction outcome loss': 0.8121753743716649, 'Total loss': 0.8121753743716649}
2022-11-18 00:32:15,231 INFO:     Found new best model at epoch 12
2022-11-18 00:32:15,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:15,232 INFO:     Epoch: 13
2022-11-18 00:32:15,999 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7931595268574628, 'Total loss': 0.7931595268574628} | train loss {'Reaction outcome loss': 0.8116627239451116, 'Total loss': 0.8116627239451116}
2022-11-18 00:32:15,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:15,999 INFO:     Epoch: 14
2022-11-18 00:32:16,807 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.785793511704965, 'Total loss': 0.785793511704965} | train loss {'Reaction outcome loss': 0.8136346265977743, 'Total loss': 0.8136346265977743}
2022-11-18 00:32:16,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:16,807 INFO:     Epoch: 15
2022-11-18 00:32:17,648 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7764048766006123, 'Total loss': 0.7764048766006123} | train loss {'Reaction outcome loss': 0.8171036782313367, 'Total loss': 0.8171036782313367}
2022-11-18 00:32:17,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:17,648 INFO:     Epoch: 16
2022-11-18 00:32:18,451 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7895787527615373, 'Total loss': 0.7895787527615373} | train loss {'Reaction outcome loss': 0.8111275151676062, 'Total loss': 0.8111275151676062}
2022-11-18 00:32:18,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:18,451 INFO:     Epoch: 17
2022-11-18 00:32:19,292 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7806816229766066, 'Total loss': 0.7806816229766066} | train loss {'Reaction outcome loss': 0.8123818313588902, 'Total loss': 0.8123818313588902}
2022-11-18 00:32:19,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:19,292 INFO:     Epoch: 18
2022-11-18 00:32:20,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7902071404863488, 'Total loss': 0.7902071404863488} | train loss {'Reaction outcome loss': 0.8116748435156685, 'Total loss': 0.8116748435156685}
2022-11-18 00:32:20,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:20,066 INFO:     Epoch: 19
2022-11-18 00:32:20,853 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7700207382440567, 'Total loss': 0.7700207382440567} | train loss {'Reaction outcome loss': 0.8151945837906429, 'Total loss': 0.8151945837906429}
2022-11-18 00:32:20,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:20,854 INFO:     Epoch: 20
2022-11-18 00:32:21,688 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7804914719679139, 'Total loss': 0.7804914719679139} | train loss {'Reaction outcome loss': 0.8134846012203061, 'Total loss': 0.8134846012203061}
2022-11-18 00:32:21,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:21,688 INFO:     Epoch: 21
2022-11-18 00:32:22,454 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8089168322357264, 'Total loss': 0.8089168322357264} | train loss {'Reaction outcome loss': 0.8066666112870586, 'Total loss': 0.8066666112870586}
2022-11-18 00:32:22,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:22,455 INFO:     Epoch: 22
2022-11-18 00:32:23,250 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7741861126639626, 'Total loss': 0.7741861126639626} | train loss {'Reaction outcome loss': 0.8093070684647073, 'Total loss': 0.8093070684647073}
2022-11-18 00:32:23,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:23,250 INFO:     Epoch: 23
2022-11-18 00:32:24,028 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7799601094289259, 'Total loss': 0.7799601094289259} | train loss {'Reaction outcome loss': 0.8084949837655437, 'Total loss': 0.8084949837655437}
2022-11-18 00:32:24,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:24,029 INFO:     Epoch: 24
2022-11-18 00:32:24,826 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7952295474030755, 'Total loss': 0.7952295474030755} | train loss {'Reaction outcome loss': 0.8104376408518578, 'Total loss': 0.8104376408518578}
2022-11-18 00:32:24,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:24,826 INFO:     Epoch: 25
2022-11-18 00:32:25,606 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7836973883888938, 'Total loss': 0.7836973883888938} | train loss {'Reaction outcome loss': 0.8081136772219015, 'Total loss': 0.8081136772219015}
2022-11-18 00:32:25,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:25,606 INFO:     Epoch: 26
2022-11-18 00:32:26,390 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8889639303088188, 'Total loss': 0.8889639303088188} | train loss {'Reaction outcome loss': 0.8052895558123686, 'Total loss': 0.8052895558123686}
2022-11-18 00:32:26,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:26,390 INFO:     Epoch: 27
2022-11-18 00:32:27,135 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7883189022541046, 'Total loss': 0.7883189022541046} | train loss {'Reaction outcome loss': 0.8075590502242653, 'Total loss': 0.8075590502242653}
2022-11-18 00:32:27,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:27,135 INFO:     Epoch: 28
2022-11-18 00:32:27,897 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8000346151265231, 'Total loss': 0.8000346151265231} | train loss {'Reaction outcome loss': 0.8083641816158684, 'Total loss': 0.8083641816158684}
2022-11-18 00:32:27,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:27,898 INFO:     Epoch: 29
2022-11-18 00:32:28,681 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7683418223803694, 'Total loss': 0.7683418223803694} | train loss {'Reaction outcome loss': 0.8075880875392836, 'Total loss': 0.8075880875392836}
2022-11-18 00:32:28,681 INFO:     Found new best model at epoch 29
2022-11-18 00:32:28,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:28,682 INFO:     Epoch: 30
2022-11-18 00:32:29,461 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8079019690101797, 'Total loss': 0.8079019690101797} | train loss {'Reaction outcome loss': 0.8058490016022507, 'Total loss': 0.8058490016022507}
2022-11-18 00:32:29,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:29,461 INFO:     Epoch: 31
2022-11-18 00:32:30,224 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7979033460671251, 'Total loss': 0.7979033460671251} | train loss {'Reaction outcome loss': 0.8082890514208346, 'Total loss': 0.8082890514208346}
2022-11-18 00:32:30,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:30,225 INFO:     Epoch: 32
2022-11-18 00:32:31,000 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7747198793698441, 'Total loss': 0.7747198793698441} | train loss {'Reaction outcome loss': 0.810923720379265, 'Total loss': 0.810923720379265}
2022-11-18 00:32:31,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:31,001 INFO:     Epoch: 33
2022-11-18 00:32:31,805 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7702821259471503, 'Total loss': 0.7702821259471503} | train loss {'Reaction outcome loss': 0.80946570525364, 'Total loss': 0.80946570525364}
2022-11-18 00:32:31,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:31,805 INFO:     Epoch: 34
2022-11-18 00:32:32,595 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8021309714425694, 'Total loss': 0.8021309714425694} | train loss {'Reaction outcome loss': 0.8044055185755905, 'Total loss': 0.8044055185755905}
2022-11-18 00:32:32,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:32,596 INFO:     Epoch: 35
2022-11-18 00:32:33,366 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7932026880708608, 'Total loss': 0.7932026880708608} | train loss {'Reaction outcome loss': 0.8058191699641092, 'Total loss': 0.8058191699641092}
2022-11-18 00:32:33,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:33,367 INFO:     Epoch: 36
2022-11-18 00:32:34,158 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7805566140873865, 'Total loss': 0.7805566140873865} | train loss {'Reaction outcome loss': 0.8053545153870875, 'Total loss': 0.8053545153870875}
2022-11-18 00:32:34,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:34,159 INFO:     Epoch: 37
2022-11-18 00:32:34,945 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8014190359549089, 'Total loss': 0.8014190359549089} | train loss {'Reaction outcome loss': 0.8072947671218794, 'Total loss': 0.8072947671218794}
2022-11-18 00:32:34,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:34,945 INFO:     Epoch: 38
2022-11-18 00:32:35,727 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8206939629533074, 'Total loss': 0.8206939629533074} | train loss {'Reaction outcome loss': 0.8047441735559581, 'Total loss': 0.8047441735559581}
2022-11-18 00:32:35,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:35,727 INFO:     Epoch: 39
2022-11-18 00:32:36,485 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.797941813414747, 'Total loss': 0.797941813414747} | train loss {'Reaction outcome loss': 0.8087102674708074, 'Total loss': 0.8087102674708074}
2022-11-18 00:32:36,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:36,485 INFO:     Epoch: 40
2022-11-18 00:32:37,259 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7999296476217833, 'Total loss': 0.7999296476217833} | train loss {'Reaction outcome loss': 0.8096013290541513, 'Total loss': 0.8096013290541513}
2022-11-18 00:32:37,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:37,259 INFO:     Epoch: 41
2022-11-18 00:32:38,053 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7894430797208439, 'Total loss': 0.7894430797208439} | train loss {'Reaction outcome loss': 0.8114752267088209, 'Total loss': 0.8114752267088209}
2022-11-18 00:32:38,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:38,054 INFO:     Epoch: 42
2022-11-18 00:32:38,847 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7962727695703506, 'Total loss': 0.7962727695703506} | train loss {'Reaction outcome loss': 0.8069666672726067, 'Total loss': 0.8069666672726067}
2022-11-18 00:32:38,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:38,848 INFO:     Epoch: 43
2022-11-18 00:32:39,647 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7902677702632818, 'Total loss': 0.7902677702632818} | train loss {'Reaction outcome loss': 0.8068529062125147, 'Total loss': 0.8068529062125147}
2022-11-18 00:32:39,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:39,647 INFO:     Epoch: 44
2022-11-18 00:32:40,427 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8030741174112667, 'Total loss': 0.8030741174112667} | train loss {'Reaction outcome loss': 0.8116258064094855, 'Total loss': 0.8116258064094855}
2022-11-18 00:32:40,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:40,427 INFO:     Epoch: 45
2022-11-18 00:32:41,212 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7746101658452641, 'Total loss': 0.7746101658452641} | train loss {'Reaction outcome loss': 0.8066338118241758, 'Total loss': 0.8066338118241758}
2022-11-18 00:32:41,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:41,213 INFO:     Epoch: 46
2022-11-18 00:32:41,983 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.776131505315954, 'Total loss': 0.776131505315954} | train loss {'Reaction outcome loss': 0.8054014157275764, 'Total loss': 0.8054014157275764}
2022-11-18 00:32:41,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:41,983 INFO:     Epoch: 47
2022-11-18 00:32:42,777 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7956611920486797, 'Total loss': 0.7956611920486797} | train loss {'Reaction outcome loss': 0.8068982844450036, 'Total loss': 0.8068982844450036}
2022-11-18 00:32:42,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:42,778 INFO:     Epoch: 48
2022-11-18 00:32:43,564 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7885646427219565, 'Total loss': 0.7885646427219565} | train loss {'Reaction outcome loss': 0.8058609995306755, 'Total loss': 0.8058609995306755}
2022-11-18 00:32:43,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:43,564 INFO:     Epoch: 49
2022-11-18 00:32:44,345 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7852681001478975, 'Total loss': 0.7852681001478975} | train loss {'Reaction outcome loss': 0.8089233292608845, 'Total loss': 0.8089233292608845}
2022-11-18 00:32:44,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:44,346 INFO:     Epoch: 50
2022-11-18 00:32:45,134 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7821700715205886, 'Total loss': 0.7821700715205886} | train loss {'Reaction outcome loss': 0.8068765151257418, 'Total loss': 0.8068765151257418}
2022-11-18 00:32:45,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:45,135 INFO:     Epoch: 51
2022-11-18 00:32:45,936 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.782080349597064, 'Total loss': 0.782080349597064} | train loss {'Reaction outcome loss': 0.8094243745414578, 'Total loss': 0.8094243745414578}
2022-11-18 00:32:45,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:45,936 INFO:     Epoch: 52
2022-11-18 00:32:46,718 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7783371982249346, 'Total loss': 0.7783371982249346} | train loss {'Reaction outcome loss': 0.8070542798966778, 'Total loss': 0.8070542798966778}
2022-11-18 00:32:46,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:46,719 INFO:     Epoch: 53
2022-11-18 00:32:47,496 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7876614000309597, 'Total loss': 0.7876614000309597} | train loss {'Reaction outcome loss': 0.8060375942259419, 'Total loss': 0.8060375942259419}
2022-11-18 00:32:47,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:47,497 INFO:     Epoch: 54
2022-11-18 00:32:48,308 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7805085866288706, 'Total loss': 0.7805085866288706} | train loss {'Reaction outcome loss': 0.8094634248285878, 'Total loss': 0.8094634248285878}
2022-11-18 00:32:48,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:48,308 INFO:     Epoch: 55
2022-11-18 00:32:49,083 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7792565165595575, 'Total loss': 0.7792565165595575} | train loss {'Reaction outcome loss': 0.8097760078858356, 'Total loss': 0.8097760078858356}
2022-11-18 00:32:49,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:49,083 INFO:     Epoch: 56
2022-11-18 00:32:49,868 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7938133051449602, 'Total loss': 0.7938133051449602} | train loss {'Reaction outcome loss': 0.805572422304932, 'Total loss': 0.805572422304932}
2022-11-18 00:32:49,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:49,869 INFO:     Epoch: 57
2022-11-18 00:32:50,666 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8078960315747694, 'Total loss': 0.8078960315747694} | train loss {'Reaction outcome loss': 0.8037406957879358, 'Total loss': 0.8037406957879358}
2022-11-18 00:32:50,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:50,667 INFO:     Epoch: 58
2022-11-18 00:32:51,477 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7748371315273371, 'Total loss': 0.7748371315273371} | train loss {'Reaction outcome loss': 0.8093560730924412, 'Total loss': 0.8093560730924412}
2022-11-18 00:32:51,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:51,478 INFO:     Epoch: 59
2022-11-18 00:32:52,271 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7738978706977584, 'Total loss': 0.7738978706977584} | train loss {'Reaction outcome loss': 0.8073309398427302, 'Total loss': 0.8073309398427302}
2022-11-18 00:32:52,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:52,271 INFO:     Epoch: 60
2022-11-18 00:32:53,067 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.772712267935276, 'Total loss': 0.772712267935276} | train loss {'Reaction outcome loss': 0.809061436750451, 'Total loss': 0.809061436750451}
2022-11-18 00:32:53,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:53,067 INFO:     Epoch: 61
2022-11-18 00:32:53,853 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8048733486370607, 'Total loss': 0.8048733486370607} | train loss {'Reaction outcome loss': 0.8055668555960364, 'Total loss': 0.8055668555960364}
2022-11-18 00:32:53,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:53,853 INFO:     Epoch: 62
2022-11-18 00:32:54,626 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7886627194556323, 'Total loss': 0.7886627194556323} | train loss {'Reaction outcome loss': 0.8083182154869547, 'Total loss': 0.8083182154869547}
2022-11-18 00:32:54,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:54,626 INFO:     Epoch: 63
2022-11-18 00:32:55,399 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7757943245497617, 'Total loss': 0.7757943245497617} | train loss {'Reaction outcome loss': 0.8111824331234913, 'Total loss': 0.8111824331234913}
2022-11-18 00:32:55,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:55,400 INFO:     Epoch: 64
2022-11-18 00:32:56,165 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8108304874463514, 'Total loss': 0.8108304874463514} | train loss {'Reaction outcome loss': 0.8083641856300587, 'Total loss': 0.8083641856300587}
2022-11-18 00:32:56,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:56,166 INFO:     Epoch: 65
2022-11-18 00:32:56,930 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7800912735137072, 'Total loss': 0.7800912735137072} | train loss {'Reaction outcome loss': 0.8039945848134099, 'Total loss': 0.8039945848134099}
2022-11-18 00:32:56,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:56,930 INFO:     Epoch: 66
2022-11-18 00:32:57,696 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7903554724021391, 'Total loss': 0.7903554724021391} | train loss {'Reaction outcome loss': 0.8095492311278168, 'Total loss': 0.8095492311278168}
2022-11-18 00:32:57,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:57,696 INFO:     Epoch: 67
2022-11-18 00:32:58,464 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7958463809706948, 'Total loss': 0.7958463809706948} | train loss {'Reaction outcome loss': 0.8072366022333807, 'Total loss': 0.8072366022333807}
2022-11-18 00:32:58,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:58,464 INFO:     Epoch: 68
2022-11-18 00:32:59,275 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7934422641992569, 'Total loss': 0.7934422641992569} | train loss {'Reaction outcome loss': 0.8072402147614226, 'Total loss': 0.8072402147614226}
2022-11-18 00:32:59,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:32:59,276 INFO:     Epoch: 69
2022-11-18 00:33:00,066 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7781167321584441, 'Total loss': 0.7781167321584441} | train loss {'Reaction outcome loss': 0.8066528046617703, 'Total loss': 0.8066528046617703}
2022-11-18 00:33:00,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:00,066 INFO:     Epoch: 70
2022-11-18 00:33:00,871 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7910128107125108, 'Total loss': 0.7910128107125108} | train loss {'Reaction outcome loss': 0.8041844051711413, 'Total loss': 0.8041844051711413}
2022-11-18 00:33:00,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:00,871 INFO:     Epoch: 71
2022-11-18 00:33:01,646 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8085448714819822, 'Total loss': 0.8085448714819822} | train loss {'Reaction outcome loss': 0.8008328231013551, 'Total loss': 0.8008328231013551}
2022-11-18 00:33:01,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:01,646 INFO:     Epoch: 72
2022-11-18 00:33:02,462 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7937038601799444, 'Total loss': 0.7937038601799444} | train loss {'Reaction outcome loss': 0.8082857583250318, 'Total loss': 0.8082857583250318}
2022-11-18 00:33:02,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:02,463 INFO:     Epoch: 73
2022-11-18 00:33:03,286 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7850996242328123, 'Total loss': 0.7850996242328123} | train loss {'Reaction outcome loss': 0.8059672412823657, 'Total loss': 0.8059672412823657}
2022-11-18 00:33:03,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:03,286 INFO:     Epoch: 74
2022-11-18 00:33:04,077 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7842426923188296, 'Total loss': 0.7842426923188296} | train loss {'Reaction outcome loss': 0.8052825346284983, 'Total loss': 0.8052825346284983}
2022-11-18 00:33:04,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:04,077 INFO:     Epoch: 75
2022-11-18 00:33:04,871 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8053781112486665, 'Total loss': 0.8053781112486665} | train loss {'Reaction outcome loss': 0.8096770815703334, 'Total loss': 0.8096770815703334}
2022-11-18 00:33:04,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:04,872 INFO:     Epoch: 76
2022-11-18 00:33:05,648 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7729489684782245, 'Total loss': 0.7729489684782245} | train loss {'Reaction outcome loss': 0.8082207210209905, 'Total loss': 0.8082207210209905}
2022-11-18 00:33:05,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:05,650 INFO:     Epoch: 77
2022-11-18 00:33:06,512 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.786716413768855, 'Total loss': 0.786716413768855} | train loss {'Reaction outcome loss': 0.8038084570242434, 'Total loss': 0.8038084570242434}
2022-11-18 00:33:06,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:06,512 INFO:     Epoch: 78
2022-11-18 00:33:07,310 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7776854227889668, 'Total loss': 0.7776854227889668} | train loss {'Reaction outcome loss': 0.8092940952096667, 'Total loss': 0.8092940952096667}
2022-11-18 00:33:07,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:07,310 INFO:     Epoch: 79
2022-11-18 00:33:08,120 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8026235821572217, 'Total loss': 0.8026235821572217} | train loss {'Reaction outcome loss': 0.8067530093144397, 'Total loss': 0.8067530093144397}
2022-11-18 00:33:08,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:08,120 INFO:     Epoch: 80
2022-11-18 00:33:08,912 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7868133586916056, 'Total loss': 0.7868133586916056} | train loss {'Reaction outcome loss': 0.8005252204379257, 'Total loss': 0.8005252204379257}
2022-11-18 00:33:08,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:08,913 INFO:     Epoch: 81
2022-11-18 00:33:09,768 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8135725632309914, 'Total loss': 0.8135725632309914} | train loss {'Reaction outcome loss': 0.8087077620078106, 'Total loss': 0.8087077620078106}
2022-11-18 00:33:09,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:09,769 INFO:     Epoch: 82
2022-11-18 00:33:10,585 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7869513454762372, 'Total loss': 0.7869513454762372} | train loss {'Reaction outcome loss': 0.8026399200059929, 'Total loss': 0.8026399200059929}
2022-11-18 00:33:10,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:10,585 INFO:     Epoch: 83
2022-11-18 00:33:11,353 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7872068421407179, 'Total loss': 0.7872068421407179} | train loss {'Reaction outcome loss': 0.8060718543675481, 'Total loss': 0.8060718543675481}
2022-11-18 00:33:11,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:11,353 INFO:     Epoch: 84
2022-11-18 00:33:12,126 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8104578453031454, 'Total loss': 0.8104578453031454} | train loss {'Reaction outcome loss': 0.8107215872832707, 'Total loss': 0.8107215872832707}
2022-11-18 00:33:12,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:12,126 INFO:     Epoch: 85
2022-11-18 00:33:12,940 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7828402282162146, 'Total loss': 0.7828402282162146} | train loss {'Reaction outcome loss': 0.8058229639822123, 'Total loss': 0.8058229639822123}
2022-11-18 00:33:12,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:12,940 INFO:     Epoch: 86
2022-11-18 00:33:13,724 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7798701142045584, 'Total loss': 0.7798701142045584} | train loss {'Reaction outcome loss': 0.8022899897731081, 'Total loss': 0.8022899897731081}
2022-11-18 00:33:13,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:13,724 INFO:     Epoch: 87
2022-11-18 00:33:14,565 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7894457531246272, 'Total loss': 0.7894457531246272} | train loss {'Reaction outcome loss': 0.8025653931559349, 'Total loss': 0.8025653931559349}
2022-11-18 00:33:14,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:14,565 INFO:     Epoch: 88
2022-11-18 00:33:15,400 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7804161235690117, 'Total loss': 0.7804161235690117} | train loss {'Reaction outcome loss': 0.8031615406883006, 'Total loss': 0.8031615406883006}
2022-11-18 00:33:15,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:15,400 INFO:     Epoch: 89
2022-11-18 00:33:16,228 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7732278962026943, 'Total loss': 0.7732278962026943} | train loss {'Reaction outcome loss': 0.8048911462024767, 'Total loss': 0.8048911462024767}
2022-11-18 00:33:16,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:16,229 INFO:     Epoch: 90
2022-11-18 00:33:17,029 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7956368882547725, 'Total loss': 0.7956368882547725} | train loss {'Reaction outcome loss': 0.8073601633918529, 'Total loss': 0.8073601633918529}
2022-11-18 00:33:17,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:17,030 INFO:     Epoch: 91
2022-11-18 00:33:17,860 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7816512632099065, 'Total loss': 0.7816512632099065} | train loss {'Reaction outcome loss': 0.8057528928834565, 'Total loss': 0.8057528928834565}
2022-11-18 00:33:17,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:17,862 INFO:     Epoch: 92
2022-11-18 00:33:18,606 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.789752334356308, 'Total loss': 0.789752334356308} | train loss {'Reaction outcome loss': 0.8142088626112257, 'Total loss': 0.8142088626112257}
2022-11-18 00:33:18,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:18,607 INFO:     Epoch: 93
2022-11-18 00:33:19,414 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7841407785361464, 'Total loss': 0.7841407785361464} | train loss {'Reaction outcome loss': 0.8074093287088433, 'Total loss': 0.8074093287088433}
2022-11-18 00:33:19,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:19,414 INFO:     Epoch: 94
2022-11-18 00:33:20,186 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.79140101169998, 'Total loss': 0.79140101169998} | train loss {'Reaction outcome loss': 0.8056522751341061, 'Total loss': 0.8056522751341061}
2022-11-18 00:33:20,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:20,187 INFO:     Epoch: 95
2022-11-18 00:33:21,020 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7949937683614817, 'Total loss': 0.7949937683614817} | train loss {'Reaction outcome loss': 0.8030493936976608, 'Total loss': 0.8030493936976608}
2022-11-18 00:33:21,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:21,020 INFO:     Epoch: 96
2022-11-18 00:33:21,853 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7824629294601354, 'Total loss': 0.7824629294601354} | train loss {'Reaction outcome loss': 0.8065091535753134, 'Total loss': 0.8065091535753134}
2022-11-18 00:33:21,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:21,854 INFO:     Epoch: 97
2022-11-18 00:33:22,699 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.769338686357845, 'Total loss': 0.769338686357845} | train loss {'Reaction outcome loss': 0.808374478865643, 'Total loss': 0.808374478865643}
2022-11-18 00:33:22,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:22,699 INFO:     Epoch: 98
2022-11-18 00:33:23,535 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7769947255199606, 'Total loss': 0.7769947255199606} | train loss {'Reaction outcome loss': 0.8049051947739659, 'Total loss': 0.8049051947739659}
2022-11-18 00:33:23,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:23,535 INFO:     Epoch: 99
2022-11-18 00:33:24,381 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8064475587823174, 'Total loss': 0.8064475587823174} | train loss {'Reaction outcome loss': 0.806144155044945, 'Total loss': 0.806144155044945}
2022-11-18 00:33:24,381 INFO:     Best model found after epoch 30 of 100.
2022-11-18 00:33:24,381 INFO:   Done with stage: TRAINING
2022-11-18 00:33:24,381 INFO:   Starting stage: EVALUATION
2022-11-18 00:33:24,509 INFO:   Done with stage: EVALUATION
2022-11-18 00:33:24,509 INFO:   Leaving out SEQ value Fold_5
2022-11-18 00:33:24,522 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:33:24,523 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:33:25,195 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:33:25,195 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:33:25,266 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:33:25,266 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:33:25,266 INFO:     No hyperparam tuning for this model
2022-11-18 00:33:25,267 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:33:25,267 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:33:25,267 INFO:     None feature selector for col prot
2022-11-18 00:33:25,267 INFO:     None feature selector for col prot
2022-11-18 00:33:25,268 INFO:     None feature selector for col prot
2022-11-18 00:33:25,268 INFO:     None feature selector for col chem
2022-11-18 00:33:25,268 INFO:     None feature selector for col chem
2022-11-18 00:33:25,268 INFO:     None feature selector for col chem
2022-11-18 00:33:25,268 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:33:25,268 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:33:25,270 INFO:     Number of params in model 168571
2022-11-18 00:33:25,273 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:33:25,273 INFO:   Starting stage: TRAINING
2022-11-18 00:33:25,330 INFO:     Val loss before train {'Reaction outcome loss': 1.0402661196210168, 'Total loss': 1.0402661196210168}
2022-11-18 00:33:25,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:25,331 INFO:     Epoch: 0
2022-11-18 00:33:26,151 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8476266739043322, 'Total loss': 0.8476266739043322} | train loss {'Reaction outcome loss': 0.8773279764994919, 'Total loss': 0.8773279764994919}
2022-11-18 00:33:26,151 INFO:     Found new best model at epoch 0
2022-11-18 00:33:26,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:26,152 INFO:     Epoch: 1
2022-11-18 00:33:26,958 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8588675240224058, 'Total loss': 0.8588675240224058} | train loss {'Reaction outcome loss': 0.8501176813594725, 'Total loss': 0.8501176813594725}
2022-11-18 00:33:26,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:26,958 INFO:     Epoch: 2
2022-11-18 00:33:27,759 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8665812970562414, 'Total loss': 0.8665812970562414} | train loss {'Reaction outcome loss': 0.8488698231305188, 'Total loss': 0.8488698231305188}
2022-11-18 00:33:27,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:27,760 INFO:     Epoch: 3
2022-11-18 00:33:28,564 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8371958143331788, 'Total loss': 0.8371958143331788} | train loss {'Reaction outcome loss': 0.8412232702439614, 'Total loss': 0.8412232702439614}
2022-11-18 00:33:28,564 INFO:     Found new best model at epoch 3
2022-11-18 00:33:28,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:28,565 INFO:     Epoch: 4
2022-11-18 00:33:29,433 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8662162226709452, 'Total loss': 0.8662162226709452} | train loss {'Reaction outcome loss': 0.8353175377314873, 'Total loss': 0.8353175377314873}
2022-11-18 00:33:29,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:29,434 INFO:     Epoch: 5
2022-11-18 00:33:30,242 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.834071887487715, 'Total loss': 0.834071887487715} | train loss {'Reaction outcome loss': 0.8320606274884722, 'Total loss': 0.8320606274884722}
2022-11-18 00:33:30,243 INFO:     Found new best model at epoch 5
2022-11-18 00:33:30,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:30,245 INFO:     Epoch: 6
2022-11-18 00:33:31,103 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8414102454077114, 'Total loss': 0.8414102454077114} | train loss {'Reaction outcome loss': 0.8328109085559845, 'Total loss': 0.8328109085559845}
2022-11-18 00:33:31,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:31,104 INFO:     Epoch: 7
2022-11-18 00:33:31,930 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8384431153535843, 'Total loss': 0.8384431153535843} | train loss {'Reaction outcome loss': 0.8321359520740355, 'Total loss': 0.8321359520740355}
2022-11-18 00:33:31,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:31,931 INFO:     Epoch: 8
2022-11-18 00:33:32,745 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.828170797702941, 'Total loss': 0.828170797702941} | train loss {'Reaction outcome loss': 0.8299496688461496, 'Total loss': 0.8299496688461496}
2022-11-18 00:33:32,745 INFO:     Found new best model at epoch 8
2022-11-18 00:33:32,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:32,746 INFO:     Epoch: 9
2022-11-18 00:33:33,526 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8993957984176549, 'Total loss': 0.8993957984176549} | train loss {'Reaction outcome loss': 0.8278913778452738, 'Total loss': 0.8278913778452738}
2022-11-18 00:33:33,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:33,526 INFO:     Epoch: 10
2022-11-18 00:33:34,362 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8403341255404733, 'Total loss': 0.8403341255404733} | train loss {'Reaction outcome loss': 0.8310880909866167, 'Total loss': 0.8310880909866167}
2022-11-18 00:33:34,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:34,362 INFO:     Epoch: 11
2022-11-18 00:33:35,167 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8241839666258205, 'Total loss': 0.8241839666258205} | train loss {'Reaction outcome loss': 0.828588067761317, 'Total loss': 0.828588067761317}
2022-11-18 00:33:35,167 INFO:     Found new best model at epoch 11
2022-11-18 00:33:35,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:35,168 INFO:     Epoch: 12
2022-11-18 00:33:36,018 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8394603106108579, 'Total loss': 0.8394603106108579} | train loss {'Reaction outcome loss': 0.8290838320637762, 'Total loss': 0.8290838320637762}
2022-11-18 00:33:36,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:36,018 INFO:     Epoch: 13
2022-11-18 00:33:36,798 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8419308486309919, 'Total loss': 0.8419308486309919} | train loss {'Reaction outcome loss': 0.8216833382965583, 'Total loss': 0.8216833382965583}
2022-11-18 00:33:36,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:36,799 INFO:     Epoch: 14
2022-11-18 00:33:37,589 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8380588360808112, 'Total loss': 0.8380588360808112} | train loss {'Reaction outcome loss': 0.8311076541902566, 'Total loss': 0.8311076541902566}
2022-11-18 00:33:37,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:37,589 INFO:     Epoch: 15
2022-11-18 00:33:38,428 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8324532102454792, 'Total loss': 0.8324532102454792} | train loss {'Reaction outcome loss': 0.8205641293332644, 'Total loss': 0.8205641293332644}
2022-11-18 00:33:38,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:38,428 INFO:     Epoch: 16
2022-11-18 00:33:39,232 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8368760191581466, 'Total loss': 0.8368760191581466} | train loss {'Reaction outcome loss': 0.8305201300001337, 'Total loss': 0.8305201300001337}
2022-11-18 00:33:39,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:39,232 INFO:     Epoch: 17
2022-11-18 00:33:40,012 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8307427899404005, 'Total loss': 0.8307427899404005} | train loss {'Reaction outcome loss': 0.8251228802177587, 'Total loss': 0.8251228802177587}
2022-11-18 00:33:40,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:40,012 INFO:     Epoch: 18
2022-11-18 00:33:40,787 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8412572308020159, 'Total loss': 0.8412572308020159} | train loss {'Reaction outcome loss': 0.821046205667349, 'Total loss': 0.821046205667349}
2022-11-18 00:33:40,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:40,787 INFO:     Epoch: 19
2022-11-18 00:33:41,578 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8474278815767982, 'Total loss': 0.8474278815767982} | train loss {'Reaction outcome loss': 0.8277667011567938, 'Total loss': 0.8277667011567938}
2022-11-18 00:33:41,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:41,578 INFO:     Epoch: 20
2022-11-18 00:33:42,367 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8306246440518986, 'Total loss': 0.8306246440518986} | train loss {'Reaction outcome loss': 0.8249069978351052, 'Total loss': 0.8249069978351052}
2022-11-18 00:33:42,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:42,367 INFO:     Epoch: 21
2022-11-18 00:33:43,178 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8235674168575894, 'Total loss': 0.8235674168575894} | train loss {'Reaction outcome loss': 0.8231594045212877, 'Total loss': 0.8231594045212877}
2022-11-18 00:33:43,178 INFO:     Found new best model at epoch 21
2022-11-18 00:33:43,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:43,179 INFO:     Epoch: 22
2022-11-18 00:33:43,946 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8483827398581938, 'Total loss': 0.8483827398581938} | train loss {'Reaction outcome loss': 0.8213425986921257, 'Total loss': 0.8213425986921257}
2022-11-18 00:33:43,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:43,947 INFO:     Epoch: 23
2022-11-18 00:33:44,718 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8517728691751306, 'Total loss': 0.8517728691751306} | train loss {'Reaction outcome loss': 0.8267747718795591, 'Total loss': 0.8267747718795591}
2022-11-18 00:33:44,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:44,718 INFO:     Epoch: 24
2022-11-18 00:33:45,514 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8206035941839218, 'Total loss': 0.8206035941839218} | train loss {'Reaction outcome loss': 0.8230544314210714, 'Total loss': 0.8230544314210714}
2022-11-18 00:33:45,514 INFO:     Found new best model at epoch 24
2022-11-18 00:33:45,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:45,515 INFO:     Epoch: 25
2022-11-18 00:33:46,311 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8263903490521691, 'Total loss': 0.8263903490521691} | train loss {'Reaction outcome loss': 0.8207120038418152, 'Total loss': 0.8207120038418152}
2022-11-18 00:33:46,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:46,311 INFO:     Epoch: 26
2022-11-18 00:33:47,111 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8355308595028791, 'Total loss': 0.8355308595028791} | train loss {'Reaction outcome loss': 0.8242776370965518, 'Total loss': 0.8242776370965518}
2022-11-18 00:33:47,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:47,111 INFO:     Epoch: 27
2022-11-18 00:33:47,889 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.839923810552467, 'Total loss': 0.839923810552467} | train loss {'Reaction outcome loss': 0.8223752025891895, 'Total loss': 0.8223752025891895}
2022-11-18 00:33:47,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:47,889 INFO:     Epoch: 28
2022-11-18 00:33:48,703 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8284128735011275, 'Total loss': 0.8284128735011275} | train loss {'Reaction outcome loss': 0.8247396605700134, 'Total loss': 0.8247396605700134}
2022-11-18 00:33:48,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:48,703 INFO:     Epoch: 29
2022-11-18 00:33:49,458 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8370771990580992, 'Total loss': 0.8370771990580992} | train loss {'Reaction outcome loss': 0.8191292088041421, 'Total loss': 0.8191292088041421}
2022-11-18 00:33:49,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:49,459 INFO:     Epoch: 30
2022-11-18 00:33:50,257 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8309475874358957, 'Total loss': 0.8309475874358957} | train loss {'Reaction outcome loss': 0.8251925961450044, 'Total loss': 0.8251925961450044}
2022-11-18 00:33:50,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:50,257 INFO:     Epoch: 31
2022-11-18 00:33:51,038 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8267398442734372, 'Total loss': 0.8267398442734372} | train loss {'Reaction outcome loss': 0.8254307313004003, 'Total loss': 0.8254307313004003}
2022-11-18 00:33:51,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:51,039 INFO:     Epoch: 32
2022-11-18 00:33:51,814 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.837899002161893, 'Total loss': 0.837899002161893} | train loss {'Reaction outcome loss': 0.8252518523318565, 'Total loss': 0.8252518523318565}
2022-11-18 00:33:51,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:51,815 INFO:     Epoch: 33
2022-11-18 00:33:52,603 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8352406234903769, 'Total loss': 0.8352406234903769} | train loss {'Reaction outcome loss': 0.8238035787937612, 'Total loss': 0.8238035787937612}
2022-11-18 00:33:52,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:52,603 INFO:     Epoch: 34
2022-11-18 00:33:53,396 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8185127912597223, 'Total loss': 0.8185127912597223} | train loss {'Reaction outcome loss': 0.8216215017353475, 'Total loss': 0.8216215017353475}
2022-11-18 00:33:53,396 INFO:     Found new best model at epoch 34
2022-11-18 00:33:53,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:53,397 INFO:     Epoch: 35
2022-11-18 00:33:54,165 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8311777941205285, 'Total loss': 0.8311777941205285} | train loss {'Reaction outcome loss': 0.8214302112457723, 'Total loss': 0.8214302112457723}
2022-11-18 00:33:54,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:54,165 INFO:     Epoch: 36
2022-11-18 00:33:54,941 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8143201172351837, 'Total loss': 0.8143201172351837} | train loss {'Reaction outcome loss': 0.8252794284086961, 'Total loss': 0.8252794284086961}
2022-11-18 00:33:54,941 INFO:     Found new best model at epoch 36
2022-11-18 00:33:54,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:54,942 INFO:     Epoch: 37
2022-11-18 00:33:55,729 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8132884549823675, 'Total loss': 0.8132884549823675} | train loss {'Reaction outcome loss': 0.8204010260642057, 'Total loss': 0.8204010260642057}
2022-11-18 00:33:55,730 INFO:     Found new best model at epoch 37
2022-11-18 00:33:55,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:55,730 INFO:     Epoch: 38
2022-11-18 00:33:56,512 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8174916275522925, 'Total loss': 0.8174916275522925} | train loss {'Reaction outcome loss': 0.8190777708403012, 'Total loss': 0.8190777708403012}
2022-11-18 00:33:56,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:56,513 INFO:     Epoch: 39
2022-11-18 00:33:57,327 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8379979655146599, 'Total loss': 0.8379979655146599} | train loss {'Reaction outcome loss': 0.8183918872523887, 'Total loss': 0.8183918872523887}
2022-11-18 00:33:57,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:57,327 INFO:     Epoch: 40
2022-11-18 00:33:58,117 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.826781189577146, 'Total loss': 0.826781189577146} | train loss {'Reaction outcome loss': 0.824369371299319, 'Total loss': 0.824369371299319}
2022-11-18 00:33:58,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:58,117 INFO:     Epoch: 41
2022-11-18 00:33:58,905 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8479338775981556, 'Total loss': 0.8479338775981556} | train loss {'Reaction outcome loss': 0.817307826719786, 'Total loss': 0.817307826719786}
2022-11-18 00:33:58,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:58,906 INFO:     Epoch: 42
2022-11-18 00:33:59,699 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8419839787212285, 'Total loss': 0.8419839787212285} | train loss {'Reaction outcome loss': 0.8213711195146507, 'Total loss': 0.8213711195146507}
2022-11-18 00:33:59,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:33:59,699 INFO:     Epoch: 43
2022-11-18 00:34:00,512 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8194970637559891, 'Total loss': 0.8194970637559891} | train loss {'Reaction outcome loss': 0.823642531749208, 'Total loss': 0.823642531749208}
2022-11-18 00:34:00,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:00,512 INFO:     Epoch: 44
2022-11-18 00:34:01,329 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8334013047543439, 'Total loss': 0.8334013047543439} | train loss {'Reaction outcome loss': 0.8176120561868073, 'Total loss': 0.8176120561868073}
2022-11-18 00:34:01,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:01,329 INFO:     Epoch: 45
2022-11-18 00:34:02,131 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8344385210763324, 'Total loss': 0.8344385210763324} | train loss {'Reaction outcome loss': 0.8153327222053821, 'Total loss': 0.8153327222053821}
2022-11-18 00:34:02,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:02,132 INFO:     Epoch: 46
2022-11-18 00:34:02,926 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8318397165699438, 'Total loss': 0.8318397165699438} | train loss {'Reaction outcome loss': 0.818299436949284, 'Total loss': 0.818299436949284}
2022-11-18 00:34:02,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:02,926 INFO:     Epoch: 47
2022-11-18 00:34:03,754 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8300201418724927, 'Total loss': 0.8300201418724927} | train loss {'Reaction outcome loss': 0.828715729327337, 'Total loss': 0.828715729327337}
2022-11-18 00:34:03,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:03,754 INFO:     Epoch: 48
2022-11-18 00:34:04,552 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.826511865312403, 'Total loss': 0.826511865312403} | train loss {'Reaction outcome loss': 0.8233331855733385, 'Total loss': 0.8233331855733385}
2022-11-18 00:34:04,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:04,553 INFO:     Epoch: 49
2022-11-18 00:34:05,345 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8220213550058278, 'Total loss': 0.8220213550058278} | train loss {'Reaction outcome loss': 0.8232073256602654, 'Total loss': 0.8232073256602654}
2022-11-18 00:34:05,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:05,345 INFO:     Epoch: 50
2022-11-18 00:34:06,116 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8180869004943154, 'Total loss': 0.8180869004943154} | train loss {'Reaction outcome loss': 0.8191919444272151, 'Total loss': 0.8191919444272151}
2022-11-18 00:34:06,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:06,116 INFO:     Epoch: 51
2022-11-18 00:34:06,867 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8299894082275304, 'Total loss': 0.8299894082275304} | train loss {'Reaction outcome loss': 0.8182213943798532, 'Total loss': 0.8182213943798532}
2022-11-18 00:34:06,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:06,868 INFO:     Epoch: 52
2022-11-18 00:34:07,639 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8275468254631216, 'Total loss': 0.8275468254631216} | train loss {'Reaction outcome loss': 0.818041189811249, 'Total loss': 0.818041189811249}
2022-11-18 00:34:07,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:07,639 INFO:     Epoch: 53
2022-11-18 00:34:08,433 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8359961496158079, 'Total loss': 0.8359961496158079} | train loss {'Reaction outcome loss': 0.8154107427548783, 'Total loss': 0.8154107427548783}
2022-11-18 00:34:08,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:08,434 INFO:     Epoch: 54
2022-11-18 00:34:09,243 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8241239847107367, 'Total loss': 0.8241239847107367} | train loss {'Reaction outcome loss': 0.8248754406747548, 'Total loss': 0.8248754406747548}
2022-11-18 00:34:09,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:09,243 INFO:     Epoch: 55
2022-11-18 00:34:10,079 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8220186233520508, 'Total loss': 0.8220186233520508} | train loss {'Reaction outcome loss': 0.8227611907158303, 'Total loss': 0.8227611907158303}
2022-11-18 00:34:10,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:10,079 INFO:     Epoch: 56
2022-11-18 00:34:10,895 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8175062510100278, 'Total loss': 0.8175062510100278} | train loss {'Reaction outcome loss': 0.820105059969763, 'Total loss': 0.820105059969763}
2022-11-18 00:34:10,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:10,895 INFO:     Epoch: 57
2022-11-18 00:34:11,724 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8229946263811805, 'Total loss': 0.8229946263811805} | train loss {'Reaction outcome loss': 0.8125219921834073, 'Total loss': 0.8125219921834073}
2022-11-18 00:34:11,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:11,724 INFO:     Epoch: 58
2022-11-18 00:34:12,547 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8238710131157528, 'Total loss': 0.8238710131157528} | train loss {'Reaction outcome loss': 0.8162565431614154, 'Total loss': 0.8162565431614154}
2022-11-18 00:34:12,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:12,547 INFO:     Epoch: 59
2022-11-18 00:34:13,320 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8183410099961541, 'Total loss': 0.8183410099961541} | train loss {'Reaction outcome loss': 0.8143369519502407, 'Total loss': 0.8143369519502407}
2022-11-18 00:34:13,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:13,320 INFO:     Epoch: 60
2022-11-18 00:34:14,130 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8352121941067956, 'Total loss': 0.8352121941067956} | train loss {'Reaction outcome loss': 0.8109201359966023, 'Total loss': 0.8109201359966023}
2022-11-18 00:34:14,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:14,130 INFO:     Epoch: 61
2022-11-18 00:34:14,960 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8317183486439965, 'Total loss': 0.8317183486439965} | train loss {'Reaction outcome loss': 0.8154189940089518, 'Total loss': 0.8154189940089518}
2022-11-18 00:34:14,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:14,960 INFO:     Epoch: 62
2022-11-18 00:34:15,783 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8214774165641178, 'Total loss': 0.8214774165641178} | train loss {'Reaction outcome loss': 0.8226456877432371, 'Total loss': 0.8226456877432371}
2022-11-18 00:34:15,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:15,783 INFO:     Epoch: 63
2022-11-18 00:34:16,625 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8552244285290892, 'Total loss': 0.8552244285290892} | train loss {'Reaction outcome loss': 0.8141246757767944, 'Total loss': 0.8141246757767944}
2022-11-18 00:34:16,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:16,625 INFO:     Epoch: 64
2022-11-18 00:34:17,434 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8259030038660223, 'Total loss': 0.8259030038660223} | train loss {'Reaction outcome loss': 0.8209980015571301, 'Total loss': 0.8209980015571301}
2022-11-18 00:34:17,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:17,435 INFO:     Epoch: 65
2022-11-18 00:34:18,233 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8192962767048315, 'Total loss': 0.8192962767048315} | train loss {'Reaction outcome loss': 0.8149327948267161, 'Total loss': 0.8149327948267161}
2022-11-18 00:34:18,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:18,233 INFO:     Epoch: 66
2022-11-18 00:34:19,026 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8351659293879162, 'Total loss': 0.8351659293879162} | train loss {'Reaction outcome loss': 0.8179977288854267, 'Total loss': 0.8179977288854267}
2022-11-18 00:34:19,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:19,026 INFO:     Epoch: 67
2022-11-18 00:34:19,806 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8217623884027655, 'Total loss': 0.8217623884027655} | train loss {'Reaction outcome loss': 0.8190645084448671, 'Total loss': 0.8190645084448671}
2022-11-18 00:34:19,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:19,806 INFO:     Epoch: 68
2022-11-18 00:34:20,615 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.839137615127997, 'Total loss': 0.839137615127997} | train loss {'Reaction outcome loss': 0.820210021637712, 'Total loss': 0.820210021637712}
2022-11-18 00:34:20,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:20,616 INFO:     Epoch: 69
2022-11-18 00:34:21,426 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8273051950064573, 'Total loss': 0.8273051950064573} | train loss {'Reaction outcome loss': 0.8221470693103697, 'Total loss': 0.8221470693103697}
2022-11-18 00:34:21,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:21,427 INFO:     Epoch: 70
2022-11-18 00:34:22,219 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8263479789549654, 'Total loss': 0.8263479789549654} | train loss {'Reaction outcome loss': 0.8240453006043608, 'Total loss': 0.8240453006043608}
2022-11-18 00:34:22,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:22,220 INFO:     Epoch: 71
2022-11-18 00:34:23,058 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8256819939071481, 'Total loss': 0.8256819939071481} | train loss {'Reaction outcome loss': 0.8209359853373848, 'Total loss': 0.8209359853373848}
2022-11-18 00:34:23,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:23,058 INFO:     Epoch: 72
2022-11-18 00:34:23,855 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8296993496743116, 'Total loss': 0.8296993496743116} | train loss {'Reaction outcome loss': 0.8139353410495438, 'Total loss': 0.8139353410495438}
2022-11-18 00:34:23,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:23,855 INFO:     Epoch: 73
2022-11-18 00:34:24,647 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8343340876427564, 'Total loss': 0.8343340876427564} | train loss {'Reaction outcome loss': 0.8175061406032277, 'Total loss': 0.8175061406032277}
2022-11-18 00:34:24,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:24,647 INFO:     Epoch: 74
2022-11-18 00:34:25,416 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8378856019540266, 'Total loss': 0.8378856019540266} | train loss {'Reaction outcome loss': 0.8206140269876009, 'Total loss': 0.8206140269876009}
2022-11-18 00:34:25,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:25,416 INFO:     Epoch: 75
2022-11-18 00:34:26,182 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8364335291764953, 'Total loss': 0.8364335291764953} | train loss {'Reaction outcome loss': 0.8182285198798547, 'Total loss': 0.8182285198798547}
2022-11-18 00:34:26,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:26,182 INFO:     Epoch: 76
2022-11-18 00:34:26,976 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8350580145012249, 'Total loss': 0.8350580145012249} | train loss {'Reaction outcome loss': 0.8164865847541253, 'Total loss': 0.8164865847541253}
2022-11-18 00:34:26,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:26,976 INFO:     Epoch: 77
2022-11-18 00:34:27,788 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.808467676693743, 'Total loss': 0.808467676693743} | train loss {'Reaction outcome loss': 0.8205116655421161, 'Total loss': 0.8205116655421161}
2022-11-18 00:34:27,788 INFO:     Found new best model at epoch 77
2022-11-18 00:34:27,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:27,789 INFO:     Epoch: 78
2022-11-18 00:34:28,594 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8169089176438071, 'Total loss': 0.8169089176438071} | train loss {'Reaction outcome loss': 0.8211720672696226, 'Total loss': 0.8211720672696226}
2022-11-18 00:34:28,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:28,595 INFO:     Epoch: 79
2022-11-18 00:34:29,376 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8342864594676278, 'Total loss': 0.8342864594676278} | train loss {'Reaction outcome loss': 0.8134152534519613, 'Total loss': 0.8134152534519613}
2022-11-18 00:34:29,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:29,377 INFO:     Epoch: 80
2022-11-18 00:34:30,175 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8164928277785127, 'Total loss': 0.8164928277785127} | train loss {'Reaction outcome loss': 0.8167895864137271, 'Total loss': 0.8167895864137271}
2022-11-18 00:34:30,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:30,175 INFO:     Epoch: 81
2022-11-18 00:34:30,950 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8258370879021558, 'Total loss': 0.8258370879021558} | train loss {'Reaction outcome loss': 0.8197049291027703, 'Total loss': 0.8197049291027703}
2022-11-18 00:34:30,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:30,950 INFO:     Epoch: 82
2022-11-18 00:34:31,774 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8444596948948774, 'Total loss': 0.8444596948948774} | train loss {'Reaction outcome loss': 0.8222314224310732, 'Total loss': 0.8222314224310732}
2022-11-18 00:34:31,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:31,774 INFO:     Epoch: 83
2022-11-18 00:34:32,552 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8249400041320107, 'Total loss': 0.8249400041320107} | train loss {'Reaction outcome loss': 0.8236154299757259, 'Total loss': 0.8236154299757259}
2022-11-18 00:34:32,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:32,552 INFO:     Epoch: 84
2022-11-18 00:34:33,321 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8290143006227233, 'Total loss': 0.8290143006227233} | train loss {'Reaction outcome loss': 0.8165340053166456, 'Total loss': 0.8165340053166456}
2022-11-18 00:34:33,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:33,322 INFO:     Epoch: 85
2022-11-18 00:34:34,143 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8136696801944212, 'Total loss': 0.8136696801944212} | train loss {'Reaction outcome loss': 0.8188262278975745, 'Total loss': 0.8188262278975745}
2022-11-18 00:34:34,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:34,144 INFO:     Epoch: 86
2022-11-18 00:34:34,962 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8337827670303258, 'Total loss': 0.8337827670303258} | train loss {'Reaction outcome loss': 0.824250864596502, 'Total loss': 0.824250864596502}
2022-11-18 00:34:34,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:34,962 INFO:     Epoch: 87
2022-11-18 00:34:35,795 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8224574415521189, 'Total loss': 0.8224574415521189} | train loss {'Reaction outcome loss': 0.8195901065009085, 'Total loss': 0.8195901065009085}
2022-11-18 00:34:35,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:35,796 INFO:     Epoch: 88
2022-11-18 00:34:36,617 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8463587984442711, 'Total loss': 0.8463587984442711} | train loss {'Reaction outcome loss': 0.8230430242503702, 'Total loss': 0.8230430242503702}
2022-11-18 00:34:36,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:36,618 INFO:     Epoch: 89
2022-11-18 00:34:37,407 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8333576958287846, 'Total loss': 0.8333576958287846} | train loss {'Reaction outcome loss': 0.8187963413564783, 'Total loss': 0.8187963413564783}
2022-11-18 00:34:37,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:37,407 INFO:     Epoch: 90
2022-11-18 00:34:38,226 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8582615242762999, 'Total loss': 0.8582615242762999} | train loss {'Reaction outcome loss': 0.8312240851070234, 'Total loss': 0.8312240851070234}
2022-11-18 00:34:38,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:38,226 INFO:     Epoch: 91
2022-11-18 00:34:39,013 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8145915804938837, 'Total loss': 0.8145915804938837} | train loss {'Reaction outcome loss': 0.8191489372176197, 'Total loss': 0.8191489372176197}
2022-11-18 00:34:39,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:39,013 INFO:     Epoch: 92
2022-11-18 00:34:39,851 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8558262315663424, 'Total loss': 0.8558262315663424} | train loss {'Reaction outcome loss': 0.8164599827426647, 'Total loss': 0.8164599827426647}
2022-11-18 00:34:39,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:39,852 INFO:     Epoch: 93
2022-11-18 00:34:40,714 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8255504356189207, 'Total loss': 0.8255504356189207} | train loss {'Reaction outcome loss': 0.8197248731306207, 'Total loss': 0.8197248731306207}
2022-11-18 00:34:40,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:40,714 INFO:     Epoch: 94
2022-11-18 00:34:41,535 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8294384181499481, 'Total loss': 0.8294384181499481} | train loss {'Reaction outcome loss': 0.8218355135396425, 'Total loss': 0.8218355135396425}
2022-11-18 00:34:41,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:41,535 INFO:     Epoch: 95
2022-11-18 00:34:42,319 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8348006660288031, 'Total loss': 0.8348006660288031} | train loss {'Reaction outcome loss': 0.8185669119933597, 'Total loss': 0.8185669119933597}
2022-11-18 00:34:42,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:42,320 INFO:     Epoch: 96
2022-11-18 00:34:43,096 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8472253328019922, 'Total loss': 0.8472253328019922} | train loss {'Reaction outcome loss': 0.8215056511795955, 'Total loss': 0.8215056511795955}
2022-11-18 00:34:43,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:43,096 INFO:     Epoch: 97
2022-11-18 00:34:43,892 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.835190356455066, 'Total loss': 0.835190356455066} | train loss {'Reaction outcome loss': 0.8244153924799158, 'Total loss': 0.8244153924799158}
2022-11-18 00:34:43,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:43,892 INFO:     Epoch: 98
2022-11-18 00:34:44,707 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.889090512286533, 'Total loss': 0.889090512286533} | train loss {'Reaction outcome loss': 0.823888148494095, 'Total loss': 0.823888148494095}
2022-11-18 00:34:44,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:44,707 INFO:     Epoch: 99
2022-11-18 00:34:45,499 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8410209823738445, 'Total loss': 0.8410209823738445} | train loss {'Reaction outcome loss': 0.8194650906300255, 'Total loss': 0.8194650906300255}
2022-11-18 00:34:45,500 INFO:     Best model found after epoch 78 of 100.
2022-11-18 00:34:45,500 INFO:   Done with stage: TRAINING
2022-11-18 00:34:45,500 INFO:   Starting stage: EVALUATION
2022-11-18 00:34:45,625 INFO:   Done with stage: EVALUATION
2022-11-18 00:34:45,625 INFO:   Leaving out SEQ value Fold_6
2022-11-18 00:34:45,638 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 00:34:45,638 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:34:46,309 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:34:46,309 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:34:46,380 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:34:46,380 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:34:46,380 INFO:     No hyperparam tuning for this model
2022-11-18 00:34:46,380 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:34:46,380 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:34:46,381 INFO:     None feature selector for col prot
2022-11-18 00:34:46,381 INFO:     None feature selector for col prot
2022-11-18 00:34:46,381 INFO:     None feature selector for col prot
2022-11-18 00:34:46,382 INFO:     None feature selector for col chem
2022-11-18 00:34:46,382 INFO:     None feature selector for col chem
2022-11-18 00:34:46,382 INFO:     None feature selector for col chem
2022-11-18 00:34:46,382 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:34:46,382 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:34:46,384 INFO:     Number of params in model 168571
2022-11-18 00:34:46,387 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:34:46,387 INFO:   Starting stage: TRAINING
2022-11-18 00:34:46,445 INFO:     Val loss before train {'Reaction outcome loss': 1.0034572576934642, 'Total loss': 1.0034572576934642}
2022-11-18 00:34:46,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:46,445 INFO:     Epoch: 0
2022-11-18 00:34:47,262 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9278458472002636, 'Total loss': 0.9278458472002636} | train loss {'Reaction outcome loss': 0.8807420564755317, 'Total loss': 0.8807420564755317}
2022-11-18 00:34:47,262 INFO:     Found new best model at epoch 0
2022-11-18 00:34:47,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:47,263 INFO:     Epoch: 1
2022-11-18 00:34:48,086 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8663133518262343, 'Total loss': 0.8663133518262343} | train loss {'Reaction outcome loss': 0.8556258130458093, 'Total loss': 0.8556258130458093}
2022-11-18 00:34:48,087 INFO:     Found new best model at epoch 1
2022-11-18 00:34:48,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:48,087 INFO:     Epoch: 2
2022-11-18 00:34:48,874 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8561639768833463, 'Total loss': 0.8561639768833463} | train loss {'Reaction outcome loss': 0.8562583662569523, 'Total loss': 0.8562583662569523}
2022-11-18 00:34:48,874 INFO:     Found new best model at epoch 2
2022-11-18 00:34:48,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:48,875 INFO:     Epoch: 3
2022-11-18 00:34:49,651 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8447871675545519, 'Total loss': 0.8447871675545519} | train loss {'Reaction outcome loss': 0.8453492347992235, 'Total loss': 0.8453492347992235}
2022-11-18 00:34:49,652 INFO:     Found new best model at epoch 3
2022-11-18 00:34:49,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:49,652 INFO:     Epoch: 4
2022-11-18 00:34:50,488 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8303875164552168, 'Total loss': 0.8303875164552168} | train loss {'Reaction outcome loss': 0.848767189849769, 'Total loss': 0.848767189849769}
2022-11-18 00:34:50,488 INFO:     Found new best model at epoch 4
2022-11-18 00:34:50,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:50,489 INFO:     Epoch: 5
2022-11-18 00:34:51,363 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8420938890088688, 'Total loss': 0.8420938890088688} | train loss {'Reaction outcome loss': 0.843780786640221, 'Total loss': 0.843780786640221}
2022-11-18 00:34:51,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:51,363 INFO:     Epoch: 6
2022-11-18 00:34:52,174 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8330232528122988, 'Total loss': 0.8330232528122988} | train loss {'Reaction outcome loss': 0.8357461118890394, 'Total loss': 0.8357461118890394}
2022-11-18 00:34:52,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:52,176 INFO:     Epoch: 7
2022-11-18 00:34:53,036 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8272779360413551, 'Total loss': 0.8272779360413551} | train loss {'Reaction outcome loss': 0.8367138253825326, 'Total loss': 0.8367138253825326}
2022-11-18 00:34:53,036 INFO:     Found new best model at epoch 7
2022-11-18 00:34:53,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:53,037 INFO:     Epoch: 8
2022-11-18 00:34:53,837 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8312457447702234, 'Total loss': 0.8312457447702234} | train loss {'Reaction outcome loss': 0.8300367236858414, 'Total loss': 0.8300367236858414}
2022-11-18 00:34:53,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:53,837 INFO:     Epoch: 9
2022-11-18 00:34:54,607 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8311552574688738, 'Total loss': 0.8311552574688738} | train loss {'Reaction outcome loss': 0.830887462703451, 'Total loss': 0.830887462703451}
2022-11-18 00:34:54,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:54,607 INFO:     Epoch: 10
2022-11-18 00:34:55,421 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8175013851035725, 'Total loss': 0.8175013851035725} | train loss {'Reaction outcome loss': 0.8319343651735014, 'Total loss': 0.8319343651735014}
2022-11-18 00:34:55,421 INFO:     Found new best model at epoch 10
2022-11-18 00:34:55,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:55,422 INFO:     Epoch: 11
2022-11-18 00:34:56,248 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8338448290120472, 'Total loss': 0.8338448290120472} | train loss {'Reaction outcome loss': 0.8316851462568006, 'Total loss': 0.8316851462568006}
2022-11-18 00:34:56,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:56,248 INFO:     Epoch: 12
2022-11-18 00:34:57,067 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8226582407951355, 'Total loss': 0.8226582407951355} | train loss {'Reaction outcome loss': 0.8272524108329127, 'Total loss': 0.8272524108329127}
2022-11-18 00:34:57,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:57,067 INFO:     Epoch: 13
2022-11-18 00:34:57,844 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8133804086934436, 'Total loss': 0.8133804086934436} | train loss {'Reaction outcome loss': 0.8245539558270285, 'Total loss': 0.8245539558270285}
2022-11-18 00:34:57,844 INFO:     Found new best model at epoch 13
2022-11-18 00:34:57,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:57,845 INFO:     Epoch: 14
2022-11-18 00:34:58,658 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8260245871814814, 'Total loss': 0.8260245871814814} | train loss {'Reaction outcome loss': 0.8244475173133035, 'Total loss': 0.8244475173133035}
2022-11-18 00:34:58,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:58,658 INFO:     Epoch: 15
2022-11-18 00:34:59,476 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8196465948765929, 'Total loss': 0.8196465948765929} | train loss {'Reaction outcome loss': 0.824422464135193, 'Total loss': 0.824422464135193}
2022-11-18 00:34:59,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:34:59,477 INFO:     Epoch: 16
2022-11-18 00:35:00,297 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8681688701564615, 'Total loss': 0.8681688701564615} | train loss {'Reaction outcome loss': 0.8259447569087628, 'Total loss': 0.8259447569087628}
2022-11-18 00:35:00,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:00,298 INFO:     Epoch: 17
2022-11-18 00:35:01,116 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8094818090850656, 'Total loss': 0.8094818090850656} | train loss {'Reaction outcome loss': 0.8235018467230182, 'Total loss': 0.8235018467230182}
2022-11-18 00:35:01,116 INFO:     Found new best model at epoch 17
2022-11-18 00:35:01,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:01,117 INFO:     Epoch: 18
2022-11-18 00:35:01,926 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8235414082353766, 'Total loss': 0.8235414082353766} | train loss {'Reaction outcome loss': 0.8249552654883554, 'Total loss': 0.8249552654883554}
2022-11-18 00:35:01,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:01,926 INFO:     Epoch: 19
2022-11-18 00:35:02,750 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8110157203945246, 'Total loss': 0.8110157203945246} | train loss {'Reaction outcome loss': 0.8197882140596067, 'Total loss': 0.8197882140596067}
2022-11-18 00:35:02,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:02,751 INFO:     Epoch: 20
2022-11-18 00:35:03,577 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8267769170078364, 'Total loss': 0.8267769170078364} | train loss {'Reaction outcome loss': 0.8227790684228943, 'Total loss': 0.8227790684228943}
2022-11-18 00:35:03,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:03,577 INFO:     Epoch: 21
2022-11-18 00:35:04,361 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8269325311888348, 'Total loss': 0.8269325311888348} | train loss {'Reaction outcome loss': 0.820343736438982, 'Total loss': 0.820343736438982}
2022-11-18 00:35:04,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:04,362 INFO:     Epoch: 22
2022-11-18 00:35:05,170 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8107580881227147, 'Total loss': 0.8107580881227147} | train loss {'Reaction outcome loss': 0.8202853862556719, 'Total loss': 0.8202853862556719}
2022-11-18 00:35:05,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:05,170 INFO:     Epoch: 23
2022-11-18 00:35:05,985 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8445128642699935, 'Total loss': 0.8445128642699935} | train loss {'Reaction outcome loss': 0.8177454242062184, 'Total loss': 0.8177454242062184}
2022-11-18 00:35:05,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:05,986 INFO:     Epoch: 24
2022-11-18 00:35:06,787 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.814581040631641, 'Total loss': 0.814581040631641} | train loss {'Reaction outcome loss': 0.822371399691028, 'Total loss': 0.822371399691028}
2022-11-18 00:35:06,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:06,787 INFO:     Epoch: 25
2022-11-18 00:35:07,566 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.818012764508074, 'Total loss': 0.818012764508074} | train loss {'Reaction outcome loss': 0.8242408028773723, 'Total loss': 0.8242408028773723}
2022-11-18 00:35:07,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:07,566 INFO:     Epoch: 26
2022-11-18 00:35:08,383 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8305334381081841, 'Total loss': 0.8305334381081841} | train loss {'Reaction outcome loss': 0.8216050538805223, 'Total loss': 0.8216050538805223}
2022-11-18 00:35:08,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:08,383 INFO:     Epoch: 27
2022-11-18 00:35:09,212 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8305975029414351, 'Total loss': 0.8305975029414351} | train loss {'Reaction outcome loss': 0.825733766740849, 'Total loss': 0.825733766740849}
2022-11-18 00:35:09,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:09,212 INFO:     Epoch: 28
2022-11-18 00:35:10,033 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8154022395610809, 'Total loss': 0.8154022395610809} | train loss {'Reaction outcome loss': 0.8200514722735651, 'Total loss': 0.8200514722735651}
2022-11-18 00:35:10,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:10,033 INFO:     Epoch: 29
2022-11-18 00:35:10,858 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8121883754025806, 'Total loss': 0.8121883754025806} | train loss {'Reaction outcome loss': 0.8200816444812282, 'Total loss': 0.8200816444812282}
2022-11-18 00:35:10,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:10,860 INFO:     Epoch: 30
2022-11-18 00:35:11,665 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8206943409009413, 'Total loss': 0.8206943409009413} | train loss {'Reaction outcome loss': 0.8195580388569543, 'Total loss': 0.8195580388569543}
2022-11-18 00:35:11,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:11,665 INFO:     Epoch: 31
2022-11-18 00:35:12,490 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8103017366745255, 'Total loss': 0.8103017366745255} | train loss {'Reaction outcome loss': 0.8238919487883968, 'Total loss': 0.8238919487883968}
2022-11-18 00:35:12,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:12,490 INFO:     Epoch: 32
2022-11-18 00:35:13,294 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8135667375542901, 'Total loss': 0.8135667375542901} | train loss {'Reaction outcome loss': 0.8208598387577841, 'Total loss': 0.8208598387577841}
2022-11-18 00:35:13,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:13,294 INFO:     Epoch: 33
2022-11-18 00:35:14,083 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8300103098154068, 'Total loss': 0.8300103098154068} | train loss {'Reaction outcome loss': 0.8230426722476559, 'Total loss': 0.8230426722476559}
2022-11-18 00:35:14,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:14,083 INFO:     Epoch: 34
2022-11-18 00:35:14,906 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8148465048183094, 'Total loss': 0.8148465048183094} | train loss {'Reaction outcome loss': 0.8202643007520707, 'Total loss': 0.8202643007520707}
2022-11-18 00:35:14,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:14,906 INFO:     Epoch: 35
2022-11-18 00:35:15,732 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8287168389016931, 'Total loss': 0.8287168389016931} | train loss {'Reaction outcome loss': 0.8192435734935345, 'Total loss': 0.8192435734935345}
2022-11-18 00:35:15,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:15,732 INFO:     Epoch: 36
2022-11-18 00:35:16,529 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8164066184650768, 'Total loss': 0.8164066184650768} | train loss {'Reaction outcome loss': 0.8200872280905324, 'Total loss': 0.8200872280905324}
2022-11-18 00:35:16,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:16,529 INFO:     Epoch: 37
2022-11-18 00:35:17,384 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8183228888294913, 'Total loss': 0.8183228888294913} | train loss {'Reaction outcome loss': 0.8179589346531899, 'Total loss': 0.8179589346531899}
2022-11-18 00:35:17,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:17,385 INFO:     Epoch: 38
2022-11-18 00:35:18,191 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8243651708418672, 'Total loss': 0.8243651708418672} | train loss {'Reaction outcome loss': 0.816272771526729, 'Total loss': 0.816272771526729}
2022-11-18 00:35:18,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:18,191 INFO:     Epoch: 39
2022-11-18 00:35:18,967 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8096464357592843, 'Total loss': 0.8096464357592843} | train loss {'Reaction outcome loss': 0.8238478920632794, 'Total loss': 0.8238478920632794}
2022-11-18 00:35:18,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:18,967 INFO:     Epoch: 40
2022-11-18 00:35:19,738 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8238428966565565, 'Total loss': 0.8238428966565565} | train loss {'Reaction outcome loss': 0.8175324504413912, 'Total loss': 0.8175324504413912}
2022-11-18 00:35:19,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:19,739 INFO:     Epoch: 41
2022-11-18 00:35:20,565 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8083389191464945, 'Total loss': 0.8083389191464945} | train loss {'Reaction outcome loss': 0.8147505864260658, 'Total loss': 0.8147505864260658}
2022-11-18 00:35:20,565 INFO:     Found new best model at epoch 41
2022-11-18 00:35:20,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:20,566 INFO:     Epoch: 42
2022-11-18 00:35:21,385 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8048567460341887, 'Total loss': 0.8048567460341887} | train loss {'Reaction outcome loss': 0.8180932665784513, 'Total loss': 0.8180932665784513}
2022-11-18 00:35:21,385 INFO:     Found new best model at epoch 42
2022-11-18 00:35:21,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:21,386 INFO:     Epoch: 43
2022-11-18 00:35:22,228 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8201009834354575, 'Total loss': 0.8201009834354575} | train loss {'Reaction outcome loss': 0.8223877580415818, 'Total loss': 0.8223877580415818}
2022-11-18 00:35:22,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:22,229 INFO:     Epoch: 44
2022-11-18 00:35:23,011 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8089961931109428, 'Total loss': 0.8089961931109428} | train loss {'Reaction outcome loss': 0.8209079361009982, 'Total loss': 0.8209079361009982}
2022-11-18 00:35:23,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:23,013 INFO:     Epoch: 45
2022-11-18 00:35:23,799 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8080548948862336, 'Total loss': 0.8080548948862336} | train loss {'Reaction outcome loss': 0.8198146094237605, 'Total loss': 0.8198146094237605}
2022-11-18 00:35:23,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:23,800 INFO:     Epoch: 46
2022-11-18 00:35:24,615 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8296355632218447, 'Total loss': 0.8296355632218447} | train loss {'Reaction outcome loss': 0.8167890563847557, 'Total loss': 0.8167890563847557}
2022-11-18 00:35:24,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:24,615 INFO:     Epoch: 47
2022-11-18 00:35:25,443 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8100852349942381, 'Total loss': 0.8100852349942381} | train loss {'Reaction outcome loss': 0.8219202336284422, 'Total loss': 0.8219202336284422}
2022-11-18 00:35:25,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:25,443 INFO:     Epoch: 48
2022-11-18 00:35:26,280 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8347497616301883, 'Total loss': 0.8347497616301883} | train loss {'Reaction outcome loss': 0.8170351270706423, 'Total loss': 0.8170351270706423}
2022-11-18 00:35:26,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:26,281 INFO:     Epoch: 49
2022-11-18 00:35:27,104 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8448751040480353, 'Total loss': 0.8448751040480353} | train loss {'Reaction outcome loss': 0.8225052289424404, 'Total loss': 0.8225052289424404}
2022-11-18 00:35:27,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:27,104 INFO:     Epoch: 50
2022-11-18 00:35:27,938 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8080416592684659, 'Total loss': 0.8080416592684659} | train loss {'Reaction outcome loss': 0.8172831423580647, 'Total loss': 0.8172831423580647}
2022-11-18 00:35:27,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:27,938 INFO:     Epoch: 51
2022-11-18 00:35:28,758 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8190809217366305, 'Total loss': 0.8190809217366305} | train loss {'Reaction outcome loss': 0.8160699670833926, 'Total loss': 0.8160699670833926}
2022-11-18 00:35:28,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:28,758 INFO:     Epoch: 52
2022-11-18 00:35:29,564 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.810700226913799, 'Total loss': 0.810700226913799} | train loss {'Reaction outcome loss': 0.8211380208451902, 'Total loss': 0.8211380208451902}
2022-11-18 00:35:29,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:29,565 INFO:     Epoch: 53
2022-11-18 00:35:30,355 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.815956520085985, 'Total loss': 0.815956520085985} | train loss {'Reaction outcome loss': 0.8197891266355591, 'Total loss': 0.8197891266355591}
2022-11-18 00:35:30,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:30,355 INFO:     Epoch: 54
2022-11-18 00:35:31,133 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8311248828064312, 'Total loss': 0.8311248828064312} | train loss {'Reaction outcome loss': 0.8191386999622468, 'Total loss': 0.8191386999622468}
2022-11-18 00:35:31,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:31,133 INFO:     Epoch: 55
2022-11-18 00:35:31,932 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8079968419941989, 'Total loss': 0.8079968419941989} | train loss {'Reaction outcome loss': 0.8193146344875136, 'Total loss': 0.8193146344875136}
2022-11-18 00:35:31,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:31,932 INFO:     Epoch: 56
2022-11-18 00:35:32,743 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8186404840512709, 'Total loss': 0.8186404840512709} | train loss {'Reaction outcome loss': 0.8201419240044009, 'Total loss': 0.8201419240044009}
2022-11-18 00:35:32,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:32,743 INFO:     Epoch: 57
2022-11-18 00:35:33,553 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8231337829069658, 'Total loss': 0.8231337829069658} | train loss {'Reaction outcome loss': 0.8233930094828529, 'Total loss': 0.8233930094828529}
2022-11-18 00:35:33,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:33,553 INFO:     Epoch: 58
2022-11-18 00:35:34,326 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8190879456021569, 'Total loss': 0.8190879456021569} | train loss {'Reaction outcome loss': 0.8206759885914864, 'Total loss': 0.8206759885914864}
2022-11-18 00:35:34,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:34,326 INFO:     Epoch: 59
2022-11-18 00:35:35,115 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8254406425085935, 'Total loss': 0.8254406425085935} | train loss {'Reaction outcome loss': 0.8171242003839824, 'Total loss': 0.8171242003839824}
2022-11-18 00:35:35,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:35,116 INFO:     Epoch: 60
2022-11-18 00:35:35,934 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.818767022002827, 'Total loss': 0.818767022002827} | train loss {'Reaction outcome loss': 0.8173052229948582, 'Total loss': 0.8173052229948582}
2022-11-18 00:35:35,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:35,934 INFO:     Epoch: 61
2022-11-18 00:35:36,731 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8175691596486352, 'Total loss': 0.8175691596486352} | train loss {'Reaction outcome loss': 0.81934803183521, 'Total loss': 0.81934803183521}
2022-11-18 00:35:36,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:36,731 INFO:     Epoch: 62
2022-11-18 00:35:37,539 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8135687607255849, 'Total loss': 0.8135687607255849} | train loss {'Reaction outcome loss': 0.8183610732516935, 'Total loss': 0.8183610732516935}
2022-11-18 00:35:37,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:37,539 INFO:     Epoch: 63
2022-11-18 00:35:38,358 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8159556646238674, 'Total loss': 0.8159556646238674} | train loss {'Reaction outcome loss': 0.8212847719269414, 'Total loss': 0.8212847719269414}
2022-11-18 00:35:38,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:38,358 INFO:     Epoch: 64
2022-11-18 00:35:39,181 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8065842132676732, 'Total loss': 0.8065842132676732} | train loss {'Reaction outcome loss': 0.8191984538589755, 'Total loss': 0.8191984538589755}
2022-11-18 00:35:39,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:39,182 INFO:     Epoch: 65
2022-11-18 00:35:40,001 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8134253411130472, 'Total loss': 0.8134253411130472} | train loss {'Reaction outcome loss': 0.8193608767563297, 'Total loss': 0.8193608767563297}
2022-11-18 00:35:40,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:40,001 INFO:     Epoch: 66
2022-11-18 00:35:40,807 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8100705844434825, 'Total loss': 0.8100705844434825} | train loss {'Reaction outcome loss': 0.8235618522570979, 'Total loss': 0.8235618522570979}
2022-11-18 00:35:40,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:40,807 INFO:     Epoch: 67
2022-11-18 00:35:41,589 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8461540625853972, 'Total loss': 0.8461540625853972} | train loss {'Reaction outcome loss': 0.8191748570290304, 'Total loss': 0.8191748570290304}
2022-11-18 00:35:41,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:41,590 INFO:     Epoch: 68
2022-11-18 00:35:42,410 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8168854462829503, 'Total loss': 0.8168854462829503} | train loss {'Reaction outcome loss': 0.8200032964589135, 'Total loss': 0.8200032964589135}
2022-11-18 00:35:42,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:42,410 INFO:     Epoch: 69
2022-11-18 00:35:43,249 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8230481432242827, 'Total loss': 0.8230481432242827} | train loss {'Reaction outcome loss': 0.8199081055579647, 'Total loss': 0.8199081055579647}
2022-11-18 00:35:43,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:43,250 INFO:     Epoch: 70
2022-11-18 00:35:44,060 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8050013888965953, 'Total loss': 0.8050013888965953} | train loss {'Reaction outcome loss': 0.818213205544218, 'Total loss': 0.818213205544218}
2022-11-18 00:35:44,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:44,060 INFO:     Epoch: 71
2022-11-18 00:35:44,863 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8260087330232967, 'Total loss': 0.8260087330232967} | train loss {'Reaction outcome loss': 0.8179450758522556, 'Total loss': 0.8179450758522556}
2022-11-18 00:35:44,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:44,864 INFO:     Epoch: 72
2022-11-18 00:35:45,692 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8152588219805197, 'Total loss': 0.8152588219805197} | train loss {'Reaction outcome loss': 0.8222854118193349, 'Total loss': 0.8222854118193349}
2022-11-18 00:35:45,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:45,692 INFO:     Epoch: 73
2022-11-18 00:35:46,485 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.823281501504508, 'Total loss': 0.823281501504508} | train loss {'Reaction outcome loss': 0.8172860766851133, 'Total loss': 0.8172860766851133}
2022-11-18 00:35:46,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:46,485 INFO:     Epoch: 74
2022-11-18 00:35:47,263 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8174539675766771, 'Total loss': 0.8174539675766771} | train loss {'Reaction outcome loss': 0.8146416422340178, 'Total loss': 0.8146416422340178}
2022-11-18 00:35:47,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:47,263 INFO:     Epoch: 75
2022-11-18 00:35:48,075 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8137541779062964, 'Total loss': 0.8137541779062964} | train loss {'Reaction outcome loss': 0.8229592202171203, 'Total loss': 0.8229592202171203}
2022-11-18 00:35:48,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:48,075 INFO:     Epoch: 76
2022-11-18 00:35:48,872 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8273619528521191, 'Total loss': 0.8273619528521191} | train loss {'Reaction outcome loss': 0.8186623598899572, 'Total loss': 0.8186623598899572}
2022-11-18 00:35:48,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:48,873 INFO:     Epoch: 77
2022-11-18 00:35:49,724 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8138188875534318, 'Total loss': 0.8138188875534318} | train loss {'Reaction outcome loss': 0.8222578787995923, 'Total loss': 0.8222578787995923}
2022-11-18 00:35:49,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:49,724 INFO:     Epoch: 78
2022-11-18 00:35:50,548 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8246094218709252, 'Total loss': 0.8246094218709252} | train loss {'Reaction outcome loss': 0.8202593794032451, 'Total loss': 0.8202593794032451}
2022-11-18 00:35:50,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:50,549 INFO:     Epoch: 79
2022-11-18 00:35:51,386 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8136742128567263, 'Total loss': 0.8136742128567263} | train loss {'Reaction outcome loss': 0.8165112136592788, 'Total loss': 0.8165112136592788}
2022-11-18 00:35:51,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:51,387 INFO:     Epoch: 80
2022-11-18 00:35:52,230 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8218103552406485, 'Total loss': 0.8218103552406485} | train loss {'Reaction outcome loss': 0.8166622865584588, 'Total loss': 0.8166622865584588}
2022-11-18 00:35:52,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:52,230 INFO:     Epoch: 81
2022-11-18 00:35:53,031 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8263466297225519, 'Total loss': 0.8263466297225519} | train loss {'Reaction outcome loss': 0.8205854189732382, 'Total loss': 0.8205854189732382}
2022-11-18 00:35:53,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:53,031 INFO:     Epoch: 82
2022-11-18 00:35:53,861 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8285665132782676, 'Total loss': 0.8285665132782676} | train loss {'Reaction outcome loss': 0.8214340227986535, 'Total loss': 0.8214340227986535}
2022-11-18 00:35:53,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:53,862 INFO:     Epoch: 83
2022-11-18 00:35:54,678 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8345235735177994, 'Total loss': 0.8345235735177994} | train loss {'Reaction outcome loss': 0.8261342428384288, 'Total loss': 0.8261342428384288}
2022-11-18 00:35:54,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:54,678 INFO:     Epoch: 84
2022-11-18 00:35:55,475 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8106969371438026, 'Total loss': 0.8106969371438026} | train loss {'Reaction outcome loss': 0.8216946836440794, 'Total loss': 0.8216946836440794}
2022-11-18 00:35:55,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:55,476 INFO:     Epoch: 85
2022-11-18 00:35:56,316 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8265033330429684, 'Total loss': 0.8265033330429684} | train loss {'Reaction outcome loss': 0.8144102932344521, 'Total loss': 0.8144102932344521}
2022-11-18 00:35:56,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:56,316 INFO:     Epoch: 86
2022-11-18 00:35:57,146 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8044565380974249, 'Total loss': 0.8044565380974249} | train loss {'Reaction outcome loss': 0.8203957188994654, 'Total loss': 0.8203957188994654}
2022-11-18 00:35:57,146 INFO:     Found new best model at epoch 86
2022-11-18 00:35:57,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:57,147 INFO:     Epoch: 87
2022-11-18 00:35:57,929 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8203690140084787, 'Total loss': 0.8203690140084787} | train loss {'Reaction outcome loss': 0.8186719270963823, 'Total loss': 0.8186719270963823}
2022-11-18 00:35:57,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:57,930 INFO:     Epoch: 88
2022-11-18 00:35:58,738 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8105644184080038, 'Total loss': 0.8105644184080038} | train loss {'Reaction outcome loss': 0.8201107128012565, 'Total loss': 0.8201107128012565}
2022-11-18 00:35:58,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:58,739 INFO:     Epoch: 89
2022-11-18 00:35:59,538 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8064566478133202, 'Total loss': 0.8064566478133202} | train loss {'Reaction outcome loss': 0.8213018085206708, 'Total loss': 0.8213018085206708}
2022-11-18 00:35:59,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:35:59,538 INFO:     Epoch: 90
2022-11-18 00:36:00,393 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8290570100600069, 'Total loss': 0.8290570100600069} | train loss {'Reaction outcome loss': 0.8170989745807263, 'Total loss': 0.8170989745807263}
2022-11-18 00:36:00,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:00,393 INFO:     Epoch: 91
2022-11-18 00:36:01,200 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8235241526907141, 'Total loss': 0.8235241526907141} | train loss {'Reaction outcome loss': 0.8194035107810651, 'Total loss': 0.8194035107810651}
2022-11-18 00:36:01,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:01,200 INFO:     Epoch: 92
2022-11-18 00:36:01,989 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8125516271049326, 'Total loss': 0.8125516271049326} | train loss {'Reaction outcome loss': 0.8219089554923196, 'Total loss': 0.8219089554923196}
2022-11-18 00:36:01,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:01,989 INFO:     Epoch: 93
2022-11-18 00:36:02,807 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8095697686076164, 'Total loss': 0.8095697686076164} | train loss {'Reaction outcome loss': 0.8191500992303894, 'Total loss': 0.8191500992303894}
2022-11-18 00:36:02,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:02,807 INFO:     Epoch: 94
2022-11-18 00:36:03,618 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8325808759440075, 'Total loss': 0.8325808759440075} | train loss {'Reaction outcome loss': 0.8254821278875873, 'Total loss': 0.8254821278875873}
2022-11-18 00:36:03,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:03,618 INFO:     Epoch: 95
2022-11-18 00:36:04,444 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8229338845068758, 'Total loss': 0.8229338845068758} | train loss {'Reaction outcome loss': 0.8229729213541553, 'Total loss': 0.8229729213541553}
2022-11-18 00:36:04,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:04,444 INFO:     Epoch: 96
2022-11-18 00:36:05,237 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8276149732145396, 'Total loss': 0.8276149732145396} | train loss {'Reaction outcome loss': 0.819738395872616, 'Total loss': 0.819738395872616}
2022-11-18 00:36:05,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:05,238 INFO:     Epoch: 97
2022-11-18 00:36:06,032 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8148441578854214, 'Total loss': 0.8148441578854214} | train loss {'Reaction outcome loss': 0.8206128315819848, 'Total loss': 0.8206128315819848}
2022-11-18 00:36:06,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:06,032 INFO:     Epoch: 98
2022-11-18 00:36:06,835 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8092639683322473, 'Total loss': 0.8092639683322473} | train loss {'Reaction outcome loss': 0.820339466535276, 'Total loss': 0.820339466535276}
2022-11-18 00:36:06,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:06,837 INFO:     Epoch: 99
2022-11-18 00:36:07,698 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8343851024454291, 'Total loss': 0.8343851024454291} | train loss {'Reaction outcome loss': 0.8171282614911756, 'Total loss': 0.8171282614911756}
2022-11-18 00:36:07,698 INFO:     Best model found after epoch 87 of 100.
2022-11-18 00:36:07,699 INFO:   Done with stage: TRAINING
2022-11-18 00:36:07,699 INFO:   Starting stage: EVALUATION
2022-11-18 00:36:07,816 INFO:   Done with stage: EVALUATION
2022-11-18 00:36:07,816 INFO:   Leaving out SEQ value Fold_7
2022-11-18 00:36:07,830 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:36:07,830 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:36:08,500 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:36:08,501 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:36:08,572 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:36:08,572 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:36:08,572 INFO:     No hyperparam tuning for this model
2022-11-18 00:36:08,572 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:36:08,572 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:36:08,573 INFO:     None feature selector for col prot
2022-11-18 00:36:08,573 INFO:     None feature selector for col prot
2022-11-18 00:36:08,573 INFO:     None feature selector for col prot
2022-11-18 00:36:08,574 INFO:     None feature selector for col chem
2022-11-18 00:36:08,574 INFO:     None feature selector for col chem
2022-11-18 00:36:08,574 INFO:     None feature selector for col chem
2022-11-18 00:36:08,574 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:36:08,574 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:36:08,575 INFO:     Number of params in model 168571
2022-11-18 00:36:08,578 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:36:08,579 INFO:   Starting stage: TRAINING
2022-11-18 00:36:08,638 INFO:     Val loss before train {'Reaction outcome loss': 1.03065624833107, 'Total loss': 1.03065624833107}
2022-11-18 00:36:08,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:08,638 INFO:     Epoch: 0
2022-11-18 00:36:09,422 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8525614684278314, 'Total loss': 0.8525614684278314} | train loss {'Reaction outcome loss': 0.8765020654027761, 'Total loss': 0.8765020654027761}
2022-11-18 00:36:09,422 INFO:     Found new best model at epoch 0
2022-11-18 00:36:09,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:09,423 INFO:     Epoch: 1
2022-11-18 00:36:10,249 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8405197181484916, 'Total loss': 0.8405197181484916} | train loss {'Reaction outcome loss': 0.8427040219186288, 'Total loss': 0.8427040219186288}
2022-11-18 00:36:10,249 INFO:     Found new best model at epoch 1
2022-11-18 00:36:10,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:10,250 INFO:     Epoch: 2
2022-11-18 00:36:11,085 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8485949066552249, 'Total loss': 0.8485949066552249} | train loss {'Reaction outcome loss': 0.8425602765701078, 'Total loss': 0.8425602765701078}
2022-11-18 00:36:11,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:11,085 INFO:     Epoch: 3
2022-11-18 00:36:11,887 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8263271830298684, 'Total loss': 0.8263271830298684} | train loss {'Reaction outcome loss': 0.8405897197453117, 'Total loss': 0.8405897197453117}
2022-11-18 00:36:11,887 INFO:     Found new best model at epoch 3
2022-11-18 00:36:11,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:11,888 INFO:     Epoch: 4
2022-11-18 00:36:12,676 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8315916643901304, 'Total loss': 0.8315916643901304} | train loss {'Reaction outcome loss': 0.836387150200755, 'Total loss': 0.836387150200755}
2022-11-18 00:36:12,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:12,677 INFO:     Epoch: 5
2022-11-18 00:36:13,505 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.829686662690206, 'Total loss': 0.829686662690206} | train loss {'Reaction outcome loss': 0.8316876988420602, 'Total loss': 0.8316876988420602}
2022-11-18 00:36:13,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:13,506 INFO:     Epoch: 6
2022-11-18 00:36:14,322 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8315033939751711, 'Total loss': 0.8315033939751711} | train loss {'Reaction outcome loss': 0.8314467419979543, 'Total loss': 0.8314467419979543}
2022-11-18 00:36:14,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:14,322 INFO:     Epoch: 7
2022-11-18 00:36:15,161 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8089953566139395, 'Total loss': 0.8089953566139395} | train loss {'Reaction outcome loss': 0.8206045015711292, 'Total loss': 0.8206045015711292}
2022-11-18 00:36:15,161 INFO:     Found new best model at epoch 7
2022-11-18 00:36:15,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:15,162 INFO:     Epoch: 8
2022-11-18 00:36:15,952 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8034698529676958, 'Total loss': 0.8034698529676958} | train loss {'Reaction outcome loss': 0.8225191251831017, 'Total loss': 0.8225191251831017}
2022-11-18 00:36:15,952 INFO:     Found new best model at epoch 8
2022-11-18 00:36:15,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:15,953 INFO:     Epoch: 9
2022-11-18 00:36:16,744 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8099363554607738, 'Total loss': 0.8099363554607738} | train loss {'Reaction outcome loss': 0.8272080247701421, 'Total loss': 0.8272080247701421}
2022-11-18 00:36:16,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:16,744 INFO:     Epoch: 10
2022-11-18 00:36:17,579 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8489514521577142, 'Total loss': 0.8489514521577142} | train loss {'Reaction outcome loss': 0.8254960372832864, 'Total loss': 0.8254960372832864}
2022-11-18 00:36:17,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:17,579 INFO:     Epoch: 11
2022-11-18 00:36:18,422 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8186333633281968, 'Total loss': 0.8186333633281968} | train loss {'Reaction outcome loss': 0.816359212976477, 'Total loss': 0.816359212976477}
2022-11-18 00:36:18,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:18,422 INFO:     Epoch: 12
2022-11-18 00:36:19,208 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8533975874835794, 'Total loss': 0.8533975874835794} | train loss {'Reaction outcome loss': 0.8362986903924209, 'Total loss': 0.8362986903924209}
2022-11-18 00:36:19,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:19,208 INFO:     Epoch: 13
2022-11-18 00:36:20,023 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.818210092457858, 'Total loss': 0.818210092457858} | train loss {'Reaction outcome loss': 0.8184426676647866, 'Total loss': 0.8184426676647866}
2022-11-18 00:36:20,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:20,023 INFO:     Epoch: 14
2022-11-18 00:36:20,820 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8075701628218998, 'Total loss': 0.8075701628218998} | train loss {'Reaction outcome loss': 0.8269821434368488, 'Total loss': 0.8269821434368488}
2022-11-18 00:36:20,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:20,820 INFO:     Epoch: 15
2022-11-18 00:36:21,640 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.810670444233851, 'Total loss': 0.810670444233851} | train loss {'Reaction outcome loss': 0.8168134268237511, 'Total loss': 0.8168134268237511}
2022-11-18 00:36:21,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:21,640 INFO:     Epoch: 16
2022-11-18 00:36:22,441 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.828423911197619, 'Total loss': 0.828423911197619} | train loss {'Reaction outcome loss': 0.8122736474401072, 'Total loss': 0.8122736474401072}
2022-11-18 00:36:22,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:22,441 INFO:     Epoch: 17
2022-11-18 00:36:23,242 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8000307557257739, 'Total loss': 0.8000307557257739} | train loss {'Reaction outcome loss': 0.8127041298307871, 'Total loss': 0.8127041298307871}
2022-11-18 00:36:23,242 INFO:     Found new best model at epoch 17
2022-11-18 00:36:23,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:23,243 INFO:     Epoch: 18
2022-11-18 00:36:24,020 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8384196941148151, 'Total loss': 0.8384196941148151} | train loss {'Reaction outcome loss': 0.8154540518034807, 'Total loss': 0.8154540518034807}
2022-11-18 00:36:24,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:24,021 INFO:     Epoch: 19
2022-11-18 00:36:24,838 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8231591975147073, 'Total loss': 0.8231591975147073} | train loss {'Reaction outcome loss': 0.8177320001428185, 'Total loss': 0.8177320001428185}
2022-11-18 00:36:24,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:24,838 INFO:     Epoch: 20
2022-11-18 00:36:25,647 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8263476992195303, 'Total loss': 0.8263476992195303} | train loss {'Reaction outcome loss': 0.8149549338499061, 'Total loss': 0.8149549338499061}
2022-11-18 00:36:25,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:25,648 INFO:     Epoch: 21
2022-11-18 00:36:26,480 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7980174611915242, 'Total loss': 0.7980174611915242} | train loss {'Reaction outcome loss': 0.8158159108779691, 'Total loss': 0.8158159108779691}
2022-11-18 00:36:26,480 INFO:     Found new best model at epoch 21
2022-11-18 00:36:26,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:26,481 INFO:     Epoch: 22
2022-11-18 00:36:27,266 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8107427074150606, 'Total loss': 0.8107427074150606} | train loss {'Reaction outcome loss': 0.8203453387808703, 'Total loss': 0.8203453387808703}
2022-11-18 00:36:27,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:27,266 INFO:     Epoch: 23
2022-11-18 00:36:28,059 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8147416893731464, 'Total loss': 0.8147416893731464} | train loss {'Reaction outcome loss': 0.818029001536157, 'Total loss': 0.818029001536157}
2022-11-18 00:36:28,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:28,060 INFO:     Epoch: 24
2022-11-18 00:36:28,885 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8280434953895482, 'Total loss': 0.8280434953895482} | train loss {'Reaction outcome loss': 0.8195634398624482, 'Total loss': 0.8195634398624482}
2022-11-18 00:36:28,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:28,885 INFO:     Epoch: 25
2022-11-18 00:36:29,664 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.81696171652187, 'Total loss': 0.81696171652187} | train loss {'Reaction outcome loss': 0.8216788826683755, 'Total loss': 0.8216788826683755}
2022-11-18 00:36:29,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:29,664 INFO:     Epoch: 26
2022-11-18 00:36:30,489 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8201095041903582, 'Total loss': 0.8201095041903582} | train loss {'Reaction outcome loss': 0.8190428800428444, 'Total loss': 0.8190428800428444}
2022-11-18 00:36:30,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:30,490 INFO:     Epoch: 27
2022-11-18 00:36:31,322 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8157231150702997, 'Total loss': 0.8157231150702997} | train loss {'Reaction outcome loss': 0.813496537566909, 'Total loss': 0.813496537566909}
2022-11-18 00:36:31,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:31,322 INFO:     Epoch: 28
2022-11-18 00:36:32,164 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8091934512961995, 'Total loss': 0.8091934512961995} | train loss {'Reaction outcome loss': 0.815517813133204, 'Total loss': 0.815517813133204}
2022-11-18 00:36:32,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:32,164 INFO:     Epoch: 29
2022-11-18 00:36:32,957 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8306612196293744, 'Total loss': 0.8306612196293744} | train loss {'Reaction outcome loss': 0.825707504865129, 'Total loss': 0.825707504865129}
2022-11-18 00:36:32,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:32,957 INFO:     Epoch: 30
2022-11-18 00:36:33,741 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8068232319571755, 'Total loss': 0.8068232319571755} | train loss {'Reaction outcome loss': 0.8163168991384236, 'Total loss': 0.8163168991384236}
2022-11-18 00:36:33,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:33,742 INFO:     Epoch: 31
2022-11-18 00:36:34,521 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8164532685821707, 'Total loss': 0.8164532685821707} | train loss {'Reaction outcome loss': 0.8166025943360348, 'Total loss': 0.8166025943360348}
2022-11-18 00:36:34,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:34,521 INFO:     Epoch: 32
2022-11-18 00:36:35,340 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8159019669348543, 'Total loss': 0.8159019669348543} | train loss {'Reaction outcome loss': 0.813472020119308, 'Total loss': 0.813472020119308}
2022-11-18 00:36:35,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:35,340 INFO:     Epoch: 33
2022-11-18 00:36:36,166 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8118986148725856, 'Total loss': 0.8118986148725856} | train loss {'Reaction outcome loss': 0.811280980917365, 'Total loss': 0.811280980917365}
2022-11-18 00:36:36,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:36,166 INFO:     Epoch: 34
2022-11-18 00:36:36,968 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.808275238356807, 'Total loss': 0.808275238356807} | train loss {'Reaction outcome loss': 0.8106249358489929, 'Total loss': 0.8106249358489929}
2022-11-18 00:36:36,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:36,968 INFO:     Epoch: 35
2022-11-18 00:36:37,822 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.80263721130111, 'Total loss': 0.80263721130111} | train loss {'Reaction outcome loss': 0.8148545543191886, 'Total loss': 0.8148545543191886}
2022-11-18 00:36:37,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:37,824 INFO:     Epoch: 36
2022-11-18 00:36:38,646 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8118667866696011, 'Total loss': 0.8118667866696011} | train loss {'Reaction outcome loss': 0.8125162181342661, 'Total loss': 0.8125162181342661}
2022-11-18 00:36:38,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:38,646 INFO:     Epoch: 37
2022-11-18 00:36:39,469 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.808826013722203, 'Total loss': 0.808826013722203} | train loss {'Reaction outcome loss': 0.8190760821224707, 'Total loss': 0.8190760821224707}
2022-11-18 00:36:39,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:39,469 INFO:     Epoch: 38
2022-11-18 00:36:40,300 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8103485256433487, 'Total loss': 0.8103485256433487} | train loss {'Reaction outcome loss': 0.822846745551839, 'Total loss': 0.822846745551839}
2022-11-18 00:36:40,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:40,300 INFO:     Epoch: 39
2022-11-18 00:36:41,086 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8098447939211671, 'Total loss': 0.8098447939211671} | train loss {'Reaction outcome loss': 0.8142652909765359, 'Total loss': 0.8142652909765359}
2022-11-18 00:36:41,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:41,086 INFO:     Epoch: 40
2022-11-18 00:36:41,856 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8121787655082616, 'Total loss': 0.8121787655082616} | train loss {'Reaction outcome loss': 0.8203512234726416, 'Total loss': 0.8203512234726416}
2022-11-18 00:36:41,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:41,856 INFO:     Epoch: 41
2022-11-18 00:36:42,656 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7913415303284471, 'Total loss': 0.7913415303284471} | train loss {'Reaction outcome loss': 0.8095644009620072, 'Total loss': 0.8095644009620072}
2022-11-18 00:36:42,657 INFO:     Found new best model at epoch 41
2022-11-18 00:36:42,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:42,657 INFO:     Epoch: 42
2022-11-18 00:36:43,497 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7927514334971254, 'Total loss': 0.7927514334971254} | train loss {'Reaction outcome loss': 0.8106334524960653, 'Total loss': 0.8106334524960653}
2022-11-18 00:36:43,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:43,497 INFO:     Epoch: 43
2022-11-18 00:36:44,303 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8013620810075239, 'Total loss': 0.8013620810075239} | train loss {'Reaction outcome loss': 0.8147581353602622, 'Total loss': 0.8147581353602622}
2022-11-18 00:36:44,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:44,304 INFO:     Epoch: 44
2022-11-18 00:36:45,077 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8072388158603148, 'Total loss': 0.8072388158603148} | train loss {'Reaction outcome loss': 0.8151628044452744, 'Total loss': 0.8151628044452744}
2022-11-18 00:36:45,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:45,077 INFO:     Epoch: 45
2022-11-18 00:36:45,889 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8125795071775263, 'Total loss': 0.8125795071775263} | train loss {'Reaction outcome loss': 0.814954223541113, 'Total loss': 0.814954223541113}
2022-11-18 00:36:45,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:45,889 INFO:     Epoch: 46
2022-11-18 00:36:46,736 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8373008397492495, 'Total loss': 0.8373008397492495} | train loss {'Reaction outcome loss': 0.8170038513567767, 'Total loss': 0.8170038513567767}
2022-11-18 00:36:46,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:46,736 INFO:     Epoch: 47
2022-11-18 00:36:47,551 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8090275228023529, 'Total loss': 0.8090275228023529} | train loss {'Reaction outcome loss': 0.8139809740910887, 'Total loss': 0.8139809740910887}
2022-11-18 00:36:47,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:47,551 INFO:     Epoch: 48
2022-11-18 00:36:48,343 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8186986866322431, 'Total loss': 0.8186986866322431} | train loss {'Reaction outcome loss': 0.8138242841732164, 'Total loss': 0.8138242841732164}
2022-11-18 00:36:48,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:48,343 INFO:     Epoch: 49
2022-11-18 00:36:49,125 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8071826486424967, 'Total loss': 0.8071826486424967} | train loss {'Reaction outcome loss': 0.8134627056266615, 'Total loss': 0.8134627056266615}
2022-11-18 00:36:49,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:49,125 INFO:     Epoch: 50
2022-11-18 00:36:49,919 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8136482739990408, 'Total loss': 0.8136482739990408} | train loss {'Reaction outcome loss': 0.8158856818550512, 'Total loss': 0.8158856818550512}
2022-11-18 00:36:49,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:49,920 INFO:     Epoch: 51
2022-11-18 00:36:50,707 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8325601375915788, 'Total loss': 0.8325601375915788} | train loss {'Reaction outcome loss': 0.8083509933128048, 'Total loss': 0.8083509933128048}
2022-11-18 00:36:50,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:50,708 INFO:     Epoch: 52
2022-11-18 00:36:51,521 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8115657500245355, 'Total loss': 0.8115657500245355} | train loss {'Reaction outcome loss': 0.8204444089399175, 'Total loss': 0.8204444089399175}
2022-11-18 00:36:51,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:51,522 INFO:     Epoch: 53
2022-11-18 00:36:52,324 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8159548220309344, 'Total loss': 0.8159548220309344} | train loss {'Reaction outcome loss': 0.8160659653183661, 'Total loss': 0.8160659653183661}
2022-11-18 00:36:52,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:52,324 INFO:     Epoch: 54
2022-11-18 00:36:53,156 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.798133675347675, 'Total loss': 0.798133675347675} | train loss {'Reaction outcome loss': 0.8101819947301617, 'Total loss': 0.8101819947301617}
2022-11-18 00:36:53,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:53,156 INFO:     Epoch: 55
2022-11-18 00:36:53,984 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8135306469418786, 'Total loss': 0.8135306469418786} | train loss {'Reaction outcome loss': 0.8095252932565897, 'Total loss': 0.8095252932565897}
2022-11-18 00:36:53,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:53,985 INFO:     Epoch: 56
2022-11-18 00:36:54,789 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8095147040757266, 'Total loss': 0.8095147040757266} | train loss {'Reaction outcome loss': 0.8260187951900698, 'Total loss': 0.8260187951900698}
2022-11-18 00:36:54,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:54,790 INFO:     Epoch: 57
2022-11-18 00:36:55,603 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8444337716156786, 'Total loss': 0.8444337716156786} | train loss {'Reaction outcome loss': 0.8140034375010956, 'Total loss': 0.8140034375010956}
2022-11-18 00:36:55,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:55,603 INFO:     Epoch: 58
2022-11-18 00:36:56,420 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8288244347680699, 'Total loss': 0.8288244347680699} | train loss {'Reaction outcome loss': 0.8167766275917471, 'Total loss': 0.8167766275917471}
2022-11-18 00:36:56,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:56,421 INFO:     Epoch: 59
2022-11-18 00:36:57,226 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8080518042499368, 'Total loss': 0.8080518042499368} | train loss {'Reaction outcome loss': 0.8119380511795944, 'Total loss': 0.8119380511795944}
2022-11-18 00:36:57,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:57,226 INFO:     Epoch: 60
2022-11-18 00:36:58,053 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8100738193501126, 'Total loss': 0.8100738193501126} | train loss {'Reaction outcome loss': 0.811436181443061, 'Total loss': 0.811436181443061}
2022-11-18 00:36:58,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:58,053 INFO:     Epoch: 61
2022-11-18 00:36:58,875 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8084808594801209, 'Total loss': 0.8084808594801209} | train loss {'Reaction outcome loss': 0.8159110573863211, 'Total loss': 0.8159110573863211}
2022-11-18 00:36:58,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:58,875 INFO:     Epoch: 62
2022-11-18 00:36:59,740 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8130581392483278, 'Total loss': 0.8130581392483278} | train loss {'Reaction outcome loss': 0.8163727149065689, 'Total loss': 0.8163727149065689}
2022-11-18 00:36:59,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:36:59,740 INFO:     Epoch: 63
2022-11-18 00:37:00,557 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8105345822193406, 'Total loss': 0.8105345822193406} | train loss {'Reaction outcome loss': 0.8119293261877438, 'Total loss': 0.8119293261877438}
2022-11-18 00:37:00,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:00,557 INFO:     Epoch: 64
2022-11-18 00:37:01,385 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8062119328162887, 'Total loss': 0.8062119328162887} | train loss {'Reaction outcome loss': 0.8150873055100923, 'Total loss': 0.8150873055100923}
2022-11-18 00:37:01,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:01,386 INFO:     Epoch: 65
2022-11-18 00:37:02,258 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8111391304568811, 'Total loss': 0.8111391304568811} | train loss {'Reaction outcome loss': 0.8179483531940321, 'Total loss': 0.8179483531940321}
2022-11-18 00:37:02,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:02,258 INFO:     Epoch: 66
2022-11-18 00:37:03,077 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8081356063485146, 'Total loss': 0.8081356063485146} | train loss {'Reaction outcome loss': 0.8108432320689383, 'Total loss': 0.8108432320689383}
2022-11-18 00:37:03,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:03,077 INFO:     Epoch: 67
2022-11-18 00:37:03,882 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.814255950125781, 'Total loss': 0.814255950125781} | train loss {'Reaction outcome loss': 0.8152483760375484, 'Total loss': 0.8152483760375484}
2022-11-18 00:37:03,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:03,882 INFO:     Epoch: 68
2022-11-18 00:37:04,679 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8258666450327093, 'Total loss': 0.8258666450327093} | train loss {'Reaction outcome loss': 0.8116520580492521, 'Total loss': 0.8116520580492521}
2022-11-18 00:37:04,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:04,679 INFO:     Epoch: 69
2022-11-18 00:37:05,496 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8232921764931895, 'Total loss': 0.8232921764931895} | train loss {'Reaction outcome loss': 0.8088379124187024, 'Total loss': 0.8088379124187024}
2022-11-18 00:37:05,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:05,496 INFO:     Epoch: 70
2022-11-18 00:37:06,297 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8138750818642703, 'Total loss': 0.8138750818642703} | train loss {'Reaction outcome loss': 0.8070032076857351, 'Total loss': 0.8070032076857351}
2022-11-18 00:37:06,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:06,297 INFO:     Epoch: 71
2022-11-18 00:37:07,108 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.831344951282848, 'Total loss': 0.831344951282848} | train loss {'Reaction outcome loss': 0.8112495174774756, 'Total loss': 0.8112495174774756}
2022-11-18 00:37:07,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:07,108 INFO:     Epoch: 72
2022-11-18 00:37:07,918 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8196821253408085, 'Total loss': 0.8196821253408085} | train loss {'Reaction outcome loss': 0.8183165452016993, 'Total loss': 0.8183165452016993}
2022-11-18 00:37:07,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:07,919 INFO:     Epoch: 73
2022-11-18 00:37:08,770 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8207138532941992, 'Total loss': 0.8207138532941992} | train loss {'Reaction outcome loss': 0.8150200450468642, 'Total loss': 0.8150200450468642}
2022-11-18 00:37:08,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:08,771 INFO:     Epoch: 74
2022-11-18 00:37:09,621 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7947317334738645, 'Total loss': 0.7947317334738645} | train loss {'Reaction outcome loss': 0.8167767575395252, 'Total loss': 0.8167767575395252}
2022-11-18 00:37:09,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:09,621 INFO:     Epoch: 75
2022-11-18 00:37:10,420 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8050818402658809, 'Total loss': 0.8050818402658809} | train loss {'Reaction outcome loss': 0.8202558946512971, 'Total loss': 0.8202558946512971}
2022-11-18 00:37:10,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:10,420 INFO:     Epoch: 76
2022-11-18 00:37:11,237 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8229280066761103, 'Total loss': 0.8229280066761103} | train loss {'Reaction outcome loss': 0.8136079245009403, 'Total loss': 0.8136079245009403}
2022-11-18 00:37:11,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:11,237 INFO:     Epoch: 77
2022-11-18 00:37:12,075 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8336981656876478, 'Total loss': 0.8336981656876478} | train loss {'Reaction outcome loss': 0.8089061009015149, 'Total loss': 0.8089061009015149}
2022-11-18 00:37:12,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:12,075 INFO:     Epoch: 78
2022-11-18 00:37:12,923 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8187618093057112, 'Total loss': 0.8187618093057112} | train loss {'Reaction outcome loss': 0.807272917707922, 'Total loss': 0.807272917707922}
2022-11-18 00:37:12,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:12,924 INFO:     Epoch: 79
2022-11-18 00:37:13,712 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8128052238713611, 'Total loss': 0.8128052238713611} | train loss {'Reaction outcome loss': 0.812189631375224, 'Total loss': 0.812189631375224}
2022-11-18 00:37:13,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:13,712 INFO:     Epoch: 80
2022-11-18 00:37:14,536 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8089965893463655, 'Total loss': 0.8089965893463655} | train loss {'Reaction outcome loss': 0.8175096217135669, 'Total loss': 0.8175096217135669}
2022-11-18 00:37:14,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:14,536 INFO:     Epoch: 81
2022-11-18 00:37:15,368 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8105744299563494, 'Total loss': 0.8105744299563494} | train loss {'Reaction outcome loss': 0.8095235992298435, 'Total loss': 0.8095235992298435}
2022-11-18 00:37:15,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:15,369 INFO:     Epoch: 82
2022-11-18 00:37:16,176 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8205653076822107, 'Total loss': 0.8205653076822107} | train loss {'Reaction outcome loss': 0.8082779108995368, 'Total loss': 0.8082779108995368}
2022-11-18 00:37:16,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:16,176 INFO:     Epoch: 83
2022-11-18 00:37:16,962 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8119817741892554, 'Total loss': 0.8119817741892554} | train loss {'Reaction outcome loss': 0.8116051374900679, 'Total loss': 0.8116051374900679}
2022-11-18 00:37:16,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:16,963 INFO:     Epoch: 84
2022-11-18 00:37:17,784 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8209477351470427, 'Total loss': 0.8209477351470427} | train loss {'Reaction outcome loss': 0.8080687717146237, 'Total loss': 0.8080687717146237}
2022-11-18 00:37:17,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:17,784 INFO:     Epoch: 85
2022-11-18 00:37:18,610 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.803909876129844, 'Total loss': 0.803909876129844} | train loss {'Reaction outcome loss': 0.8196167255702772, 'Total loss': 0.8196167255702772}
2022-11-18 00:37:18,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:18,610 INFO:     Epoch: 86
2022-11-18 00:37:19,428 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8095889836549759, 'Total loss': 0.8095889836549759} | train loss {'Reaction outcome loss': 0.8159203832207421, 'Total loss': 0.8159203832207421}
2022-11-18 00:37:19,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:19,429 INFO:     Epoch: 87
2022-11-18 00:37:20,265 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8070825467055495, 'Total loss': 0.8070825467055495} | train loss {'Reaction outcome loss': 0.8121495794670784, 'Total loss': 0.8121495794670784}
2022-11-18 00:37:20,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:20,265 INFO:     Epoch: 88
2022-11-18 00:37:21,095 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8049983260306445, 'Total loss': 0.8049983260306445} | train loss {'Reaction outcome loss': 0.8149288143766554, 'Total loss': 0.8149288143766554}
2022-11-18 00:37:21,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:21,095 INFO:     Epoch: 89
2022-11-18 00:37:21,898 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8264650357040492, 'Total loss': 0.8264650357040492} | train loss {'Reaction outcome loss': 0.808326442111359, 'Total loss': 0.808326442111359}
2022-11-18 00:37:21,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:21,898 INFO:     Epoch: 90
2022-11-18 00:37:22,689 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8146234838799997, 'Total loss': 0.8146234838799997} | train loss {'Reaction outcome loss': 0.8062727444085033, 'Total loss': 0.8062727444085033}
2022-11-18 00:37:22,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:22,689 INFO:     Epoch: 91
2022-11-18 00:37:23,514 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8057034422050823, 'Total loss': 0.8057034422050823} | train loss {'Reaction outcome loss': 0.8085044139792562, 'Total loss': 0.8085044139792562}
2022-11-18 00:37:23,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:23,514 INFO:     Epoch: 92
2022-11-18 00:37:24,359 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8156334859403697, 'Total loss': 0.8156334859403697} | train loss {'Reaction outcome loss': 0.8235191266063736, 'Total loss': 0.8235191266063736}
2022-11-18 00:37:24,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:24,359 INFO:     Epoch: 93
2022-11-18 00:37:25,164 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8414038148793307, 'Total loss': 0.8414038148793307} | train loss {'Reaction outcome loss': 0.8173097969308073, 'Total loss': 0.8173097969308073}
2022-11-18 00:37:25,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:25,164 INFO:     Epoch: 94
2022-11-18 00:37:25,983 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8236592032692649, 'Total loss': 0.8236592032692649} | train loss {'Reaction outcome loss': 0.8145912089328534, 'Total loss': 0.8145912089328534}
2022-11-18 00:37:25,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:25,983 INFO:     Epoch: 95
2022-11-18 00:37:26,799 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8248003775423224, 'Total loss': 0.8248003775423224} | train loss {'Reaction outcome loss': 0.8172968142187065, 'Total loss': 0.8172968142187065}
2022-11-18 00:37:26,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:26,799 INFO:     Epoch: 96
2022-11-18 00:37:27,594 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8074281554330479, 'Total loss': 0.8074281554330479} | train loss {'Reaction outcome loss': 0.8080208463526448, 'Total loss': 0.8080208463526448}
2022-11-18 00:37:27,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:27,595 INFO:     Epoch: 97
2022-11-18 00:37:28,365 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8036307448690588, 'Total loss': 0.8036307448690588} | train loss {'Reaction outcome loss': 0.8094720601552894, 'Total loss': 0.8094720601552894}
2022-11-18 00:37:28,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:28,366 INFO:     Epoch: 98
2022-11-18 00:37:29,144 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8082005591555075, 'Total loss': 0.8082005591555075} | train loss {'Reaction outcome loss': 0.8141818965977503, 'Total loss': 0.8141818965977503}
2022-11-18 00:37:29,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:29,144 INFO:     Epoch: 99
2022-11-18 00:37:29,937 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8057850111614574, 'Total loss': 0.8057850111614574} | train loss {'Reaction outcome loss': 0.8176088563585089, 'Total loss': 0.8176088563585089}
2022-11-18 00:37:29,937 INFO:     Best model found after epoch 42 of 100.
2022-11-18 00:37:29,937 INFO:   Done with stage: TRAINING
2022-11-18 00:37:29,937 INFO:   Starting stage: EVALUATION
2022-11-18 00:37:30,062 INFO:   Done with stage: EVALUATION
2022-11-18 00:37:30,062 INFO:   Leaving out SEQ value Fold_8
2022-11-18 00:37:30,075 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:37:30,076 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:37:30,757 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:37:30,757 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:37:30,829 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:37:30,829 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:37:30,830 INFO:     No hyperparam tuning for this model
2022-11-18 00:37:30,830 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:37:30,830 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:37:30,830 INFO:     None feature selector for col prot
2022-11-18 00:37:30,831 INFO:     None feature selector for col prot
2022-11-18 00:37:30,831 INFO:     None feature selector for col prot
2022-11-18 00:37:30,831 INFO:     None feature selector for col chem
2022-11-18 00:37:30,831 INFO:     None feature selector for col chem
2022-11-18 00:37:30,831 INFO:     None feature selector for col chem
2022-11-18 00:37:30,831 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:37:30,832 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:37:30,833 INFO:     Number of params in model 168571
2022-11-18 00:37:30,836 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:37:30,836 INFO:   Starting stage: TRAINING
2022-11-18 00:37:30,897 INFO:     Val loss before train {'Reaction outcome loss': 0.9881626584313132, 'Total loss': 0.9881626584313132}
2022-11-18 00:37:30,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:30,897 INFO:     Epoch: 0
2022-11-18 00:37:31,734 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8417669561776248, 'Total loss': 0.8417669561776248} | train loss {'Reaction outcome loss': 0.9012345342259658, 'Total loss': 0.9012345342259658}
2022-11-18 00:37:31,734 INFO:     Found new best model at epoch 0
2022-11-18 00:37:31,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:31,735 INFO:     Epoch: 1
2022-11-18 00:37:32,548 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8124495297670364, 'Total loss': 0.8124495297670364} | train loss {'Reaction outcome loss': 0.8619466730457569, 'Total loss': 0.8619466730457569}
2022-11-18 00:37:32,548 INFO:     Found new best model at epoch 1
2022-11-18 00:37:32,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:32,549 INFO:     Epoch: 2
2022-11-18 00:37:33,314 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8129096417264505, 'Total loss': 0.8129096417264505} | train loss {'Reaction outcome loss': 0.8537021359873687, 'Total loss': 0.8537021359873687}
2022-11-18 00:37:33,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:33,315 INFO:     Epoch: 3
2022-11-18 00:37:34,111 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.80553764578971, 'Total loss': 0.80553764578971} | train loss {'Reaction outcome loss': 0.8578093575562543, 'Total loss': 0.8578093575562543}
2022-11-18 00:37:34,111 INFO:     Found new best model at epoch 3
2022-11-18 00:37:34,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:34,112 INFO:     Epoch: 4
2022-11-18 00:37:34,901 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8010754124684767, 'Total loss': 0.8010754124684767} | train loss {'Reaction outcome loss': 0.8498563470869411, 'Total loss': 0.8498563470869411}
2022-11-18 00:37:34,901 INFO:     Found new best model at epoch 4
2022-11-18 00:37:34,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:34,902 INFO:     Epoch: 5
2022-11-18 00:37:35,679 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7962004799734462, 'Total loss': 0.7962004799734462} | train loss {'Reaction outcome loss': 0.8451268221685279, 'Total loss': 0.8451268221685279}
2022-11-18 00:37:35,679 INFO:     Found new best model at epoch 5
2022-11-18 00:37:35,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:35,680 INFO:     Epoch: 6
2022-11-18 00:37:36,474 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7958690666339614, 'Total loss': 0.7958690666339614} | train loss {'Reaction outcome loss': 0.839104375496567, 'Total loss': 0.839104375496567}
2022-11-18 00:37:36,474 INFO:     Found new best model at epoch 6
2022-11-18 00:37:36,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:36,475 INFO:     Epoch: 7
2022-11-18 00:37:37,231 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8170005814595656, 'Total loss': 0.8170005814595656} | train loss {'Reaction outcome loss': 0.8379786495979016, 'Total loss': 0.8379786495979016}
2022-11-18 00:37:37,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:37,231 INFO:     Epoch: 8
2022-11-18 00:37:38,018 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8028048615564, 'Total loss': 0.8028048615564} | train loss {'Reaction outcome loss': 0.8443544270538608, 'Total loss': 0.8443544270538608}
2022-11-18 00:37:38,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:38,018 INFO:     Epoch: 9
2022-11-18 00:37:38,825 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.794564272869717, 'Total loss': 0.794564272869717} | train loss {'Reaction outcome loss': 0.8361092544187178, 'Total loss': 0.8361092544187178}
2022-11-18 00:37:38,825 INFO:     Found new best model at epoch 9
2022-11-18 00:37:38,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:38,826 INFO:     Epoch: 10
2022-11-18 00:37:39,598 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8045079450715672, 'Total loss': 0.8045079450715672} | train loss {'Reaction outcome loss': 0.8340878168098357, 'Total loss': 0.8340878168098357}
2022-11-18 00:37:39,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:39,600 INFO:     Epoch: 11
2022-11-18 00:37:40,366 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8249056352810427, 'Total loss': 0.8249056352810427} | train loss {'Reaction outcome loss': 0.8336761412229615, 'Total loss': 0.8336761412229615}
2022-11-18 00:37:40,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:40,366 INFO:     Epoch: 12
2022-11-18 00:37:41,146 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8045169995589689, 'Total loss': 0.8045169995589689} | train loss {'Reaction outcome loss': 0.8338455340640265, 'Total loss': 0.8338455340640265}
2022-11-18 00:37:41,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:41,146 INFO:     Epoch: 13
2022-11-18 00:37:41,930 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8108653805472634, 'Total loss': 0.8108653805472634} | train loss {'Reaction outcome loss': 0.8371290215837811, 'Total loss': 0.8371290215837811}
2022-11-18 00:37:41,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:41,930 INFO:     Epoch: 14
2022-11-18 00:37:42,703 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.806442840532823, 'Total loss': 0.806442840532823} | train loss {'Reaction outcome loss': 0.8371849911898254, 'Total loss': 0.8371849911898254}
2022-11-18 00:37:42,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:42,704 INFO:     Epoch: 15
2022-11-18 00:37:43,487 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.822831002148715, 'Total loss': 0.822831002148715} | train loss {'Reaction outcome loss': 0.8365053051879049, 'Total loss': 0.8365053051879049}
2022-11-18 00:37:43,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:43,487 INFO:     Epoch: 16
2022-11-18 00:37:44,285 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.799081954089078, 'Total loss': 0.799081954089078} | train loss {'Reaction outcome loss': 0.8333325763704323, 'Total loss': 0.8333325763704323}
2022-11-18 00:37:44,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:44,285 INFO:     Epoch: 17
2022-11-18 00:37:45,060 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7917836315252564, 'Total loss': 0.7917836315252564} | train loss {'Reaction outcome loss': 0.8332468565659001, 'Total loss': 0.8332468565659001}
2022-11-18 00:37:45,060 INFO:     Found new best model at epoch 17
2022-11-18 00:37:45,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:45,061 INFO:     Epoch: 18
2022-11-18 00:37:45,845 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7964313531463797, 'Total loss': 0.7964313531463797} | train loss {'Reaction outcome loss': 0.8324922948231098, 'Total loss': 0.8324922948231098}
2022-11-18 00:37:45,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:45,846 INFO:     Epoch: 19
2022-11-18 00:37:46,662 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.792147271335125, 'Total loss': 0.792147271335125} | train loss {'Reaction outcome loss': 0.833042981955204, 'Total loss': 0.833042981955204}
2022-11-18 00:37:46,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:46,662 INFO:     Epoch: 20
2022-11-18 00:37:47,432 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7987221614880995, 'Total loss': 0.7987221614880995} | train loss {'Reaction outcome loss': 0.8364438972009821, 'Total loss': 0.8364438972009821}
2022-11-18 00:37:47,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:47,433 INFO:     Epoch: 21
2022-11-18 00:37:48,241 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7953660372983326, 'Total loss': 0.7953660372983326} | train loss {'Reaction outcome loss': 0.8318628714634821, 'Total loss': 0.8318628714634821}
2022-11-18 00:37:48,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:48,241 INFO:     Epoch: 22
2022-11-18 00:37:49,018 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7945014292543585, 'Total loss': 0.7945014292543585} | train loss {'Reaction outcome loss': 0.83296229512344, 'Total loss': 0.83296229512344}
2022-11-18 00:37:49,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:49,019 INFO:     Epoch: 23
2022-11-18 00:37:49,823 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8068705052137375, 'Total loss': 0.8068705052137375} | train loss {'Reaction outcome loss': 0.8355623757549626, 'Total loss': 0.8355623757549626}
2022-11-18 00:37:49,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:49,823 INFO:     Epoch: 24
2022-11-18 00:37:50,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.798016527836973, 'Total loss': 0.798016527836973} | train loss {'Reaction outcome loss': 0.8279996985637466, 'Total loss': 0.8279996985637466}
2022-11-18 00:37:50,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:50,607 INFO:     Epoch: 25
2022-11-18 00:37:51,397 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7948804138736292, 'Total loss': 0.7948804138736292} | train loss {'Reaction outcome loss': 0.8343204723195992, 'Total loss': 0.8343204723195992}
2022-11-18 00:37:51,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:51,398 INFO:     Epoch: 26
2022-11-18 00:37:52,165 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7927152399312366, 'Total loss': 0.7927152399312366} | train loss {'Reaction outcome loss': 0.8341227149673802, 'Total loss': 0.8341227149673802}
2022-11-18 00:37:52,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:52,165 INFO:     Epoch: 27
2022-11-18 00:37:52,970 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8003435399044644, 'Total loss': 0.8003435399044644} | train loss {'Reaction outcome loss': 0.8342688505948797, 'Total loss': 0.8342688505948797}
2022-11-18 00:37:52,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:52,971 INFO:     Epoch: 28
2022-11-18 00:37:53,745 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.811037308790467, 'Total loss': 0.811037308790467} | train loss {'Reaction outcome loss': 0.8307694476625698, 'Total loss': 0.8307694476625698}
2022-11-18 00:37:53,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:53,745 INFO:     Epoch: 29
2022-11-18 00:37:54,534 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7827291867949746, 'Total loss': 0.7827291867949746} | train loss {'Reaction outcome loss': 0.834667123823996, 'Total loss': 0.834667123823996}
2022-11-18 00:37:54,534 INFO:     Found new best model at epoch 29
2022-11-18 00:37:54,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:54,535 INFO:     Epoch: 30
2022-11-18 00:37:55,323 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.793882739814845, 'Total loss': 0.793882739814845} | train loss {'Reaction outcome loss': 0.8286762168774238, 'Total loss': 0.8286762168774238}
2022-11-18 00:37:55,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:55,324 INFO:     Epoch: 31
2022-11-18 00:37:56,086 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7901126051490958, 'Total loss': 0.7901126051490958} | train loss {'Reaction outcome loss': 0.8230331715060631, 'Total loss': 0.8230331715060631}
2022-11-18 00:37:56,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:56,086 INFO:     Epoch: 32
2022-11-18 00:37:56,856 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7971030568534677, 'Total loss': 0.7971030568534677} | train loss {'Reaction outcome loss': 0.8322555571191224, 'Total loss': 0.8322555571191224}
2022-11-18 00:37:56,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:56,857 INFO:     Epoch: 33
2022-11-18 00:37:57,607 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7869614836844531, 'Total loss': 0.7869614836844531} | train loss {'Reaction outcome loss': 0.8243680048266403, 'Total loss': 0.8243680048266403}
2022-11-18 00:37:57,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:57,608 INFO:     Epoch: 34
2022-11-18 00:37:58,393 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8245344189080325, 'Total loss': 0.8245344189080325} | train loss {'Reaction outcome loss': 0.828529670291584, 'Total loss': 0.828529670291584}
2022-11-18 00:37:58,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:58,394 INFO:     Epoch: 35
2022-11-18 00:37:59,168 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7927104153416373, 'Total loss': 0.7927104153416373} | train loss {'Reaction outcome loss': 0.8308011589021336, 'Total loss': 0.8308011589021336}
2022-11-18 00:37:59,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:59,169 INFO:     Epoch: 36
2022-11-18 00:37:59,934 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7895556539297104, 'Total loss': 0.7895556539297104} | train loss {'Reaction outcome loss': 0.8301018489758495, 'Total loss': 0.8301018489758495}
2022-11-18 00:37:59,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:37:59,935 INFO:     Epoch: 37
2022-11-18 00:38:00,704 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8052414567633108, 'Total loss': 0.8052414567633108} | train loss {'Reaction outcome loss': 0.8283165339757557, 'Total loss': 0.8283165339757557}
2022-11-18 00:38:00,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:00,704 INFO:     Epoch: 38
2022-11-18 00:38:01,499 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.790030566806143, 'Total loss': 0.790030566806143} | train loss {'Reaction outcome loss': 0.8255732471221372, 'Total loss': 0.8255732471221372}
2022-11-18 00:38:01,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:01,500 INFO:     Epoch: 39
2022-11-18 00:38:02,322 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8184825764460997, 'Total loss': 0.8184825764460997} | train loss {'Reaction outcome loss': 0.8242006975146923, 'Total loss': 0.8242006975146923}
2022-11-18 00:38:02,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:02,322 INFO:     Epoch: 40
2022-11-18 00:38:03,110 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.798997278240594, 'Total loss': 0.798997278240594} | train loss {'Reaction outcome loss': 0.8251640898013405, 'Total loss': 0.8251640898013405}
2022-11-18 00:38:03,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:03,110 INFO:     Epoch: 41
2022-11-18 00:38:03,923 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7949429838494821, 'Total loss': 0.7949429838494821} | train loss {'Reaction outcome loss': 0.8274950416464555, 'Total loss': 0.8274950416464555}
2022-11-18 00:38:03,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:03,923 INFO:     Epoch: 42
2022-11-18 00:38:04,708 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8245573484084823, 'Total loss': 0.8245573484084823} | train loss {'Reaction outcome loss': 0.8288514921781023, 'Total loss': 0.8288514921781023}
2022-11-18 00:38:04,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:04,708 INFO:     Epoch: 43
2022-11-18 00:38:05,484 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7850782424211502, 'Total loss': 0.7850782424211502} | train loss {'Reaction outcome loss': 0.8230082089843055, 'Total loss': 0.8230082089843055}
2022-11-18 00:38:05,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:05,484 INFO:     Epoch: 44
2022-11-18 00:38:06,255 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7891041954809969, 'Total loss': 0.7891041954809969} | train loss {'Reaction outcome loss': 0.8225784993726715, 'Total loss': 0.8225784993726715}
2022-11-18 00:38:06,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:06,255 INFO:     Epoch: 45
2022-11-18 00:38:07,065 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7881992168047212, 'Total loss': 0.7881992168047212} | train loss {'Reaction outcome loss': 0.8235435286755504, 'Total loss': 0.8235435286755504}
2022-11-18 00:38:07,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:07,065 INFO:     Epoch: 46
2022-11-18 00:38:07,847 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7936486527323723, 'Total loss': 0.7936486527323723} | train loss {'Reaction outcome loss': 0.8207624875582181, 'Total loss': 0.8207624875582181}
2022-11-18 00:38:07,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:07,847 INFO:     Epoch: 47
2022-11-18 00:38:08,638 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7865239185365763, 'Total loss': 0.7865239185365763} | train loss {'Reaction outcome loss': 0.8198737834508603, 'Total loss': 0.8198737834508603}
2022-11-18 00:38:08,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:08,638 INFO:     Epoch: 48
2022-11-18 00:38:09,427 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7733643332665617, 'Total loss': 0.7733643332665617} | train loss {'Reaction outcome loss': 0.8163422505382584, 'Total loss': 0.8163422505382584}
2022-11-18 00:38:09,427 INFO:     Found new best model at epoch 48
2022-11-18 00:38:09,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:09,428 INFO:     Epoch: 49
2022-11-18 00:38:10,216 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8229402405294505, 'Total loss': 0.8229402405294505} | train loss {'Reaction outcome loss': 0.8251056089574992, 'Total loss': 0.8251056089574992}
2022-11-18 00:38:10,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:10,217 INFO:     Epoch: 50
2022-11-18 00:38:10,995 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7868233973329718, 'Total loss': 0.7868233973329718} | train loss {'Reaction outcome loss': 0.8232727019410384, 'Total loss': 0.8232727019410384}
2022-11-18 00:38:10,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:10,995 INFO:     Epoch: 51
2022-11-18 00:38:11,745 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7849255597049539, 'Total loss': 0.7849255597049539} | train loss {'Reaction outcome loss': 0.8189647618213646, 'Total loss': 0.8189647618213646}
2022-11-18 00:38:11,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:11,745 INFO:     Epoch: 52
2022-11-18 00:38:12,522 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.792889376255599, 'Total loss': 0.792889376255599} | train loss {'Reaction outcome loss': 0.8195381539794597, 'Total loss': 0.8195381539794597}
2022-11-18 00:38:12,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:12,522 INFO:     Epoch: 53
2022-11-18 00:38:13,282 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7920336398211393, 'Total loss': 0.7920336398211393} | train loss {'Reaction outcome loss': 0.8171063310462936, 'Total loss': 0.8171063310462936}
2022-11-18 00:38:13,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:13,282 INFO:     Epoch: 54
2022-11-18 00:38:14,059 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7823825038292191, 'Total loss': 0.7823825038292191} | train loss {'Reaction outcome loss': 0.819898493618135, 'Total loss': 0.819898493618135}
2022-11-18 00:38:14,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:14,060 INFO:     Epoch: 55
2022-11-18 00:38:14,829 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7830296091058038, 'Total loss': 0.7830296091058038} | train loss {'Reaction outcome loss': 0.8428872152861313, 'Total loss': 0.8428872152861313}
2022-11-18 00:38:14,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:14,829 INFO:     Epoch: 56
2022-11-18 00:38:15,619 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8428646021268584, 'Total loss': 0.8428646021268584} | train loss {'Reaction outcome loss': 0.8125652858783842, 'Total loss': 0.8125652858783842}
2022-11-18 00:38:15,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:15,619 INFO:     Epoch: 57
2022-11-18 00:38:16,397 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7732445164160295, 'Total loss': 0.7732445164160295} | train loss {'Reaction outcome loss': 0.8179093773065791, 'Total loss': 0.8179093773065791}
2022-11-18 00:38:16,398 INFO:     Found new best model at epoch 57
2022-11-18 00:38:16,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:16,398 INFO:     Epoch: 58
2022-11-18 00:38:17,164 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7857952449809421, 'Total loss': 0.7857952449809421} | train loss {'Reaction outcome loss': 0.8217113283481675, 'Total loss': 0.8217113283481675}
2022-11-18 00:38:17,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:17,165 INFO:     Epoch: 59
2022-11-18 00:38:17,943 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7852439785545523, 'Total loss': 0.7852439785545523} | train loss {'Reaction outcome loss': 0.8162988265938604, 'Total loss': 0.8162988265938604}
2022-11-18 00:38:17,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:17,943 INFO:     Epoch: 60
2022-11-18 00:38:18,735 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8006973659450357, 'Total loss': 0.8006973659450357} | train loss {'Reaction outcome loss': 0.8162481782407414, 'Total loss': 0.8162481782407414}
2022-11-18 00:38:18,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:18,735 INFO:     Epoch: 61
2022-11-18 00:38:19,509 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.788591052998196, 'Total loss': 0.788591052998196} | train loss {'Reaction outcome loss': 0.8139435569284416, 'Total loss': 0.8139435569284416}
2022-11-18 00:38:19,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:19,510 INFO:     Epoch: 62
2022-11-18 00:38:20,307 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7822385850277814, 'Total loss': 0.7822385850277814} | train loss {'Reaction outcome loss': 0.8161467351170204, 'Total loss': 0.8161467351170204}
2022-11-18 00:38:20,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:20,307 INFO:     Epoch: 63
2022-11-18 00:38:21,119 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7912765030156482, 'Total loss': 0.7912765030156482} | train loss {'Reaction outcome loss': 0.813732181000806, 'Total loss': 0.813732181000806}
2022-11-18 00:38:21,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:21,119 INFO:     Epoch: 64
2022-11-18 00:38:21,940 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.767863700335676, 'Total loss': 0.767863700335676} | train loss {'Reaction outcome loss': 0.8140106524533106, 'Total loss': 0.8140106524533106}
2022-11-18 00:38:21,940 INFO:     Found new best model at epoch 64
2022-11-18 00:38:21,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:21,941 INFO:     Epoch: 65
2022-11-18 00:38:22,738 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7855940088629723, 'Total loss': 0.7855940088629723} | train loss {'Reaction outcome loss': 0.8089650938747383, 'Total loss': 0.8089650938747383}
2022-11-18 00:38:22,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:22,739 INFO:     Epoch: 66
2022-11-18 00:38:23,570 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7954625331542708, 'Total loss': 0.7954625331542708} | train loss {'Reaction outcome loss': 0.8119783443115983, 'Total loss': 0.8119783443115983}
2022-11-18 00:38:23,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:23,570 INFO:     Epoch: 67
2022-11-18 00:38:24,382 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7771524692123587, 'Total loss': 0.7771524692123587} | train loss {'Reaction outcome loss': 0.808746028163655, 'Total loss': 0.808746028163655}
2022-11-18 00:38:24,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:24,382 INFO:     Epoch: 68
2022-11-18 00:38:25,190 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7795692316510461, 'Total loss': 0.7795692316510461} | train loss {'Reaction outcome loss': 0.8072719744704513, 'Total loss': 0.8072719744704513}
2022-11-18 00:38:25,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:25,190 INFO:     Epoch: 69
2022-11-18 00:38:26,022 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7586904608390548, 'Total loss': 0.7586904608390548} | train loss {'Reaction outcome loss': 0.8073571007020077, 'Total loss': 0.8073571007020077}
2022-11-18 00:38:26,022 INFO:     Found new best model at epoch 69
2022-11-18 00:38:26,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:26,023 INFO:     Epoch: 70
2022-11-18 00:38:26,822 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8089088811115785, 'Total loss': 0.8089088811115785} | train loss {'Reaction outcome loss': 0.8115999710704633, 'Total loss': 0.8115999710704633}
2022-11-18 00:38:26,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:26,822 INFO:     Epoch: 71
2022-11-18 00:38:27,646 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7667876739393581, 'Total loss': 0.7667876739393581} | train loss {'Reaction outcome loss': 0.8122723170590063, 'Total loss': 0.8122723170590063}
2022-11-18 00:38:27,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:27,646 INFO:     Epoch: 72
2022-11-18 00:38:28,466 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7747968970374628, 'Total loss': 0.7747968970374628} | train loss {'Reaction outcome loss': 0.8128487309704908, 'Total loss': 0.8128487309704908}
2022-11-18 00:38:28,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:28,467 INFO:     Epoch: 73
2022-11-18 00:38:29,255 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7538654641671614, 'Total loss': 0.7538654641671614} | train loss {'Reaction outcome loss': 0.8034468843386724, 'Total loss': 0.8034468843386724}
2022-11-18 00:38:29,255 INFO:     Found new best model at epoch 73
2022-11-18 00:38:29,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:29,256 INFO:     Epoch: 74
2022-11-18 00:38:30,035 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7909547849134966, 'Total loss': 0.7909547849134966} | train loss {'Reaction outcome loss': 0.8095042419578382, 'Total loss': 0.8095042419578382}
2022-11-18 00:38:30,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:30,035 INFO:     Epoch: 75
2022-11-18 00:38:30,856 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7688985846259377, 'Total loss': 0.7688985846259377} | train loss {'Reaction outcome loss': 0.8101925804064825, 'Total loss': 0.8101925804064825}
2022-11-18 00:38:30,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:30,857 INFO:     Epoch: 76
2022-11-18 00:38:31,679 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.79835579815236, 'Total loss': 0.79835579815236} | train loss {'Reaction outcome loss': 0.8089627770759799, 'Total loss': 0.8089627770759799}
2022-11-18 00:38:31,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:31,679 INFO:     Epoch: 77
2022-11-18 00:38:32,493 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7842696911909364, 'Total loss': 0.7842696911909364} | train loss {'Reaction outcome loss': 0.7981949957457148, 'Total loss': 0.7981949957457148}
2022-11-18 00:38:32,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:32,493 INFO:     Epoch: 78
2022-11-18 00:38:33,325 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.770758100531318, 'Total loss': 0.770758100531318} | train loss {'Reaction outcome loss': 0.7932923963436713, 'Total loss': 0.7932923963436713}
2022-11-18 00:38:33,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:33,326 INFO:     Epoch: 79
2022-11-18 00:38:34,130 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7684764516624537, 'Total loss': 0.7684764516624537} | train loss {'Reaction outcome loss': 0.7906560710808526, 'Total loss': 0.7906560710808526}
2022-11-18 00:38:34,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:34,130 INFO:     Epoch: 80
2022-11-18 00:38:34,937 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7622536610473286, 'Total loss': 0.7622536610473286} | train loss {'Reaction outcome loss': 0.7869024720751805, 'Total loss': 0.7869024720751805}
2022-11-18 00:38:34,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:34,937 INFO:     Epoch: 81
2022-11-18 00:38:35,771 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7654596567153931, 'Total loss': 0.7654596567153931} | train loss {'Reaction outcome loss': 0.7933834318207343, 'Total loss': 0.7933834318207343}
2022-11-18 00:38:35,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:35,771 INFO:     Epoch: 82
2022-11-18 00:38:36,552 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.748977820304307, 'Total loss': 0.748977820304307} | train loss {'Reaction outcome loss': 0.792610695125603, 'Total loss': 0.792610695125603}
2022-11-18 00:38:36,552 INFO:     Found new best model at epoch 82
2022-11-18 00:38:36,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:36,553 INFO:     Epoch: 83
2022-11-18 00:38:37,370 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7451559508388693, 'Total loss': 0.7451559508388693} | train loss {'Reaction outcome loss': 0.7816423011212214, 'Total loss': 0.7816423011212214}
2022-11-18 00:38:37,370 INFO:     Found new best model at epoch 83
2022-11-18 00:38:37,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:37,371 INFO:     Epoch: 84
2022-11-18 00:38:38,147 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7382114455103874, 'Total loss': 0.7382114455103874} | train loss {'Reaction outcome loss': 0.7805006419598814, 'Total loss': 0.7805006419598814}
2022-11-18 00:38:38,147 INFO:     Found new best model at epoch 84
2022-11-18 00:38:38,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:38,148 INFO:     Epoch: 85
2022-11-18 00:38:38,944 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7936219769445333, 'Total loss': 0.7936219769445333} | train loss {'Reaction outcome loss': 0.7796548163359948, 'Total loss': 0.7796548163359948}
2022-11-18 00:38:38,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:38,944 INFO:     Epoch: 86
2022-11-18 00:38:39,725 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7733425626700575, 'Total loss': 0.7733425626700575} | train loss {'Reaction outcome loss': 0.7944325959151574, 'Total loss': 0.7944325959151574}
2022-11-18 00:38:39,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:39,725 INFO:     Epoch: 87
2022-11-18 00:38:40,502 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7286321622404185, 'Total loss': 0.7286321622404185} | train loss {'Reaction outcome loss': 0.7573553963228759, 'Total loss': 0.7573553963228759}
2022-11-18 00:38:40,502 INFO:     Found new best model at epoch 87
2022-11-18 00:38:40,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:40,503 INFO:     Epoch: 88
2022-11-18 00:38:41,293 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.72587781467221, 'Total loss': 0.72587781467221} | train loss {'Reaction outcome loss': 0.7613910021569564, 'Total loss': 0.7613910021569564}
2022-11-18 00:38:41,294 INFO:     Found new best model at epoch 88
2022-11-18 00:38:41,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:41,295 INFO:     Epoch: 89
2022-11-18 00:38:42,056 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8281991237943823, 'Total loss': 0.8281991237943823} | train loss {'Reaction outcome loss': 0.7639968679984089, 'Total loss': 0.7639968679984089}
2022-11-18 00:38:42,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:42,058 INFO:     Epoch: 90
2022-11-18 00:38:42,862 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7750098569826647, 'Total loss': 0.7750098569826647} | train loss {'Reaction outcome loss': 0.7476881658017394, 'Total loss': 0.7476881658017394}
2022-11-18 00:38:42,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:42,863 INFO:     Epoch: 91
2022-11-18 00:38:43,664 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.793298527598381, 'Total loss': 0.793298527598381} | train loss {'Reaction outcome loss': 0.7348976322272529, 'Total loss': 0.7348976322272529}
2022-11-18 00:38:43,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:43,665 INFO:     Epoch: 92
2022-11-18 00:38:44,465 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7602659355510365, 'Total loss': 0.7602659355510365} | train loss {'Reaction outcome loss': 0.7272944832560022, 'Total loss': 0.7272944832560022}
2022-11-18 00:38:44,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:44,465 INFO:     Epoch: 93
2022-11-18 00:38:45,233 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7558359652757645, 'Total loss': 0.7558359652757645} | train loss {'Reaction outcome loss': 0.7153845268946427, 'Total loss': 0.7153845268946427}
2022-11-18 00:38:45,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:45,233 INFO:     Epoch: 94
2022-11-18 00:38:46,033 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6700126454234123, 'Total loss': 0.6700126454234123} | train loss {'Reaction outcome loss': 0.6966622371663932, 'Total loss': 0.6966622371663932}
2022-11-18 00:38:46,033 INFO:     Found new best model at epoch 94
2022-11-18 00:38:46,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:46,034 INFO:     Epoch: 95
2022-11-18 00:38:46,849 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6966990002176978, 'Total loss': 0.6966990002176978} | train loss {'Reaction outcome loss': 0.6901047387827746, 'Total loss': 0.6901047387827746}
2022-11-18 00:38:46,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:46,850 INFO:     Epoch: 96
2022-11-18 00:38:47,627 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8431059061126276, 'Total loss': 0.8431059061126276} | train loss {'Reaction outcome loss': 0.7116213322651048, 'Total loss': 0.7116213322651048}
2022-11-18 00:38:47,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:47,627 INFO:     Epoch: 97
2022-11-18 00:38:48,424 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6491697911511768, 'Total loss': 0.6491697911511768} | train loss {'Reaction outcome loss': 0.6921684510312099, 'Total loss': 0.6921684510312099}
2022-11-18 00:38:48,425 INFO:     Found new best model at epoch 97
2022-11-18 00:38:48,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:48,426 INFO:     Epoch: 98
2022-11-18 00:38:49,204 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6398657621307806, 'Total loss': 0.6398657621307806} | train loss {'Reaction outcome loss': 0.6615064537778557, 'Total loss': 0.6615064537778557}
2022-11-18 00:38:49,204 INFO:     Found new best model at epoch 98
2022-11-18 00:38:49,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:49,205 INFO:     Epoch: 99
2022-11-18 00:38:49,988 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7095158140767704, 'Total loss': 0.7095158140767704} | train loss {'Reaction outcome loss': 0.6409939091939193, 'Total loss': 0.6409939091939193}
2022-11-18 00:38:49,988 INFO:     Best model found after epoch 99 of 100.
2022-11-18 00:38:49,988 INFO:   Done with stage: TRAINING
2022-11-18 00:38:49,988 INFO:   Starting stage: EVALUATION
2022-11-18 00:38:50,112 INFO:   Done with stage: EVALUATION
2022-11-18 00:38:50,112 INFO:   Leaving out SEQ value Fold_9
2022-11-18 00:38:50,125 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:38:50,125 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:38:50,803 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:38:50,803 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:38:50,874 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:38:50,874 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:38:50,874 INFO:     No hyperparam tuning for this model
2022-11-18 00:38:50,874 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:38:50,874 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:38:50,875 INFO:     None feature selector for col prot
2022-11-18 00:38:50,875 INFO:     None feature selector for col prot
2022-11-18 00:38:50,875 INFO:     None feature selector for col prot
2022-11-18 00:38:50,876 INFO:     None feature selector for col chem
2022-11-18 00:38:50,876 INFO:     None feature selector for col chem
2022-11-18 00:38:50,876 INFO:     None feature selector for col chem
2022-11-18 00:38:50,876 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:38:50,876 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:38:50,878 INFO:     Number of params in model 168571
2022-11-18 00:38:50,881 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:38:50,881 INFO:   Starting stage: TRAINING
2022-11-18 00:38:50,939 INFO:     Val loss before train {'Reaction outcome loss': 1.030371224338358, 'Total loss': 1.030371224338358}
2022-11-18 00:38:50,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:50,939 INFO:     Epoch: 0
2022-11-18 00:38:51,750 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8656545342369513, 'Total loss': 0.8656545342369513} | train loss {'Reaction outcome loss': 0.863707938295627, 'Total loss': 0.863707938295627}
2022-11-18 00:38:51,750 INFO:     Found new best model at epoch 0
2022-11-18 00:38:51,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:51,751 INFO:     Epoch: 1
2022-11-18 00:38:52,533 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8545816405252977, 'Total loss': 0.8545816405252977} | train loss {'Reaction outcome loss': 0.8449583666527319, 'Total loss': 0.8449583666527319}
2022-11-18 00:38:52,533 INFO:     Found new best model at epoch 1
2022-11-18 00:38:52,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:52,534 INFO:     Epoch: 2
2022-11-18 00:38:53,308 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.846591626378623, 'Total loss': 0.846591626378623} | train loss {'Reaction outcome loss': 0.8339128014047136, 'Total loss': 0.8339128014047136}
2022-11-18 00:38:53,308 INFO:     Found new best model at epoch 2
2022-11-18 00:38:53,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:53,309 INFO:     Epoch: 3
2022-11-18 00:38:54,075 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8457820164886388, 'Total loss': 0.8457820164886388} | train loss {'Reaction outcome loss': 0.83800752997881, 'Total loss': 0.83800752997881}
2022-11-18 00:38:54,075 INFO:     Found new best model at epoch 3
2022-11-18 00:38:54,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:54,076 INFO:     Epoch: 4
2022-11-18 00:38:54,855 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8462227081710642, 'Total loss': 0.8462227081710642} | train loss {'Reaction outcome loss': 0.8232698109951097, 'Total loss': 0.8232698109951097}
2022-11-18 00:38:54,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:54,855 INFO:     Epoch: 5
2022-11-18 00:38:55,658 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8752327927134254, 'Total loss': 0.8752327927134254} | train loss {'Reaction outcome loss': 0.8237600903279385, 'Total loss': 0.8237600903279385}
2022-11-18 00:38:55,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:55,658 INFO:     Epoch: 6
2022-11-18 00:38:56,476 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8448176593943075, 'Total loss': 0.8448176593943075} | train loss {'Reaction outcome loss': 0.824976343887779, 'Total loss': 0.824976343887779}
2022-11-18 00:38:56,476 INFO:     Found new best model at epoch 6
2022-11-18 00:38:56,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:56,477 INFO:     Epoch: 7
2022-11-18 00:38:57,223 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8546703735535796, 'Total loss': 0.8546703735535796} | train loss {'Reaction outcome loss': 0.8220444129787476, 'Total loss': 0.8220444129787476}
2022-11-18 00:38:57,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:57,223 INFO:     Epoch: 8
2022-11-18 00:38:58,009 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8580796691504392, 'Total loss': 0.8580796691504392} | train loss {'Reaction outcome loss': 0.8170436306551159, 'Total loss': 0.8170436306551159}
2022-11-18 00:38:58,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:58,009 INFO:     Epoch: 9
2022-11-18 00:38:58,775 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.837977410717444, 'Total loss': 0.837977410717444} | train loss {'Reaction outcome loss': 0.8122306621750357, 'Total loss': 0.8122306621750357}
2022-11-18 00:38:58,776 INFO:     Found new best model at epoch 9
2022-11-18 00:38:58,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:58,776 INFO:     Epoch: 10
2022-11-18 00:38:59,564 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8537326753139496, 'Total loss': 0.8537326753139496} | train loss {'Reaction outcome loss': 0.8151076174216715, 'Total loss': 0.8151076174216715}
2022-11-18 00:38:59,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:38:59,565 INFO:     Epoch: 11
2022-11-18 00:39:00,353 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8450582494789903, 'Total loss': 0.8450582494789903} | train loss {'Reaction outcome loss': 0.8233754690359478, 'Total loss': 0.8233754690359478}
2022-11-18 00:39:00,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:00,353 INFO:     Epoch: 12
2022-11-18 00:39:01,143 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8571981841867621, 'Total loss': 0.8571981841867621} | train loss {'Reaction outcome loss': 0.8209137308452776, 'Total loss': 0.8209137308452776}
2022-11-18 00:39:01,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:01,144 INFO:     Epoch: 13
2022-11-18 00:39:01,929 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8430035669695247, 'Total loss': 0.8430035669695247} | train loss {'Reaction outcome loss': 0.8164972947676655, 'Total loss': 0.8164972947676655}
2022-11-18 00:39:01,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:01,930 INFO:     Epoch: 14
2022-11-18 00:39:02,719 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.837862435050986, 'Total loss': 0.837862435050986} | train loss {'Reaction outcome loss': 0.8082190473160522, 'Total loss': 0.8082190473160522}
2022-11-18 00:39:02,719 INFO:     Found new best model at epoch 14
2022-11-18 00:39:02,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:02,720 INFO:     Epoch: 15
2022-11-18 00:39:03,507 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8356706005605784, 'Total loss': 0.8356706005605784} | train loss {'Reaction outcome loss': 0.813811353946987, 'Total loss': 0.813811353946987}
2022-11-18 00:39:03,507 INFO:     Found new best model at epoch 15
2022-11-18 00:39:03,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:03,508 INFO:     Epoch: 16
2022-11-18 00:39:04,298 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8491744520989332, 'Total loss': 0.8491744520989332} | train loss {'Reaction outcome loss': 0.8151037118997169, 'Total loss': 0.8151037118997169}
2022-11-18 00:39:04,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:04,298 INFO:     Epoch: 17
2022-11-18 00:39:05,114 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8457477268847552, 'Total loss': 0.8457477268847552} | train loss {'Reaction outcome loss': 0.8100944784006127, 'Total loss': 0.8100944784006127}
2022-11-18 00:39:05,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:05,114 INFO:     Epoch: 18
2022-11-18 00:39:05,911 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8485063531182029, 'Total loss': 0.8485063531182029} | train loss {'Reaction outcome loss': 0.8111753343691227, 'Total loss': 0.8111753343691227}
2022-11-18 00:39:05,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:05,911 INFO:     Epoch: 19
2022-11-18 00:39:06,686 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8328024948185141, 'Total loss': 0.8328024948185141} | train loss {'Reaction outcome loss': 0.8157087048055672, 'Total loss': 0.8157087048055672}
2022-11-18 00:39:06,686 INFO:     Found new best model at epoch 19
2022-11-18 00:39:06,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:06,687 INFO:     Epoch: 20
2022-11-18 00:39:07,472 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8356505713679574, 'Total loss': 0.8356505713679574} | train loss {'Reaction outcome loss': 0.8077195295196796, 'Total loss': 0.8077195295196796}
2022-11-18 00:39:07,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:07,473 INFO:     Epoch: 21
2022-11-18 00:39:08,245 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8746875294230201, 'Total loss': 0.8746875294230201} | train loss {'Reaction outcome loss': 0.8068289884068223, 'Total loss': 0.8068289884068223}
2022-11-18 00:39:08,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:08,245 INFO:     Epoch: 22
2022-11-18 00:39:09,022 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8461346951397982, 'Total loss': 0.8461346951397982} | train loss {'Reaction outcome loss': 0.813168083487252, 'Total loss': 0.813168083487252}
2022-11-18 00:39:09,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:09,022 INFO:     Epoch: 23
2022-11-18 00:39:09,817 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.831339569254355, 'Total loss': 0.831339569254355} | train loss {'Reaction outcome loss': 0.812281821541458, 'Total loss': 0.812281821541458}
2022-11-18 00:39:09,817 INFO:     Found new best model at epoch 23
2022-11-18 00:39:09,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:09,818 INFO:     Epoch: 24
2022-11-18 00:39:10,603 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8595463518391956, 'Total loss': 0.8595463518391956} | train loss {'Reaction outcome loss': 0.8118344755307866, 'Total loss': 0.8118344755307866}
2022-11-18 00:39:10,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:10,603 INFO:     Epoch: 25
2022-11-18 00:39:11,361 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8455731631679968, 'Total loss': 0.8455731631679968} | train loss {'Reaction outcome loss': 0.8063828615765822, 'Total loss': 0.8063828615765822}
2022-11-18 00:39:11,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:11,361 INFO:     Epoch: 26
2022-11-18 00:39:12,151 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8425431061874736, 'Total loss': 0.8425431061874736} | train loss {'Reaction outcome loss': 0.8078039150066704, 'Total loss': 0.8078039150066704}
2022-11-18 00:39:12,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:12,152 INFO:     Epoch: 27
2022-11-18 00:39:12,905 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8387312997471202, 'Total loss': 0.8387312997471202} | train loss {'Reaction outcome loss': 0.8104867042317564, 'Total loss': 0.8104867042317564}
2022-11-18 00:39:12,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:12,907 INFO:     Epoch: 28
2022-11-18 00:39:13,711 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8428617499091409, 'Total loss': 0.8428617499091409} | train loss {'Reaction outcome loss': 0.8091676012888128, 'Total loss': 0.8091676012888128}
2022-11-18 00:39:13,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:13,711 INFO:     Epoch: 29
2022-11-18 00:39:14,481 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8305892043493011, 'Total loss': 0.8305892043493011} | train loss {'Reaction outcome loss': 0.810642917267224, 'Total loss': 0.810642917267224}
2022-11-18 00:39:14,482 INFO:     Found new best model at epoch 29
2022-11-18 00:39:14,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:14,482 INFO:     Epoch: 30
2022-11-18 00:39:15,246 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8469717746431177, 'Total loss': 0.8469717746431177} | train loss {'Reaction outcome loss': 0.8156508039607693, 'Total loss': 0.8156508039607693}
2022-11-18 00:39:15,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:15,246 INFO:     Epoch: 31
2022-11-18 00:39:16,024 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.846848264336586, 'Total loss': 0.846848264336586} | train loss {'Reaction outcome loss': 0.8109858620625275, 'Total loss': 0.8109858620625275}
2022-11-18 00:39:16,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:16,024 INFO:     Epoch: 32
2022-11-18 00:39:16,805 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8450384844433178, 'Total loss': 0.8450384844433178} | train loss {'Reaction outcome loss': 0.8074982471251295, 'Total loss': 0.8074982471251295}
2022-11-18 00:39:16,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:16,805 INFO:     Epoch: 33
2022-11-18 00:39:17,590 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8998908617279746, 'Total loss': 0.8998908617279746} | train loss {'Reaction outcome loss': 0.8098893642184223, 'Total loss': 0.8098893642184223}
2022-11-18 00:39:17,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:17,590 INFO:     Epoch: 34
2022-11-18 00:39:18,393 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.833908193490722, 'Total loss': 0.833908193490722} | train loss {'Reaction outcome loss': 0.8179562730103852, 'Total loss': 0.8179562730103852}
2022-11-18 00:39:18,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:18,393 INFO:     Epoch: 35
2022-11-18 00:39:19,181 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8195240230045535, 'Total loss': 0.8195240230045535} | train loss {'Reaction outcome loss': 0.8078958967677977, 'Total loss': 0.8078958967677977}
2022-11-18 00:39:19,182 INFO:     Found new best model at epoch 35
2022-11-18 00:39:19,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:19,183 INFO:     Epoch: 36
2022-11-18 00:39:19,953 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8309559205716307, 'Total loss': 0.8309559205716307} | train loss {'Reaction outcome loss': 0.8114367033305921, 'Total loss': 0.8114367033305921}
2022-11-18 00:39:19,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:19,954 INFO:     Epoch: 37
2022-11-18 00:39:20,749 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8412305929444053, 'Total loss': 0.8412305929444053} | train loss {'Reaction outcome loss': 0.8088183321571543, 'Total loss': 0.8088183321571543}
2022-11-18 00:39:20,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:20,749 INFO:     Epoch: 38
2022-11-18 00:39:21,523 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8588818846778437, 'Total loss': 0.8588818846778437} | train loss {'Reaction outcome loss': 0.8063502794335246, 'Total loss': 0.8063502794335246}
2022-11-18 00:39:21,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:21,523 INFO:     Epoch: 39
2022-11-18 00:39:22,308 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.849378073757345, 'Total loss': 0.849378073757345} | train loss {'Reaction outcome loss': 0.8115705301163167, 'Total loss': 0.8115705301163167}
2022-11-18 00:39:22,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:22,308 INFO:     Epoch: 40
2022-11-18 00:39:23,081 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8334875127131288, 'Total loss': 0.8334875127131288} | train loss {'Reaction outcome loss': 0.8166450404445169, 'Total loss': 0.8166450404445169}
2022-11-18 00:39:23,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:23,081 INFO:     Epoch: 41
2022-11-18 00:39:23,853 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8366852626204491, 'Total loss': 0.8366852626204491} | train loss {'Reaction outcome loss': 0.8061511263190976, 'Total loss': 0.8061511263190976}
2022-11-18 00:39:23,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:23,853 INFO:     Epoch: 42
2022-11-18 00:39:24,627 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8320963233709335, 'Total loss': 0.8320963233709335} | train loss {'Reaction outcome loss': 0.8084267112407607, 'Total loss': 0.8084267112407607}
2022-11-18 00:39:24,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:24,627 INFO:     Epoch: 43
2022-11-18 00:39:25,404 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8311924182555892, 'Total loss': 0.8311924182555892} | train loss {'Reaction outcome loss': 0.8039062265080479, 'Total loss': 0.8039062265080479}
2022-11-18 00:39:25,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:25,404 INFO:     Epoch: 44
2022-11-18 00:39:26,192 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8548450700261376, 'Total loss': 0.8548450700261376} | train loss {'Reaction outcome loss': 0.8124674762550154, 'Total loss': 0.8124674762550154}
2022-11-18 00:39:26,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:26,192 INFO:     Epoch: 45
2022-11-18 00:39:26,983 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8361644487489354, 'Total loss': 0.8361644487489354} | train loss {'Reaction outcome loss': 0.8038197080435058, 'Total loss': 0.8038197080435058}
2022-11-18 00:39:26,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:26,983 INFO:     Epoch: 46
2022-11-18 00:39:27,770 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8326610096476295, 'Total loss': 0.8326610096476295} | train loss {'Reaction outcome loss': 0.8015743997777521, 'Total loss': 0.8015743997777521}
2022-11-18 00:39:27,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:27,770 INFO:     Epoch: 47
2022-11-18 00:39:28,555 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8427725143053315, 'Total loss': 0.8427725143053315} | train loss {'Reaction outcome loss': 0.8091633237807857, 'Total loss': 0.8091633237807857}
2022-11-18 00:39:28,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:28,555 INFO:     Epoch: 48
2022-11-18 00:39:29,318 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8508045890114524, 'Total loss': 0.8508045890114524} | train loss {'Reaction outcome loss': 0.8083430089222395, 'Total loss': 0.8083430089222395}
2022-11-18 00:39:29,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:29,318 INFO:     Epoch: 49
2022-11-18 00:39:30,112 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8776374405080621, 'Total loss': 0.8776374405080621} | train loss {'Reaction outcome loss': 0.8131441706829226, 'Total loss': 0.8131441706829226}
2022-11-18 00:39:30,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:30,112 INFO:     Epoch: 50
2022-11-18 00:39:30,904 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8392062458125028, 'Total loss': 0.8392062458125028} | train loss {'Reaction outcome loss': 0.8152778338082889, 'Total loss': 0.8152778338082889}
2022-11-18 00:39:30,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:30,904 INFO:     Epoch: 51
2022-11-18 00:39:31,703 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8555142595009371, 'Total loss': 0.8555142595009371} | train loss {'Reaction outcome loss': 0.8107886783748504, 'Total loss': 0.8107886783748504}
2022-11-18 00:39:31,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:31,704 INFO:     Epoch: 52
2022-11-18 00:39:32,511 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8444916992024942, 'Total loss': 0.8444916992024942} | train loss {'Reaction outcome loss': 0.8092647351716694, 'Total loss': 0.8092647351716694}
2022-11-18 00:39:32,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:32,511 INFO:     Epoch: 53
2022-11-18 00:39:33,349 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8955317776311528, 'Total loss': 0.8955317776311528} | train loss {'Reaction outcome loss': 0.8125349315795821, 'Total loss': 0.8125349315795821}
2022-11-18 00:39:33,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:33,349 INFO:     Epoch: 54
2022-11-18 00:39:34,172 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8406633849848401, 'Total loss': 0.8406633849848401} | train loss {'Reaction outcome loss': 0.8167827941009752, 'Total loss': 0.8167827941009752}
2022-11-18 00:39:34,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:34,172 INFO:     Epoch: 55
2022-11-18 00:39:34,972 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8379802250049331, 'Total loss': 0.8379802250049331} | train loss {'Reaction outcome loss': 0.8042199836689451, 'Total loss': 0.8042199836689451}
2022-11-18 00:39:34,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:34,973 INFO:     Epoch: 56
2022-11-18 00:39:35,781 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8527188605882905, 'Total loss': 0.8527188605882905} | train loss {'Reaction outcome loss': 0.8075103680131889, 'Total loss': 0.8075103680131889}
2022-11-18 00:39:35,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:35,781 INFO:     Epoch: 57
2022-11-18 00:39:36,646 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8477871837941083, 'Total loss': 0.8477871837941083} | train loss {'Reaction outcome loss': 0.8095197260138477, 'Total loss': 0.8095197260138477}
2022-11-18 00:39:36,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:36,646 INFO:     Epoch: 58
2022-11-18 00:39:37,409 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8433891297741369, 'Total loss': 0.8433891297741369} | train loss {'Reaction outcome loss': 0.8129465500352836, 'Total loss': 0.8129465500352836}
2022-11-18 00:39:37,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:37,409 INFO:     Epoch: 59
2022-11-18 00:39:38,220 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8341425623406064, 'Total loss': 0.8341425623406064} | train loss {'Reaction outcome loss': 0.8145096613327983, 'Total loss': 0.8145096613327983}
2022-11-18 00:39:38,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:38,220 INFO:     Epoch: 60
2022-11-18 00:39:39,046 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8363474539735101, 'Total loss': 0.8363474539735101} | train loss {'Reaction outcome loss': 0.8044102752980916, 'Total loss': 0.8044102752980916}
2022-11-18 00:39:39,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:39,046 INFO:     Epoch: 61
2022-11-18 00:39:39,889 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8664060627872293, 'Total loss': 0.8664060627872293} | train loss {'Reaction outcome loss': 0.8144644548294515, 'Total loss': 0.8144644548294515}
2022-11-18 00:39:39,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:39,890 INFO:     Epoch: 62
2022-11-18 00:39:40,721 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8710552237250588, 'Total loss': 0.8710552237250588} | train loss {'Reaction outcome loss': 0.8102388774093828, 'Total loss': 0.8102388774093828}
2022-11-18 00:39:40,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:40,721 INFO:     Epoch: 63
2022-11-18 00:39:41,534 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8384163454174995, 'Total loss': 0.8384163454174995} | train loss {'Reaction outcome loss': 0.8074888157005976, 'Total loss': 0.8074888157005976}
2022-11-18 00:39:41,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:41,535 INFO:     Epoch: 64
2022-11-18 00:39:42,303 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8406115147200498, 'Total loss': 0.8406115147200498} | train loss {'Reaction outcome loss': 0.8046756836808162, 'Total loss': 0.8046756836808162}
2022-11-18 00:39:42,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:42,303 INFO:     Epoch: 65
2022-11-18 00:39:43,095 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8406067863106728, 'Total loss': 0.8406067863106728} | train loss {'Reaction outcome loss': 0.8091170067563351, 'Total loss': 0.8091170067563351}
2022-11-18 00:39:43,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:43,095 INFO:     Epoch: 66
2022-11-18 00:39:43,899 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8558833673596382, 'Total loss': 0.8558833673596382} | train loss {'Reaction outcome loss': 0.8099461115806209, 'Total loss': 0.8099461115806209}
2022-11-18 00:39:43,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:43,901 INFO:     Epoch: 67
2022-11-18 00:39:44,691 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8400943401184949, 'Total loss': 0.8400943401184949} | train loss {'Reaction outcome loss': 0.8143307713844515, 'Total loss': 0.8143307713844515}
2022-11-18 00:39:44,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:44,692 INFO:     Epoch: 68
2022-11-18 00:39:45,467 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8417595401406288, 'Total loss': 0.8417595401406288} | train loss {'Reaction outcome loss': 0.8111409331381563, 'Total loss': 0.8111409331381563}
2022-11-18 00:39:45,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:45,467 INFO:     Epoch: 69
2022-11-18 00:39:46,308 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8330015797506679, 'Total loss': 0.8330015797506679} | train loss {'Reaction outcome loss': 0.8121351821702502, 'Total loss': 0.8121351821702502}
2022-11-18 00:39:46,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:46,309 INFO:     Epoch: 70
2022-11-18 00:39:47,120 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8435118178075011, 'Total loss': 0.8435118178075011} | train loss {'Reaction outcome loss': 0.8000980814700185, 'Total loss': 0.8000980814700185}
2022-11-18 00:39:47,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:47,120 INFO:     Epoch: 71
2022-11-18 00:39:48,002 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8430229289965196, 'Total loss': 0.8430229289965196} | train loss {'Reaction outcome loss': 0.8097901509599648, 'Total loss': 0.8097901509599648}
2022-11-18 00:39:48,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:48,002 INFO:     Epoch: 72
2022-11-18 00:39:48,817 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8238847662102092, 'Total loss': 0.8238847662102092} | train loss {'Reaction outcome loss': 0.809272379482444, 'Total loss': 0.809272379482444}
2022-11-18 00:39:48,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:48,817 INFO:     Epoch: 73
2022-11-18 00:39:49,619 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8488181992010637, 'Total loss': 0.8488181992010637} | train loss {'Reaction outcome loss': 0.8105055647581695, 'Total loss': 0.8105055647581695}
2022-11-18 00:39:49,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:49,620 INFO:     Epoch: 74
2022-11-18 00:39:50,443 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8429879437793385, 'Total loss': 0.8429879437793385} | train loss {'Reaction outcome loss': 0.8125210531086091, 'Total loss': 0.8125210531086091}
2022-11-18 00:39:50,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:50,444 INFO:     Epoch: 75
2022-11-18 00:39:51,259 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8351311805573377, 'Total loss': 0.8351311805573377} | train loss {'Reaction outcome loss': 0.8163066432784926, 'Total loss': 0.8163066432784926}
2022-11-18 00:39:51,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:51,260 INFO:     Epoch: 76
2022-11-18 00:39:52,086 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8210023458708416, 'Total loss': 0.8210023458708416} | train loss {'Reaction outcome loss': 0.8089906492455285, 'Total loss': 0.8089906492455285}
2022-11-18 00:39:52,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:52,086 INFO:     Epoch: 77
2022-11-18 00:39:52,912 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8325552283362909, 'Total loss': 0.8325552283362909} | train loss {'Reaction outcome loss': 0.8135751105754482, 'Total loss': 0.8135751105754482}
2022-11-18 00:39:52,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:52,912 INFO:     Epoch: 78
2022-11-18 00:39:53,726 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8323056095025756, 'Total loss': 0.8323056095025756} | train loss {'Reaction outcome loss': 0.8096399685812865, 'Total loss': 0.8096399685812865}
2022-11-18 00:39:53,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:53,726 INFO:     Epoch: 79
2022-11-18 00:39:54,534 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8284559588540684, 'Total loss': 0.8284559588540684} | train loss {'Reaction outcome loss': 0.8089455724486455, 'Total loss': 0.8089455724486455}
2022-11-18 00:39:54,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:54,534 INFO:     Epoch: 80
2022-11-18 00:39:55,325 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8362978141416203, 'Total loss': 0.8362978141416203} | train loss {'Reaction outcome loss': 0.8044478472789772, 'Total loss': 0.8044478472789772}
2022-11-18 00:39:55,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:55,326 INFO:     Epoch: 81
2022-11-18 00:39:56,116 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.9092169106006622, 'Total loss': 0.9092169106006622} | train loss {'Reaction outcome loss': 0.8078376334688442, 'Total loss': 0.8078376334688442}
2022-11-18 00:39:56,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:56,116 INFO:     Epoch: 82
2022-11-18 00:39:56,919 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8292013664137233, 'Total loss': 0.8292013664137233} | train loss {'Reaction outcome loss': 0.8062156228280744, 'Total loss': 0.8062156228280744}
2022-11-18 00:39:56,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:56,919 INFO:     Epoch: 83
2022-11-18 00:39:57,696 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8322738266804002, 'Total loss': 0.8322738266804002} | train loss {'Reaction outcome loss': 0.8037678297714665, 'Total loss': 0.8037678297714665}
2022-11-18 00:39:57,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:57,696 INFO:     Epoch: 84
2022-11-18 00:39:58,538 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8403062508864836, 'Total loss': 0.8403062508864836} | train loss {'Reaction outcome loss': 0.8115620668600445, 'Total loss': 0.8115620668600445}
2022-11-18 00:39:58,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:58,538 INFO:     Epoch: 85
2022-11-18 00:39:59,356 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8667824132875963, 'Total loss': 0.8667824132875963} | train loss {'Reaction outcome loss': 0.8113822447143586, 'Total loss': 0.8113822447143586}
2022-11-18 00:39:59,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:39:59,356 INFO:     Epoch: 86
2022-11-18 00:40:00,147 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.83270698311654, 'Total loss': 0.83270698311654} | train loss {'Reaction outcome loss': 0.7995650579753192, 'Total loss': 0.7995650579753192}
2022-11-18 00:40:00,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:00,147 INFO:     Epoch: 87
2022-11-18 00:40:00,935 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8547804694284092, 'Total loss': 0.8547804694284092} | train loss {'Reaction outcome loss': 0.8134266676207785, 'Total loss': 0.8134266676207785}
2022-11-18 00:40:00,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:00,935 INFO:     Epoch: 88
2022-11-18 00:40:01,733 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8282030258666385, 'Total loss': 0.8282030258666385} | train loss {'Reaction outcome loss': 0.8090326757686823, 'Total loss': 0.8090326757686823}
2022-11-18 00:40:01,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:01,733 INFO:     Epoch: 89
2022-11-18 00:40:02,539 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8433513709089973, 'Total loss': 0.8433513709089973} | train loss {'Reaction outcome loss': 0.8120017182006527, 'Total loss': 0.8120017182006527}
2022-11-18 00:40:02,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:02,540 INFO:     Epoch: 90
2022-11-18 00:40:03,328 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8406983349810947, 'Total loss': 0.8406983349810947} | train loss {'Reaction outcome loss': 0.8034560945231904, 'Total loss': 0.8034560945231904}
2022-11-18 00:40:03,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:03,328 INFO:     Epoch: 91
2022-11-18 00:40:04,123 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8451258892362769, 'Total loss': 0.8451258892362769} | train loss {'Reaction outcome loss': 0.8079349092747036, 'Total loss': 0.8079349092747036}
2022-11-18 00:40:04,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:04,124 INFO:     Epoch: 92
2022-11-18 00:40:04,903 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8431782898577777, 'Total loss': 0.8431782898577777} | train loss {'Reaction outcome loss': 0.809321220104511, 'Total loss': 0.809321220104511}
2022-11-18 00:40:04,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:04,903 INFO:     Epoch: 93
2022-11-18 00:40:05,754 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8364724002101205, 'Total loss': 0.8364724002101205} | train loss {'Reaction outcome loss': 0.8082209788112023, 'Total loss': 0.8082209788112023}
2022-11-18 00:40:05,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:05,754 INFO:     Epoch: 94
2022-11-18 00:40:06,580 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8324328593232415, 'Total loss': 0.8324328593232415} | train loss {'Reaction outcome loss': 0.8054839195268839, 'Total loss': 0.8054839195268839}
2022-11-18 00:40:06,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:06,581 INFO:     Epoch: 95
2022-11-18 00:40:07,430 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8580217185345563, 'Total loss': 0.8580217185345563} | train loss {'Reaction outcome loss': 0.8157431275738396, 'Total loss': 0.8157431275738396}
2022-11-18 00:40:07,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:07,430 INFO:     Epoch: 96
2022-11-18 00:40:08,249 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8383986462246288, 'Total loss': 0.8383986462246288} | train loss {'Reaction outcome loss': 0.8183066369550913, 'Total loss': 0.8183066369550913}
2022-11-18 00:40:08,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:08,249 INFO:     Epoch: 97
2022-11-18 00:40:09,075 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8421767956831239, 'Total loss': 0.8421767956831239} | train loss {'Reaction outcome loss': 0.8101675125510104, 'Total loss': 0.8101675125510104}
2022-11-18 00:40:09,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:09,075 INFO:     Epoch: 98
2022-11-18 00:40:09,894 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8370155197652903, 'Total loss': 0.8370155197652903} | train loss {'Reaction outcome loss': 0.8114136129859005, 'Total loss': 0.8114136129859005}
2022-11-18 00:40:09,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:09,894 INFO:     Epoch: 99
2022-11-18 00:40:10,733 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8350313678383827, 'Total loss': 0.8350313678383827} | train loss {'Reaction outcome loss': 0.8023027331994371, 'Total loss': 0.8023027331994371}
2022-11-18 00:40:10,733 INFO:     Best model found after epoch 36 of 100.
2022-11-18 00:40:10,734 INFO:   Done with stage: TRAINING
2022-11-18 00:40:10,734 INFO:   Starting stage: EVALUATION
2022-11-18 00:40:10,857 INFO:   Done with stage: EVALUATION
2022-11-18 00:40:10,866 INFO:   Leaving out SEQ value Fold_0
2022-11-18 00:40:10,879 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 00:40:10,879 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:40:11,546 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:40:11,546 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:40:11,619 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:40:11,619 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:40:11,619 INFO:     No hyperparam tuning for this model
2022-11-18 00:40:11,619 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:40:11,619 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:40:11,620 INFO:     None feature selector for col prot
2022-11-18 00:40:11,620 INFO:     None feature selector for col prot
2022-11-18 00:40:11,620 INFO:     None feature selector for col prot
2022-11-18 00:40:11,621 INFO:     None feature selector for col chem
2022-11-18 00:40:11,621 INFO:     None feature selector for col chem
2022-11-18 00:40:11,621 INFO:     None feature selector for col chem
2022-11-18 00:40:11,621 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:40:11,621 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:40:11,623 INFO:     Number of params in model 168571
2022-11-18 00:40:11,626 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:40:11,626 INFO:   Starting stage: TRAINING
2022-11-18 00:40:11,682 INFO:     Val loss before train {'Reaction outcome loss': 0.95070602173029, 'Total loss': 0.95070602173029}
2022-11-18 00:40:11,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:11,683 INFO:     Epoch: 0
2022-11-18 00:40:12,467 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7686256225719008, 'Total loss': 0.7686256225719008} | train loss {'Reaction outcome loss': 0.8771635517171381, 'Total loss': 0.8771635517171381}
2022-11-18 00:40:12,467 INFO:     Found new best model at epoch 0
2022-11-18 00:40:12,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:12,468 INFO:     Epoch: 1
2022-11-18 00:40:13,252 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8008655621561893, 'Total loss': 0.8008655621561893} | train loss {'Reaction outcome loss': 0.8513716366065383, 'Total loss': 0.8513716366065383}
2022-11-18 00:40:13,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:13,252 INFO:     Epoch: 2
2022-11-18 00:40:14,047 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.77994089764218, 'Total loss': 0.77994089764218} | train loss {'Reaction outcome loss': 0.8433181913301288, 'Total loss': 0.8433181913301288}
2022-11-18 00:40:14,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:14,048 INFO:     Epoch: 3
2022-11-18 00:40:14,807 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7688065088072489, 'Total loss': 0.7688065088072489} | train loss {'Reaction outcome loss': 0.842262404813688, 'Total loss': 0.842262404813688}
2022-11-18 00:40:14,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:14,808 INFO:     Epoch: 4
2022-11-18 00:40:15,655 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7693118875802949, 'Total loss': 0.7693118875802949} | train loss {'Reaction outcome loss': 0.8366031219929825, 'Total loss': 0.8366031219929825}
2022-11-18 00:40:15,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:15,655 INFO:     Epoch: 5
2022-11-18 00:40:16,444 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7636506363402965, 'Total loss': 0.7636506363402965} | train loss {'Reaction outcome loss': 0.8314243826110668, 'Total loss': 0.8314243826110668}
2022-11-18 00:40:16,444 INFO:     Found new best model at epoch 5
2022-11-18 00:40:16,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:16,445 INFO:     Epoch: 6
2022-11-18 00:40:17,288 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7593905932681505, 'Total loss': 0.7593905932681505} | train loss {'Reaction outcome loss': 0.8300505590782244, 'Total loss': 0.8300505590782244}
2022-11-18 00:40:17,288 INFO:     Found new best model at epoch 6
2022-11-18 00:40:17,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:17,289 INFO:     Epoch: 7
2022-11-18 00:40:18,090 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7735626850017282, 'Total loss': 0.7735626850017282} | train loss {'Reaction outcome loss': 0.8253060785340675, 'Total loss': 0.8253060785340675}
2022-11-18 00:40:18,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:18,090 INFO:     Epoch: 8
2022-11-18 00:40:18,895 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7750345884367477, 'Total loss': 0.7750345884367477} | train loss {'Reaction outcome loss': 0.821133863042902, 'Total loss': 0.821133863042902}
2022-11-18 00:40:18,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:18,895 INFO:     Epoch: 9
2022-11-18 00:40:19,698 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7857946739640347, 'Total loss': 0.7857946739640347} | train loss {'Reaction outcome loss': 0.823432396346159, 'Total loss': 0.823432396346159}
2022-11-18 00:40:19,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:19,699 INFO:     Epoch: 10
2022-11-18 00:40:20,477 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7589555438174758, 'Total loss': 0.7589555438174758} | train loss {'Reaction outcome loss': 0.8208229877821211, 'Total loss': 0.8208229877821211}
2022-11-18 00:40:20,477 INFO:     Found new best model at epoch 10
2022-11-18 00:40:20,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:20,478 INFO:     Epoch: 11
2022-11-18 00:40:21,278 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7845234635264374, 'Total loss': 0.7845234635264374} | train loss {'Reaction outcome loss': 0.8219409983589816, 'Total loss': 0.8219409983589816}
2022-11-18 00:40:21,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:21,279 INFO:     Epoch: 12
2022-11-18 00:40:22,041 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7796376208926357, 'Total loss': 0.7796376208926357} | train loss {'Reaction outcome loss': 0.8238844831048706, 'Total loss': 0.8238844831048706}
2022-11-18 00:40:22,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:22,041 INFO:     Epoch: 13
2022-11-18 00:40:22,834 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7887334913708443, 'Total loss': 0.7887334913708443} | train loss {'Reaction outcome loss': 0.8192439965995741, 'Total loss': 0.8192439965995741}
2022-11-18 00:40:22,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:22,834 INFO:     Epoch: 14
2022-11-18 00:40:23,625 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7599878997303718, 'Total loss': 0.7599878997303718} | train loss {'Reaction outcome loss': 0.8201457146754481, 'Total loss': 0.8201457146754481}
2022-11-18 00:40:23,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:23,626 INFO:     Epoch: 15
2022-11-18 00:40:24,461 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7759254436160243, 'Total loss': 0.7759254436160243} | train loss {'Reaction outcome loss': 0.8269969320591585, 'Total loss': 0.8269969320591585}
2022-11-18 00:40:24,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:24,462 INFO:     Epoch: 16
2022-11-18 00:40:25,228 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8121600837208504, 'Total loss': 0.8121600837208504} | train loss {'Reaction outcome loss': 0.8182488999984883, 'Total loss': 0.8182488999984883}
2022-11-18 00:40:25,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:25,228 INFO:     Epoch: 17
2022-11-18 00:40:26,021 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7549705526163412, 'Total loss': 0.7549705526163412} | train loss {'Reaction outcome loss': 0.8243996646914462, 'Total loss': 0.8243996646914462}
2022-11-18 00:40:26,021 INFO:     Found new best model at epoch 17
2022-11-18 00:40:26,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:26,022 INFO:     Epoch: 18
2022-11-18 00:40:26,809 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7599055981913279, 'Total loss': 0.7599055981913279} | train loss {'Reaction outcome loss': 0.8175414953948048, 'Total loss': 0.8175414953948048}
2022-11-18 00:40:26,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:26,809 INFO:     Epoch: 19
2022-11-18 00:40:27,594 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7647997023061265, 'Total loss': 0.7647997023061265} | train loss {'Reaction outcome loss': 0.8154056973663377, 'Total loss': 0.8154056973663377}
2022-11-18 00:40:27,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:27,595 INFO:     Epoch: 20
2022-11-18 00:40:28,354 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7678716231224149, 'Total loss': 0.7678716231224149} | train loss {'Reaction outcome loss': 0.8172995049521756, 'Total loss': 0.8172995049521756}
2022-11-18 00:40:28,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:28,355 INFO:     Epoch: 21
2022-11-18 00:40:29,130 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7912506641343583, 'Total loss': 0.7912506641343583} | train loss {'Reaction outcome loss': 0.8201514802597187, 'Total loss': 0.8201514802597187}
2022-11-18 00:40:29,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:29,130 INFO:     Epoch: 22
2022-11-18 00:40:29,944 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8249790966510773, 'Total loss': 0.8249790966510773} | train loss {'Reaction outcome loss': 0.8151080857333823, 'Total loss': 0.8151080857333823}
2022-11-18 00:40:29,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:29,944 INFO:     Epoch: 23
2022-11-18 00:40:30,751 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7647674069848172, 'Total loss': 0.7647674069848172} | train loss {'Reaction outcome loss': 0.8233416763598046, 'Total loss': 0.8233416763598046}
2022-11-18 00:40:30,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:30,752 INFO:     Epoch: 24
2022-11-18 00:40:31,543 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.765065212582433, 'Total loss': 0.765065212582433} | train loss {'Reaction outcome loss': 0.8187367967617365, 'Total loss': 0.8187367967617365}
2022-11-18 00:40:31,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:31,543 INFO:     Epoch: 25
2022-11-18 00:40:32,362 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7724159249039584, 'Total loss': 0.7724159249039584} | train loss {'Reaction outcome loss': 0.8194765698762587, 'Total loss': 0.8194765698762587}
2022-11-18 00:40:32,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:32,362 INFO:     Epoch: 26
2022-11-18 00:40:33,161 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7817342946695727, 'Total loss': 0.7817342946695727} | train loss {'Reaction outcome loss': 0.8170559563263944, 'Total loss': 0.8170559563263944}
2022-11-18 00:40:33,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:33,161 INFO:     Epoch: 27
2022-11-18 00:40:33,969 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7722742869410404, 'Total loss': 0.7722742869410404} | train loss {'Reaction outcome loss': 0.8193103629375191, 'Total loss': 0.8193103629375191}
2022-11-18 00:40:33,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:33,970 INFO:     Epoch: 28
2022-11-18 00:40:34,744 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.760213888661806, 'Total loss': 0.760213888661806} | train loss {'Reaction outcome loss': 0.8192330510528, 'Total loss': 0.8192330510528}
2022-11-18 00:40:34,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:34,744 INFO:     Epoch: 29
2022-11-18 00:40:35,580 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7653547518475111, 'Total loss': 0.7653547518475111} | train loss {'Reaction outcome loss': 0.8159019277419572, 'Total loss': 0.8159019277419572}
2022-11-18 00:40:35,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:35,580 INFO:     Epoch: 30
2022-11-18 00:40:36,363 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7672471313975578, 'Total loss': 0.7672471313975578} | train loss {'Reaction outcome loss': 0.820183148845233, 'Total loss': 0.820183148845233}
2022-11-18 00:40:36,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:36,364 INFO:     Epoch: 31
2022-11-18 00:40:37,172 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7620271056197411, 'Total loss': 0.7620271056197411} | train loss {'Reaction outcome loss': 0.8190398743613757, 'Total loss': 0.8190398743613757}
2022-11-18 00:40:37,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:37,173 INFO:     Epoch: 32
2022-11-18 00:40:37,946 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7514714882817379, 'Total loss': 0.7514714882817379} | train loss {'Reaction outcome loss': 0.8120681186026506, 'Total loss': 0.8120681186026506}
2022-11-18 00:40:37,946 INFO:     Found new best model at epoch 32
2022-11-18 00:40:37,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:37,947 INFO:     Epoch: 33
2022-11-18 00:40:38,724 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7883211145567339, 'Total loss': 0.7883211145567339} | train loss {'Reaction outcome loss': 0.813443985618191, 'Total loss': 0.813443985618191}
2022-11-18 00:40:38,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:38,724 INFO:     Epoch: 34
2022-11-18 00:40:39,502 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7562011175377424, 'Total loss': 0.7562011175377424} | train loss {'Reaction outcome loss': 0.8196721049983806, 'Total loss': 0.8196721049983806}
2022-11-18 00:40:39,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:39,502 INFO:     Epoch: 35
2022-11-18 00:40:40,320 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7708380513413008, 'Total loss': 0.7708380513413008} | train loss {'Reaction outcome loss': 0.8195619850492282, 'Total loss': 0.8195619850492282}
2022-11-18 00:40:40,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:40,320 INFO:     Epoch: 36
2022-11-18 00:40:41,082 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7597265409868817, 'Total loss': 0.7597265409868817} | train loss {'Reaction outcome loss': 0.8138848616139879, 'Total loss': 0.8138848616139879}
2022-11-18 00:40:41,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:41,083 INFO:     Epoch: 37
2022-11-18 00:40:41,866 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7524144247520802, 'Total loss': 0.7524144247520802} | train loss {'Reaction outcome loss': 0.8193846118057706, 'Total loss': 0.8193846118057706}
2022-11-18 00:40:41,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:41,866 INFO:     Epoch: 38
2022-11-18 00:40:42,671 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7659819174644559, 'Total loss': 0.7659819174644559} | train loss {'Reaction outcome loss': 0.8175602496406178, 'Total loss': 0.8175602496406178}
2022-11-18 00:40:42,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:42,671 INFO:     Epoch: 39
2022-11-18 00:40:43,454 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7488568030124487, 'Total loss': 0.7488568030124487} | train loss {'Reaction outcome loss': 0.8140571217968631, 'Total loss': 0.8140571217968631}
2022-11-18 00:40:43,455 INFO:     Found new best model at epoch 39
2022-11-18 00:40:43,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:43,455 INFO:     Epoch: 40
2022-11-18 00:40:44,257 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.756859093211418, 'Total loss': 0.756859093211418} | train loss {'Reaction outcome loss': 0.8108938834304181, 'Total loss': 0.8108938834304181}
2022-11-18 00:40:44,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:44,258 INFO:     Epoch: 41
2022-11-18 00:40:45,079 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7702500903329184, 'Total loss': 0.7702500903329184} | train loss {'Reaction outcome loss': 0.8168850861213826, 'Total loss': 0.8168850861213826}
2022-11-18 00:40:45,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:45,079 INFO:     Epoch: 42
2022-11-18 00:40:45,880 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7517626909322517, 'Total loss': 0.7517626909322517} | train loss {'Reaction outcome loss': 0.8152076198485653, 'Total loss': 0.8152076198485653}
2022-11-18 00:40:45,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:45,881 INFO:     Epoch: 43
2022-11-18 00:40:46,690 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7709163157052772, 'Total loss': 0.7709163157052772} | train loss {'Reaction outcome loss': 0.8140460601068819, 'Total loss': 0.8140460601068819}
2022-11-18 00:40:46,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:46,691 INFO:     Epoch: 44
2022-11-18 00:40:47,513 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7587588297766309, 'Total loss': 0.7587588297766309} | train loss {'Reaction outcome loss': 0.8177773057188026, 'Total loss': 0.8177773057188026}
2022-11-18 00:40:47,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:47,514 INFO:     Epoch: 45
2022-11-18 00:40:48,345 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7403777740722479, 'Total loss': 0.7403777740722479} | train loss {'Reaction outcome loss': 0.8146324743949828, 'Total loss': 0.8146324743949828}
2022-11-18 00:40:48,345 INFO:     Found new best model at epoch 45
2022-11-18 00:40:48,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:48,346 INFO:     Epoch: 46
2022-11-18 00:40:49,133 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7514585513015126, 'Total loss': 0.7514585513015126} | train loss {'Reaction outcome loss': 0.8179610165548913, 'Total loss': 0.8179610165548913}
2022-11-18 00:40:49,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:49,133 INFO:     Epoch: 47
2022-11-18 00:40:49,915 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7680088940054871, 'Total loss': 0.7680088940054871} | train loss {'Reaction outcome loss': 0.812336190124598, 'Total loss': 0.812336190124598}
2022-11-18 00:40:49,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:49,915 INFO:     Epoch: 48
2022-11-18 00:40:50,694 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7481136488360028, 'Total loss': 0.7481136488360028} | train loss {'Reaction outcome loss': 0.8207378529717402, 'Total loss': 0.8207378529717402}
2022-11-18 00:40:50,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:50,694 INFO:     Epoch: 49
2022-11-18 00:40:51,515 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7597036888433057, 'Total loss': 0.7597036888433057} | train loss {'Reaction outcome loss': 0.8121627542217082, 'Total loss': 0.8121627542217082}
2022-11-18 00:40:51,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:51,515 INFO:     Epoch: 50
2022-11-18 00:40:52,306 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7499623866968377, 'Total loss': 0.7499623866968377} | train loss {'Reaction outcome loss': 0.8151466614670224, 'Total loss': 0.8151466614670224}
2022-11-18 00:40:52,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:52,307 INFO:     Epoch: 51
2022-11-18 00:40:53,104 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7515065905659698, 'Total loss': 0.7515065905659698} | train loss {'Reaction outcome loss': 0.8196467071648978, 'Total loss': 0.8196467071648978}
2022-11-18 00:40:53,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:53,104 INFO:     Epoch: 52
2022-11-18 00:40:53,891 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7462865155796672, 'Total loss': 0.7462865155796672} | train loss {'Reaction outcome loss': 0.8074424563611976, 'Total loss': 0.8074424563611976}
2022-11-18 00:40:53,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:53,891 INFO:     Epoch: 53
2022-11-18 00:40:54,655 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7664524621741716, 'Total loss': 0.7664524621741716} | train loss {'Reaction outcome loss': 0.8102610244917772, 'Total loss': 0.8102610244917772}
2022-11-18 00:40:54,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:54,656 INFO:     Epoch: 54
2022-11-18 00:40:55,427 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7706097225810207, 'Total loss': 0.7706097225810207} | train loss {'Reaction outcome loss': 0.811947294346099, 'Total loss': 0.811947294346099}
2022-11-18 00:40:55,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:55,427 INFO:     Epoch: 55
2022-11-18 00:40:56,208 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.758710037830264, 'Total loss': 0.758710037830264} | train loss {'Reaction outcome loss': 0.8142934908837448, 'Total loss': 0.8142934908837448}
2022-11-18 00:40:56,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:56,208 INFO:     Epoch: 56
2022-11-18 00:40:56,969 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7613061597180921, 'Total loss': 0.7613061597180921} | train loss {'Reaction outcome loss': 0.8151163219669719, 'Total loss': 0.8151163219669719}
2022-11-18 00:40:56,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:56,969 INFO:     Epoch: 57
2022-11-18 00:40:57,720 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7529026671897533, 'Total loss': 0.7529026671897533} | train loss {'Reaction outcome loss': 0.8089886274602678, 'Total loss': 0.8089886274602678}
2022-11-18 00:40:57,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:57,720 INFO:     Epoch: 58
2022-11-18 00:40:58,465 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7486686616442925, 'Total loss': 0.7486686616442925} | train loss {'Reaction outcome loss': 0.8149799399169875, 'Total loss': 0.8149799399169875}
2022-11-18 00:40:58,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:58,465 INFO:     Epoch: 59
2022-11-18 00:40:59,231 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7537558993627859, 'Total loss': 0.7537558993627859} | train loss {'Reaction outcome loss': 0.8182292054464788, 'Total loss': 0.8182292054464788}
2022-11-18 00:40:59,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:40:59,231 INFO:     Epoch: 60
2022-11-18 00:41:00,010 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7511201951392862, 'Total loss': 0.7511201951392862} | train loss {'Reaction outcome loss': 0.8137352041010995, 'Total loss': 0.8137352041010995}
2022-11-18 00:41:00,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:00,010 INFO:     Epoch: 61
2022-11-18 00:41:00,794 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7528750390507454, 'Total loss': 0.7528750390507454} | train loss {'Reaction outcome loss': 0.8122014611836814, 'Total loss': 0.8122014611836814}
2022-11-18 00:41:00,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:00,794 INFO:     Epoch: 62
2022-11-18 00:41:01,564 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7547287899394368, 'Total loss': 0.7547287899394368} | train loss {'Reaction outcome loss': 0.8104255448398276, 'Total loss': 0.8104255448398276}
2022-11-18 00:41:01,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:01,564 INFO:     Epoch: 63
2022-11-18 00:41:02,345 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7623916185179422, 'Total loss': 0.7623916185179422} | train loss {'Reaction outcome loss': 0.8129480118123592, 'Total loss': 0.8129480118123592}
2022-11-18 00:41:02,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:02,346 INFO:     Epoch: 64
2022-11-18 00:41:03,119 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7552367019098859, 'Total loss': 0.7552367019098859} | train loss {'Reaction outcome loss': 0.8103400202690328, 'Total loss': 0.8103400202690328}
2022-11-18 00:41:03,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:03,119 INFO:     Epoch: 65
2022-11-18 00:41:03,893 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7473042801369069, 'Total loss': 0.7473042801369069} | train loss {'Reaction outcome loss': 0.8142731929266894, 'Total loss': 0.8142731929266894}
2022-11-18 00:41:03,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:03,893 INFO:     Epoch: 66
2022-11-18 00:41:04,646 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7721097296060517, 'Total loss': 0.7721097296060517} | train loss {'Reaction outcome loss': 0.8143956816981359, 'Total loss': 0.8143956816981359}
2022-11-18 00:41:04,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:04,647 INFO:     Epoch: 67
2022-11-18 00:41:05,399 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7475072734577711, 'Total loss': 0.7475072734577711} | train loss {'Reaction outcome loss': 0.8146501004450606, 'Total loss': 0.8146501004450606}
2022-11-18 00:41:05,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:05,400 INFO:     Epoch: 68
2022-11-18 00:41:06,182 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.749631059724231, 'Total loss': 0.749631059724231} | train loss {'Reaction outcome loss': 0.8143863416748283, 'Total loss': 0.8143863416748283}
2022-11-18 00:41:06,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:06,182 INFO:     Epoch: 69
2022-11-18 00:41:06,968 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7435963375623836, 'Total loss': 0.7435963375623836} | train loss {'Reaction outcome loss': 0.8147323401376544, 'Total loss': 0.8147323401376544}
2022-11-18 00:41:06,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:06,968 INFO:     Epoch: 70
2022-11-18 00:41:07,756 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.749551244253336, 'Total loss': 0.749551244253336} | train loss {'Reaction outcome loss': 0.8160235520007679, 'Total loss': 0.8160235520007679}
2022-11-18 00:41:07,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:07,756 INFO:     Epoch: 71
2022-11-18 00:41:08,527 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7528460365395213, 'Total loss': 0.7528460365395213} | train loss {'Reaction outcome loss': 0.8168580366505517, 'Total loss': 0.8168580366505517}
2022-11-18 00:41:08,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:08,527 INFO:     Epoch: 72
2022-11-18 00:41:09,290 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7638715138269025, 'Total loss': 0.7638715138269025} | train loss {'Reaction outcome loss': 0.8166520664230786, 'Total loss': 0.8166520664230786}
2022-11-18 00:41:09,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:09,290 INFO:     Epoch: 73
2022-11-18 00:41:10,048 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7537126457968424, 'Total loss': 0.7537126457968424} | train loss {'Reaction outcome loss': 0.8127012913855015, 'Total loss': 0.8127012913855015}
2022-11-18 00:41:10,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:10,048 INFO:     Epoch: 74
2022-11-18 00:41:10,804 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.746048508688461, 'Total loss': 0.746048508688461} | train loss {'Reaction outcome loss': 0.8141573042045405, 'Total loss': 0.8141573042045405}
2022-11-18 00:41:10,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:10,804 INFO:     Epoch: 75
2022-11-18 00:41:11,581 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7529510876467062, 'Total loss': 0.7529510876467062} | train loss {'Reaction outcome loss': 0.8129353512216497, 'Total loss': 0.8129353512216497}
2022-11-18 00:41:11,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:11,581 INFO:     Epoch: 76
2022-11-18 00:41:12,363 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7960132235704467, 'Total loss': 0.7960132235704467} | train loss {'Reaction outcome loss': 0.8111334669982455, 'Total loss': 0.8111334669982455}
2022-11-18 00:41:12,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:12,363 INFO:     Epoch: 77
2022-11-18 00:41:13,107 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7508516512637915, 'Total loss': 0.7508516512637915} | train loss {'Reaction outcome loss': 0.8186454966725636, 'Total loss': 0.8186454966725636}
2022-11-18 00:41:13,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:13,108 INFO:     Epoch: 78
2022-11-18 00:41:13,879 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7639570707498595, 'Total loss': 0.7639570707498595} | train loss {'Reaction outcome loss': 0.8201472553206078, 'Total loss': 0.8201472553206078}
2022-11-18 00:41:13,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:13,879 INFO:     Epoch: 79
2022-11-18 00:41:14,636 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7543035232743551, 'Total loss': 0.7543035232743551} | train loss {'Reaction outcome loss': 0.81232297616731, 'Total loss': 0.81232297616731}
2022-11-18 00:41:14,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:14,636 INFO:     Epoch: 80
2022-11-18 00:41:15,403 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7530708403088325, 'Total loss': 0.7530708403088325} | train loss {'Reaction outcome loss': 0.8134082303125671, 'Total loss': 0.8134082303125671}
2022-11-18 00:41:15,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:15,403 INFO:     Epoch: 81
2022-11-18 00:41:16,161 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7661938216797141, 'Total loss': 0.7661938216797141} | train loss {'Reaction outcome loss': 0.8171883797571983, 'Total loss': 0.8171883797571983}
2022-11-18 00:41:16,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:16,161 INFO:     Epoch: 82
2022-11-18 00:41:16,943 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.766482873711475, 'Total loss': 0.766482873711475} | train loss {'Reaction outcome loss': 0.8183983542301037, 'Total loss': 0.8183983542301037}
2022-11-18 00:41:16,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:16,945 INFO:     Epoch: 83
2022-11-18 00:41:17,716 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7691437172335248, 'Total loss': 0.7691437172335248} | train loss {'Reaction outcome loss': 0.813893724493529, 'Total loss': 0.813893724493529}
2022-11-18 00:41:17,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:17,716 INFO:     Epoch: 84
2022-11-18 00:41:18,476 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7530466692392216, 'Total loss': 0.7530466692392216} | train loss {'Reaction outcome loss': 0.8120142930942308, 'Total loss': 0.8120142930942308}
2022-11-18 00:41:18,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:18,476 INFO:     Epoch: 85
2022-11-18 00:41:19,235 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7510708348695622, 'Total loss': 0.7510708348695622} | train loss {'Reaction outcome loss': 0.8105086008462395, 'Total loss': 0.8105086008462395}
2022-11-18 00:41:19,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:19,235 INFO:     Epoch: 86
2022-11-18 00:41:20,022 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7679633914038192, 'Total loss': 0.7679633914038192} | train loss {'Reaction outcome loss': 0.8172256394668862, 'Total loss': 0.8172256394668862}
2022-11-18 00:41:20,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:20,023 INFO:     Epoch: 87
2022-11-18 00:41:20,776 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7417930468570354, 'Total loss': 0.7417930468570354} | train loss {'Reaction outcome loss': 0.8110127121578028, 'Total loss': 0.8110127121578028}
2022-11-18 00:41:20,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:20,776 INFO:     Epoch: 88
2022-11-18 00:41:21,542 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.760033444609753, 'Total loss': 0.760033444609753} | train loss {'Reaction outcome loss': 0.8159576529338036, 'Total loss': 0.8159576529338036}
2022-11-18 00:41:21,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:21,542 INFO:     Epoch: 89
2022-11-18 00:41:22,325 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7662872575050177, 'Total loss': 0.7662872575050177} | train loss {'Reaction outcome loss': 0.8150756909768768, 'Total loss': 0.8150756909768768}
2022-11-18 00:41:22,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:22,325 INFO:     Epoch: 90
2022-11-18 00:41:23,125 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.752018517533014, 'Total loss': 0.752018517533014} | train loss {'Reaction outcome loss': 0.8147738179797498, 'Total loss': 0.8147738179797498}
2022-11-18 00:41:23,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:23,126 INFO:     Epoch: 91
2022-11-18 00:41:23,882 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7796990067459816, 'Total loss': 0.7796990067459816} | train loss {'Reaction outcome loss': 0.8114497288754938, 'Total loss': 0.8114497288754938}
2022-11-18 00:41:23,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:23,882 INFO:     Epoch: 92
2022-11-18 00:41:24,668 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7504386007785797, 'Total loss': 0.7504386007785797} | train loss {'Reaction outcome loss': 0.8150011580667378, 'Total loss': 0.8150011580667378}
2022-11-18 00:41:24,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:24,668 INFO:     Epoch: 93
2022-11-18 00:41:25,413 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7625117787095004, 'Total loss': 0.7625117787095004} | train loss {'Reaction outcome loss': 0.8110880240981961, 'Total loss': 0.8110880240981961}
2022-11-18 00:41:25,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:25,413 INFO:     Epoch: 94
2022-11-18 00:41:26,182 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7523315798404605, 'Total loss': 0.7523315798404605} | train loss {'Reaction outcome loss': 0.818331094190417, 'Total loss': 0.818331094190417}
2022-11-18 00:41:26,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:26,182 INFO:     Epoch: 95
2022-11-18 00:41:26,958 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7572376908257951, 'Total loss': 0.7572376908257951} | train loss {'Reaction outcome loss': 0.8112977714327628, 'Total loss': 0.8112977714327628}
2022-11-18 00:41:26,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:26,958 INFO:     Epoch: 96
2022-11-18 00:41:27,705 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7558118014834648, 'Total loss': 0.7558118014834648} | train loss {'Reaction outcome loss': 0.8137301052058185, 'Total loss': 0.8137301052058185}
2022-11-18 00:41:27,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:27,705 INFO:     Epoch: 97
2022-11-18 00:41:28,459 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.751413211573002, 'Total loss': 0.751413211573002} | train loss {'Reaction outcome loss': 0.8085940983069777, 'Total loss': 0.8085940983069777}
2022-11-18 00:41:28,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:28,459 INFO:     Epoch: 98
2022-11-18 00:41:29,223 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7670208700867587, 'Total loss': 0.7670208700867587} | train loss {'Reaction outcome loss': 0.8110933500062291, 'Total loss': 0.8110933500062291}
2022-11-18 00:41:29,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:29,223 INFO:     Epoch: 99
2022-11-18 00:41:29,988 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7541884260122166, 'Total loss': 0.7541884260122166} | train loss {'Reaction outcome loss': 0.8146303987797395, 'Total loss': 0.8146303987797395}
2022-11-18 00:41:29,989 INFO:     Best model found after epoch 46 of 100.
2022-11-18 00:41:29,989 INFO:   Done with stage: TRAINING
2022-11-18 00:41:29,989 INFO:   Starting stage: EVALUATION
2022-11-18 00:41:30,131 INFO:   Done with stage: EVALUATION
2022-11-18 00:41:30,131 INFO:   Leaving out SEQ value Fold_1
2022-11-18 00:41:30,144 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:41:30,144 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:41:30,819 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:41:30,819 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:41:30,891 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:41:30,891 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:41:30,891 INFO:     No hyperparam tuning for this model
2022-11-18 00:41:30,891 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:41:30,891 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:41:30,892 INFO:     None feature selector for col prot
2022-11-18 00:41:30,892 INFO:     None feature selector for col prot
2022-11-18 00:41:30,892 INFO:     None feature selector for col prot
2022-11-18 00:41:30,893 INFO:     None feature selector for col chem
2022-11-18 00:41:30,893 INFO:     None feature selector for col chem
2022-11-18 00:41:30,893 INFO:     None feature selector for col chem
2022-11-18 00:41:30,893 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:41:30,893 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:41:30,895 INFO:     Number of params in model 168571
2022-11-18 00:41:30,898 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:41:30,898 INFO:   Starting stage: TRAINING
2022-11-18 00:41:30,957 INFO:     Val loss before train {'Reaction outcome loss': 1.0279427008195356, 'Total loss': 1.0279427008195356}
2022-11-18 00:41:30,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:30,957 INFO:     Epoch: 0
2022-11-18 00:41:31,742 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8458509838039224, 'Total loss': 0.8458509838039224} | train loss {'Reaction outcome loss': 0.8882000752788807, 'Total loss': 0.8882000752788807}
2022-11-18 00:41:31,743 INFO:     Found new best model at epoch 0
2022-11-18 00:41:31,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:31,744 INFO:     Epoch: 1
2022-11-18 00:41:32,517 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8509626117619601, 'Total loss': 0.8509626117619601} | train loss {'Reaction outcome loss': 0.8524630397920184, 'Total loss': 0.8524630397920184}
2022-11-18 00:41:32,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:32,518 INFO:     Epoch: 2
2022-11-18 00:41:33,316 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8011933260343291, 'Total loss': 0.8011933260343291} | train loss {'Reaction outcome loss': 0.8440342464669031, 'Total loss': 0.8440342464669031}
2022-11-18 00:41:33,316 INFO:     Found new best model at epoch 2
2022-11-18 00:41:33,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:33,317 INFO:     Epoch: 3
2022-11-18 00:41:34,110 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8401849296959963, 'Total loss': 0.8401849296959963} | train loss {'Reaction outcome loss': 0.8348997133946129, 'Total loss': 0.8348997133946129}
2022-11-18 00:41:34,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:34,110 INFO:     Epoch: 4
2022-11-18 00:41:34,901 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8183743764053691, 'Total loss': 0.8183743764053691} | train loss {'Reaction outcome loss': 0.8356248422672874, 'Total loss': 0.8356248422672874}
2022-11-18 00:41:34,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:34,901 INFO:     Epoch: 5
2022-11-18 00:41:35,672 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7995353449474681, 'Total loss': 0.7995353449474681} | train loss {'Reaction outcome loss': 0.8293830317403623, 'Total loss': 0.8293830317403623}
2022-11-18 00:41:35,673 INFO:     Found new best model at epoch 5
2022-11-18 00:41:35,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:35,674 INFO:     Epoch: 6
2022-11-18 00:41:36,502 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8308196413246068, 'Total loss': 0.8308196413246068} | train loss {'Reaction outcome loss': 0.8267179370409081, 'Total loss': 0.8267179370409081}
2022-11-18 00:41:36,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:36,502 INFO:     Epoch: 7
2022-11-18 00:41:37,274 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8136098344217647, 'Total loss': 0.8136098344217647} | train loss {'Reaction outcome loss': 0.823379775893833, 'Total loss': 0.823379775893833}
2022-11-18 00:41:37,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:37,274 INFO:     Epoch: 8
2022-11-18 00:41:38,118 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7994571091099218, 'Total loss': 0.7994571091099218} | train loss {'Reaction outcome loss': 0.8254507624427316, 'Total loss': 0.8254507624427316}
2022-11-18 00:41:38,118 INFO:     Found new best model at epoch 8
2022-11-18 00:41:38,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:38,119 INFO:     Epoch: 9
2022-11-18 00:41:38,932 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8006239546970888, 'Total loss': 0.8006239546970888} | train loss {'Reaction outcome loss': 0.8280342946409697, 'Total loss': 0.8280342946409697}
2022-11-18 00:41:38,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:38,932 INFO:     Epoch: 10
2022-11-18 00:41:39,735 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8336047442121939, 'Total loss': 0.8336047442121939} | train loss {'Reaction outcome loss': 0.8178120425596893, 'Total loss': 0.8178120425596893}
2022-11-18 00:41:39,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:39,736 INFO:     Epoch: 11
2022-11-18 00:41:40,520 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8192278688604181, 'Total loss': 0.8192278688604181} | train loss {'Reaction outcome loss': 0.8317399887662185, 'Total loss': 0.8317399887662185}
2022-11-18 00:41:40,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:40,520 INFO:     Epoch: 12
2022-11-18 00:41:41,346 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8279655304822054, 'Total loss': 0.8279655304822054} | train loss {'Reaction outcome loss': 0.8313797369659671, 'Total loss': 0.8313797369659671}
2022-11-18 00:41:41,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:41,346 INFO:     Epoch: 13
2022-11-18 00:41:42,212 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7985294535756111, 'Total loss': 0.7985294535756111} | train loss {'Reaction outcome loss': 0.8302349120016522, 'Total loss': 0.8302349120016522}
2022-11-18 00:41:42,212 INFO:     Found new best model at epoch 13
2022-11-18 00:41:42,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:42,213 INFO:     Epoch: 14
2022-11-18 00:41:43,002 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.809472921219739, 'Total loss': 0.809472921219739} | train loss {'Reaction outcome loss': 0.8224933283773028, 'Total loss': 0.8224933283773028}
2022-11-18 00:41:43,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:43,002 INFO:     Epoch: 15
2022-11-18 00:41:43,797 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8006596456874501, 'Total loss': 0.8006596456874501} | train loss {'Reaction outcome loss': 0.8267952557276135, 'Total loss': 0.8267952557276135}
2022-11-18 00:41:43,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:43,797 INFO:     Epoch: 16
2022-11-18 00:41:44,617 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7986987646330487, 'Total loss': 0.7986987646330487} | train loss {'Reaction outcome loss': 0.8154548299216066, 'Total loss': 0.8154548299216066}
2022-11-18 00:41:44,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:44,617 INFO:     Epoch: 17
2022-11-18 00:41:45,410 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8055173212831671, 'Total loss': 0.8055173212831671} | train loss {'Reaction outcome loss': 0.8212461724937686, 'Total loss': 0.8212461724937686}
2022-11-18 00:41:45,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:45,410 INFO:     Epoch: 18
2022-11-18 00:41:46,233 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8004458634690805, 'Total loss': 0.8004458634690805} | train loss {'Reaction outcome loss': 0.8192112340859556, 'Total loss': 0.8192112340859556}
2022-11-18 00:41:46,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:46,233 INFO:     Epoch: 19
2022-11-18 00:41:47,104 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8005881207910451, 'Total loss': 0.8005881207910451} | train loss {'Reaction outcome loss': 0.8215632828382345, 'Total loss': 0.8215632828382345}
2022-11-18 00:41:47,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:47,105 INFO:     Epoch: 20
2022-11-18 00:41:47,893 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8011907874183222, 'Total loss': 0.8011907874183222} | train loss {'Reaction outcome loss': 0.819503759806938, 'Total loss': 0.819503759806938}
2022-11-18 00:41:47,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:47,895 INFO:     Epoch: 21
2022-11-18 00:41:48,738 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8143211210315878, 'Total loss': 0.8143211210315878} | train loss {'Reaction outcome loss': 0.8148122556537751, 'Total loss': 0.8148122556537751}
2022-11-18 00:41:48,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:48,738 INFO:     Epoch: 22
2022-11-18 00:41:49,569 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.798270279710943, 'Total loss': 0.798270279710943} | train loss {'Reaction outcome loss': 0.8183750068610497, 'Total loss': 0.8183750068610497}
2022-11-18 00:41:49,569 INFO:     Found new best model at epoch 22
2022-11-18 00:41:49,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:49,570 INFO:     Epoch: 23
2022-11-18 00:41:50,412 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8025857603008096, 'Total loss': 0.8025857603008096} | train loss {'Reaction outcome loss': 0.8262453059918484, 'Total loss': 0.8262453059918484}
2022-11-18 00:41:50,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:50,413 INFO:     Epoch: 24
2022-11-18 00:41:51,227 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7965939356522127, 'Total loss': 0.7965939356522127} | train loss {'Reaction outcome loss': 0.8150201477864494, 'Total loss': 0.8150201477864494}
2022-11-18 00:41:51,227 INFO:     Found new best model at epoch 24
2022-11-18 00:41:51,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:51,228 INFO:     Epoch: 25
2022-11-18 00:41:52,055 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7947044914419, 'Total loss': 0.7947044914419} | train loss {'Reaction outcome loss': 0.8178236214255514, 'Total loss': 0.8178236214255514}
2022-11-18 00:41:52,056 INFO:     Found new best model at epoch 25
2022-11-18 00:41:52,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:52,056 INFO:     Epoch: 26
2022-11-18 00:41:52,848 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7973980253392999, 'Total loss': 0.7973980253392999} | train loss {'Reaction outcome loss': 0.8206641045417863, 'Total loss': 0.8206641045417863}
2022-11-18 00:41:52,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:52,849 INFO:     Epoch: 27
2022-11-18 00:41:53,608 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8072446923364293, 'Total loss': 0.8072446923364293} | train loss {'Reaction outcome loss': 0.8203343198246319, 'Total loss': 0.8203343198246319}
2022-11-18 00:41:53,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:53,608 INFO:     Epoch: 28
2022-11-18 00:41:54,377 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8063030039722269, 'Total loss': 0.8063030039722269} | train loss {'Reaction outcome loss': 0.8216798239150028, 'Total loss': 0.8216798239150028}
2022-11-18 00:41:54,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:54,378 INFO:     Epoch: 29
2022-11-18 00:41:55,151 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8008639426393942, 'Total loss': 0.8008639426393942} | train loss {'Reaction outcome loss': 0.8198594032270223, 'Total loss': 0.8198594032270223}
2022-11-18 00:41:55,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:55,151 INFO:     Epoch: 30
2022-11-18 00:41:55,959 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7904454063285481, 'Total loss': 0.7904454063285481} | train loss {'Reaction outcome loss': 0.8235509902359504, 'Total loss': 0.8235509902359504}
2022-11-18 00:41:55,959 INFO:     Found new best model at epoch 30
2022-11-18 00:41:55,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:55,960 INFO:     Epoch: 31
2022-11-18 00:41:56,760 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8378961289470847, 'Total loss': 0.8378961289470847} | train loss {'Reaction outcome loss': 0.8246831534362515, 'Total loss': 0.8246831534362515}
2022-11-18 00:41:56,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:56,761 INFO:     Epoch: 32
2022-11-18 00:41:57,539 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7967033359137449, 'Total loss': 0.7967033359137449} | train loss {'Reaction outcome loss': 0.8143541034356303, 'Total loss': 0.8143541034356303}
2022-11-18 00:41:57,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:57,540 INFO:     Epoch: 33
2022-11-18 00:41:58,362 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7874066938053478, 'Total loss': 0.7874066938053478} | train loss {'Reaction outcome loss': 0.8169603124562546, 'Total loss': 0.8169603124562546}
2022-11-18 00:41:58,362 INFO:     Found new best model at epoch 33
2022-11-18 00:41:58,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:58,363 INFO:     Epoch: 34
2022-11-18 00:41:59,166 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8174110508777879, 'Total loss': 0.8174110508777879} | train loss {'Reaction outcome loss': 0.8233725750735896, 'Total loss': 0.8233725750735896}
2022-11-18 00:41:59,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:59,167 INFO:     Epoch: 35
2022-11-18 00:41:59,985 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7935770099813287, 'Total loss': 0.7935770099813287} | train loss {'Reaction outcome loss': 0.8251502990481342, 'Total loss': 0.8251502990481342}
2022-11-18 00:41:59,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:41:59,985 INFO:     Epoch: 36
2022-11-18 00:42:00,831 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7995066568255424, 'Total loss': 0.7995066568255424} | train loss {'Reaction outcome loss': 0.819753170858028, 'Total loss': 0.819753170858028}
2022-11-18 00:42:00,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:00,831 INFO:     Epoch: 37
2022-11-18 00:42:01,647 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8175774338570508, 'Total loss': 0.8175774338570508} | train loss {'Reaction outcome loss': 0.81497014473807, 'Total loss': 0.81497014473807}
2022-11-18 00:42:01,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:01,647 INFO:     Epoch: 38
2022-11-18 00:42:02,478 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.797305436974222, 'Total loss': 0.797305436974222} | train loss {'Reaction outcome loss': 0.8225437681443295, 'Total loss': 0.8225437681443295}
2022-11-18 00:42:02,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:02,478 INFO:     Epoch: 39
2022-11-18 00:42:03,272 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8038015040484342, 'Total loss': 0.8038015040484342} | train loss {'Reaction outcome loss': 0.8225492532044528, 'Total loss': 0.8225492532044528}
2022-11-18 00:42:03,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:03,272 INFO:     Epoch: 40
2022-11-18 00:42:04,108 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7827322767539457, 'Total loss': 0.7827322767539457} | train loss {'Reaction outcome loss': 0.8241834908361859, 'Total loss': 0.8241834908361859}
2022-11-18 00:42:04,109 INFO:     Found new best model at epoch 40
2022-11-18 00:42:04,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:04,109 INFO:     Epoch: 41
2022-11-18 00:42:04,901 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8012118325992064, 'Total loss': 0.8012118325992064} | train loss {'Reaction outcome loss': 0.8251994168951444, 'Total loss': 0.8251994168951444}
2022-11-18 00:42:04,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:04,901 INFO:     Epoch: 42
2022-11-18 00:42:05,670 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8663570806384087, 'Total loss': 0.8663570806384087} | train loss {'Reaction outcome loss': 0.8210267197747945, 'Total loss': 0.8210267197747945}
2022-11-18 00:42:05,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:05,670 INFO:     Epoch: 43
2022-11-18 00:42:06,506 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8130042986436323, 'Total loss': 0.8130042986436323} | train loss {'Reaction outcome loss': 0.8154965939550747, 'Total loss': 0.8154965939550747}
2022-11-18 00:42:06,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:06,507 INFO:     Epoch: 44
2022-11-18 00:42:07,309 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8345157273791053, 'Total loss': 0.8345157273791053} | train loss {'Reaction outcome loss': 0.8251389186633261, 'Total loss': 0.8251389186633261}
2022-11-18 00:42:07,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:07,309 INFO:     Epoch: 45
2022-11-18 00:42:08,093 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.816392985934561, 'Total loss': 0.816392985934561} | train loss {'Reaction outcome loss': 0.8203327504970767, 'Total loss': 0.8203327504970767}
2022-11-18 00:42:08,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:08,093 INFO:     Epoch: 46
2022-11-18 00:42:08,928 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7950112088160082, 'Total loss': 0.7950112088160082} | train loss {'Reaction outcome loss': 0.825291078582949, 'Total loss': 0.825291078582949}
2022-11-18 00:42:08,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:08,929 INFO:     Epoch: 47
2022-11-18 00:42:09,714 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8037239028648897, 'Total loss': 0.8037239028648897} | train loss {'Reaction outcome loss': 0.8213449770863722, 'Total loss': 0.8213449770863722}
2022-11-18 00:42:09,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:09,714 INFO:     Epoch: 48
2022-11-18 00:42:10,514 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8210714141076262, 'Total loss': 0.8210714141076262} | train loss {'Reaction outcome loss': 0.8184624303449021, 'Total loss': 0.8184624303449021}
2022-11-18 00:42:10,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:10,514 INFO:     Epoch: 49
2022-11-18 00:42:11,328 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8036263232881372, 'Total loss': 0.8036263232881372} | train loss {'Reaction outcome loss': 0.8253501659704123, 'Total loss': 0.8253501659704123}
2022-11-18 00:42:11,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:11,329 INFO:     Epoch: 50
2022-11-18 00:42:12,128 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8018020797859539, 'Total loss': 0.8018020797859539} | train loss {'Reaction outcome loss': 0.8288618789510689, 'Total loss': 0.8288618789510689}
2022-11-18 00:42:12,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:12,129 INFO:     Epoch: 51
2022-11-18 00:42:12,948 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8445078906687823, 'Total loss': 0.8445078906687823} | train loss {'Reaction outcome loss': 0.8146399991654674, 'Total loss': 0.8146399991654674}
2022-11-18 00:42:12,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:12,948 INFO:     Epoch: 52
2022-11-18 00:42:13,749 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7921597964384339, 'Total loss': 0.7921597964384339} | train loss {'Reaction outcome loss': 0.8212059155890816, 'Total loss': 0.8212059155890816}
2022-11-18 00:42:13,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:13,750 INFO:     Epoch: 53
2022-11-18 00:42:14,544 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7998599762266333, 'Total loss': 0.7998599762266333} | train loss {'Reaction outcome loss': 0.822552299571906, 'Total loss': 0.822552299571906}
2022-11-18 00:42:14,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:14,544 INFO:     Epoch: 54
2022-11-18 00:42:15,361 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8079380724917758, 'Total loss': 0.8079380724917758} | train loss {'Reaction outcome loss': 0.8175514928302784, 'Total loss': 0.8175514928302784}
2022-11-18 00:42:15,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:15,361 INFO:     Epoch: 55
2022-11-18 00:42:16,188 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8020896125923503, 'Total loss': 0.8020896125923503} | train loss {'Reaction outcome loss': 0.8151054656819293, 'Total loss': 0.8151054656819293}
2022-11-18 00:42:16,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:16,189 INFO:     Epoch: 56
2022-11-18 00:42:17,002 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7936237434094603, 'Total loss': 0.7936237434094603} | train loss {'Reaction outcome loss': 0.812534233577821, 'Total loss': 0.812534233577821}
2022-11-18 00:42:17,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:17,002 INFO:     Epoch: 57
2022-11-18 00:42:17,792 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7959938577630303, 'Total loss': 0.7959938577630303} | train loss {'Reaction outcome loss': 0.8159797043814833, 'Total loss': 0.8159797043814833}
2022-11-18 00:42:17,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:17,793 INFO:     Epoch: 58
2022-11-18 00:42:18,602 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7917643717744134, 'Total loss': 0.7917643717744134} | train loss {'Reaction outcome loss': 0.8204973654949713, 'Total loss': 0.8204973654949713}
2022-11-18 00:42:18,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:18,603 INFO:     Epoch: 59
2022-11-18 00:42:19,420 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7923179512674158, 'Total loss': 0.7923179512674158} | train loss {'Reaction outcome loss': 0.8196879573739492, 'Total loss': 0.8196879573739492}
2022-11-18 00:42:19,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:19,421 INFO:     Epoch: 60
2022-11-18 00:42:20,216 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7922069897705858, 'Total loss': 0.7922069897705858} | train loss {'Reaction outcome loss': 0.8219130787289577, 'Total loss': 0.8219130787289577}
2022-11-18 00:42:20,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:20,217 INFO:     Epoch: 61
2022-11-18 00:42:21,022 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7946675419807434, 'Total loss': 0.7946675419807434} | train loss {'Reaction outcome loss': 0.8200865566489185, 'Total loss': 0.8200865566489185}
2022-11-18 00:42:21,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:21,023 INFO:     Epoch: 62
2022-11-18 00:42:21,831 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7953906960108064, 'Total loss': 0.7953906960108064} | train loss {'Reaction outcome loss': 0.8202260414115813, 'Total loss': 0.8202260414115813}
2022-11-18 00:42:21,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:21,832 INFO:     Epoch: 63
2022-11-18 00:42:22,627 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7822645584290678, 'Total loss': 0.7822645584290678} | train loss {'Reaction outcome loss': 0.8237232955602499, 'Total loss': 0.8237232955602499}
2022-11-18 00:42:22,627 INFO:     Found new best model at epoch 63
2022-11-18 00:42:22,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:22,628 INFO:     Epoch: 64
2022-11-18 00:42:23,463 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7961475659500469, 'Total loss': 0.7961475659500469} | train loss {'Reaction outcome loss': 0.8216837701285898, 'Total loss': 0.8216837701285898}
2022-11-18 00:42:23,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:23,463 INFO:     Epoch: 65
2022-11-18 00:42:24,313 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7765416062690995, 'Total loss': 0.7765416062690995} | train loss {'Reaction outcome loss': 0.8186404423388512, 'Total loss': 0.8186404423388512}
2022-11-18 00:42:24,313 INFO:     Found new best model at epoch 65
2022-11-18 00:42:24,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:24,314 INFO:     Epoch: 66
2022-11-18 00:42:25,121 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7966791987419128, 'Total loss': 0.7966791987419128} | train loss {'Reaction outcome loss': 0.8226644998861228, 'Total loss': 0.8226644998861228}
2022-11-18 00:42:25,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:25,121 INFO:     Epoch: 67
2022-11-18 00:42:25,943 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7903523180972446, 'Total loss': 0.7903523180972446} | train loss {'Reaction outcome loss': 0.8197809442923016, 'Total loss': 0.8197809442923016}
2022-11-18 00:42:25,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:25,944 INFO:     Epoch: 68
2022-11-18 00:42:26,768 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8026858080517162, 'Total loss': 0.8026858080517162} | train loss {'Reaction outcome loss': 0.8224239500186704, 'Total loss': 0.8224239500186704}
2022-11-18 00:42:26,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:26,768 INFO:     Epoch: 69
2022-11-18 00:42:27,643 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8027968366037715, 'Total loss': 0.8027968366037715} | train loss {'Reaction outcome loss': 0.818983213500938, 'Total loss': 0.818983213500938}
2022-11-18 00:42:27,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:27,643 INFO:     Epoch: 70
2022-11-18 00:42:28,505 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7919139814647761, 'Total loss': 0.7919139814647761} | train loss {'Reaction outcome loss': 0.8270643591156855, 'Total loss': 0.8270643591156855}
2022-11-18 00:42:28,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:28,505 INFO:     Epoch: 71
2022-11-18 00:42:29,389 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8113187531178648, 'Total loss': 0.8113187531178648} | train loss {'Reaction outcome loss': 0.8248527320290384, 'Total loss': 0.8248527320290384}
2022-11-18 00:42:29,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:29,390 INFO:     Epoch: 72
2022-11-18 00:42:30,205 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7934997508471663, 'Total loss': 0.7934997508471663} | train loss {'Reaction outcome loss': 0.819711415873848, 'Total loss': 0.819711415873848}
2022-11-18 00:42:30,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:30,206 INFO:     Epoch: 73
2022-11-18 00:42:31,043 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7929698181423274, 'Total loss': 0.7929698181423274} | train loss {'Reaction outcome loss': 0.820764722913383, 'Total loss': 0.820764722913383}
2022-11-18 00:42:31,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:31,043 INFO:     Epoch: 74
2022-11-18 00:42:31,922 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8054106282916936, 'Total loss': 0.8054106282916936} | train loss {'Reaction outcome loss': 0.8275436917055956, 'Total loss': 0.8275436917055956}
2022-11-18 00:42:31,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:31,922 INFO:     Epoch: 75
2022-11-18 00:42:32,733 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8004209913990714, 'Total loss': 0.8004209913990714} | train loss {'Reaction outcome loss': 0.8236866267586527, 'Total loss': 0.8236866267586527}
2022-11-18 00:42:32,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:32,734 INFO:     Epoch: 76
2022-11-18 00:42:33,577 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.807805560529232, 'Total loss': 0.807805560529232} | train loss {'Reaction outcome loss': 0.8247751949528451, 'Total loss': 0.8247751949528451}
2022-11-18 00:42:33,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:33,577 INFO:     Epoch: 77
2022-11-18 00:42:34,360 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8238697350025177, 'Total loss': 0.8238697350025177} | train loss {'Reaction outcome loss': 0.8264885840386997, 'Total loss': 0.8264885840386997}
2022-11-18 00:42:34,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:34,360 INFO:     Epoch: 78
2022-11-18 00:42:35,179 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8158091652122411, 'Total loss': 0.8158091652122411} | train loss {'Reaction outcome loss': 0.8171526401149116, 'Total loss': 0.8171526401149116}
2022-11-18 00:42:35,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:35,179 INFO:     Epoch: 79
2022-11-18 00:42:35,999 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8009994449940595, 'Total loss': 0.8009994449940595} | train loss {'Reaction outcome loss': 0.8205922895114914, 'Total loss': 0.8205922895114914}
2022-11-18 00:42:35,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:35,999 INFO:     Epoch: 80
2022-11-18 00:42:36,828 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8015852638266303, 'Total loss': 0.8015852638266303} | train loss {'Reaction outcome loss': 0.821715496691615, 'Total loss': 0.821715496691615}
2022-11-18 00:42:36,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:36,828 INFO:     Epoch: 81
2022-11-18 00:42:37,631 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8097417706793005, 'Total loss': 0.8097417706793005} | train loss {'Reaction outcome loss': 0.8286133628142508, 'Total loss': 0.8286133628142508}
2022-11-18 00:42:37,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:37,632 INFO:     Epoch: 82
2022-11-18 00:42:38,469 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8062457577748732, 'Total loss': 0.8062457577748732} | train loss {'Reaction outcome loss': 0.8211235116850509, 'Total loss': 0.8211235116850509}
2022-11-18 00:42:38,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:38,470 INFO:     Epoch: 83
2022-11-18 00:42:39,321 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7949875979260965, 'Total loss': 0.7949875979260965} | train loss {'Reaction outcome loss': 0.820325771520133, 'Total loss': 0.820325771520133}
2022-11-18 00:42:39,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:39,321 INFO:     Epoch: 84
2022-11-18 00:42:40,110 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7949763936075297, 'Total loss': 0.7949763936075297} | train loss {'Reaction outcome loss': 0.8141371379738395, 'Total loss': 0.8141371379738395}
2022-11-18 00:42:40,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:40,110 INFO:     Epoch: 85
2022-11-18 00:42:40,955 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7958339669487693, 'Total loss': 0.7958339669487693} | train loss {'Reaction outcome loss': 0.817624871185434, 'Total loss': 0.817624871185434}
2022-11-18 00:42:40,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:40,956 INFO:     Epoch: 86
2022-11-18 00:42:41,820 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8171426572582938, 'Total loss': 0.8171426572582938} | train loss {'Reaction outcome loss': 0.8254567119274062, 'Total loss': 0.8254567119274062}
2022-11-18 00:42:41,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:41,820 INFO:     Epoch: 87
2022-11-18 00:42:42,605 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8487768119031732, 'Total loss': 0.8487768119031732} | train loss {'Reaction outcome loss': 0.8219410267918699, 'Total loss': 0.8219410267918699}
2022-11-18 00:42:42,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:42,605 INFO:     Epoch: 88
2022-11-18 00:42:43,425 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8160690861669454, 'Total loss': 0.8160690861669454} | train loss {'Reaction outcome loss': 0.8187568300829725, 'Total loss': 0.8187568300829725}
2022-11-18 00:42:43,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:43,425 INFO:     Epoch: 89
2022-11-18 00:42:44,234 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7878755236213858, 'Total loss': 0.7878755236213858} | train loss {'Reaction outcome loss': 0.8170356109798679, 'Total loss': 0.8170356109798679}
2022-11-18 00:42:44,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:44,234 INFO:     Epoch: 90
2022-11-18 00:42:45,080 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8064588288014586, 'Total loss': 0.8064588288014586} | train loss {'Reaction outcome loss': 0.8166135289529075, 'Total loss': 0.8166135289529075}
2022-11-18 00:42:45,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:45,081 INFO:     Epoch: 91
2022-11-18 00:42:45,929 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7954465977170251, 'Total loss': 0.7954465977170251} | train loss {'Reaction outcome loss': 0.8183270555276138, 'Total loss': 0.8183270555276138}
2022-11-18 00:42:45,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:45,929 INFO:     Epoch: 92
2022-11-18 00:42:46,732 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8038026866587725, 'Total loss': 0.8038026866587725} | train loss {'Reaction outcome loss': 0.8200038118883666, 'Total loss': 0.8200038118883666}
2022-11-18 00:42:46,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:46,732 INFO:     Epoch: 93
2022-11-18 00:42:47,570 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8319192610003732, 'Total loss': 0.8319192610003732} | train loss {'Reaction outcome loss': 0.8201618022568192, 'Total loss': 0.8201618022568192}
2022-11-18 00:42:47,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:47,570 INFO:     Epoch: 94
2022-11-18 00:42:48,407 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8398785550485958, 'Total loss': 0.8398785550485958} | train loss {'Reaction outcome loss': 0.8197613099084692, 'Total loss': 0.8197613099084692}
2022-11-18 00:42:48,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:48,408 INFO:     Epoch: 95
2022-11-18 00:42:49,253 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8026224185119976, 'Total loss': 0.8026224185119976} | train loss {'Reaction outcome loss': 0.8249592195276306, 'Total loss': 0.8249592195276306}
2022-11-18 00:42:49,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:49,253 INFO:     Epoch: 96
2022-11-18 00:42:50,084 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8186945881355893, 'Total loss': 0.8186945881355893} | train loss {'Reaction outcome loss': 0.8231137007595557, 'Total loss': 0.8231137007595557}
2022-11-18 00:42:50,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:50,085 INFO:     Epoch: 97
2022-11-18 00:42:50,868 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8063065782189369, 'Total loss': 0.8063065782189369} | train loss {'Reaction outcome loss': 0.8219026708409853, 'Total loss': 0.8219026708409853}
2022-11-18 00:42:50,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:50,868 INFO:     Epoch: 98
2022-11-18 00:42:51,669 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.809249911795963, 'Total loss': 0.809249911795963} | train loss {'Reaction outcome loss': 0.8256750655801672, 'Total loss': 0.8256750655801672}
2022-11-18 00:42:51,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:51,669 INFO:     Epoch: 99
2022-11-18 00:42:52,438 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7952108823440291, 'Total loss': 0.7952108823440291} | train loss {'Reaction outcome loss': 0.8171746004448246, 'Total loss': 0.8171746004448246}
2022-11-18 00:42:52,439 INFO:     Best model found after epoch 66 of 100.
2022-11-18 00:42:52,439 INFO:   Done with stage: TRAINING
2022-11-18 00:42:52,439 INFO:   Starting stage: EVALUATION
2022-11-18 00:42:52,562 INFO:   Done with stage: EVALUATION
2022-11-18 00:42:52,562 INFO:   Leaving out SEQ value Fold_2
2022-11-18 00:42:52,575 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 00:42:52,575 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:42:53,243 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:42:53,243 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:42:53,313 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:42:53,314 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:42:53,314 INFO:     No hyperparam tuning for this model
2022-11-18 00:42:53,314 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:42:53,314 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:42:53,315 INFO:     None feature selector for col prot
2022-11-18 00:42:53,315 INFO:     None feature selector for col prot
2022-11-18 00:42:53,315 INFO:     None feature selector for col prot
2022-11-18 00:42:53,315 INFO:     None feature selector for col chem
2022-11-18 00:42:53,316 INFO:     None feature selector for col chem
2022-11-18 00:42:53,316 INFO:     None feature selector for col chem
2022-11-18 00:42:53,316 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:42:53,316 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:42:53,317 INFO:     Number of params in model 168571
2022-11-18 00:42:53,321 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:42:53,321 INFO:   Starting stage: TRAINING
2022-11-18 00:42:53,379 INFO:     Val loss before train {'Reaction outcome loss': 1.0214729288762265, 'Total loss': 1.0214729288762265}
2022-11-18 00:42:53,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:53,379 INFO:     Epoch: 0
2022-11-18 00:42:54,175 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8804857974702661, 'Total loss': 0.8804857974702661} | train loss {'Reaction outcome loss': 0.9015025730035743, 'Total loss': 0.9015025730035743}
2022-11-18 00:42:54,175 INFO:     Found new best model at epoch 0
2022-11-18 00:42:54,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:54,176 INFO:     Epoch: 1
2022-11-18 00:42:54,949 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8973650444637645, 'Total loss': 0.8973650444637645} | train loss {'Reaction outcome loss': 0.868962139742715, 'Total loss': 0.868962139742715}
2022-11-18 00:42:54,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:54,949 INFO:     Epoch: 2
2022-11-18 00:42:55,715 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9066109758886424, 'Total loss': 0.9066109758886424} | train loss {'Reaction outcome loss': 0.8581254682978805, 'Total loss': 0.8581254682978805}
2022-11-18 00:42:55,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:55,716 INFO:     Epoch: 3
2022-11-18 00:42:56,501 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8783773854374886, 'Total loss': 0.8783773854374886} | train loss {'Reaction outcome loss': 0.8602337771532487, 'Total loss': 0.8602337771532487}
2022-11-18 00:42:56,502 INFO:     Found new best model at epoch 3
2022-11-18 00:42:56,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:56,503 INFO:     Epoch: 4
2022-11-18 00:42:57,297 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9088750955733386, 'Total loss': 0.9088750955733386} | train loss {'Reaction outcome loss': 0.8616236051734613, 'Total loss': 0.8616236051734613}
2022-11-18 00:42:57,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:57,297 INFO:     Epoch: 5
2022-11-18 00:42:58,073 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8795979144898328, 'Total loss': 0.8795979144898328} | train loss {'Reaction outcome loss': 0.854124813542074, 'Total loss': 0.854124813542074}
2022-11-18 00:42:58,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:58,073 INFO:     Epoch: 6
2022-11-18 00:42:58,817 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8695905181494626, 'Total loss': 0.8695905181494626} | train loss {'Reaction outcome loss': 0.8502972572433706, 'Total loss': 0.8502972572433706}
2022-11-18 00:42:58,818 INFO:     Found new best model at epoch 6
2022-11-18 00:42:58,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:58,818 INFO:     Epoch: 7
2022-11-18 00:42:59,592 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8507009182463993, 'Total loss': 0.8507009182463993} | train loss {'Reaction outcome loss': 0.8457211922626107, 'Total loss': 0.8457211922626107}
2022-11-18 00:42:59,592 INFO:     Found new best model at epoch 7
2022-11-18 00:42:59,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:42:59,593 INFO:     Epoch: 8
2022-11-18 00:43:00,406 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8512803925709291, 'Total loss': 0.8512803925709291} | train loss {'Reaction outcome loss': 0.853013786856009, 'Total loss': 0.853013786856009}
2022-11-18 00:43:00,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:00,406 INFO:     Epoch: 9
2022-11-18 00:43:01,192 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8574214862151579, 'Total loss': 0.8574214862151579} | train loss {'Reaction outcome loss': 0.8485653143756243, 'Total loss': 0.8485653143756243}
2022-11-18 00:43:01,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:01,192 INFO:     Epoch: 10
2022-11-18 00:43:01,955 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8626771975647319, 'Total loss': 0.8626771975647319} | train loss {'Reaction outcome loss': 0.8426454019789793, 'Total loss': 0.8426454019789793}
2022-11-18 00:43:01,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:01,955 INFO:     Epoch: 11
2022-11-18 00:43:02,738 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8578121824698015, 'Total loss': 0.8578121824698015} | train loss {'Reaction outcome loss': 0.8420765060551313, 'Total loss': 0.8420765060551313}
2022-11-18 00:43:02,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:02,738 INFO:     Epoch: 12
2022-11-18 00:43:03,527 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8866173503073779, 'Total loss': 0.8866173503073779} | train loss {'Reaction outcome loss': 0.8469698145681498, 'Total loss': 0.8469698145681498}
2022-11-18 00:43:03,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:03,527 INFO:     Epoch: 13
2022-11-18 00:43:04,316 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8678383854302493, 'Total loss': 0.8678383854302493} | train loss {'Reaction outcome loss': 0.840270926149524, 'Total loss': 0.840270926149524}
2022-11-18 00:43:04,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:04,316 INFO:     Epoch: 14
2022-11-18 00:43:05,097 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.860658741810105, 'Total loss': 0.860658741810105} | train loss {'Reaction outcome loss': 0.8412488655168183, 'Total loss': 0.8412488655168183}
2022-11-18 00:43:05,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:05,097 INFO:     Epoch: 15
2022-11-18 00:43:05,911 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.859922122548927, 'Total loss': 0.859922122548927} | train loss {'Reaction outcome loss': 0.8359835231790738, 'Total loss': 0.8359835231790738}
2022-11-18 00:43:05,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:05,911 INFO:     Epoch: 16
2022-11-18 00:43:06,698 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8544212037866766, 'Total loss': 0.8544212037866766} | train loss {'Reaction outcome loss': 0.8417599347172952, 'Total loss': 0.8417599347172952}
2022-11-18 00:43:06,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:06,698 INFO:     Epoch: 17
2022-11-18 00:43:07,498 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8748220645568587, 'Total loss': 0.8748220645568587} | train loss {'Reaction outcome loss': 0.8339240664122056, 'Total loss': 0.8339240664122056}
2022-11-18 00:43:07,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:07,498 INFO:     Epoch: 18
2022-11-18 00:43:08,270 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8854587498036298, 'Total loss': 0.8854587498036298} | train loss {'Reaction outcome loss': 0.8333931138320845, 'Total loss': 0.8333931138320845}
2022-11-18 00:43:08,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:08,270 INFO:     Epoch: 19
2022-11-18 00:43:09,064 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8666216527873819, 'Total loss': 0.8666216527873819} | train loss {'Reaction outcome loss': 0.8363797579492841, 'Total loss': 0.8363797579492841}
2022-11-18 00:43:09,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:09,065 INFO:     Epoch: 20
2022-11-18 00:43:09,879 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8543399436907335, 'Total loss': 0.8543399436907335} | train loss {'Reaction outcome loss': 0.8400105179572592, 'Total loss': 0.8400105179572592}
2022-11-18 00:43:09,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:09,879 INFO:     Epoch: 21
2022-11-18 00:43:10,650 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8496278077363968, 'Total loss': 0.8496278077363968} | train loss {'Reaction outcome loss': 0.8427769432262499, 'Total loss': 0.8427769432262499}
2022-11-18 00:43:10,650 INFO:     Found new best model at epoch 21
2022-11-18 00:43:10,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:10,651 INFO:     Epoch: 22
2022-11-18 00:43:11,452 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8909630463881926, 'Total loss': 0.8909630463881926} | train loss {'Reaction outcome loss': 0.8347425309370975, 'Total loss': 0.8347425309370975}
2022-11-18 00:43:11,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:11,452 INFO:     Epoch: 23
2022-11-18 00:43:12,210 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8538728789849714, 'Total loss': 0.8538728789849714} | train loss {'Reaction outcome loss': 0.8337638237038437, 'Total loss': 0.8337638237038437}
2022-11-18 00:43:12,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:12,210 INFO:     Epoch: 24
2022-11-18 00:43:13,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8544847680763765, 'Total loss': 0.8544847680763765} | train loss {'Reaction outcome loss': 0.8336863582231561, 'Total loss': 0.8336863582231561}
2022-11-18 00:43:13,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:13,028 INFO:     Epoch: 25
2022-11-18 00:43:13,837 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.843880379741842, 'Total loss': 0.843880379741842} | train loss {'Reaction outcome loss': 0.8383730629268957, 'Total loss': 0.8383730629268957}
2022-11-18 00:43:13,837 INFO:     Found new best model at epoch 25
2022-11-18 00:43:13,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:13,838 INFO:     Epoch: 26
2022-11-18 00:43:14,612 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8469242609360002, 'Total loss': 0.8469242609360002} | train loss {'Reaction outcome loss': 0.8366646997782649, 'Total loss': 0.8366646997782649}
2022-11-18 00:43:14,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:14,612 INFO:     Epoch: 27
2022-11-18 00:43:15,371 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.880423637276346, 'Total loss': 0.880423637276346} | train loss {'Reaction outcome loss': 0.8347474118884729, 'Total loss': 0.8347474118884729}
2022-11-18 00:43:15,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:15,371 INFO:     Epoch: 28
2022-11-18 00:43:16,182 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8518245870416815, 'Total loss': 0.8518245870416815} | train loss {'Reaction outcome loss': 0.8421573800700052, 'Total loss': 0.8421573800700052}
2022-11-18 00:43:16,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:16,182 INFO:     Epoch: 29
2022-11-18 00:43:17,059 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8521266051314094, 'Total loss': 0.8521266051314094} | train loss {'Reaction outcome loss': 0.8316630794077503, 'Total loss': 0.8316630794077503}
2022-11-18 00:43:17,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:17,060 INFO:     Epoch: 30
2022-11-18 00:43:17,868 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8450482568957589, 'Total loss': 0.8450482568957589} | train loss {'Reaction outcome loss': 0.8360450970883272, 'Total loss': 0.8360450970883272}
2022-11-18 00:43:17,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:17,868 INFO:     Epoch: 31
2022-11-18 00:43:18,709 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8437683399428021, 'Total loss': 0.8437683399428021} | train loss {'Reaction outcome loss': 0.8307332027931602, 'Total loss': 0.8307332027931602}
2022-11-18 00:43:18,709 INFO:     Found new best model at epoch 31
2022-11-18 00:43:18,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:18,710 INFO:     Epoch: 32
2022-11-18 00:43:19,540 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8611261438239705, 'Total loss': 0.8611261438239705} | train loss {'Reaction outcome loss': 0.8311700080122266, 'Total loss': 0.8311700080122266}
2022-11-18 00:43:19,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:19,541 INFO:     Epoch: 33
2022-11-18 00:43:20,338 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8533387075770985, 'Total loss': 0.8533387075770985} | train loss {'Reaction outcome loss': 0.8309660414043738, 'Total loss': 0.8309660414043738}
2022-11-18 00:43:20,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:20,339 INFO:     Epoch: 34
2022-11-18 00:43:21,129 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8351686044850133, 'Total loss': 0.8351686044850133} | train loss {'Reaction outcome loss': 0.8323970135377378, 'Total loss': 0.8323970135377378}
2022-11-18 00:43:21,129 INFO:     Found new best model at epoch 34
2022-11-18 00:43:21,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:21,130 INFO:     Epoch: 35
2022-11-18 00:43:21,959 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8782400014725599, 'Total loss': 0.8782400014725599} | train loss {'Reaction outcome loss': 0.832544008809693, 'Total loss': 0.832544008809693}
2022-11-18 00:43:21,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:21,961 INFO:     Epoch: 36
2022-11-18 00:43:22,772 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8446724089709196, 'Total loss': 0.8446724089709196} | train loss {'Reaction outcome loss': 0.8338525538541832, 'Total loss': 0.8338525538541832}
2022-11-18 00:43:22,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:22,772 INFO:     Epoch: 37
2022-11-18 00:43:23,604 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8360570652241056, 'Total loss': 0.8360570652241056} | train loss {'Reaction outcome loss': 0.832643385687653, 'Total loss': 0.832643385687653}
2022-11-18 00:43:23,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:23,604 INFO:     Epoch: 38
2022-11-18 00:43:24,429 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8671247166666117, 'Total loss': 0.8671247166666117} | train loss {'Reaction outcome loss': 0.8346693851509873, 'Total loss': 0.8346693851509873}
2022-11-18 00:43:24,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:24,429 INFO:     Epoch: 39
2022-11-18 00:43:25,223 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8461339683695273, 'Total loss': 0.8461339683695273} | train loss {'Reaction outcome loss': 0.8293960489788834, 'Total loss': 0.8293960489788834}
2022-11-18 00:43:25,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:25,223 INFO:     Epoch: 40
2022-11-18 00:43:26,041 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8418942987918854, 'Total loss': 0.8418942987918854} | train loss {'Reaction outcome loss': 0.8299361625496222, 'Total loss': 0.8299361625496222}
2022-11-18 00:43:26,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:26,041 INFO:     Epoch: 41
2022-11-18 00:43:26,869 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8714560060338541, 'Total loss': 0.8714560060338541} | train loss {'Reaction outcome loss': 0.8307264231905646, 'Total loss': 0.8307264231905646}
2022-11-18 00:43:26,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:26,870 INFO:     Epoch: 42
2022-11-18 00:43:27,683 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.858878416093913, 'Total loss': 0.858878416093913} | train loss {'Reaction outcome loss': 0.8307190538669119, 'Total loss': 0.8307190538669119}
2022-11-18 00:43:27,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:27,683 INFO:     Epoch: 43
2022-11-18 00:43:28,492 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8390889370983298, 'Total loss': 0.8390889370983298} | train loss {'Reaction outcome loss': 0.8272280116470493, 'Total loss': 0.8272280116470493}
2022-11-18 00:43:28,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:28,493 INFO:     Epoch: 44
2022-11-18 00:43:29,318 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8538548695770177, 'Total loss': 0.8538548695770177} | train loss {'Reaction outcome loss': 0.8311245355070854, 'Total loss': 0.8311245355070854}
2022-11-18 00:43:29,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:29,318 INFO:     Epoch: 45
2022-11-18 00:43:30,107 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8429108295928348, 'Total loss': 0.8429108295928348} | train loss {'Reaction outcome loss': 0.8300158189267528, 'Total loss': 0.8300158189267528}
2022-11-18 00:43:30,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:30,107 INFO:     Epoch: 46
2022-11-18 00:43:30,908 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8734202615239404, 'Total loss': 0.8734202615239404} | train loss {'Reaction outcome loss': 0.8302583633636942, 'Total loss': 0.8302583633636942}
2022-11-18 00:43:30,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:30,909 INFO:     Epoch: 47
2022-11-18 00:43:31,730 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8485488573258574, 'Total loss': 0.8485488573258574} | train loss {'Reaction outcome loss': 0.8275092514193788, 'Total loss': 0.8275092514193788}
2022-11-18 00:43:31,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:31,730 INFO:     Epoch: 48
2022-11-18 00:43:32,539 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8746960616924546, 'Total loss': 0.8746960616924546} | train loss {'Reaction outcome loss': 0.82863068726598, 'Total loss': 0.82863068726598}
2022-11-18 00:43:32,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:32,539 INFO:     Epoch: 49
2022-11-18 00:43:33,320 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.847926527261734, 'Total loss': 0.847926527261734} | train loss {'Reaction outcome loss': 0.8295422940838094, 'Total loss': 0.8295422940838094}
2022-11-18 00:43:33,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:33,320 INFO:     Epoch: 50
2022-11-18 00:43:34,170 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8710732785138217, 'Total loss': 0.8710732785138217} | train loss {'Reaction outcome loss': 0.8318803569492028, 'Total loss': 0.8318803569492028}
2022-11-18 00:43:34,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:34,170 INFO:     Epoch: 51
2022-11-18 00:43:34,947 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8785282773050395, 'Total loss': 0.8785282773050395} | train loss {'Reaction outcome loss': 0.8296685402490654, 'Total loss': 0.8296685402490654}
2022-11-18 00:43:34,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:34,947 INFO:     Epoch: 52
2022-11-18 00:43:35,743 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8787634995850649, 'Total loss': 0.8787634995850649} | train loss {'Reaction outcome loss': 0.8324038467845138, 'Total loss': 0.8324038467845138}
2022-11-18 00:43:35,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:35,743 INFO:     Epoch: 53
2022-11-18 00:43:36,552 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8651449531316757, 'Total loss': 0.8651449531316757} | train loss {'Reaction outcome loss': 0.8310812570610825, 'Total loss': 0.8310812570610825}
2022-11-18 00:43:36,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:36,552 INFO:     Epoch: 54
2022-11-18 00:43:37,331 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8614987392317165, 'Total loss': 0.8614987392317165} | train loss {'Reaction outcome loss': 0.8279905408012623, 'Total loss': 0.8279905408012623}
2022-11-18 00:43:37,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:37,331 INFO:     Epoch: 55
2022-11-18 00:43:38,144 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8474565839225595, 'Total loss': 0.8474565839225595} | train loss {'Reaction outcome loss': 0.8288208487082501, 'Total loss': 0.8288208487082501}
2022-11-18 00:43:38,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:38,144 INFO:     Epoch: 56
2022-11-18 00:43:38,934 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8626456355506723, 'Total loss': 0.8626456355506723} | train loss {'Reaction outcome loss': 0.8286554231935618, 'Total loss': 0.8286554231935618}
2022-11-18 00:43:38,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:38,934 INFO:     Epoch: 57
2022-11-18 00:43:39,758 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8599164228547703, 'Total loss': 0.8599164228547703} | train loss {'Reaction outcome loss': 0.8250590750149318, 'Total loss': 0.8250590750149318}
2022-11-18 00:43:39,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:39,758 INFO:     Epoch: 58
2022-11-18 00:43:40,572 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8406176377426494, 'Total loss': 0.8406176377426494} | train loss {'Reaction outcome loss': 0.8276215953486307, 'Total loss': 0.8276215953486307}
2022-11-18 00:43:40,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:40,574 INFO:     Epoch: 59
2022-11-18 00:43:41,395 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8494954434308138, 'Total loss': 0.8494954434308138} | train loss {'Reaction outcome loss': 0.8264404455009772, 'Total loss': 0.8264404455009772}
2022-11-18 00:43:41,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:41,395 INFO:     Epoch: 60
2022-11-18 00:43:42,196 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8596460372209549, 'Total loss': 0.8596460372209549} | train loss {'Reaction outcome loss': 0.8254604221606742, 'Total loss': 0.8254604221606742}
2022-11-18 00:43:42,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:42,196 INFO:     Epoch: 61
2022-11-18 00:43:43,000 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8385566605085676, 'Total loss': 0.8385566605085676} | train loss {'Reaction outcome loss': 0.825827163944439, 'Total loss': 0.825827163944439}
2022-11-18 00:43:43,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:43,000 INFO:     Epoch: 62
2022-11-18 00:43:43,867 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8499760045246645, 'Total loss': 0.8499760045246645} | train loss {'Reaction outcome loss': 0.8276101280231865, 'Total loss': 0.8276101280231865}
2022-11-18 00:43:43,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:43,867 INFO:     Epoch: 63
2022-11-18 00:43:44,689 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.832489898936315, 'Total loss': 0.832489898936315} | train loss {'Reaction outcome loss': 0.8212781530253741, 'Total loss': 0.8212781530253741}
2022-11-18 00:43:44,689 INFO:     Found new best model at epoch 63
2022-11-18 00:43:44,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:44,690 INFO:     Epoch: 64
2022-11-18 00:43:45,528 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8244122490286827, 'Total loss': 0.8244122490286827} | train loss {'Reaction outcome loss': 0.8270415627226537, 'Total loss': 0.8270415627226537}
2022-11-18 00:43:45,529 INFO:     Found new best model at epoch 64
2022-11-18 00:43:45,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:45,529 INFO:     Epoch: 65
2022-11-18 00:43:46,343 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8552476973696188, 'Total loss': 0.8552476973696188} | train loss {'Reaction outcome loss': 0.8222246830560723, 'Total loss': 0.8222246830560723}
2022-11-18 00:43:46,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:46,344 INFO:     Epoch: 66
2022-11-18 00:43:47,121 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8361772711981427, 'Total loss': 0.8361772711981427} | train loss {'Reaction outcome loss': 0.8236560753413609, 'Total loss': 0.8236560753413609}
2022-11-18 00:43:47,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:47,121 INFO:     Epoch: 67
2022-11-18 00:43:47,963 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8386939411813562, 'Total loss': 0.8386939411813562} | train loss {'Reaction outcome loss': 0.8218243293616236, 'Total loss': 0.8218243293616236}
2022-11-18 00:43:47,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:47,963 INFO:     Epoch: 68
2022-11-18 00:43:48,740 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8303754012185064, 'Total loss': 0.8303754012185064} | train loss {'Reaction outcome loss': 0.8172830115775673, 'Total loss': 0.8172830115775673}
2022-11-18 00:43:48,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:48,740 INFO:     Epoch: 69
2022-11-18 00:43:49,556 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8656386915933002, 'Total loss': 0.8656386915933002} | train loss {'Reaction outcome loss': 0.814794006274671, 'Total loss': 0.814794006274671}
2022-11-18 00:43:49,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:49,556 INFO:     Epoch: 70
2022-11-18 00:43:50,349 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8401404964652929, 'Total loss': 0.8401404964652929} | train loss {'Reaction outcome loss': 0.8186186325793363, 'Total loss': 0.8186186325793363}
2022-11-18 00:43:50,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:50,350 INFO:     Epoch: 71
2022-11-18 00:43:51,173 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.840864400294694, 'Total loss': 0.840864400294694} | train loss {'Reaction outcome loss': 0.8229509052573418, 'Total loss': 0.8229509052573418}
2022-11-18 00:43:51,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:51,173 INFO:     Epoch: 72
2022-11-18 00:43:51,981 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8367539603601802, 'Total loss': 0.8367539603601802} | train loss {'Reaction outcome loss': 0.8205778005171795, 'Total loss': 0.8205778005171795}
2022-11-18 00:43:51,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:51,981 INFO:     Epoch: 73
2022-11-18 00:43:52,793 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8387452960014343, 'Total loss': 0.8387452960014343} | train loss {'Reaction outcome loss': 0.8145728043147495, 'Total loss': 0.8145728043147495}
2022-11-18 00:43:52,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:52,794 INFO:     Epoch: 74
2022-11-18 00:43:53,586 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8342566588385538, 'Total loss': 0.8342566588385538} | train loss {'Reaction outcome loss': 0.8152885180346819, 'Total loss': 0.8152885180346819}
2022-11-18 00:43:53,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:53,586 INFO:     Epoch: 75
2022-11-18 00:43:54,386 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8199545842680064, 'Total loss': 0.8199545842680064} | train loss {'Reaction outcome loss': 0.8123564063286295, 'Total loss': 0.8123564063286295}
2022-11-18 00:43:54,386 INFO:     Found new best model at epoch 75
2022-11-18 00:43:54,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:54,387 INFO:     Epoch: 76
2022-11-18 00:43:55,205 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8418157425793734, 'Total loss': 0.8418157425793734} | train loss {'Reaction outcome loss': 0.8105218313178237, 'Total loss': 0.8105218313178237}
2022-11-18 00:43:55,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:55,205 INFO:     Epoch: 77
2022-11-18 00:43:56,019 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8197302371263504, 'Total loss': 0.8197302371263504} | train loss {'Reaction outcome loss': 0.8092914718754437, 'Total loss': 0.8092914718754437}
2022-11-18 00:43:56,019 INFO:     Found new best model at epoch 77
2022-11-18 00:43:56,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:56,020 INFO:     Epoch: 78
2022-11-18 00:43:56,814 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8633276197043332, 'Total loss': 0.8633276197043332} | train loss {'Reaction outcome loss': 0.8113566785442586, 'Total loss': 0.8113566785442586}
2022-11-18 00:43:56,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:56,815 INFO:     Epoch: 79
2022-11-18 00:43:57,634 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8239367719401013, 'Total loss': 0.8239367719401013} | train loss {'Reaction outcome loss': 0.8145043043457731, 'Total loss': 0.8145043043457731}
2022-11-18 00:43:57,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:57,634 INFO:     Epoch: 80
2022-11-18 00:43:58,429 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.827498465099118, 'Total loss': 0.827498465099118} | train loss {'Reaction outcome loss': 0.8129151326052997, 'Total loss': 0.8129151326052997}
2022-11-18 00:43:58,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:58,429 INFO:     Epoch: 81
2022-11-18 00:43:59,210 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8357329653068022, 'Total loss': 0.8357329653068022} | train loss {'Reaction outcome loss': 0.8095944220314221, 'Total loss': 0.8095944220314221}
2022-11-18 00:43:59,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:59,211 INFO:     Epoch: 82
2022-11-18 00:43:59,985 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8824887884442102, 'Total loss': 0.8824887884442102} | train loss {'Reaction outcome loss': 0.8084410402239586, 'Total loss': 0.8084410402239586}
2022-11-18 00:43:59,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:43:59,986 INFO:     Epoch: 83
2022-11-18 00:44:00,786 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8280888629907911, 'Total loss': 0.8280888629907911} | train loss {'Reaction outcome loss': 0.8159988646604577, 'Total loss': 0.8159988646604577}
2022-11-18 00:44:00,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:00,786 INFO:     Epoch: 84
2022-11-18 00:44:01,612 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8371162455190312, 'Total loss': 0.8371162455190312} | train loss {'Reaction outcome loss': 0.8096936711243221, 'Total loss': 0.8096936711243221}
2022-11-18 00:44:01,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:01,612 INFO:     Epoch: 85
2022-11-18 00:44:02,440 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.822392768480561, 'Total loss': 0.822392768480561} | train loss {'Reaction outcome loss': 0.8090165518984502, 'Total loss': 0.8090165518984502}
2022-11-18 00:44:02,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:02,440 INFO:     Epoch: 86
2022-11-18 00:44:03,237 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8200550038706172, 'Total loss': 0.8200550038706172} | train loss {'Reaction outcome loss': 0.8080503741089179, 'Total loss': 0.8080503741089179}
2022-11-18 00:44:03,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:03,237 INFO:     Epoch: 87
2022-11-18 00:44:04,024 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.845382689752362, 'Total loss': 0.845382689752362} | train loss {'Reaction outcome loss': 0.8056185282006556, 'Total loss': 0.8056185282006556}
2022-11-18 00:44:04,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:04,024 INFO:     Epoch: 88
2022-11-18 00:44:04,851 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.836562192575498, 'Total loss': 0.836562192575498} | train loss {'Reaction outcome loss': 0.8018412902647135, 'Total loss': 0.8018412902647135}
2022-11-18 00:44:04,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:04,851 INFO:     Epoch: 89
2022-11-18 00:44:05,686 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8441686684435065, 'Total loss': 0.8441686684435065} | train loss {'Reaction outcome loss': 0.8063187240337839, 'Total loss': 0.8063187240337839}
2022-11-18 00:44:05,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:05,686 INFO:     Epoch: 90
2022-11-18 00:44:06,498 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8232096006924455, 'Total loss': 0.8232096006924455} | train loss {'Reaction outcome loss': 0.8048641218214619, 'Total loss': 0.8048641218214619}
2022-11-18 00:44:06,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:06,498 INFO:     Epoch: 91
2022-11-18 00:44:07,330 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8291308290579102, 'Total loss': 0.8291308290579102} | train loss {'Reaction outcome loss': 0.8035803640375332, 'Total loss': 0.8035803640375332}
2022-11-18 00:44:07,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:07,330 INFO:     Epoch: 92
2022-11-18 00:44:08,128 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.815858741375533, 'Total loss': 0.815858741375533} | train loss {'Reaction outcome loss': 0.7958306655591848, 'Total loss': 0.7958306655591848}
2022-11-18 00:44:08,128 INFO:     Found new best model at epoch 92
2022-11-18 00:44:08,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:08,129 INFO:     Epoch: 93
2022-11-18 00:44:08,958 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8082280253822153, 'Total loss': 0.8082280253822153} | train loss {'Reaction outcome loss': 0.8019562838028889, 'Total loss': 0.8019562838028889}
2022-11-18 00:44:08,959 INFO:     Found new best model at epoch 93
2022-11-18 00:44:08,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:08,959 INFO:     Epoch: 94
2022-11-18 00:44:09,785 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8133759329264815, 'Total loss': 0.8133759329264815} | train loss {'Reaction outcome loss': 0.7904820417871281, 'Total loss': 0.7904820417871281}
2022-11-18 00:44:09,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:09,786 INFO:     Epoch: 95
2022-11-18 00:44:10,569 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7905336347493258, 'Total loss': 0.7905336347493258} | train loss {'Reaction outcome loss': 0.7971480693135943, 'Total loss': 0.7971480693135943}
2022-11-18 00:44:10,569 INFO:     Found new best model at epoch 95
2022-11-18 00:44:10,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:10,570 INFO:     Epoch: 96
2022-11-18 00:44:11,387 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8059345930814743, 'Total loss': 0.8059345930814743} | train loss {'Reaction outcome loss': 0.7866052498622816, 'Total loss': 0.7866052498622816}
2022-11-18 00:44:11,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:11,388 INFO:     Epoch: 97
2022-11-18 00:44:12,174 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7949619916352358, 'Total loss': 0.7949619916352358} | train loss {'Reaction outcome loss': 0.7889004595425664, 'Total loss': 0.7889004595425664}
2022-11-18 00:44:12,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:12,175 INFO:     Epoch: 98
2022-11-18 00:44:12,992 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7965166226706721, 'Total loss': 0.7965166226706721} | train loss {'Reaction outcome loss': 0.7768608137052886, 'Total loss': 0.7768608137052886}
2022-11-18 00:44:12,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:12,993 INFO:     Epoch: 99
2022-11-18 00:44:13,834 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7936758256771348, 'Total loss': 0.7936758256771348} | train loss {'Reaction outcome loss': 0.7711423007809386, 'Total loss': 0.7711423007809386}
2022-11-18 00:44:13,834 INFO:     Best model found after epoch 96 of 100.
2022-11-18 00:44:13,834 INFO:   Done with stage: TRAINING
2022-11-18 00:44:13,834 INFO:   Starting stage: EVALUATION
2022-11-18 00:44:13,964 INFO:   Done with stage: EVALUATION
2022-11-18 00:44:13,964 INFO:   Leaving out SEQ value Fold_3
2022-11-18 00:44:13,977 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 00:44:13,977 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:44:14,647 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:44:14,647 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:44:14,717 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:44:14,717 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:44:14,717 INFO:     No hyperparam tuning for this model
2022-11-18 00:44:14,717 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:44:14,718 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:44:14,718 INFO:     None feature selector for col prot
2022-11-18 00:44:14,718 INFO:     None feature selector for col prot
2022-11-18 00:44:14,719 INFO:     None feature selector for col prot
2022-11-18 00:44:14,719 INFO:     None feature selector for col chem
2022-11-18 00:44:14,719 INFO:     None feature selector for col chem
2022-11-18 00:44:14,719 INFO:     None feature selector for col chem
2022-11-18 00:44:14,720 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:44:14,720 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:44:14,721 INFO:     Number of params in model 168571
2022-11-18 00:44:14,724 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:44:14,724 INFO:   Starting stage: TRAINING
2022-11-18 00:44:14,783 INFO:     Val loss before train {'Reaction outcome loss': 1.0025443365407545, 'Total loss': 1.0025443365407545}
2022-11-18 00:44:14,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:14,783 INFO:     Epoch: 0
2022-11-18 00:44:15,594 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8585584926050763, 'Total loss': 0.8585584926050763} | train loss {'Reaction outcome loss': 0.8712878346321036, 'Total loss': 0.8712878346321036}
2022-11-18 00:44:15,594 INFO:     Found new best model at epoch 0
2022-11-18 00:44:15,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:15,595 INFO:     Epoch: 1
2022-11-18 00:44:16,374 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.854417854963347, 'Total loss': 0.854417854963347} | train loss {'Reaction outcome loss': 0.8351955353969434, 'Total loss': 0.8351955353969434}
2022-11-18 00:44:16,375 INFO:     Found new best model at epoch 1
2022-11-18 00:44:16,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:16,375 INFO:     Epoch: 2
2022-11-18 00:44:17,172 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8690092487390652, 'Total loss': 0.8690092487390652} | train loss {'Reaction outcome loss': 0.8303784627894886, 'Total loss': 0.8303784627894886}
2022-11-18 00:44:17,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:17,172 INFO:     Epoch: 3
2022-11-18 00:44:17,953 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.896548377913098, 'Total loss': 0.896548377913098} | train loss {'Reaction outcome loss': 0.8257258574737877, 'Total loss': 0.8257258574737877}
2022-11-18 00:44:17,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:17,953 INFO:     Epoch: 4
2022-11-18 00:44:18,797 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8512591553288836, 'Total loss': 0.8512591553288836} | train loss {'Reaction outcome loss': 0.8205791631194411, 'Total loss': 0.8205791631194411}
2022-11-18 00:44:18,798 INFO:     Found new best model at epoch 4
2022-11-18 00:44:18,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:18,798 INFO:     Epoch: 5
2022-11-18 00:44:19,595 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8433371006056319, 'Total loss': 0.8433371006056319} | train loss {'Reaction outcome loss': 0.8187171824154307, 'Total loss': 0.8187171824154307}
2022-11-18 00:44:19,595 INFO:     Found new best model at epoch 5
2022-11-18 00:44:19,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:19,596 INFO:     Epoch: 6
2022-11-18 00:44:20,372 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8644191165303075, 'Total loss': 0.8644191165303075} | train loss {'Reaction outcome loss': 0.8136908374116069, 'Total loss': 0.8136908374116069}
2022-11-18 00:44:20,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:20,372 INFO:     Epoch: 7
2022-11-18 00:44:21,158 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8551271647907966, 'Total loss': 0.8551271647907966} | train loss {'Reaction outcome loss': 0.8077690343632072, 'Total loss': 0.8077690343632072}
2022-11-18 00:44:21,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:21,158 INFO:     Epoch: 8
2022-11-18 00:44:21,935 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8430628734965657, 'Total loss': 0.8430628734965657} | train loss {'Reaction outcome loss': 0.8129373427297248, 'Total loss': 0.8129373427297248}
2022-11-18 00:44:21,935 INFO:     Found new best model at epoch 8
2022-11-18 00:44:21,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:21,936 INFO:     Epoch: 9
2022-11-18 00:44:22,705 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8420633895452633, 'Total loss': 0.8420633895452633} | train loss {'Reaction outcome loss': 0.8117334970929584, 'Total loss': 0.8117334970929584}
2022-11-18 00:44:22,705 INFO:     Found new best model at epoch 9
2022-11-18 00:44:22,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:22,706 INFO:     Epoch: 10
2022-11-18 00:44:23,522 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8556868669598602, 'Total loss': 0.8556868669598602} | train loss {'Reaction outcome loss': 0.8081269796754493, 'Total loss': 0.8081269796754493}
2022-11-18 00:44:23,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:23,524 INFO:     Epoch: 11
2022-11-18 00:44:24,334 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8503398250701816, 'Total loss': 0.8503398250701816} | train loss {'Reaction outcome loss': 0.8073218897229335, 'Total loss': 0.8073218897229335}
2022-11-18 00:44:24,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:24,334 INFO:     Epoch: 12
2022-11-18 00:44:25,140 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8627444810645525, 'Total loss': 0.8627444810645525} | train loss {'Reaction outcome loss': 0.8063706146156202, 'Total loss': 0.8063706146156202}
2022-11-18 00:44:25,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:25,140 INFO:     Epoch: 13
2022-11-18 00:44:25,965 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8305259915285332, 'Total loss': 0.8305259915285332} | train loss {'Reaction outcome loss': 0.8069737407027698, 'Total loss': 0.8069737407027698}
2022-11-18 00:44:25,966 INFO:     Found new best model at epoch 13
2022-11-18 00:44:25,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:25,966 INFO:     Epoch: 14
2022-11-18 00:44:26,755 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.840176964915076, 'Total loss': 0.840176964915076} | train loss {'Reaction outcome loss': 0.8098901862003764, 'Total loss': 0.8098901862003764}
2022-11-18 00:44:26,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:26,755 INFO:     Epoch: 15
2022-11-18 00:44:27,562 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.851217856240827, 'Total loss': 0.851217856240827} | train loss {'Reaction outcome loss': 0.8083932619602954, 'Total loss': 0.8083932619602954}
2022-11-18 00:44:27,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:27,562 INFO:     Epoch: 16
2022-11-18 00:44:28,381 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8366935038289358, 'Total loss': 0.8366935038289358} | train loss {'Reaction outcome loss': 0.802373577336796, 'Total loss': 0.802373577336796}
2022-11-18 00:44:28,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:28,381 INFO:     Epoch: 17
2022-11-18 00:44:29,189 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8381491525228634, 'Total loss': 0.8381491525228634} | train loss {'Reaction outcome loss': 0.7992480814945503, 'Total loss': 0.7992480814945503}
2022-11-18 00:44:29,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:29,190 INFO:     Epoch: 18
2022-11-18 00:44:29,965 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8835723400115967, 'Total loss': 0.8835723400115967} | train loss {'Reaction outcome loss': 0.803776844725257, 'Total loss': 0.803776844725257}
2022-11-18 00:44:29,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:29,966 INFO:     Epoch: 19
2022-11-18 00:44:30,776 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8497658905594848, 'Total loss': 0.8497658905594848} | train loss {'Reaction outcome loss': 0.7997539931389152, 'Total loss': 0.7997539931389152}
2022-11-18 00:44:30,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:30,776 INFO:     Epoch: 20
2022-11-18 00:44:31,554 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.837102493574453, 'Total loss': 0.837102493574453} | train loss {'Reaction outcome loss': 0.8038105855955452, 'Total loss': 0.8038105855955452}
2022-11-18 00:44:31,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:31,555 INFO:     Epoch: 21
2022-11-18 00:44:32,352 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8604273955489314, 'Total loss': 0.8604273955489314} | train loss {'Reaction outcome loss': 0.8029164303033078, 'Total loss': 0.8029164303033078}
2022-11-18 00:44:32,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:32,353 INFO:     Epoch: 22
2022-11-18 00:44:33,136 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8397713906543199, 'Total loss': 0.8397713906543199} | train loss {'Reaction outcome loss': 0.801278966127849, 'Total loss': 0.801278966127849}
2022-11-18 00:44:33,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:33,136 INFO:     Epoch: 23
2022-11-18 00:44:33,945 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8346697958402856, 'Total loss': 0.8346697958402856} | train loss {'Reaction outcome loss': 0.7996923718296114, 'Total loss': 0.7996923718296114}
2022-11-18 00:44:33,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:33,945 INFO:     Epoch: 24
2022-11-18 00:44:34,747 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8347642906876498, 'Total loss': 0.8347642906876498} | train loss {'Reaction outcome loss': 0.8037907806087713, 'Total loss': 0.8037907806087713}
2022-11-18 00:44:34,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:34,747 INFO:     Epoch: 25
2022-11-18 00:44:35,538 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8333869035853896, 'Total loss': 0.8333869035853896} | train loss {'Reaction outcome loss': 0.8019267014059864, 'Total loss': 0.8019267014059864}
2022-11-18 00:44:35,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:35,538 INFO:     Epoch: 26
2022-11-18 00:44:36,371 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8672910582187564, 'Total loss': 0.8672910582187564} | train loss {'Reaction outcome loss': 0.8013828357712167, 'Total loss': 0.8013828357712167}
2022-11-18 00:44:36,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:36,372 INFO:     Epoch: 27
2022-11-18 00:44:37,189 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8291444085365118, 'Total loss': 0.8291444085365118} | train loss {'Reaction outcome loss': 0.8044724126086861, 'Total loss': 0.8044724126086861}
2022-11-18 00:44:37,190 INFO:     Found new best model at epoch 27
2022-11-18 00:44:37,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:37,191 INFO:     Epoch: 28
2022-11-18 00:44:38,008 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8296969727028248, 'Total loss': 0.8296969727028248} | train loss {'Reaction outcome loss': 0.8006263670862698, 'Total loss': 0.8006263670862698}
2022-11-18 00:44:38,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:38,009 INFO:     Epoch: 29
2022-11-18 00:44:38,805 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8319855221482211, 'Total loss': 0.8319855221482211} | train loss {'Reaction outcome loss': 0.7986601299194039, 'Total loss': 0.7986601299194039}
2022-11-18 00:44:38,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:38,806 INFO:     Epoch: 30
2022-11-18 00:44:39,602 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8359796862269557, 'Total loss': 0.8359796862269557} | train loss {'Reaction outcome loss': 0.8047262753863804, 'Total loss': 0.8047262753863804}
2022-11-18 00:44:39,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:39,603 INFO:     Epoch: 31
2022-11-18 00:44:40,397 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8494304903717929, 'Total loss': 0.8494304903717929} | train loss {'Reaction outcome loss': 0.8053175957232225, 'Total loss': 0.8053175957232225}
2022-11-18 00:44:40,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:40,397 INFO:     Epoch: 32
2022-11-18 00:44:41,213 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8461581926013149, 'Total loss': 0.8461581926013149} | train loss {'Reaction outcome loss': 0.7974986431540035, 'Total loss': 0.7974986431540035}
2022-11-18 00:44:41,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:41,213 INFO:     Epoch: 33
2022-11-18 00:44:41,986 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8593030128368112, 'Total loss': 0.8593030128368112} | train loss {'Reaction outcome loss': 0.802441095719572, 'Total loss': 0.802441095719572}
2022-11-18 00:44:41,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:41,987 INFO:     Epoch: 34
2022-11-18 00:44:42,759 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8487798377524974, 'Total loss': 0.8487798377524974} | train loss {'Reaction outcome loss': 0.7973041304799376, 'Total loss': 0.7973041304799376}
2022-11-18 00:44:42,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:42,759 INFO:     Epoch: 35
2022-11-18 00:44:43,549 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8295798253181369, 'Total loss': 0.8295798253181369} | train loss {'Reaction outcome loss': 0.8016337738906751, 'Total loss': 0.8016337738906751}
2022-11-18 00:44:43,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:43,549 INFO:     Epoch: 36
2022-11-18 00:44:44,340 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.823849081993103, 'Total loss': 0.823849081993103} | train loss {'Reaction outcome loss': 0.7977817779803862, 'Total loss': 0.7977817779803862}
2022-11-18 00:44:44,340 INFO:     Found new best model at epoch 36
2022-11-18 00:44:44,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:44,341 INFO:     Epoch: 37
2022-11-18 00:44:45,106 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8367961257003075, 'Total loss': 0.8367961257003075} | train loss {'Reaction outcome loss': 0.798772476491381, 'Total loss': 0.798772476491381}
2022-11-18 00:44:45,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:45,107 INFO:     Epoch: 38
2022-11-18 00:44:45,903 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.833571273920148, 'Total loss': 0.833571273920148} | train loss {'Reaction outcome loss': 0.8015607478188687, 'Total loss': 0.8015607478188687}
2022-11-18 00:44:45,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:45,903 INFO:     Epoch: 39
2022-11-18 00:44:46,686 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8401996160662452, 'Total loss': 0.8401996160662452} | train loss {'Reaction outcome loss': 0.7979755428482275, 'Total loss': 0.7979755428482275}
2022-11-18 00:44:46,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:46,687 INFO:     Epoch: 40
2022-11-18 00:44:47,464 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8357936864675477, 'Total loss': 0.8357936864675477} | train loss {'Reaction outcome loss': 0.8010231572829309, 'Total loss': 0.8010231572829309}
2022-11-18 00:44:47,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:47,464 INFO:     Epoch: 41
2022-11-18 00:44:48,267 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8343238768189453, 'Total loss': 0.8343238768189453} | train loss {'Reaction outcome loss': 0.8009578635091664, 'Total loss': 0.8009578635091664}
2022-11-18 00:44:48,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:48,268 INFO:     Epoch: 42
2022-11-18 00:44:49,053 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8345442746960839, 'Total loss': 0.8345442746960839} | train loss {'Reaction outcome loss': 0.8001721265618918, 'Total loss': 0.8001721265618918}
2022-11-18 00:44:49,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:49,053 INFO:     Epoch: 43
2022-11-18 00:44:49,818 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.851048584594283, 'Total loss': 0.851048584594283} | train loss {'Reaction outcome loss': 0.7957512870675227, 'Total loss': 0.7957512870675227}
2022-11-18 00:44:49,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:49,818 INFO:     Epoch: 44
2022-11-18 00:44:50,604 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8432790401370026, 'Total loss': 0.8432790401370026} | train loss {'Reaction outcome loss': 0.7977432619597091, 'Total loss': 0.7977432619597091}
2022-11-18 00:44:50,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:50,604 INFO:     Epoch: 45
2022-11-18 00:44:51,373 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.835325667331385, 'Total loss': 0.835325667331385} | train loss {'Reaction outcome loss': 0.7980594705851352, 'Total loss': 0.7980594705851352}
2022-11-18 00:44:51,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:51,374 INFO:     Epoch: 46
2022-11-18 00:44:52,169 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8329365100971488, 'Total loss': 0.8329365100971488} | train loss {'Reaction outcome loss': 0.801515274604813, 'Total loss': 0.801515274604813}
2022-11-18 00:44:52,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:52,170 INFO:     Epoch: 47
2022-11-18 00:44:52,977 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8440351874329323, 'Total loss': 0.8440351874329323} | train loss {'Reaction outcome loss': 0.8023253441101215, 'Total loss': 0.8023253441101215}
2022-11-18 00:44:52,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:52,977 INFO:     Epoch: 48
2022-11-18 00:44:53,795 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8397672190222629, 'Total loss': 0.8397672190222629} | train loss {'Reaction outcome loss': 0.8004039599270117, 'Total loss': 0.8004039599270117}
2022-11-18 00:44:53,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:53,795 INFO:     Epoch: 49
2022-11-18 00:44:54,579 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8353707707205484, 'Total loss': 0.8353707707205484} | train loss {'Reaction outcome loss': 0.8013295467759742, 'Total loss': 0.8013295467759742}
2022-11-18 00:44:54,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:54,581 INFO:     Epoch: 50
2022-11-18 00:44:55,357 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8387572924758113, 'Total loss': 0.8387572924758113} | train loss {'Reaction outcome loss': 0.7936806236622763, 'Total loss': 0.7936806236622763}
2022-11-18 00:44:55,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:55,358 INFO:     Epoch: 51
2022-11-18 00:44:56,158 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8444958412370016, 'Total loss': 0.8444958412370016} | train loss {'Reaction outcome loss': 0.8033664257067149, 'Total loss': 0.8033664257067149}
2022-11-18 00:44:56,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:56,159 INFO:     Epoch: 52
2022-11-18 00:44:56,950 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8321029737938282, 'Total loss': 0.8321029737938282} | train loss {'Reaction outcome loss': 0.7995106750091568, 'Total loss': 0.7995106750091568}
2022-11-18 00:44:56,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:56,950 INFO:     Epoch: 53
2022-11-18 00:44:57,725 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.852556916170342, 'Total loss': 0.852556916170342} | train loss {'Reaction outcome loss': 0.7994739012640031, 'Total loss': 0.7994739012640031}
2022-11-18 00:44:57,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:57,726 INFO:     Epoch: 54
2022-11-18 00:44:58,533 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8664900397145471, 'Total loss': 0.8664900397145471} | train loss {'Reaction outcome loss': 0.79520347140363, 'Total loss': 0.79520347140363}
2022-11-18 00:44:58,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:58,533 INFO:     Epoch: 55
2022-11-18 00:44:59,320 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8488819259543752, 'Total loss': 0.8488819259543752} | train loss {'Reaction outcome loss': 0.7967966696033713, 'Total loss': 0.7967966696033713}
2022-11-18 00:44:59,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:44:59,320 INFO:     Epoch: 56
2022-11-18 00:45:00,138 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8466727692027425, 'Total loss': 0.8466727692027425} | train loss {'Reaction outcome loss': 0.8003023213050404, 'Total loss': 0.8003023213050404}
2022-11-18 00:45:00,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:00,138 INFO:     Epoch: 57
2022-11-18 00:45:00,905 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8344773968984914, 'Total loss': 0.8344773968984914} | train loss {'Reaction outcome loss': 0.8031516536825993, 'Total loss': 0.8031516536825993}
2022-11-18 00:45:00,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:00,906 INFO:     Epoch: 58
2022-11-18 00:45:01,691 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8305246545824894, 'Total loss': 0.8305246545824894} | train loss {'Reaction outcome loss': 0.7950617175121777, 'Total loss': 0.7950617175121777}
2022-11-18 00:45:01,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:01,692 INFO:     Epoch: 59
2022-11-18 00:45:02,478 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8268771407216094, 'Total loss': 0.8268771407216094} | train loss {'Reaction outcome loss': 0.8021758320878764, 'Total loss': 0.8021758320878764}
2022-11-18 00:45:02,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:02,478 INFO:     Epoch: 60
2022-11-18 00:45:03,249 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8380539410336073, 'Total loss': 0.8380539410336073} | train loss {'Reaction outcome loss': 0.7958883623607823, 'Total loss': 0.7958883623607823}
2022-11-18 00:45:03,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:03,249 INFO:     Epoch: 61
2022-11-18 00:45:04,043 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8305719356204189, 'Total loss': 0.8305719356204189} | train loss {'Reaction outcome loss': 0.8005801460049191, 'Total loss': 0.8005801460049191}
2022-11-18 00:45:04,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:04,043 INFO:     Epoch: 62
2022-11-18 00:45:04,861 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8327198666195537, 'Total loss': 0.8327198666195537} | train loss {'Reaction outcome loss': 0.7975676157435433, 'Total loss': 0.7975676157435433}
2022-11-18 00:45:04,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:04,861 INFO:     Epoch: 63
2022-11-18 00:45:05,681 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8449992329575294, 'Total loss': 0.8449992329575294} | train loss {'Reaction outcome loss': 0.7934995445071674, 'Total loss': 0.7934995445071674}
2022-11-18 00:45:05,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:05,681 INFO:     Epoch: 64
2022-11-18 00:45:06,499 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8343433904093366, 'Total loss': 0.8343433904093366} | train loss {'Reaction outcome loss': 0.7997558938919521, 'Total loss': 0.7997558938919521}
2022-11-18 00:45:06,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:06,499 INFO:     Epoch: 65
2022-11-18 00:45:07,301 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8326062809589297, 'Total loss': 0.8326062809589297} | train loss {'Reaction outcome loss': 0.8044718874038242, 'Total loss': 0.8044718874038242}
2022-11-18 00:45:07,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:07,301 INFO:     Epoch: 66
2022-11-18 00:45:08,090 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8527538332828256, 'Total loss': 0.8527538332828256} | train loss {'Reaction outcome loss': 0.8011351363336454, 'Total loss': 0.8011351363336454}
2022-11-18 00:45:08,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:08,090 INFO:     Epoch: 67
2022-11-18 00:45:08,907 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8437921280084655, 'Total loss': 0.8437921280084655} | train loss {'Reaction outcome loss': 0.8013168639335476, 'Total loss': 0.8013168639335476}
2022-11-18 00:45:08,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:08,907 INFO:     Epoch: 68
2022-11-18 00:45:09,730 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8442501474258511, 'Total loss': 0.8442501474258511} | train loss {'Reaction outcome loss': 0.80146781611638, 'Total loss': 0.80146781611638}
2022-11-18 00:45:09,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:09,730 INFO:     Epoch: 69
2022-11-18 00:45:10,540 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8369477294212164, 'Total loss': 0.8369477294212164} | train loss {'Reaction outcome loss': 0.8002155454920941, 'Total loss': 0.8002155454920941}
2022-11-18 00:45:10,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:10,541 INFO:     Epoch: 70
2022-11-18 00:45:11,317 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8305413196253222, 'Total loss': 0.8305413196253222} | train loss {'Reaction outcome loss': 0.7965900179792623, 'Total loss': 0.7965900179792623}
2022-11-18 00:45:11,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:11,317 INFO:     Epoch: 71
2022-11-18 00:45:12,128 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8334956529528595, 'Total loss': 0.8334956529528595} | train loss {'Reaction outcome loss': 0.7951241202774595, 'Total loss': 0.7951241202774595}
2022-11-18 00:45:12,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:12,128 INFO:     Epoch: 72
2022-11-18 00:45:12,890 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8278057395025741, 'Total loss': 0.8278057395025741} | train loss {'Reaction outcome loss': 0.7974346822402516, 'Total loss': 0.7974346822402516}
2022-11-18 00:45:12,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:12,890 INFO:     Epoch: 73
2022-11-18 00:45:13,667 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8388553123141445, 'Total loss': 0.8388553123141445} | train loss {'Reaction outcome loss': 0.7968550576049773, 'Total loss': 0.7968550576049773}
2022-11-18 00:45:13,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:13,668 INFO:     Epoch: 74
2022-11-18 00:45:14,455 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8329680562019348, 'Total loss': 0.8329680562019348} | train loss {'Reaction outcome loss': 0.7998081102478699, 'Total loss': 0.7998081102478699}
2022-11-18 00:45:14,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:14,455 INFO:     Epoch: 75
2022-11-18 00:45:15,257 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8385059556295705, 'Total loss': 0.8385059556295705} | train loss {'Reaction outcome loss': 0.7954095922044067, 'Total loss': 0.7954095922044067}
2022-11-18 00:45:15,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:15,258 INFO:     Epoch: 76
2022-11-18 00:45:16,067 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8398675682932831, 'Total loss': 0.8398675682932831} | train loss {'Reaction outcome loss': 0.8018833308434877, 'Total loss': 0.8018833308434877}
2022-11-18 00:45:16,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:16,067 INFO:     Epoch: 77
2022-11-18 00:45:16,857 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8329408439092858, 'Total loss': 0.8329408439092858} | train loss {'Reaction outcome loss': 0.7988648237507852, 'Total loss': 0.7988648237507852}
2022-11-18 00:45:16,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:16,858 INFO:     Epoch: 78
2022-11-18 00:45:17,649 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8471938316212144, 'Total loss': 0.8471938316212144} | train loss {'Reaction outcome loss': 0.794646538488689, 'Total loss': 0.794646538488689}
2022-11-18 00:45:17,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:17,649 INFO:     Epoch: 79
2022-11-18 00:45:18,457 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.835428190785785, 'Total loss': 0.835428190785785} | train loss {'Reaction outcome loss': 0.7990124585931418, 'Total loss': 0.7990124585931418}
2022-11-18 00:45:18,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:18,457 INFO:     Epoch: 80
2022-11-18 00:45:19,237 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8706935491672781, 'Total loss': 0.8706935491672781} | train loss {'Reaction outcome loss': 0.7984699867055064, 'Total loss': 0.7984699867055064}
2022-11-18 00:45:19,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:19,237 INFO:     Epoch: 81
2022-11-18 00:45:20,034 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8339528379052185, 'Total loss': 0.8339528379052185} | train loss {'Reaction outcome loss': 0.799477507711434, 'Total loss': 0.799477507711434}
2022-11-18 00:45:20,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:20,035 INFO:     Epoch: 82
2022-11-18 00:45:20,798 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8440606607947239, 'Total loss': 0.8440606607947239} | train loss {'Reaction outcome loss': 0.7997578853955034, 'Total loss': 0.7997578853955034}
2022-11-18 00:45:20,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:20,799 INFO:     Epoch: 83
2022-11-18 00:45:21,645 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8481074696363404, 'Total loss': 0.8481074696363404} | train loss {'Reaction outcome loss': 0.7979741367648859, 'Total loss': 0.7979741367648859}
2022-11-18 00:45:21,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:21,645 INFO:     Epoch: 84
2022-11-18 00:45:22,426 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.825644563103831, 'Total loss': 0.825644563103831} | train loss {'Reaction outcome loss': 0.7974059127393316, 'Total loss': 0.7974059127393316}
2022-11-18 00:45:22,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:22,427 INFO:     Epoch: 85
2022-11-18 00:45:23,209 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.861113756201988, 'Total loss': 0.861113756201988} | train loss {'Reaction outcome loss': 0.7911654179457759, 'Total loss': 0.7911654179457759}
2022-11-18 00:45:23,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:23,209 INFO:     Epoch: 86
2022-11-18 00:45:24,007 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8465066780877668, 'Total loss': 0.8465066780877668} | train loss {'Reaction outcome loss': 0.7928492432979287, 'Total loss': 0.7928492432979287}
2022-11-18 00:45:24,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:24,007 INFO:     Epoch: 87
2022-11-18 00:45:24,784 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8275124784125838, 'Total loss': 0.8275124784125838} | train loss {'Reaction outcome loss': 0.7989865337483218, 'Total loss': 0.7989865337483218}
2022-11-18 00:45:24,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:24,784 INFO:     Epoch: 88
2022-11-18 00:45:25,586 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8434393097494923, 'Total loss': 0.8434393097494923} | train loss {'Reaction outcome loss': 0.7963143467414574, 'Total loss': 0.7963143467414574}
2022-11-18 00:45:25,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:25,588 INFO:     Epoch: 89
2022-11-18 00:45:26,434 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8489731106647226, 'Total loss': 0.8489731106647226} | train loss {'Reaction outcome loss': 0.8009206208049274, 'Total loss': 0.8009206208049274}
2022-11-18 00:45:26,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:26,435 INFO:     Epoch: 90
2022-11-18 00:45:27,246 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8245087841222453, 'Total loss': 0.8245087841222453} | train loss {'Reaction outcome loss': 0.8018724849966706, 'Total loss': 0.8018724849966706}
2022-11-18 00:45:27,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:27,246 INFO:     Epoch: 91
2022-11-18 00:45:28,039 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.834883069576219, 'Total loss': 0.834883069576219} | train loss {'Reaction outcome loss': 0.7952297312802956, 'Total loss': 0.7952297312802956}
2022-11-18 00:45:28,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:28,039 INFO:     Epoch: 92
2022-11-18 00:45:28,833 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8413822803386423, 'Total loss': 0.8413822803386423} | train loss {'Reaction outcome loss': 0.7964802737363049, 'Total loss': 0.7964802737363049}
2022-11-18 00:45:28,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:28,834 INFO:     Epoch: 93
2022-11-18 00:45:29,685 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8367910676224287, 'Total loss': 0.8367910676224287} | train loss {'Reaction outcome loss': 0.7987557900000791, 'Total loss': 0.7987557900000791}
2022-11-18 00:45:29,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:29,685 INFO:     Epoch: 94
2022-11-18 00:45:30,482 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8440837007622386, 'Total loss': 0.8440837007622386} | train loss {'Reaction outcome loss': 0.7979223304351822, 'Total loss': 0.7979223304351822}
2022-11-18 00:45:30,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:30,482 INFO:     Epoch: 95
2022-11-18 00:45:31,304 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8325144537659579, 'Total loss': 0.8325144537659579} | train loss {'Reaction outcome loss': 0.797676648883546, 'Total loss': 0.797676648883546}
2022-11-18 00:45:31,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:31,305 INFO:     Epoch: 96
2022-11-18 00:45:32,103 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8311274924943614, 'Total loss': 0.8311274924943614} | train loss {'Reaction outcome loss': 0.7898756876343587, 'Total loss': 0.7898756876343587}
2022-11-18 00:45:32,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:32,104 INFO:     Epoch: 97
2022-11-18 00:45:32,870 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.839060879030893, 'Total loss': 0.839060879030893} | train loss {'Reaction outcome loss': 0.7956560735331207, 'Total loss': 0.7956560735331207}
2022-11-18 00:45:32,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:32,870 INFO:     Epoch: 98
2022-11-18 00:45:33,645 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8214435036792311, 'Total loss': 0.8214435036792311} | train loss {'Reaction outcome loss': 0.7973488649872483, 'Total loss': 0.7973488649872483}
2022-11-18 00:45:33,645 INFO:     Found new best model at epoch 98
2022-11-18 00:45:33,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:33,646 INFO:     Epoch: 99
2022-11-18 00:45:34,441 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8227821297423784, 'Total loss': 0.8227821297423784} | train loss {'Reaction outcome loss': 0.7923050287072776, 'Total loss': 0.7923050287072776}
2022-11-18 00:45:34,441 INFO:     Best model found after epoch 99 of 100.
2022-11-18 00:45:34,441 INFO:   Done with stage: TRAINING
2022-11-18 00:45:34,441 INFO:   Starting stage: EVALUATION
2022-11-18 00:45:34,576 INFO:   Done with stage: EVALUATION
2022-11-18 00:45:34,576 INFO:   Leaving out SEQ value Fold_4
2022-11-18 00:45:34,590 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 00:45:34,590 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:45:35,259 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:45:35,259 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:45:35,330 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:45:35,330 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:45:35,330 INFO:     No hyperparam tuning for this model
2022-11-18 00:45:35,330 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:45:35,330 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:45:35,331 INFO:     None feature selector for col prot
2022-11-18 00:45:35,331 INFO:     None feature selector for col prot
2022-11-18 00:45:35,331 INFO:     None feature selector for col prot
2022-11-18 00:45:35,332 INFO:     None feature selector for col chem
2022-11-18 00:45:35,332 INFO:     None feature selector for col chem
2022-11-18 00:45:35,332 INFO:     None feature selector for col chem
2022-11-18 00:45:35,332 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:45:35,332 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:45:35,334 INFO:     Number of params in model 168571
2022-11-18 00:45:35,337 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:45:35,337 INFO:   Starting stage: TRAINING
2022-11-18 00:45:35,395 INFO:     Val loss before train {'Reaction outcome loss': 1.0001529522917487, 'Total loss': 1.0001529522917487}
2022-11-18 00:45:35,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:35,395 INFO:     Epoch: 0
2022-11-18 00:45:36,207 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8737261247905818, 'Total loss': 0.8737261247905818} | train loss {'Reaction outcome loss': 0.8768429042125235, 'Total loss': 0.8768429042125235}
2022-11-18 00:45:36,208 INFO:     Found new best model at epoch 0
2022-11-18 00:45:36,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:36,208 INFO:     Epoch: 1
2022-11-18 00:45:37,038 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8522373912009326, 'Total loss': 0.8522373912009326} | train loss {'Reaction outcome loss': 0.8518309113930683, 'Total loss': 0.8518309113930683}
2022-11-18 00:45:37,038 INFO:     Found new best model at epoch 1
2022-11-18 00:45:37,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:37,039 INFO:     Epoch: 2
2022-11-18 00:45:37,902 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8394424122842875, 'Total loss': 0.8394424122842875} | train loss {'Reaction outcome loss': 0.8478536278617625, 'Total loss': 0.8478536278617625}
2022-11-18 00:45:37,902 INFO:     Found new best model at epoch 2
2022-11-18 00:45:37,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:37,903 INFO:     Epoch: 3
2022-11-18 00:45:38,742 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8598253273151137, 'Total loss': 0.8598253273151137} | train loss {'Reaction outcome loss': 0.8364809236964401, 'Total loss': 0.8364809236964401}
2022-11-18 00:45:38,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:38,742 INFO:     Epoch: 4
2022-11-18 00:45:39,498 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.841529515656558, 'Total loss': 0.841529515656558} | train loss {'Reaction outcome loss': 0.8312670358589718, 'Total loss': 0.8312670358589718}
2022-11-18 00:45:39,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:39,498 INFO:     Epoch: 5
2022-11-18 00:45:40,290 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8500553843649951, 'Total loss': 0.8500553843649951} | train loss {'Reaction outcome loss': 0.837788525284553, 'Total loss': 0.837788525284553}
2022-11-18 00:45:40,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:40,291 INFO:     Epoch: 6
2022-11-18 00:45:41,117 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8530729182741859, 'Total loss': 0.8530729182741859} | train loss {'Reaction outcome loss': 0.8333511960749723, 'Total loss': 0.8333511960749723}
2022-11-18 00:45:41,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:41,117 INFO:     Epoch: 7
2022-11-18 00:45:41,958 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8308997601270676, 'Total loss': 0.8308997601270676} | train loss {'Reaction outcome loss': 0.8262563861146265, 'Total loss': 0.8262563861146265}
2022-11-18 00:45:41,958 INFO:     Found new best model at epoch 7
2022-11-18 00:45:41,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:41,959 INFO:     Epoch: 8
2022-11-18 00:45:42,736 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8640426207672466, 'Total loss': 0.8640426207672466} | train loss {'Reaction outcome loss': 0.828114319577509, 'Total loss': 0.828114319577509}
2022-11-18 00:45:42,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:42,737 INFO:     Epoch: 9
2022-11-18 00:45:43,509 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8091320612213828, 'Total loss': 0.8091320612213828} | train loss {'Reaction outcome loss': 0.8230129019338257, 'Total loss': 0.8230129019338257}
2022-11-18 00:45:43,509 INFO:     Found new best model at epoch 9
2022-11-18 00:45:43,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:43,510 INFO:     Epoch: 10
2022-11-18 00:45:44,288 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8192568983544003, 'Total loss': 0.8192568983544003} | train loss {'Reaction outcome loss': 0.824002080304282, 'Total loss': 0.824002080304282}
2022-11-18 00:45:44,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:44,289 INFO:     Epoch: 11
2022-11-18 00:45:45,089 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8186892323534597, 'Total loss': 0.8186892323534597} | train loss {'Reaction outcome loss': 0.8195792448763944, 'Total loss': 0.8195792448763944}
2022-11-18 00:45:45,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:45,089 INFO:     Epoch: 12
2022-11-18 00:45:45,845 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.821376536380161, 'Total loss': 0.821376536380161} | train loss {'Reaction outcome loss': 0.8209315746414418, 'Total loss': 0.8209315746414418}
2022-11-18 00:45:45,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:45,846 INFO:     Epoch: 13
2022-11-18 00:45:46,634 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8401764726096933, 'Total loss': 0.8401764726096933} | train loss {'Reaction outcome loss': 0.8219776196139199, 'Total loss': 0.8219776196139199}
2022-11-18 00:45:46,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:46,634 INFO:     Epoch: 14
2022-11-18 00:45:47,411 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8217946331609379, 'Total loss': 0.8217946331609379} | train loss {'Reaction outcome loss': 0.8149679867588744, 'Total loss': 0.8149679867588744}
2022-11-18 00:45:47,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:47,411 INFO:     Epoch: 15
2022-11-18 00:45:48,189 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8274916451085698, 'Total loss': 0.8274916451085698} | train loss {'Reaction outcome loss': 0.81579958103141, 'Total loss': 0.81579958103141}
2022-11-18 00:45:48,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:48,189 INFO:     Epoch: 16
2022-11-18 00:45:48,974 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8504396324807947, 'Total loss': 0.8504396324807947} | train loss {'Reaction outcome loss': 0.8206703638543889, 'Total loss': 0.8206703638543889}
2022-11-18 00:45:48,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:48,975 INFO:     Epoch: 17
2022-11-18 00:45:49,744 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8150341036644849, 'Total loss': 0.8150341036644849} | train loss {'Reaction outcome loss': 0.8175829274313791, 'Total loss': 0.8175829274313791}
2022-11-18 00:45:49,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:49,744 INFO:     Epoch: 18
2022-11-18 00:45:50,519 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8332681662657044, 'Total loss': 0.8332681662657044} | train loss {'Reaction outcome loss': 0.8170904135217472, 'Total loss': 0.8170904135217472}
2022-11-18 00:45:50,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:50,520 INFO:     Epoch: 19
2022-11-18 00:45:51,277 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8178324408151887, 'Total loss': 0.8178324408151887} | train loss {'Reaction outcome loss': 0.8145874248475444, 'Total loss': 0.8145874248475444}
2022-11-18 00:45:51,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:51,278 INFO:     Epoch: 20
2022-11-18 00:45:52,056 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8284545147960837, 'Total loss': 0.8284545147960837} | train loss {'Reaction outcome loss': 0.8109439231911484, 'Total loss': 0.8109439231911484}
2022-11-18 00:45:52,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:52,056 INFO:     Epoch: 21
2022-11-18 00:45:52,824 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8622339652343229, 'Total loss': 0.8622339652343229} | train loss {'Reaction outcome loss': 0.8197742887905666, 'Total loss': 0.8197742887905666}
2022-11-18 00:45:52,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:52,824 INFO:     Epoch: 22
2022-11-18 00:45:53,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8705759658054872, 'Total loss': 0.8705759658054872} | train loss {'Reaction outcome loss': 0.8119977527735185, 'Total loss': 0.8119977527735185}
2022-11-18 00:45:53,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:53,606 INFO:     Epoch: 23
2022-11-18 00:45:54,378 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.856849377128211, 'Total loss': 0.856849377128211} | train loss {'Reaction outcome loss': 0.8111977904426808, 'Total loss': 0.8111977904426808}
2022-11-18 00:45:54,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:54,378 INFO:     Epoch: 24
2022-11-18 00:45:55,176 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8312792859294198, 'Total loss': 0.8312792859294198} | train loss {'Reaction outcome loss': 0.8165979448629885, 'Total loss': 0.8165979448629885}
2022-11-18 00:45:55,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:55,176 INFO:     Epoch: 25
2022-11-18 00:45:55,939 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8615781292319298, 'Total loss': 0.8615781292319298} | train loss {'Reaction outcome loss': 0.8127944490131067, 'Total loss': 0.8127944490131067}
2022-11-18 00:45:55,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:55,939 INFO:     Epoch: 26
2022-11-18 00:45:56,669 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.818639303472909, 'Total loss': 0.818639303472909} | train loss {'Reaction outcome loss': 0.8134826866947875, 'Total loss': 0.8134826866947875}
2022-11-18 00:45:56,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:56,671 INFO:     Epoch: 27
2022-11-18 00:45:57,432 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8181298856030811, 'Total loss': 0.8181298856030811} | train loss {'Reaction outcome loss': 0.8123562452744465, 'Total loss': 0.8123562452744465}
2022-11-18 00:45:57,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:57,433 INFO:     Epoch: 28
2022-11-18 00:45:58,204 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8311733305454254, 'Total loss': 0.8311733305454254} | train loss {'Reaction outcome loss': 0.8142161442309009, 'Total loss': 0.8142161442309009}
2022-11-18 00:45:58,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:58,204 INFO:     Epoch: 29
2022-11-18 00:45:59,009 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8381358561190692, 'Total loss': 0.8381358561190692} | train loss {'Reaction outcome loss': 0.8130458582420739, 'Total loss': 0.8130458582420739}
2022-11-18 00:45:59,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:59,009 INFO:     Epoch: 30
2022-11-18 00:45:59,777 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8094701387665488, 'Total loss': 0.8094701387665488} | train loss {'Reaction outcome loss': 0.8134363772917766, 'Total loss': 0.8134363772917766}
2022-11-18 00:45:59,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:45:59,777 INFO:     Epoch: 31
2022-11-18 00:46:00,548 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8296710415319963, 'Total loss': 0.8296710415319963} | train loss {'Reaction outcome loss': 0.8129506750982635, 'Total loss': 0.8129506750982635}
2022-11-18 00:46:00,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:00,548 INFO:     Epoch: 32
2022-11-18 00:46:01,346 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8368485786698081, 'Total loss': 0.8368485786698081} | train loss {'Reaction outcome loss': 0.8171530852512437, 'Total loss': 0.8171530852512437}
2022-11-18 00:46:01,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:01,347 INFO:     Epoch: 33
2022-11-18 00:46:02,137 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8042925149202347, 'Total loss': 0.8042925149202347} | train loss {'Reaction outcome loss': 0.8134447510145149, 'Total loss': 0.8134447510145149}
2022-11-18 00:46:02,138 INFO:     Found new best model at epoch 33
2022-11-18 00:46:02,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:02,138 INFO:     Epoch: 34
2022-11-18 00:46:02,910 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8442982970313593, 'Total loss': 0.8442982970313593} | train loss {'Reaction outcome loss': 0.8148639452700712, 'Total loss': 0.8148639452700712}
2022-11-18 00:46:02,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:02,911 INFO:     Epoch: 35
2022-11-18 00:46:03,695 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8266296833753586, 'Total loss': 0.8266296833753586} | train loss {'Reaction outcome loss': 0.8167593026647763, 'Total loss': 0.8167593026647763}
2022-11-18 00:46:03,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:03,695 INFO:     Epoch: 36
2022-11-18 00:46:04,482 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8482280177148905, 'Total loss': 0.8482280177148905} | train loss {'Reaction outcome loss': 0.8197616242632574, 'Total loss': 0.8197616242632574}
2022-11-18 00:46:04,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:04,483 INFO:     Epoch: 37
2022-11-18 00:46:05,253 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8286398107355292, 'Total loss': 0.8286398107355292} | train loss {'Reaction outcome loss': 0.8155168202458596, 'Total loss': 0.8155168202458596}
2022-11-18 00:46:05,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:05,253 INFO:     Epoch: 38
2022-11-18 00:46:06,048 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.848160596056418, 'Total loss': 0.848160596056418} | train loss {'Reaction outcome loss': 0.8152400940048451, 'Total loss': 0.8152400940048451}
2022-11-18 00:46:06,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:06,048 INFO:     Epoch: 39
2022-11-18 00:46:06,825 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8260173296386545, 'Total loss': 0.8260173296386545} | train loss {'Reaction outcome loss': 0.8123133327279772, 'Total loss': 0.8123133327279772}
2022-11-18 00:46:06,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:06,825 INFO:     Epoch: 40
2022-11-18 00:46:07,631 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.810936952856454, 'Total loss': 0.810936952856454} | train loss {'Reaction outcome loss': 0.8150899145067955, 'Total loss': 0.8150899145067955}
2022-11-18 00:46:07,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:07,631 INFO:     Epoch: 41
2022-11-18 00:46:08,385 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.826362261379307, 'Total loss': 0.826362261379307} | train loss {'Reaction outcome loss': 0.8163944633639588, 'Total loss': 0.8163944633639588}
2022-11-18 00:46:08,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:08,385 INFO:     Epoch: 42
2022-11-18 00:46:09,138 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8275094160979445, 'Total loss': 0.8275094160979445} | train loss {'Reaction outcome loss': 0.8142129552607633, 'Total loss': 0.8142129552607633}
2022-11-18 00:46:09,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:09,138 INFO:     Epoch: 43
2022-11-18 00:46:09,908 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8237363086505369, 'Total loss': 0.8237363086505369} | train loss {'Reaction outcome loss': 0.8148263126003499, 'Total loss': 0.8148263126003499}
2022-11-18 00:46:09,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:09,909 INFO:     Epoch: 44
2022-11-18 00:46:10,674 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8316408788616007, 'Total loss': 0.8316408788616007} | train loss {'Reaction outcome loss': 0.8130710152947173, 'Total loss': 0.8130710152947173}
2022-11-18 00:46:10,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:10,675 INFO:     Epoch: 45
2022-11-18 00:46:11,459 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8322416422041979, 'Total loss': 0.8322416422041979} | train loss {'Reaction outcome loss': 0.816192547885739, 'Total loss': 0.816192547885739}
2022-11-18 00:46:11,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:11,459 INFO:     Epoch: 46
2022-11-18 00:46:12,232 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8387449376962401, 'Total loss': 0.8387449376962401} | train loss {'Reaction outcome loss': 0.8122010803952509, 'Total loss': 0.8122010803952509}
2022-11-18 00:46:12,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:12,232 INFO:     Epoch: 47
2022-11-18 00:46:13,017 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8362603817473758, 'Total loss': 0.8362603817473758} | train loss {'Reaction outcome loss': 0.8155205938280845, 'Total loss': 0.8155205938280845}
2022-11-18 00:46:13,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:13,017 INFO:     Epoch: 48
2022-11-18 00:46:13,759 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8293456882238388, 'Total loss': 0.8293456882238388} | train loss {'Reaction outcome loss': 0.813486631062566, 'Total loss': 0.813486631062566}
2022-11-18 00:46:13,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:13,760 INFO:     Epoch: 49
2022-11-18 00:46:14,506 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8456687839193777, 'Total loss': 0.8456687839193777} | train loss {'Reaction outcome loss': 0.8174888900348118, 'Total loss': 0.8174888900348118}
2022-11-18 00:46:14,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:14,507 INFO:     Epoch: 50
2022-11-18 00:46:15,314 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8076378560879014, 'Total loss': 0.8076378560879014} | train loss {'Reaction outcome loss': 0.8178407958575657, 'Total loss': 0.8178407958575657}
2022-11-18 00:46:15,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:15,315 INFO:     Epoch: 51
2022-11-18 00:46:16,090 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8303799249909141, 'Total loss': 0.8303799249909141} | train loss {'Reaction outcome loss': 0.809712580637056, 'Total loss': 0.809712580637056}
2022-11-18 00:46:16,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:16,090 INFO:     Epoch: 52
2022-11-18 00:46:16,870 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.832475904036652, 'Total loss': 0.832475904036652} | train loss {'Reaction outcome loss': 0.8077468072881504, 'Total loss': 0.8077468072881504}
2022-11-18 00:46:16,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:16,870 INFO:     Epoch: 53
2022-11-18 00:46:17,646 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8560242740945383, 'Total loss': 0.8560242740945383} | train loss {'Reaction outcome loss': 0.8136387446705176, 'Total loss': 0.8136387446705176}
2022-11-18 00:46:17,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:17,646 INFO:     Epoch: 54
2022-11-18 00:46:18,430 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8210795745253563, 'Total loss': 0.8210795745253563} | train loss {'Reaction outcome loss': 0.8144682319796815, 'Total loss': 0.8144682319796815}
2022-11-18 00:46:18,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:18,430 INFO:     Epoch: 55
2022-11-18 00:46:19,235 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8344855030829256, 'Total loss': 0.8344855030829256} | train loss {'Reaction outcome loss': 0.8112295765049603, 'Total loss': 0.8112295765049603}
2022-11-18 00:46:19,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:19,235 INFO:     Epoch: 56
2022-11-18 00:46:19,999 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.843836438249458, 'Total loss': 0.843836438249458} | train loss {'Reaction outcome loss': 0.8102822525160653, 'Total loss': 0.8102822525160653}
2022-11-18 00:46:20,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:20,000 INFO:     Epoch: 57
2022-11-18 00:46:20,777 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8270748508247462, 'Total loss': 0.8270748508247462} | train loss {'Reaction outcome loss': 0.8179532506028, 'Total loss': 0.8179532506028}
2022-11-18 00:46:20,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:20,778 INFO:     Epoch: 58
2022-11-18 00:46:21,550 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8385006487369537, 'Total loss': 0.8385006487369537} | train loss {'Reaction outcome loss': 0.8129940677662285, 'Total loss': 0.8129940677662285}
2022-11-18 00:46:21,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:21,550 INFO:     Epoch: 59
2022-11-18 00:46:22,325 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8458622978492216, 'Total loss': 0.8458622978492216} | train loss {'Reaction outcome loss': 0.8115871496346532, 'Total loss': 0.8115871496346532}
2022-11-18 00:46:22,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:22,325 INFO:     Epoch: 60
2022-11-18 00:46:23,078 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8259448266842149, 'Total loss': 0.8259448266842149} | train loss {'Reaction outcome loss': 0.8128930804680805, 'Total loss': 0.8128930804680805}
2022-11-18 00:46:23,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:23,079 INFO:     Epoch: 61
2022-11-18 00:46:23,843 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8267930177125064, 'Total loss': 0.8267930177125064} | train loss {'Reaction outcome loss': 0.8074459517488675, 'Total loss': 0.8074459517488675}
2022-11-18 00:46:23,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:23,843 INFO:     Epoch: 62
2022-11-18 00:46:24,611 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8267099925062873, 'Total loss': 0.8267099925062873} | train loss {'Reaction outcome loss': 0.8113457334284879, 'Total loss': 0.8113457334284879}
2022-11-18 00:46:24,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:24,612 INFO:     Epoch: 63
2022-11-18 00:46:25,382 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8400903276421807, 'Total loss': 0.8400903276421807} | train loss {'Reaction outcome loss': 0.8167023936096502, 'Total loss': 0.8167023936096502}
2022-11-18 00:46:25,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:25,382 INFO:     Epoch: 64
2022-11-18 00:46:26,144 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.82826228575273, 'Total loss': 0.82826228575273} | train loss {'Reaction outcome loss': 0.811167879493869, 'Total loss': 0.811167879493869}
2022-11-18 00:46:26,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:26,145 INFO:     Epoch: 65
2022-11-18 00:46:26,930 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8198193711313334, 'Total loss': 0.8198193711313334} | train loss {'Reaction outcome loss': 0.8107235288133426, 'Total loss': 0.8107235288133426}
2022-11-18 00:46:26,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:26,930 INFO:     Epoch: 66
2022-11-18 00:46:27,710 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8265083303505724, 'Total loss': 0.8265083303505724} | train loss {'Reaction outcome loss': 0.8163135600333311, 'Total loss': 0.8163135600333311}
2022-11-18 00:46:27,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:27,711 INFO:     Epoch: 67
2022-11-18 00:46:28,478 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8383460478349165, 'Total loss': 0.8383460478349165} | train loss {'Reaction outcome loss': 0.8090255428333671, 'Total loss': 0.8090255428333671}
2022-11-18 00:46:28,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:28,479 INFO:     Epoch: 68
2022-11-18 00:46:29,275 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8316853093830022, 'Total loss': 0.8316853093830022} | train loss {'Reaction outcome loss': 0.809335094811965, 'Total loss': 0.809335094811965}
2022-11-18 00:46:29,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:29,275 INFO:     Epoch: 69
2022-11-18 00:46:30,039 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8117328611287203, 'Total loss': 0.8117328611287203} | train loss {'Reaction outcome loss': 0.8122387012656854, 'Total loss': 0.8122387012656854}
2022-11-18 00:46:30,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:30,040 INFO:     Epoch: 70
2022-11-18 00:46:30,815 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8412426710128784, 'Total loss': 0.8412426710128784} | train loss {'Reaction outcome loss': 0.8117131140767312, 'Total loss': 0.8117131140767312}
2022-11-18 00:46:30,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:30,816 INFO:     Epoch: 71
2022-11-18 00:46:31,632 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8501713919368658, 'Total loss': 0.8501713919368658} | train loss {'Reaction outcome loss': 0.8135185863290514, 'Total loss': 0.8135185863290514}
2022-11-18 00:46:31,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:31,633 INFO:     Epoch: 72
2022-11-18 00:46:32,400 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8445436175573956, 'Total loss': 0.8445436175573956} | train loss {'Reaction outcome loss': 0.8151724274061164, 'Total loss': 0.8151724274061164}
2022-11-18 00:46:32,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:32,400 INFO:     Epoch: 73
2022-11-18 00:46:33,176 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8334733450954611, 'Total loss': 0.8334733450954611} | train loss {'Reaction outcome loss': 0.8146495204799029, 'Total loss': 0.8146495204799029}
2022-11-18 00:46:33,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:33,176 INFO:     Epoch: 74
2022-11-18 00:46:33,966 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.828762027350339, 'Total loss': 0.828762027350339} | train loss {'Reaction outcome loss': 0.812910057208976, 'Total loss': 0.812910057208976}
2022-11-18 00:46:33,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:33,967 INFO:     Epoch: 75
2022-11-18 00:46:34,736 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8373349234461784, 'Total loss': 0.8373349234461784} | train loss {'Reaction outcome loss': 0.8121357326604882, 'Total loss': 0.8121357326604882}
2022-11-18 00:46:34,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:34,736 INFO:     Epoch: 76
2022-11-18 00:46:35,510 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8314668888395483, 'Total loss': 0.8314668888395483} | train loss {'Reaction outcome loss': 0.8121021342520811, 'Total loss': 0.8121021342520811}
2022-11-18 00:46:35,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:35,510 INFO:     Epoch: 77
2022-11-18 00:46:36,302 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8422390811822631, 'Total loss': 0.8422390811822631} | train loss {'Reaction outcome loss': 0.8113717407596355, 'Total loss': 0.8113717407596355}
2022-11-18 00:46:36,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:36,303 INFO:     Epoch: 78
2022-11-18 00:46:37,054 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.830964248966087, 'Total loss': 0.830964248966087} | train loss {'Reaction outcome loss': 0.8151701565907926, 'Total loss': 0.8151701565907926}
2022-11-18 00:46:37,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:37,054 INFO:     Epoch: 79
2022-11-18 00:46:37,856 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8276930932294239, 'Total loss': 0.8276930932294239} | train loss {'Reaction outcome loss': 0.8129525497251627, 'Total loss': 0.8129525497251627}
2022-11-18 00:46:37,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:37,856 INFO:     Epoch: 80
2022-11-18 00:46:38,647 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8402159004048868, 'Total loss': 0.8402159004048868} | train loss {'Reaction outcome loss': 0.815722580831878, 'Total loss': 0.815722580831878}
2022-11-18 00:46:38,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:38,647 INFO:     Epoch: 81
2022-11-18 00:46:39,427 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8143832602284171, 'Total loss': 0.8143832602284171} | train loss {'Reaction outcome loss': 0.814710599913889, 'Total loss': 0.814710599913889}
2022-11-18 00:46:39,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:39,427 INFO:     Epoch: 82
2022-11-18 00:46:40,199 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8365586020729758, 'Total loss': 0.8365586020729758} | train loss {'Reaction outcome loss': 0.8126933029719762, 'Total loss': 0.8126933029719762}
2022-11-18 00:46:40,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:40,199 INFO:     Epoch: 83
2022-11-18 00:46:40,971 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8275991691784426, 'Total loss': 0.8275991691784426} | train loss {'Reaction outcome loss': 0.8141179621219635, 'Total loss': 0.8141179621219635}
2022-11-18 00:46:40,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:40,971 INFO:     Epoch: 84
2022-11-18 00:46:41,784 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.843128843063658, 'Total loss': 0.843128843063658} | train loss {'Reaction outcome loss': 0.8123679607498403, 'Total loss': 0.8123679607498403}
2022-11-18 00:46:41,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:41,785 INFO:     Epoch: 85
2022-11-18 00:46:42,583 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8130546367981217, 'Total loss': 0.8130546367981217} | train loss {'Reaction outcome loss': 0.8168083613016167, 'Total loss': 0.8168083613016167}
2022-11-18 00:46:42,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:42,584 INFO:     Epoch: 86
2022-11-18 00:46:43,365 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8248646022243933, 'Total loss': 0.8248646022243933} | train loss {'Reaction outcome loss': 0.814294891819662, 'Total loss': 0.814294891819662}
2022-11-18 00:46:43,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:43,365 INFO:     Epoch: 87
2022-11-18 00:46:44,117 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8429170589555394, 'Total loss': 0.8429170589555394} | train loss {'Reaction outcome loss': 0.813930955590034, 'Total loss': 0.813930955590034}
2022-11-18 00:46:44,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:44,117 INFO:     Epoch: 88
2022-11-18 00:46:44,878 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8290329114957289, 'Total loss': 0.8290329114957289} | train loss {'Reaction outcome loss': 0.8154185712337494, 'Total loss': 0.8154185712337494}
2022-11-18 00:46:44,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:44,878 INFO:     Epoch: 89
2022-11-18 00:46:45,645 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8194792067462747, 'Total loss': 0.8194792067462747} | train loss {'Reaction outcome loss': 0.8098706627378658, 'Total loss': 0.8098706627378658}
2022-11-18 00:46:45,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:45,645 INFO:     Epoch: 90
2022-11-18 00:46:46,450 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8236670460213315, 'Total loss': 0.8236670460213315} | train loss {'Reaction outcome loss': 0.8187573397646145, 'Total loss': 0.8187573397646145}
2022-11-18 00:46:46,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:46,451 INFO:     Epoch: 91
2022-11-18 00:46:47,227 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8558079891584136, 'Total loss': 0.8558079891584136} | train loss {'Reaction outcome loss': 0.8119552158579535, 'Total loss': 0.8119552158579535}
2022-11-18 00:46:47,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:47,227 INFO:     Epoch: 92
2022-11-18 00:46:48,009 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8275318281217054, 'Total loss': 0.8275318281217054} | train loss {'Reaction outcome loss': 0.8111656850698042, 'Total loss': 0.8111656850698042}
2022-11-18 00:46:48,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:48,010 INFO:     Epoch: 93
2022-11-18 00:46:48,811 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8563657240434126, 'Total loss': 0.8563657240434126} | train loss {'Reaction outcome loss': 0.8115502085004535, 'Total loss': 0.8115502085004535}
2022-11-18 00:46:48,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:48,811 INFO:     Epoch: 94
2022-11-18 00:46:49,603 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8691318251869895, 'Total loss': 0.8691318251869895} | train loss {'Reaction outcome loss': 0.8161906039228245, 'Total loss': 0.8161906039228245}
2022-11-18 00:46:49,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:49,603 INFO:     Epoch: 95
2022-11-18 00:46:50,379 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8284627194093033, 'Total loss': 0.8284627194093033} | train loss {'Reaction outcome loss': 0.811590440905824, 'Total loss': 0.811590440905824}
2022-11-18 00:46:50,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:50,380 INFO:     Epoch: 96
2022-11-18 00:46:51,200 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8354764194651083, 'Total loss': 0.8354764194651083} | train loss {'Reaction outcome loss': 0.8102514046795514, 'Total loss': 0.8102514046795514}
2022-11-18 00:46:51,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:51,201 INFO:     Epoch: 97
2022-11-18 00:46:51,999 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8428102867169813, 'Total loss': 0.8428102867169813} | train loss {'Reaction outcome loss': 0.8106991613397793, 'Total loss': 0.8106991613397793}
2022-11-18 00:46:51,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:51,999 INFO:     Epoch: 98
2022-11-18 00:46:52,775 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8216237303885546, 'Total loss': 0.8216237303885546} | train loss {'Reaction outcome loss': 0.8186541803029119, 'Total loss': 0.8186541803029119}
2022-11-18 00:46:52,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:52,776 INFO:     Epoch: 99
2022-11-18 00:46:53,605 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8363253779032014, 'Total loss': 0.8363253779032014} | train loss {'Reaction outcome loss': 0.8123621377409721, 'Total loss': 0.8123621377409721}
2022-11-18 00:46:53,605 INFO:     Best model found after epoch 34 of 100.
2022-11-18 00:46:53,606 INFO:   Done with stage: TRAINING
2022-11-18 00:46:53,606 INFO:   Starting stage: EVALUATION
2022-11-18 00:46:53,736 INFO:   Done with stage: EVALUATION
2022-11-18 00:46:53,736 INFO:   Leaving out SEQ value Fold_5
2022-11-18 00:46:53,750 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:46:53,750 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:46:54,416 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:46:54,416 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:46:54,491 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:46:54,491 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:46:54,491 INFO:     No hyperparam tuning for this model
2022-11-18 00:46:54,491 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:46:54,491 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:46:54,492 INFO:     None feature selector for col prot
2022-11-18 00:46:54,492 INFO:     None feature selector for col prot
2022-11-18 00:46:54,492 INFO:     None feature selector for col prot
2022-11-18 00:46:54,493 INFO:     None feature selector for col chem
2022-11-18 00:46:54,493 INFO:     None feature selector for col chem
2022-11-18 00:46:54,493 INFO:     None feature selector for col chem
2022-11-18 00:46:54,493 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:46:54,493 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:46:54,495 INFO:     Number of params in model 168571
2022-11-18 00:46:54,498 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:46:54,498 INFO:   Starting stage: TRAINING
2022-11-18 00:46:54,556 INFO:     Val loss before train {'Reaction outcome loss': 1.0623928200114856, 'Total loss': 1.0623928200114856}
2022-11-18 00:46:54,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:54,557 INFO:     Epoch: 0
2022-11-18 00:46:55,363 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9039526920426976, 'Total loss': 0.9039526920426976} | train loss {'Reaction outcome loss': 0.8810409116841521, 'Total loss': 0.8810409116841521}
2022-11-18 00:46:55,363 INFO:     Found new best model at epoch 0
2022-11-18 00:46:55,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:55,364 INFO:     Epoch: 1
2022-11-18 00:46:56,163 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9047470864924517, 'Total loss': 0.9047470864924517} | train loss {'Reaction outcome loss': 0.8355301640897628, 'Total loss': 0.8355301640897628}
2022-11-18 00:46:56,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:56,163 INFO:     Epoch: 2
2022-11-18 00:46:57,010 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8762447102503343, 'Total loss': 0.8762447102503343} | train loss {'Reaction outcome loss': 0.8351886219341262, 'Total loss': 0.8351886219341262}
2022-11-18 00:46:57,010 INFO:     Found new best model at epoch 2
2022-11-18 00:46:57,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:57,011 INFO:     Epoch: 3
2022-11-18 00:46:57,836 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.9314347356557846, 'Total loss': 0.9314347356557846} | train loss {'Reaction outcome loss': 0.8262898405553841, 'Total loss': 0.8262898405553841}
2022-11-18 00:46:57,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:57,836 INFO:     Epoch: 4
2022-11-18 00:46:58,626 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8601620522412387, 'Total loss': 0.8601620522412387} | train loss {'Reaction outcome loss': 0.8306102694770102, 'Total loss': 0.8306102694770102}
2022-11-18 00:46:58,627 INFO:     Found new best model at epoch 4
2022-11-18 00:46:58,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:58,628 INFO:     Epoch: 5
2022-11-18 00:46:59,430 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8949564329602502, 'Total loss': 0.8949564329602502} | train loss {'Reaction outcome loss': 0.8268590966458262, 'Total loss': 0.8268590966458262}
2022-11-18 00:46:59,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:46:59,430 INFO:     Epoch: 6
2022-11-18 00:47:00,241 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8635786257006905, 'Total loss': 0.8635786257006905} | train loss {'Reaction outcome loss': 0.8269168856414223, 'Total loss': 0.8269168856414223}
2022-11-18 00:47:00,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:00,241 INFO:     Epoch: 7
2022-11-18 00:47:01,052 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8657278608192097, 'Total loss': 0.8657278608192097} | train loss {'Reaction outcome loss': 0.8269200939157231, 'Total loss': 0.8269200939157231}
2022-11-18 00:47:01,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:01,052 INFO:     Epoch: 8
2022-11-18 00:47:01,903 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8500973331657323, 'Total loss': 0.8500973331657323} | train loss {'Reaction outcome loss': 0.8283943027137262, 'Total loss': 0.8283943027137262}
2022-11-18 00:47:01,903 INFO:     Found new best model at epoch 8
2022-11-18 00:47:01,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:01,904 INFO:     Epoch: 9
2022-11-18 00:47:02,727 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8640003068880602, 'Total loss': 0.8640003068880602} | train loss {'Reaction outcome loss': 0.8113859636701553, 'Total loss': 0.8113859636701553}
2022-11-18 00:47:02,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:02,728 INFO:     Epoch: 10
2022-11-18 00:47:03,535 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8629379313100468, 'Total loss': 0.8629379313100468} | train loss {'Reaction outcome loss': 0.8221373360166665, 'Total loss': 0.8221373360166665}
2022-11-18 00:47:03,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:03,535 INFO:     Epoch: 11
2022-11-18 00:47:04,364 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.846743606030941, 'Total loss': 0.846743606030941} | train loss {'Reaction outcome loss': 0.8227309460642367, 'Total loss': 0.8227309460642367}
2022-11-18 00:47:04,364 INFO:     Found new best model at epoch 11
2022-11-18 00:47:04,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:04,365 INFO:     Epoch: 12
2022-11-18 00:47:05,180 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8733035637573763, 'Total loss': 0.8733035637573763} | train loss {'Reaction outcome loss': 0.8161234006225339, 'Total loss': 0.8161234006225339}
2022-11-18 00:47:05,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:05,182 INFO:     Epoch: 13
2022-11-18 00:47:05,997 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8601256134835157, 'Total loss': 0.8601256134835157} | train loss {'Reaction outcome loss': 0.8234864928220448, 'Total loss': 0.8234864928220448}
2022-11-18 00:47:05,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:05,997 INFO:     Epoch: 14
2022-11-18 00:47:06,785 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8595318204977296, 'Total loss': 0.8595318204977296} | train loss {'Reaction outcome loss': 0.8162552497466566, 'Total loss': 0.8162552497466566}
2022-11-18 00:47:06,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:06,786 INFO:     Epoch: 15
2022-11-18 00:47:07,614 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8736389672214334, 'Total loss': 0.8736389672214334} | train loss {'Reaction outcome loss': 0.8216175303044106, 'Total loss': 0.8216175303044106}
2022-11-18 00:47:07,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:07,615 INFO:     Epoch: 16
2022-11-18 00:47:08,444 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8543224280530756, 'Total loss': 0.8543224280530756} | train loss {'Reaction outcome loss': 0.814016885482348, 'Total loss': 0.814016885482348}
2022-11-18 00:47:08,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:08,445 INFO:     Epoch: 17
2022-11-18 00:47:09,269 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8533810620958154, 'Total loss': 0.8533810620958154} | train loss {'Reaction outcome loss': 0.8096637118924485, 'Total loss': 0.8096637118924485}
2022-11-18 00:47:09,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:09,269 INFO:     Epoch: 18
2022-11-18 00:47:10,040 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8470887297933752, 'Total loss': 0.8470887297933752} | train loss {'Reaction outcome loss': 0.8133912190251987, 'Total loss': 0.8133912190251987}
2022-11-18 00:47:10,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:10,041 INFO:     Epoch: 19
2022-11-18 00:47:10,859 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.85489091954448, 'Total loss': 0.85489091954448} | train loss {'Reaction outcome loss': 0.8174381547490595, 'Total loss': 0.8174381547490595}
2022-11-18 00:47:10,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:10,860 INFO:     Epoch: 20
2022-11-18 00:47:11,671 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8685315860943361, 'Total loss': 0.8685315860943361} | train loss {'Reaction outcome loss': 0.8221857694961764, 'Total loss': 0.8221857694961764}
2022-11-18 00:47:11,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:11,672 INFO:     Epoch: 21
2022-11-18 00:47:12,517 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.852752878584645, 'Total loss': 0.852752878584645} | train loss {'Reaction outcome loss': 0.8102696550979849, 'Total loss': 0.8102696550979849}
2022-11-18 00:47:12,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:12,517 INFO:     Epoch: 22
2022-11-18 00:47:13,326 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8530491048639471, 'Total loss': 0.8530491048639471} | train loss {'Reaction outcome loss': 0.8089165693593894, 'Total loss': 0.8089165693593894}
2022-11-18 00:47:13,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:13,326 INFO:     Epoch: 23
2022-11-18 00:47:14,161 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8659087284044786, 'Total loss': 0.8659087284044786} | train loss {'Reaction outcome loss': 0.8116631132629719, 'Total loss': 0.8116631132629719}
2022-11-18 00:47:14,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:14,162 INFO:     Epoch: 24
2022-11-18 00:47:14,964 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8653479320081797, 'Total loss': 0.8653479320081797} | train loss {'Reaction outcome loss': 0.8178855225383511, 'Total loss': 0.8178855225383511}
2022-11-18 00:47:14,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:14,964 INFO:     Epoch: 25
2022-11-18 00:47:15,761 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8516764674674381, 'Total loss': 0.8516764674674381} | train loss {'Reaction outcome loss': 0.8103396039501376, 'Total loss': 0.8103396039501376}
2022-11-18 00:47:15,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:15,762 INFO:     Epoch: 26
2022-11-18 00:47:16,590 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8448383740403436, 'Total loss': 0.8448383740403436} | train loss {'Reaction outcome loss': 0.8154527871956226, 'Total loss': 0.8154527871956226}
2022-11-18 00:47:16,590 INFO:     Found new best model at epoch 26
2022-11-18 00:47:16,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:16,591 INFO:     Epoch: 27
2022-11-18 00:47:17,388 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8381514034487985, 'Total loss': 0.8381514034487985} | train loss {'Reaction outcome loss': 0.8127960880637651, 'Total loss': 0.8127960880637651}
2022-11-18 00:47:17,389 INFO:     Found new best model at epoch 27
2022-11-18 00:47:17,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:17,390 INFO:     Epoch: 28
2022-11-18 00:47:18,180 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8729460252956911, 'Total loss': 0.8729460252956911} | train loss {'Reaction outcome loss': 0.8110753647711596, 'Total loss': 0.8110753647711596}
2022-11-18 00:47:18,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:18,180 INFO:     Epoch: 29
2022-11-18 00:47:18,981 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8537824296138503, 'Total loss': 0.8537824296138503} | train loss {'Reaction outcome loss': 0.80943720193527, 'Total loss': 0.80943720193527}
2022-11-18 00:47:18,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:18,981 INFO:     Epoch: 30
2022-11-18 00:47:19,797 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8470131707462397, 'Total loss': 0.8470131707462397} | train loss {'Reaction outcome loss': 0.8092891721107699, 'Total loss': 0.8092891721107699}
2022-11-18 00:47:19,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:19,797 INFO:     Epoch: 31
2022-11-18 00:47:20,621 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8438078977844932, 'Total loss': 0.8438078977844932} | train loss {'Reaction outcome loss': 0.814106281469708, 'Total loss': 0.814106281469708}
2022-11-18 00:47:20,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:20,622 INFO:     Epoch: 32
2022-11-18 00:47:21,419 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8429174226793376, 'Total loss': 0.8429174226793376} | train loss {'Reaction outcome loss': 0.808712386228295, 'Total loss': 0.808712386228295}
2022-11-18 00:47:21,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:21,419 INFO:     Epoch: 33
2022-11-18 00:47:22,246 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8515130078250711, 'Total loss': 0.8515130078250711} | train loss {'Reaction outcome loss': 0.8074750501194946, 'Total loss': 0.8074750501194946}
2022-11-18 00:47:22,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:22,247 INFO:     Epoch: 34
2022-11-18 00:47:23,027 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8623662462288683, 'Total loss': 0.8623662462288683} | train loss {'Reaction outcome loss': 0.8105621731233018, 'Total loss': 0.8105621731233018}
2022-11-18 00:47:23,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:23,027 INFO:     Epoch: 35
2022-11-18 00:47:23,833 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8547545705329288, 'Total loss': 0.8547545705329288} | train loss {'Reaction outcome loss': 0.8109251286095454, 'Total loss': 0.8109251286095454}
2022-11-18 00:47:23,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:23,834 INFO:     Epoch: 36
2022-11-18 00:47:24,616 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8504592762752012, 'Total loss': 0.8504592762752012} | train loss {'Reaction outcome loss': 0.8051887756055184, 'Total loss': 0.8051887756055184}
2022-11-18 00:47:24,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:24,616 INFO:     Epoch: 37
2022-11-18 00:47:25,439 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8497410985556516, 'Total loss': 0.8497410985556516} | train loss {'Reaction outcome loss': 0.8116621779285462, 'Total loss': 0.8116621779285462}
2022-11-18 00:47:25,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:25,440 INFO:     Epoch: 38
2022-11-18 00:47:26,231 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.9023198478601195, 'Total loss': 0.9023198478601195} | train loss {'Reaction outcome loss': 0.8117063958876529, 'Total loss': 0.8117063958876529}
2022-11-18 00:47:26,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:26,231 INFO:     Epoch: 39
2022-11-18 00:47:27,026 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8679604117165912, 'Total loss': 0.8679604117165912} | train loss {'Reaction outcome loss': 0.8091252803319862, 'Total loss': 0.8091252803319862}
2022-11-18 00:47:27,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:27,027 INFO:     Epoch: 40
2022-11-18 00:47:27,834 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.843748885799538, 'Total loss': 0.843748885799538} | train loss {'Reaction outcome loss': 0.811352294104302, 'Total loss': 0.811352294104302}
2022-11-18 00:47:27,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:27,834 INFO:     Epoch: 41
2022-11-18 00:47:28,649 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8411050635305318, 'Total loss': 0.8411050635305318} | train loss {'Reaction outcome loss': 0.8084167524991248, 'Total loss': 0.8084167524991248}
2022-11-18 00:47:28,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:28,649 INFO:     Epoch: 42
2022-11-18 00:47:29,443 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8415461087768729, 'Total loss': 0.8415461087768729} | train loss {'Reaction outcome loss': 0.8113305767779408, 'Total loss': 0.8113305767779408}
2022-11-18 00:47:29,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:29,445 INFO:     Epoch: 43
2022-11-18 00:47:30,267 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8544048775326122, 'Total loss': 0.8544048775326122} | train loss {'Reaction outcome loss': 0.8092036139114425, 'Total loss': 0.8092036139114425}
2022-11-18 00:47:30,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:30,268 INFO:     Epoch: 44
2022-11-18 00:47:31,111 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8401089080355384, 'Total loss': 0.8401089080355384} | train loss {'Reaction outcome loss': 0.8154593449131198, 'Total loss': 0.8154593449131198}
2022-11-18 00:47:31,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:31,111 INFO:     Epoch: 45
2022-11-18 00:47:31,923 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8638327081095089, 'Total loss': 0.8638327081095089} | train loss {'Reaction outcome loss': 0.8066486520805822, 'Total loss': 0.8066486520805822}
2022-11-18 00:47:31,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:31,923 INFO:     Epoch: 46
2022-11-18 00:47:32,779 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8505933826619928, 'Total loss': 0.8505933826619928} | train loss {'Reaction outcome loss': 0.8031399484105438, 'Total loss': 0.8031399484105438}
2022-11-18 00:47:32,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:32,780 INFO:     Epoch: 47
2022-11-18 00:47:33,559 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8672811111265962, 'Total loss': 0.8672811111265962} | train loss {'Reaction outcome loss': 0.8099110362983426, 'Total loss': 0.8099110362983426}
2022-11-18 00:47:33,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:33,559 INFO:     Epoch: 48
2022-11-18 00:47:34,424 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8510077378966592, 'Total loss': 0.8510077378966592} | train loss {'Reaction outcome loss': 0.8083485315444499, 'Total loss': 0.8083485315444499}
2022-11-18 00:47:34,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:34,424 INFO:     Epoch: 49
2022-11-18 00:47:35,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8646203563971953, 'Total loss': 0.8646203563971953} | train loss {'Reaction outcome loss': 0.8075799411426672, 'Total loss': 0.8075799411426672}
2022-11-18 00:47:35,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:35,233 INFO:     Epoch: 50
2022-11-18 00:47:36,051 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8450622138651934, 'Total loss': 0.8450622138651934} | train loss {'Reaction outcome loss': 0.8075819858896588, 'Total loss': 0.8075819858896588}
2022-11-18 00:47:36,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:36,052 INFO:     Epoch: 51
2022-11-18 00:47:36,877 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8737280958078124, 'Total loss': 0.8737280958078124} | train loss {'Reaction outcome loss': 0.8034600234828014, 'Total loss': 0.8034600234828014}
2022-11-18 00:47:36,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:36,877 INFO:     Epoch: 52
2022-11-18 00:47:37,679 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8801490813493729, 'Total loss': 0.8801490813493729} | train loss {'Reaction outcome loss': 0.8076873475512271, 'Total loss': 0.8076873475512271}
2022-11-18 00:47:37,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:37,679 INFO:     Epoch: 53
2022-11-18 00:47:38,502 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8633535253730688, 'Total loss': 0.8633535253730688} | train loss {'Reaction outcome loss': 0.8100315502539337, 'Total loss': 0.8100315502539337}
2022-11-18 00:47:38,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:38,503 INFO:     Epoch: 54
2022-11-18 00:47:39,313 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8490154130214994, 'Total loss': 0.8490154130214994} | train loss {'Reaction outcome loss': 0.8064564958757717, 'Total loss': 0.8064564958757717}
2022-11-18 00:47:39,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:39,313 INFO:     Epoch: 55
2022-11-18 00:47:40,147 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8757733018560843, 'Total loss': 0.8757733018560843} | train loss {'Reaction outcome loss': 0.8117964477674199, 'Total loss': 0.8117964477674199}
2022-11-18 00:47:40,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:40,148 INFO:     Epoch: 56
2022-11-18 00:47:40,941 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8935430375012484, 'Total loss': 0.8935430375012484} | train loss {'Reaction outcome loss': 0.81146505101007, 'Total loss': 0.81146505101007}
2022-11-18 00:47:40,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:40,942 INFO:     Epoch: 57
2022-11-18 00:47:41,745 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.847476608373902, 'Total loss': 0.847476608373902} | train loss {'Reaction outcome loss': 0.8052871036626067, 'Total loss': 0.8052871036626067}
2022-11-18 00:47:41,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:41,745 INFO:     Epoch: 58
2022-11-18 00:47:42,545 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8673571781678633, 'Total loss': 0.8673571781678633} | train loss {'Reaction outcome loss': 0.8084836982884388, 'Total loss': 0.8084836982884388}
2022-11-18 00:47:42,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:42,545 INFO:     Epoch: 59
2022-11-18 00:47:43,352 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.849295736713843, 'Total loss': 0.849295736713843} | train loss {'Reaction outcome loss': 0.8086241616411247, 'Total loss': 0.8086241616411247}
2022-11-18 00:47:43,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:43,352 INFO:     Epoch: 60
2022-11-18 00:47:44,175 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8752521831880916, 'Total loss': 0.8752521831880916} | train loss {'Reaction outcome loss': 0.8059964935306595, 'Total loss': 0.8059964935306595}
2022-11-18 00:47:44,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:44,175 INFO:     Epoch: 61
2022-11-18 00:47:45,015 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8431387421759692, 'Total loss': 0.8431387421759692} | train loss {'Reaction outcome loss': 0.8032748015665332, 'Total loss': 0.8032748015665332}
2022-11-18 00:47:45,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:45,015 INFO:     Epoch: 62
2022-11-18 00:47:45,812 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.9051867188377813, 'Total loss': 0.9051867188377813} | train loss {'Reaction outcome loss': 0.8078044117220983, 'Total loss': 0.8078044117220983}
2022-11-18 00:47:45,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:45,813 INFO:     Epoch: 63
2022-11-18 00:47:46,649 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8619199699976228, 'Total loss': 0.8619199699976228} | train loss {'Reaction outcome loss': 0.8111960860157785, 'Total loss': 0.8111960860157785}
2022-11-18 00:47:46,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:46,649 INFO:     Epoch: 64
2022-11-18 00:47:47,471 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8385885019193996, 'Total loss': 0.8385885019193996} | train loss {'Reaction outcome loss': 0.8123225569725037, 'Total loss': 0.8123225569725037}
2022-11-18 00:47:47,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:47,471 INFO:     Epoch: 65
2022-11-18 00:47:48,274 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8488846197724342, 'Total loss': 0.8488846197724342} | train loss {'Reaction outcome loss': 0.8096909494052532, 'Total loss': 0.8096909494052532}
2022-11-18 00:47:48,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:48,275 INFO:     Epoch: 66
2022-11-18 00:47:49,069 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8665020215240392, 'Total loss': 0.8665020215240392} | train loss {'Reaction outcome loss': 0.8023035676946283, 'Total loss': 0.8023035676946283}
2022-11-18 00:47:49,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:49,070 INFO:     Epoch: 67
2022-11-18 00:47:49,852 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8611901544711806, 'Total loss': 0.8611901544711806} | train loss {'Reaction outcome loss': 0.8033512991208297, 'Total loss': 0.8033512991208297}
2022-11-18 00:47:49,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:49,852 INFO:     Epoch: 68
2022-11-18 00:47:50,703 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8388586023991759, 'Total loss': 0.8388586023991759} | train loss {'Reaction outcome loss': 0.8149517540506989, 'Total loss': 0.8149517540506989}
2022-11-18 00:47:50,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:50,703 INFO:     Epoch: 69
2022-11-18 00:47:51,523 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8394538123499263, 'Total loss': 0.8394538123499263} | train loss {'Reaction outcome loss': 0.8136639972688698, 'Total loss': 0.8136639972688698}
2022-11-18 00:47:51,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:51,523 INFO:     Epoch: 70
2022-11-18 00:47:52,371 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8429470143534921, 'Total loss': 0.8429470143534921} | train loss {'Reaction outcome loss': 0.8129143352933258, 'Total loss': 0.8129143352933258}
2022-11-18 00:47:52,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:52,372 INFO:     Epoch: 71
2022-11-18 00:47:53,164 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8459143157709729, 'Total loss': 0.8459143157709729} | train loss {'Reaction outcome loss': 0.8036719313275958, 'Total loss': 0.8036719313275958}
2022-11-18 00:47:53,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:53,165 INFO:     Epoch: 72
2022-11-18 00:47:53,958 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8536521541801366, 'Total loss': 0.8536521541801366} | train loss {'Reaction outcome loss': 0.8037608324998786, 'Total loss': 0.8037608324998786}
2022-11-18 00:47:53,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:53,958 INFO:     Epoch: 73
2022-11-18 00:47:54,758 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8578116602518342, 'Total loss': 0.8578116602518342} | train loss {'Reaction outcome loss': 0.8067127810074732, 'Total loss': 0.8067127810074732}
2022-11-18 00:47:54,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:54,759 INFO:     Epoch: 74
2022-11-18 00:47:55,547 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8666217313571409, 'Total loss': 0.8666217313571409} | train loss {'Reaction outcome loss': 0.8076973020547797, 'Total loss': 0.8076973020547797}
2022-11-18 00:47:55,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:55,548 INFO:     Epoch: 75
2022-11-18 00:47:56,381 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8392972116443244, 'Total loss': 0.8392972116443244} | train loss {'Reaction outcome loss': 0.8078499545120759, 'Total loss': 0.8078499545120759}
2022-11-18 00:47:56,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:56,381 INFO:     Epoch: 76
2022-11-18 00:47:57,197 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8771338571201671, 'Total loss': 0.8771338571201671} | train loss {'Reaction outcome loss': 0.8062917909882812, 'Total loss': 0.8062917909882812}
2022-11-18 00:47:57,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:57,197 INFO:     Epoch: 77
2022-11-18 00:47:58,030 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8552556247873739, 'Total loss': 0.8552556247873739} | train loss {'Reaction outcome loss': 0.8018950116839486, 'Total loss': 0.8018950116839486}
2022-11-18 00:47:58,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:58,030 INFO:     Epoch: 78
2022-11-18 00:47:58,816 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8376963409510526, 'Total loss': 0.8376963409510526} | train loss {'Reaction outcome loss': 0.7982847872774611, 'Total loss': 0.7982847872774611}
2022-11-18 00:47:58,816 INFO:     Found new best model at epoch 78
2022-11-18 00:47:58,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:58,817 INFO:     Epoch: 79
2022-11-18 00:47:59,588 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8383673233064738, 'Total loss': 0.8383673233064738} | train loss {'Reaction outcome loss': 0.7994127554992433, 'Total loss': 0.7994127554992433}
2022-11-18 00:47:59,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:47:59,588 INFO:     Epoch: 80
2022-11-18 00:48:00,392 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8513628102161668, 'Total loss': 0.8513628102161668} | train loss {'Reaction outcome loss': 0.8033495415077518, 'Total loss': 0.8033495415077518}
2022-11-18 00:48:00,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:00,393 INFO:     Epoch: 81
2022-11-18 00:48:01,191 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8595050471750173, 'Total loss': 0.8595050471750173} | train loss {'Reaction outcome loss': 0.8187023649814158, 'Total loss': 0.8187023649814158}
2022-11-18 00:48:01,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:01,192 INFO:     Epoch: 82
2022-11-18 00:48:01,977 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8614045279947194, 'Total loss': 0.8614045279947194} | train loss {'Reaction outcome loss': 0.8194131794487417, 'Total loss': 0.8194131794487417}
2022-11-18 00:48:01,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:01,977 INFO:     Epoch: 83
2022-11-18 00:48:02,785 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8398050997744907, 'Total loss': 0.8398050997744907} | train loss {'Reaction outcome loss': 0.8062919326398054, 'Total loss': 0.8062919326398054}
2022-11-18 00:48:02,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:02,786 INFO:     Epoch: 84
2022-11-18 00:48:03,562 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8594964343038473, 'Total loss': 0.8594964343038473} | train loss {'Reaction outcome loss': 0.8077152262815097, 'Total loss': 0.8077152262815097}
2022-11-18 00:48:03,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:03,563 INFO:     Epoch: 85
2022-11-18 00:48:04,366 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8698580156673085, 'Total loss': 0.8698580156673085} | train loss {'Reaction outcome loss': 0.8053207811918336, 'Total loss': 0.8053207811918336}
2022-11-18 00:48:04,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:04,366 INFO:     Epoch: 86
2022-11-18 00:48:05,166 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8490533015944741, 'Total loss': 0.8490533015944741} | train loss {'Reaction outcome loss': 0.8001167810850056, 'Total loss': 0.8001167810850056}
2022-11-18 00:48:05,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:05,167 INFO:     Epoch: 87
2022-11-18 00:48:05,942 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8467098542235114, 'Total loss': 0.8467098542235114} | train loss {'Reaction outcome loss': 0.803716769826557, 'Total loss': 0.803716769826557}
2022-11-18 00:48:05,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:05,942 INFO:     Epoch: 88
2022-11-18 00:48:06,736 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8349824297157201, 'Total loss': 0.8349824297157201} | train loss {'Reaction outcome loss': 0.8039614240891537, 'Total loss': 0.8039614240891537}
2022-11-18 00:48:06,737 INFO:     Found new best model at epoch 88
2022-11-18 00:48:06,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:06,738 INFO:     Epoch: 89
2022-11-18 00:48:07,511 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8466124886816199, 'Total loss': 0.8466124886816199} | train loss {'Reaction outcome loss': 0.8081737347701301, 'Total loss': 0.8081737347701301}
2022-11-18 00:48:07,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:07,511 INFO:     Epoch: 90
2022-11-18 00:48:08,318 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8612559180368077, 'Total loss': 0.8612559180368077} | train loss {'Reaction outcome loss': 0.8040145844341773, 'Total loss': 0.8040145844341773}
2022-11-18 00:48:08,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:08,319 INFO:     Epoch: 91
2022-11-18 00:48:09,104 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8478431417183443, 'Total loss': 0.8478431417183443} | train loss {'Reaction outcome loss': 0.8005367384145134, 'Total loss': 0.8005367384145134}
2022-11-18 00:48:09,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:09,105 INFO:     Epoch: 92
2022-11-18 00:48:09,890 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8765234351158142, 'Total loss': 0.8765234351158142} | train loss {'Reaction outcome loss': 0.8022683486040787, 'Total loss': 0.8022683486040787}
2022-11-18 00:48:09,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:09,890 INFO:     Epoch: 93
2022-11-18 00:48:10,677 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8500525578856468, 'Total loss': 0.8500525578856468} | train loss {'Reaction outcome loss': 0.8080654022423363, 'Total loss': 0.8080654022423363}
2022-11-18 00:48:10,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:10,677 INFO:     Epoch: 94
2022-11-18 00:48:11,446 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8410523499954831, 'Total loss': 0.8410523499954831} | train loss {'Reaction outcome loss': 0.8023229016948809, 'Total loss': 0.8023229016948809}
2022-11-18 00:48:11,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:11,447 INFO:     Epoch: 95
2022-11-18 00:48:12,219 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8360773663629185, 'Total loss': 0.8360773663629185} | train loss {'Reaction outcome loss': 0.7992670148731726, 'Total loss': 0.7992670148731726}
2022-11-18 00:48:12,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:12,219 INFO:     Epoch: 96
2022-11-18 00:48:12,998 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8461420590227301, 'Total loss': 0.8461420590227301} | train loss {'Reaction outcome loss': 0.8075741389502398, 'Total loss': 0.8075741389502398}
2022-11-18 00:48:12,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:12,998 INFO:     Epoch: 97
2022-11-18 00:48:13,796 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8590345714579929, 'Total loss': 0.8590345714579929} | train loss {'Reaction outcome loss': 0.8122533136292508, 'Total loss': 0.8122533136292508}
2022-11-18 00:48:13,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:13,796 INFO:     Epoch: 98
2022-11-18 00:48:14,581 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8623217825185169, 'Total loss': 0.8623217825185169} | train loss {'Reaction outcome loss': 0.8073038063671908, 'Total loss': 0.8073038063671908}
2022-11-18 00:48:14,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:14,581 INFO:     Epoch: 99
2022-11-18 00:48:15,365 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8582559465007349, 'Total loss': 0.8582559465007349} | train loss {'Reaction outcome loss': 0.8026754734245872, 'Total loss': 0.8026754734245872}
2022-11-18 00:48:15,365 INFO:     Best model found after epoch 89 of 100.
2022-11-18 00:48:15,366 INFO:   Done with stage: TRAINING
2022-11-18 00:48:15,366 INFO:   Starting stage: EVALUATION
2022-11-18 00:48:15,489 INFO:   Done with stage: EVALUATION
2022-11-18 00:48:15,489 INFO:   Leaving out SEQ value Fold_6
2022-11-18 00:48:15,502 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 00:48:15,503 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:48:16,174 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:48:16,174 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:48:16,247 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:48:16,247 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:48:16,247 INFO:     No hyperparam tuning for this model
2022-11-18 00:48:16,247 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:48:16,248 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:48:16,248 INFO:     None feature selector for col prot
2022-11-18 00:48:16,248 INFO:     None feature selector for col prot
2022-11-18 00:48:16,249 INFO:     None feature selector for col prot
2022-11-18 00:48:16,249 INFO:     None feature selector for col chem
2022-11-18 00:48:16,249 INFO:     None feature selector for col chem
2022-11-18 00:48:16,249 INFO:     None feature selector for col chem
2022-11-18 00:48:16,250 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:48:16,250 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:48:16,251 INFO:     Number of params in model 168571
2022-11-18 00:48:16,254 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:48:16,255 INFO:   Starting stage: TRAINING
2022-11-18 00:48:16,313 INFO:     Val loss before train {'Reaction outcome loss': 0.9594237547029149, 'Total loss': 0.9594237547029149}
2022-11-18 00:48:16,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:16,314 INFO:     Epoch: 0
2022-11-18 00:48:17,100 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8175759180025621, 'Total loss': 0.8175759180025621} | train loss {'Reaction outcome loss': 0.8797864962008691, 'Total loss': 0.8797864962008691}
2022-11-18 00:48:17,100 INFO:     Found new best model at epoch 0
2022-11-18 00:48:17,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:17,101 INFO:     Epoch: 1
2022-11-18 00:48:17,899 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8043461543592539, 'Total loss': 0.8043461543592539} | train loss {'Reaction outcome loss': 0.8497541838836286, 'Total loss': 0.8497541838836286}
2022-11-18 00:48:17,900 INFO:     Found new best model at epoch 1
2022-11-18 00:48:17,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:17,900 INFO:     Epoch: 2
2022-11-18 00:48:18,714 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8152670067819682, 'Total loss': 0.8152670067819682} | train loss {'Reaction outcome loss': 0.8430189461477341, 'Total loss': 0.8430189461477341}
2022-11-18 00:48:18,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:18,714 INFO:     Epoch: 3
2022-11-18 00:48:19,494 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8021673180840232, 'Total loss': 0.8021673180840232} | train loss {'Reaction outcome loss': 0.8447169286589469, 'Total loss': 0.8447169286589469}
2022-11-18 00:48:19,495 INFO:     Found new best model at epoch 3
2022-11-18 00:48:19,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:19,496 INFO:     Epoch: 4
2022-11-18 00:48:20,289 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7907696935263547, 'Total loss': 0.7907696935263547} | train loss {'Reaction outcome loss': 0.8384976533632125, 'Total loss': 0.8384976533632125}
2022-11-18 00:48:20,289 INFO:     Found new best model at epoch 4
2022-11-18 00:48:20,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:20,290 INFO:     Epoch: 5
2022-11-18 00:48:21,077 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7937785867940296, 'Total loss': 0.7937785867940296} | train loss {'Reaction outcome loss': 0.8316614081061655, 'Total loss': 0.8316614081061655}
2022-11-18 00:48:21,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:21,077 INFO:     Epoch: 6
2022-11-18 00:48:21,847 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8346553180705417, 'Total loss': 0.8346553180705417} | train loss {'Reaction outcome loss': 0.8290250365051531, 'Total loss': 0.8290250365051531}
2022-11-18 00:48:21,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:21,847 INFO:     Epoch: 7
2022-11-18 00:48:22,614 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7984953360124067, 'Total loss': 0.7984953360124067} | train loss {'Reaction outcome loss': 0.8256443415678316, 'Total loss': 0.8256443415678316}
2022-11-18 00:48:22,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:22,614 INFO:     Epoch: 8
2022-11-18 00:48:23,409 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7999157126654278, 'Total loss': 0.7999157126654278} | train loss {'Reaction outcome loss': 0.8253277347933862, 'Total loss': 0.8253277347933862}
2022-11-18 00:48:23,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:23,409 INFO:     Epoch: 9
2022-11-18 00:48:24,189 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7828237813982096, 'Total loss': 0.7828237813982096} | train loss {'Reaction outcome loss': 0.8329938341292643, 'Total loss': 0.8329938341292643}
2022-11-18 00:48:24,189 INFO:     Found new best model at epoch 9
2022-11-18 00:48:24,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:24,190 INFO:     Epoch: 10
2022-11-18 00:48:24,970 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7951031171462752, 'Total loss': 0.7951031171462752} | train loss {'Reaction outcome loss': 0.8229467966143162, 'Total loss': 0.8229467966143162}
2022-11-18 00:48:24,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:24,971 INFO:     Epoch: 11
2022-11-18 00:48:25,761 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7955803701823408, 'Total loss': 0.7955803701823408} | train loss {'Reaction outcome loss': 0.8195028338701494, 'Total loss': 0.8195028338701494}
2022-11-18 00:48:25,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:25,761 INFO:     Epoch: 12
2022-11-18 00:48:26,538 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7955659966577183, 'Total loss': 0.7955659966577183} | train loss {'Reaction outcome loss': 0.8235897646555977, 'Total loss': 0.8235897646555977}
2022-11-18 00:48:26,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:26,538 INFO:     Epoch: 13
2022-11-18 00:48:27,294 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7935665026307106, 'Total loss': 0.7935665026307106} | train loss {'Reaction outcome loss': 0.824312558097224, 'Total loss': 0.824312558097224}
2022-11-18 00:48:27,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:27,294 INFO:     Epoch: 14
2022-11-18 00:48:28,072 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7865767973390493, 'Total loss': 0.7865767973390493} | train loss {'Reaction outcome loss': 0.8213262276784066, 'Total loss': 0.8213262276784066}
2022-11-18 00:48:28,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:28,072 INFO:     Epoch: 15
2022-11-18 00:48:28,871 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.777406788685105, 'Total loss': 0.777406788685105} | train loss {'Reaction outcome loss': 0.8199793707218862, 'Total loss': 0.8199793707218862}
2022-11-18 00:48:28,871 INFO:     Found new best model at epoch 15
2022-11-18 00:48:28,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:28,872 INFO:     Epoch: 16
2022-11-18 00:48:29,676 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7879128923470323, 'Total loss': 0.7879128923470323} | train loss {'Reaction outcome loss': 0.824406850482187, 'Total loss': 0.824406850482187}
2022-11-18 00:48:29,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:29,677 INFO:     Epoch: 17
2022-11-18 00:48:30,485 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7922910424796018, 'Total loss': 0.7922910424796018} | train loss {'Reaction outcome loss': 0.8238118861711794, 'Total loss': 0.8238118861711794}
2022-11-18 00:48:30,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:30,485 INFO:     Epoch: 18
2022-11-18 00:48:31,282 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7874007035385479, 'Total loss': 0.7874007035385479} | train loss {'Reaction outcome loss': 0.8224205041844999, 'Total loss': 0.8224205041844999}
2022-11-18 00:48:31,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:31,284 INFO:     Epoch: 19
2022-11-18 00:48:32,089 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7793132154779001, 'Total loss': 0.7793132154779001} | train loss {'Reaction outcome loss': 0.8186862161082606, 'Total loss': 0.8186862161082606}
2022-11-18 00:48:32,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:32,089 INFO:     Epoch: 20
2022-11-18 00:48:32,888 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7888632267713547, 'Total loss': 0.7888632267713547} | train loss {'Reaction outcome loss': 0.8227315533065027, 'Total loss': 0.8227315533065027}
2022-11-18 00:48:32,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:32,888 INFO:     Epoch: 21
2022-11-18 00:48:33,686 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7772556407885118, 'Total loss': 0.7772556407885118} | train loss {'Reaction outcome loss': 0.8191898388247336, 'Total loss': 0.8191898388247336}
2022-11-18 00:48:33,686 INFO:     Found new best model at epoch 21
2022-11-18 00:48:33,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:33,687 INFO:     Epoch: 22
2022-11-18 00:48:34,476 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7772933183745905, 'Total loss': 0.7772933183745905} | train loss {'Reaction outcome loss': 0.8181615318021467, 'Total loss': 0.8181615318021467}
2022-11-18 00:48:34,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:34,476 INFO:     Epoch: 23
2022-11-18 00:48:35,286 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7890580513260581, 'Total loss': 0.7890580513260581} | train loss {'Reaction outcome loss': 0.8203440511659268, 'Total loss': 0.8203440511659268}
2022-11-18 00:48:35,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:35,287 INFO:     Epoch: 24
2022-11-18 00:48:36,095 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7862617739222266, 'Total loss': 0.7862617739222266} | train loss {'Reaction outcome loss': 0.8217017602535986, 'Total loss': 0.8217017602535986}
2022-11-18 00:48:36,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:36,095 INFO:     Epoch: 25
2022-11-18 00:48:36,917 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8006055835973133, 'Total loss': 0.8006055835973133} | train loss {'Reaction outcome loss': 0.8165508816319127, 'Total loss': 0.8165508816319127}
2022-11-18 00:48:36,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:36,917 INFO:     Epoch: 26
2022-11-18 00:48:37,714 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7758587023073976, 'Total loss': 0.7758587023073976} | train loss {'Reaction outcome loss': 0.818181233180146, 'Total loss': 0.818181233180146}
2022-11-18 00:48:37,715 INFO:     Found new best model at epoch 26
2022-11-18 00:48:37,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:37,716 INFO:     Epoch: 27
2022-11-18 00:48:38,521 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7787973081523721, 'Total loss': 0.7787973081523721} | train loss {'Reaction outcome loss': 0.8235388960569135, 'Total loss': 0.8235388960569135}
2022-11-18 00:48:38,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:38,521 INFO:     Epoch: 28
2022-11-18 00:48:39,308 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7787713990970091, 'Total loss': 0.7787713990970091} | train loss {'Reaction outcome loss': 0.817162171607056, 'Total loss': 0.817162171607056}
2022-11-18 00:48:39,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:39,308 INFO:     Epoch: 29
2022-11-18 00:48:40,093 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.799661523239179, 'Total loss': 0.799661523239179} | train loss {'Reaction outcome loss': 0.8221756246301436, 'Total loss': 0.8221756246301436}
2022-11-18 00:48:40,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:40,093 INFO:     Epoch: 30
2022-11-18 00:48:40,894 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7817816158587282, 'Total loss': 0.7817816158587282} | train loss {'Reaction outcome loss': 0.8194375109047659, 'Total loss': 0.8194375109047659}
2022-11-18 00:48:40,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:40,894 INFO:     Epoch: 31
2022-11-18 00:48:41,670 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.782138311050155, 'Total loss': 0.782138311050155} | train loss {'Reaction outcome loss': 0.8190566533275189, 'Total loss': 0.8190566533275189}
2022-11-18 00:48:41,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:41,671 INFO:     Epoch: 32
2022-11-18 00:48:42,452 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7837541699409485, 'Total loss': 0.7837541699409485} | train loss {'Reaction outcome loss': 0.8179330453276634, 'Total loss': 0.8179330453276634}
2022-11-18 00:48:42,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:42,452 INFO:     Epoch: 33
2022-11-18 00:48:43,249 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7779691043225202, 'Total loss': 0.7779691043225202} | train loss {'Reaction outcome loss': 0.8157855936836812, 'Total loss': 0.8157855936836812}
2022-11-18 00:48:43,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:43,249 INFO:     Epoch: 34
2022-11-18 00:48:44,040 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7811537655917081, 'Total loss': 0.7811537655917081} | train loss {'Reaction outcome loss': 0.8173096046572731, 'Total loss': 0.8173096046572731}
2022-11-18 00:48:44,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:44,041 INFO:     Epoch: 35
2022-11-18 00:48:44,801 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7955884852192618, 'Total loss': 0.7955884852192618} | train loss {'Reaction outcome loss': 0.8197668512021342, 'Total loss': 0.8197668512021342}
2022-11-18 00:48:44,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:44,801 INFO:     Epoch: 36
2022-11-18 00:48:45,592 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7796746634624221, 'Total loss': 0.7796746634624221} | train loss {'Reaction outcome loss': 0.8168833776106758, 'Total loss': 0.8168833776106758}
2022-11-18 00:48:45,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:45,593 INFO:     Epoch: 37
2022-11-18 00:48:46,392 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7999026606028731, 'Total loss': 0.7999026606028731} | train loss {'Reaction outcome loss': 0.8226359402460437, 'Total loss': 0.8226359402460437}
2022-11-18 00:48:46,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:46,392 INFO:     Epoch: 38
2022-11-18 00:48:47,166 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7687674489888278, 'Total loss': 0.7687674489888278} | train loss {'Reaction outcome loss': 0.8151525811202103, 'Total loss': 0.8151525811202103}
2022-11-18 00:48:47,166 INFO:     Found new best model at epoch 38
2022-11-18 00:48:47,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:47,167 INFO:     Epoch: 39
2022-11-18 00:48:47,964 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7756872956048358, 'Total loss': 0.7756872956048358} | train loss {'Reaction outcome loss': 0.8166878486592923, 'Total loss': 0.8166878486592923}
2022-11-18 00:48:47,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:47,965 INFO:     Epoch: 40
2022-11-18 00:48:48,744 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7822929654609073, 'Total loss': 0.7822929654609073} | train loss {'Reaction outcome loss': 0.820726715028286, 'Total loss': 0.820726715028286}
2022-11-18 00:48:48,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:48,744 INFO:     Epoch: 41
2022-11-18 00:48:49,537 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7882454957474362, 'Total loss': 0.7882454957474362} | train loss {'Reaction outcome loss': 0.8195852407765004, 'Total loss': 0.8195852407765004}
2022-11-18 00:48:49,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:49,538 INFO:     Epoch: 42
2022-11-18 00:48:50,288 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8181877718730406, 'Total loss': 0.8181877718730406} | train loss {'Reaction outcome loss': 0.8203734339725587, 'Total loss': 0.8203734339725587}
2022-11-18 00:48:50,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:50,289 INFO:     Epoch: 43
2022-11-18 00:48:51,067 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7855836979367516, 'Total loss': 0.7855836979367516} | train loss {'Reaction outcome loss': 0.8182979133580962, 'Total loss': 0.8182979133580962}
2022-11-18 00:48:51,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:51,067 INFO:     Epoch: 44
2022-11-18 00:48:51,852 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7976610227064653, 'Total loss': 0.7976610227064653} | train loss {'Reaction outcome loss': 0.8186126884914213, 'Total loss': 0.8186126884914213}
2022-11-18 00:48:51,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:51,852 INFO:     Epoch: 45
2022-11-18 00:48:52,645 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7882373454895887, 'Total loss': 0.7882373454895887} | train loss {'Reaction outcome loss': 0.8165703920587417, 'Total loss': 0.8165703920587417}
2022-11-18 00:48:52,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:52,646 INFO:     Epoch: 46
2022-11-18 00:48:53,448 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7948215935717929, 'Total loss': 0.7948215935717929} | train loss {'Reaction outcome loss': 0.8157071221259332, 'Total loss': 0.8157071221259332}
2022-11-18 00:48:53,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:53,448 INFO:     Epoch: 47
2022-11-18 00:48:54,238 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7779931222850626, 'Total loss': 0.7779931222850626} | train loss {'Reaction outcome loss': 0.819157368593639, 'Total loss': 0.819157368593639}
2022-11-18 00:48:54,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:54,238 INFO:     Epoch: 48
2022-11-18 00:48:55,030 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7825988056984815, 'Total loss': 0.7825988056984815} | train loss {'Reaction outcome loss': 0.816161768210511, 'Total loss': 0.816161768210511}
2022-11-18 00:48:55,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:55,031 INFO:     Epoch: 49
2022-11-18 00:48:55,804 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7931625003164465, 'Total loss': 0.7931625003164465} | train loss {'Reaction outcome loss': 0.8189756532590236, 'Total loss': 0.8189756532590236}
2022-11-18 00:48:55,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:55,805 INFO:     Epoch: 50
2022-11-18 00:48:56,601 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7753582840616052, 'Total loss': 0.7753582840616052} | train loss {'Reaction outcome loss': 0.8134080755614466, 'Total loss': 0.8134080755614466}
2022-11-18 00:48:56,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:56,601 INFO:     Epoch: 51
2022-11-18 00:48:57,383 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7727504772218791, 'Total loss': 0.7727504772218791} | train loss {'Reaction outcome loss': 0.8209666774397896, 'Total loss': 0.8209666774397896}
2022-11-18 00:48:57,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:57,383 INFO:     Epoch: 52
2022-11-18 00:48:58,182 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7750236195596781, 'Total loss': 0.7750236195596781} | train loss {'Reaction outcome loss': 0.8171583831069931, 'Total loss': 0.8171583831069931}
2022-11-18 00:48:58,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:58,183 INFO:     Epoch: 53
2022-11-18 00:48:58,967 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7872662523930724, 'Total loss': 0.7872662523930724} | train loss {'Reaction outcome loss': 0.8186557691904807, 'Total loss': 0.8186557691904807}
2022-11-18 00:48:58,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:58,968 INFO:     Epoch: 54
2022-11-18 00:48:59,744 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7765574373982169, 'Total loss': 0.7765574373982169} | train loss {'Reaction outcome loss': 0.8168804897896705, 'Total loss': 0.8168804897896705}
2022-11-18 00:48:59,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:48:59,744 INFO:     Epoch: 55
2022-11-18 00:49:00,546 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7671037661758336, 'Total loss': 0.7671037661758336} | train loss {'Reaction outcome loss': 0.8148493236832081, 'Total loss': 0.8148493236832081}
2022-11-18 00:49:00,546 INFO:     Found new best model at epoch 55
2022-11-18 00:49:00,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:00,547 INFO:     Epoch: 56
2022-11-18 00:49:01,347 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7832533039829948, 'Total loss': 0.7832533039829948} | train loss {'Reaction outcome loss': 0.818435569564181, 'Total loss': 0.818435569564181}
2022-11-18 00:49:01,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:01,347 INFO:     Epoch: 57
2022-11-18 00:49:02,127 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7816776375878941, 'Total loss': 0.7816776375878941} | train loss {'Reaction outcome loss': 0.8155174569016502, 'Total loss': 0.8155174569016502}
2022-11-18 00:49:02,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:02,129 INFO:     Epoch: 58
2022-11-18 00:49:02,902 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7886900210922415, 'Total loss': 0.7886900210922415} | train loss {'Reaction outcome loss': 0.8152050190274754, 'Total loss': 0.8152050190274754}
2022-11-18 00:49:02,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:02,902 INFO:     Epoch: 59
2022-11-18 00:49:03,683 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7881810319694605, 'Total loss': 0.7881810319694605} | train loss {'Reaction outcome loss': 0.8148774338225203, 'Total loss': 0.8148774338225203}
2022-11-18 00:49:03,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:03,684 INFO:     Epoch: 60
2022-11-18 00:49:04,468 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7783313921906732, 'Total loss': 0.7783313921906732} | train loss {'Reaction outcome loss': 0.8141685421428373, 'Total loss': 0.8141685421428373}
2022-11-18 00:49:04,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:04,469 INFO:     Epoch: 61
2022-11-18 00:49:05,270 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7759989737109705, 'Total loss': 0.7759989737109705} | train loss {'Reaction outcome loss': 0.8168612002365051, 'Total loss': 0.8168612002365051}
2022-11-18 00:49:05,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:05,270 INFO:     Epoch: 62
2022-11-18 00:49:06,040 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7828498712994836, 'Total loss': 0.7828498712994836} | train loss {'Reaction outcome loss': 0.8192074411819058, 'Total loss': 0.8192074411819058}
2022-11-18 00:49:06,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:06,040 INFO:     Epoch: 63
2022-11-18 00:49:06,838 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7698281028053977, 'Total loss': 0.7698281028053977} | train loss {'Reaction outcome loss': 0.8203568098045164, 'Total loss': 0.8203568098045164}
2022-11-18 00:49:06,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:06,838 INFO:     Epoch: 64
2022-11-18 00:49:07,604 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.772570317441767, 'Total loss': 0.772570317441767} | train loss {'Reaction outcome loss': 0.8134864092834534, 'Total loss': 0.8134864092834534}
2022-11-18 00:49:07,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:07,604 INFO:     Epoch: 65
2022-11-18 00:49:08,367 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7891804454001513, 'Total loss': 0.7891804454001513} | train loss {'Reaction outcome loss': 0.8176644181291903, 'Total loss': 0.8176644181291903}
2022-11-18 00:49:08,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:08,368 INFO:     Epoch: 66
2022-11-18 00:49:09,141 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8143332593820312, 'Total loss': 0.8143332593820312} | train loss {'Reaction outcome loss': 0.811960749808819, 'Total loss': 0.811960749808819}
2022-11-18 00:49:09,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:09,141 INFO:     Epoch: 67
2022-11-18 00:49:09,926 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7898104996843771, 'Total loss': 0.7898104996843771} | train loss {'Reaction outcome loss': 0.8202351167077019, 'Total loss': 0.8202351167077019}
2022-11-18 00:49:09,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:09,926 INFO:     Epoch: 68
2022-11-18 00:49:10,727 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8060235462405465, 'Total loss': 0.8060235462405465} | train loss {'Reaction outcome loss': 0.8200062365541535, 'Total loss': 0.8200062365541535}
2022-11-18 00:49:10,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:10,727 INFO:     Epoch: 69
2022-11-18 00:49:11,514 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7937560433691199, 'Total loss': 0.7937560433691199} | train loss {'Reaction outcome loss': 0.8135073992513842, 'Total loss': 0.8135073992513842}
2022-11-18 00:49:11,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:11,514 INFO:     Epoch: 70
2022-11-18 00:49:12,300 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7842056609012864, 'Total loss': 0.7842056609012864} | train loss {'Reaction outcome loss': 0.8129228742853287, 'Total loss': 0.8129228742853287}
2022-11-18 00:49:12,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:12,301 INFO:     Epoch: 71
2022-11-18 00:49:13,086 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7722512253306129, 'Total loss': 0.7722512253306129} | train loss {'Reaction outcome loss': 0.8160243059598631, 'Total loss': 0.8160243059598631}
2022-11-18 00:49:13,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:13,086 INFO:     Epoch: 72
2022-11-18 00:49:13,910 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7952933081171729, 'Total loss': 0.7952933081171729} | train loss {'Reaction outcome loss': 0.8175515593780626, 'Total loss': 0.8175515593780626}
2022-11-18 00:49:13,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:13,910 INFO:     Epoch: 73
2022-11-18 00:49:14,703 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7761474333026193, 'Total loss': 0.7761474333026193} | train loss {'Reaction outcome loss': 0.8220963556199304, 'Total loss': 0.8220963556199304}
2022-11-18 00:49:14,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:14,703 INFO:     Epoch: 74
2022-11-18 00:49:15,540 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7868914671919562, 'Total loss': 0.7868914671919562} | train loss {'Reaction outcome loss': 0.818008478370405, 'Total loss': 0.818008478370405}
2022-11-18 00:49:15,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:15,541 INFO:     Epoch: 75
2022-11-18 00:49:16,370 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.780113659799099, 'Total loss': 0.780113659799099} | train loss {'Reaction outcome loss': 0.81775619378013, 'Total loss': 0.81775619378013}
2022-11-18 00:49:16,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:16,370 INFO:     Epoch: 76
2022-11-18 00:49:17,178 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7711209675127809, 'Total loss': 0.7711209675127809} | train loss {'Reaction outcome loss': 0.8158483139930233, 'Total loss': 0.8158483139930233}
2022-11-18 00:49:17,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:17,178 INFO:     Epoch: 77
2022-11-18 00:49:17,994 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8327181081880223, 'Total loss': 0.8327181081880223} | train loss {'Reaction outcome loss': 0.8167474301111314, 'Total loss': 0.8167474301111314}
2022-11-18 00:49:17,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:17,995 INFO:     Epoch: 78
2022-11-18 00:49:18,812 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7817898446863348, 'Total loss': 0.7817898446863348} | train loss {'Reaction outcome loss': 0.8161233215322418, 'Total loss': 0.8161233215322418}
2022-11-18 00:49:18,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:18,813 INFO:     Epoch: 79
2022-11-18 00:49:19,625 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7823874215510759, 'Total loss': 0.7823874215510759} | train loss {'Reaction outcome loss': 0.8118705084967998, 'Total loss': 0.8118705084967998}
2022-11-18 00:49:19,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:19,625 INFO:     Epoch: 80
2022-11-18 00:49:20,448 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7563110932030461, 'Total loss': 0.7563110932030461} | train loss {'Reaction outcome loss': 0.8153757079234046, 'Total loss': 0.8153757079234046}
2022-11-18 00:49:20,449 INFO:     Found new best model at epoch 80
2022-11-18 00:49:20,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:20,450 INFO:     Epoch: 81
2022-11-18 00:49:21,227 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7822776118462736, 'Total loss': 0.7822776118462736} | train loss {'Reaction outcome loss': 0.8160080335313274, 'Total loss': 0.8160080335313274}
2022-11-18 00:49:21,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:21,228 INFO:     Epoch: 82
2022-11-18 00:49:22,026 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7698647203770551, 'Total loss': 0.7698647203770551} | train loss {'Reaction outcome loss': 0.81513702268562, 'Total loss': 0.81513702268562}
2022-11-18 00:49:22,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:22,027 INFO:     Epoch: 83
2022-11-18 00:49:22,851 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7769582278349183, 'Total loss': 0.7769582278349183} | train loss {'Reaction outcome loss': 0.8211798094693692, 'Total loss': 0.8211798094693692}
2022-11-18 00:49:22,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:22,852 INFO:     Epoch: 84
2022-11-18 00:49:23,688 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7813566848635674, 'Total loss': 0.7813566848635674} | train loss {'Reaction outcome loss': 0.8152486212070911, 'Total loss': 0.8152486212070911}
2022-11-18 00:49:23,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:23,688 INFO:     Epoch: 85
2022-11-18 00:49:24,473 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7644115706736391, 'Total loss': 0.7644115706736391} | train loss {'Reaction outcome loss': 0.8147980807529341, 'Total loss': 0.8147980807529341}
2022-11-18 00:49:24,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:24,474 INFO:     Epoch: 86
2022-11-18 00:49:25,261 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7876777283170007, 'Total loss': 0.7876777283170007} | train loss {'Reaction outcome loss': 0.816183436541788, 'Total loss': 0.816183436541788}
2022-11-18 00:49:25,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:25,261 INFO:     Epoch: 87
2022-11-18 00:49:26,042 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7728625210848722, 'Total loss': 0.7728625210848722} | train loss {'Reaction outcome loss': 0.8192129714354393, 'Total loss': 0.8192129714354393}
2022-11-18 00:49:26,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:26,042 INFO:     Epoch: 88
2022-11-18 00:49:26,815 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7767455185001547, 'Total loss': 0.7767455185001547} | train loss {'Reaction outcome loss': 0.8171462589694608, 'Total loss': 0.8171462589694608}
2022-11-18 00:49:26,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:26,815 INFO:     Epoch: 89
2022-11-18 00:49:27,590 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.782852744514292, 'Total loss': 0.782852744514292} | train loss {'Reaction outcome loss': 0.8168783942537923, 'Total loss': 0.8168783942537923}
2022-11-18 00:49:27,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:27,591 INFO:     Epoch: 90
2022-11-18 00:49:28,397 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7914516925811768, 'Total loss': 0.7914516925811768} | train loss {'Reaction outcome loss': 0.8203036556801488, 'Total loss': 0.8203036556801488}
2022-11-18 00:49:28,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:28,397 INFO:     Epoch: 91
2022-11-18 00:49:29,221 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7841373390772126, 'Total loss': 0.7841373390772126} | train loss {'Reaction outcome loss': 0.8147441535707443, 'Total loss': 0.8147441535707443}
2022-11-18 00:49:29,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:29,222 INFO:     Epoch: 92
2022-11-18 00:49:29,984 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7894330837509849, 'Total loss': 0.7894330837509849} | train loss {'Reaction outcome loss': 0.8185928296898642, 'Total loss': 0.8185928296898642}
2022-11-18 00:49:29,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:29,984 INFO:     Epoch: 93
2022-11-18 00:49:30,793 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7956294972788204, 'Total loss': 0.7956294972788204} | train loss {'Reaction outcome loss': 0.8137192984502162, 'Total loss': 0.8137192984502162}
2022-11-18 00:49:30,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:30,793 INFO:     Epoch: 94
2022-11-18 00:49:31,578 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7902662848884409, 'Total loss': 0.7902662848884409} | train loss {'Reaction outcome loss': 0.8173117143732886, 'Total loss': 0.8173117143732886}
2022-11-18 00:49:31,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:31,578 INFO:     Epoch: 95
2022-11-18 00:49:32,369 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7794556936079805, 'Total loss': 0.7794556936079805} | train loss {'Reaction outcome loss': 0.8163890652959386, 'Total loss': 0.8163890652959386}
2022-11-18 00:49:32,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:32,370 INFO:     Epoch: 96
2022-11-18 00:49:33,154 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7785733511502092, 'Total loss': 0.7785733511502092} | train loss {'Reaction outcome loss': 0.8156097725995125, 'Total loss': 0.8156097725995125}
2022-11-18 00:49:33,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:33,156 INFO:     Epoch: 97
2022-11-18 00:49:33,943 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7885744016278874, 'Total loss': 0.7885744016278874} | train loss {'Reaction outcome loss': 0.814758857772235, 'Total loss': 0.814758857772235}
2022-11-18 00:49:33,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:33,943 INFO:     Epoch: 98
2022-11-18 00:49:34,744 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7784720198674635, 'Total loss': 0.7784720198674635} | train loss {'Reaction outcome loss': 0.8168223910033703, 'Total loss': 0.8168223910033703}
2022-11-18 00:49:34,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:34,744 INFO:     Epoch: 99
2022-11-18 00:49:35,522 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7793886390599337, 'Total loss': 0.7793886390599337} | train loss {'Reaction outcome loss': 0.8185223562102164, 'Total loss': 0.8185223562102164}
2022-11-18 00:49:35,522 INFO:     Best model found after epoch 81 of 100.
2022-11-18 00:49:35,522 INFO:   Done with stage: TRAINING
2022-11-18 00:49:35,522 INFO:   Starting stage: EVALUATION
2022-11-18 00:49:35,641 INFO:   Done with stage: EVALUATION
2022-11-18 00:49:35,641 INFO:   Leaving out SEQ value Fold_7
2022-11-18 00:49:35,654 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 00:49:35,655 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:49:36,328 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:49:36,328 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:49:36,399 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:49:36,400 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:49:36,400 INFO:     No hyperparam tuning for this model
2022-11-18 00:49:36,400 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:49:36,400 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:49:36,401 INFO:     None feature selector for col prot
2022-11-18 00:49:36,401 INFO:     None feature selector for col prot
2022-11-18 00:49:36,401 INFO:     None feature selector for col prot
2022-11-18 00:49:36,402 INFO:     None feature selector for col chem
2022-11-18 00:49:36,402 INFO:     None feature selector for col chem
2022-11-18 00:49:36,402 INFO:     None feature selector for col chem
2022-11-18 00:49:36,402 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:49:36,402 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:49:36,403 INFO:     Number of params in model 168571
2022-11-18 00:49:36,407 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:49:36,407 INFO:   Starting stage: TRAINING
2022-11-18 00:49:36,466 INFO:     Val loss before train {'Reaction outcome loss': 0.9919234162027185, 'Total loss': 0.9919234162027185}
2022-11-18 00:49:36,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:36,466 INFO:     Epoch: 0
2022-11-18 00:49:37,259 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8240053653717041, 'Total loss': 0.8240053653717041} | train loss {'Reaction outcome loss': 0.8712182276912274, 'Total loss': 0.8712182276912274}
2022-11-18 00:49:37,259 INFO:     Found new best model at epoch 0
2022-11-18 00:49:37,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:37,260 INFO:     Epoch: 1
2022-11-18 00:49:38,042 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8198343698274005, 'Total loss': 0.8198343698274005} | train loss {'Reaction outcome loss': 0.8357180187538746, 'Total loss': 0.8357180187538746}
2022-11-18 00:49:38,042 INFO:     Found new best model at epoch 1
2022-11-18 00:49:38,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:38,043 INFO:     Epoch: 2
2022-11-18 00:49:38,820 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8367271084677089, 'Total loss': 0.8367271084677089} | train loss {'Reaction outcome loss': 0.8259073433376127, 'Total loss': 0.8259073433376127}
2022-11-18 00:49:38,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:38,820 INFO:     Epoch: 3
2022-11-18 00:49:39,599 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8147796622731469, 'Total loss': 0.8147796622731469} | train loss {'Reaction outcome loss': 0.8250618780091885, 'Total loss': 0.8250618780091885}
2022-11-18 00:49:39,599 INFO:     Found new best model at epoch 3
2022-11-18 00:49:39,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:39,600 INFO:     Epoch: 4
2022-11-18 00:49:40,404 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8228250755505129, 'Total loss': 0.8228250755505129} | train loss {'Reaction outcome loss': 0.8230203822735818, 'Total loss': 0.8230203822735818}
2022-11-18 00:49:40,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:40,404 INFO:     Epoch: 5
2022-11-18 00:49:41,187 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8105362789197401, 'Total loss': 0.8105362789197401} | train loss {'Reaction outcome loss': 0.8133162032933005, 'Total loss': 0.8133162032933005}
2022-11-18 00:49:41,187 INFO:     Found new best model at epoch 5
2022-11-18 00:49:41,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:41,188 INFO:     Epoch: 6
2022-11-18 00:49:41,984 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8039159781553529, 'Total loss': 0.8039159781553529} | train loss {'Reaction outcome loss': 0.8158474577771079, 'Total loss': 0.8158474577771079}
2022-11-18 00:49:41,985 INFO:     Found new best model at epoch 6
2022-11-18 00:49:41,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:41,985 INFO:     Epoch: 7
2022-11-18 00:49:42,779 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8161504559896209, 'Total loss': 0.8161504559896209} | train loss {'Reaction outcome loss': 0.8175222778752926, 'Total loss': 0.8175222778752926}
2022-11-18 00:49:42,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:42,779 INFO:     Epoch: 8
2022-11-18 00:49:43,639 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8103543188084256, 'Total loss': 0.8103543188084256} | train loss {'Reaction outcome loss': 0.8127662958877702, 'Total loss': 0.8127662958877702}
2022-11-18 00:49:43,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:43,639 INFO:     Epoch: 9
2022-11-18 00:49:44,426 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8029425076463006, 'Total loss': 0.8029425076463006} | train loss {'Reaction outcome loss': 0.8134422277010256, 'Total loss': 0.8134422277010256}
2022-11-18 00:49:44,426 INFO:     Found new best model at epoch 9
2022-11-18 00:49:44,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:44,427 INFO:     Epoch: 10
2022-11-18 00:49:45,250 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7994706894863736, 'Total loss': 0.7994706894863736} | train loss {'Reaction outcome loss': 0.8128303025038012, 'Total loss': 0.8128303025038012}
2022-11-18 00:49:45,250 INFO:     Found new best model at epoch 10
2022-11-18 00:49:45,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:45,251 INFO:     Epoch: 11
2022-11-18 00:49:46,066 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8101281083442948, 'Total loss': 0.8101281083442948} | train loss {'Reaction outcome loss': 0.8143750637048676, 'Total loss': 0.8143750637048676}
2022-11-18 00:49:46,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:46,067 INFO:     Epoch: 12
2022-11-18 00:49:46,880 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8136364465410059, 'Total loss': 0.8136364465410059} | train loss {'Reaction outcome loss': 0.812087677299015, 'Total loss': 0.812087677299015}
2022-11-18 00:49:46,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:46,881 INFO:     Epoch: 13
2022-11-18 00:49:47,669 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8095429465174675, 'Total loss': 0.8095429465174675} | train loss {'Reaction outcome loss': 0.805784959886824, 'Total loss': 0.805784959886824}
2022-11-18 00:49:47,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:47,669 INFO:     Epoch: 14
2022-11-18 00:49:48,483 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8015638244422999, 'Total loss': 0.8015638244422999} | train loss {'Reaction outcome loss': 0.8132537564923686, 'Total loss': 0.8132537564923686}
2022-11-18 00:49:48,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:48,484 INFO:     Epoch: 15
2022-11-18 00:49:49,330 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8182171894745394, 'Total loss': 0.8182171894745394} | train loss {'Reaction outcome loss': 0.8095847264893593, 'Total loss': 0.8095847264893593}
2022-11-18 00:49:49,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:49,331 INFO:     Epoch: 16
2022-11-18 00:49:50,111 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8154326209967787, 'Total loss': 0.8154326209967787} | train loss {'Reaction outcome loss': 0.809329143695293, 'Total loss': 0.809329143695293}
2022-11-18 00:49:50,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:50,111 INFO:     Epoch: 17
2022-11-18 00:49:50,937 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8101970743049275, 'Total loss': 0.8101970743049275} | train loss {'Reaction outcome loss': 0.8103751131603795, 'Total loss': 0.8103751131603795}
2022-11-18 00:49:50,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:50,938 INFO:     Epoch: 18
2022-11-18 00:49:51,751 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8127608908848329, 'Total loss': 0.8127608908848329} | train loss {'Reaction outcome loss': 0.8075382916196701, 'Total loss': 0.8075382916196701}
2022-11-18 00:49:51,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:51,752 INFO:     Epoch: 19
2022-11-18 00:49:52,598 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8085470565340735, 'Total loss': 0.8085470565340735} | train loss {'Reaction outcome loss': 0.8059534363208278, 'Total loss': 0.8059534363208278}
2022-11-18 00:49:52,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:52,599 INFO:     Epoch: 20
2022-11-18 00:49:53,466 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8075073591687463, 'Total loss': 0.8075073591687463} | train loss {'Reaction outcome loss': 0.8075190943575674, 'Total loss': 0.8075190943575674}
2022-11-18 00:49:53,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:53,466 INFO:     Epoch: 21
2022-11-18 00:49:54,303 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8053637214682319, 'Total loss': 0.8053637214682319} | train loss {'Reaction outcome loss': 0.8118497979256415, 'Total loss': 0.8118497979256415}
2022-11-18 00:49:54,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:54,303 INFO:     Epoch: 22
2022-11-18 00:49:55,129 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7950555980205536, 'Total loss': 0.7950555980205536} | train loss {'Reaction outcome loss': 0.8042979661014772, 'Total loss': 0.8042979661014772}
2022-11-18 00:49:55,129 INFO:     Found new best model at epoch 22
2022-11-18 00:49:55,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:55,130 INFO:     Epoch: 23
2022-11-18 00:49:55,943 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8108177069913257, 'Total loss': 0.8108177069913257} | train loss {'Reaction outcome loss': 0.8065934959919222, 'Total loss': 0.8065934959919222}
2022-11-18 00:49:55,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:55,943 INFO:     Epoch: 24
2022-11-18 00:49:56,730 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.79863848334009, 'Total loss': 0.79863848334009} | train loss {'Reaction outcome loss': 0.8038474945051055, 'Total loss': 0.8038474945051055}
2022-11-18 00:49:56,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:56,730 INFO:     Epoch: 25
2022-11-18 00:49:57,532 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7942399108274416, 'Total loss': 0.7942399108274416} | train loss {'Reaction outcome loss': 0.807277409059386, 'Total loss': 0.807277409059386}
2022-11-18 00:49:57,532 INFO:     Found new best model at epoch 25
2022-11-18 00:49:57,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:57,533 INFO:     Epoch: 26
2022-11-18 00:49:58,345 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8046183768998493, 'Total loss': 0.8046183768998493} | train loss {'Reaction outcome loss': 0.8058696010660741, 'Total loss': 0.8058696010660741}
2022-11-18 00:49:58,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:58,346 INFO:     Epoch: 27
2022-11-18 00:49:59,184 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8149134509942748, 'Total loss': 0.8149134509942748} | train loss {'Reaction outcome loss': 0.8045748413330124, 'Total loss': 0.8045748413330124}
2022-11-18 00:49:59,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:49:59,185 INFO:     Epoch: 28
2022-11-18 00:50:00,011 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8431299423629587, 'Total loss': 0.8431299423629587} | train loss {'Reaction outcome loss': 0.8020149576327493, 'Total loss': 0.8020149576327493}
2022-11-18 00:50:00,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:00,012 INFO:     Epoch: 29
2022-11-18 00:50:00,807 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8104201724583452, 'Total loss': 0.8104201724583452} | train loss {'Reaction outcome loss': 0.8118284660721978, 'Total loss': 0.8118284660721978}
2022-11-18 00:50:00,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:00,808 INFO:     Epoch: 30
2022-11-18 00:50:01,645 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8147955232045867, 'Total loss': 0.8147955232045867} | train loss {'Reaction outcome loss': 0.8077296506493322, 'Total loss': 0.8077296506493322}
2022-11-18 00:50:01,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:01,645 INFO:     Epoch: 31
2022-11-18 00:50:02,441 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8013749759305607, 'Total loss': 0.8013749759305607} | train loss {'Reaction outcome loss': 0.8080960702030889, 'Total loss': 0.8080960702030889}
2022-11-18 00:50:02,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:02,441 INFO:     Epoch: 32
2022-11-18 00:50:03,245 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8309940248727798, 'Total loss': 0.8309940248727798} | train loss {'Reaction outcome loss': 0.8070539532890243, 'Total loss': 0.8070539532890243}
2022-11-18 00:50:03,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:03,245 INFO:     Epoch: 33
2022-11-18 00:50:04,059 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7976212284781716, 'Total loss': 0.7976212284781716} | train loss {'Reaction outcome loss': 0.804816298547291, 'Total loss': 0.804816298547291}
2022-11-18 00:50:04,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:04,061 INFO:     Epoch: 34
2022-11-18 00:50:04,841 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.806856086308306, 'Total loss': 0.806856086308306} | train loss {'Reaction outcome loss': 0.8045175484712085, 'Total loss': 0.8045175484712085}
2022-11-18 00:50:04,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:04,841 INFO:     Epoch: 35
2022-11-18 00:50:05,628 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7907076979225333, 'Total loss': 0.7907076979225333} | train loss {'Reaction outcome loss': 0.8044475467214661, 'Total loss': 0.8044475467214661}
2022-11-18 00:50:05,629 INFO:     Found new best model at epoch 35
2022-11-18 00:50:05,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:05,630 INFO:     Epoch: 36
2022-11-18 00:50:06,413 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8037561625242233, 'Total loss': 0.8037561625242233} | train loss {'Reaction outcome loss': 0.8048214531473575, 'Total loss': 0.8048214531473575}
2022-11-18 00:50:06,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:06,413 INFO:     Epoch: 37
2022-11-18 00:50:07,252 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8064551759849895, 'Total loss': 0.8064551759849895} | train loss {'Reaction outcome loss': 0.8055129491033093, 'Total loss': 0.8055129491033093}
2022-11-18 00:50:07,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:07,253 INFO:     Epoch: 38
2022-11-18 00:50:08,101 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8040068583054976, 'Total loss': 0.8040068583054976} | train loss {'Reaction outcome loss': 0.7996422529460923, 'Total loss': 0.7996422529460923}
2022-11-18 00:50:08,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:08,102 INFO:     Epoch: 39
2022-11-18 00:50:08,902 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7955252162434838, 'Total loss': 0.7955252162434838} | train loss {'Reaction outcome loss': 0.806651608838189, 'Total loss': 0.806651608838189}
2022-11-18 00:50:08,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:08,903 INFO:     Epoch: 40
2022-11-18 00:50:09,742 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7922320907766168, 'Total loss': 0.7922320907766168} | train loss {'Reaction outcome loss': 0.801352034713472, 'Total loss': 0.801352034713472}
2022-11-18 00:50:09,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:09,743 INFO:     Epoch: 41
2022-11-18 00:50:10,554 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8071948289871216, 'Total loss': 0.8071948289871216} | train loss {'Reaction outcome loss': 0.7977965059539964, 'Total loss': 0.7977965059539964}
2022-11-18 00:50:10,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:10,555 INFO:     Epoch: 42
2022-11-18 00:50:11,379 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7997978648001497, 'Total loss': 0.7997978648001497} | train loss {'Reaction outcome loss': 0.8076275667596248, 'Total loss': 0.8076275667596248}
2022-11-18 00:50:11,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:11,379 INFO:     Epoch: 43
2022-11-18 00:50:12,212 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.805432452396913, 'Total loss': 0.805432452396913} | train loss {'Reaction outcome loss': 0.8067095225616809, 'Total loss': 0.8067095225616809}
2022-11-18 00:50:12,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:12,212 INFO:     Epoch: 44
2022-11-18 00:50:13,062 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7999699332497336, 'Total loss': 0.7999699332497336} | train loss {'Reaction outcome loss': 0.7999448571955005, 'Total loss': 0.7999448571955005}
2022-11-18 00:50:13,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:13,063 INFO:     Epoch: 45
2022-11-18 00:50:13,861 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7989650382237001, 'Total loss': 0.7989650382237001} | train loss {'Reaction outcome loss': 0.8014219280692839, 'Total loss': 0.8014219280692839}
2022-11-18 00:50:13,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:13,862 INFO:     Epoch: 46
2022-11-18 00:50:14,651 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8054559257897463, 'Total loss': 0.8054559257897463} | train loss {'Reaction outcome loss': 0.8072749798095995, 'Total loss': 0.8072749798095995}
2022-11-18 00:50:14,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:14,652 INFO:     Epoch: 47
2022-11-18 00:50:15,473 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7934837239709768, 'Total loss': 0.7934837239709768} | train loss {'Reaction outcome loss': 0.8018249758789616, 'Total loss': 0.8018249758789616}
2022-11-18 00:50:15,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:15,473 INFO:     Epoch: 48
2022-11-18 00:50:16,268 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8090360354293477, 'Total loss': 0.8090360354293477} | train loss {'Reaction outcome loss': 0.8058859657856726, 'Total loss': 0.8058859657856726}
2022-11-18 00:50:16,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:16,268 INFO:     Epoch: 49
2022-11-18 00:50:17,057 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8009383177215402, 'Total loss': 0.8009383177215402} | train loss {'Reaction outcome loss': 0.803900055827633, 'Total loss': 0.803900055827633}
2022-11-18 00:50:17,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:17,058 INFO:     Epoch: 50
2022-11-18 00:50:17,857 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.791712338951501, 'Total loss': 0.791712338951501} | train loss {'Reaction outcome loss': 0.7989112226472747, 'Total loss': 0.7989112226472747}
2022-11-18 00:50:17,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:17,858 INFO:     Epoch: 51
2022-11-18 00:50:18,627 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.800580648536032, 'Total loss': 0.800580648536032} | train loss {'Reaction outcome loss': 0.800811774187511, 'Total loss': 0.800811774187511}
2022-11-18 00:50:18,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:18,627 INFO:     Epoch: 52
2022-11-18 00:50:19,418 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.809170547534119, 'Total loss': 0.809170547534119} | train loss {'Reaction outcome loss': 0.8042778175684714, 'Total loss': 0.8042778175684714}
2022-11-18 00:50:19,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:19,419 INFO:     Epoch: 53
2022-11-18 00:50:20,193 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8091498362747106, 'Total loss': 0.8091498362747106} | train loss {'Reaction outcome loss': 0.8108414133950588, 'Total loss': 0.8108414133950588}
2022-11-18 00:50:20,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:20,193 INFO:     Epoch: 54
2022-11-18 00:50:20,998 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8027995411645282, 'Total loss': 0.8027995411645282} | train loss {'Reaction outcome loss': 0.8076413559817499, 'Total loss': 0.8076413559817499}
2022-11-18 00:50:20,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:20,998 INFO:     Epoch: 55
2022-11-18 00:50:21,780 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8038595515218648, 'Total loss': 0.8038595515218648} | train loss {'Reaction outcome loss': 0.80151761034804, 'Total loss': 0.80151761034804}
2022-11-18 00:50:21,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:21,780 INFO:     Epoch: 56
2022-11-18 00:50:22,579 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8051788414066489, 'Total loss': 0.8051788414066489} | train loss {'Reaction outcome loss': 0.801832624380627, 'Total loss': 0.801832624380627}
2022-11-18 00:50:22,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:22,580 INFO:     Epoch: 57
2022-11-18 00:50:23,405 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7961935218084942, 'Total loss': 0.7961935218084942} | train loss {'Reaction outcome loss': 0.8078580645303572, 'Total loss': 0.8078580645303572}
2022-11-18 00:50:23,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:23,405 INFO:     Epoch: 58
2022-11-18 00:50:24,215 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8054300702430985, 'Total loss': 0.8054300702430985} | train loss {'Reaction outcome loss': 0.7991716510826542, 'Total loss': 0.7991716510826542}
2022-11-18 00:50:24,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:24,215 INFO:     Epoch: 59
2022-11-18 00:50:25,012 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8015758855776354, 'Total loss': 0.8015758855776354} | train loss {'Reaction outcome loss': 0.807456093930429, 'Total loss': 0.807456093930429}
2022-11-18 00:50:25,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:25,012 INFO:     Epoch: 60
2022-11-18 00:50:25,828 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8104959049008109, 'Total loss': 0.8104959049008109} | train loss {'Reaction outcome loss': 0.8095041919619806, 'Total loss': 0.8095041919619806}
2022-11-18 00:50:25,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:25,829 INFO:     Epoch: 61
2022-11-18 00:50:26,649 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7969029389999129, 'Total loss': 0.7969029389999129} | train loss {'Reaction outcome loss': 0.8060175477256698, 'Total loss': 0.8060175477256698}
2022-11-18 00:50:26,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:26,649 INFO:     Epoch: 62
2022-11-18 00:50:27,435 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8061656843532216, 'Total loss': 0.8061656843532216} | train loss {'Reaction outcome loss': 0.8033808868738913, 'Total loss': 0.8033808868738913}
2022-11-18 00:50:27,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:27,435 INFO:     Epoch: 63
2022-11-18 00:50:28,234 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8003012429584156, 'Total loss': 0.8003012429584156} | train loss {'Reaction outcome loss': 0.8031648100624161, 'Total loss': 0.8031648100624161}
2022-11-18 00:50:28,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:28,234 INFO:     Epoch: 64
2022-11-18 00:50:29,066 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8090472722595389, 'Total loss': 0.8090472722595389} | train loss {'Reaction outcome loss': 0.8008463182035954, 'Total loss': 0.8008463182035954}
2022-11-18 00:50:29,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:29,066 INFO:     Epoch: 65
2022-11-18 00:50:29,894 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8102192892269655, 'Total loss': 0.8102192892269655} | train loss {'Reaction outcome loss': 0.8002912599232889, 'Total loss': 0.8002912599232889}
2022-11-18 00:50:29,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:29,895 INFO:     Epoch: 66
2022-11-18 00:50:30,694 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7994073141704906, 'Total loss': 0.7994073141704906} | train loss {'Reaction outcome loss': 0.8040346856559476, 'Total loss': 0.8040346856559476}
2022-11-18 00:50:30,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:30,694 INFO:     Epoch: 67
2022-11-18 00:50:31,482 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8062151948159392, 'Total loss': 0.8062151948159392} | train loss {'Reaction outcome loss': 0.8044671274481281, 'Total loss': 0.8044671274481281}
2022-11-18 00:50:31,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:31,482 INFO:     Epoch: 68
2022-11-18 00:50:32,295 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7913729345256632, 'Total loss': 0.7913729345256632} | train loss {'Reaction outcome loss': 0.8036036631993709, 'Total loss': 0.8036036631993709}
2022-11-18 00:50:32,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:32,295 INFO:     Epoch: 69
2022-11-18 00:50:33,085 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7988874858075922, 'Total loss': 0.7988874858075922} | train loss {'Reaction outcome loss': 0.8038705037005486, 'Total loss': 0.8038705037005486}
2022-11-18 00:50:33,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:33,086 INFO:     Epoch: 70
2022-11-18 00:50:33,926 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.80102854560722, 'Total loss': 0.80102854560722} | train loss {'Reaction outcome loss': 0.8037419421297889, 'Total loss': 0.8037419421297889}
2022-11-18 00:50:33,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:33,926 INFO:     Epoch: 71
2022-11-18 00:50:34,734 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7877644151449203, 'Total loss': 0.7877644151449203} | train loss {'Reaction outcome loss': 0.8063278813515941, 'Total loss': 0.8063278813515941}
2022-11-18 00:50:34,734 INFO:     Found new best model at epoch 71
2022-11-18 00:50:34,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:34,735 INFO:     Epoch: 72
2022-11-18 00:50:35,507 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7941101301800121, 'Total loss': 0.7941101301800121} | train loss {'Reaction outcome loss': 0.8063020306008477, 'Total loss': 0.8063020306008477}
2022-11-18 00:50:35,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:35,508 INFO:     Epoch: 73
2022-11-18 00:50:36,302 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7967621386051178, 'Total loss': 0.7967621386051178} | train loss {'Reaction outcome loss': 0.8050045643842989, 'Total loss': 0.8050045643842989}
2022-11-18 00:50:36,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:36,302 INFO:     Epoch: 74
2022-11-18 00:50:37,111 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.815388790585778, 'Total loss': 0.815388790585778} | train loss {'Reaction outcome loss': 0.8060032552288424, 'Total loss': 0.8060032552288424}
2022-11-18 00:50:37,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:37,111 INFO:     Epoch: 75
2022-11-18 00:50:37,969 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7960999635132876, 'Total loss': 0.7960999635132876} | train loss {'Reaction outcome loss': 0.8007373521404881, 'Total loss': 0.8007373521404881}
2022-11-18 00:50:37,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:37,969 INFO:     Epoch: 76
2022-11-18 00:50:38,841 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7942408716136758, 'Total loss': 0.7942408716136758} | train loss {'Reaction outcome loss': 0.8045742770116175, 'Total loss': 0.8045742770116175}
2022-11-18 00:50:38,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:38,841 INFO:     Epoch: 77
2022-11-18 00:50:39,675 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8044608946550976, 'Total loss': 0.8044608946550976} | train loss {'Reaction outcome loss': 0.7993905043770229, 'Total loss': 0.7993905043770229}
2022-11-18 00:50:39,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:39,675 INFO:     Epoch: 78
2022-11-18 00:50:40,522 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.797722764313221, 'Total loss': 0.797722764313221} | train loss {'Reaction outcome loss': 0.8065652694673308, 'Total loss': 0.8065652694673308}
2022-11-18 00:50:40,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:40,522 INFO:     Epoch: 79
2022-11-18 00:50:41,349 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7997861572287299, 'Total loss': 0.7997861572287299} | train loss {'Reaction outcome loss': 0.8037503294406398, 'Total loss': 0.8037503294406398}
2022-11-18 00:50:41,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:41,349 INFO:     Epoch: 80
2022-11-18 00:50:42,149 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.80182342028076, 'Total loss': 0.80182342028076} | train loss {'Reaction outcome loss': 0.807164984845346, 'Total loss': 0.807164984845346}
2022-11-18 00:50:42,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:42,150 INFO:     Epoch: 81
2022-11-18 00:50:42,940 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8076357238671996, 'Total loss': 0.8076357238671996} | train loss {'Reaction outcome loss': 0.8023364557133567, 'Total loss': 0.8023364557133567}
2022-11-18 00:50:42,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:42,941 INFO:     Epoch: 82
2022-11-18 00:50:43,790 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8098360083319924, 'Total loss': 0.8098360083319924} | train loss {'Reaction outcome loss': 0.8006102203601791, 'Total loss': 0.8006102203601791}
2022-11-18 00:50:43,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:43,790 INFO:     Epoch: 83
2022-11-18 00:50:44,617 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8038786026564512, 'Total loss': 0.8038786026564512} | train loss {'Reaction outcome loss': 0.8019761724337455, 'Total loss': 0.8019761724337455}
2022-11-18 00:50:44,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:44,618 INFO:     Epoch: 84
2022-11-18 00:50:45,425 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.796037842604247, 'Total loss': 0.796037842604247} | train loss {'Reaction outcome loss': 0.805194367083811, 'Total loss': 0.805194367083811}
2022-11-18 00:50:45,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:45,425 INFO:     Epoch: 85
2022-11-18 00:50:46,248 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8331605900417675, 'Total loss': 0.8331605900417675} | train loss {'Reaction outcome loss': 0.8024969002412211, 'Total loss': 0.8024969002412211}
2022-11-18 00:50:46,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:46,248 INFO:     Epoch: 86
2022-11-18 00:50:47,046 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.796952219849283, 'Total loss': 0.796952219849283} | train loss {'Reaction outcome loss': 0.798536533429738, 'Total loss': 0.798536533429738}
2022-11-18 00:50:47,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:47,046 INFO:     Epoch: 87
2022-11-18 00:50:47,825 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8001928166909651, 'Total loss': 0.8001928166909651} | train loss {'Reaction outcome loss': 0.8046264352817689, 'Total loss': 0.8046264352817689}
2022-11-18 00:50:47,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:47,825 INFO:     Epoch: 88
2022-11-18 00:50:48,661 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7937553118575703, 'Total loss': 0.7937553118575703} | train loss {'Reaction outcome loss': 0.8015821703499363, 'Total loss': 0.8015821703499363}
2022-11-18 00:50:48,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:48,662 INFO:     Epoch: 89
2022-11-18 00:50:49,449 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7989634559913115, 'Total loss': 0.7989634559913115} | train loss {'Reaction outcome loss': 0.8022249458778289, 'Total loss': 0.8022249458778289}
2022-11-18 00:50:49,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:49,449 INFO:     Epoch: 90
2022-11-18 00:50:50,244 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7944245406172492, 'Total loss': 0.7944245406172492} | train loss {'Reaction outcome loss': 0.8042459645338597, 'Total loss': 0.8042459645338597}
2022-11-18 00:50:50,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:50,244 INFO:     Epoch: 91
2022-11-18 00:50:51,029 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8106500391255725, 'Total loss': 0.8106500391255725} | train loss {'Reaction outcome loss': 0.8082589854396158, 'Total loss': 0.8082589854396158}
2022-11-18 00:50:51,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:51,030 INFO:     Epoch: 92
2022-11-18 00:50:51,772 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7878587164662101, 'Total loss': 0.7878587164662101} | train loss {'Reaction outcome loss': 0.8034700286244193, 'Total loss': 0.8034700286244193}
2022-11-18 00:50:51,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:51,772 INFO:     Epoch: 93
2022-11-18 00:50:52,559 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7885649895126169, 'Total loss': 0.7885649895126169} | train loss {'Reaction outcome loss': 0.8026414439082146, 'Total loss': 0.8026414439082146}
2022-11-18 00:50:52,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:52,559 INFO:     Epoch: 94
2022-11-18 00:50:53,336 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8322778865695, 'Total loss': 0.8322778865695} | train loss {'Reaction outcome loss': 0.8052389138648587, 'Total loss': 0.8052389138648587}
2022-11-18 00:50:53,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:53,336 INFO:     Epoch: 95
2022-11-18 00:50:54,132 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7985364097085866, 'Total loss': 0.7985364097085866} | train loss {'Reaction outcome loss': 0.806682885654511, 'Total loss': 0.806682885654511}
2022-11-18 00:50:54,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:54,132 INFO:     Epoch: 96
2022-11-18 00:50:54,919 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8255952488292347, 'Total loss': 0.8255952488292347} | train loss {'Reaction outcome loss': 0.8014448194974854, 'Total loss': 0.8014448194974854}
2022-11-18 00:50:54,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:54,920 INFO:     Epoch: 97
2022-11-18 00:50:55,733 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7988850772380829, 'Total loss': 0.7988850772380829} | train loss {'Reaction outcome loss': 0.8008206622494806, 'Total loss': 0.8008206622494806}
2022-11-18 00:50:55,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:55,734 INFO:     Epoch: 98
2022-11-18 00:50:56,538 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7868425683541731, 'Total loss': 0.7868425683541731} | train loss {'Reaction outcome loss': 0.8056250231400612, 'Total loss': 0.8056250231400612}
2022-11-18 00:50:56,538 INFO:     Found new best model at epoch 98
2022-11-18 00:50:56,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:56,539 INFO:     Epoch: 99
2022-11-18 00:50:57,349 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8036081425168298, 'Total loss': 0.8036081425168298} | train loss {'Reaction outcome loss': 0.8008820336432226, 'Total loss': 0.8008820336432226}
2022-11-18 00:50:57,349 INFO:     Best model found after epoch 99 of 100.
2022-11-18 00:50:57,350 INFO:   Done with stage: TRAINING
2022-11-18 00:50:57,350 INFO:   Starting stage: EVALUATION
2022-11-18 00:50:57,467 INFO:   Done with stage: EVALUATION
2022-11-18 00:50:57,468 INFO:   Leaving out SEQ value Fold_8
2022-11-18 00:50:57,481 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:50:57,481 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:50:58,147 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:50:58,147 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:50:58,217 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:50:58,218 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:50:58,218 INFO:     No hyperparam tuning for this model
2022-11-18 00:50:58,218 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:50:58,218 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:50:58,219 INFO:     None feature selector for col prot
2022-11-18 00:50:58,219 INFO:     None feature selector for col prot
2022-11-18 00:50:58,219 INFO:     None feature selector for col prot
2022-11-18 00:50:58,219 INFO:     None feature selector for col chem
2022-11-18 00:50:58,219 INFO:     None feature selector for col chem
2022-11-18 00:50:58,219 INFO:     None feature selector for col chem
2022-11-18 00:50:58,220 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:50:58,220 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:50:58,221 INFO:     Number of params in model 168571
2022-11-18 00:50:58,224 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:50:58,224 INFO:   Starting stage: TRAINING
2022-11-18 00:50:58,282 INFO:     Val loss before train {'Reaction outcome loss': 1.035646526650949, 'Total loss': 1.035646526650949}
2022-11-18 00:50:58,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:58,282 INFO:     Epoch: 0
2022-11-18 00:50:59,032 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8470962034030394, 'Total loss': 0.8470962034030394} | train loss {'Reaction outcome loss': 0.8892626512629783, 'Total loss': 0.8892626512629783}
2022-11-18 00:50:59,032 INFO:     Found new best model at epoch 0
2022-11-18 00:50:59,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:59,033 INFO:     Epoch: 1
2022-11-18 00:50:59,809 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8410883180119775, 'Total loss': 0.8410883180119775} | train loss {'Reaction outcome loss': 0.8393087353451774, 'Total loss': 0.8393087353451774}
2022-11-18 00:50:59,809 INFO:     Found new best model at epoch 1
2022-11-18 00:50:59,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:50:59,810 INFO:     Epoch: 2
2022-11-18 00:51:00,621 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8270532915538008, 'Total loss': 0.8270532915538008} | train loss {'Reaction outcome loss': 0.8386272283700796, 'Total loss': 0.8386272283700796}
2022-11-18 00:51:00,621 INFO:     Found new best model at epoch 2
2022-11-18 00:51:00,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:00,622 INFO:     Epoch: 3
2022-11-18 00:51:01,404 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8484935713085261, 'Total loss': 0.8484935713085261} | train loss {'Reaction outcome loss': 0.829025165573788, 'Total loss': 0.829025165573788}
2022-11-18 00:51:01,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:01,404 INFO:     Epoch: 4
2022-11-18 00:51:02,179 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8253689841790632, 'Total loss': 0.8253689841790632} | train loss {'Reaction outcome loss': 0.8284106822872934, 'Total loss': 0.8284106822872934}
2022-11-18 00:51:02,179 INFO:     Found new best model at epoch 4
2022-11-18 00:51:02,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:02,180 INFO:     Epoch: 5
2022-11-18 00:51:02,959 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8207233284007419, 'Total loss': 0.8207233284007419} | train loss {'Reaction outcome loss': 0.8251970854968678, 'Total loss': 0.8251970854968678}
2022-11-18 00:51:02,959 INFO:     Found new best model at epoch 5
2022-11-18 00:51:02,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:02,960 INFO:     Epoch: 6
2022-11-18 00:51:03,753 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8449041430245746, 'Total loss': 0.8449041430245746} | train loss {'Reaction outcome loss': 0.8219449477881072, 'Total loss': 0.8219449477881072}
2022-11-18 00:51:03,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:03,753 INFO:     Epoch: 7
2022-11-18 00:51:04,532 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8141109144145792, 'Total loss': 0.8141109144145792} | train loss {'Reaction outcome loss': 0.8197813195738233, 'Total loss': 0.8197813195738233}
2022-11-18 00:51:04,532 INFO:     Found new best model at epoch 7
2022-11-18 00:51:04,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:04,533 INFO:     Epoch: 8
2022-11-18 00:51:05,306 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8147252120754935, 'Total loss': 0.8147252120754935} | train loss {'Reaction outcome loss': 0.8123763129718391, 'Total loss': 0.8123763129718391}
2022-11-18 00:51:05,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:05,306 INFO:     Epoch: 9
2022-11-18 00:51:06,081 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8094065907326612, 'Total loss': 0.8094065907326612} | train loss {'Reaction outcome loss': 0.8191690023852746, 'Total loss': 0.8191690023852746}
2022-11-18 00:51:06,081 INFO:     Found new best model at epoch 9
2022-11-18 00:51:06,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:06,082 INFO:     Epoch: 10
2022-11-18 00:51:06,878 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.821861370043321, 'Total loss': 0.821861370043321} | train loss {'Reaction outcome loss': 0.8174602260684919, 'Total loss': 0.8174602260684919}
2022-11-18 00:51:06,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:06,879 INFO:     Epoch: 11
2022-11-18 00:51:07,652 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7983631058172747, 'Total loss': 0.7983631058172747} | train loss {'Reaction outcome loss': 0.8220723112102463, 'Total loss': 0.8220723112102463}
2022-11-18 00:51:07,653 INFO:     Found new best model at epoch 11
2022-11-18 00:51:07,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:07,653 INFO:     Epoch: 12
2022-11-18 00:51:08,438 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8152442466128956, 'Total loss': 0.8152442466128956} | train loss {'Reaction outcome loss': 0.819665912553849, 'Total loss': 0.819665912553849}
2022-11-18 00:51:08,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:08,438 INFO:     Epoch: 13
2022-11-18 00:51:09,220 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8093813949010589, 'Total loss': 0.8093813949010589} | train loss {'Reaction outcome loss': 0.8173796222036184, 'Total loss': 0.8173796222036184}
2022-11-18 00:51:09,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:09,220 INFO:     Epoch: 14
2022-11-18 00:51:10,021 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8432044413956729, 'Total loss': 0.8432044413956729} | train loss {'Reaction outcome loss': 0.8194821164434255, 'Total loss': 0.8194821164434255}
2022-11-18 00:51:10,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:10,022 INFO:     Epoch: 15
2022-11-18 00:51:10,808 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8089061230421066, 'Total loss': 0.8089061230421066} | train loss {'Reaction outcome loss': 0.8157262161434421, 'Total loss': 0.8157262161434421}
2022-11-18 00:51:10,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:10,809 INFO:     Epoch: 16
2022-11-18 00:51:11,582 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8096237060698596, 'Total loss': 0.8096237060698596} | train loss {'Reaction outcome loss': 0.8135646270354268, 'Total loss': 0.8135646270354268}
2022-11-18 00:51:11,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:11,582 INFO:     Epoch: 17
2022-11-18 00:51:12,380 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8076035583561118, 'Total loss': 0.8076035583561118} | train loss {'Reaction outcome loss': 0.8214844795856399, 'Total loss': 0.8214844795856399}
2022-11-18 00:51:12,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:12,380 INFO:     Epoch: 18
2022-11-18 00:51:13,138 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8285712755539201, 'Total loss': 0.8285712755539201} | train loss {'Reaction outcome loss': 0.8325073546484897, 'Total loss': 0.8325073546484897}
2022-11-18 00:51:13,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:13,139 INFO:     Epoch: 19
2022-11-18 00:51:13,934 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8066542087630793, 'Total loss': 0.8066542087630793} | train loss {'Reaction outcome loss': 0.819555560059031, 'Total loss': 0.819555560059031}
2022-11-18 00:51:13,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:13,934 INFO:     Epoch: 20
2022-11-18 00:51:14,724 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8276611593636599, 'Total loss': 0.8276611593636599} | train loss {'Reaction outcome loss': 0.8159504357861121, 'Total loss': 0.8159504357861121}
2022-11-18 00:51:14,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:14,724 INFO:     Epoch: 21
2022-11-18 00:51:15,505 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8167225271463394, 'Total loss': 0.8167225271463394} | train loss {'Reaction outcome loss': 0.8154948882245825, 'Total loss': 0.8154948882245825}
2022-11-18 00:51:15,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:15,506 INFO:     Epoch: 22
2022-11-18 00:51:16,277 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.804407237605615, 'Total loss': 0.804407237605615} | train loss {'Reaction outcome loss': 0.8159352318960645, 'Total loss': 0.8159352318960645}
2022-11-18 00:51:16,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:16,277 INFO:     Epoch: 23
2022-11-18 00:51:17,065 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.799282122742046, 'Total loss': 0.799282122742046} | train loss {'Reaction outcome loss': 0.8120780146797659, 'Total loss': 0.8120780146797659}
2022-11-18 00:51:17,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:17,065 INFO:     Epoch: 24
2022-11-18 00:51:17,837 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8047686165029352, 'Total loss': 0.8047686165029352} | train loss {'Reaction outcome loss': 0.8108764864232859, 'Total loss': 0.8108764864232859}
2022-11-18 00:51:17,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:17,837 INFO:     Epoch: 25
2022-11-18 00:51:18,627 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8122722154313867, 'Total loss': 0.8122722154313867} | train loss {'Reaction outcome loss': 0.8167603148622551, 'Total loss': 0.8167603148622551}
2022-11-18 00:51:18,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:18,627 INFO:     Epoch: 26
2022-11-18 00:51:19,446 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8132036992094733, 'Total loss': 0.8132036992094733} | train loss {'Reaction outcome loss': 0.8151687887395441, 'Total loss': 0.8151687887395441}
2022-11-18 00:51:19,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:19,446 INFO:     Epoch: 27
2022-11-18 00:51:20,235 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8153895322572101, 'Total loss': 0.8153895322572101} | train loss {'Reaction outcome loss': 0.8146912334901601, 'Total loss': 0.8146912334901601}
2022-11-18 00:51:20,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:20,235 INFO:     Epoch: 28
2022-11-18 00:51:21,022 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8095064088702202, 'Total loss': 0.8095064088702202} | train loss {'Reaction outcome loss': 0.8130892446407905, 'Total loss': 0.8130892446407905}
2022-11-18 00:51:21,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:21,022 INFO:     Epoch: 29
2022-11-18 00:51:21,796 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8374886580488898, 'Total loss': 0.8374886580488898} | train loss {'Reaction outcome loss': 0.8184127407035364, 'Total loss': 0.8184127407035364}
2022-11-18 00:51:21,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:21,796 INFO:     Epoch: 30
2022-11-18 00:51:22,583 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8064381006089124, 'Total loss': 0.8064381006089124} | train loss {'Reaction outcome loss': 0.8121922288527373, 'Total loss': 0.8121922288527373}
2022-11-18 00:51:22,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:22,583 INFO:     Epoch: 31
2022-11-18 00:51:23,353 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8406849964098497, 'Total loss': 0.8406849964098497} | train loss {'Reaction outcome loss': 0.8059379904255694, 'Total loss': 0.8059379904255694}
2022-11-18 00:51:23,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:23,353 INFO:     Epoch: 32
2022-11-18 00:51:24,129 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.863995757969943, 'Total loss': 0.863995757969943} | train loss {'Reaction outcome loss': 0.8146733659723027, 'Total loss': 0.8146733659723027}
2022-11-18 00:51:24,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:24,129 INFO:     Epoch: 33
2022-11-18 00:51:24,922 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8212242803790353, 'Total loss': 0.8212242803790353} | train loss {'Reaction outcome loss': 0.815734850250275, 'Total loss': 0.815734850250275}
2022-11-18 00:51:24,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:24,922 INFO:     Epoch: 34
2022-11-18 00:51:25,724 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.806753548708829, 'Total loss': 0.806753548708829} | train loss {'Reaction outcome loss': 0.8081019975033849, 'Total loss': 0.8081019975033849}
2022-11-18 00:51:25,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:25,725 INFO:     Epoch: 35
2022-11-18 00:51:26,530 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.814177693291144, 'Total loss': 0.814177693291144} | train loss {'Reaction outcome loss': 0.8200080394744873, 'Total loss': 0.8200080394744873}
2022-11-18 00:51:26,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:26,531 INFO:     Epoch: 36
2022-11-18 00:51:27,339 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8010582497174089, 'Total loss': 0.8010582497174089} | train loss {'Reaction outcome loss': 0.8075811170373368, 'Total loss': 0.8075811170373368}
2022-11-18 00:51:27,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:27,339 INFO:     Epoch: 37
2022-11-18 00:51:28,133 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8084540556777607, 'Total loss': 0.8084540556777607} | train loss {'Reaction outcome loss': 0.8065492619990338, 'Total loss': 0.8065492619990338}
2022-11-18 00:51:28,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:28,133 INFO:     Epoch: 38
2022-11-18 00:51:28,930 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8023144812746481, 'Total loss': 0.8023144812746481} | train loss {'Reaction outcome loss': 0.8111694832652928, 'Total loss': 0.8111694832652928}
2022-11-18 00:51:28,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:28,930 INFO:     Epoch: 39
2022-11-18 00:51:29,741 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8003687045790933, 'Total loss': 0.8003687045790933} | train loss {'Reaction outcome loss': 0.807054535942039, 'Total loss': 0.807054535942039}
2022-11-18 00:51:29,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:29,742 INFO:     Epoch: 40
2022-11-18 00:51:30,516 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.80028939450329, 'Total loss': 0.80028939450329} | train loss {'Reaction outcome loss': 0.8143944161140967, 'Total loss': 0.8143944161140967}
2022-11-18 00:51:30,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:30,516 INFO:     Epoch: 41
2022-11-18 00:51:31,299 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8292154121127996, 'Total loss': 0.8292154121127996} | train loss {'Reaction outcome loss': 0.8114779028091353, 'Total loss': 0.8114779028091353}
2022-11-18 00:51:31,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:31,299 INFO:     Epoch: 42
2022-11-18 00:51:32,079 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8222943612120368, 'Total loss': 0.8222943612120368} | train loss {'Reaction outcome loss': 0.8085087660232536, 'Total loss': 0.8085087660232536}
2022-11-18 00:51:32,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:32,080 INFO:     Epoch: 43
2022-11-18 00:51:32,892 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8140138976953246, 'Total loss': 0.8140138976953246} | train loss {'Reaction outcome loss': 0.8052313365193031, 'Total loss': 0.8052313365193031}
2022-11-18 00:51:32,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:32,893 INFO:     Epoch: 44
2022-11-18 00:51:33,755 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.811029160564596, 'Total loss': 0.811029160564596} | train loss {'Reaction outcome loss': 0.8046318760767639, 'Total loss': 0.8046318760767639}
2022-11-18 00:51:33,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:33,755 INFO:     Epoch: 45
2022-11-18 00:51:34,574 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8019500368020751, 'Total loss': 0.8019500368020751} | train loss {'Reaction outcome loss': 0.8091340811870359, 'Total loss': 0.8091340811870359}
2022-11-18 00:51:34,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:34,574 INFO:     Epoch: 46
2022-11-18 00:51:35,379 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8006136356429621, 'Total loss': 0.8006136356429621} | train loss {'Reaction outcome loss': 0.8159762859827111, 'Total loss': 0.8159762859827111}
2022-11-18 00:51:35,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:35,379 INFO:     Epoch: 47
2022-11-18 00:51:36,180 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7990034588358619, 'Total loss': 0.7990034588358619} | train loss {'Reaction outcome loss': 0.8192148855340625, 'Total loss': 0.8192148855340625}
2022-11-18 00:51:36,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:36,180 INFO:     Epoch: 48
2022-11-18 00:51:37,025 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8511459868062626, 'Total loss': 0.8511459868062626} | train loss {'Reaction outcome loss': 0.8095167275322112, 'Total loss': 0.8095167275322112}
2022-11-18 00:51:37,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:37,025 INFO:     Epoch: 49
2022-11-18 00:51:37,882 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8404445892030542, 'Total loss': 0.8404445892030542} | train loss {'Reaction outcome loss': 0.8106166495967974, 'Total loss': 0.8106166495967974}
2022-11-18 00:51:37,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:37,882 INFO:     Epoch: 50
2022-11-18 00:51:38,695 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7953229248523712, 'Total loss': 0.7953229248523712} | train loss {'Reaction outcome loss': 0.8129336786294273, 'Total loss': 0.8129336786294273}
2022-11-18 00:51:38,697 INFO:     Found new best model at epoch 50
2022-11-18 00:51:38,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:38,698 INFO:     Epoch: 51
2022-11-18 00:51:39,550 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8076124360615556, 'Total loss': 0.8076124360615556} | train loss {'Reaction outcome loss': 0.8086678659626347, 'Total loss': 0.8086678659626347}
2022-11-18 00:51:39,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:39,550 INFO:     Epoch: 52
2022-11-18 00:51:40,338 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8275903896851973, 'Total loss': 0.8275903896851973} | train loss {'Reaction outcome loss': 0.8089289002814274, 'Total loss': 0.8089289002814274}
2022-11-18 00:51:40,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:40,338 INFO:     Epoch: 53
2022-11-18 00:51:41,144 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.804628501561555, 'Total loss': 0.804628501561555} | train loss {'Reaction outcome loss': 0.8071724996875654, 'Total loss': 0.8071724996875654}
2022-11-18 00:51:41,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:41,144 INFO:     Epoch: 54
2022-11-18 00:51:41,922 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8313199322332036, 'Total loss': 0.8313199322332036} | train loss {'Reaction outcome loss': 0.8070816093610849, 'Total loss': 0.8070816093610849}
2022-11-18 00:51:41,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:41,922 INFO:     Epoch: 55
2022-11-18 00:51:42,701 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7961301823908632, 'Total loss': 0.7961301823908632} | train loss {'Reaction outcome loss': 0.804027888049119, 'Total loss': 0.804027888049119}
2022-11-18 00:51:42,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:42,701 INFO:     Epoch: 56
2022-11-18 00:51:43,450 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8198931501670317, 'Total loss': 0.8198931501670317} | train loss {'Reaction outcome loss': 0.8058281889569904, 'Total loss': 0.8058281889569904}
2022-11-18 00:51:43,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:43,450 INFO:     Epoch: 57
2022-11-18 00:51:44,224 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.811710508709604, 'Total loss': 0.811710508709604} | train loss {'Reaction outcome loss': 0.8103326071611783, 'Total loss': 0.8103326071611783}
2022-11-18 00:51:44,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:44,224 INFO:     Epoch: 58
2022-11-18 00:51:44,996 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8028967658227141, 'Total loss': 0.8028967658227141} | train loss {'Reaction outcome loss': 0.8119848541885253, 'Total loss': 0.8119848541885253}
2022-11-18 00:51:44,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:44,997 INFO:     Epoch: 59
2022-11-18 00:51:45,775 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8117419352585619, 'Total loss': 0.8117419352585619} | train loss {'Reaction outcome loss': 0.8077075398161344, 'Total loss': 0.8077075398161344}
2022-11-18 00:51:45,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:45,776 INFO:     Epoch: 60
2022-11-18 00:51:46,544 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8154732666232369, 'Total loss': 0.8154732666232369} | train loss {'Reaction outcome loss': 0.8097375467238639, 'Total loss': 0.8097375467238639}
2022-11-18 00:51:46,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:46,545 INFO:     Epoch: 61
2022-11-18 00:51:47,301 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.806527235291221, 'Total loss': 0.806527235291221} | train loss {'Reaction outcome loss': 0.8082017535381472, 'Total loss': 0.8082017535381472}
2022-11-18 00:51:47,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:47,301 INFO:     Epoch: 62
2022-11-18 00:51:48,102 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8065912859006361, 'Total loss': 0.8065912859006361} | train loss {'Reaction outcome loss': 0.8060284030099629, 'Total loss': 0.8060284030099629}
2022-11-18 00:51:48,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:48,102 INFO:     Epoch: 63
2022-11-18 00:51:48,886 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8096539242701097, 'Total loss': 0.8096539242701097} | train loss {'Reaction outcome loss': 0.8095218476496244, 'Total loss': 0.8095218476496244}
2022-11-18 00:51:48,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:48,886 INFO:     Epoch: 64
2022-11-18 00:51:49,651 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7994000911712646, 'Total loss': 0.7994000911712646} | train loss {'Reaction outcome loss': 0.8028756906146463, 'Total loss': 0.8028756906146463}
2022-11-18 00:51:49,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:49,651 INFO:     Epoch: 65
2022-11-18 00:51:50,441 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8014829368753866, 'Total loss': 0.8014829368753866} | train loss {'Reaction outcome loss': 0.8096187538222263, 'Total loss': 0.8096187538222263}
2022-11-18 00:51:50,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:50,441 INFO:     Epoch: 66
2022-11-18 00:51:51,215 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7974303087050264, 'Total loss': 0.7974303087050264} | train loss {'Reaction outcome loss': 0.8123687317496852, 'Total loss': 0.8123687317496852}
2022-11-18 00:51:51,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:51,216 INFO:     Epoch: 67
2022-11-18 00:51:52,031 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7937913963740523, 'Total loss': 0.7937913963740523} | train loss {'Reaction outcome loss': 0.8059080227425224, 'Total loss': 0.8059080227425224}
2022-11-18 00:51:52,031 INFO:     Found new best model at epoch 67
2022-11-18 00:51:52,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:52,032 INFO:     Epoch: 68
2022-11-18 00:51:52,813 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8036682483824816, 'Total loss': 0.8036682483824816} | train loss {'Reaction outcome loss': 0.8092526309644645, 'Total loss': 0.8092526309644645}
2022-11-18 00:51:52,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:52,813 INFO:     Epoch: 69
2022-11-18 00:51:53,587 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8137746507471258, 'Total loss': 0.8137746507471258} | train loss {'Reaction outcome loss': 0.8087800397322729, 'Total loss': 0.8087800397322729}
2022-11-18 00:51:53,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:53,588 INFO:     Epoch: 70
2022-11-18 00:51:54,364 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8129779113964601, 'Total loss': 0.8129779113964601} | train loss {'Reaction outcome loss': 0.808951000875307, 'Total loss': 0.808951000875307}
2022-11-18 00:51:54,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:54,364 INFO:     Epoch: 71
2022-11-18 00:51:55,176 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8093410635536368, 'Total loss': 0.8093410635536368} | train loss {'Reaction outcome loss': 0.804754829720447, 'Total loss': 0.804754829720447}
2022-11-18 00:51:55,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:55,176 INFO:     Epoch: 72
2022-11-18 00:51:55,981 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7904803346503865, 'Total loss': 0.7904803346503865} | train loss {'Reaction outcome loss': 0.8090716707802977, 'Total loss': 0.8090716707802977}
2022-11-18 00:51:55,981 INFO:     Found new best model at epoch 72
2022-11-18 00:51:55,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:55,982 INFO:     Epoch: 73
2022-11-18 00:51:56,769 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7983590533787553, 'Total loss': 0.7983590533787553} | train loss {'Reaction outcome loss': 0.8021540424601752, 'Total loss': 0.8021540424601752}
2022-11-18 00:51:56,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:56,770 INFO:     Epoch: 74
2022-11-18 00:51:57,587 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8025454093109478, 'Total loss': 0.8025454093109478} | train loss {'Reaction outcome loss': 0.8031107254235851, 'Total loss': 0.8031107254235851}
2022-11-18 00:51:57,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:57,588 INFO:     Epoch: 75
2022-11-18 00:51:58,398 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8109848986972462, 'Total loss': 0.8109848986972462} | train loss {'Reaction outcome loss': 0.8091625116373363, 'Total loss': 0.8091625116373363}
2022-11-18 00:51:58,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:58,398 INFO:     Epoch: 76
2022-11-18 00:51:59,154 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7957319088957526, 'Total loss': 0.7957319088957526} | train loss {'Reaction outcome loss': 0.812578490267881, 'Total loss': 0.812578490267881}
2022-11-18 00:51:59,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:59,154 INFO:     Epoch: 77
2022-11-18 00:51:59,946 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8044833188707178, 'Total loss': 0.8044833188707178} | train loss {'Reaction outcome loss': 0.8087126727287586, 'Total loss': 0.8087126727287586}
2022-11-18 00:51:59,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:51:59,946 INFO:     Epoch: 78
2022-11-18 00:52:00,748 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8161364008079875, 'Total loss': 0.8161364008079875} | train loss {'Reaction outcome loss': 0.8025174880558662, 'Total loss': 0.8025174880558662}
2022-11-18 00:52:00,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:00,749 INFO:     Epoch: 79
2022-11-18 00:52:01,512 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7856637970967726, 'Total loss': 0.7856637970967726} | train loss {'Reaction outcome loss': 0.8002666464067905, 'Total loss': 0.8002666464067905}
2022-11-18 00:52:01,512 INFO:     Found new best model at epoch 79
2022-11-18 00:52:01,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:01,513 INFO:     Epoch: 80
2022-11-18 00:52:02,296 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7872732545841824, 'Total loss': 0.7872732545841824} | train loss {'Reaction outcome loss': 0.8044197611239275, 'Total loss': 0.8044197611239275}
2022-11-18 00:52:02,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:02,296 INFO:     Epoch: 81
2022-11-18 00:52:03,072 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7940557985143228, 'Total loss': 0.7940557985143228} | train loss {'Reaction outcome loss': 0.8060250206273577, 'Total loss': 0.8060250206273577}
2022-11-18 00:52:03,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:03,073 INFO:     Epoch: 82
2022-11-18 00:52:03,874 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7868925705552101, 'Total loss': 0.7868925705552101} | train loss {'Reaction outcome loss': 0.807498552297291, 'Total loss': 0.807498552297291}
2022-11-18 00:52:03,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:03,874 INFO:     Epoch: 83
2022-11-18 00:52:04,666 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7913388427008282, 'Total loss': 0.7913388427008282} | train loss {'Reaction outcome loss': 0.8023526982257241, 'Total loss': 0.8023526982257241}
2022-11-18 00:52:04,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:04,667 INFO:     Epoch: 84
2022-11-18 00:52:05,463 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8102327978069132, 'Total loss': 0.8102327978069132} | train loss {'Reaction outcome loss': 0.8006973392085025, 'Total loss': 0.8006973392085025}
2022-11-18 00:52:05,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:05,463 INFO:     Epoch: 85
2022-11-18 00:52:06,247 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8153774711218748, 'Total loss': 0.8153774711218748} | train loss {'Reaction outcome loss': 0.8086832095736917, 'Total loss': 0.8086832095736917}
2022-11-18 00:52:06,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:06,248 INFO:     Epoch: 86
2022-11-18 00:52:07,037 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7860133349895477, 'Total loss': 0.7860133349895477} | train loss {'Reaction outcome loss': 0.8046473090947881, 'Total loss': 0.8046473090947881}
2022-11-18 00:52:07,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:07,038 INFO:     Epoch: 87
2022-11-18 00:52:07,804 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.806576625189998, 'Total loss': 0.806576625189998} | train loss {'Reaction outcome loss': 0.8019260420249059, 'Total loss': 0.8019260420249059}
2022-11-18 00:52:07,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:07,804 INFO:     Epoch: 88
2022-11-18 00:52:08,571 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7910347709601576, 'Total loss': 0.7910347709601576} | train loss {'Reaction outcome loss': 0.8038046682170528, 'Total loss': 0.8038046682170528}
2022-11-18 00:52:08,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:08,572 INFO:     Epoch: 89
2022-11-18 00:52:09,320 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7867938232692805, 'Total loss': 0.7867938232692805} | train loss {'Reaction outcome loss': 0.7997693795303584, 'Total loss': 0.7997693795303584}
2022-11-18 00:52:09,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:09,321 INFO:     Epoch: 90
2022-11-18 00:52:10,073 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7846730852668936, 'Total loss': 0.7846730852668936} | train loss {'Reaction outcome loss': 0.801443201991228, 'Total loss': 0.801443201991228}
2022-11-18 00:52:10,073 INFO:     Found new best model at epoch 90
2022-11-18 00:52:10,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:10,074 INFO:     Epoch: 91
2022-11-18 00:52:10,867 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7856040705334056, 'Total loss': 0.7856040705334056} | train loss {'Reaction outcome loss': 0.7998650846512694, 'Total loss': 0.7998650846512694}
2022-11-18 00:52:10,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:10,868 INFO:     Epoch: 92
2022-11-18 00:52:11,679 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8090623610398986, 'Total loss': 0.8090623610398986} | train loss {'Reaction outcome loss': 0.8020674528078995, 'Total loss': 0.8020674528078995}
2022-11-18 00:52:11,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:11,680 INFO:     Epoch: 93
2022-11-18 00:52:12,443 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.795449969443408, 'Total loss': 0.795449969443408} | train loss {'Reaction outcome loss': 0.8033411940823683, 'Total loss': 0.8033411940823683}
2022-11-18 00:52:12,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:12,444 INFO:     Epoch: 94
2022-11-18 00:52:13,228 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7881776609204032, 'Total loss': 0.7881776609204032} | train loss {'Reaction outcome loss': 0.8079660762900766, 'Total loss': 0.8079660762900766}
2022-11-18 00:52:13,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:13,229 INFO:     Epoch: 95
2022-11-18 00:52:14,027 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8034486072984609, 'Total loss': 0.8034486072984609} | train loss {'Reaction outcome loss': 0.799246810467137, 'Total loss': 0.799246810467137}
2022-11-18 00:52:14,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:14,027 INFO:     Epoch: 96
2022-11-18 00:52:14,814 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7992932904850353, 'Total loss': 0.7992932904850353} | train loss {'Reaction outcome loss': 0.8034715734814343, 'Total loss': 0.8034715734814343}
2022-11-18 00:52:14,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:14,815 INFO:     Epoch: 97
2022-11-18 00:52:15,605 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7764022113247351, 'Total loss': 0.7764022113247351} | train loss {'Reaction outcome loss': 0.7940430360948026, 'Total loss': 0.7940430360948026}
2022-11-18 00:52:15,605 INFO:     Found new best model at epoch 97
2022-11-18 00:52:15,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:15,606 INFO:     Epoch: 98
2022-11-18 00:52:16,372 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7917004214091734, 'Total loss': 0.7917004214091734} | train loss {'Reaction outcome loss': 0.7962047750891944, 'Total loss': 0.7962047750891944}
2022-11-18 00:52:16,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:16,372 INFO:     Epoch: 99
2022-11-18 00:52:17,135 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7888976335525513, 'Total loss': 0.7888976335525513} | train loss {'Reaction outcome loss': 0.8057562741432113, 'Total loss': 0.8057562741432113}
2022-11-18 00:52:17,135 INFO:     Best model found after epoch 98 of 100.
2022-11-18 00:52:17,135 INFO:   Done with stage: TRAINING
2022-11-18 00:52:17,135 INFO:   Starting stage: EVALUATION
2022-11-18 00:52:17,260 INFO:   Done with stage: EVALUATION
2022-11-18 00:52:17,260 INFO:   Leaving out SEQ value Fold_9
2022-11-18 00:52:17,274 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 00:52:17,274 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:52:17,949 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:52:17,949 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:52:18,021 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:52:18,021 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:52:18,021 INFO:     No hyperparam tuning for this model
2022-11-18 00:52:18,021 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:52:18,021 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:52:18,022 INFO:     None feature selector for col prot
2022-11-18 00:52:18,022 INFO:     None feature selector for col prot
2022-11-18 00:52:18,022 INFO:     None feature selector for col prot
2022-11-18 00:52:18,023 INFO:     None feature selector for col chem
2022-11-18 00:52:18,023 INFO:     None feature selector for col chem
2022-11-18 00:52:18,023 INFO:     None feature selector for col chem
2022-11-18 00:52:18,023 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:52:18,023 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:52:18,025 INFO:     Number of params in model 168571
2022-11-18 00:52:18,028 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:52:18,028 INFO:   Starting stage: TRAINING
2022-11-18 00:52:18,086 INFO:     Val loss before train {'Reaction outcome loss': 1.045024348930879, 'Total loss': 1.045024348930879}
2022-11-18 00:52:18,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:18,086 INFO:     Epoch: 0
2022-11-18 00:52:18,871 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8300056850368326, 'Total loss': 0.8300056850368326} | train loss {'Reaction outcome loss': 0.8881205058386249, 'Total loss': 0.8881205058386249}
2022-11-18 00:52:18,872 INFO:     Found new best model at epoch 0
2022-11-18 00:52:18,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:18,872 INFO:     Epoch: 1
2022-11-18 00:52:19,654 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8517760295759548, 'Total loss': 0.8517760295759548} | train loss {'Reaction outcome loss': 0.8546600693896893, 'Total loss': 0.8546600693896893}
2022-11-18 00:52:19,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:19,654 INFO:     Epoch: 2
2022-11-18 00:52:20,442 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8369245237924836, 'Total loss': 0.8369245237924836} | train loss {'Reaction outcome loss': 0.8563469087164248, 'Total loss': 0.8563469087164248}
2022-11-18 00:52:20,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:20,442 INFO:     Epoch: 3
2022-11-18 00:52:21,233 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8398273072459481, 'Total loss': 0.8398273072459481} | train loss {'Reaction outcome loss': 0.850846249129503, 'Total loss': 0.850846249129503}
2022-11-18 00:52:21,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:21,234 INFO:     Epoch: 4
2022-11-18 00:52:22,005 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8164769275621935, 'Total loss': 0.8164769275621935} | train loss {'Reaction outcome loss': 0.8468266098249343, 'Total loss': 0.8468266098249343}
2022-11-18 00:52:22,005 INFO:     Found new best model at epoch 4
2022-11-18 00:52:22,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:22,006 INFO:     Epoch: 5
2022-11-18 00:52:22,790 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8360368230126121, 'Total loss': 0.8360368230126121} | train loss {'Reaction outcome loss': 0.8357928603166535, 'Total loss': 0.8357928603166535}
2022-11-18 00:52:22,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:22,790 INFO:     Epoch: 6
2022-11-18 00:52:23,601 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8042629157954996, 'Total loss': 0.8042629157954996} | train loss {'Reaction outcome loss': 0.8415525402993925, 'Total loss': 0.8415525402993925}
2022-11-18 00:52:23,601 INFO:     Found new best model at epoch 6
2022-11-18 00:52:23,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:23,602 INFO:     Epoch: 7
2022-11-18 00:52:24,408 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8303915871815248, 'Total loss': 0.8303915871815248} | train loss {'Reaction outcome loss': 0.8359425739655572, 'Total loss': 0.8359425739655572}
2022-11-18 00:52:24,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:24,408 INFO:     Epoch: 8
2022-11-18 00:52:25,187 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8563127348368819, 'Total loss': 0.8563127348368819} | train loss {'Reaction outcome loss': 0.8325413836226347, 'Total loss': 0.8325413836226347}
2022-11-18 00:52:25,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:25,188 INFO:     Epoch: 9
2022-11-18 00:52:25,985 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8137253326448527, 'Total loss': 0.8137253326448527} | train loss {'Reaction outcome loss': 0.8360908099960896, 'Total loss': 0.8360908099960896}
2022-11-18 00:52:25,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:25,986 INFO:     Epoch: 10
2022-11-18 00:52:26,771 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8043525164777582, 'Total loss': 0.8043525164777582} | train loss {'Reaction outcome loss': 0.8325819142403141, 'Total loss': 0.8325819142403141}
2022-11-18 00:52:26,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:26,772 INFO:     Epoch: 11
2022-11-18 00:52:27,542 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8099569116126407, 'Total loss': 0.8099569116126407} | train loss {'Reaction outcome loss': 0.8270414422356314, 'Total loss': 0.8270414422356314}
2022-11-18 00:52:27,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:27,542 INFO:     Epoch: 12
2022-11-18 00:52:28,336 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8181223510341211, 'Total loss': 0.8181223510341211} | train loss {'Reaction outcome loss': 0.8293083340169922, 'Total loss': 0.8293083340169922}
2022-11-18 00:52:28,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:28,337 INFO:     Epoch: 13
2022-11-18 00:52:29,109 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8021561483090575, 'Total loss': 0.8021561483090575} | train loss {'Reaction outcome loss': 0.8285092938571207, 'Total loss': 0.8285092938571207}
2022-11-18 00:52:29,109 INFO:     Found new best model at epoch 13
2022-11-18 00:52:29,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:29,110 INFO:     Epoch: 14
2022-11-18 00:52:29,880 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8056375187906352, 'Total loss': 0.8056375187906352} | train loss {'Reaction outcome loss': 0.8266526231121633, 'Total loss': 0.8266526231121633}
2022-11-18 00:52:29,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:29,881 INFO:     Epoch: 15
2022-11-18 00:52:30,655 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.813407110219652, 'Total loss': 0.813407110219652} | train loss {'Reaction outcome loss': 0.8259721822555988, 'Total loss': 0.8259721822555988}
2022-11-18 00:52:30,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:30,656 INFO:     Epoch: 16
2022-11-18 00:52:31,429 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8168473650108684, 'Total loss': 0.8168473650108684} | train loss {'Reaction outcome loss': 0.8279743415694083, 'Total loss': 0.8279743415694083}
2022-11-18 00:52:31,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:31,430 INFO:     Epoch: 17
2022-11-18 00:52:32,214 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8289463790980253, 'Total loss': 0.8289463790980253} | train loss {'Reaction outcome loss': 0.8272160338538308, 'Total loss': 0.8272160338538308}
2022-11-18 00:52:32,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:32,215 INFO:     Epoch: 18
2022-11-18 00:52:33,001 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8256408639929511, 'Total loss': 0.8256408639929511} | train loss {'Reaction outcome loss': 0.8288303914089357, 'Total loss': 0.8288303914089357}
2022-11-18 00:52:33,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:33,002 INFO:     Epoch: 19
2022-11-18 00:52:33,788 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8141815885901451, 'Total loss': 0.8141815885901451} | train loss {'Reaction outcome loss': 0.8246805794056384, 'Total loss': 0.8246805794056384}
2022-11-18 00:52:33,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:33,789 INFO:     Epoch: 20
2022-11-18 00:52:34,572 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8031250841238282, 'Total loss': 0.8031250841238282} | train loss {'Reaction outcome loss': 0.8254313635970315, 'Total loss': 0.8254313635970315}
2022-11-18 00:52:34,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:34,572 INFO:     Epoch: 21
2022-11-18 00:52:35,366 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8021354255351153, 'Total loss': 0.8021354255351153} | train loss {'Reaction outcome loss': 0.8260349940148092, 'Total loss': 0.8260349940148092}
2022-11-18 00:52:35,366 INFO:     Found new best model at epoch 21
2022-11-18 00:52:35,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:35,367 INFO:     Epoch: 22
2022-11-18 00:52:36,142 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8068640638481487, 'Total loss': 0.8068640638481487} | train loss {'Reaction outcome loss': 0.828091261367644, 'Total loss': 0.828091261367644}
2022-11-18 00:52:36,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:36,142 INFO:     Epoch: 23
2022-11-18 00:52:36,933 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8169297806241296, 'Total loss': 0.8169297806241296} | train loss {'Reaction outcome loss': 0.8267779602639137, 'Total loss': 0.8267779602639137}
2022-11-18 00:52:36,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:36,933 INFO:     Epoch: 24
2022-11-18 00:52:37,731 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7965977070006457, 'Total loss': 0.7965977070006457} | train loss {'Reaction outcome loss': 0.8293439313288657, 'Total loss': 0.8293439313288657}
2022-11-18 00:52:37,731 INFO:     Found new best model at epoch 24
2022-11-18 00:52:37,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:37,732 INFO:     Epoch: 25
2022-11-18 00:52:38,523 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8078237731348384, 'Total loss': 0.8078237731348384} | train loss {'Reaction outcome loss': 0.8257887770812358, 'Total loss': 0.8257887770812358}
2022-11-18 00:52:38,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:38,524 INFO:     Epoch: 26
2022-11-18 00:52:39,284 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8118753920901906, 'Total loss': 0.8118753920901906} | train loss {'Reaction outcome loss': 0.8241099486908605, 'Total loss': 0.8241099486908605}
2022-11-18 00:52:39,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:39,285 INFO:     Epoch: 27
2022-11-18 00:52:40,047 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8086215569214388, 'Total loss': 0.8086215569214388} | train loss {'Reaction outcome loss': 0.8288806533861545, 'Total loss': 0.8288806533861545}
2022-11-18 00:52:40,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:40,048 INFO:     Epoch: 28
2022-11-18 00:52:40,818 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8053327731110833, 'Total loss': 0.8053327731110833} | train loss {'Reaction outcome loss': 0.8246810371356625, 'Total loss': 0.8246810371356625}
2022-11-18 00:52:40,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:40,818 INFO:     Epoch: 29
2022-11-18 00:52:41,619 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8199692666530609, 'Total loss': 0.8199692666530609} | train loss {'Reaction outcome loss': 0.8301438490950293, 'Total loss': 0.8301438490950293}
2022-11-18 00:52:41,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:41,620 INFO:     Epoch: 30
2022-11-18 00:52:42,421 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.810320416634733, 'Total loss': 0.810320416634733} | train loss {'Reaction outcome loss': 0.8216385377510902, 'Total loss': 0.8216385377510902}
2022-11-18 00:52:42,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:42,421 INFO:     Epoch: 31
2022-11-18 00:52:43,202 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.80283973230557, 'Total loss': 0.80283973230557} | train loss {'Reaction outcome loss': 0.8225689184281134, 'Total loss': 0.8225689184281134}
2022-11-18 00:52:43,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:43,202 INFO:     Epoch: 32
2022-11-18 00:52:43,998 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.802815436639569, 'Total loss': 0.802815436639569} | train loss {'Reaction outcome loss': 0.825032030382464, 'Total loss': 0.825032030382464}
2022-11-18 00:52:43,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:43,998 INFO:     Epoch: 33
2022-11-18 00:52:44,753 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7947677861560475, 'Total loss': 0.7947677861560475} | train loss {'Reaction outcome loss': 0.8268588881098455, 'Total loss': 0.8268588881098455}
2022-11-18 00:52:44,753 INFO:     Found new best model at epoch 33
2022-11-18 00:52:44,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:44,754 INFO:     Epoch: 34
2022-11-18 00:52:45,543 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.809820753606883, 'Total loss': 0.809820753606883} | train loss {'Reaction outcome loss': 0.8202649990637456, 'Total loss': 0.8202649990637456}
2022-11-18 00:52:45,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:45,543 INFO:     Epoch: 35
2022-11-18 00:52:46,335 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7959439124573361, 'Total loss': 0.7959439124573361} | train loss {'Reaction outcome loss': 0.8262390297266745, 'Total loss': 0.8262390297266745}
2022-11-18 00:52:46,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:46,336 INFO:     Epoch: 36
2022-11-18 00:52:47,118 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7966223989020694, 'Total loss': 0.7966223989020694} | train loss {'Reaction outcome loss': 0.8298140537113913, 'Total loss': 0.8298140537113913}
2022-11-18 00:52:47,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:47,118 INFO:     Epoch: 37
2022-11-18 00:52:47,918 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8191614977338098, 'Total loss': 0.8191614977338098} | train loss {'Reaction outcome loss': 0.8220901789684449, 'Total loss': 0.8220901789684449}
2022-11-18 00:52:47,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:47,918 INFO:     Epoch: 38
2022-11-18 00:52:48,730 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8132954890077765, 'Total loss': 0.8132954890077765} | train loss {'Reaction outcome loss': 0.8246124249192015, 'Total loss': 0.8246124249192015}
2022-11-18 00:52:48,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:48,730 INFO:     Epoch: 39
2022-11-18 00:52:49,516 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7990040460770781, 'Total loss': 0.7990040460770781} | train loss {'Reaction outcome loss': 0.8244845833509199, 'Total loss': 0.8244845833509199}
2022-11-18 00:52:49,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:49,517 INFO:     Epoch: 40
2022-11-18 00:52:50,307 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8230781426483934, 'Total loss': 0.8230781426483934} | train loss {'Reaction outcome loss': 0.8257784660785429, 'Total loss': 0.8257784660785429}
2022-11-18 00:52:50,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:50,308 INFO:     Epoch: 41
2022-11-18 00:52:51,090 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.800647724758495, 'Total loss': 0.800647724758495} | train loss {'Reaction outcome loss': 0.8287756642506968, 'Total loss': 0.8287756642506968}
2022-11-18 00:52:51,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:51,090 INFO:     Epoch: 42
2022-11-18 00:52:51,866 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8034491064873609, 'Total loss': 0.8034491064873609} | train loss {'Reaction outcome loss': 0.8254515410911653, 'Total loss': 0.8254515410911653}
2022-11-18 00:52:51,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:51,866 INFO:     Epoch: 43
2022-11-18 00:52:52,658 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8252605822953311, 'Total loss': 0.8252605822953311} | train loss {'Reaction outcome loss': 0.8217190037811956, 'Total loss': 0.8217190037811956}
2022-11-18 00:52:52,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:52,658 INFO:     Epoch: 44
2022-11-18 00:52:53,440 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8141466758467935, 'Total loss': 0.8141466758467935} | train loss {'Reaction outcome loss': 0.8285058334229454, 'Total loss': 0.8285058334229454}
2022-11-18 00:52:53,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:53,440 INFO:     Epoch: 45
2022-11-18 00:52:54,222 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7989727035164833, 'Total loss': 0.7989727035164833} | train loss {'Reaction outcome loss': 0.8228551836744431, 'Total loss': 0.8228551836744431}
2022-11-18 00:52:54,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:54,222 INFO:     Epoch: 46
2022-11-18 00:52:55,016 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7984322370453314, 'Total loss': 0.7984322370453314} | train loss {'Reaction outcome loss': 0.8221435504815271, 'Total loss': 0.8221435504815271}
2022-11-18 00:52:55,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:55,017 INFO:     Epoch: 47
2022-11-18 00:52:55,798 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8024408146739006, 'Total loss': 0.8024408146739006} | train loss {'Reaction outcome loss': 0.824489569231387, 'Total loss': 0.824489569231387}
2022-11-18 00:52:55,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:55,798 INFO:     Epoch: 48
2022-11-18 00:52:56,592 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8076482780955054, 'Total loss': 0.8076482780955054} | train loss {'Reaction outcome loss': 0.8236068509999783, 'Total loss': 0.8236068509999783}
2022-11-18 00:52:56,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:56,592 INFO:     Epoch: 49
2022-11-18 00:52:57,364 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8024717989293012, 'Total loss': 0.8024717989293012} | train loss {'Reaction outcome loss': 0.8244353449873386, 'Total loss': 0.8244353449873386}
2022-11-18 00:52:57,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:57,364 INFO:     Epoch: 50
2022-11-18 00:52:58,168 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8317152722315355, 'Total loss': 0.8317152722315355} | train loss {'Reaction outcome loss': 0.8279445363629249, 'Total loss': 0.8279445363629249}
2022-11-18 00:52:58,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:58,168 INFO:     Epoch: 51
2022-11-18 00:52:58,949 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8013711801984094, 'Total loss': 0.8013711801984094} | train loss {'Reaction outcome loss': 0.8244720645729573, 'Total loss': 0.8244720645729573}
2022-11-18 00:52:58,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:58,950 INFO:     Epoch: 52
2022-11-18 00:52:59,749 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8024808507074009, 'Total loss': 0.8024808507074009} | train loss {'Reaction outcome loss': 0.8243510809636885, 'Total loss': 0.8243510809636885}
2022-11-18 00:52:59,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:52:59,750 INFO:     Epoch: 53
2022-11-18 00:53:00,541 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7935590771111575, 'Total loss': 0.7935590771111575} | train loss {'Reaction outcome loss': 0.8231298286587961, 'Total loss': 0.8231298286587961}
2022-11-18 00:53:00,541 INFO:     Found new best model at epoch 53
2022-11-18 00:53:00,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:00,542 INFO:     Epoch: 54
2022-11-18 00:53:01,320 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8068083037029613, 'Total loss': 0.8068083037029613} | train loss {'Reaction outcome loss': 0.8232031017541885, 'Total loss': 0.8232031017541885}
2022-11-18 00:53:01,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:01,320 INFO:     Epoch: 55
2022-11-18 00:53:02,097 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8022126745093953, 'Total loss': 0.8022126745093953} | train loss {'Reaction outcome loss': 0.8252765163779259, 'Total loss': 0.8252765163779259}
2022-11-18 00:53:02,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:02,097 INFO:     Epoch: 56
2022-11-18 00:53:02,892 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8016985925761136, 'Total loss': 0.8016985925761136} | train loss {'Reaction outcome loss': 0.824317135397465, 'Total loss': 0.824317135397465}
2022-11-18 00:53:02,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:02,892 INFO:     Epoch: 57
2022-11-18 00:53:03,685 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.807483084499836, 'Total loss': 0.807483084499836} | train loss {'Reaction outcome loss': 0.8246704007108365, 'Total loss': 0.8246704007108365}
2022-11-18 00:53:03,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:03,685 INFO:     Epoch: 58
2022-11-18 00:53:04,448 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.801318802616813, 'Total loss': 0.801318802616813} | train loss {'Reaction outcome loss': 0.8200550890497623, 'Total loss': 0.8200550890497623}
2022-11-18 00:53:04,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:04,448 INFO:     Epoch: 59
2022-11-18 00:53:05,232 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8417870598760518, 'Total loss': 0.8417870598760518} | train loss {'Reaction outcome loss': 0.8232307521806609, 'Total loss': 0.8232307521806609}
2022-11-18 00:53:05,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:05,232 INFO:     Epoch: 60
2022-11-18 00:53:06,016 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7895464924248782, 'Total loss': 0.7895464924248782} | train loss {'Reaction outcome loss': 0.8232675939798355, 'Total loss': 0.8232675939798355}
2022-11-18 00:53:06,017 INFO:     Found new best model at epoch 60
2022-11-18 00:53:06,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:06,018 INFO:     Epoch: 61
2022-11-18 00:53:06,807 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8097052438692613, 'Total loss': 0.8097052438692613} | train loss {'Reaction outcome loss': 0.8240847253511029, 'Total loss': 0.8240847253511029}
2022-11-18 00:53:06,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:06,808 INFO:     Epoch: 62
2022-11-18 00:53:07,604 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8090656630017541, 'Total loss': 0.8090656630017541} | train loss {'Reaction outcome loss': 0.8218505866825581, 'Total loss': 0.8218505866825581}
2022-11-18 00:53:07,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:07,604 INFO:     Epoch: 63
2022-11-18 00:53:08,378 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7934258519248529, 'Total loss': 0.7934258519248529} | train loss {'Reaction outcome loss': 0.8209634804196896, 'Total loss': 0.8209634804196896}
2022-11-18 00:53:08,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:08,379 INFO:     Epoch: 64
2022-11-18 00:53:09,184 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.801604223522273, 'Total loss': 0.801604223522273} | train loss {'Reaction outcome loss': 0.8261796199987012, 'Total loss': 0.8261796199987012}
2022-11-18 00:53:09,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:09,184 INFO:     Epoch: 65
2022-11-18 00:53:09,983 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8343999941240657, 'Total loss': 0.8343999941240657} | train loss {'Reaction outcome loss': 0.8259805975662123, 'Total loss': 0.8259805975662123}
2022-11-18 00:53:09,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:09,983 INFO:     Epoch: 66
2022-11-18 00:53:10,757 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8082669925960627, 'Total loss': 0.8082669925960627} | train loss {'Reaction outcome loss': 0.8234738636641733, 'Total loss': 0.8234738636641733}
2022-11-18 00:53:10,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:10,757 INFO:     Epoch: 67
2022-11-18 00:53:11,553 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8063383684916929, 'Total loss': 0.8063383684916929} | train loss {'Reaction outcome loss': 0.8238442577421665, 'Total loss': 0.8238442577421665}
2022-11-18 00:53:11,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:11,555 INFO:     Epoch: 68
2022-11-18 00:53:12,329 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7970072776079178, 'Total loss': 0.7970072776079178} | train loss {'Reaction outcome loss': 0.8248664812455254, 'Total loss': 0.8248664812455254}
2022-11-18 00:53:12,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:12,329 INFO:     Epoch: 69
2022-11-18 00:53:13,092 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7936574383215471, 'Total loss': 0.7936574383215471} | train loss {'Reaction outcome loss': 0.8278686947399571, 'Total loss': 0.8278686947399571}
2022-11-18 00:53:13,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:13,092 INFO:     Epoch: 70
2022-11-18 00:53:13,869 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8098268874666907, 'Total loss': 0.8098268874666907} | train loss {'Reaction outcome loss': 0.8212378565822879, 'Total loss': 0.8212378565822879}
2022-11-18 00:53:13,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:13,869 INFO:     Epoch: 71
2022-11-18 00:53:14,624 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8254521489143372, 'Total loss': 0.8254521489143372} | train loss {'Reaction outcome loss': 0.8240520976964505, 'Total loss': 0.8240520976964505}
2022-11-18 00:53:14,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:14,624 INFO:     Epoch: 72
2022-11-18 00:53:15,388 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8102655207568948, 'Total loss': 0.8102655207568948} | train loss {'Reaction outcome loss': 0.8262128984976199, 'Total loss': 0.8262128984976199}
2022-11-18 00:53:15,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:15,388 INFO:     Epoch: 73
2022-11-18 00:53:16,177 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7980349084193056, 'Total loss': 0.7980349084193056} | train loss {'Reaction outcome loss': 0.8284364923113777, 'Total loss': 0.8284364923113777}
2022-11-18 00:53:16,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:16,177 INFO:     Epoch: 74
2022-11-18 00:53:16,973 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8245392109860074, 'Total loss': 0.8245392109860074} | train loss {'Reaction outcome loss': 0.8277524623178667, 'Total loss': 0.8277524623178667}
2022-11-18 00:53:16,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:16,973 INFO:     Epoch: 75
2022-11-18 00:53:17,787 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8288782340559092, 'Total loss': 0.8288782340559092} | train loss {'Reaction outcome loss': 0.8299315821739935, 'Total loss': 0.8299315821739935}
2022-11-18 00:53:17,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:17,788 INFO:     Epoch: 76
2022-11-18 00:53:18,577 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8214971951463006, 'Total loss': 0.8214971951463006} | train loss {'Reaction outcome loss': 0.8248361036662133, 'Total loss': 0.8248361036662133}
2022-11-18 00:53:18,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:18,577 INFO:     Epoch: 77
2022-11-18 00:53:19,378 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8049401180310682, 'Total loss': 0.8049401180310682} | train loss {'Reaction outcome loss': 0.8249733345883508, 'Total loss': 0.8249733345883508}
2022-11-18 00:53:19,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:19,378 INFO:     Epoch: 78
2022-11-18 00:53:20,153 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7993483516302976, 'Total loss': 0.7993483516302976} | train loss {'Reaction outcome loss': 0.824924293064302, 'Total loss': 0.824924293064302}
2022-11-18 00:53:20,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:20,153 INFO:     Epoch: 79
2022-11-18 00:53:20,949 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8228953805836764, 'Total loss': 0.8228953805836764} | train loss {'Reaction outcome loss': 0.8264064933023145, 'Total loss': 0.8264064933023145}
2022-11-18 00:53:20,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:20,949 INFO:     Epoch: 80
2022-11-18 00:53:21,737 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7963875952092084, 'Total loss': 0.7963875952092084} | train loss {'Reaction outcome loss': 0.8224765019070718, 'Total loss': 0.8224765019070718}
2022-11-18 00:53:21,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:21,738 INFO:     Epoch: 81
2022-11-18 00:53:22,494 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8032933412627741, 'Total loss': 0.8032933412627741} | train loss {'Reaction outcome loss': 0.8250498115535705, 'Total loss': 0.8250498115535705}
2022-11-18 00:53:22,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:22,494 INFO:     Epoch: 82
2022-11-18 00:53:23,272 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8078845881602981, 'Total loss': 0.8078845881602981} | train loss {'Reaction outcome loss': 0.8206318369315516, 'Total loss': 0.8206318369315516}
2022-11-18 00:53:23,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:23,273 INFO:     Epoch: 83
2022-11-18 00:53:24,056 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.789310825819319, 'Total loss': 0.789310825819319} | train loss {'Reaction outcome loss': 0.823352066379401, 'Total loss': 0.823352066379401}
2022-11-18 00:53:24,056 INFO:     Found new best model at epoch 83
2022-11-18 00:53:24,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:24,057 INFO:     Epoch: 84
2022-11-18 00:53:24,831 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8074372017925436, 'Total loss': 0.8074372017925436} | train loss {'Reaction outcome loss': 0.8230868003541424, 'Total loss': 0.8230868003541424}
2022-11-18 00:53:24,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:24,832 INFO:     Epoch: 85
2022-11-18 00:53:25,611 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8061340938914906, 'Total loss': 0.8061340938914906} | train loss {'Reaction outcome loss': 0.8232252022191402, 'Total loss': 0.8232252022191402}
2022-11-18 00:53:25,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:25,611 INFO:     Epoch: 86
2022-11-18 00:53:26,408 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8069268478588625, 'Total loss': 0.8069268478588625} | train loss {'Reaction outcome loss': 0.8277344412861332, 'Total loss': 0.8277344412861332}
2022-11-18 00:53:26,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:26,408 INFO:     Epoch: 87
2022-11-18 00:53:27,189 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.817385811697353, 'Total loss': 0.817385811697353} | train loss {'Reaction outcome loss': 0.8264867055319971, 'Total loss': 0.8264867055319971}
2022-11-18 00:53:27,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:27,189 INFO:     Epoch: 88
2022-11-18 00:53:27,979 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8122825182297013, 'Total loss': 0.8122825182297013} | train loss {'Reaction outcome loss': 0.8306642832054246, 'Total loss': 0.8306642832054246}
2022-11-18 00:53:27,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:27,980 INFO:     Epoch: 89
2022-11-18 00:53:28,768 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8012399206107313, 'Total loss': 0.8012399206107313} | train loss {'Reaction outcome loss': 0.8258315062811298, 'Total loss': 0.8258315062811298}
2022-11-18 00:53:28,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:28,768 INFO:     Epoch: 90
2022-11-18 00:53:29,570 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.808456311171705, 'Total loss': 0.808456311171705} | train loss {'Reaction outcome loss': 0.8246587389899839, 'Total loss': 0.8246587389899839}
2022-11-18 00:53:29,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:29,571 INFO:     Epoch: 91
2022-11-18 00:53:30,363 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8005192361094735, 'Total loss': 0.8005192361094735} | train loss {'Reaction outcome loss': 0.8261821914103723, 'Total loss': 0.8261821914103723}
2022-11-18 00:53:30,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:30,364 INFO:     Epoch: 92
2022-11-18 00:53:31,159 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8465065698732029, 'Total loss': 0.8465065698732029} | train loss {'Reaction outcome loss': 0.82780149182485, 'Total loss': 0.82780149182485}
2022-11-18 00:53:31,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:31,159 INFO:     Epoch: 93
2022-11-18 00:53:31,931 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7935262153094466, 'Total loss': 0.7935262153094466} | train loss {'Reaction outcome loss': 0.8263150681891749, 'Total loss': 0.8263150681891749}
2022-11-18 00:53:31,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:31,932 INFO:     Epoch: 94
2022-11-18 00:53:32,695 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8181419751860879, 'Total loss': 0.8181419751860879} | train loss {'Reaction outcome loss': 0.8251632979560283, 'Total loss': 0.8251632979560283}
2022-11-18 00:53:32,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:32,695 INFO:     Epoch: 95
2022-11-18 00:53:33,478 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8002096719362519, 'Total loss': 0.8002096719362519} | train loss {'Reaction outcome loss': 0.8273250028010337, 'Total loss': 0.8273250028010337}
2022-11-18 00:53:33,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:33,478 INFO:     Epoch: 96
2022-11-18 00:53:34,282 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8010083884000778, 'Total loss': 0.8010083884000778} | train loss {'Reaction outcome loss': 0.8195938221629588, 'Total loss': 0.8195938221629588}
2022-11-18 00:53:34,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:34,282 INFO:     Epoch: 97
2022-11-18 00:53:35,081 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8048681562597101, 'Total loss': 0.8048681562597101} | train loss {'Reaction outcome loss': 0.821197264016636, 'Total loss': 0.821197264016636}
2022-11-18 00:53:35,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:35,081 INFO:     Epoch: 98
2022-11-18 00:53:35,863 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.848742543973706, 'Total loss': 0.848742543973706} | train loss {'Reaction outcome loss': 0.8238811424422648, 'Total loss': 0.8238811424422648}
2022-11-18 00:53:35,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:35,863 INFO:     Epoch: 99
2022-11-18 00:53:36,677 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8100311580029401, 'Total loss': 0.8100311580029401} | train loss {'Reaction outcome loss': 0.822315817999263, 'Total loss': 0.822315817999263}
2022-11-18 00:53:36,677 INFO:     Best model found after epoch 84 of 100.
2022-11-18 00:53:36,677 INFO:   Done with stage: TRAINING
2022-11-18 00:53:36,677 INFO:   Starting stage: EVALUATION
2022-11-18 00:53:36,796 INFO:   Done with stage: EVALUATION
2022-11-18 00:53:36,805 INFO:   Leaving out SEQ value Fold_0
2022-11-18 00:53:36,818 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 00:53:36,818 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:53:37,488 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:53:37,488 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:53:37,558 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:53:37,558 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:53:37,558 INFO:     No hyperparam tuning for this model
2022-11-18 00:53:37,558 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:53:37,558 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:53:37,559 INFO:     None feature selector for col prot
2022-11-18 00:53:37,559 INFO:     None feature selector for col prot
2022-11-18 00:53:37,559 INFO:     None feature selector for col prot
2022-11-18 00:53:37,560 INFO:     None feature selector for col chem
2022-11-18 00:53:37,560 INFO:     None feature selector for col chem
2022-11-18 00:53:37,560 INFO:     None feature selector for col chem
2022-11-18 00:53:37,560 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:53:37,560 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:53:37,562 INFO:     Number of params in model 168571
2022-11-18 00:53:37,565 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:53:37,565 INFO:   Starting stage: TRAINING
2022-11-18 00:53:37,624 INFO:     Val loss before train {'Reaction outcome loss': 0.9725820069963281, 'Total loss': 0.9725820069963281}
2022-11-18 00:53:37,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:37,624 INFO:     Epoch: 0
2022-11-18 00:53:38,429 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8910792876373638, 'Total loss': 0.8910792876373638} | train loss {'Reaction outcome loss': 0.8708981965269361, 'Total loss': 0.8708981965269361}
2022-11-18 00:53:38,429 INFO:     Found new best model at epoch 0
2022-11-18 00:53:38,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:38,430 INFO:     Epoch: 1
2022-11-18 00:53:39,220 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8186169808561151, 'Total loss': 0.8186169808561151} | train loss {'Reaction outcome loss': 0.8354781891618456, 'Total loss': 0.8354781891618456}
2022-11-18 00:53:39,220 INFO:     Found new best model at epoch 1
2022-11-18 00:53:39,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:39,221 INFO:     Epoch: 2
2022-11-18 00:53:39,984 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8270585428584706, 'Total loss': 0.8270585428584706} | train loss {'Reaction outcome loss': 0.8316387457506997, 'Total loss': 0.8316387457506997}
2022-11-18 00:53:39,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:39,984 INFO:     Epoch: 3
2022-11-18 00:53:40,784 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8434702232480049, 'Total loss': 0.8434702232480049} | train loss {'Reaction outcome loss': 0.8287885766856524, 'Total loss': 0.8287885766856524}
2022-11-18 00:53:40,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:40,785 INFO:     Epoch: 4
2022-11-18 00:53:41,581 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8429352343082428, 'Total loss': 0.8429352343082428} | train loss {'Reaction outcome loss': 0.8265330090814708, 'Total loss': 0.8265330090814708}
2022-11-18 00:53:41,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:41,581 INFO:     Epoch: 5
2022-11-18 00:53:42,375 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8260356201366945, 'Total loss': 0.8260356201366945} | train loss {'Reaction outcome loss': 0.8229179601280057, 'Total loss': 0.8229179601280057}
2022-11-18 00:53:42,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:42,375 INFO:     Epoch: 6
2022-11-18 00:53:43,169 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8181060410358689, 'Total loss': 0.8181060410358689} | train loss {'Reaction outcome loss': 0.8239125054709765, 'Total loss': 0.8239125054709765}
2022-11-18 00:53:43,171 INFO:     Found new best model at epoch 6
2022-11-18 00:53:43,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:43,172 INFO:     Epoch: 7
2022-11-18 00:53:43,936 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8311860392039473, 'Total loss': 0.8311860392039473} | train loss {'Reaction outcome loss': 0.8195879617515875, 'Total loss': 0.8195879617515875}
2022-11-18 00:53:43,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:43,937 INFO:     Epoch: 8
2022-11-18 00:53:44,716 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8382837183096192, 'Total loss': 0.8382837183096192} | train loss {'Reaction outcome loss': 0.8177256074486946, 'Total loss': 0.8177256074486946}
2022-11-18 00:53:44,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:44,717 INFO:     Epoch: 9
2022-11-18 00:53:45,510 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8457995388995517, 'Total loss': 0.8457995388995517} | train loss {'Reaction outcome loss': 0.8131566796983991, 'Total loss': 0.8131566796983991}
2022-11-18 00:53:45,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:45,511 INFO:     Epoch: 10
2022-11-18 00:53:46,273 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.789478369734504, 'Total loss': 0.789478369734504} | train loss {'Reaction outcome loss': 0.8212558425202662, 'Total loss': 0.8212558425202662}
2022-11-18 00:53:46,273 INFO:     Found new best model at epoch 10
2022-11-18 00:53:46,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:46,274 INFO:     Epoch: 11
2022-11-18 00:53:47,050 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8085442192175172, 'Total loss': 0.8085442192175172} | train loss {'Reaction outcome loss': 0.8134496957671885, 'Total loss': 0.8134496957671885}
2022-11-18 00:53:47,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:47,050 INFO:     Epoch: 12
2022-11-18 00:53:47,825 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.811970129609108, 'Total loss': 0.811970129609108} | train loss {'Reaction outcome loss': 0.8172043248098724, 'Total loss': 0.8172043248098724}
2022-11-18 00:53:47,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:47,826 INFO:     Epoch: 13
2022-11-18 00:53:48,585 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8186102096330036, 'Total loss': 0.8186102096330036} | train loss {'Reaction outcome loss': 0.8201804629393986, 'Total loss': 0.8201804629393986}
2022-11-18 00:53:48,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:48,585 INFO:     Epoch: 14
2022-11-18 00:53:49,385 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8025150353258307, 'Total loss': 0.8025150353258307} | train loss {'Reaction outcome loss': 0.8111316196772517, 'Total loss': 0.8111316196772517}
2022-11-18 00:53:49,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:49,386 INFO:     Epoch: 15
2022-11-18 00:53:50,156 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8034684766422618, 'Total loss': 0.8034684766422618} | train loss {'Reaction outcome loss': 0.8171239846823167, 'Total loss': 0.8171239846823167}
2022-11-18 00:53:50,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:50,156 INFO:     Epoch: 16
2022-11-18 00:53:50,938 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8060188218951225, 'Total loss': 0.8060188218951225} | train loss {'Reaction outcome loss': 0.8122372397354671, 'Total loss': 0.8122372397354671}
2022-11-18 00:53:50,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:50,939 INFO:     Epoch: 17
2022-11-18 00:53:51,710 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8013344671238553, 'Total loss': 0.8013344671238553} | train loss {'Reaction outcome loss': 0.8150496387968258, 'Total loss': 0.8150496387968258}
2022-11-18 00:53:51,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:51,710 INFO:     Epoch: 18
2022-11-18 00:53:52,503 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7927558523687449, 'Total loss': 0.7927558523687449} | train loss {'Reaction outcome loss': 0.8114624710715547, 'Total loss': 0.8114624710715547}
2022-11-18 00:53:52,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:52,503 INFO:     Epoch: 19
2022-11-18 00:53:53,299 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8182881311936812, 'Total loss': 0.8182881311936812} | train loss {'Reaction outcome loss': 0.8103755404754561, 'Total loss': 0.8103755404754561}
2022-11-18 00:53:53,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:53,299 INFO:     Epoch: 20
2022-11-18 00:53:54,093 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8209082260727882, 'Total loss': 0.8209082260727882} | train loss {'Reaction outcome loss': 0.8111229536484699, 'Total loss': 0.8111229536484699}
2022-11-18 00:53:54,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:54,093 INFO:     Epoch: 21
2022-11-18 00:53:54,850 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.829239543188702, 'Total loss': 0.829239543188702} | train loss {'Reaction outcome loss': 0.8134282320129628, 'Total loss': 0.8134282320129628}
2022-11-18 00:53:54,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:54,850 INFO:     Epoch: 22
2022-11-18 00:53:55,588 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8233194798231125, 'Total loss': 0.8233194798231125} | train loss {'Reaction outcome loss': 0.8146401895552265, 'Total loss': 0.8146401895552265}
2022-11-18 00:53:55,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:55,588 INFO:     Epoch: 23
2022-11-18 00:53:56,372 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7928073460405524, 'Total loss': 0.7928073460405524} | train loss {'Reaction outcome loss': 0.811030810219901, 'Total loss': 0.811030810219901}
2022-11-18 00:53:56,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:56,373 INFO:     Epoch: 24
2022-11-18 00:53:57,153 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7952531217174097, 'Total loss': 0.7952531217174097} | train loss {'Reaction outcome loss': 0.8133877423344826, 'Total loss': 0.8133877423344826}
2022-11-18 00:53:57,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:57,153 INFO:     Epoch: 25
2022-11-18 00:53:57,919 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8237589529969476, 'Total loss': 0.8237589529969476} | train loss {'Reaction outcome loss': 0.8101010522063897, 'Total loss': 0.8101010522063897}
2022-11-18 00:53:57,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:57,919 INFO:     Epoch: 26
2022-11-18 00:53:58,699 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8163560852408409, 'Total loss': 0.8163560852408409} | train loss {'Reaction outcome loss': 0.811387355716861, 'Total loss': 0.811387355716861}
2022-11-18 00:53:58,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:58,699 INFO:     Epoch: 27
2022-11-18 00:53:59,472 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8324460170485757, 'Total loss': 0.8324460170485757} | train loss {'Reaction outcome loss': 0.8094356457797849, 'Total loss': 0.8094356457797849}
2022-11-18 00:53:59,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:53:59,473 INFO:     Epoch: 28
2022-11-18 00:54:00,279 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8016320466995239, 'Total loss': 0.8016320466995239} | train loss {'Reaction outcome loss': 0.8100821671437244, 'Total loss': 0.8100821671437244}
2022-11-18 00:54:00,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:00,279 INFO:     Epoch: 29
2022-11-18 00:54:01,051 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.799586745487018, 'Total loss': 0.799586745487018} | train loss {'Reaction outcome loss': 0.8096888538526029, 'Total loss': 0.8096888538526029}
2022-11-18 00:54:01,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:01,051 INFO:     Epoch: 30
2022-11-18 00:54:01,832 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8226835192604498, 'Total loss': 0.8226835192604498} | train loss {'Reaction outcome loss': 0.8118360623413202, 'Total loss': 0.8118360623413202}
2022-11-18 00:54:01,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:01,833 INFO:     Epoch: 31
2022-11-18 00:54:02,642 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8430385846983303, 'Total loss': 0.8430385846983303} | train loss {'Reaction outcome loss': 0.8097828785375673, 'Total loss': 0.8097828785375673}
2022-11-18 00:54:02,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:02,642 INFO:     Epoch: 32
2022-11-18 00:54:03,432 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8244434242898767, 'Total loss': 0.8244434242898767} | train loss {'Reaction outcome loss': 0.8153783817680514, 'Total loss': 0.8153783817680514}
2022-11-18 00:54:03,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:03,432 INFO:     Epoch: 33
2022-11-18 00:54:04,226 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7937871898439798, 'Total loss': 0.7937871898439798} | train loss {'Reaction outcome loss': 0.8103274789391731, 'Total loss': 0.8103274789391731}
2022-11-18 00:54:04,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:04,227 INFO:     Epoch: 34
2022-11-18 00:54:04,988 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8081404383886944, 'Total loss': 0.8081404383886944} | train loss {'Reaction outcome loss': 0.8111590104443687, 'Total loss': 0.8111590104443687}
2022-11-18 00:54:04,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:04,988 INFO:     Epoch: 35
2022-11-18 00:54:05,757 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8239335620945151, 'Total loss': 0.8239335620945151} | train loss {'Reaction outcome loss': 0.8086725085365529, 'Total loss': 0.8086725085365529}
2022-11-18 00:54:05,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:05,757 INFO:     Epoch: 36
2022-11-18 00:54:06,542 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8140243142843246, 'Total loss': 0.8140243142843246} | train loss {'Reaction outcome loss': 0.8116475815675697, 'Total loss': 0.8116475815675697}
2022-11-18 00:54:06,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:06,542 INFO:     Epoch: 37
2022-11-18 00:54:07,297 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.804342544214292, 'Total loss': 0.804342544214292} | train loss {'Reaction outcome loss': 0.8128529148442405, 'Total loss': 0.8128529148442405}
2022-11-18 00:54:07,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:07,297 INFO:     Epoch: 38
2022-11-18 00:54:08,065 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.810935219580477, 'Total loss': 0.810935219580477} | train loss {'Reaction outcome loss': 0.8085674265209509, 'Total loss': 0.8085674265209509}
2022-11-18 00:54:08,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:08,065 INFO:     Epoch: 39
2022-11-18 00:54:08,828 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8203745274381204, 'Total loss': 0.8203745274381204} | train loss {'Reaction outcome loss': 0.8085043893784892, 'Total loss': 0.8085043893784892}
2022-11-18 00:54:08,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:08,829 INFO:     Epoch: 40
2022-11-18 00:54:09,586 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8050317378206686, 'Total loss': 0.8050317378206686} | train loss {'Reaction outcome loss': 0.8087808054320667, 'Total loss': 0.8087808054320667}
2022-11-18 00:54:09,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:09,586 INFO:     Epoch: 41
2022-11-18 00:54:10,373 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8310329805720936, 'Total loss': 0.8310329805720936} | train loss {'Reaction outcome loss': 0.8089616998117797, 'Total loss': 0.8089616998117797}
2022-11-18 00:54:10,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:10,373 INFO:     Epoch: 42
2022-11-18 00:54:11,157 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8064302199266173, 'Total loss': 0.8064302199266173} | train loss {'Reaction outcome loss': 0.8058942653694932, 'Total loss': 0.8058942653694932}
2022-11-18 00:54:11,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:11,158 INFO:     Epoch: 43
2022-11-18 00:54:11,928 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8029795187440786, 'Total loss': 0.8029795187440786} | train loss {'Reaction outcome loss': 0.8079414059921187, 'Total loss': 0.8079414059921187}
2022-11-18 00:54:11,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:11,929 INFO:     Epoch: 44
2022-11-18 00:54:12,690 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7964165820316835, 'Total loss': 0.7964165820316835} | train loss {'Reaction outcome loss': 0.8104201009078902, 'Total loss': 0.8104201009078902}
2022-11-18 00:54:12,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:12,691 INFO:     Epoch: 45
2022-11-18 00:54:13,476 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8016410639340227, 'Total loss': 0.8016410639340227} | train loss {'Reaction outcome loss': 0.8093984280313764, 'Total loss': 0.8093984280313764}
2022-11-18 00:54:13,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:13,477 INFO:     Epoch: 46
2022-11-18 00:54:14,264 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8342533558607101, 'Total loss': 0.8342533558607101} | train loss {'Reaction outcome loss': 0.8030014267989567, 'Total loss': 0.8030014267989567}
2022-11-18 00:54:14,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:14,265 INFO:     Epoch: 47
2022-11-18 00:54:15,070 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7867231050675566, 'Total loss': 0.7867231050675566} | train loss {'Reaction outcome loss': 0.8082496622387244, 'Total loss': 0.8082496622387244}
2022-11-18 00:54:15,070 INFO:     Found new best model at epoch 47
2022-11-18 00:54:15,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:15,071 INFO:     Epoch: 48
2022-11-18 00:54:15,849 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7977016629143194, 'Total loss': 0.7977016629143194} | train loss {'Reaction outcome loss': 0.8093164951217418, 'Total loss': 0.8093164951217418}
2022-11-18 00:54:15,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:15,849 INFO:     Epoch: 49
2022-11-18 00:54:16,594 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8147123903036118, 'Total loss': 0.8147123903036118} | train loss {'Reaction outcome loss': 0.8091508147667865, 'Total loss': 0.8091508147667865}
2022-11-18 00:54:16,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:16,594 INFO:     Epoch: 50
2022-11-18 00:54:17,363 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8075075982646509, 'Total loss': 0.8075075982646509} | train loss {'Reaction outcome loss': 0.8069772266611761, 'Total loss': 0.8069772266611761}
2022-11-18 00:54:17,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:17,364 INFO:     Epoch: 51
2022-11-18 00:54:18,126 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8147957961667668, 'Total loss': 0.8147957961667668} | train loss {'Reaction outcome loss': 0.8128037305510774, 'Total loss': 0.8128037305510774}
2022-11-18 00:54:18,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:18,126 INFO:     Epoch: 52
2022-11-18 00:54:18,903 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8220578757199374, 'Total loss': 0.8220578757199374} | train loss {'Reaction outcome loss': 0.8087319027404396, 'Total loss': 0.8087319027404396}
2022-11-18 00:54:18,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:18,904 INFO:     Epoch: 53
2022-11-18 00:54:19,702 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7968308316035704, 'Total loss': 0.7968308316035704} | train loss {'Reaction outcome loss': 0.8117956864590548, 'Total loss': 0.8117956864590548}
2022-11-18 00:54:19,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:19,702 INFO:     Epoch: 54
2022-11-18 00:54:20,462 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8041483678601005, 'Total loss': 0.8041483678601005} | train loss {'Reaction outcome loss': 0.8086941569435353, 'Total loss': 0.8086941569435353}
2022-11-18 00:54:20,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:20,463 INFO:     Epoch: 55
2022-11-18 00:54:21,236 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8030707273970951, 'Total loss': 0.8030707273970951} | train loss {'Reaction outcome loss': 0.8109221230964272, 'Total loss': 0.8109221230964272}
2022-11-18 00:54:21,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:21,237 INFO:     Epoch: 56
2022-11-18 00:54:22,054 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8110191463069483, 'Total loss': 0.8110191463069483} | train loss {'Reaction outcome loss': 0.8052833568076698, 'Total loss': 0.8052833568076698}
2022-11-18 00:54:22,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:22,054 INFO:     Epoch: 57
2022-11-18 00:54:22,834 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8004147904840383, 'Total loss': 0.8004147904840383} | train loss {'Reaction outcome loss': 0.8077866098102258, 'Total loss': 0.8077866098102258}
2022-11-18 00:54:22,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:22,835 INFO:     Epoch: 58
2022-11-18 00:54:23,638 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8051154958930883, 'Total loss': 0.8051154958930883} | train loss {'Reaction outcome loss': 0.8070192360148138, 'Total loss': 0.8070192360148138}
2022-11-18 00:54:23,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:23,638 INFO:     Epoch: 59
2022-11-18 00:54:24,444 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7897773960774596, 'Total loss': 0.7897773960774596} | train loss {'Reaction outcome loss': 0.8057462355312036, 'Total loss': 0.8057462355312036}
2022-11-18 00:54:24,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:24,444 INFO:     Epoch: 60
2022-11-18 00:54:25,265 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8175695782357996, 'Total loss': 0.8175695782357996} | train loss {'Reaction outcome loss': 0.8096672711323719, 'Total loss': 0.8096672711323719}
2022-11-18 00:54:25,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:25,265 INFO:     Epoch: 61
2022-11-18 00:54:26,105 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8223518851128492, 'Total loss': 0.8223518851128492} | train loss {'Reaction outcome loss': 0.8090357414313725, 'Total loss': 0.8090357414313725}
2022-11-18 00:54:26,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:26,105 INFO:     Epoch: 62
2022-11-18 00:54:26,933 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8071824833750725, 'Total loss': 0.8071824833750725} | train loss {'Reaction outcome loss': 0.8036766945099344, 'Total loss': 0.8036766945099344}
2022-11-18 00:54:26,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:26,933 INFO:     Epoch: 63
2022-11-18 00:54:27,716 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8053151805969802, 'Total loss': 0.8053151805969802} | train loss {'Reaction outcome loss': 0.8098580904152929, 'Total loss': 0.8098580904152929}
2022-11-18 00:54:27,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:27,716 INFO:     Epoch: 64
2022-11-18 00:54:28,501 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8255177221514962, 'Total loss': 0.8255177221514962} | train loss {'Reaction outcome loss': 0.8075095362809239, 'Total loss': 0.8075095362809239}
2022-11-18 00:54:28,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:28,501 INFO:     Epoch: 65
2022-11-18 00:54:29,269 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8161194297400388, 'Total loss': 0.8161194297400388} | train loss {'Reaction outcome loss': 0.8068163527517903, 'Total loss': 0.8068163527517903}
2022-11-18 00:54:29,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:29,269 INFO:     Epoch: 66
2022-11-18 00:54:30,104 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7996930229392919, 'Total loss': 0.7996930229392919} | train loss {'Reaction outcome loss': 0.8103740624019078, 'Total loss': 0.8103740624019078}
2022-11-18 00:54:30,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:30,104 INFO:     Epoch: 67
2022-11-18 00:54:30,959 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7944173199886625, 'Total loss': 0.7944173199886625} | train loss {'Reaction outcome loss': 0.8082393055059471, 'Total loss': 0.8082393055059471}
2022-11-18 00:54:30,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:30,959 INFO:     Epoch: 68
2022-11-18 00:54:31,747 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.79599875618111, 'Total loss': 0.79599875618111} | train loss {'Reaction outcome loss': 0.806680666427223, 'Total loss': 0.806680666427223}
2022-11-18 00:54:31,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:31,747 INFO:     Epoch: 69
2022-11-18 00:54:32,549 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8379692055962302, 'Total loss': 0.8379692055962302} | train loss {'Reaction outcome loss': 0.8068718964956245, 'Total loss': 0.8068718964956245}
2022-11-18 00:54:32,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:32,551 INFO:     Epoch: 70
2022-11-18 00:54:33,387 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7936316200278022, 'Total loss': 0.7936316200278022} | train loss {'Reaction outcome loss': 0.8045658049534778, 'Total loss': 0.8045658049534778}
2022-11-18 00:54:33,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:33,388 INFO:     Epoch: 71
2022-11-18 00:54:34,194 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8159590593793176, 'Total loss': 0.8159590593793176} | train loss {'Reaction outcome loss': 0.803604520218713, 'Total loss': 0.803604520218713}
2022-11-18 00:54:34,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:34,194 INFO:     Epoch: 72
2022-11-18 00:54:34,991 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8038234121420167, 'Total loss': 0.8038234121420167} | train loss {'Reaction outcome loss': 0.8042344592055496, 'Total loss': 0.8042344592055496}
2022-11-18 00:54:34,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:34,991 INFO:     Epoch: 73
2022-11-18 00:54:35,794 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8171406266364184, 'Total loss': 0.8171406266364184} | train loss {'Reaction outcome loss': 0.8068446124086575, 'Total loss': 0.8068446124086575}
2022-11-18 00:54:35,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:35,794 INFO:     Epoch: 74
2022-11-18 00:54:36,602 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8163627873767506, 'Total loss': 0.8163627873767506} | train loss {'Reaction outcome loss': 0.8055003875372361, 'Total loss': 0.8055003875372361}
2022-11-18 00:54:36,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:36,602 INFO:     Epoch: 75
2022-11-18 00:54:37,435 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.800417001274499, 'Total loss': 0.800417001274499} | train loss {'Reaction outcome loss': 0.807527140208653, 'Total loss': 0.807527140208653}
2022-11-18 00:54:37,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:37,435 INFO:     Epoch: 76
2022-11-18 00:54:38,258 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8160679306496273, 'Total loss': 0.8160679306496273} | train loss {'Reaction outcome loss': 0.8099371789669504, 'Total loss': 0.8099371789669504}
2022-11-18 00:54:38,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:38,258 INFO:     Epoch: 77
2022-11-18 00:54:39,089 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7908763120120222, 'Total loss': 0.7908763120120222} | train loss {'Reaction outcome loss': 0.80591087535936, 'Total loss': 0.80591087535936}
2022-11-18 00:54:39,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:39,089 INFO:     Epoch: 78
2022-11-18 00:54:39,857 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7921860654923049, 'Total loss': 0.7921860654923049} | train loss {'Reaction outcome loss': 0.8057901380013447, 'Total loss': 0.8057901380013447}
2022-11-18 00:54:39,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:39,857 INFO:     Epoch: 79
2022-11-18 00:54:40,628 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8245464346625588, 'Total loss': 0.8245464346625588} | train loss {'Reaction outcome loss': 0.802252242394856, 'Total loss': 0.802252242394856}
2022-11-18 00:54:40,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:40,628 INFO:     Epoch: 80
2022-11-18 00:54:41,399 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8187346871603619, 'Total loss': 0.8187346871603619} | train loss {'Reaction outcome loss': 0.8073683213214485, 'Total loss': 0.8073683213214485}
2022-11-18 00:54:41,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:41,400 INFO:     Epoch: 81
2022-11-18 00:54:42,213 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7929763793945312, 'Total loss': 0.7929763793945312} | train loss {'Reaction outcome loss': 0.806180618855418, 'Total loss': 0.806180618855418}
2022-11-18 00:54:42,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:42,213 INFO:     Epoch: 82
2022-11-18 00:54:43,062 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8129418065602129, 'Total loss': 0.8129418065602129} | train loss {'Reaction outcome loss': 0.8059153649271751, 'Total loss': 0.8059153649271751}
2022-11-18 00:54:43,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:43,062 INFO:     Epoch: 83
2022-11-18 00:54:43,880 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8287507146596909, 'Total loss': 0.8287507146596909} | train loss {'Reaction outcome loss': 0.806483934971751, 'Total loss': 0.806483934971751}
2022-11-18 00:54:43,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:43,881 INFO:     Epoch: 84
2022-11-18 00:54:44,705 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8059711178595369, 'Total loss': 0.8059711178595369} | train loss {'Reaction outcome loss': 0.8089222360630425, 'Total loss': 0.8089222360630425}
2022-11-18 00:54:44,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:44,706 INFO:     Epoch: 85
2022-11-18 00:54:45,507 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8006342256611044, 'Total loss': 0.8006342256611044} | train loss {'Reaction outcome loss': 0.807220151594707, 'Total loss': 0.807220151594707}
2022-11-18 00:54:45,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:45,509 INFO:     Epoch: 86
2022-11-18 00:54:46,353 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8052058843049136, 'Total loss': 0.8052058843049136} | train loss {'Reaction outcome loss': 0.8000046288480565, 'Total loss': 0.8000046288480565}
2022-11-18 00:54:46,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:46,353 INFO:     Epoch: 87
2022-11-18 00:54:47,182 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8031768514351412, 'Total loss': 0.8031768514351412} | train loss {'Reaction outcome loss': 0.8024115814238179, 'Total loss': 0.8024115814238179}
2022-11-18 00:54:47,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:47,182 INFO:     Epoch: 88
2022-11-18 00:54:48,026 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.794590528038415, 'Total loss': 0.794590528038415} | train loss {'Reaction outcome loss': 0.8045842405484647, 'Total loss': 0.8045842405484647}
2022-11-18 00:54:48,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:48,027 INFO:     Epoch: 89
2022-11-18 00:54:48,778 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7930613620714708, 'Total loss': 0.7930613620714708} | train loss {'Reaction outcome loss': 0.8083109308262261, 'Total loss': 0.8083109308262261}
2022-11-18 00:54:48,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:48,778 INFO:     Epoch: 90
2022-11-18 00:54:49,591 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8166002597321164, 'Total loss': 0.8166002597321164} | train loss {'Reaction outcome loss': 0.8066654070299499, 'Total loss': 0.8066654070299499}
2022-11-18 00:54:49,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:49,591 INFO:     Epoch: 91
2022-11-18 00:54:50,407 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8483617441220717, 'Total loss': 0.8483617441220717} | train loss {'Reaction outcome loss': 0.804565468369698, 'Total loss': 0.804565468369698}
2022-11-18 00:54:50,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:50,407 INFO:     Epoch: 92
2022-11-18 00:54:51,189 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8045922233299776, 'Total loss': 0.8045922233299776} | train loss {'Reaction outcome loss': 0.8091062866911596, 'Total loss': 0.8091062866911596}
2022-11-18 00:54:51,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:51,189 INFO:     Epoch: 93
2022-11-18 00:54:52,005 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8104818801988255, 'Total loss': 0.8104818801988255} | train loss {'Reaction outcome loss': 0.8065788934425432, 'Total loss': 0.8065788934425432}
2022-11-18 00:54:52,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:52,006 INFO:     Epoch: 94
2022-11-18 00:54:52,825 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8012304082512856, 'Total loss': 0.8012304082512856} | train loss {'Reaction outcome loss': 0.8083489315850394, 'Total loss': 0.8083489315850394}
2022-11-18 00:54:52,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:52,825 INFO:     Epoch: 95
2022-11-18 00:54:53,608 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8096467947418039, 'Total loss': 0.8096467947418039} | train loss {'Reaction outcome loss': 0.8037410193560075, 'Total loss': 0.8037410193560075}
2022-11-18 00:54:53,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:53,609 INFO:     Epoch: 96
2022-11-18 00:54:54,407 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8064643496816809, 'Total loss': 0.8064643496816809} | train loss {'Reaction outcome loss': 0.8037129174689858, 'Total loss': 0.8037129174689858}
2022-11-18 00:54:54,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:54,407 INFO:     Epoch: 97
2022-11-18 00:54:55,193 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7993578233502128, 'Total loss': 0.7993578233502128} | train loss {'Reaction outcome loss': 0.8063756526732931, 'Total loss': 0.8063756526732931}
2022-11-18 00:54:55,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:55,193 INFO:     Epoch: 98
2022-11-18 00:54:55,979 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7924151664430444, 'Total loss': 0.7924151664430444} | train loss {'Reaction outcome loss': 0.8081688170530358, 'Total loss': 0.8081688170530358}
2022-11-18 00:54:55,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:55,979 INFO:     Epoch: 99
2022-11-18 00:54:56,783 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8111167292703282, 'Total loss': 0.8111167292703282} | train loss {'Reaction outcome loss': 0.7999693773230728, 'Total loss': 0.7999693773230728}
2022-11-18 00:54:56,783 INFO:     Best model found after epoch 48 of 100.
2022-11-18 00:54:56,783 INFO:   Done with stage: TRAINING
2022-11-18 00:54:56,783 INFO:   Starting stage: EVALUATION
2022-11-18 00:54:56,912 INFO:   Done with stage: EVALUATION
2022-11-18 00:54:56,912 INFO:   Leaving out SEQ value Fold_1
2022-11-18 00:54:56,925 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 00:54:56,925 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:54:57,590 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:54:57,590 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:54:57,664 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:54:57,665 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:54:57,665 INFO:     No hyperparam tuning for this model
2022-11-18 00:54:57,665 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:54:57,665 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:54:57,666 INFO:     None feature selector for col prot
2022-11-18 00:54:57,666 INFO:     None feature selector for col prot
2022-11-18 00:54:57,666 INFO:     None feature selector for col prot
2022-11-18 00:54:57,666 INFO:     None feature selector for col chem
2022-11-18 00:54:57,667 INFO:     None feature selector for col chem
2022-11-18 00:54:57,667 INFO:     None feature selector for col chem
2022-11-18 00:54:57,667 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:54:57,667 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:54:57,668 INFO:     Number of params in model 168571
2022-11-18 00:54:57,672 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:54:57,672 INFO:   Starting stage: TRAINING
2022-11-18 00:54:57,729 INFO:     Val loss before train {'Reaction outcome loss': 1.004402497480082, 'Total loss': 1.004402497480082}
2022-11-18 00:54:57,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:57,729 INFO:     Epoch: 0
2022-11-18 00:54:58,551 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8452676811883616, 'Total loss': 0.8452676811883616} | train loss {'Reaction outcome loss': 0.8778790095706045, 'Total loss': 0.8778790095706045}
2022-11-18 00:54:58,551 INFO:     Found new best model at epoch 0
2022-11-18 00:54:58,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:58,552 INFO:     Epoch: 1
2022-11-18 00:54:59,335 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8179618591486022, 'Total loss': 0.8179618591486022} | train loss {'Reaction outcome loss': 0.8500230969715511, 'Total loss': 0.8500230969715511}
2022-11-18 00:54:59,336 INFO:     Found new best model at epoch 1
2022-11-18 00:54:59,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:54:59,336 INFO:     Epoch: 2
2022-11-18 00:55:00,121 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8311806335005649, 'Total loss': 0.8311806335005649} | train loss {'Reaction outcome loss': 0.8493973441084717, 'Total loss': 0.8493973441084717}
2022-11-18 00:55:00,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:00,121 INFO:     Epoch: 3
2022-11-18 00:55:00,907 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8570786742276923, 'Total loss': 0.8570786742276923} | train loss {'Reaction outcome loss': 0.845647227739601, 'Total loss': 0.845647227739601}
2022-11-18 00:55:00,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:00,907 INFO:     Epoch: 4
2022-11-18 00:55:01,677 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8177104273507761, 'Total loss': 0.8177104273507761} | train loss {'Reaction outcome loss': 0.8378186232023278, 'Total loss': 0.8378186232023278}
2022-11-18 00:55:01,677 INFO:     Found new best model at epoch 4
2022-11-18 00:55:01,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:01,678 INFO:     Epoch: 5
2022-11-18 00:55:02,450 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.863263210584951, 'Total loss': 0.863263210584951} | train loss {'Reaction outcome loss': 0.8295533665659006, 'Total loss': 0.8295533665659006}
2022-11-18 00:55:02,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:02,451 INFO:     Epoch: 6
2022-11-18 00:55:03,231 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8259543000265609, 'Total loss': 0.8259543000265609} | train loss {'Reaction outcome loss': 0.8335748335706844, 'Total loss': 0.8335748335706844}
2022-11-18 00:55:03,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:03,231 INFO:     Epoch: 7
2022-11-18 00:55:04,022 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8099422434041667, 'Total loss': 0.8099422434041667} | train loss {'Reaction outcome loss': 0.8360985279573825, 'Total loss': 0.8360985279573825}
2022-11-18 00:55:04,023 INFO:     Found new best model at epoch 7
2022-11-18 00:55:04,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:04,024 INFO:     Epoch: 8
2022-11-18 00:55:04,789 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8184456548025442, 'Total loss': 0.8184456548025442} | train loss {'Reaction outcome loss': 0.8323521632471202, 'Total loss': 0.8323521632471202}
2022-11-18 00:55:04,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:04,789 INFO:     Epoch: 9
2022-11-18 00:55:05,566 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8342928609182668, 'Total loss': 0.8342928609182668} | train loss {'Reaction outcome loss': 0.830484730103379, 'Total loss': 0.830484730103379}
2022-11-18 00:55:05,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:05,566 INFO:     Epoch: 10
2022-11-18 00:55:06,382 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8204121894614641, 'Total loss': 0.8204121894614641} | train loss {'Reaction outcome loss': 0.8273681293053882, 'Total loss': 0.8273681293053882}
2022-11-18 00:55:06,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:06,382 INFO:     Epoch: 11
2022-11-18 00:55:07,187 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8357177543085675, 'Total loss': 0.8357177543085675} | train loss {'Reaction outcome loss': 0.8256820163118496, 'Total loss': 0.8256820163118496}
2022-11-18 00:55:07,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:07,188 INFO:     Epoch: 12
2022-11-18 00:55:07,977 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8036626674408136, 'Total loss': 0.8036626674408136} | train loss {'Reaction outcome loss': 0.8230884256676881, 'Total loss': 0.8230884256676881}
2022-11-18 00:55:07,977 INFO:     Found new best model at epoch 12
2022-11-18 00:55:07,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:07,978 INFO:     Epoch: 13
2022-11-18 00:55:08,784 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8388162054294763, 'Total loss': 0.8388162054294763} | train loss {'Reaction outcome loss': 0.822269943393307, 'Total loss': 0.822269943393307}
2022-11-18 00:55:08,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:08,785 INFO:     Epoch: 14
2022-11-18 00:55:09,558 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8050315768219704, 'Total loss': 0.8050315768219704} | train loss {'Reaction outcome loss': 0.8256147750365881, 'Total loss': 0.8256147750365881}
2022-11-18 00:55:09,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:09,558 INFO:     Epoch: 15
2022-11-18 00:55:10,373 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7971661118573921, 'Total loss': 0.7971661118573921} | train loss {'Reaction outcome loss': 0.8203554473541401, 'Total loss': 0.8203554473541401}
2022-11-18 00:55:10,373 INFO:     Found new best model at epoch 15
2022-11-18 00:55:10,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:10,374 INFO:     Epoch: 16
2022-11-18 00:55:11,204 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.804692147776138, 'Total loss': 0.804692147776138} | train loss {'Reaction outcome loss': 0.8138810115341296, 'Total loss': 0.8138810115341296}
2022-11-18 00:55:11,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:11,204 INFO:     Epoch: 17
2022-11-18 00:55:11,980 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8360735711663269, 'Total loss': 0.8360735711663269} | train loss {'Reaction outcome loss': 0.8208970720630614, 'Total loss': 0.8208970720630614}
2022-11-18 00:55:11,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:11,980 INFO:     Epoch: 18
2022-11-18 00:55:12,763 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8098551852758541, 'Total loss': 0.8098551852758541} | train loss {'Reaction outcome loss': 0.8193535537386136, 'Total loss': 0.8193535537386136}
2022-11-18 00:55:12,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:12,764 INFO:     Epoch: 19
2022-11-18 00:55:13,588 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8016046049983002, 'Total loss': 0.8016046049983002} | train loss {'Reaction outcome loss': 0.8201713526445161, 'Total loss': 0.8201713526445161}
2022-11-18 00:55:13,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:13,589 INFO:     Epoch: 20
2022-11-18 00:55:14,392 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8053535368553427, 'Total loss': 0.8053535368553427} | train loss {'Reaction outcome loss': 0.8209846780133345, 'Total loss': 0.8209846780133345}
2022-11-18 00:55:14,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:14,393 INFO:     Epoch: 21
2022-11-18 00:55:15,172 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8201630198678305, 'Total loss': 0.8201630198678305} | train loss {'Reaction outcome loss': 0.8160866248754808, 'Total loss': 0.8160866248754808}
2022-11-18 00:55:15,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:15,172 INFO:     Epoch: 22
2022-11-18 00:55:15,959 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8016958222832791, 'Total loss': 0.8016958222832791} | train loss {'Reaction outcome loss': 0.8170346645906629, 'Total loss': 0.8170346645906629}
2022-11-18 00:55:15,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:15,960 INFO:     Epoch: 23
2022-11-18 00:55:16,772 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.823467846526656, 'Total loss': 0.823467846526656} | train loss {'Reaction outcome loss': 0.8199925961072553, 'Total loss': 0.8199925961072553}
2022-11-18 00:55:16,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:16,773 INFO:     Epoch: 24
2022-11-18 00:55:17,604 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8076470092285511, 'Total loss': 0.8076470092285511} | train loss {'Reaction outcome loss': 0.8212388013125447, 'Total loss': 0.8212388013125447}
2022-11-18 00:55:17,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:17,605 INFO:     Epoch: 25
2022-11-18 00:55:18,423 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8055671723776086, 'Total loss': 0.8055671723776086} | train loss {'Reaction outcome loss': 0.8216915630999907, 'Total loss': 0.8216915630999907}
2022-11-18 00:55:18,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:18,423 INFO:     Epoch: 26
2022-11-18 00:55:19,227 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8090310803679532, 'Total loss': 0.8090310803679532} | train loss {'Reaction outcome loss': 0.8142424646473716, 'Total loss': 0.8142424646473716}
2022-11-18 00:55:19,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:19,227 INFO:     Epoch: 27
2022-11-18 00:55:20,005 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8164848123872003, 'Total loss': 0.8164848123872003} | train loss {'Reaction outcome loss': 0.8152656155358616, 'Total loss': 0.8152656155358616}
2022-11-18 00:55:20,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:20,005 INFO:     Epoch: 28
2022-11-18 00:55:20,810 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7994546980358833, 'Total loss': 0.7994546980358833} | train loss {'Reaction outcome loss': 0.8161546143975278, 'Total loss': 0.8161546143975278}
2022-11-18 00:55:20,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:20,810 INFO:     Epoch: 29
2022-11-18 00:55:21,621 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8086410830187243, 'Total loss': 0.8086410830187243} | train loss {'Reaction outcome loss': 0.8153646015581281, 'Total loss': 0.8153646015581281}
2022-11-18 00:55:21,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:21,621 INFO:     Epoch: 30
2022-11-18 00:55:22,400 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8234852004882901, 'Total loss': 0.8234852004882901} | train loss {'Reaction outcome loss': 0.8156410919295417, 'Total loss': 0.8156410919295417}
2022-11-18 00:55:22,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:22,401 INFO:     Epoch: 31
2022-11-18 00:55:23,201 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7936470279859942, 'Total loss': 0.7936470279859942} | train loss {'Reaction outcome loss': 0.8131623627472316, 'Total loss': 0.8131623627472316}
2022-11-18 00:55:23,202 INFO:     Found new best model at epoch 31
2022-11-18 00:55:23,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:23,202 INFO:     Epoch: 32
2022-11-18 00:55:23,988 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8083612724792125, 'Total loss': 0.8083612724792125} | train loss {'Reaction outcome loss': 0.8169659132084238, 'Total loss': 0.8169659132084238}
2022-11-18 00:55:23,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:23,988 INFO:     Epoch: 33
2022-11-18 00:55:24,764 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7877831375876139, 'Total loss': 0.7877831375876139} | train loss {'Reaction outcome loss': 0.8124294701672385, 'Total loss': 0.8124294701672385}
2022-11-18 00:55:24,764 INFO:     Found new best model at epoch 33
2022-11-18 00:55:24,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:24,765 INFO:     Epoch: 34
2022-11-18 00:55:25,556 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.798334285270336, 'Total loss': 0.798334285270336} | train loss {'Reaction outcome loss': 0.8166575355784883, 'Total loss': 0.8166575355784883}
2022-11-18 00:55:25,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:25,556 INFO:     Epoch: 35
2022-11-18 00:55:26,330 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7966349083323812, 'Total loss': 0.7966349083323812} | train loss {'Reaction outcome loss': 0.8155278064341211, 'Total loss': 0.8155278064341211}
2022-11-18 00:55:26,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:26,330 INFO:     Epoch: 36
2022-11-18 00:55:27,122 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8016784094100775, 'Total loss': 0.8016784094100775} | train loss {'Reaction outcome loss': 0.8115620427906759, 'Total loss': 0.8115620427906759}
2022-11-18 00:55:27,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:27,122 INFO:     Epoch: 37
2022-11-18 00:55:27,926 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8251204192638397, 'Total loss': 0.8251204192638397} | train loss {'Reaction outcome loss': 0.8174161730725088, 'Total loss': 0.8174161730725088}
2022-11-18 00:55:27,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:27,926 INFO:     Epoch: 38
2022-11-18 00:55:28,723 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7998396276041518, 'Total loss': 0.7998396276041518} | train loss {'Reaction outcome loss': 0.8226869764887257, 'Total loss': 0.8226869764887257}
2022-11-18 00:55:28,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:28,723 INFO:     Epoch: 39
2022-11-18 00:55:29,515 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7920717583146206, 'Total loss': 0.7920717583146206} | train loss {'Reaction outcome loss': 0.8155197717034768, 'Total loss': 0.8155197717034768}
2022-11-18 00:55:29,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:29,516 INFO:     Epoch: 40
2022-11-18 00:55:30,350 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7951277660769086, 'Total loss': 0.7951277660769086} | train loss {'Reaction outcome loss': 0.8199099124459083, 'Total loss': 0.8199099124459083}
2022-11-18 00:55:30,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:30,350 INFO:     Epoch: 41
2022-11-18 00:55:31,103 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7908300299977147, 'Total loss': 0.7908300299977147} | train loss {'Reaction outcome loss': 0.8183759118549128, 'Total loss': 0.8183759118549128}
2022-11-18 00:55:31,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:31,103 INFO:     Epoch: 42
2022-11-18 00:55:31,867 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7960316954657088, 'Total loss': 0.7960316954657088} | train loss {'Reaction outcome loss': 0.8114123311920912, 'Total loss': 0.8114123311920912}
2022-11-18 00:55:31,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:31,867 INFO:     Epoch: 43
2022-11-18 00:55:32,630 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8074028304843015, 'Total loss': 0.8074028304843015} | train loss {'Reaction outcome loss': 0.8080676009134992, 'Total loss': 0.8080676009134992}
2022-11-18 00:55:32,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:32,631 INFO:     Epoch: 44
2022-11-18 00:55:33,389 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8136734255524569, 'Total loss': 0.8136734255524569} | train loss {'Reaction outcome loss': 0.8135350889875075, 'Total loss': 0.8135350889875075}
2022-11-18 00:55:33,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:33,390 INFO:     Epoch: 45
2022-11-18 00:55:34,197 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8030505457589793, 'Total loss': 0.8030505457589793} | train loss {'Reaction outcome loss': 0.819069380868119, 'Total loss': 0.819069380868119}
2022-11-18 00:55:34,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:34,197 INFO:     Epoch: 46
2022-11-18 00:55:34,980 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7944726306338643, 'Total loss': 0.7944726306338643} | train loss {'Reaction outcome loss': 0.8201163175665303, 'Total loss': 0.8201163175665303}
2022-11-18 00:55:34,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:34,981 INFO:     Epoch: 47
2022-11-18 00:55:35,757 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8045347111169682, 'Total loss': 0.8045347111169682} | train loss {'Reaction outcome loss': 0.8116815276597262, 'Total loss': 0.8116815276597262}
2022-11-18 00:55:35,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:35,758 INFO:     Epoch: 48
2022-11-18 00:55:36,529 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.811165742402853, 'Total loss': 0.811165742402853} | train loss {'Reaction outcome loss': 0.8172245138466604, 'Total loss': 0.8172245138466604}
2022-11-18 00:55:36,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:36,530 INFO:     Epoch: 49
2022-11-18 00:55:37,302 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.792013265365778, 'Total loss': 0.792013265365778} | train loss {'Reaction outcome loss': 0.8168738626648859, 'Total loss': 0.8168738626648859}
2022-11-18 00:55:37,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:37,303 INFO:     Epoch: 50
2022-11-18 00:55:38,064 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8133667222289152, 'Total loss': 0.8133667222289152} | train loss {'Reaction outcome loss': 0.8117060322820404, 'Total loss': 0.8117060322820404}
2022-11-18 00:55:38,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:38,064 INFO:     Epoch: 51
2022-11-18 00:55:38,843 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8074561343636624, 'Total loss': 0.8074561343636624} | train loss {'Reaction outcome loss': 0.8202706612186668, 'Total loss': 0.8202706612186668}
2022-11-18 00:55:38,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:38,844 INFO:     Epoch: 52
2022-11-18 00:55:39,612 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.806620601997819, 'Total loss': 0.806620601997819} | train loss {'Reaction outcome loss': 0.8138508873957174, 'Total loss': 0.8138508873957174}
2022-11-18 00:55:39,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:39,612 INFO:     Epoch: 53
2022-11-18 00:55:40,372 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7929172079230464, 'Total loss': 0.7929172079230464} | train loss {'Reaction outcome loss': 0.8142132315125485, 'Total loss': 0.8142132315125485}
2022-11-18 00:55:40,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:40,372 INFO:     Epoch: 54
2022-11-18 00:55:41,149 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7905491964761601, 'Total loss': 0.7905491964761601} | train loss {'Reaction outcome loss': 0.8172899306801612, 'Total loss': 0.8172899306801612}
2022-11-18 00:55:41,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:41,149 INFO:     Epoch: 55
2022-11-18 00:55:41,909 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8105861558470615, 'Total loss': 0.8105861558470615} | train loss {'Reaction outcome loss': 0.8152864530008026, 'Total loss': 0.8152864530008026}
2022-11-18 00:55:41,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:41,910 INFO:     Epoch: 56
2022-11-18 00:55:42,702 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8093192050623339, 'Total loss': 0.8093192050623339} | train loss {'Reaction outcome loss': 0.8125021305594424, 'Total loss': 0.8125021305594424}
2022-11-18 00:55:42,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:42,702 INFO:     Epoch: 57
2022-11-18 00:55:43,446 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.812363747940507, 'Total loss': 0.812363747940507} | train loss {'Reaction outcome loss': 0.8128945226531951, 'Total loss': 0.8128945226531951}
2022-11-18 00:55:43,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:43,446 INFO:     Epoch: 58
2022-11-18 00:55:44,223 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.805644107419391, 'Total loss': 0.805644107419391} | train loss {'Reaction outcome loss': 0.811687298149729, 'Total loss': 0.811687298149729}
2022-11-18 00:55:44,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:44,224 INFO:     Epoch: 59
2022-11-18 00:55:44,975 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8205571271652399, 'Total loss': 0.8205571271652399} | train loss {'Reaction outcome loss': 0.8196137666456984, 'Total loss': 0.8196137666456984}
2022-11-18 00:55:44,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:44,976 INFO:     Epoch: 60
2022-11-18 00:55:45,751 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8069440750188606, 'Total loss': 0.8069440750188606} | train loss {'Reaction outcome loss': 0.817189852764577, 'Total loss': 0.817189852764577}
2022-11-18 00:55:45,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:45,752 INFO:     Epoch: 61
2022-11-18 00:55:46,523 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7986096441745758, 'Total loss': 0.7986096441745758} | train loss {'Reaction outcome loss': 0.8173812077123932, 'Total loss': 0.8173812077123932}
2022-11-18 00:55:46,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:46,523 INFO:     Epoch: 62
2022-11-18 00:55:47,292 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8023828219535739, 'Total loss': 0.8023828219535739} | train loss {'Reaction outcome loss': 0.8157277519320264, 'Total loss': 0.8157277519320264}
2022-11-18 00:55:47,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:47,292 INFO:     Epoch: 63
2022-11-18 00:55:48,061 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.801288766916408, 'Total loss': 0.801288766916408} | train loss {'Reaction outcome loss': 0.8111204260906565, 'Total loss': 0.8111204260906565}
2022-11-18 00:55:48,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:48,063 INFO:     Epoch: 64
2022-11-18 00:55:48,866 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7941297902617344, 'Total loss': 0.7941297902617344} | train loss {'Reaction outcome loss': 0.8146693663587296, 'Total loss': 0.8146693663587296}
2022-11-18 00:55:48,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:48,866 INFO:     Epoch: 65
2022-11-18 00:55:49,623 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.795867035555285, 'Total loss': 0.795867035555285} | train loss {'Reaction outcome loss': 0.8142449236455768, 'Total loss': 0.8142449236455768}
2022-11-18 00:55:49,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:49,624 INFO:     Epoch: 66
2022-11-18 00:55:50,392 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8065928733626078, 'Total loss': 0.8065928733626078} | train loss {'Reaction outcome loss': 0.8140512140690054, 'Total loss': 0.8140512140690054}
2022-11-18 00:55:50,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:50,392 INFO:     Epoch: 67
2022-11-18 00:55:51,155 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8106829614140266, 'Total loss': 0.8106829614140266} | train loss {'Reaction outcome loss': 0.8140499688715601, 'Total loss': 0.8140499688715601}
2022-11-18 00:55:51,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:51,155 INFO:     Epoch: 68
2022-11-18 00:55:51,956 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8162773251533508, 'Total loss': 0.8162773251533508} | train loss {'Reaction outcome loss': 0.8162657468897816, 'Total loss': 0.8162657468897816}
2022-11-18 00:55:51,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:51,956 INFO:     Epoch: 69
2022-11-18 00:55:52,731 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.805712831574817, 'Total loss': 0.805712831574817} | train loss {'Reaction outcome loss': 0.8148465052308369, 'Total loss': 0.8148465052308369}
2022-11-18 00:55:52,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:52,732 INFO:     Epoch: 70
2022-11-18 00:55:53,510 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7978064979231635, 'Total loss': 0.7978064979231635} | train loss {'Reaction outcome loss': 0.8127922470922824, 'Total loss': 0.8127922470922824}
2022-11-18 00:55:53,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:53,510 INFO:     Epoch: 71
2022-11-18 00:55:54,282 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8031240077905877, 'Total loss': 0.8031240077905877} | train loss {'Reaction outcome loss': 0.8146579425030775, 'Total loss': 0.8146579425030775}
2022-11-18 00:55:54,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:54,283 INFO:     Epoch: 72
2022-11-18 00:55:55,046 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.809113721514857, 'Total loss': 0.809113721514857} | train loss {'Reaction outcome loss': 0.817987975760252, 'Total loss': 0.817987975760252}
2022-11-18 00:55:55,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:55,046 INFO:     Epoch: 73
2022-11-18 00:55:55,802 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8172860505969025, 'Total loss': 0.8172860505969025} | train loss {'Reaction outcome loss': 0.8138925937222846, 'Total loss': 0.8138925937222846}
2022-11-18 00:55:55,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:55,803 INFO:     Epoch: 74
2022-11-18 00:55:56,568 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8275481684263363, 'Total loss': 0.8275481684263363} | train loss {'Reaction outcome loss': 0.818274086640205, 'Total loss': 0.818274086640205}
2022-11-18 00:55:56,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:56,569 INFO:     Epoch: 75
2022-11-18 00:55:57,344 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7940080942109574, 'Total loss': 0.7940080942109574} | train loss {'Reaction outcome loss': 0.8104396776407344, 'Total loss': 0.8104396776407344}
2022-11-18 00:55:57,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:57,344 INFO:     Epoch: 76
2022-11-18 00:55:58,145 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8075184794359429, 'Total loss': 0.8075184794359429} | train loss {'Reaction outcome loss': 0.8132514135582457, 'Total loss': 0.8132514135582457}
2022-11-18 00:55:58,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:58,145 INFO:     Epoch: 77
2022-11-18 00:55:58,906 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.820722758769989, 'Total loss': 0.820722758769989} | train loss {'Reaction outcome loss': 0.8176865810720028, 'Total loss': 0.8176865810720028}
2022-11-18 00:55:58,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:58,907 INFO:     Epoch: 78
2022-11-18 00:55:59,686 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8136598350003709, 'Total loss': 0.8136598350003709} | train loss {'Reaction outcome loss': 0.8152021044566308, 'Total loss': 0.8152021044566308}
2022-11-18 00:55:59,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:55:59,686 INFO:     Epoch: 79
2022-11-18 00:56:00,464 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.801592243965282, 'Total loss': 0.801592243965282} | train loss {'Reaction outcome loss': 0.8114702604680395, 'Total loss': 0.8114702604680395}
2022-11-18 00:56:00,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:00,464 INFO:     Epoch: 80
2022-11-18 00:56:01,229 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7991729621277299, 'Total loss': 0.7991729621277299} | train loss {'Reaction outcome loss': 0.8132410384254691, 'Total loss': 0.8132410384254691}
2022-11-18 00:56:01,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:01,229 INFO:     Epoch: 81
2022-11-18 00:56:01,995 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8184115020341651, 'Total loss': 0.8184115020341651} | train loss {'Reaction outcome loss': 0.8154065833415514, 'Total loss': 0.8154065833415514}
2022-11-18 00:56:01,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:01,995 INFO:     Epoch: 82
2022-11-18 00:56:02,777 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8101065082605495, 'Total loss': 0.8101065082605495} | train loss {'Reaction outcome loss': 0.8152005999912451, 'Total loss': 0.8152005999912451}
2022-11-18 00:56:02,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:02,777 INFO:     Epoch: 83
2022-11-18 00:56:03,542 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8000934110131375, 'Total loss': 0.8000934110131375} | train loss {'Reaction outcome loss': 0.8153669480924253, 'Total loss': 0.8153669480924253}
2022-11-18 00:56:03,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:03,542 INFO:     Epoch: 84
2022-11-18 00:56:04,327 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8218968080919843, 'Total loss': 0.8218968080919843} | train loss {'Reaction outcome loss': 0.8140304525202684, 'Total loss': 0.8140304525202684}
2022-11-18 00:56:04,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:04,327 INFO:     Epoch: 85
2022-11-18 00:56:05,114 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7985006404477496, 'Total loss': 0.7985006404477496} | train loss {'Reaction outcome loss': 0.8127968421688786, 'Total loss': 0.8127968421688786}
2022-11-18 00:56:05,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:05,115 INFO:     Epoch: 86
2022-11-18 00:56:05,889 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7881946626097657, 'Total loss': 0.7881946626097657} | train loss {'Reaction outcome loss': 0.8129084606965383, 'Total loss': 0.8129084606965383}
2022-11-18 00:56:05,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:05,890 INFO:     Epoch: 87
2022-11-18 00:56:06,675 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7937904513159464, 'Total loss': 0.7937904513159464} | train loss {'Reaction outcome loss': 0.8138459744276824, 'Total loss': 0.8138459744276824}
2022-11-18 00:56:06,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:06,676 INFO:     Epoch: 88
2022-11-18 00:56:07,438 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8056565959786259, 'Total loss': 0.8056565959786259} | train loss {'Reaction outcome loss': 0.8153381202937153, 'Total loss': 0.8153381202937153}
2022-11-18 00:56:07,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:07,439 INFO:     Epoch: 89
2022-11-18 00:56:08,209 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7994450566380523, 'Total loss': 0.7994450566380523} | train loss {'Reaction outcome loss': 0.8217446374795074, 'Total loss': 0.8217446374795074}
2022-11-18 00:56:08,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:08,209 INFO:     Epoch: 90
2022-11-18 00:56:08,959 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8033775520879168, 'Total loss': 0.8033775520879168} | train loss {'Reaction outcome loss': 0.8152731907220534, 'Total loss': 0.8152731907220534}
2022-11-18 00:56:08,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:08,959 INFO:     Epoch: 91
2022-11-18 00:56:09,720 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8136093540247097, 'Total loss': 0.8136093540247097} | train loss {'Reaction outcome loss': 0.8131682082949352, 'Total loss': 0.8131682082949352}
2022-11-18 00:56:09,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:09,720 INFO:     Epoch: 92
2022-11-18 00:56:10,508 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7888037292070167, 'Total loss': 0.7888037292070167} | train loss {'Reaction outcome loss': 0.8127987318568759, 'Total loss': 0.8127987318568759}
2022-11-18 00:56:10,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:10,508 INFO:     Epoch: 93
2022-11-18 00:56:11,294 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7998840587083683, 'Total loss': 0.7998840587083683} | train loss {'Reaction outcome loss': 0.8175570650846379, 'Total loss': 0.8175570650846379}
2022-11-18 00:56:11,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:11,294 INFO:     Epoch: 94
2022-11-18 00:56:12,075 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8020426263642866, 'Total loss': 0.8020426263642866} | train loss {'Reaction outcome loss': 0.812066295387323, 'Total loss': 0.812066295387323}
2022-11-18 00:56:12,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:12,075 INFO:     Epoch: 95
2022-11-18 00:56:12,836 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8125466025152872, 'Total loss': 0.8125466025152872} | train loss {'Reaction outcome loss': 0.8109311224747097, 'Total loss': 0.8109311224747097}
2022-11-18 00:56:12,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:12,836 INFO:     Epoch: 96
2022-11-18 00:56:13,626 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8393588620562886, 'Total loss': 0.8393588620562886} | train loss {'Reaction outcome loss': 0.8167164566094983, 'Total loss': 0.8167164566094983}
2022-11-18 00:56:13,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:13,627 INFO:     Epoch: 97
2022-11-18 00:56:14,364 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8173385990220446, 'Total loss': 0.8173385990220446} | train loss {'Reaction outcome loss': 0.8087200347042869, 'Total loss': 0.8087200347042869}
2022-11-18 00:56:14,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:14,364 INFO:     Epoch: 98
2022-11-18 00:56:15,133 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8191185773805131, 'Total loss': 0.8191185773805131} | train loss {'Reaction outcome loss': 0.8126350806819068, 'Total loss': 0.8126350806819068}
2022-11-18 00:56:15,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:15,133 INFO:     Epoch: 99
2022-11-18 00:56:15,909 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8157487830450368, 'Total loss': 0.8157487830450368} | train loss {'Reaction outcome loss': 0.8207485440336628, 'Total loss': 0.8207485440336628}
2022-11-18 00:56:15,909 INFO:     Best model found after epoch 34 of 100.
2022-11-18 00:56:15,909 INFO:   Done with stage: TRAINING
2022-11-18 00:56:15,909 INFO:   Starting stage: EVALUATION
2022-11-18 00:56:16,049 INFO:   Done with stage: EVALUATION
2022-11-18 00:56:16,050 INFO:   Leaving out SEQ value Fold_2
2022-11-18 00:56:16,063 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 00:56:16,063 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:56:16,724 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:56:16,725 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:56:16,795 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:56:16,795 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:56:16,795 INFO:     No hyperparam tuning for this model
2022-11-18 00:56:16,795 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:56:16,796 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:56:16,796 INFO:     None feature selector for col prot
2022-11-18 00:56:16,796 INFO:     None feature selector for col prot
2022-11-18 00:56:16,797 INFO:     None feature selector for col prot
2022-11-18 00:56:16,797 INFO:     None feature selector for col chem
2022-11-18 00:56:16,797 INFO:     None feature selector for col chem
2022-11-18 00:56:16,797 INFO:     None feature selector for col chem
2022-11-18 00:56:16,797 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:56:16,798 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:56:16,799 INFO:     Number of params in model 168571
2022-11-18 00:56:16,802 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:56:16,802 INFO:   Starting stage: TRAINING
2022-11-18 00:56:16,860 INFO:     Val loss before train {'Reaction outcome loss': 0.9419180263172496, 'Total loss': 0.9419180263172496}
2022-11-18 00:56:16,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:16,860 INFO:     Epoch: 0
2022-11-18 00:56:17,642 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8097196180712093, 'Total loss': 0.8097196180712093} | train loss {'Reaction outcome loss': 0.8783195232331511, 'Total loss': 0.8783195232331511}
2022-11-18 00:56:17,642 INFO:     Found new best model at epoch 0
2022-11-18 00:56:17,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:17,643 INFO:     Epoch: 1
2022-11-18 00:56:18,413 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8327422670342706, 'Total loss': 0.8327422670342706} | train loss {'Reaction outcome loss': 0.8566927468245812, 'Total loss': 0.8566927468245812}
2022-11-18 00:56:18,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:18,413 INFO:     Epoch: 2
2022-11-18 00:56:19,177 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8013488108461554, 'Total loss': 0.8013488108461554} | train loss {'Reaction outcome loss': 0.8567268568494542, 'Total loss': 0.8567268568494542}
2022-11-18 00:56:19,178 INFO:     Found new best model at epoch 2
2022-11-18 00:56:19,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:19,179 INFO:     Epoch: 3
2022-11-18 00:56:19,970 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8262497579509561, 'Total loss': 0.8262497579509561} | train loss {'Reaction outcome loss': 0.8487142356421783, 'Total loss': 0.8487142356421783}
2022-11-18 00:56:19,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:19,971 INFO:     Epoch: 4
2022-11-18 00:56:20,739 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8566387939182195, 'Total loss': 0.8566387939182195} | train loss {'Reaction outcome loss': 0.8386346616363718, 'Total loss': 0.8386346616363718}
2022-11-18 00:56:20,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:20,740 INFO:     Epoch: 5
2022-11-18 00:56:21,526 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.78506634790789, 'Total loss': 0.78506634790789} | train loss {'Reaction outcome loss': 0.8384300136131796, 'Total loss': 0.8384300136131796}
2022-11-18 00:56:21,527 INFO:     Found new best model at epoch 5
2022-11-18 00:56:21,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:21,528 INFO:     Epoch: 6
2022-11-18 00:56:22,294 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.799916612831029, 'Total loss': 0.799916612831029} | train loss {'Reaction outcome loss': 0.8375311000234926, 'Total loss': 0.8375311000234926}
2022-11-18 00:56:22,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:22,294 INFO:     Epoch: 7
2022-11-18 00:56:23,067 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7879039658741518, 'Total loss': 0.7879039658741518} | train loss {'Reaction outcome loss': 0.8293278565411626, 'Total loss': 0.8293278565411626}
2022-11-18 00:56:23,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:23,068 INFO:     Epoch: 8
2022-11-18 00:56:23,864 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7791046513752504, 'Total loss': 0.7791046513752504} | train loss {'Reaction outcome loss': 0.8335431210907848, 'Total loss': 0.8335431210907848}
2022-11-18 00:56:23,864 INFO:     Found new best model at epoch 8
2022-11-18 00:56:23,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:23,865 INFO:     Epoch: 9
2022-11-18 00:56:24,631 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7993727637962862, 'Total loss': 0.7993727637962862} | train loss {'Reaction outcome loss': 0.8280214085752665, 'Total loss': 0.8280214085752665}
2022-11-18 00:56:24,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:24,631 INFO:     Epoch: 10
2022-11-18 00:56:25,394 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7930717129598964, 'Total loss': 0.7930717129598964} | train loss {'Reaction outcome loss': 0.8309695526414554, 'Total loss': 0.8309695526414554}
2022-11-18 00:56:25,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:25,395 INFO:     Epoch: 11
2022-11-18 00:56:26,190 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7786369669166479, 'Total loss': 0.7786369669166479} | train loss {'Reaction outcome loss': 0.8322126579429456, 'Total loss': 0.8322126579429456}
2022-11-18 00:56:26,190 INFO:     Found new best model at epoch 11
2022-11-18 00:56:26,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:26,191 INFO:     Epoch: 12
2022-11-18 00:56:27,014 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.782416158779101, 'Total loss': 0.782416158779101} | train loss {'Reaction outcome loss': 0.8272600833944946, 'Total loss': 0.8272600833944946}
2022-11-18 00:56:27,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:27,014 INFO:     Epoch: 13
2022-11-18 00:56:27,794 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7793668095361103, 'Total loss': 0.7793668095361103} | train loss {'Reaction outcome loss': 0.8211578638085469, 'Total loss': 0.8211578638085469}
2022-11-18 00:56:27,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:27,795 INFO:     Epoch: 14
2022-11-18 00:56:28,665 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7882412733002142, 'Total loss': 0.7882412733002142} | train loss {'Reaction outcome loss': 0.8253625438280916, 'Total loss': 0.8253625438280916}
2022-11-18 00:56:28,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:28,665 INFO:     Epoch: 15
2022-11-18 00:56:29,474 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7734688561071049, 'Total loss': 0.7734688561071049} | train loss {'Reaction outcome loss': 0.8260599944423809, 'Total loss': 0.8260599944423809}
2022-11-18 00:56:29,474 INFO:     Found new best model at epoch 15
2022-11-18 00:56:29,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:29,475 INFO:     Epoch: 16
2022-11-18 00:56:30,299 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7887042347680439, 'Total loss': 0.7887042347680439} | train loss {'Reaction outcome loss': 0.8258419051796559, 'Total loss': 0.8258419051796559}
2022-11-18 00:56:30,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:30,299 INFO:     Epoch: 17
2022-11-18 00:56:31,102 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7853414314714345, 'Total loss': 0.7853414314714345} | train loss {'Reaction outcome loss': 0.8209536788072663, 'Total loss': 0.8209536788072663}
2022-11-18 00:56:31,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:31,102 INFO:     Epoch: 18
2022-11-18 00:56:31,911 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.77479373189536, 'Total loss': 0.77479373189536} | train loss {'Reaction outcome loss': 0.8259194340059149, 'Total loss': 0.8259194340059149}
2022-11-18 00:56:31,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:31,911 INFO:     Epoch: 19
2022-11-18 00:56:32,714 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7821361036463217, 'Total loss': 0.7821361036463217} | train loss {'Reaction outcome loss': 0.8228103458157435, 'Total loss': 0.8228103458157435}
2022-11-18 00:56:32,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:32,714 INFO:     Epoch: 20
2022-11-18 00:56:33,525 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7732767388224602, 'Total loss': 0.7732767388224602} | train loss {'Reaction outcome loss': 0.8231095216776195, 'Total loss': 0.8231095216776195}
2022-11-18 00:56:33,525 INFO:     Found new best model at epoch 20
2022-11-18 00:56:33,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:33,526 INFO:     Epoch: 21
2022-11-18 00:56:34,317 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7930656895041466, 'Total loss': 0.7930656895041466} | train loss {'Reaction outcome loss': 0.8307138313407357, 'Total loss': 0.8307138313407357}
2022-11-18 00:56:34,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:34,317 INFO:     Epoch: 22
2022-11-18 00:56:35,157 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7763576019893993, 'Total loss': 0.7763576019893993} | train loss {'Reaction outcome loss': 0.8354460726141447, 'Total loss': 0.8354460726141447}
2022-11-18 00:56:35,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:35,157 INFO:     Epoch: 23
2022-11-18 00:56:35,977 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7712903036312624, 'Total loss': 0.7712903036312624} | train loss {'Reaction outcome loss': 0.8311257130703945, 'Total loss': 0.8311257130703945}
2022-11-18 00:56:35,977 INFO:     Found new best model at epoch 23
2022-11-18 00:56:35,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:35,978 INFO:     Epoch: 24
2022-11-18 00:56:36,784 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8024597533724525, 'Total loss': 0.8024597533724525} | train loss {'Reaction outcome loss': 0.8284087638382004, 'Total loss': 0.8284087638382004}
2022-11-18 00:56:36,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:36,785 INFO:     Epoch: 25
2022-11-18 00:56:37,583 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.794709446077997, 'Total loss': 0.794709446077997} | train loss {'Reaction outcome loss': 0.8241546094900201, 'Total loss': 0.8241546094900201}
2022-11-18 00:56:37,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:37,584 INFO:     Epoch: 26
2022-11-18 00:56:38,382 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7781309647993608, 'Total loss': 0.7781309647993608} | train loss {'Reaction outcome loss': 0.8364388604878414, 'Total loss': 0.8364388604878414}
2022-11-18 00:56:38,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:38,382 INFO:     Epoch: 27
2022-11-18 00:56:39,144 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7872292365540158, 'Total loss': 0.7872292365540158} | train loss {'Reaction outcome loss': 0.8175479973014067, 'Total loss': 0.8175479973014067}
2022-11-18 00:56:39,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:39,144 INFO:     Epoch: 28
2022-11-18 00:56:40,008 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7920247756622054, 'Total loss': 0.7920247756622054} | train loss {'Reaction outcome loss': 0.8157611406042509, 'Total loss': 0.8157611406042509}
2022-11-18 00:56:40,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:40,009 INFO:     Epoch: 29
2022-11-18 00:56:40,806 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7956236709247936, 'Total loss': 0.7956236709247936} | train loss {'Reaction outcome loss': 0.8237756151660733, 'Total loss': 0.8237756151660733}
2022-11-18 00:56:40,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:40,806 INFO:     Epoch: 30
2022-11-18 00:56:41,641 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7634409232573076, 'Total loss': 0.7634409232573076} | train loss {'Reaction outcome loss': 0.825845646954741, 'Total loss': 0.825845646954741}
2022-11-18 00:56:41,642 INFO:     Found new best model at epoch 30
2022-11-18 00:56:41,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:41,642 INFO:     Epoch: 31
2022-11-18 00:56:42,444 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7777693244543943, 'Total loss': 0.7777693244543943} | train loss {'Reaction outcome loss': 0.817087931988331, 'Total loss': 0.817087931988331}
2022-11-18 00:56:42,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:42,445 INFO:     Epoch: 32
2022-11-18 00:56:43,276 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7795681750232523, 'Total loss': 0.7795681750232523} | train loss {'Reaction outcome loss': 0.8180152943983734, 'Total loss': 0.8180152943983734}
2022-11-18 00:56:43,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:43,276 INFO:     Epoch: 33
2022-11-18 00:56:44,120 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7730151055888697, 'Total loss': 0.7730151055888697} | train loss {'Reaction outcome loss': 0.818082397584973, 'Total loss': 0.818082397584973}
2022-11-18 00:56:44,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:44,120 INFO:     Epoch: 34
2022-11-18 00:56:44,965 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8144195492972027, 'Total loss': 0.8144195492972027} | train loss {'Reaction outcome loss': 0.820213118183468, 'Total loss': 0.820213118183468}
2022-11-18 00:56:44,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:44,965 INFO:     Epoch: 35
2022-11-18 00:56:45,766 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7812357192689722, 'Total loss': 0.7812357192689722} | train loss {'Reaction outcome loss': 0.8191774658225326, 'Total loss': 0.8191774658225326}
2022-11-18 00:56:45,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:45,766 INFO:     Epoch: 36
2022-11-18 00:56:46,589 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7900138768282804, 'Total loss': 0.7900138768282804} | train loss {'Reaction outcome loss': 0.8173782614621556, 'Total loss': 0.8173782614621556}
2022-11-18 00:56:46,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:46,590 INFO:     Epoch: 37
2022-11-18 00:56:47,408 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7732103060592305, 'Total loss': 0.7732103060592305} | train loss {'Reaction outcome loss': 0.8163680760303007, 'Total loss': 0.8163680760303007}
2022-11-18 00:56:47,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:47,409 INFO:     Epoch: 38
2022-11-18 00:56:48,217 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7927470620382916, 'Total loss': 0.7927470620382916} | train loss {'Reaction outcome loss': 0.8146496203686544, 'Total loss': 0.8146496203686544}
2022-11-18 00:56:48,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:48,217 INFO:     Epoch: 39
2022-11-18 00:56:49,023 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7807258272712881, 'Total loss': 0.7807258272712881} | train loss {'Reaction outcome loss': 0.8227931553052987, 'Total loss': 0.8227931553052987}
2022-11-18 00:56:49,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:49,023 INFO:     Epoch: 40
2022-11-18 00:56:49,796 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8027548898350109, 'Total loss': 0.8027548898350109} | train loss {'Reaction outcome loss': 0.8281437040340562, 'Total loss': 0.8281437040340562}
2022-11-18 00:56:49,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:49,797 INFO:     Epoch: 41
2022-11-18 00:56:50,618 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.790650797161189, 'Total loss': 0.790650797161189} | train loss {'Reaction outcome loss': 0.8183165211305927, 'Total loss': 0.8183165211305927}
2022-11-18 00:56:50,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:50,618 INFO:     Epoch: 42
2022-11-18 00:56:51,443 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7742682160301642, 'Total loss': 0.7742682160301642} | train loss {'Reaction outcome loss': 0.8181381565839173, 'Total loss': 0.8181381565839173}
2022-11-18 00:56:51,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:51,443 INFO:     Epoch: 43
2022-11-18 00:56:52,277 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7763675661249594, 'Total loss': 0.7763675661249594} | train loss {'Reaction outcome loss': 0.8265589375486259, 'Total loss': 0.8265589375486259}
2022-11-18 00:56:52,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:52,278 INFO:     Epoch: 44
2022-11-18 00:56:53,057 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8005644435232336, 'Total loss': 0.8005644435232336} | train loss {'Reaction outcome loss': 0.8230099229194857, 'Total loss': 0.8230099229194857}
2022-11-18 00:56:53,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:53,057 INFO:     Epoch: 45
2022-11-18 00:56:53,855 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7874878895553675, 'Total loss': 0.7874878895553675} | train loss {'Reaction outcome loss': 0.8248147230881911, 'Total loss': 0.8248147230881911}
2022-11-18 00:56:53,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:53,856 INFO:     Epoch: 46
2022-11-18 00:56:54,647 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7884985675865953, 'Total loss': 0.7884985675865953} | train loss {'Reaction outcome loss': 0.8184290588626012, 'Total loss': 0.8184290588626012}
2022-11-18 00:56:54,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:54,647 INFO:     Epoch: 47
2022-11-18 00:56:55,434 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7840318835594438, 'Total loss': 0.7840318835594438} | train loss {'Reaction outcome loss': 0.8180408114001818, 'Total loss': 0.8180408114001818}
2022-11-18 00:56:55,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:55,434 INFO:     Epoch: 48
2022-11-18 00:56:56,293 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7775919748978182, 'Total loss': 0.7775919748978182} | train loss {'Reaction outcome loss': 0.8224242429742928, 'Total loss': 0.8224242429742928}
2022-11-18 00:56:56,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:56,294 INFO:     Epoch: 49
2022-11-18 00:56:57,113 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7822925482283939, 'Total loss': 0.7822925482283939} | train loss {'Reaction outcome loss': 0.8199439801667866, 'Total loss': 0.8199439801667866}
2022-11-18 00:56:57,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:57,114 INFO:     Epoch: 50
2022-11-18 00:56:57,973 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8108276291327043, 'Total loss': 0.8108276291327043} | train loss {'Reaction outcome loss': 0.8148139409932048, 'Total loss': 0.8148139409932048}
2022-11-18 00:56:57,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:57,973 INFO:     Epoch: 51
2022-11-18 00:56:58,791 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7758299925110557, 'Total loss': 0.7758299925110557} | train loss {'Reaction outcome loss': 0.8178305570413227, 'Total loss': 0.8178305570413227}
2022-11-18 00:56:58,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:58,791 INFO:     Epoch: 52
2022-11-18 00:56:59,586 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7870920957489447, 'Total loss': 0.7870920957489447} | train loss {'Reaction outcome loss': 0.8205942013847684, 'Total loss': 0.8205942013847684}
2022-11-18 00:56:59,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:56:59,586 INFO:     Epoch: 53
2022-11-18 00:57:00,451 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7986613647504286, 'Total loss': 0.7986613647504286} | train loss {'Reaction outcome loss': 0.8191774493528281, 'Total loss': 0.8191774493528281}
2022-11-18 00:57:00,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:00,452 INFO:     Epoch: 54
2022-11-18 00:57:01,274 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.817586050792174, 'Total loss': 0.817586050792174} | train loss {'Reaction outcome loss': 0.8192633921318209, 'Total loss': 0.8192633921318209}
2022-11-18 00:57:01,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:01,274 INFO:     Epoch: 55
2022-11-18 00:57:02,043 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.787777417762713, 'Total loss': 0.787777417762713} | train loss {'Reaction outcome loss': 0.8167466953215812, 'Total loss': 0.8167466953215812}
2022-11-18 00:57:02,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:02,043 INFO:     Epoch: 56
2022-11-18 00:57:02,822 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7853805619207296, 'Total loss': 0.7853805619207296} | train loss {'Reaction outcome loss': 0.8280196410683003, 'Total loss': 0.8280196410683003}
2022-11-18 00:57:02,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:02,822 INFO:     Epoch: 57
2022-11-18 00:57:03,629 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7883834960785779, 'Total loss': 0.7883834960785779} | train loss {'Reaction outcome loss': 0.8218731129700355, 'Total loss': 0.8218731129700355}
2022-11-18 00:57:03,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:03,629 INFO:     Epoch: 58
2022-11-18 00:57:04,417 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7885054268620231, 'Total loss': 0.7885054268620231} | train loss {'Reaction outcome loss': 0.8219953826081897, 'Total loss': 0.8219953826081897}
2022-11-18 00:57:04,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:04,417 INFO:     Epoch: 59
2022-11-18 00:57:05,225 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7824812836267732, 'Total loss': 0.7824812836267732} | train loss {'Reaction outcome loss': 0.8240362048631737, 'Total loss': 0.8240362048631737}
2022-11-18 00:57:05,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:05,225 INFO:     Epoch: 60
2022-11-18 00:57:06,070 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7930526706305417, 'Total loss': 0.7930526706305417} | train loss {'Reaction outcome loss': 0.8120765221203387, 'Total loss': 0.8120765221203387}
2022-11-18 00:57:06,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:06,070 INFO:     Epoch: 61
2022-11-18 00:57:06,882 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7995323511687192, 'Total loss': 0.7995323511687192} | train loss {'Reaction outcome loss': 0.819014928360217, 'Total loss': 0.819014928360217}
2022-11-18 00:57:06,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:06,882 INFO:     Epoch: 62
2022-11-18 00:57:07,683 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7797589484940876, 'Total loss': 0.7797589484940876} | train loss {'Reaction outcome loss': 0.8188255669375663, 'Total loss': 0.8188255669375663}
2022-11-18 00:57:07,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:07,684 INFO:     Epoch: 63
2022-11-18 00:57:08,453 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8249693675474687, 'Total loss': 0.8249693675474687} | train loss {'Reaction outcome loss': 0.817620322130892, 'Total loss': 0.817620322130892}
2022-11-18 00:57:08,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:08,454 INFO:     Epoch: 64
2022-11-18 00:57:09,238 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7761954793875868, 'Total loss': 0.7761954793875868} | train loss {'Reaction outcome loss': 0.8098624227832445, 'Total loss': 0.8098624227832445}
2022-11-18 00:57:09,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:09,238 INFO:     Epoch: 65
2022-11-18 00:57:10,038 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7893346615812995, 'Total loss': 0.7893346615812995} | train loss {'Reaction outcome loss': 0.8142970871587514, 'Total loss': 0.8142970871587514}
2022-11-18 00:57:10,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:10,038 INFO:     Epoch: 66
2022-11-18 00:57:10,800 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7745235142382708, 'Total loss': 0.7745235142382708} | train loss {'Reaction outcome loss': 0.8167754243983913, 'Total loss': 0.8167754243983913}
2022-11-18 00:57:10,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:10,800 INFO:     Epoch: 67
2022-11-18 00:57:11,565 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7720624215223573, 'Total loss': 0.7720624215223573} | train loss {'Reaction outcome loss': 0.8153911608192119, 'Total loss': 0.8153911608192119}
2022-11-18 00:57:11,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:11,566 INFO:     Epoch: 68
2022-11-18 00:57:12,354 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7690437686714259, 'Total loss': 0.7690437686714259} | train loss {'Reaction outcome loss': 0.8243500312812898, 'Total loss': 0.8243500312812898}
2022-11-18 00:57:12,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:12,355 INFO:     Epoch: 69
2022-11-18 00:57:13,124 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.782377774065191, 'Total loss': 0.782377774065191} | train loss {'Reaction outcome loss': 0.8126951311281335, 'Total loss': 0.8126951311281335}
2022-11-18 00:57:13,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:13,125 INFO:     Epoch: 70
2022-11-18 00:57:13,893 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7853314768184315, 'Total loss': 0.7853314768184315} | train loss {'Reaction outcome loss': 0.8135131987241598, 'Total loss': 0.8135131987241598}
2022-11-18 00:57:13,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:13,893 INFO:     Epoch: 71
2022-11-18 00:57:14,663 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7770795930515636, 'Total loss': 0.7770795930515636} | train loss {'Reaction outcome loss': 0.8192365520637528, 'Total loss': 0.8192365520637528}
2022-11-18 00:57:14,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:14,663 INFO:     Epoch: 72
2022-11-18 00:57:15,431 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7819328138774092, 'Total loss': 0.7819328138774092} | train loss {'Reaction outcome loss': 0.8161583148274827, 'Total loss': 0.8161583148274827}
2022-11-18 00:57:15,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:15,431 INFO:     Epoch: 73
2022-11-18 00:57:16,234 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7781946259466085, 'Total loss': 0.7781946259466085} | train loss {'Reaction outcome loss': 0.8151122771113025, 'Total loss': 0.8151122771113025}
2022-11-18 00:57:16,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:16,234 INFO:     Epoch: 74
2022-11-18 00:57:17,012 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7711046426133676, 'Total loss': 0.7711046426133676} | train loss {'Reaction outcome loss': 0.817961065996031, 'Total loss': 0.817961065996031}
2022-11-18 00:57:17,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:17,012 INFO:     Epoch: 75
2022-11-18 00:57:17,804 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7800942760976878, 'Total loss': 0.7800942760976878} | train loss {'Reaction outcome loss': 0.8212575450358603, 'Total loss': 0.8212575450358603}
2022-11-18 00:57:17,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:17,804 INFO:     Epoch: 76
2022-11-18 00:57:18,579 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7847290641882203, 'Total loss': 0.7847290641882203} | train loss {'Reaction outcome loss': 0.8158419805499706, 'Total loss': 0.8158419805499706}
2022-11-18 00:57:18,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:18,579 INFO:     Epoch: 77
2022-11-18 00:57:19,379 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7841677990826693, 'Total loss': 0.7841677990826693} | train loss {'Reaction outcome loss': 0.8184382291699228, 'Total loss': 0.8184382291699228}
2022-11-18 00:57:19,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:19,380 INFO:     Epoch: 78
2022-11-18 00:57:20,204 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7828059304844249, 'Total loss': 0.7828059304844249} | train loss {'Reaction outcome loss': 0.8195304444233175, 'Total loss': 0.8195304444233175}
2022-11-18 00:57:20,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:20,204 INFO:     Epoch: 79
2022-11-18 00:57:20,983 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7966954017227347, 'Total loss': 0.7966954017227347} | train loss {'Reaction outcome loss': 0.8120209919778925, 'Total loss': 0.8120209919778925}
2022-11-18 00:57:20,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:20,985 INFO:     Epoch: 80
2022-11-18 00:57:21,796 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7861316644332625, 'Total loss': 0.7861316644332625} | train loss {'Reaction outcome loss': 0.821622250775094, 'Total loss': 0.821622250775094}
2022-11-18 00:57:21,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:21,796 INFO:     Epoch: 81
2022-11-18 00:57:22,636 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.798040892590176, 'Total loss': 0.798040892590176} | train loss {'Reaction outcome loss': 0.8110884668433714, 'Total loss': 0.8110884668433714}
2022-11-18 00:57:22,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:22,637 INFO:     Epoch: 82
2022-11-18 00:57:23,478 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.774107542227615, 'Total loss': 0.774107542227615} | train loss {'Reaction outcome loss': 0.8148916072932332, 'Total loss': 0.8148916072932332}
2022-11-18 00:57:23,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:23,479 INFO:     Epoch: 83
2022-11-18 00:57:24,284 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7606056623838164, 'Total loss': 0.7606056623838164} | train loss {'Reaction outcome loss': 0.8129123747348785, 'Total loss': 0.8129123747348785}
2022-11-18 00:57:24,284 INFO:     Found new best model at epoch 83
2022-11-18 00:57:24,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:24,285 INFO:     Epoch: 84
2022-11-18 00:57:25,063 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7780633812600916, 'Total loss': 0.7780633812600916} | train loss {'Reaction outcome loss': 0.8089729724866659, 'Total loss': 0.8089729724866659}
2022-11-18 00:57:25,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:25,063 INFO:     Epoch: 85
2022-11-18 00:57:25,887 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8104420710693706, 'Total loss': 0.8104420710693706} | train loss {'Reaction outcome loss': 0.8189483790503822, 'Total loss': 0.8189483790503822}
2022-11-18 00:57:25,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:25,887 INFO:     Epoch: 86
2022-11-18 00:57:26,694 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7912976132197813, 'Total loss': 0.7912976132197813} | train loss {'Reaction outcome loss': 0.8231264718389704, 'Total loss': 0.8231264718389704}
2022-11-18 00:57:26,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:26,695 INFO:     Epoch: 87
2022-11-18 00:57:27,499 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7825017364865, 'Total loss': 0.7825017364865} | train loss {'Reaction outcome loss': 0.8164893122095811, 'Total loss': 0.8164893122095811}
2022-11-18 00:57:27,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:27,501 INFO:     Epoch: 88
2022-11-18 00:57:28,303 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7810796770182523, 'Total loss': 0.7810796770182523} | train loss {'Reaction outcome loss': 0.8172777247453026, 'Total loss': 0.8172777247453026}
2022-11-18 00:57:28,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:28,303 INFO:     Epoch: 89
2022-11-18 00:57:29,115 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7807156775485385, 'Total loss': 0.7807156775485385} | train loss {'Reaction outcome loss': 0.8150508397745218, 'Total loss': 0.8150508397745218}
2022-11-18 00:57:29,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:29,115 INFO:     Epoch: 90
2022-11-18 00:57:29,906 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7948058186606928, 'Total loss': 0.7948058186606928} | train loss {'Reaction outcome loss': 0.8221690742834377, 'Total loss': 0.8221690742834377}
2022-11-18 00:57:29,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:29,906 INFO:     Epoch: 91
2022-11-18 00:57:30,756 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7806735059077089, 'Total loss': 0.7806735059077089} | train loss {'Reaction outcome loss': 0.8222784784882657, 'Total loss': 0.8222784784882657}
2022-11-18 00:57:30,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:30,756 INFO:     Epoch: 92
2022-11-18 00:57:31,611 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7967988821593198, 'Total loss': 0.7967988821593198} | train loss {'Reaction outcome loss': 0.8155757110369833, 'Total loss': 0.8155757110369833}
2022-11-18 00:57:31,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:31,611 INFO:     Epoch: 93
2022-11-18 00:57:32,416 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7745332941412926, 'Total loss': 0.7745332941412926} | train loss {'Reaction outcome loss': 0.815965289951336, 'Total loss': 0.815965289951336}
2022-11-18 00:57:32,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:32,417 INFO:     Epoch: 94
2022-11-18 00:57:33,234 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7761048342693936, 'Total loss': 0.7761048342693936} | train loss {'Reaction outcome loss': 0.8202834669877643, 'Total loss': 0.8202834669877643}
2022-11-18 00:57:33,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:33,234 INFO:     Epoch: 95
2022-11-18 00:57:34,040 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7710231115872209, 'Total loss': 0.7710231115872209} | train loss {'Reaction outcome loss': 0.8149287290418679, 'Total loss': 0.8149287290418679}
2022-11-18 00:57:34,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:34,041 INFO:     Epoch: 96
2022-11-18 00:57:34,857 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8050050125880674, 'Total loss': 0.8050050125880674} | train loss {'Reaction outcome loss': 0.8224710156077798, 'Total loss': 0.8224710156077798}
2022-11-18 00:57:34,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:34,857 INFO:     Epoch: 97
2022-11-18 00:57:35,699 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8066295527599074, 'Total loss': 0.8066295527599074} | train loss {'Reaction outcome loss': 0.8184643139240713, 'Total loss': 0.8184643139240713}
2022-11-18 00:57:35,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:35,699 INFO:     Epoch: 98
2022-11-18 00:57:36,525 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7866440496661447, 'Total loss': 0.7866440496661447} | train loss {'Reaction outcome loss': 0.8152529690791721, 'Total loss': 0.8152529690791721}
2022-11-18 00:57:36,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:36,525 INFO:     Epoch: 99
2022-11-18 00:57:37,322 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7791091918267987, 'Total loss': 0.7791091918267987} | train loss {'Reaction outcome loss': 0.8139437488185973, 'Total loss': 0.8139437488185973}
2022-11-18 00:57:37,322 INFO:     Best model found after epoch 84 of 100.
2022-11-18 00:57:37,322 INFO:   Done with stage: TRAINING
2022-11-18 00:57:37,322 INFO:   Starting stage: EVALUATION
2022-11-18 00:57:37,446 INFO:   Done with stage: EVALUATION
2022-11-18 00:57:37,446 INFO:   Leaving out SEQ value Fold_3
2022-11-18 00:57:37,459 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 00:57:37,459 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:57:38,124 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:57:38,124 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:57:38,195 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:57:38,195 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:57:38,195 INFO:     No hyperparam tuning for this model
2022-11-18 00:57:38,195 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:57:38,195 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:57:38,196 INFO:     None feature selector for col prot
2022-11-18 00:57:38,196 INFO:     None feature selector for col prot
2022-11-18 00:57:38,196 INFO:     None feature selector for col prot
2022-11-18 00:57:38,197 INFO:     None feature selector for col chem
2022-11-18 00:57:38,197 INFO:     None feature selector for col chem
2022-11-18 00:57:38,197 INFO:     None feature selector for col chem
2022-11-18 00:57:38,197 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:57:38,197 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:57:38,199 INFO:     Number of params in model 168571
2022-11-18 00:57:38,202 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:57:38,202 INFO:   Starting stage: TRAINING
2022-11-18 00:57:38,259 INFO:     Val loss before train {'Reaction outcome loss': 0.9953701038693272, 'Total loss': 0.9953701038693272}
2022-11-18 00:57:38,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:38,259 INFO:     Epoch: 0
2022-11-18 00:57:39,067 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8572568810263346, 'Total loss': 0.8572568810263346} | train loss {'Reaction outcome loss': 0.8757788090676558, 'Total loss': 0.8757788090676558}
2022-11-18 00:57:39,067 INFO:     Found new best model at epoch 0
2022-11-18 00:57:39,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:39,068 INFO:     Epoch: 1
2022-11-18 00:57:39,911 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8778805996096412, 'Total loss': 0.8778805996096412} | train loss {'Reaction outcome loss': 0.8449798774768095, 'Total loss': 0.8449798774768095}
2022-11-18 00:57:39,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:39,912 INFO:     Epoch: 2
2022-11-18 00:57:40,740 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8280632412710855, 'Total loss': 0.8280632412710855} | train loss {'Reaction outcome loss': 0.8402733568285332, 'Total loss': 0.8402733568285332}
2022-11-18 00:57:40,740 INFO:     Found new best model at epoch 2
2022-11-18 00:57:40,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:40,741 INFO:     Epoch: 3
2022-11-18 00:57:41,524 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8380209068919338, 'Total loss': 0.8380209068919338} | train loss {'Reaction outcome loss': 0.8230746106290426, 'Total loss': 0.8230746106290426}
2022-11-18 00:57:41,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:41,524 INFO:     Epoch: 4
2022-11-18 00:57:42,312 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8413374680419301, 'Total loss': 0.8413374680419301} | train loss {'Reaction outcome loss': 0.8228142048980369, 'Total loss': 0.8228142048980369}
2022-11-18 00:57:42,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:42,313 INFO:     Epoch: 5
2022-11-18 00:57:43,122 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8423568987569143, 'Total loss': 0.8423568987569143} | train loss {'Reaction outcome loss': 0.8173717753809007, 'Total loss': 0.8173717753809007}
2022-11-18 00:57:43,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:43,122 INFO:     Epoch: 6
2022-11-18 00:57:44,007 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8265545388986898, 'Total loss': 0.8265545388986898} | train loss {'Reaction outcome loss': 0.8179668032976447, 'Total loss': 0.8179668032976447}
2022-11-18 00:57:44,007 INFO:     Found new best model at epoch 6
2022-11-18 00:57:44,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:44,008 INFO:     Epoch: 7
2022-11-18 00:57:44,810 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8398241095764692, 'Total loss': 0.8398241095764692} | train loss {'Reaction outcome loss': 0.8184798616366308, 'Total loss': 0.8184798616366308}
2022-11-18 00:57:44,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:44,810 INFO:     Epoch: 8
2022-11-18 00:57:45,628 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8567297666571861, 'Total loss': 0.8567297666571861} | train loss {'Reaction outcome loss': 0.8171120372707726, 'Total loss': 0.8171120372707726}
2022-11-18 00:57:45,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:45,628 INFO:     Epoch: 9
2022-11-18 00:57:46,443 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8248274374839871, 'Total loss': 0.8248274374839871} | train loss {'Reaction outcome loss': 0.8164290879837802, 'Total loss': 0.8164290879837802}
2022-11-18 00:57:46,443 INFO:     Found new best model at epoch 9
2022-11-18 00:57:46,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:46,444 INFO:     Epoch: 10
2022-11-18 00:57:47,247 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8274910865828048, 'Total loss': 0.8274910865828048} | train loss {'Reaction outcome loss': 0.8144928565035101, 'Total loss': 0.8144928565035101}
2022-11-18 00:57:47,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:47,247 INFO:     Epoch: 11
2022-11-18 00:57:48,062 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8228119895901791, 'Total loss': 0.8228119895901791} | train loss {'Reaction outcome loss': 0.8173499404162657, 'Total loss': 0.8173499404162657}
2022-11-18 00:57:48,062 INFO:     Found new best model at epoch 11
2022-11-18 00:57:48,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:48,063 INFO:     Epoch: 12
2022-11-18 00:57:48,841 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8181163488432418, 'Total loss': 0.8181163488432418} | train loss {'Reaction outcome loss': 0.815449627940772, 'Total loss': 0.815449627940772}
2022-11-18 00:57:48,841 INFO:     Found new best model at epoch 12
2022-11-18 00:57:48,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:48,842 INFO:     Epoch: 13
2022-11-18 00:57:49,601 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8483426446138427, 'Total loss': 0.8483426446138427} | train loss {'Reaction outcome loss': 0.8135903817219813, 'Total loss': 0.8135903817219813}
2022-11-18 00:57:49,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:49,602 INFO:     Epoch: 14
2022-11-18 00:57:50,409 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.823672490064488, 'Total loss': 0.823672490064488} | train loss {'Reaction outcome loss': 0.8143421931833518, 'Total loss': 0.8143421931833518}
2022-11-18 00:57:50,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:50,409 INFO:     Epoch: 15
2022-11-18 00:57:51,178 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8362673063610875, 'Total loss': 0.8362673063610875} | train loss {'Reaction outcome loss': 0.8150491774326465, 'Total loss': 0.8150491774326465}
2022-11-18 00:57:51,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:51,179 INFO:     Epoch: 16
2022-11-18 00:57:51,973 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8171836719956509, 'Total loss': 0.8171836719956509} | train loss {'Reaction outcome loss': 0.8139359933919594, 'Total loss': 0.8139359933919594}
2022-11-18 00:57:51,975 INFO:     Found new best model at epoch 16
2022-11-18 00:57:51,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:51,976 INFO:     Epoch: 17
2022-11-18 00:57:52,764 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8246608154718266, 'Total loss': 0.8246608154718266} | train loss {'Reaction outcome loss': 0.8121031073273205, 'Total loss': 0.8121031073273205}
2022-11-18 00:57:52,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:52,765 INFO:     Epoch: 18
2022-11-18 00:57:53,580 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.822280542101971, 'Total loss': 0.822280542101971} | train loss {'Reaction outcome loss': 0.8133281171321869, 'Total loss': 0.8133281171321869}
2022-11-18 00:57:53,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:53,581 INFO:     Epoch: 19
2022-11-18 00:57:54,407 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8406540377195492, 'Total loss': 0.8406540377195492} | train loss {'Reaction outcome loss': 0.8138355765430654, 'Total loss': 0.8138355765430654}
2022-11-18 00:57:54,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:54,408 INFO:     Epoch: 20
2022-11-18 00:57:55,223 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8207607449487199, 'Total loss': 0.8207607449487199} | train loss {'Reaction outcome loss': 0.8133105562358606, 'Total loss': 0.8133105562358606}
2022-11-18 00:57:55,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:55,223 INFO:     Epoch: 21
2022-11-18 00:57:56,004 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8139422660650208, 'Total loss': 0.8139422660650208} | train loss {'Reaction outcome loss': 0.8139293089997574, 'Total loss': 0.8139293089997574}
2022-11-18 00:57:56,005 INFO:     Found new best model at epoch 21
2022-11-18 00:57:56,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:56,005 INFO:     Epoch: 22
2022-11-18 00:57:56,825 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8308695769587229, 'Total loss': 0.8308695769587229} | train loss {'Reaction outcome loss': 0.8161359870287238, 'Total loss': 0.8161359870287238}
2022-11-18 00:57:56,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:56,825 INFO:     Epoch: 23
2022-11-18 00:57:57,600 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8127387013546256, 'Total loss': 0.8127387013546256} | train loss {'Reaction outcome loss': 0.8118882350257186, 'Total loss': 0.8118882350257186}
2022-11-18 00:57:57,600 INFO:     Found new best model at epoch 23
2022-11-18 00:57:57,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:57,602 INFO:     Epoch: 24
2022-11-18 00:57:58,410 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8155089623706285, 'Total loss': 0.8155089623706285} | train loss {'Reaction outcome loss': 0.8154853807121026, 'Total loss': 0.8154853807121026}
2022-11-18 00:57:58,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:58,411 INFO:     Epoch: 25
2022-11-18 00:57:59,217 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8117907830449038, 'Total loss': 0.8117907830449038} | train loss {'Reaction outcome loss': 0.8088805273663803, 'Total loss': 0.8088805273663803}
2022-11-18 00:57:59,217 INFO:     Found new best model at epoch 25
2022-11-18 00:57:59,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:57:59,218 INFO:     Epoch: 26
2022-11-18 00:58:00,006 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8216251301210981, 'Total loss': 0.8216251301210981} | train loss {'Reaction outcome loss': 0.8102192191071198, 'Total loss': 0.8102192191071198}
2022-11-18 00:58:00,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:00,006 INFO:     Epoch: 27
2022-11-18 00:58:00,809 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8184841372245966, 'Total loss': 0.8184841372245966} | train loss {'Reaction outcome loss': 0.8155488491546913, 'Total loss': 0.8155488491546913}
2022-11-18 00:58:00,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:00,809 INFO:     Epoch: 28
2022-11-18 00:58:01,589 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8373624737872634, 'Total loss': 0.8373624737872634} | train loss {'Reaction outcome loss': 0.8113685564183798, 'Total loss': 0.8113685564183798}
2022-11-18 00:58:01,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:01,589 INFO:     Epoch: 29
2022-11-18 00:58:02,427 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8111022502876991, 'Total loss': 0.8111022502876991} | train loss {'Reaction outcome loss': 0.8153345959841228, 'Total loss': 0.8153345959841228}
2022-11-18 00:58:02,427 INFO:     Found new best model at epoch 29
2022-11-18 00:58:02,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:02,428 INFO:     Epoch: 30
2022-11-18 00:58:03,247 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8244677574135536, 'Total loss': 0.8244677574135536} | train loss {'Reaction outcome loss': 0.8118629594806765, 'Total loss': 0.8118629594806765}
2022-11-18 00:58:03,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:03,247 INFO:     Epoch: 31
2022-11-18 00:58:04,044 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8209888650927433, 'Total loss': 0.8209888650927433} | train loss {'Reaction outcome loss': 0.8089741275447314, 'Total loss': 0.8089741275447314}
2022-11-18 00:58:04,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:04,044 INFO:     Epoch: 32
2022-11-18 00:58:04,859 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8249848318654437, 'Total loss': 0.8249848318654437} | train loss {'Reaction outcome loss': 0.8096413600151656, 'Total loss': 0.8096413600151656}
2022-11-18 00:58:04,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:04,860 INFO:     Epoch: 33
2022-11-18 00:58:05,662 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8272197170313015, 'Total loss': 0.8272197170313015} | train loss {'Reaction outcome loss': 0.8093683371534113, 'Total loss': 0.8093683371534113}
2022-11-18 00:58:05,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:05,662 INFO:     Epoch: 34
2022-11-18 00:58:06,426 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8237500017465547, 'Total loss': 0.8237500017465547} | train loss {'Reaction outcome loss': 0.811470197971727, 'Total loss': 0.811470197971727}
2022-11-18 00:58:06,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:06,427 INFO:     Epoch: 35
2022-11-18 00:58:07,260 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8379788204681041, 'Total loss': 0.8379788204681041} | train loss {'Reaction outcome loss': 0.8095996814673064, 'Total loss': 0.8095996814673064}
2022-11-18 00:58:07,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:07,260 INFO:     Epoch: 36
2022-11-18 00:58:08,081 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8649465455565342, 'Total loss': 0.8649465455565342} | train loss {'Reaction outcome loss': 0.8109120610551755, 'Total loss': 0.8109120610551755}
2022-11-18 00:58:08,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:08,082 INFO:     Epoch: 37
2022-11-18 00:58:08,873 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8223631007726803, 'Total loss': 0.8223631007726803} | train loss {'Reaction outcome loss': 0.81072207601344, 'Total loss': 0.81072207601344}
2022-11-18 00:58:08,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:08,873 INFO:     Epoch: 38
2022-11-18 00:58:09,678 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8152289709379507, 'Total loss': 0.8152289709379507} | train loss {'Reaction outcome loss': 0.812849260133798, 'Total loss': 0.812849260133798}
2022-11-18 00:58:09,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:09,679 INFO:     Epoch: 39
2022-11-18 00:58:10,453 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8097321716851966, 'Total loss': 0.8097321716851966} | train loss {'Reaction outcome loss': 0.8137294030824646, 'Total loss': 0.8137294030824646}
2022-11-18 00:58:10,454 INFO:     Found new best model at epoch 39
2022-11-18 00:58:10,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:10,455 INFO:     Epoch: 40
2022-11-18 00:58:11,252 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8418273281219394, 'Total loss': 0.8418273281219394} | train loss {'Reaction outcome loss': 0.8076796532898652, 'Total loss': 0.8076796532898652}
2022-11-18 00:58:11,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:11,253 INFO:     Epoch: 41
2022-11-18 00:58:12,052 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8135049467863038, 'Total loss': 0.8135049467863038} | train loss {'Reaction outcome loss': 0.8177288544715428, 'Total loss': 0.8177288544715428}
2022-11-18 00:58:12,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:12,052 INFO:     Epoch: 42
2022-11-18 00:58:12,876 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8352677350820497, 'Total loss': 0.8352677350820497} | train loss {'Reaction outcome loss': 0.8133080489322787, 'Total loss': 0.8133080489322787}
2022-11-18 00:58:12,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:12,876 INFO:     Epoch: 43
2022-11-18 00:58:13,679 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8277853325355885, 'Total loss': 0.8277853325355885} | train loss {'Reaction outcome loss': 0.806578060886899, 'Total loss': 0.806578060886899}
2022-11-18 00:58:13,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:13,679 INFO:     Epoch: 44
2022-11-18 00:58:14,452 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8210489639016085, 'Total loss': 0.8210489639016085} | train loss {'Reaction outcome loss': 0.8151196604136561, 'Total loss': 0.8151196604136561}
2022-11-18 00:58:14,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:14,453 INFO:     Epoch: 45
2022-11-18 00:58:15,216 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8198523140230844, 'Total loss': 0.8198523140230844} | train loss {'Reaction outcome loss': 0.8129664527588203, 'Total loss': 0.8129664527588203}
2022-11-18 00:58:15,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:15,216 INFO:     Epoch: 46
2022-11-18 00:58:15,988 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8312852902467861, 'Total loss': 0.8312852902467861} | train loss {'Reaction outcome loss': 0.8127673675046593, 'Total loss': 0.8127673675046593}
2022-11-18 00:58:15,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:15,988 INFO:     Epoch: 47
2022-11-18 00:58:16,843 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8166072174560192, 'Total loss': 0.8166072174560192} | train loss {'Reaction outcome loss': 0.8167699359235217, 'Total loss': 0.8167699359235217}
2022-11-18 00:58:16,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:16,843 INFO:     Epoch: 48
2022-11-18 00:58:17,648 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8127927738566731, 'Total loss': 0.8127927738566731} | train loss {'Reaction outcome loss': 0.8111270112825222, 'Total loss': 0.8111270112825222}
2022-11-18 00:58:17,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:17,649 INFO:     Epoch: 49
2022-11-18 00:58:18,448 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8166758182436921, 'Total loss': 0.8166758182436921} | train loss {'Reaction outcome loss': 0.8081274613982341, 'Total loss': 0.8081274613982341}
2022-11-18 00:58:18,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:18,448 INFO:     Epoch: 50
2022-11-18 00:58:19,253 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8127117198567058, 'Total loss': 0.8127117198567058} | train loss {'Reaction outcome loss': 0.8100159698333896, 'Total loss': 0.8100159698333896}
2022-11-18 00:58:19,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:19,253 INFO:     Epoch: 51
2022-11-18 00:58:20,044 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8355373996634816, 'Total loss': 0.8355373996634816} | train loss {'Reaction outcome loss': 0.809506249720933, 'Total loss': 0.809506249720933}
2022-11-18 00:58:20,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:20,044 INFO:     Epoch: 52
2022-11-18 00:58:20,878 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8204834509727567, 'Total loss': 0.8204834509727567} | train loss {'Reaction outcome loss': 0.8142720903040933, 'Total loss': 0.8142720903040933}
2022-11-18 00:58:20,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:20,879 INFO:     Epoch: 53
2022-11-18 00:58:21,684 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8158931801485461, 'Total loss': 0.8158931801485461} | train loss {'Reaction outcome loss': 0.8118459882794834, 'Total loss': 0.8118459882794834}
2022-11-18 00:58:21,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:21,684 INFO:     Epoch: 54
2022-11-18 00:58:22,468 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.816965383152629, 'Total loss': 0.816965383152629} | train loss {'Reaction outcome loss': 0.8106532943297605, 'Total loss': 0.8106532943297605}
2022-11-18 00:58:22,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:22,469 INFO:     Epoch: 55
2022-11-18 00:58:23,287 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8207203295341757, 'Total loss': 0.8207203295341757} | train loss {'Reaction outcome loss': 0.8093463142142922, 'Total loss': 0.8093463142142922}
2022-11-18 00:58:23,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:23,288 INFO:     Epoch: 56
2022-11-18 00:58:24,072 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8287103189978489, 'Total loss': 0.8287103189978489} | train loss {'Reaction outcome loss': 0.8100764519367062, 'Total loss': 0.8100764519367062}
2022-11-18 00:58:24,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:24,072 INFO:     Epoch: 57
2022-11-18 00:58:24,930 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8403728902339935, 'Total loss': 0.8403728902339935} | train loss {'Reaction outcome loss': 0.8144620941554914, 'Total loss': 0.8144620941554914}
2022-11-18 00:58:24,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:24,931 INFO:     Epoch: 58
2022-11-18 00:58:25,730 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8305556330569955, 'Total loss': 0.8305556330569955} | train loss {'Reaction outcome loss': 0.8112760046955014, 'Total loss': 0.8112760046955014}
2022-11-18 00:58:25,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:25,731 INFO:     Epoch: 59
2022-11-18 00:58:26,513 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8184287492619005, 'Total loss': 0.8184287492619005} | train loss {'Reaction outcome loss': 0.8132202577639799, 'Total loss': 0.8132202577639799}
2022-11-18 00:58:26,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:26,513 INFO:     Epoch: 60
2022-11-18 00:58:27,305 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8222843075907508, 'Total loss': 0.8222843075907508} | train loss {'Reaction outcome loss': 0.809977196034838, 'Total loss': 0.809977196034838}
2022-11-18 00:58:27,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:27,305 INFO:     Epoch: 61
2022-11-18 00:58:28,119 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.833405268746753, 'Total loss': 0.833405268746753} | train loss {'Reaction outcome loss': 0.8120522114341376, 'Total loss': 0.8120522114341376}
2022-11-18 00:58:28,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:28,119 INFO:     Epoch: 62
2022-11-18 00:58:28,960 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8184894683749177, 'Total loss': 0.8184894683749177} | train loss {'Reaction outcome loss': 0.8132720627501363, 'Total loss': 0.8132720627501363}
2022-11-18 00:58:28,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:28,960 INFO:     Epoch: 63
2022-11-18 00:58:29,750 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8208110713681509, 'Total loss': 0.8208110713681509} | train loss {'Reaction outcome loss': 0.8146731814400094, 'Total loss': 0.8146731814400094}
2022-11-18 00:58:29,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:29,751 INFO:     Epoch: 64
2022-11-18 00:58:30,553 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8216758897138197, 'Total loss': 0.8216758897138197} | train loss {'Reaction outcome loss': 0.8096616698093102, 'Total loss': 0.8096616698093102}
2022-11-18 00:58:30,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:30,553 INFO:     Epoch: 65
2022-11-18 00:58:31,366 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.817552728015323, 'Total loss': 0.817552728015323} | train loss {'Reaction outcome loss': 0.8116616825344133, 'Total loss': 0.8116616825344133}
2022-11-18 00:58:31,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:31,366 INFO:     Epoch: 66
2022-11-18 00:58:32,184 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8208858855935031, 'Total loss': 0.8208858855935031} | train loss {'Reaction outcome loss': 0.8133705575935176, 'Total loss': 0.8133705575935176}
2022-11-18 00:58:32,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:32,185 INFO:     Epoch: 67
2022-11-18 00:58:32,985 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8193312543769216, 'Total loss': 0.8193312543769216} | train loss {'Reaction outcome loss': 0.8124775088957099, 'Total loss': 0.8124775088957099}
2022-11-18 00:58:32,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:32,986 INFO:     Epoch: 68
2022-11-18 00:58:33,769 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8149139493010765, 'Total loss': 0.8149139493010765} | train loss {'Reaction outcome loss': 0.8137645324478384, 'Total loss': 0.8137645324478384}
2022-11-18 00:58:33,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:33,769 INFO:     Epoch: 69
2022-11-18 00:58:34,573 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8338243892026502, 'Total loss': 0.8338243892026502} | train loss {'Reaction outcome loss': 0.8130511912654658, 'Total loss': 0.8130511912654658}
2022-11-18 00:58:34,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:34,574 INFO:     Epoch: 70
2022-11-18 00:58:35,388 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8158626507881076, 'Total loss': 0.8158626507881076} | train loss {'Reaction outcome loss': 0.8134133689960495, 'Total loss': 0.8134133689960495}
2022-11-18 00:58:35,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:35,389 INFO:     Epoch: 71
2022-11-18 00:58:36,252 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8160869832648787, 'Total loss': 0.8160869832648787} | train loss {'Reaction outcome loss': 0.8124537244439125, 'Total loss': 0.8124537244439125}
2022-11-18 00:58:36,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:36,252 INFO:     Epoch: 72
2022-11-18 00:58:37,040 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8148896617944851, 'Total loss': 0.8148896617944851} | train loss {'Reaction outcome loss': 0.8096609878979746, 'Total loss': 0.8096609878979746}
2022-11-18 00:58:37,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:37,041 INFO:     Epoch: 73
2022-11-18 00:58:37,867 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8188587780608687, 'Total loss': 0.8188587780608687} | train loss {'Reaction outcome loss': 0.8083262638967545, 'Total loss': 0.8083262638967545}
2022-11-18 00:58:37,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:37,868 INFO:     Epoch: 74
2022-11-18 00:58:38,682 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8213933449844981, 'Total loss': 0.8213933449844981} | train loss {'Reaction outcome loss': 0.8111100620666488, 'Total loss': 0.8111100620666488}
2022-11-18 00:58:38,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:38,683 INFO:     Epoch: 75
2022-11-18 00:58:39,491 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.81482690988585, 'Total loss': 0.81482690988585} | train loss {'Reaction outcome loss': 0.8120432426450682, 'Total loss': 0.8120432426450682}
2022-11-18 00:58:39,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:39,492 INFO:     Epoch: 76
2022-11-18 00:58:40,266 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8144018116385437, 'Total loss': 0.8144018116385437} | train loss {'Reaction outcome loss': 0.8095129283725239, 'Total loss': 0.8095129283725239}
2022-11-18 00:58:40,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:40,266 INFO:     Epoch: 77
2022-11-18 00:58:41,056 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8305402966432793, 'Total loss': 0.8305402966432793} | train loss {'Reaction outcome loss': 0.8065477068551251, 'Total loss': 0.8065477068551251}
2022-11-18 00:58:41,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:41,056 INFO:     Epoch: 78
2022-11-18 00:58:41,882 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8398331188878347, 'Total loss': 0.8398331188878347} | train loss {'Reaction outcome loss': 0.8102922849967832, 'Total loss': 0.8102922849967832}
2022-11-18 00:58:41,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:41,883 INFO:     Epoch: 79
2022-11-18 00:58:42,688 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8212791022866271, 'Total loss': 0.8212791022866271} | train loss {'Reaction outcome loss': 0.8080956626866684, 'Total loss': 0.8080956626866684}
2022-11-18 00:58:42,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:42,688 INFO:     Epoch: 80
2022-11-18 00:58:43,481 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8144158873447153, 'Total loss': 0.8144158873447153} | train loss {'Reaction outcome loss': 0.8091364956048669, 'Total loss': 0.8091364956048669}
2022-11-18 00:58:43,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:43,481 INFO:     Epoch: 81
2022-11-18 00:58:44,267 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8138847032258677, 'Total loss': 0.8138847032258677} | train loss {'Reaction outcome loss': 0.8124957111526708, 'Total loss': 0.8124957111526708}
2022-11-18 00:58:44,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:44,267 INFO:     Epoch: 82
2022-11-18 00:58:45,080 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8530365817768629, 'Total loss': 0.8530365817768629} | train loss {'Reaction outcome loss': 0.8127756529167051, 'Total loss': 0.8127756529167051}
2022-11-18 00:58:45,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:45,080 INFO:     Epoch: 83
2022-11-18 00:58:45,881 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8185324502545733, 'Total loss': 0.8185324502545733} | train loss {'Reaction outcome loss': 0.8108756864657167, 'Total loss': 0.8108756864657167}
2022-11-18 00:58:45,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:45,881 INFO:     Epoch: 84
2022-11-18 00:58:46,678 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8264260347499404, 'Total loss': 0.8264260347499404} | train loss {'Reaction outcome loss': 0.8100561484938762, 'Total loss': 0.8100561484938762}
2022-11-18 00:58:46,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:46,678 INFO:     Epoch: 85
2022-11-18 00:58:47,485 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8341500634370849, 'Total loss': 0.8341500634370849} | train loss {'Reaction outcome loss': 0.8118148293407237, 'Total loss': 0.8118148293407237}
2022-11-18 00:58:47,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:47,486 INFO:     Epoch: 86
2022-11-18 00:58:48,266 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8321142044178275, 'Total loss': 0.8321142044178275} | train loss {'Reaction outcome loss': 0.8115592630671673, 'Total loss': 0.8115592630671673}
2022-11-18 00:58:48,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:48,266 INFO:     Epoch: 87
2022-11-18 00:58:49,079 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8197393472804579, 'Total loss': 0.8197393472804579} | train loss {'Reaction outcome loss': 0.8102170336441915, 'Total loss': 0.8102170336441915}
2022-11-18 00:58:49,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:49,080 INFO:     Epoch: 88
2022-11-18 00:58:49,889 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8190366002016289, 'Total loss': 0.8190366002016289} | train loss {'Reaction outcome loss': 0.8147721842664187, 'Total loss': 0.8147721842664187}
2022-11-18 00:58:49,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:49,889 INFO:     Epoch: 89
2022-11-18 00:58:50,734 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.833541942197223, 'Total loss': 0.833541942197223} | train loss {'Reaction outcome loss': 0.8108543400637439, 'Total loss': 0.8108543400637439}
2022-11-18 00:58:50,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:50,740 INFO:     Epoch: 90
2022-11-18 00:58:51,565 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.811442012703696, 'Total loss': 0.811442012703696} | train loss {'Reaction outcome loss': 0.8098716489115699, 'Total loss': 0.8098716489115699}
2022-11-18 00:58:51,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:51,565 INFO:     Epoch: 91
2022-11-18 00:58:52,411 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8304313095503075, 'Total loss': 0.8304313095503075} | train loss {'Reaction outcome loss': 0.8072413178008111, 'Total loss': 0.8072413178008111}
2022-11-18 00:58:52,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:52,412 INFO:     Epoch: 92
2022-11-18 00:58:53,258 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8235267809657163, 'Total loss': 0.8235267809657163} | train loss {'Reaction outcome loss': 0.8154048554477145, 'Total loss': 0.8154048554477145}
2022-11-18 00:58:53,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:53,259 INFO:     Epoch: 93
2022-11-18 00:58:54,049 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8168363148389861, 'Total loss': 0.8168363148389861} | train loss {'Reaction outcome loss': 0.810973983807642, 'Total loss': 0.810973983807642}
2022-11-18 00:58:54,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:54,050 INFO:     Epoch: 94
2022-11-18 00:58:54,827 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8228046845558078, 'Total loss': 0.8228046845558078} | train loss {'Reaction outcome loss': 0.8105394057318812, 'Total loss': 0.8105394057318812}
2022-11-18 00:58:54,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:54,827 INFO:     Epoch: 95
2022-11-18 00:58:55,616 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8353743137315263, 'Total loss': 0.8353743137315263} | train loss {'Reaction outcome loss': 0.8098801694443969, 'Total loss': 0.8098801694443969}
2022-11-18 00:58:55,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:55,617 INFO:     Epoch: 96
2022-11-18 00:58:56,450 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8175970724848813, 'Total loss': 0.8175970724848813} | train loss {'Reaction outcome loss': 0.8098188119589306, 'Total loss': 0.8098188119589306}
2022-11-18 00:58:56,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:56,450 INFO:     Epoch: 97
2022-11-18 00:58:57,223 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8182618860588518, 'Total loss': 0.8182618860588518} | train loss {'Reaction outcome loss': 0.8090266691612416, 'Total loss': 0.8090266691612416}
2022-11-18 00:58:57,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:57,224 INFO:     Epoch: 98
2022-11-18 00:58:58,046 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8242136607336443, 'Total loss': 0.8242136607336443} | train loss {'Reaction outcome loss': 0.8090040252589789, 'Total loss': 0.8090040252589789}
2022-11-18 00:58:58,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:58,046 INFO:     Epoch: 99
2022-11-18 00:58:58,833 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8239180140717085, 'Total loss': 0.8239180140717085} | train loss {'Reaction outcome loss': 0.8084559741078831, 'Total loss': 0.8084559741078831}
2022-11-18 00:58:58,833 INFO:     Best model found after epoch 40 of 100.
2022-11-18 00:58:58,833 INFO:   Done with stage: TRAINING
2022-11-18 00:58:58,833 INFO:   Starting stage: EVALUATION
2022-11-18 00:58:58,968 INFO:   Done with stage: EVALUATION
2022-11-18 00:58:58,968 INFO:   Leaving out SEQ value Fold_4
2022-11-18 00:58:58,982 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 00:58:58,982 INFO:   Starting stage: FEATURE SCALING
2022-11-18 00:58:59,667 INFO:   Done with stage: FEATURE SCALING
2022-11-18 00:58:59,667 INFO:   Starting stage: SCALING TARGETS
2022-11-18 00:58:59,744 INFO:   Done with stage: SCALING TARGETS
2022-11-18 00:58:59,744 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:58:59,744 INFO:     No hyperparam tuning for this model
2022-11-18 00:58:59,744 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 00:58:59,744 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 00:58:59,745 INFO:     None feature selector for col prot
2022-11-18 00:58:59,745 INFO:     None feature selector for col prot
2022-11-18 00:58:59,745 INFO:     None feature selector for col prot
2022-11-18 00:58:59,746 INFO:     None feature selector for col chem
2022-11-18 00:58:59,746 INFO:     None feature selector for col chem
2022-11-18 00:58:59,746 INFO:     None feature selector for col chem
2022-11-18 00:58:59,746 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 00:58:59,746 INFO:   Starting stage: BUILD MODEL
2022-11-18 00:58:59,748 INFO:     Number of params in model 168571
2022-11-18 00:58:59,751 INFO:   Done with stage: BUILD MODEL
2022-11-18 00:58:59,751 INFO:   Starting stage: TRAINING
2022-11-18 00:58:59,810 INFO:     Val loss before train {'Reaction outcome loss': 0.9921600005843423, 'Total loss': 0.9921600005843423}
2022-11-18 00:58:59,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:58:59,810 INFO:     Epoch: 0
2022-11-18 00:59:00,639 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8144756670702588, 'Total loss': 0.8144756670702588} | train loss {'Reaction outcome loss': 0.8987217992544174, 'Total loss': 0.8987217992544174}
2022-11-18 00:59:00,640 INFO:     Found new best model at epoch 0
2022-11-18 00:59:00,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:00,641 INFO:     Epoch: 1
2022-11-18 00:59:01,439 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8124883635477587, 'Total loss': 0.8124883635477587} | train loss {'Reaction outcome loss': 0.8604444464848887, 'Total loss': 0.8604444464848887}
2022-11-18 00:59:01,439 INFO:     Found new best model at epoch 1
2022-11-18 00:59:01,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:01,440 INFO:     Epoch: 2
2022-11-18 00:59:02,261 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8313409239053726, 'Total loss': 0.8313409239053726} | train loss {'Reaction outcome loss': 0.8556578156928862, 'Total loss': 0.8556578156928862}
2022-11-18 00:59:02,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:02,261 INFO:     Epoch: 3
2022-11-18 00:59:03,064 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8201815594326366, 'Total loss': 0.8201815594326366} | train loss {'Reaction outcome loss': 0.8569825219531213, 'Total loss': 0.8569825219531213}
2022-11-18 00:59:03,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:03,064 INFO:     Epoch: 4
2022-11-18 00:59:03,909 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8307773145762357, 'Total loss': 0.8307773145762357} | train loss {'Reaction outcome loss': 0.8446246736472652, 'Total loss': 0.8446246736472652}
2022-11-18 00:59:03,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:03,909 INFO:     Epoch: 5
2022-11-18 00:59:04,691 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8099729527126659, 'Total loss': 0.8099729527126659} | train loss {'Reaction outcome loss': 0.8463995113007484, 'Total loss': 0.8463995113007484}
2022-11-18 00:59:04,691 INFO:     Found new best model at epoch 5
2022-11-18 00:59:04,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:04,692 INFO:     Epoch: 6
2022-11-18 00:59:05,486 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.807761777531017, 'Total loss': 0.807761777531017} | train loss {'Reaction outcome loss': 0.8451181974622511, 'Total loss': 0.8451181974622511}
2022-11-18 00:59:05,486 INFO:     Found new best model at epoch 6
2022-11-18 00:59:05,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:05,487 INFO:     Epoch: 7
2022-11-18 00:59:06,308 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8119788664308462, 'Total loss': 0.8119788664308462} | train loss {'Reaction outcome loss': 0.8425021362641165, 'Total loss': 0.8425021362641165}
2022-11-18 00:59:06,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:06,308 INFO:     Epoch: 8
2022-11-18 00:59:07,126 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7943014922467145, 'Total loss': 0.7943014922467145} | train loss {'Reaction outcome loss': 0.8357774278809947, 'Total loss': 0.8357774278809947}
2022-11-18 00:59:07,126 INFO:     Found new best model at epoch 8
2022-11-18 00:59:07,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:07,127 INFO:     Epoch: 9
2022-11-18 00:59:07,946 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8042573610490019, 'Total loss': 0.8042573610490019} | train loss {'Reaction outcome loss': 0.8364954134148936, 'Total loss': 0.8364954134148936}
2022-11-18 00:59:07,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:07,946 INFO:     Epoch: 10
2022-11-18 00:59:08,761 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8114769601009109, 'Total loss': 0.8114769601009109} | train loss {'Reaction outcome loss': 0.8406882489160183, 'Total loss': 0.8406882489160183}
2022-11-18 00:59:08,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:08,762 INFO:     Epoch: 11
2022-11-18 00:59:09,581 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8044534166428176, 'Total loss': 0.8044534166428176} | train loss {'Reaction outcome loss': 0.8320644592806217, 'Total loss': 0.8320644592806217}
2022-11-18 00:59:09,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:09,581 INFO:     Epoch: 12
2022-11-18 00:59:10,419 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7973132485693152, 'Total loss': 0.7973132485693152} | train loss {'Reaction outcome loss': 0.8394323886642533, 'Total loss': 0.8394323886642533}
2022-11-18 00:59:10,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:10,420 INFO:     Epoch: 13
2022-11-18 00:59:11,245 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7964900643988089, 'Total loss': 0.7964900643988089} | train loss {'Reaction outcome loss': 0.8379210488450143, 'Total loss': 0.8379210488450143}
2022-11-18 00:59:11,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:11,245 INFO:     Epoch: 14
2022-11-18 00:59:12,054 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8041019758040254, 'Total loss': 0.8041019758040254} | train loss {'Reaction outcome loss': 0.8349133750363704, 'Total loss': 0.8349133750363704}
2022-11-18 00:59:12,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:12,055 INFO:     Epoch: 15
2022-11-18 00:59:12,905 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7885447517037392, 'Total loss': 0.7885447517037392} | train loss {'Reaction outcome loss': 0.8382692897031384, 'Total loss': 0.8382692897031384}
2022-11-18 00:59:12,906 INFO:     Found new best model at epoch 15
2022-11-18 00:59:12,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:12,907 INFO:     Epoch: 16
2022-11-18 00:59:13,702 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7985063886100595, 'Total loss': 0.7985063886100595} | train loss {'Reaction outcome loss': 0.8330751552937492, 'Total loss': 0.8330751552937492}
2022-11-18 00:59:13,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:13,702 INFO:     Epoch: 17
2022-11-18 00:59:14,544 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7849008163267915, 'Total loss': 0.7849008163267915} | train loss {'Reaction outcome loss': 0.8371774788585401, 'Total loss': 0.8371774788585401}
2022-11-18 00:59:14,544 INFO:     Found new best model at epoch 17
2022-11-18 00:59:14,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:14,545 INFO:     Epoch: 18
2022-11-18 00:59:15,373 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7870195643468336, 'Total loss': 0.7870195643468336} | train loss {'Reaction outcome loss': 0.8339719468307111, 'Total loss': 0.8339719468307111}
2022-11-18 00:59:15,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:15,373 INFO:     Epoch: 19
2022-11-18 00:59:16,222 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7997931282628666, 'Total loss': 0.7997931282628666} | train loss {'Reaction outcome loss': 0.8369631335860298, 'Total loss': 0.8369631335860298}
2022-11-18 00:59:16,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:16,223 INFO:     Epoch: 20
2022-11-18 00:59:17,048 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7972708134488626, 'Total loss': 0.7972708134488626} | train loss {'Reaction outcome loss': 0.8321949173846552, 'Total loss': 0.8321949173846552}
2022-11-18 00:59:17,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:17,048 INFO:     Epoch: 21
2022-11-18 00:59:17,874 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8118910728530451, 'Total loss': 0.8118910728530451} | train loss {'Reaction outcome loss': 0.8269322359513852, 'Total loss': 0.8269322359513852}
2022-11-18 00:59:17,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:17,875 INFO:     Epoch: 22
2022-11-18 00:59:18,729 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7937801040031693, 'Total loss': 0.7937801040031693} | train loss {'Reaction outcome loss': 0.8325171685747562, 'Total loss': 0.8325171685747562}
2022-11-18 00:59:18,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:18,730 INFO:     Epoch: 23
2022-11-18 00:59:19,524 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7882114906202663, 'Total loss': 0.7882114906202663} | train loss {'Reaction outcome loss': 0.8284584919531499, 'Total loss': 0.8284584919531499}
2022-11-18 00:59:19,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:19,525 INFO:     Epoch: 24
2022-11-18 00:59:20,343 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8044899742711674, 'Total loss': 0.8044899742711674} | train loss {'Reaction outcome loss': 0.8329495419898341, 'Total loss': 0.8329495419898341}
2022-11-18 00:59:20,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:20,344 INFO:     Epoch: 25
2022-11-18 00:59:21,161 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8077787079594352, 'Total loss': 0.8077787079594352} | train loss {'Reaction outcome loss': 0.8305879298958087, 'Total loss': 0.8305879298958087}
2022-11-18 00:59:21,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:21,161 INFO:     Epoch: 26
2022-11-18 00:59:21,926 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.794091673059897, 'Total loss': 0.794091673059897} | train loss {'Reaction outcome loss': 0.8273597590384945, 'Total loss': 0.8273597590384945}
2022-11-18 00:59:21,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:21,927 INFO:     Epoch: 27
2022-11-18 00:59:22,717 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7983788251876831, 'Total loss': 0.7983788251876831} | train loss {'Reaction outcome loss': 0.8280114149374347, 'Total loss': 0.8280114149374347}
2022-11-18 00:59:22,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:22,717 INFO:     Epoch: 28
2022-11-18 00:59:23,508 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7997322068973021, 'Total loss': 0.7997322068973021} | train loss {'Reaction outcome loss': 0.8329833945439707, 'Total loss': 0.8329833945439707}
2022-11-18 00:59:23,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:23,509 INFO:     Epoch: 29
2022-11-18 00:59:24,334 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8026735193350099, 'Total loss': 0.8026735193350099} | train loss {'Reaction outcome loss': 0.830764812447371, 'Total loss': 0.830764812447371}
2022-11-18 00:59:24,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:24,334 INFO:     Epoch: 30
2022-11-18 00:59:25,135 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7993121973492883, 'Total loss': 0.7993121973492883} | train loss {'Reaction outcome loss': 0.8271031127341332, 'Total loss': 0.8271031127341332}
2022-11-18 00:59:25,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:25,137 INFO:     Epoch: 31
2022-11-18 00:59:25,986 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8125868297436021, 'Total loss': 0.8125868297436021} | train loss {'Reaction outcome loss': 0.8277139116919809, 'Total loss': 0.8277139116919809}
2022-11-18 00:59:25,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:25,986 INFO:     Epoch: 32
2022-11-18 00:59:26,752 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8067857379263098, 'Total loss': 0.8067857379263098} | train loss {'Reaction outcome loss': 0.8321375831240608, 'Total loss': 0.8321375831240608}
2022-11-18 00:59:26,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:26,753 INFO:     Epoch: 33
2022-11-18 00:59:27,567 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7943363311615858, 'Total loss': 0.7943363311615858} | train loss {'Reaction outcome loss': 0.8302908045870643, 'Total loss': 0.8302908045870643}
2022-11-18 00:59:27,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:27,567 INFO:     Epoch: 34
2022-11-18 00:59:28,375 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7923629283905029, 'Total loss': 0.7923629283905029} | train loss {'Reaction outcome loss': 0.82984045916988, 'Total loss': 0.82984045916988}
2022-11-18 00:59:28,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:28,375 INFO:     Epoch: 35
2022-11-18 00:59:29,148 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7973413318395615, 'Total loss': 0.7973413318395615} | train loss {'Reaction outcome loss': 0.8247748564087576, 'Total loss': 0.8247748564087576}
2022-11-18 00:59:29,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:29,148 INFO:     Epoch: 36
2022-11-18 00:59:29,969 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7926839766177264, 'Total loss': 0.7926839766177264} | train loss {'Reaction outcome loss': 0.8292622533777068, 'Total loss': 0.8292622533777068}
2022-11-18 00:59:29,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:29,969 INFO:     Epoch: 37
2022-11-18 00:59:30,758 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7940118983387947, 'Total loss': 0.7940118983387947} | train loss {'Reaction outcome loss': 0.8245912344465333, 'Total loss': 0.8245912344465333}
2022-11-18 00:59:30,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:30,758 INFO:     Epoch: 38
2022-11-18 00:59:31,576 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7970626211979173, 'Total loss': 0.7970626211979173} | train loss {'Reaction outcome loss': 0.8290232224089484, 'Total loss': 0.8290232224089484}
2022-11-18 00:59:31,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:31,577 INFO:     Epoch: 39
2022-11-18 00:59:32,405 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8025462329387665, 'Total loss': 0.8025462329387665} | train loss {'Reaction outcome loss': 0.8277967831780834, 'Total loss': 0.8277967831780834}
2022-11-18 00:59:32,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:32,405 INFO:     Epoch: 40
2022-11-18 00:59:33,237 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7898762591860511, 'Total loss': 0.7898762591860511} | train loss {'Reaction outcome loss': 0.8279417337429139, 'Total loss': 0.8279417337429139}
2022-11-18 00:59:33,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:33,238 INFO:     Epoch: 41
2022-11-18 00:59:34,049 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8100261241197586, 'Total loss': 0.8100261241197586} | train loss {'Reaction outcome loss': 0.8237404061421272, 'Total loss': 0.8237404061421272}
2022-11-18 00:59:34,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:34,049 INFO:     Epoch: 42
2022-11-18 00:59:34,853 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8103166073560715, 'Total loss': 0.8103166073560715} | train loss {'Reaction outcome loss': 0.8293899278486928, 'Total loss': 0.8293899278486928}
2022-11-18 00:59:34,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:34,854 INFO:     Epoch: 43
2022-11-18 00:59:35,663 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7862355742942203, 'Total loss': 0.7862355742942203} | train loss {'Reaction outcome loss': 0.8279543830262076, 'Total loss': 0.8279543830262076}
2022-11-18 00:59:35,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:35,663 INFO:     Epoch: 44
2022-11-18 00:59:36,478 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8010309921069578, 'Total loss': 0.8010309921069578} | train loss {'Reaction outcome loss': 0.8242612950984509, 'Total loss': 0.8242612950984509}
2022-11-18 00:59:36,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:36,479 INFO:     Epoch: 45
2022-11-18 00:59:37,304 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7904553562402725, 'Total loss': 0.7904553562402725} | train loss {'Reaction outcome loss': 0.8233973014979593, 'Total loss': 0.8233973014979593}
2022-11-18 00:59:37,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:37,305 INFO:     Epoch: 46
2022-11-18 00:59:38,113 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8077145279808478, 'Total loss': 0.8077145279808478} | train loss {'Reaction outcome loss': 0.8306713360211542, 'Total loss': 0.8306713360211542}
2022-11-18 00:59:38,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:38,114 INFO:     Epoch: 47
2022-11-18 00:59:38,883 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8057894327423789, 'Total loss': 0.8057894327423789} | train loss {'Reaction outcome loss': 0.8270452712332049, 'Total loss': 0.8270452712332049}
2022-11-18 00:59:38,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:38,883 INFO:     Epoch: 48
2022-11-18 00:59:39,678 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8242197795347734, 'Total loss': 0.8242197795347734} | train loss {'Reaction outcome loss': 0.8252285913594307, 'Total loss': 0.8252285913594307}
2022-11-18 00:59:39,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:39,679 INFO:     Epoch: 49
2022-11-18 00:59:40,504 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7923846515742216, 'Total loss': 0.7923846515742216} | train loss {'Reaction outcome loss': 0.8262285417126071, 'Total loss': 0.8262285417126071}
2022-11-18 00:59:40,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:40,504 INFO:     Epoch: 50
2022-11-18 00:59:41,321 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7901165702126243, 'Total loss': 0.7901165702126243} | train loss {'Reaction outcome loss': 0.825909331320755, 'Total loss': 0.825909331320755}
2022-11-18 00:59:41,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:41,321 INFO:     Epoch: 51
2022-11-18 00:59:42,149 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7880121943625537, 'Total loss': 0.7880121943625537} | train loss {'Reaction outcome loss': 0.8258699200326397, 'Total loss': 0.8258699200326397}
2022-11-18 00:59:42,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:42,150 INFO:     Epoch: 52
2022-11-18 00:59:42,954 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8035277426242828, 'Total loss': 0.8035277426242828} | train loss {'Reaction outcome loss': 0.8235922190210512, 'Total loss': 0.8235922190210512}
2022-11-18 00:59:42,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:42,954 INFO:     Epoch: 53
2022-11-18 00:59:43,760 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7858606407588179, 'Total loss': 0.7858606407588179} | train loss {'Reaction outcome loss': 0.8264511693869868, 'Total loss': 0.8264511693869868}
2022-11-18 00:59:43,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:43,761 INFO:     Epoch: 54
2022-11-18 00:59:44,540 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7969968461177566, 'Total loss': 0.7969968461177566} | train loss {'Reaction outcome loss': 0.8280105138978651, 'Total loss': 0.8280105138978651}
2022-11-18 00:59:44,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:44,541 INFO:     Epoch: 55
2022-11-18 00:59:45,357 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7974165434187109, 'Total loss': 0.7974165434187109} | train loss {'Reaction outcome loss': 0.8276749720736858, 'Total loss': 0.8276749720736858}
2022-11-18 00:59:45,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:45,357 INFO:     Epoch: 56
2022-11-18 00:59:46,168 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7878969352353703, 'Total loss': 0.7878969352353703} | train loss {'Reaction outcome loss': 0.8240105700829337, 'Total loss': 0.8240105700829337}
2022-11-18 00:59:46,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:46,168 INFO:     Epoch: 57
2022-11-18 00:59:46,963 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.795502399856394, 'Total loss': 0.795502399856394} | train loss {'Reaction outcome loss': 0.8259415296056578, 'Total loss': 0.8259415296056578}
2022-11-18 00:59:46,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:46,964 INFO:     Epoch: 58
2022-11-18 00:59:47,752 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7888319973241199, 'Total loss': 0.7888319973241199} | train loss {'Reaction outcome loss': 0.8241988224608283, 'Total loss': 0.8241988224608283}
2022-11-18 00:59:47,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:47,752 INFO:     Epoch: 59
2022-11-18 00:59:48,587 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.793843309987675, 'Total loss': 0.793843309987675} | train loss {'Reaction outcome loss': 0.8251836692854282, 'Total loss': 0.8251836692854282}
2022-11-18 00:59:48,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:48,587 INFO:     Epoch: 60
2022-11-18 00:59:49,419 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7988790625875647, 'Total loss': 0.7988790625875647} | train loss {'Reaction outcome loss': 0.8255744656968501, 'Total loss': 0.8255744656968501}
2022-11-18 00:59:49,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:49,419 INFO:     Epoch: 61
2022-11-18 00:59:50,259 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7828250791538846, 'Total loss': 0.7828250791538846} | train loss {'Reaction outcome loss': 0.8241784091918699, 'Total loss': 0.8241784091918699}
2022-11-18 00:59:50,259 INFO:     Found new best model at epoch 61
2022-11-18 00:59:50,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:50,260 INFO:     Epoch: 62
2022-11-18 00:59:51,074 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8031764782287858, 'Total loss': 0.8031764782287858} | train loss {'Reaction outcome loss': 0.8261274820373904, 'Total loss': 0.8261274820373904}
2022-11-18 00:59:51,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:51,074 INFO:     Epoch: 63
2022-11-18 00:59:51,878 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8016016293655742, 'Total loss': 0.8016016293655742} | train loss {'Reaction outcome loss': 0.8228888952684018, 'Total loss': 0.8228888952684018}
2022-11-18 00:59:51,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:51,878 INFO:     Epoch: 64
2022-11-18 00:59:52,691 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7908564386042681, 'Total loss': 0.7908564386042681} | train loss {'Reaction outcome loss': 0.8267489197033067, 'Total loss': 0.8267489197033067}
2022-11-18 00:59:52,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:52,693 INFO:     Epoch: 65
2022-11-18 00:59:53,480 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7883140763098543, 'Total loss': 0.7883140763098543} | train loss {'Reaction outcome loss': 0.8222689012125615, 'Total loss': 0.8222689012125615}
2022-11-18 00:59:53,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:53,481 INFO:     Epoch: 66
2022-11-18 00:59:54,298 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7889240275729786, 'Total loss': 0.7889240275729786} | train loss {'Reaction outcome loss': 0.8244561789737593, 'Total loss': 0.8244561789737593}
2022-11-18 00:59:54,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:54,298 INFO:     Epoch: 67
2022-11-18 00:59:55,114 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7951704412698746, 'Total loss': 0.7951704412698746} | train loss {'Reaction outcome loss': 0.8292536888151399, 'Total loss': 0.8292536888151399}
2022-11-18 00:59:55,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:55,114 INFO:     Epoch: 68
2022-11-18 00:59:55,915 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7910491438074545, 'Total loss': 0.7910491438074545} | train loss {'Reaction outcome loss': 0.8251583568992154, 'Total loss': 0.8251583568992154}
2022-11-18 00:59:55,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:55,917 INFO:     Epoch: 69
2022-11-18 00:59:56,712 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.802809056233276, 'Total loss': 0.802809056233276} | train loss {'Reaction outcome loss': 0.8282445779731197, 'Total loss': 0.8282445779731197}
2022-11-18 00:59:56,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:56,712 INFO:     Epoch: 70
2022-11-18 00:59:57,554 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8025009137662974, 'Total loss': 0.8025009137662974} | train loss {'Reaction outcome loss': 0.825452345994211, 'Total loss': 0.825452345994211}
2022-11-18 00:59:57,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:57,554 INFO:     Epoch: 71
2022-11-18 00:59:58,360 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7962688959457658, 'Total loss': 0.7962688959457658} | train loss {'Reaction outcome loss': 0.8271881376783694, 'Total loss': 0.8271881376783694}
2022-11-18 00:59:58,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:58,360 INFO:     Epoch: 72
2022-11-18 00:59:59,193 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.793996617875316, 'Total loss': 0.793996617875316} | train loss {'Reaction outcome loss': 0.8225364931408436, 'Total loss': 0.8225364931408436}
2022-11-18 00:59:59,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 00:59:59,193 INFO:     Epoch: 73
2022-11-18 01:00:00,029 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.791463355449113, 'Total loss': 0.791463355449113} | train loss {'Reaction outcome loss': 0.8231021182070817, 'Total loss': 0.8231021182070817}
2022-11-18 01:00:00,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:00,030 INFO:     Epoch: 74
2022-11-18 01:00:00,825 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8096782483837821, 'Total loss': 0.8096782483837821} | train loss {'Reaction outcome loss': 0.8233244404677422, 'Total loss': 0.8233244404677422}
2022-11-18 01:00:00,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:00,826 INFO:     Epoch: 75
2022-11-18 01:00:01,629 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7848250337622382, 'Total loss': 0.7848250337622382} | train loss {'Reaction outcome loss': 0.8252948833809745, 'Total loss': 0.8252948833809745}
2022-11-18 01:00:01,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:01,630 INFO:     Epoch: 76
2022-11-18 01:00:02,428 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7977817383679476, 'Total loss': 0.7977817383679476} | train loss {'Reaction outcome loss': 0.8257288621558297, 'Total loss': 0.8257288621558297}
2022-11-18 01:00:02,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:02,429 INFO:     Epoch: 77
2022-11-18 01:00:03,227 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7881550897251476, 'Total loss': 0.7881550897251476} | train loss {'Reaction outcome loss': 0.8243814965169276, 'Total loss': 0.8243814965169276}
2022-11-18 01:00:03,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:03,227 INFO:     Epoch: 78
2022-11-18 01:00:04,013 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.792505910450762, 'Total loss': 0.792505910450762} | train loss {'Reaction outcome loss': 0.8251341073022734, 'Total loss': 0.8251341073022734}
2022-11-18 01:00:04,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:04,013 INFO:     Epoch: 79
2022-11-18 01:00:04,817 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7943317314440553, 'Total loss': 0.7943317314440553} | train loss {'Reaction outcome loss': 0.833518860681403, 'Total loss': 0.833518860681403}
2022-11-18 01:00:04,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:04,817 INFO:     Epoch: 80
2022-11-18 01:00:05,628 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8362087946046483, 'Total loss': 0.8362087946046483} | train loss {'Reaction outcome loss': 0.8232893917349077, 'Total loss': 0.8232893917349077}
2022-11-18 01:00:05,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:05,629 INFO:     Epoch: 81
2022-11-18 01:00:06,419 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7788180742751468, 'Total loss': 0.7788180742751468} | train loss {'Reaction outcome loss': 0.824090130747326, 'Total loss': 0.824090130747326}
2022-11-18 01:00:06,419 INFO:     Found new best model at epoch 81
2022-11-18 01:00:06,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:06,420 INFO:     Epoch: 82
2022-11-18 01:00:07,206 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7950026210058819, 'Total loss': 0.7950026210058819} | train loss {'Reaction outcome loss': 0.8239164289928251, 'Total loss': 0.8239164289928251}
2022-11-18 01:00:07,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:07,206 INFO:     Epoch: 83
2022-11-18 01:00:07,995 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7784955074841325, 'Total loss': 0.7784955074841325} | train loss {'Reaction outcome loss': 0.8255817693087363, 'Total loss': 0.8255817693087363}
2022-11-18 01:00:07,995 INFO:     Found new best model at epoch 83
2022-11-18 01:00:07,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:07,996 INFO:     Epoch: 84
2022-11-18 01:00:08,814 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8002105937762694, 'Total loss': 0.8002105937762694} | train loss {'Reaction outcome loss': 0.8314300024461362, 'Total loss': 0.8314300024461362}
2022-11-18 01:00:08,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:08,815 INFO:     Epoch: 85
2022-11-18 01:00:09,612 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7878174287351695, 'Total loss': 0.7878174287351695} | train loss {'Reaction outcome loss': 0.8269890516756042, 'Total loss': 0.8269890516756042}
2022-11-18 01:00:09,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:09,612 INFO:     Epoch: 86
2022-11-18 01:00:10,411 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7983509376645088, 'Total loss': 0.7983509376645088} | train loss {'Reaction outcome loss': 0.8246438493050875, 'Total loss': 0.8246438493050875}
2022-11-18 01:00:10,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:10,411 INFO:     Epoch: 87
2022-11-18 01:00:11,216 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8014451841061766, 'Total loss': 0.8014451841061766} | train loss {'Reaction outcome loss': 0.8269529489259566, 'Total loss': 0.8269529489259566}
2022-11-18 01:00:11,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:11,216 INFO:     Epoch: 88
2022-11-18 01:00:12,008 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.799545138397, 'Total loss': 0.799545138397} | train loss {'Reaction outcome loss': 0.8227365004920191, 'Total loss': 0.8227365004920191}
2022-11-18 01:00:12,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:12,008 INFO:     Epoch: 89
2022-11-18 01:00:12,804 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7998888492584229, 'Total loss': 0.7998888492584229} | train loss {'Reaction outcome loss': 0.8261363669749229, 'Total loss': 0.8261363669749229}
2022-11-18 01:00:12,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:12,804 INFO:     Epoch: 90
2022-11-18 01:00:13,586 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7904925353147767, 'Total loss': 0.7904925353147767} | train loss {'Reaction outcome loss': 0.821843289319546, 'Total loss': 0.821843289319546}
2022-11-18 01:00:13,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:13,586 INFO:     Epoch: 91
2022-11-18 01:00:14,368 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7859219475225969, 'Total loss': 0.7859219475225969} | train loss {'Reaction outcome loss': 0.8219659983390762, 'Total loss': 0.8219659983390762}
2022-11-18 01:00:14,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:14,368 INFO:     Epoch: 92
2022-11-18 01:00:15,183 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7887030636722391, 'Total loss': 0.7887030636722391} | train loss {'Reaction outcome loss': 0.82490472699846, 'Total loss': 0.82490472699846}
2022-11-18 01:00:15,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:15,184 INFO:     Epoch: 93
2022-11-18 01:00:15,943 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7974994087761099, 'Total loss': 0.7974994087761099} | train loss {'Reaction outcome loss': 0.8256988488137722, 'Total loss': 0.8256988488137722}
2022-11-18 01:00:15,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:15,944 INFO:     Epoch: 94
2022-11-18 01:00:16,731 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7958385822447863, 'Total loss': 0.7958385822447863} | train loss {'Reaction outcome loss': 0.8256551495963528, 'Total loss': 0.8256551495963528}
2022-11-18 01:00:16,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:16,731 INFO:     Epoch: 95
2022-11-18 01:00:17,499 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7823805355212905, 'Total loss': 0.7823805355212905} | train loss {'Reaction outcome loss': 0.8268812924863831, 'Total loss': 0.8268812924863831}
2022-11-18 01:00:17,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:17,499 INFO:     Epoch: 96
2022-11-18 01:00:18,292 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7905650897459551, 'Total loss': 0.7905650897459551} | train loss {'Reaction outcome loss': 0.8235597647726536, 'Total loss': 0.8235597647726536}
2022-11-18 01:00:18,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:18,292 INFO:     Epoch: 97
2022-11-18 01:00:19,081 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7935834933410991, 'Total loss': 0.7935834933410991} | train loss {'Reaction outcome loss': 0.8313236570646686, 'Total loss': 0.8313236570646686}
2022-11-18 01:00:19,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:19,082 INFO:     Epoch: 98
2022-11-18 01:00:19,870 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7916336425326087, 'Total loss': 0.7916336425326087} | train loss {'Reaction outcome loss': 0.8253488325543942, 'Total loss': 0.8253488325543942}
2022-11-18 01:00:19,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:19,870 INFO:     Epoch: 99
2022-11-18 01:00:20,636 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7960309609770775, 'Total loss': 0.7960309609770775} | train loss {'Reaction outcome loss': 0.8254502574282307, 'Total loss': 0.8254502574282307}
2022-11-18 01:00:20,637 INFO:     Best model found after epoch 84 of 100.
2022-11-18 01:00:20,637 INFO:   Done with stage: TRAINING
2022-11-18 01:00:20,637 INFO:   Starting stage: EVALUATION
2022-11-18 01:00:20,755 INFO:   Done with stage: EVALUATION
2022-11-18 01:00:20,755 INFO:   Leaving out SEQ value Fold_5
2022-11-18 01:00:20,768 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:00:20,768 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:00:21,438 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:00:21,438 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:00:21,509 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:00:21,509 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:00:21,509 INFO:     No hyperparam tuning for this model
2022-11-18 01:00:21,509 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:00:21,509 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:00:21,510 INFO:     None feature selector for col prot
2022-11-18 01:00:21,510 INFO:     None feature selector for col prot
2022-11-18 01:00:21,510 INFO:     None feature selector for col prot
2022-11-18 01:00:21,511 INFO:     None feature selector for col chem
2022-11-18 01:00:21,511 INFO:     None feature selector for col chem
2022-11-18 01:00:21,511 INFO:     None feature selector for col chem
2022-11-18 01:00:21,511 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:00:21,511 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:00:21,513 INFO:     Number of params in model 168571
2022-11-18 01:00:21,516 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:00:21,516 INFO:   Starting stage: TRAINING
2022-11-18 01:00:21,574 INFO:     Val loss before train {'Reaction outcome loss': 1.044143409891562, 'Total loss': 1.044143409891562}
2022-11-18 01:00:21,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:21,574 INFO:     Epoch: 0
2022-11-18 01:00:22,344 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8595078133723952, 'Total loss': 0.8595078133723952} | train loss {'Reaction outcome loss': 0.873056769401197, 'Total loss': 0.873056769401197}
2022-11-18 01:00:22,344 INFO:     Found new best model at epoch 0
2022-11-18 01:00:22,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:22,345 INFO:     Epoch: 1
2022-11-18 01:00:23,124 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8772442516955462, 'Total loss': 0.8772442516955462} | train loss {'Reaction outcome loss': 0.8363545180754623, 'Total loss': 0.8363545180754623}
2022-11-18 01:00:23,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:23,125 INFO:     Epoch: 2
2022-11-18 01:00:23,912 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8815404623746872, 'Total loss': 0.8815404623746872} | train loss {'Reaction outcome loss': 0.8391060785726014, 'Total loss': 0.8391060785726014}
2022-11-18 01:00:23,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:23,912 INFO:     Epoch: 3
2022-11-18 01:00:24,673 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.852790580554442, 'Total loss': 0.852790580554442} | train loss {'Reaction outcome loss': 0.8419985048442717, 'Total loss': 0.8419985048442717}
2022-11-18 01:00:24,674 INFO:     Found new best model at epoch 3
2022-11-18 01:00:24,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:24,674 INFO:     Epoch: 4
2022-11-18 01:00:25,428 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8445655412294648, 'Total loss': 0.8445655412294648} | train loss {'Reaction outcome loss': 0.8289098676882292, 'Total loss': 0.8289098676882292}
2022-11-18 01:00:25,428 INFO:     Found new best model at epoch 4
2022-11-18 01:00:25,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:25,429 INFO:     Epoch: 5
2022-11-18 01:00:26,217 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8396207175471566, 'Total loss': 0.8396207175471566} | train loss {'Reaction outcome loss': 0.8343226708139968, 'Total loss': 0.8343226708139968}
2022-11-18 01:00:26,217 INFO:     Found new best model at epoch 5
2022-11-18 01:00:26,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:26,218 INFO:     Epoch: 6
2022-11-18 01:00:27,011 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8722091059793126, 'Total loss': 0.8722091059793126} | train loss {'Reaction outcome loss': 0.8361109226097462, 'Total loss': 0.8361109226097462}
2022-11-18 01:00:27,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:27,013 INFO:     Epoch: 7
2022-11-18 01:00:27,796 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8501125147396867, 'Total loss': 0.8501125147396867} | train loss {'Reaction outcome loss': 0.8201256204351239, 'Total loss': 0.8201256204351239}
2022-11-18 01:00:27,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:27,797 INFO:     Epoch: 8
2022-11-18 01:00:28,574 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.847550277682868, 'Total loss': 0.847550277682868} | train loss {'Reaction outcome loss': 0.8263170293226898, 'Total loss': 0.8263170293226898}
2022-11-18 01:00:28,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:28,574 INFO:     Epoch: 9
2022-11-18 01:00:29,328 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8233311799439517, 'Total loss': 0.8233311799439517} | train loss {'Reaction outcome loss': 0.8247007803637006, 'Total loss': 0.8247007803637006}
2022-11-18 01:00:29,328 INFO:     Found new best model at epoch 9
2022-11-18 01:00:29,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:29,329 INFO:     Epoch: 10
2022-11-18 01:00:30,101 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8585834090005268, 'Total loss': 0.8585834090005268} | train loss {'Reaction outcome loss': 0.8156226818498812, 'Total loss': 0.8156226818498812}
2022-11-18 01:00:30,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:30,101 INFO:     Epoch: 11
2022-11-18 01:00:30,881 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.840233101086183, 'Total loss': 0.840233101086183} | train loss {'Reaction outcome loss': 0.8179839166099967, 'Total loss': 0.8179839166099967}
2022-11-18 01:00:30,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:30,882 INFO:     Epoch: 12
2022-11-18 01:00:31,655 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8522746976126324, 'Total loss': 0.8522746976126324} | train loss {'Reaction outcome loss': 0.8155323616285556, 'Total loss': 0.8155323616285556}
2022-11-18 01:00:31,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:31,655 INFO:     Epoch: 13
2022-11-18 01:00:32,434 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8636924570257013, 'Total loss': 0.8636924570257013} | train loss {'Reaction outcome loss': 0.8097061356793531, 'Total loss': 0.8097061356793531}
2022-11-18 01:00:32,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:32,434 INFO:     Epoch: 14
2022-11-18 01:00:33,224 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8270319869572466, 'Total loss': 0.8270319869572466} | train loss {'Reaction outcome loss': 0.8167499739390153, 'Total loss': 0.8167499739390153}
2022-11-18 01:00:33,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:33,225 INFO:     Epoch: 15
2022-11-18 01:00:33,993 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.829068579457023, 'Total loss': 0.829068579457023} | train loss {'Reaction outcome loss': 0.8152991220174048, 'Total loss': 0.8152991220174048}
2022-11-18 01:00:33,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:33,994 INFO:     Epoch: 16
2022-11-18 01:00:34,757 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8560861572623253, 'Total loss': 0.8560861572623253} | train loss {'Reaction outcome loss': 0.8128955597095644, 'Total loss': 0.8128955597095644}
2022-11-18 01:00:34,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:34,758 INFO:     Epoch: 17
2022-11-18 01:00:35,528 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8307447724721648, 'Total loss': 0.8307447724721648} | train loss {'Reaction outcome loss': 0.818993187143735, 'Total loss': 0.818993187143735}
2022-11-18 01:00:35,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:35,528 INFO:     Epoch: 18
2022-11-18 01:00:36,290 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8398226580836556, 'Total loss': 0.8398226580836556} | train loss {'Reaction outcome loss': 0.8140684385531345, 'Total loss': 0.8140684385531345}
2022-11-18 01:00:36,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:36,290 INFO:     Epoch: 19
2022-11-18 01:00:37,057 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.830341555855491, 'Total loss': 0.830341555855491} | train loss {'Reaction outcome loss': 0.8169458491599512, 'Total loss': 0.8169458491599512}
2022-11-18 01:00:37,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:37,058 INFO:     Epoch: 20
2022-11-18 01:00:37,827 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8634969368577003, 'Total loss': 0.8634969368577003} | train loss {'Reaction outcome loss': 0.8123793384203544, 'Total loss': 0.8123793384203544}
2022-11-18 01:00:37,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:37,827 INFO:     Epoch: 21
2022-11-18 01:00:38,607 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8371417386965319, 'Total loss': 0.8371417386965319} | train loss {'Reaction outcome loss': 0.815304093515342, 'Total loss': 0.815304093515342}
2022-11-18 01:00:38,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:38,608 INFO:     Epoch: 22
2022-11-18 01:00:39,381 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8249428028410132, 'Total loss': 0.8249428028410132} | train loss {'Reaction outcome loss': 0.8156624767884069, 'Total loss': 0.8156624767884069}
2022-11-18 01:00:39,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:39,382 INFO:     Epoch: 23
2022-11-18 01:00:40,166 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8305953564968976, 'Total loss': 0.8305953564968976} | train loss {'Reaction outcome loss': 0.8126409190145099, 'Total loss': 0.8126409190145099}
2022-11-18 01:00:40,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:40,166 INFO:     Epoch: 24
2022-11-18 01:00:40,953 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8364603573625738, 'Total loss': 0.8364603573625738} | train loss {'Reaction outcome loss': 0.8141714020779258, 'Total loss': 0.8141714020779258}
2022-11-18 01:00:40,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:40,953 INFO:     Epoch: 25
2022-11-18 01:00:41,725 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.830682092092254, 'Total loss': 0.830682092092254} | train loss {'Reaction outcome loss': 0.8212426520793544, 'Total loss': 0.8212426520793544}
2022-11-18 01:00:41,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:41,725 INFO:     Epoch: 26
2022-11-18 01:00:42,525 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8328185697848146, 'Total loss': 0.8328185697848146} | train loss {'Reaction outcome loss': 0.8138731135289196, 'Total loss': 0.8138731135289196}
2022-11-18 01:00:42,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:42,525 INFO:     Epoch: 27
2022-11-18 01:00:43,366 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8365145020864226, 'Total loss': 0.8365145020864226} | train loss {'Reaction outcome loss': 0.8150719346908423, 'Total loss': 0.8150719346908423}
2022-11-18 01:00:43,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:43,366 INFO:     Epoch: 28
2022-11-18 01:00:44,165 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.825966591862115, 'Total loss': 0.825966591862115} | train loss {'Reaction outcome loss': 0.8084271884625137, 'Total loss': 0.8084271884625137}
2022-11-18 01:00:44,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:44,165 INFO:     Epoch: 29
2022-11-18 01:00:44,951 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8381232565099542, 'Total loss': 0.8381232565099542} | train loss {'Reaction outcome loss': 0.8115538409364368, 'Total loss': 0.8115538409364368}
2022-11-18 01:00:44,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:44,951 INFO:     Epoch: 30
2022-11-18 01:00:45,759 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8287251009182497, 'Total loss': 0.8287251009182497} | train loss {'Reaction outcome loss': 0.8213473698388227, 'Total loss': 0.8213473698388227}
2022-11-18 01:00:45,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:45,760 INFO:     Epoch: 31
2022-11-18 01:00:46,564 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.829422992061485, 'Total loss': 0.829422992061485} | train loss {'Reaction outcome loss': 0.8153598618652174, 'Total loss': 0.8153598618652174}
2022-11-18 01:00:46,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:46,565 INFO:     Epoch: 32
2022-11-18 01:00:47,413 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8276214315132662, 'Total loss': 0.8276214315132662} | train loss {'Reaction outcome loss': 0.819911948944393, 'Total loss': 0.819911948944393}
2022-11-18 01:00:47,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:47,413 INFO:     Epoch: 33
2022-11-18 01:00:48,194 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8401574478908018, 'Total loss': 0.8401574478908018} | train loss {'Reaction outcome loss': 0.8086797985350073, 'Total loss': 0.8086797985350073}
2022-11-18 01:00:48,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:48,194 INFO:     Epoch: 34
2022-11-18 01:00:49,019 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8390872749415311, 'Total loss': 0.8390872749415311} | train loss {'Reaction outcome loss': 0.8092888773452898, 'Total loss': 0.8092888773452898}
2022-11-18 01:00:49,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:49,020 INFO:     Epoch: 35
2022-11-18 01:00:49,828 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8658037693663077, 'Total loss': 0.8658037693663077} | train loss {'Reaction outcome loss': 0.820393361422697, 'Total loss': 0.820393361422697}
2022-11-18 01:00:49,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:49,829 INFO:     Epoch: 36
2022-11-18 01:00:50,628 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8285402865572409, 'Total loss': 0.8285402865572409} | train loss {'Reaction outcome loss': 0.8155811081531077, 'Total loss': 0.8155811081531077}
2022-11-18 01:00:50,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:50,628 INFO:     Epoch: 37
2022-11-18 01:00:51,454 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8451206094839356, 'Total loss': 0.8451206094839356} | train loss {'Reaction outcome loss': 0.8114715833895603, 'Total loss': 0.8114715833895603}
2022-11-18 01:00:51,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:51,454 INFO:     Epoch: 38
2022-11-18 01:00:52,322 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8450991822914644, 'Total loss': 0.8450991822914644} | train loss {'Reaction outcome loss': 0.8103057668517958, 'Total loss': 0.8103057668517958}
2022-11-18 01:00:52,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:52,323 INFO:     Epoch: 39
2022-11-18 01:00:53,120 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8155176937580109, 'Total loss': 0.8155176937580109} | train loss {'Reaction outcome loss': 0.8159762485789867, 'Total loss': 0.8159762485789867}
2022-11-18 01:00:53,120 INFO:     Found new best model at epoch 39
2022-11-18 01:00:53,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:53,121 INFO:     Epoch: 40
2022-11-18 01:00:53,958 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.826857176694003, 'Total loss': 0.826857176694003} | train loss {'Reaction outcome loss': 0.8069002674779429, 'Total loss': 0.8069002674779429}
2022-11-18 01:00:53,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:53,959 INFO:     Epoch: 41
2022-11-18 01:00:54,773 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8249522522091866, 'Total loss': 0.8249522522091866} | train loss {'Reaction outcome loss': 0.8077296007741318, 'Total loss': 0.8077296007741318}
2022-11-18 01:00:54,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:54,774 INFO:     Epoch: 42
2022-11-18 01:00:55,576 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8208243216980587, 'Total loss': 0.8208243216980587} | train loss {'Reaction outcome loss': 0.8135349540575313, 'Total loss': 0.8135349540575313}
2022-11-18 01:00:55,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:55,577 INFO:     Epoch: 43
2022-11-18 01:00:56,388 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8380616998130624, 'Total loss': 0.8380616998130624} | train loss {'Reaction outcome loss': 0.8119353129554857, 'Total loss': 0.8119353129554857}
2022-11-18 01:00:56,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:56,389 INFO:     Epoch: 44
2022-11-18 01:00:57,194 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8265385241671042, 'Total loss': 0.8265385241671042} | train loss {'Reaction outcome loss': 0.8132965821727567, 'Total loss': 0.8132965821727567}
2022-11-18 01:00:57,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:57,194 INFO:     Epoch: 45
2022-11-18 01:00:57,980 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8345539217645471, 'Total loss': 0.8345539217645471} | train loss {'Reaction outcome loss': 0.8118414819119912, 'Total loss': 0.8118414819119912}
2022-11-18 01:00:57,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:57,982 INFO:     Epoch: 46
2022-11-18 01:00:58,752 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8541347533464432, 'Total loss': 0.8541347533464432} | train loss {'Reaction outcome loss': 0.8103292703869854, 'Total loss': 0.8103292703869854}
2022-11-18 01:00:58,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:58,752 INFO:     Epoch: 47
2022-11-18 01:00:59,551 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8373175988143141, 'Total loss': 0.8373175988143141} | train loss {'Reaction outcome loss': 0.8056126213085796, 'Total loss': 0.8056126213085796}
2022-11-18 01:00:59,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:00:59,551 INFO:     Epoch: 48
2022-11-18 01:01:00,377 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8330813653089784, 'Total loss': 0.8330813653089784} | train loss {'Reaction outcome loss': 0.810391057358097, 'Total loss': 0.810391057358097}
2022-11-18 01:01:00,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:00,377 INFO:     Epoch: 49
2022-11-18 01:01:01,191 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8215967118740082, 'Total loss': 0.8215967118740082} | train loss {'Reaction outcome loss': 0.8007249608937546, 'Total loss': 0.8007249608937546}
2022-11-18 01:01:01,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:01,192 INFO:     Epoch: 50
2022-11-18 01:01:02,042 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8456201912327246, 'Total loss': 0.8456201912327246} | train loss {'Reaction outcome loss': 0.8053170195573315, 'Total loss': 0.8053170195573315}
2022-11-18 01:01:02,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:02,042 INFO:     Epoch: 51
2022-11-18 01:01:02,881 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8423917130990461, 'Total loss': 0.8423917130990461} | train loss {'Reaction outcome loss': 0.8072667432805667, 'Total loss': 0.8072667432805667}
2022-11-18 01:01:02,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:02,881 INFO:     Epoch: 52
2022-11-18 01:01:03,665 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8244908154010773, 'Total loss': 0.8244908154010773} | train loss {'Reaction outcome loss': 0.8009042624942204, 'Total loss': 0.8009042624942204}
2022-11-18 01:01:03,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:03,665 INFO:     Epoch: 53
2022-11-18 01:01:04,462 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8424954123117707, 'Total loss': 0.8424954123117707} | train loss {'Reaction outcome loss': 0.8091086663215267, 'Total loss': 0.8091086663215267}
2022-11-18 01:01:04,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:04,463 INFO:     Epoch: 54
2022-11-18 01:01:05,274 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8352774889631704, 'Total loss': 0.8352774889631704} | train loss {'Reaction outcome loss': 0.810745475866534, 'Total loss': 0.810745475866534}
2022-11-18 01:01:05,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:05,274 INFO:     Epoch: 55
2022-11-18 01:01:06,125 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8321693783456628, 'Total loss': 0.8321693783456628} | train loss {'Reaction outcome loss': 0.8087954341400008, 'Total loss': 0.8087954341400008}
2022-11-18 01:01:06,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:06,125 INFO:     Epoch: 56
2022-11-18 01:01:06,902 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8291874954646284, 'Total loss': 0.8291874954646284} | train loss {'Reaction outcome loss': 0.8081851896607442, 'Total loss': 0.8081851896607442}
2022-11-18 01:01:06,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:06,902 INFO:     Epoch: 57
2022-11-18 01:01:07,680 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.823004733432423, 'Total loss': 0.823004733432423} | train loss {'Reaction outcome loss': 0.8082018747986087, 'Total loss': 0.8082018747986087}
2022-11-18 01:01:07,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:07,680 INFO:     Epoch: 58
2022-11-18 01:01:08,462 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8310396874492819, 'Total loss': 0.8310396874492819} | train loss {'Reaction outcome loss': 0.805794423529011, 'Total loss': 0.805794423529011}
2022-11-18 01:01:08,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:08,462 INFO:     Epoch: 59
2022-11-18 01:01:09,328 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8299104571342468, 'Total loss': 0.8299104571342468} | train loss {'Reaction outcome loss': 0.8074440462627874, 'Total loss': 0.8074440462627874}
2022-11-18 01:01:09,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:09,328 INFO:     Epoch: 60
2022-11-18 01:01:10,189 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8199702480977232, 'Total loss': 0.8199702480977232} | train loss {'Reaction outcome loss': 0.8105678354438982, 'Total loss': 0.8105678354438982}
2022-11-18 01:01:10,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:10,189 INFO:     Epoch: 61
2022-11-18 01:01:10,993 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8366323858499527, 'Total loss': 0.8366323858499527} | train loss {'Reaction outcome loss': 0.8108265018656187, 'Total loss': 0.8108265018656187}
2022-11-18 01:01:10,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:10,993 INFO:     Epoch: 62
2022-11-18 01:01:11,765 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8310314606536519, 'Total loss': 0.8310314606536519} | train loss {'Reaction outcome loss': 0.8089232774157273, 'Total loss': 0.8089232774157273}
2022-11-18 01:01:11,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:11,766 INFO:     Epoch: 63
2022-11-18 01:01:12,527 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8301137435165319, 'Total loss': 0.8301137435165319} | train loss {'Reaction outcome loss': 0.8061430502517021, 'Total loss': 0.8061430502517021}
2022-11-18 01:01:12,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:12,528 INFO:     Epoch: 64
2022-11-18 01:01:13,295 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.83570873466405, 'Total loss': 0.83570873466405} | train loss {'Reaction outcome loss': 0.8153539201026021, 'Total loss': 0.8153539201026021}
2022-11-18 01:01:13,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:13,296 INFO:     Epoch: 65
2022-11-18 01:01:14,093 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8222360597415403, 'Total loss': 0.8222360597415403} | train loss {'Reaction outcome loss': 0.8091009212167639, 'Total loss': 0.8091009212167639}
2022-11-18 01:01:14,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:14,094 INFO:     Epoch: 66
2022-11-18 01:01:14,863 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8164339864795859, 'Total loss': 0.8164339864795859} | train loss {'Reaction outcome loss': 0.810346973207798, 'Total loss': 0.810346973207798}
2022-11-18 01:01:14,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:14,864 INFO:     Epoch: 67
2022-11-18 01:01:15,644 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8343329558318312, 'Total loss': 0.8343329558318312} | train loss {'Reaction outcome loss': 0.8132860246698866, 'Total loss': 0.8132860246698866}
2022-11-18 01:01:15,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:15,644 INFO:     Epoch: 68
2022-11-18 01:01:16,437 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8430687466805632, 'Total loss': 0.8430687466805632} | train loss {'Reaction outcome loss': 0.8119365528286228, 'Total loss': 0.8119365528286228}
2022-11-18 01:01:16,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:16,437 INFO:     Epoch: 69
2022-11-18 01:01:17,211 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8207286569205198, 'Total loss': 0.8207286569205198} | train loss {'Reaction outcome loss': 0.8063189193666706, 'Total loss': 0.8063189193666706}
2022-11-18 01:01:17,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:17,212 INFO:     Epoch: 70
2022-11-18 01:01:17,999 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8336816850033674, 'Total loss': 0.8336816850033674} | train loss {'Reaction outcome loss': 0.8089713933255508, 'Total loss': 0.8089713933255508}
2022-11-18 01:01:17,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:17,999 INFO:     Epoch: 71
2022-11-18 01:01:18,794 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8223776410926472, 'Total loss': 0.8223776410926472} | train loss {'Reaction outcome loss': 0.8074681651495729, 'Total loss': 0.8074681651495729}
2022-11-18 01:01:18,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:18,794 INFO:     Epoch: 72
2022-11-18 01:01:19,572 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8380033441565253, 'Total loss': 0.8380033441565253} | train loss {'Reaction outcome loss': 0.8061531668732523, 'Total loss': 0.8061531668732523}
2022-11-18 01:01:19,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:19,573 INFO:     Epoch: 73
2022-11-18 01:01:20,340 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8203104829246347, 'Total loss': 0.8203104829246347} | train loss {'Reaction outcome loss': 0.8078199269378233, 'Total loss': 0.8078199269378233}
2022-11-18 01:01:20,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:20,340 INFO:     Epoch: 74
2022-11-18 01:01:21,143 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8208837272091345, 'Total loss': 0.8208837272091345} | train loss {'Reaction outcome loss': 0.8045475829528411, 'Total loss': 0.8045475829528411}
2022-11-18 01:01:21,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:21,143 INFO:     Epoch: 75
2022-11-18 01:01:21,912 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8267605345357548, 'Total loss': 0.8267605345357548} | train loss {'Reaction outcome loss': 0.8041363953337496, 'Total loss': 0.8041363953337496}
2022-11-18 01:01:21,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:21,912 INFO:     Epoch: 76
2022-11-18 01:01:22,704 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8165946494449269, 'Total loss': 0.8165946494449269} | train loss {'Reaction outcome loss': 0.8092758001586203, 'Total loss': 0.8092758001586203}
2022-11-18 01:01:22,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:22,704 INFO:     Epoch: 77
2022-11-18 01:01:23,498 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8203491792082787, 'Total loss': 0.8203491792082787} | train loss {'Reaction outcome loss': 0.8137560300981468, 'Total loss': 0.8137560300981468}
2022-11-18 01:01:23,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:23,498 INFO:     Epoch: 78
2022-11-18 01:01:24,267 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8424318852749738, 'Total loss': 0.8424318852749738} | train loss {'Reaction outcome loss': 0.8039483764031639, 'Total loss': 0.8039483764031639}
2022-11-18 01:01:24,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:24,267 INFO:     Epoch: 79
2022-11-18 01:01:25,044 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.856259593909437, 'Total loss': 0.856259593909437} | train loss {'Reaction outcome loss': 0.810647123738339, 'Total loss': 0.810647123738339}
2022-11-18 01:01:25,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:25,044 INFO:     Epoch: 80
2022-11-18 01:01:25,828 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8172514377669855, 'Total loss': 0.8172514377669855} | train loss {'Reaction outcome loss': 0.8089283320012122, 'Total loss': 0.8089283320012122}
2022-11-18 01:01:25,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:25,828 INFO:     Epoch: 81
2022-11-18 01:01:26,625 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8334078009832989, 'Total loss': 0.8334078009832989} | train loss {'Reaction outcome loss': 0.8020155526365829, 'Total loss': 0.8020155526365829}
2022-11-18 01:01:26,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:26,625 INFO:     Epoch: 82
2022-11-18 01:01:27,396 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8082364668900316, 'Total loss': 0.8082364668900316} | train loss {'Reaction outcome loss': 0.8096300318897495, 'Total loss': 0.8096300318897495}
2022-11-18 01:01:27,397 INFO:     Found new best model at epoch 82
2022-11-18 01:01:27,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:27,398 INFO:     Epoch: 83
2022-11-18 01:01:28,197 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8283377438783646, 'Total loss': 0.8283377438783646} | train loss {'Reaction outcome loss': 0.8044091709229627, 'Total loss': 0.8044091709229627}
2022-11-18 01:01:28,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:28,197 INFO:     Epoch: 84
2022-11-18 01:01:28,979 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8347186839038675, 'Total loss': 0.8347186839038675} | train loss {'Reaction outcome loss': 0.8098335000064208, 'Total loss': 0.8098335000064208}
2022-11-18 01:01:28,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:28,981 INFO:     Epoch: 85
2022-11-18 01:01:29,758 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8302580152045597, 'Total loss': 0.8302580152045597} | train loss {'Reaction outcome loss': 0.8042752791030204, 'Total loss': 0.8042752791030204}
2022-11-18 01:01:29,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:29,758 INFO:     Epoch: 86
2022-11-18 01:01:30,549 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.814158025113019, 'Total loss': 0.814158025113019} | train loss {'Reaction outcome loss': 0.8024717204966526, 'Total loss': 0.8024717204966526}
2022-11-18 01:01:30,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:30,549 INFO:     Epoch: 87
2022-11-18 01:01:31,348 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8571335409175266, 'Total loss': 0.8571335409175266} | train loss {'Reaction outcome loss': 0.8048446912031907, 'Total loss': 0.8048446912031907}
2022-11-18 01:01:31,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:31,348 INFO:     Epoch: 88
2022-11-18 01:01:32,140 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8194523101503198, 'Total loss': 0.8194523101503198} | train loss {'Reaction outcome loss': 0.8097423657714596, 'Total loss': 0.8097423657714596}
2022-11-18 01:01:32,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:32,140 INFO:     Epoch: 89
2022-11-18 01:01:32,917 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8325162394480272, 'Total loss': 0.8325162394480272} | train loss {'Reaction outcome loss': 0.8071980753890898, 'Total loss': 0.8071980753890898}
2022-11-18 01:01:32,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:32,917 INFO:     Epoch: 90
2022-11-18 01:01:33,694 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8223604431206529, 'Total loss': 0.8223604431206529} | train loss {'Reaction outcome loss': 0.8051511020312908, 'Total loss': 0.8051511020312908}
2022-11-18 01:01:33,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:33,695 INFO:     Epoch: 91
2022-11-18 01:01:34,471 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8379563689231873, 'Total loss': 0.8379563689231873} | train loss {'Reaction outcome loss': 0.8061458275385713, 'Total loss': 0.8061458275385713}
2022-11-18 01:01:34,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:34,472 INFO:     Epoch: 92
2022-11-18 01:01:35,283 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8386101817542856, 'Total loss': 0.8386101817542856} | train loss {'Reaction outcome loss': 0.8020179288740824, 'Total loss': 0.8020179288740824}
2022-11-18 01:01:35,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:35,284 INFO:     Epoch: 93
2022-11-18 01:01:36,054 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8335857994177125, 'Total loss': 0.8335857994177125} | train loss {'Reaction outcome loss': 0.8045604688677228, 'Total loss': 0.8045604688677228}
2022-11-18 01:01:36,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:36,055 INFO:     Epoch: 94
2022-11-18 01:01:36,875 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8126959502696991, 'Total loss': 0.8126959502696991} | train loss {'Reaction outcome loss': 0.7990660355822278, 'Total loss': 0.7990660355822278}
2022-11-18 01:01:36,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:36,875 INFO:     Epoch: 95
2022-11-18 01:01:37,647 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8130283619869839, 'Total loss': 0.8130283619869839} | train loss {'Reaction outcome loss': 0.8028375015024715, 'Total loss': 0.8028375015024715}
2022-11-18 01:01:37,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:37,647 INFO:     Epoch: 96
2022-11-18 01:01:38,449 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8136357732794501, 'Total loss': 0.8136357732794501} | train loss {'Reaction outcome loss': 0.8043220774364858, 'Total loss': 0.8043220774364858}
2022-11-18 01:01:38,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:38,449 INFO:     Epoch: 97
2022-11-18 01:01:39,229 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8378779549490322, 'Total loss': 0.8378779549490322} | train loss {'Reaction outcome loss': 0.810904734047801, 'Total loss': 0.810904734047801}
2022-11-18 01:01:39,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:39,229 INFO:     Epoch: 98
2022-11-18 01:01:40,002 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8178220594471152, 'Total loss': 0.8178220594471152} | train loss {'Reaction outcome loss': 0.8051642107094831, 'Total loss': 0.8051642107094831}
2022-11-18 01:01:40,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:40,003 INFO:     Epoch: 99
2022-11-18 01:01:40,811 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8378039300441742, 'Total loss': 0.8378039300441742} | train loss {'Reaction outcome loss': 0.8082509232677428, 'Total loss': 0.8082509232677428}
2022-11-18 01:01:40,812 INFO:     Best model found after epoch 83 of 100.
2022-11-18 01:01:40,812 INFO:   Done with stage: TRAINING
2022-11-18 01:01:40,812 INFO:   Starting stage: EVALUATION
2022-11-18 01:01:40,936 INFO:   Done with stage: EVALUATION
2022-11-18 01:01:40,936 INFO:   Leaving out SEQ value Fold_6
2022-11-18 01:01:40,949 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:01:40,950 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:01:41,621 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:01:41,621 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:01:41,692 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:01:41,692 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:01:41,692 INFO:     No hyperparam tuning for this model
2022-11-18 01:01:41,692 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:01:41,693 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:01:41,693 INFO:     None feature selector for col prot
2022-11-18 01:01:41,694 INFO:     None feature selector for col prot
2022-11-18 01:01:41,694 INFO:     None feature selector for col prot
2022-11-18 01:01:41,694 INFO:     None feature selector for col chem
2022-11-18 01:01:41,694 INFO:     None feature selector for col chem
2022-11-18 01:01:41,694 INFO:     None feature selector for col chem
2022-11-18 01:01:41,694 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:01:41,694 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:01:41,696 INFO:     Number of params in model 168571
2022-11-18 01:01:41,700 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:01:41,700 INFO:   Starting stage: TRAINING
2022-11-18 01:01:41,758 INFO:     Val loss before train {'Reaction outcome loss': 0.9656362343918193, 'Total loss': 0.9656362343918193}
2022-11-18 01:01:41,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:41,758 INFO:     Epoch: 0
2022-11-18 01:01:42,550 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.809104585512118, 'Total loss': 0.809104585512118} | train loss {'Reaction outcome loss': 0.8802398077903255, 'Total loss': 0.8802398077903255}
2022-11-18 01:01:42,550 INFO:     Found new best model at epoch 0
2022-11-18 01:01:42,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:42,551 INFO:     Epoch: 1
2022-11-18 01:01:43,346 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.832145897502249, 'Total loss': 0.832145897502249} | train loss {'Reaction outcome loss': 0.8555573174549688, 'Total loss': 0.8555573174549688}
2022-11-18 01:01:43,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:43,347 INFO:     Epoch: 2
2022-11-18 01:01:44,181 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7986758622256193, 'Total loss': 0.7986758622256193} | train loss {'Reaction outcome loss': 0.8530849491155916, 'Total loss': 0.8530849491155916}
2022-11-18 01:01:44,182 INFO:     Found new best model at epoch 2
2022-11-18 01:01:44,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:44,182 INFO:     Epoch: 3
2022-11-18 01:01:44,949 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7995445680889216, 'Total loss': 0.7995445680889216} | train loss {'Reaction outcome loss': 0.8437426468778041, 'Total loss': 0.8437426468778041}
2022-11-18 01:01:44,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:44,949 INFO:     Epoch: 4
2022-11-18 01:01:45,736 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8195411285216158, 'Total loss': 0.8195411285216158} | train loss {'Reaction outcome loss': 0.8402640246335538, 'Total loss': 0.8402640246335538}
2022-11-18 01:01:45,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:45,736 INFO:     Epoch: 5
2022-11-18 01:01:46,521 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8000881272283468, 'Total loss': 0.8000881272283468} | train loss {'Reaction outcome loss': 0.8406105164077974, 'Total loss': 0.8406105164077974}
2022-11-18 01:01:46,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:46,521 INFO:     Epoch: 6
2022-11-18 01:01:47,291 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7803017923777754, 'Total loss': 0.7803017923777754} | train loss {'Reaction outcome loss': 0.8366402822636789, 'Total loss': 0.8366402822636789}
2022-11-18 01:01:47,292 INFO:     Found new best model at epoch 6
2022-11-18 01:01:47,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:47,293 INFO:     Epoch: 7
2022-11-18 01:01:48,088 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7988326820460233, 'Total loss': 0.7988326820460233} | train loss {'Reaction outcome loss': 0.8340965938423911, 'Total loss': 0.8340965938423911}
2022-11-18 01:01:48,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:48,089 INFO:     Epoch: 8
2022-11-18 01:01:48,865 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7823534066026862, 'Total loss': 0.7823534066026862} | train loss {'Reaction outcome loss': 0.8316952786859004, 'Total loss': 0.8316952786859004}
2022-11-18 01:01:48,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:48,865 INFO:     Epoch: 9
2022-11-18 01:01:49,644 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7811185209588571, 'Total loss': 0.7811185209588571} | train loss {'Reaction outcome loss': 0.8276401861540733, 'Total loss': 0.8276401861540733}
2022-11-18 01:01:49,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:49,645 INFO:     Epoch: 10
2022-11-18 01:01:50,437 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7778399248014797, 'Total loss': 0.7778399248014797} | train loss {'Reaction outcome loss': 0.8244320973753929, 'Total loss': 0.8244320973753929}
2022-11-18 01:01:50,437 INFO:     Found new best model at epoch 10
2022-11-18 01:01:50,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:50,438 INFO:     Epoch: 11
2022-11-18 01:01:51,208 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7868422405286268, 'Total loss': 0.7868422405286268} | train loss {'Reaction outcome loss': 0.8225343283866683, 'Total loss': 0.8225343283866683}
2022-11-18 01:01:51,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:51,209 INFO:     Epoch: 12
2022-11-18 01:01:51,970 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7987731519070539, 'Total loss': 0.7987731519070539} | train loss {'Reaction outcome loss': 0.8236502920908313, 'Total loss': 0.8236502920908313}
2022-11-18 01:01:51,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:51,970 INFO:     Epoch: 13
2022-11-18 01:01:52,756 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7730461697686802, 'Total loss': 0.7730461697686802} | train loss {'Reaction outcome loss': 0.8250119082870022, 'Total loss': 0.8250119082870022}
2022-11-18 01:01:52,756 INFO:     Found new best model at epoch 13
2022-11-18 01:01:52,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:52,757 INFO:     Epoch: 14
2022-11-18 01:01:53,524 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7707953547889536, 'Total loss': 0.7707953547889536} | train loss {'Reaction outcome loss': 0.8271510042250156, 'Total loss': 0.8271510042250156}
2022-11-18 01:01:53,524 INFO:     Found new best model at epoch 14
2022-11-18 01:01:53,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:53,525 INFO:     Epoch: 15
2022-11-18 01:01:54,293 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.772567364979874, 'Total loss': 0.772567364979874} | train loss {'Reaction outcome loss': 0.8184052785077403, 'Total loss': 0.8184052785077403}
2022-11-18 01:01:54,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:54,293 INFO:     Epoch: 16
2022-11-18 01:01:55,058 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.830997580831701, 'Total loss': 0.830997580831701} | train loss {'Reaction outcome loss': 0.8180234611274735, 'Total loss': 0.8180234611274735}
2022-11-18 01:01:55,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:55,059 INFO:     Epoch: 17
2022-11-18 01:01:55,835 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7694603584029458, 'Total loss': 0.7694603584029458} | train loss {'Reaction outcome loss': 0.8239313264287287, 'Total loss': 0.8239313264287287}
2022-11-18 01:01:55,836 INFO:     Found new best model at epoch 17
2022-11-18 01:01:55,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:55,836 INFO:     Epoch: 18
2022-11-18 01:01:56,610 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7731336985122074, 'Total loss': 0.7731336985122074} | train loss {'Reaction outcome loss': 0.8248423521797503, 'Total loss': 0.8248423521797503}
2022-11-18 01:01:56,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:56,610 INFO:     Epoch: 19
2022-11-18 01:01:57,399 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7746945856647058, 'Total loss': 0.7746945856647058} | train loss {'Reaction outcome loss': 0.8215011407531077, 'Total loss': 0.8215011407531077}
2022-11-18 01:01:57,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:57,400 INFO:     Epoch: 20
2022-11-18 01:01:58,194 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7677500647577372, 'Total loss': 0.7677500647577372} | train loss {'Reaction outcome loss': 0.8168481056007647, 'Total loss': 0.8168481056007647}
2022-11-18 01:01:58,195 INFO:     Found new best model at epoch 20
2022-11-18 01:01:58,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:58,195 INFO:     Epoch: 21
2022-11-18 01:01:58,974 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7974964712153781, 'Total loss': 0.7974964712153781} | train loss {'Reaction outcome loss': 0.8238259985321953, 'Total loss': 0.8238259985321953}
2022-11-18 01:01:58,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:58,974 INFO:     Epoch: 22
2022-11-18 01:01:59,756 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7833984683860432, 'Total loss': 0.7833984683860432} | train loss {'Reaction outcome loss': 0.8129312214591811, 'Total loss': 0.8129312214591811}
2022-11-18 01:01:59,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:01:59,758 INFO:     Epoch: 23
2022-11-18 01:02:00,540 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7956252348693934, 'Total loss': 0.7956252348693934} | train loss {'Reaction outcome loss': 0.8138552911339267, 'Total loss': 0.8138552911339267}
2022-11-18 01:02:00,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:00,540 INFO:     Epoch: 24
2022-11-18 01:02:01,332 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7782855277711694, 'Total loss': 0.7782855277711694} | train loss {'Reaction outcome loss': 0.8144258254718396, 'Total loss': 0.8144258254718396}
2022-11-18 01:02:01,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:01,332 INFO:     Epoch: 25
2022-11-18 01:02:02,113 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7979710440744053, 'Total loss': 0.7979710440744053} | train loss {'Reaction outcome loss': 0.8124037928158238, 'Total loss': 0.8124037928158238}
2022-11-18 01:02:02,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:02,114 INFO:     Epoch: 26
2022-11-18 01:02:02,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7761219590902328, 'Total loss': 0.7761219590902328} | train loss {'Reaction outcome loss': 0.817675742891527, 'Total loss': 0.817675742891527}
2022-11-18 01:02:02,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:02,899 INFO:     Epoch: 27
2022-11-18 01:02:03,692 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7824924385005777, 'Total loss': 0.7824924385005777} | train loss {'Reaction outcome loss': 0.8164297618692921, 'Total loss': 0.8164297618692921}
2022-11-18 01:02:03,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:03,693 INFO:     Epoch: 28
2022-11-18 01:02:04,483 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7795142924243753, 'Total loss': 0.7795142924243753} | train loss {'Reaction outcome loss': 0.8170931202269369, 'Total loss': 0.8170931202269369}
2022-11-18 01:02:04,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:04,483 INFO:     Epoch: 29
2022-11-18 01:02:05,249 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7742428806695071, 'Total loss': 0.7742428806695071} | train loss {'Reaction outcome loss': 0.8180922612307533, 'Total loss': 0.8180922612307533}
2022-11-18 01:02:05,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:05,249 INFO:     Epoch: 30
2022-11-18 01:02:06,054 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7782775339755145, 'Total loss': 0.7782775339755145} | train loss {'Reaction outcome loss': 0.8175542641791606, 'Total loss': 0.8175542641791606}
2022-11-18 01:02:06,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:06,055 INFO:     Epoch: 31
2022-11-18 01:02:06,877 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7701000205495141, 'Total loss': 0.7701000205495141} | train loss {'Reaction outcome loss': 0.8178022942475734, 'Total loss': 0.8178022942475734}
2022-11-18 01:02:06,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:06,878 INFO:     Epoch: 32
2022-11-18 01:02:07,647 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7909086346626282, 'Total loss': 0.7909086346626282} | train loss {'Reaction outcome loss': 0.8157182913874427, 'Total loss': 0.8157182913874427}
2022-11-18 01:02:07,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:07,647 INFO:     Epoch: 33
2022-11-18 01:02:08,417 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7679196779023517, 'Total loss': 0.7679196779023517} | train loss {'Reaction outcome loss': 0.816129916017094, 'Total loss': 0.816129916017094}
2022-11-18 01:02:08,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:08,417 INFO:     Epoch: 34
2022-11-18 01:02:09,194 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7654157308014956, 'Total loss': 0.7654157308014956} | train loss {'Reaction outcome loss': 0.8142414716703277, 'Total loss': 0.8142414716703277}
2022-11-18 01:02:09,194 INFO:     Found new best model at epoch 34
2022-11-18 01:02:09,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:09,195 INFO:     Epoch: 35
2022-11-18 01:02:09,960 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7683657224882733, 'Total loss': 0.7683657224882733} | train loss {'Reaction outcome loss': 0.8100782609995334, 'Total loss': 0.8100782609995334}
2022-11-18 01:02:09,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:09,960 INFO:     Epoch: 36
2022-11-18 01:02:10,720 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7720980915156278, 'Total loss': 0.7720980915156278} | train loss {'Reaction outcome loss': 0.8155113171425558, 'Total loss': 0.8155113171425558}
2022-11-18 01:02:10,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:10,720 INFO:     Epoch: 37
2022-11-18 01:02:11,511 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7778425392779437, 'Total loss': 0.7778425392779437} | train loss {'Reaction outcome loss': 0.8155359081443279, 'Total loss': 0.8155359081443279}
2022-11-18 01:02:11,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:11,511 INFO:     Epoch: 38
2022-11-18 01:02:12,298 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7760156792673197, 'Total loss': 0.7760156792673197} | train loss {'Reaction outcome loss': 0.8130289804070227, 'Total loss': 0.8130289804070227}
2022-11-18 01:02:12,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:12,298 INFO:     Epoch: 39
2022-11-18 01:02:13,050 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7809320105747743, 'Total loss': 0.7809320105747743} | train loss {'Reaction outcome loss': 0.8139684566807363, 'Total loss': 0.8139684566807363}
2022-11-18 01:02:13,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:13,051 INFO:     Epoch: 40
2022-11-18 01:02:13,819 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7858629551800814, 'Total loss': 0.7858629551800814} | train loss {'Reaction outcome loss': 0.8145628368421909, 'Total loss': 0.8145628368421909}
2022-11-18 01:02:13,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:13,819 INFO:     Epoch: 41
2022-11-18 01:02:14,607 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7703613036058166, 'Total loss': 0.7703613036058166} | train loss {'Reaction outcome loss': 0.8163377297741752, 'Total loss': 0.8163377297741752}
2022-11-18 01:02:14,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:14,607 INFO:     Epoch: 42
2022-11-18 01:02:15,396 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7672802758487788, 'Total loss': 0.7672802758487788} | train loss {'Reaction outcome loss': 0.8100418721235567, 'Total loss': 0.8100418721235567}
2022-11-18 01:02:15,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:15,396 INFO:     Epoch: 43
2022-11-18 01:02:16,158 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.773129864172502, 'Total loss': 0.773129864172502} | train loss {'Reaction outcome loss': 0.8221793747957675, 'Total loss': 0.8221793747957675}
2022-11-18 01:02:16,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:16,158 INFO:     Epoch: 44
2022-11-18 01:02:16,939 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7812370610508051, 'Total loss': 0.7812370610508051} | train loss {'Reaction outcome loss': 0.8167753905778931, 'Total loss': 0.8167753905778931}
2022-11-18 01:02:16,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:16,940 INFO:     Epoch: 45
2022-11-18 01:02:17,762 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7667546089399945, 'Total loss': 0.7667546089399945} | train loss {'Reaction outcome loss': 0.8133703145769334, 'Total loss': 0.8133703145769334}
2022-11-18 01:02:17,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:17,762 INFO:     Epoch: 46
2022-11-18 01:02:18,573 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7652060592716391, 'Total loss': 0.7652060592716391} | train loss {'Reaction outcome loss': 0.8152667358517647, 'Total loss': 0.8152667358517647}
2022-11-18 01:02:18,573 INFO:     Found new best model at epoch 46
2022-11-18 01:02:18,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:18,574 INFO:     Epoch: 47
2022-11-18 01:02:19,374 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7728257111527703, 'Total loss': 0.7728257111527703} | train loss {'Reaction outcome loss': 0.8121539789342112, 'Total loss': 0.8121539789342112}
2022-11-18 01:02:19,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:19,374 INFO:     Epoch: 48
2022-11-18 01:02:20,171 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.766911506652832, 'Total loss': 0.766911506652832} | train loss {'Reaction outcome loss': 0.8137526685191739, 'Total loss': 0.8137526685191739}
2022-11-18 01:02:20,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:20,171 INFO:     Epoch: 49
2022-11-18 01:02:20,976 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7623160908168013, 'Total loss': 0.7623160908168013} | train loss {'Reaction outcome loss': 0.811221019755448, 'Total loss': 0.811221019755448}
2022-11-18 01:02:20,976 INFO:     Found new best model at epoch 49
2022-11-18 01:02:20,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:20,977 INFO:     Epoch: 50
2022-11-18 01:02:21,762 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7862218862230127, 'Total loss': 0.7862218862230127} | train loss {'Reaction outcome loss': 0.815326601266861, 'Total loss': 0.815326601266861}
2022-11-18 01:02:21,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:21,762 INFO:     Epoch: 51
2022-11-18 01:02:22,527 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7751851413737644, 'Total loss': 0.7751851413737644} | train loss {'Reaction outcome loss': 0.8143828677073601, 'Total loss': 0.8143828677073601}
2022-11-18 01:02:22,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:22,527 INFO:     Epoch: 52
2022-11-18 01:02:23,302 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7712378677996722, 'Total loss': 0.7712378677996722} | train loss {'Reaction outcome loss': 0.8128197065764858, 'Total loss': 0.8128197065764858}
2022-11-18 01:02:23,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:23,303 INFO:     Epoch: 53
2022-11-18 01:02:24,099 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.765094823457978, 'Total loss': 0.765094823457978} | train loss {'Reaction outcome loss': 0.8127726215508676, 'Total loss': 0.8127726215508676}
2022-11-18 01:02:24,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:24,099 INFO:     Epoch: 54
2022-11-18 01:02:24,896 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7922282774340023, 'Total loss': 0.7922282774340023} | train loss {'Reaction outcome loss': 0.809657072107638, 'Total loss': 0.809657072107638}
2022-11-18 01:02:24,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:24,896 INFO:     Epoch: 55
2022-11-18 01:02:25,678 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7803741246461868, 'Total loss': 0.7803741246461868} | train loss {'Reaction outcome loss': 0.814508174095423, 'Total loss': 0.814508174095423}
2022-11-18 01:02:25,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:25,678 INFO:     Epoch: 56
2022-11-18 01:02:26,492 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7686107998544519, 'Total loss': 0.7686107998544519} | train loss {'Reaction outcome loss': 0.8139515475880715, 'Total loss': 0.8139515475880715}
2022-11-18 01:02:26,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:26,492 INFO:     Epoch: 57
2022-11-18 01:02:27,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7686354307965799, 'Total loss': 0.7686354307965799} | train loss {'Reaction outcome loss': 0.8149265752684686, 'Total loss': 0.8149265752684686}
2022-11-18 01:02:27,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:27,293 INFO:     Epoch: 58
2022-11-18 01:02:28,080 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7806399539113045, 'Total loss': 0.7806399539113045} | train loss {'Reaction outcome loss': 0.8076528855148823, 'Total loss': 0.8076528855148823}
2022-11-18 01:02:28,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:28,080 INFO:     Epoch: 59
2022-11-18 01:02:28,870 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.769883355633779, 'Total loss': 0.769883355633779} | train loss {'Reaction outcome loss': 0.813993516348062, 'Total loss': 0.813993516348062}
2022-11-18 01:02:28,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:28,870 INFO:     Epoch: 60
2022-11-18 01:02:29,622 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7864736359227787, 'Total loss': 0.7864736359227787} | train loss {'Reaction outcome loss': 0.8105478914033982, 'Total loss': 0.8105478914033982}
2022-11-18 01:02:29,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:29,623 INFO:     Epoch: 61
2022-11-18 01:02:30,443 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7703832672400908, 'Total loss': 0.7703832672400908} | train loss {'Reaction outcome loss': 0.8141848353608963, 'Total loss': 0.8141848353608963}
2022-11-18 01:02:30,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:30,444 INFO:     Epoch: 62
2022-11-18 01:02:31,214 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7712600806897337, 'Total loss': 0.7712600806897337} | train loss {'Reaction outcome loss': 0.813327758903465, 'Total loss': 0.813327758903465}
2022-11-18 01:02:31,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:31,214 INFO:     Epoch: 63
2022-11-18 01:02:31,998 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7648565958846699, 'Total loss': 0.7648565958846699} | train loss {'Reaction outcome loss': 0.8095584258196815, 'Total loss': 0.8095584258196815}
2022-11-18 01:02:31,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:31,998 INFO:     Epoch: 64
2022-11-18 01:02:32,804 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.774407527663491, 'Total loss': 0.774407527663491} | train loss {'Reaction outcome loss': 0.8111524467747058, 'Total loss': 0.8111524467747058}
2022-11-18 01:02:32,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:32,804 INFO:     Epoch: 65
2022-11-18 01:02:33,574 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7956986691464077, 'Total loss': 0.7956986691464077} | train loss {'Reaction outcome loss': 0.8111244155274283, 'Total loss': 0.8111244155274283}
2022-11-18 01:02:33,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:33,575 INFO:     Epoch: 66
2022-11-18 01:02:34,367 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.780362257225947, 'Total loss': 0.780362257225947} | train loss {'Reaction outcome loss': 0.8080668680129512, 'Total loss': 0.8080668680129512}
2022-11-18 01:02:34,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:34,367 INFO:     Epoch: 67
2022-11-18 01:02:35,153 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7615110176530752, 'Total loss': 0.7615110176530752} | train loss {'Reaction outcome loss': 0.8126163361293655, 'Total loss': 0.8126163361293655}
2022-11-18 01:02:35,153 INFO:     Found new best model at epoch 67
2022-11-18 01:02:35,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:35,154 INFO:     Epoch: 68
2022-11-18 01:02:35,916 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7658808664842085, 'Total loss': 0.7658808664842085} | train loss {'Reaction outcome loss': 0.8155257219989454, 'Total loss': 0.8155257219989454}
2022-11-18 01:02:35,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:35,916 INFO:     Epoch: 69
2022-11-18 01:02:36,672 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7630416432564909, 'Total loss': 0.7630416432564909} | train loss {'Reaction outcome loss': 0.8089511535100399, 'Total loss': 0.8089511535100399}
2022-11-18 01:02:36,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:36,673 INFO:     Epoch: 70
2022-11-18 01:02:37,436 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7635009620677341, 'Total loss': 0.7635009620677341} | train loss {'Reaction outcome loss': 0.8127336274952658, 'Total loss': 0.8127336274952658}
2022-11-18 01:02:37,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:37,436 INFO:     Epoch: 71
2022-11-18 01:02:38,222 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7767237282612107, 'Total loss': 0.7767237282612107} | train loss {'Reaction outcome loss': 0.8135421393859771, 'Total loss': 0.8135421393859771}
2022-11-18 01:02:38,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:38,222 INFO:     Epoch: 72
2022-11-18 01:02:39,015 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7688776755874808, 'Total loss': 0.7688776755874808} | train loss {'Reaction outcome loss': 0.8069129962353937, 'Total loss': 0.8069129962353937}
2022-11-18 01:02:39,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:39,015 INFO:     Epoch: 73
2022-11-18 01:02:39,792 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7714583934708075, 'Total loss': 0.7714583934708075} | train loss {'Reaction outcome loss': 0.8145264508503098, 'Total loss': 0.8145264508503098}
2022-11-18 01:02:39,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:39,792 INFO:     Epoch: 74
2022-11-18 01:02:40,582 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7624496092850511, 'Total loss': 0.7624496092850511} | train loss {'Reaction outcome loss': 0.8132517788439028, 'Total loss': 0.8132517788439028}
2022-11-18 01:02:40,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:40,582 INFO:     Epoch: 75
2022-11-18 01:02:41,374 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7858804708177393, 'Total loss': 0.7858804708177393} | train loss {'Reaction outcome loss': 0.8115455573124271, 'Total loss': 0.8115455573124271}
2022-11-18 01:02:41,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:41,375 INFO:     Epoch: 76
2022-11-18 01:02:42,166 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.761296579783613, 'Total loss': 0.761296579783613} | train loss {'Reaction outcome loss': 0.8124130874151184, 'Total loss': 0.8124130874151184}
2022-11-18 01:02:42,166 INFO:     Found new best model at epoch 76
2022-11-18 01:02:42,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:42,167 INFO:     Epoch: 77
2022-11-18 01:02:42,947 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7836180850863457, 'Total loss': 0.7836180850863457} | train loss {'Reaction outcome loss': 0.8107840728855902, 'Total loss': 0.8107840728855902}
2022-11-18 01:02:42,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:42,947 INFO:     Epoch: 78
2022-11-18 01:02:43,740 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7798992903395132, 'Total loss': 0.7798992903395132} | train loss {'Reaction outcome loss': 0.8108373820301025, 'Total loss': 0.8108373820301025}
2022-11-18 01:02:43,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:43,740 INFO:     Epoch: 79
2022-11-18 01:02:44,532 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7622570727359165, 'Total loss': 0.7622570727359165} | train loss {'Reaction outcome loss': 0.8115187826296014, 'Total loss': 0.8115187826296014}
2022-11-18 01:02:44,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:44,532 INFO:     Epoch: 80
2022-11-18 01:02:45,293 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.786901322955435, 'Total loss': 0.786901322955435} | train loss {'Reaction outcome loss': 0.8145401326398696, 'Total loss': 0.8145401326398696}
2022-11-18 01:02:45,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:45,293 INFO:     Epoch: 81
2022-11-18 01:02:46,104 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7789479731158777, 'Total loss': 0.7789479731158777} | train loss {'Reaction outcome loss': 0.8136710004220086, 'Total loss': 0.8136710004220086}
2022-11-18 01:02:46,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:46,104 INFO:     Epoch: 82
2022-11-18 01:02:46,849 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7820727378129959, 'Total loss': 0.7820727378129959} | train loss {'Reaction outcome loss': 0.8076952971037357, 'Total loss': 0.8076952971037357}
2022-11-18 01:02:46,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:46,850 INFO:     Epoch: 83
2022-11-18 01:02:47,619 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7701669599522244, 'Total loss': 0.7701669599522244} | train loss {'Reaction outcome loss': 0.809063536265204, 'Total loss': 0.809063536265204}
2022-11-18 01:02:47,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:47,619 INFO:     Epoch: 84
2022-11-18 01:02:48,406 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7737186083739455, 'Total loss': 0.7737186083739455} | train loss {'Reaction outcome loss': 0.8131090287239321, 'Total loss': 0.8131090287239321}
2022-11-18 01:02:48,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:48,406 INFO:     Epoch: 85
2022-11-18 01:02:49,205 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7856156392530962, 'Total loss': 0.7856156392530962} | train loss {'Reaction outcome loss': 0.8091363947718374, 'Total loss': 0.8091363947718374}
2022-11-18 01:02:49,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:49,206 INFO:     Epoch: 86
2022-11-18 01:02:49,984 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7787888883189722, 'Total loss': 0.7787888883189722} | train loss {'Reaction outcome loss': 0.8132824622575314, 'Total loss': 0.8132824622575314}
2022-11-18 01:02:49,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:49,984 INFO:     Epoch: 87
2022-11-18 01:02:50,785 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7609948881647803, 'Total loss': 0.7609948881647803} | train loss {'Reaction outcome loss': 0.806732106893774, 'Total loss': 0.806732106893774}
2022-11-18 01:02:50,785 INFO:     Found new best model at epoch 87
2022-11-18 01:02:50,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:50,786 INFO:     Epoch: 88
2022-11-18 01:02:51,562 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7765333489938215, 'Total loss': 0.7765333489938215} | train loss {'Reaction outcome loss': 0.8090616205046254, 'Total loss': 0.8090616205046254}
2022-11-18 01:02:51,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:51,562 INFO:     Epoch: 89
2022-11-18 01:02:52,351 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.780466995456002, 'Total loss': 0.780466995456002} | train loss {'Reaction outcome loss': 0.8030130889627242, 'Total loss': 0.8030130889627242}
2022-11-18 01:02:52,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:52,351 INFO:     Epoch: 90
2022-11-18 01:02:53,139 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7801293188875372, 'Total loss': 0.7801293188875372} | train loss {'Reaction outcome loss': 0.8056203426132279, 'Total loss': 0.8056203426132279}
2022-11-18 01:02:53,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:53,140 INFO:     Epoch: 91
2022-11-18 01:02:53,939 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7521232529120012, 'Total loss': 0.7521232529120012} | train loss {'Reaction outcome loss': 0.8036083199324147, 'Total loss': 0.8036083199324147}
2022-11-18 01:02:53,940 INFO:     Found new best model at epoch 91
2022-11-18 01:02:53,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:53,940 INFO:     Epoch: 92
2022-11-18 01:02:54,735 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7550708509304307, 'Total loss': 0.7550708509304307} | train loss {'Reaction outcome loss': 0.8118108967619557, 'Total loss': 0.8118108967619557}
2022-11-18 01:02:54,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:54,735 INFO:     Epoch: 93
2022-11-18 01:02:55,501 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8020436458966949, 'Total loss': 0.8020436458966949} | train loss {'Reaction outcome loss': 0.8072395033894046, 'Total loss': 0.8072395033894046}
2022-11-18 01:02:55,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:55,501 INFO:     Epoch: 94
2022-11-18 01:02:56,287 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7621464526111429, 'Total loss': 0.7621464526111429} | train loss {'Reaction outcome loss': 0.8033581978130725, 'Total loss': 0.8033581978130725}
2022-11-18 01:02:56,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:56,287 INFO:     Epoch: 95
2022-11-18 01:02:57,061 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7798320894891565, 'Total loss': 0.7798320894891565} | train loss {'Reaction outcome loss': 0.8004384456622985, 'Total loss': 0.8004384456622985}
2022-11-18 01:02:57,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:57,061 INFO:     Epoch: 96
2022-11-18 01:02:57,821 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7605126086961139, 'Total loss': 0.7605126086961139} | train loss {'Reaction outcome loss': 0.8061243338330139, 'Total loss': 0.8061243338330139}
2022-11-18 01:02:57,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:57,821 INFO:     Epoch: 97
2022-11-18 01:02:58,594 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7592323618856344, 'Total loss': 0.7592323618856344} | train loss {'Reaction outcome loss': 0.8003883719924958, 'Total loss': 0.8003883719924958}
2022-11-18 01:02:58,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:58,594 INFO:     Epoch: 98
2022-11-18 01:02:59,400 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7598108805038712, 'Total loss': 0.7598108805038712} | train loss {'Reaction outcome loss': 0.8017331465117393, 'Total loss': 0.8017331465117393}
2022-11-18 01:02:59,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:02:59,401 INFO:     Epoch: 99
2022-11-18 01:03:00,184 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.763278724795038, 'Total loss': 0.763278724795038} | train loss {'Reaction outcome loss': 0.8070592554586549, 'Total loss': 0.8070592554586549}
2022-11-18 01:03:00,185 INFO:     Best model found after epoch 92 of 100.
2022-11-18 01:03:00,185 INFO:   Done with stage: TRAINING
2022-11-18 01:03:00,185 INFO:   Starting stage: EVALUATION
2022-11-18 01:03:00,302 INFO:   Done with stage: EVALUATION
2022-11-18 01:03:00,303 INFO:   Leaving out SEQ value Fold_7
2022-11-18 01:03:00,316 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:03:00,316 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:03:00,982 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:03:00,982 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:03:01,057 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:03:01,057 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:03:01,057 INFO:     No hyperparam tuning for this model
2022-11-18 01:03:01,057 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:03:01,057 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:03:01,058 INFO:     None feature selector for col prot
2022-11-18 01:03:01,058 INFO:     None feature selector for col prot
2022-11-18 01:03:01,058 INFO:     None feature selector for col prot
2022-11-18 01:03:01,059 INFO:     None feature selector for col chem
2022-11-18 01:03:01,059 INFO:     None feature selector for col chem
2022-11-18 01:03:01,059 INFO:     None feature selector for col chem
2022-11-18 01:03:01,059 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:03:01,059 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:03:01,061 INFO:     Number of params in model 168571
2022-11-18 01:03:01,064 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:03:01,064 INFO:   Starting stage: TRAINING
2022-11-18 01:03:01,122 INFO:     Val loss before train {'Reaction outcome loss': 1.0442627343264492, 'Total loss': 1.0442627343264492}
2022-11-18 01:03:01,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:01,122 INFO:     Epoch: 0
2022-11-18 01:03:01,905 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8578574339097197, 'Total loss': 0.8578574339097197} | train loss {'Reaction outcome loss': 0.8743310608425919, 'Total loss': 0.8743310608425919}
2022-11-18 01:03:01,906 INFO:     Found new best model at epoch 0
2022-11-18 01:03:01,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:01,907 INFO:     Epoch: 1
2022-11-18 01:03:02,701 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8454362614588304, 'Total loss': 0.8454362614588304} | train loss {'Reaction outcome loss': 0.8465472332068852, 'Total loss': 0.8465472332068852}
2022-11-18 01:03:02,701 INFO:     Found new best model at epoch 1
2022-11-18 01:03:02,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:02,702 INFO:     Epoch: 2
2022-11-18 01:03:03,455 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8724192794073712, 'Total loss': 0.8724192794073712} | train loss {'Reaction outcome loss': 0.842468777967959, 'Total loss': 0.842468777967959}
2022-11-18 01:03:03,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:03,455 INFO:     Epoch: 3
2022-11-18 01:03:04,210 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8396243845874612, 'Total loss': 0.8396243845874612} | train loss {'Reaction outcome loss': 0.8328516778897266, 'Total loss': 0.8328516778897266}
2022-11-18 01:03:04,211 INFO:     Found new best model at epoch 3
2022-11-18 01:03:04,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:04,211 INFO:     Epoch: 4
2022-11-18 01:03:04,973 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8533768308433619, 'Total loss': 0.8533768308433619} | train loss {'Reaction outcome loss': 0.834075847693852, 'Total loss': 0.834075847693852}
2022-11-18 01:03:04,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:04,974 INFO:     Epoch: 5
2022-11-18 01:03:05,747 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.853298616680232, 'Total loss': 0.853298616680232} | train loss {'Reaction outcome loss': 0.8283897684544933, 'Total loss': 0.8283897684544933}
2022-11-18 01:03:05,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:05,747 INFO:     Epoch: 6
2022-11-18 01:03:06,503 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8322687365792014, 'Total loss': 0.8322687365792014} | train loss {'Reaction outcome loss': 0.8274498871394567, 'Total loss': 0.8274498871394567}
2022-11-18 01:03:06,503 INFO:     Found new best model at epoch 6
2022-11-18 01:03:06,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:06,504 INFO:     Epoch: 7
2022-11-18 01:03:07,282 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8197740797292102, 'Total loss': 0.8197740797292102} | train loss {'Reaction outcome loss': 0.8178075830547177, 'Total loss': 0.8178075830547177}
2022-11-18 01:03:07,282 INFO:     Found new best model at epoch 7
2022-11-18 01:03:07,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:07,283 INFO:     Epoch: 8
2022-11-18 01:03:08,092 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8242032920772379, 'Total loss': 0.8242032920772379} | train loss {'Reaction outcome loss': 0.8177517347189844, 'Total loss': 0.8177517347189844}
2022-11-18 01:03:08,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:08,093 INFO:     Epoch: 9
2022-11-18 01:03:08,873 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8778309971094131, 'Total loss': 0.8778309971094131} | train loss {'Reaction outcome loss': 0.8176186678360919, 'Total loss': 0.8176186678360919}
2022-11-18 01:03:08,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:08,873 INFO:     Epoch: 10
2022-11-18 01:03:09,640 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8252086558125236, 'Total loss': 0.8252086558125236} | train loss {'Reaction outcome loss': 0.8173815375688125, 'Total loss': 0.8173815375688125}
2022-11-18 01:03:09,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:09,640 INFO:     Epoch: 11
2022-11-18 01:03:10,417 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8392148288813505, 'Total loss': 0.8392148288813505} | train loss {'Reaction outcome loss': 0.8157360327487089, 'Total loss': 0.8157360327487089}
2022-11-18 01:03:10,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:10,417 INFO:     Epoch: 12
2022-11-18 01:03:11,196 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8270181837407026, 'Total loss': 0.8270181837407026} | train loss {'Reaction outcome loss': 0.8174983332351763, 'Total loss': 0.8174983332351763}
2022-11-18 01:03:11,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:11,196 INFO:     Epoch: 13
2022-11-18 01:03:11,988 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.846599512479522, 'Total loss': 0.846599512479522} | train loss {'Reaction outcome loss': 0.815500841821943, 'Total loss': 0.815500841821943}
2022-11-18 01:03:11,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:11,988 INFO:     Epoch: 14
2022-11-18 01:03:12,763 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8344223485751585, 'Total loss': 0.8344223485751585} | train loss {'Reaction outcome loss': 0.8153601616012807, 'Total loss': 0.8153601616012807}
2022-11-18 01:03:12,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:12,763 INFO:     Epoch: 15
2022-11-18 01:03:13,544 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8185447264801372, 'Total loss': 0.8185447264801372} | train loss {'Reaction outcome loss': 0.8148810739419898, 'Total loss': 0.8148810739419898}
2022-11-18 01:03:13,544 INFO:     Found new best model at epoch 15
2022-11-18 01:03:13,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:13,545 INFO:     Epoch: 16
2022-11-18 01:03:14,324 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8223387219689109, 'Total loss': 0.8223387219689109} | train loss {'Reaction outcome loss': 0.8135990999182876, 'Total loss': 0.8135990999182876}
2022-11-18 01:03:14,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:14,325 INFO:     Epoch: 17
2022-11-18 01:03:15,100 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8413522934371774, 'Total loss': 0.8413522934371774} | train loss {'Reaction outcome loss': 0.8150562882423401, 'Total loss': 0.8150562882423401}
2022-11-18 01:03:15,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:15,100 INFO:     Epoch: 18
2022-11-18 01:03:15,865 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8663417947563258, 'Total loss': 0.8663417947563258} | train loss {'Reaction outcome loss': 0.8090688992519768, 'Total loss': 0.8090688992519768}
2022-11-18 01:03:15,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:15,866 INFO:     Epoch: 19
2022-11-18 01:03:16,649 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.829468544233929, 'Total loss': 0.829468544233929} | train loss {'Reaction outcome loss': 0.8137173223252199, 'Total loss': 0.8137173223252199}
2022-11-18 01:03:16,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:16,649 INFO:     Epoch: 20
2022-11-18 01:03:17,395 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8442658456889066, 'Total loss': 0.8442658456889066} | train loss {'Reaction outcome loss': 0.8166440519751335, 'Total loss': 0.8166440519751335}
2022-11-18 01:03:17,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:17,395 INFO:     Epoch: 21
2022-11-18 01:03:18,197 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8373812409964475, 'Total loss': 0.8373812409964475} | train loss {'Reaction outcome loss': 0.8116869265935859, 'Total loss': 0.8116869265935859}
2022-11-18 01:03:18,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:18,197 INFO:     Epoch: 22
2022-11-18 01:03:18,978 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8202448575334116, 'Total loss': 0.8202448575334116} | train loss {'Reaction outcome loss': 0.8147983350315873, 'Total loss': 0.8147983350315873}
2022-11-18 01:03:18,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:18,979 INFO:     Epoch: 23
2022-11-18 01:03:19,750 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8300669552250342, 'Total loss': 0.8300669552250342} | train loss {'Reaction outcome loss': 0.8121435411122381, 'Total loss': 0.8121435411122381}
2022-11-18 01:03:19,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:19,750 INFO:     Epoch: 24
2022-11-18 01:03:20,540 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8306703865528107, 'Total loss': 0.8306703865528107} | train loss {'Reaction outcome loss': 0.8096008522169931, 'Total loss': 0.8096008522169931}
2022-11-18 01:03:20,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:20,542 INFO:     Epoch: 25
2022-11-18 01:03:21,290 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.867078569802371, 'Total loss': 0.867078569802371} | train loss {'Reaction outcome loss': 0.8125476912576325, 'Total loss': 0.8125476912576325}
2022-11-18 01:03:21,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:21,290 INFO:     Epoch: 26
2022-11-18 01:03:22,057 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8264469226652925, 'Total loss': 0.8264469226652925} | train loss {'Reaction outcome loss': 0.8094085692142954, 'Total loss': 0.8094085692142954}
2022-11-18 01:03:22,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:22,057 INFO:     Epoch: 27
2022-11-18 01:03:22,833 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8397977541793477, 'Total loss': 0.8397977541793477} | train loss {'Reaction outcome loss': 0.8076314195078247, 'Total loss': 0.8076314195078247}
2022-11-18 01:03:22,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:22,834 INFO:     Epoch: 28
2022-11-18 01:03:23,641 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8229493149979548, 'Total loss': 0.8229493149979548} | train loss {'Reaction outcome loss': 0.8086578534573925, 'Total loss': 0.8086578534573925}
2022-11-18 01:03:23,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:23,641 INFO:     Epoch: 29
2022-11-18 01:03:24,416 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8295727121559057, 'Total loss': 0.8295727121559057} | train loss {'Reaction outcome loss': 0.81298531464168, 'Total loss': 0.81298531464168}
2022-11-18 01:03:24,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:24,416 INFO:     Epoch: 30
2022-11-18 01:03:25,188 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8121742237020623, 'Total loss': 0.8121742237020623} | train loss {'Reaction outcome loss': 0.8094517847713159, 'Total loss': 0.8094517847713159}
2022-11-18 01:03:25,188 INFO:     Found new best model at epoch 30
2022-11-18 01:03:25,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:25,189 INFO:     Epoch: 31
2022-11-18 01:03:25,986 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8268097442659464, 'Total loss': 0.8268097442659464} | train loss {'Reaction outcome loss': 0.8072880614777, 'Total loss': 0.8072880614777}
2022-11-18 01:03:25,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:25,987 INFO:     Epoch: 32
2022-11-18 01:03:26,795 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8478197455406189, 'Total loss': 0.8478197455406189} | train loss {'Reaction outcome loss': 0.8100730882615459, 'Total loss': 0.8100730882615459}
2022-11-18 01:03:26,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:26,795 INFO:     Epoch: 33
2022-11-18 01:03:27,567 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8892609910531477, 'Total loss': 0.8892609910531477} | train loss {'Reaction outcome loss': 0.8178282140469064, 'Total loss': 0.8178282140469064}
2022-11-18 01:03:27,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:27,567 INFO:     Epoch: 34
2022-11-18 01:03:28,364 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8279490044171159, 'Total loss': 0.8279490044171159} | train loss {'Reaction outcome loss': 0.8099005902300076, 'Total loss': 0.8099005902300076}
2022-11-18 01:03:28,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:28,365 INFO:     Epoch: 35
2022-11-18 01:03:29,138 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8252462521195412, 'Total loss': 0.8252462521195412} | train loss {'Reaction outcome loss': 0.8117108096881789, 'Total loss': 0.8117108096881789}
2022-11-18 01:03:29,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:29,138 INFO:     Epoch: 36
2022-11-18 01:03:29,909 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8170060942118819, 'Total loss': 0.8170060942118819} | train loss {'Reaction outcome loss': 0.810367534963452, 'Total loss': 0.810367534963452}
2022-11-18 01:03:29,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:29,910 INFO:     Epoch: 37
2022-11-18 01:03:30,690 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8386496312238954, 'Total loss': 0.8386496312238954} | train loss {'Reaction outcome loss': 0.8095328435605886, 'Total loss': 0.8095328435605886}
2022-11-18 01:03:30,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:30,691 INFO:     Epoch: 38
2022-11-18 01:03:31,474 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8318971923806451, 'Total loss': 0.8318971923806451} | train loss {'Reaction outcome loss': 0.809554855434262, 'Total loss': 0.809554855434262}
2022-11-18 01:03:31,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:31,474 INFO:     Epoch: 39
2022-11-18 01:03:32,270 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8296549658883702, 'Total loss': 0.8296549658883702} | train loss {'Reaction outcome loss': 0.8099684970719474, 'Total loss': 0.8099684970719474}
2022-11-18 01:03:32,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:32,271 INFO:     Epoch: 40
2022-11-18 01:03:33,034 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8295471119609746, 'Total loss': 0.8295471119609746} | train loss {'Reaction outcome loss': 0.8095308796483643, 'Total loss': 0.8095308796483643}
2022-11-18 01:03:33,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:33,035 INFO:     Epoch: 41
2022-11-18 01:03:33,804 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8378612073985013, 'Total loss': 0.8378612073985013} | train loss {'Reaction outcome loss': 0.8081869563277887, 'Total loss': 0.8081869563277887}
2022-11-18 01:03:33,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:33,805 INFO:     Epoch: 42
2022-11-18 01:03:34,597 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8305402276190844, 'Total loss': 0.8305402276190844} | train loss {'Reaction outcome loss': 0.8071902980609816, 'Total loss': 0.8071902980609816}
2022-11-18 01:03:34,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:34,597 INFO:     Epoch: 43
2022-11-18 01:03:35,349 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8242522329092026, 'Total loss': 0.8242522329092026} | train loss {'Reaction outcome loss': 0.8065296848209537, 'Total loss': 0.8065296848209537}
2022-11-18 01:03:35,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:35,349 INFO:     Epoch: 44
2022-11-18 01:03:36,127 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8086475675756281, 'Total loss': 0.8086475675756281} | train loss {'Reaction outcome loss': 0.8064582672654366, 'Total loss': 0.8064582672654366}
2022-11-18 01:03:36,128 INFO:     Found new best model at epoch 44
2022-11-18 01:03:36,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:36,129 INFO:     Epoch: 45
2022-11-18 01:03:36,915 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8343923538923264, 'Total loss': 0.8343923538923264} | train loss {'Reaction outcome loss': 0.8073505357820161, 'Total loss': 0.8073505357820161}
2022-11-18 01:03:36,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:36,915 INFO:     Epoch: 46
2022-11-18 01:03:37,656 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8529921539805152, 'Total loss': 0.8529921539805152} | train loss {'Reaction outcome loss': 0.8131027512404383, 'Total loss': 0.8131027512404383}
2022-11-18 01:03:37,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:37,656 INFO:     Epoch: 47
2022-11-18 01:03:38,465 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.855725651437586, 'Total loss': 0.855725651437586} | train loss {'Reaction outcome loss': 0.8108481775741188, 'Total loss': 0.8108481775741188}
2022-11-18 01:03:38,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:38,466 INFO:     Epoch: 48
2022-11-18 01:03:39,228 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.806567286903208, 'Total loss': 0.806567286903208} | train loss {'Reaction outcome loss': 0.8075882445792762, 'Total loss': 0.8075882445792762}
2022-11-18 01:03:39,229 INFO:     Found new best model at epoch 48
2022-11-18 01:03:39,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:39,229 INFO:     Epoch: 49
2022-11-18 01:03:40,010 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8290127705443989, 'Total loss': 0.8290127705443989} | train loss {'Reaction outcome loss': 0.8098008462360927, 'Total loss': 0.8098008462360927}
2022-11-18 01:03:40,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:40,010 INFO:     Epoch: 50
2022-11-18 01:03:40,820 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8312815170396458, 'Total loss': 0.8312815170396458} | train loss {'Reaction outcome loss': 0.8123414449545802, 'Total loss': 0.8123414449545802}
2022-11-18 01:03:40,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:40,821 INFO:     Epoch: 51
2022-11-18 01:03:41,631 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8096296333453872, 'Total loss': 0.8096296333453872} | train loss {'Reaction outcome loss': 0.807967039638636, 'Total loss': 0.807967039638636}
2022-11-18 01:03:41,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:41,631 INFO:     Epoch: 52
2022-11-18 01:03:42,459 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8333963711153377, 'Total loss': 0.8333963711153377} | train loss {'Reaction outcome loss': 0.8063380519954526, 'Total loss': 0.8063380519954526}
2022-11-18 01:03:42,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:42,460 INFO:     Epoch: 53
2022-11-18 01:03:43,260 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8153075613081455, 'Total loss': 0.8153075613081455} | train loss {'Reaction outcome loss': 0.8107445415185422, 'Total loss': 0.8107445415185422}
2022-11-18 01:03:43,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:43,261 INFO:     Epoch: 54
2022-11-18 01:03:44,078 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8332061957229268, 'Total loss': 0.8332061957229268} | train loss {'Reaction outcome loss': 0.8015006129838982, 'Total loss': 0.8015006129838982}
2022-11-18 01:03:44,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:44,078 INFO:     Epoch: 55
2022-11-18 01:03:44,873 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8280725824561986, 'Total loss': 0.8280725824561986} | train loss {'Reaction outcome loss': 0.812364494192357, 'Total loss': 0.812364494192357}
2022-11-18 01:03:44,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:44,873 INFO:     Epoch: 56
2022-11-18 01:03:45,648 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8300018208948049, 'Total loss': 0.8300018208948049} | train loss {'Reaction outcome loss': 0.8075683113263578, 'Total loss': 0.8075683113263578}
2022-11-18 01:03:45,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:45,649 INFO:     Epoch: 57
2022-11-18 01:03:46,445 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8333455337719484, 'Total loss': 0.8333455337719484} | train loss {'Reaction outcome loss': 0.8039865721245201, 'Total loss': 0.8039865721245201}
2022-11-18 01:03:46,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:46,445 INFO:     Epoch: 58
2022-11-18 01:03:47,232 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8252593136646531, 'Total loss': 0.8252593136646531} | train loss {'Reaction outcome loss': 0.8110503359716765, 'Total loss': 0.8110503359716765}
2022-11-18 01:03:47,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:47,232 INFO:     Epoch: 59
2022-11-18 01:03:48,057 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8424302407286384, 'Total loss': 0.8424302407286384} | train loss {'Reaction outcome loss': 0.8101133778387186, 'Total loss': 0.8101133778387186}
2022-11-18 01:03:48,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:48,057 INFO:     Epoch: 60
2022-11-18 01:03:48,863 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.82409829036756, 'Total loss': 0.82409829036756} | train loss {'Reaction outcome loss': 0.8107803915228162, 'Total loss': 0.8107803915228162}
2022-11-18 01:03:48,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:48,863 INFO:     Epoch: 61
2022-11-18 01:03:49,679 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8228111510927026, 'Total loss': 0.8228111510927026} | train loss {'Reaction outcome loss': 0.8033743916725625, 'Total loss': 0.8033743916725625}
2022-11-18 01:03:49,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:49,679 INFO:     Epoch: 62
2022-11-18 01:03:50,476 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.832986059513959, 'Total loss': 0.832986059513959} | train loss {'Reaction outcome loss': 0.8068534651581122, 'Total loss': 0.8068534651581122}
2022-11-18 01:03:50,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:50,476 INFO:     Epoch: 63
2022-11-18 01:03:51,262 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8319647847251459, 'Total loss': 0.8319647847251459} | train loss {'Reaction outcome loss': 0.8099449213670225, 'Total loss': 0.8099449213670225}
2022-11-18 01:03:51,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:51,263 INFO:     Epoch: 64
2022-11-18 01:03:52,035 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8323954550380056, 'Total loss': 0.8323954550380056} | train loss {'Reaction outcome loss': 0.8073087351662772, 'Total loss': 0.8073087351662772}
2022-11-18 01:03:52,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:52,035 INFO:     Epoch: 65
2022-11-18 01:03:52,874 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8126437948508696, 'Total loss': 0.8126437948508696} | train loss {'Reaction outcome loss': 0.8075745394035262, 'Total loss': 0.8075745394035262}
2022-11-18 01:03:52,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:52,875 INFO:     Epoch: 66
2022-11-18 01:03:53,706 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8334316624836489, 'Total loss': 0.8334316624836489} | train loss {'Reaction outcome loss': 0.806904008315534, 'Total loss': 0.806904008315534}
2022-11-18 01:03:53,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:53,706 INFO:     Epoch: 67
2022-11-18 01:03:54,517 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8535902418873527, 'Total loss': 0.8535902418873527} | train loss {'Reaction outcome loss': 0.8077028920455854, 'Total loss': 0.8077028920455854}
2022-11-18 01:03:54,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:54,519 INFO:     Epoch: 68
2022-11-18 01:03:55,352 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8158384236422452, 'Total loss': 0.8158384236422452} | train loss {'Reaction outcome loss': 0.8036137906872496, 'Total loss': 0.8036137906872496}
2022-11-18 01:03:55,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:55,352 INFO:     Epoch: 69
2022-11-18 01:03:56,155 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8381421979178082, 'Total loss': 0.8381421979178082} | train loss {'Reaction outcome loss': 0.8107791258364307, 'Total loss': 0.8107791258364307}
2022-11-18 01:03:56,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:56,155 INFO:     Epoch: 70
2022-11-18 01:03:56,963 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8380276465957816, 'Total loss': 0.8380276465957816} | train loss {'Reaction outcome loss': 0.8109764566226881, 'Total loss': 0.8109764566226881}
2022-11-18 01:03:56,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:56,963 INFO:     Epoch: 71
2022-11-18 01:03:57,743 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8126750906760042, 'Total loss': 0.8126750906760042} | train loss {'Reaction outcome loss': 0.8063870035872167, 'Total loss': 0.8063870035872167}
2022-11-18 01:03:57,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:57,743 INFO:     Epoch: 72
2022-11-18 01:03:58,535 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8381271321665157, 'Total loss': 0.8381271321665157} | train loss {'Reaction outcome loss': 0.8074598097071356, 'Total loss': 0.8074598097071356}
2022-11-18 01:03:58,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:58,535 INFO:     Epoch: 73
2022-11-18 01:03:59,335 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8236789242787794, 'Total loss': 0.8236789242787794} | train loss {'Reaction outcome loss': 0.8112971551564275, 'Total loss': 0.8112971551564275}
2022-11-18 01:03:59,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:03:59,336 INFO:     Epoch: 74
2022-11-18 01:04:00,156 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8169547150080855, 'Total loss': 0.8169547150080855} | train loss {'Reaction outcome loss': 0.8087900724946236, 'Total loss': 0.8087900724946236}
2022-11-18 01:04:00,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:00,156 INFO:     Epoch: 75
2022-11-18 01:04:00,978 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8322647003964945, 'Total loss': 0.8322647003964945} | train loss {'Reaction outcome loss': 0.8077998486100411, 'Total loss': 0.8077998486100411}
2022-11-18 01:04:00,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:00,978 INFO:     Epoch: 76
2022-11-18 01:04:01,783 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8324521305886182, 'Total loss': 0.8324521305886182} | train loss {'Reaction outcome loss': 0.8071461435483427, 'Total loss': 0.8071461435483427}
2022-11-18 01:04:01,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:01,783 INFO:     Epoch: 77
2022-11-18 01:04:02,594 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8135538724335757, 'Total loss': 0.8135538724335757} | train loss {'Reaction outcome loss': 0.8075179851784998, 'Total loss': 0.8075179851784998}
2022-11-18 01:04:02,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:02,594 INFO:     Epoch: 78
2022-11-18 01:04:03,465 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8427372547713193, 'Total loss': 0.8427372547713193} | train loss {'Reaction outcome loss': 0.808448369770634, 'Total loss': 0.808448369770634}
2022-11-18 01:04:03,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:03,465 INFO:     Epoch: 79
2022-11-18 01:04:04,232 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8163330209526148, 'Total loss': 0.8163330209526148} | train loss {'Reaction outcome loss': 0.8127638883736669, 'Total loss': 0.8127638883736669}
2022-11-18 01:04:04,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:04,232 INFO:     Epoch: 80
2022-11-18 01:04:05,013 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8209401226856492, 'Total loss': 0.8209401226856492} | train loss {'Reaction outcome loss': 0.812987673039339, 'Total loss': 0.812987673039339}
2022-11-18 01:04:05,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:05,014 INFO:     Epoch: 81
2022-11-18 01:04:05,783 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8319843851707198, 'Total loss': 0.8319843851707198} | train loss {'Reaction outcome loss': 0.8046198307251443, 'Total loss': 0.8046198307251443}
2022-11-18 01:04:05,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:05,784 INFO:     Epoch: 82
2022-11-18 01:04:06,593 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8145396424965425, 'Total loss': 0.8145396424965425} | train loss {'Reaction outcome loss': 0.8123169802889532, 'Total loss': 0.8123169802889532}
2022-11-18 01:04:06,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:06,594 INFO:     Epoch: 83
2022-11-18 01:04:07,376 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8143560960888863, 'Total loss': 0.8143560960888863} | train loss {'Reaction outcome loss': 0.806976182120187, 'Total loss': 0.806976182120187}
2022-11-18 01:04:07,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:07,376 INFO:     Epoch: 84
2022-11-18 01:04:08,162 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8162795210426504, 'Total loss': 0.8162795210426504} | train loss {'Reaction outcome loss': 0.8098681667629554, 'Total loss': 0.8098681667629554}
2022-11-18 01:04:08,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:08,163 INFO:     Epoch: 85
2022-11-18 01:04:08,974 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8201175496320833, 'Total loss': 0.8201175496320833} | train loss {'Reaction outcome loss': 0.80742924189081, 'Total loss': 0.80742924189081}
2022-11-18 01:04:08,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:08,975 INFO:     Epoch: 86
2022-11-18 01:04:09,793 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8401936455206438, 'Total loss': 0.8401936455206438} | train loss {'Reaction outcome loss': 0.8082009797193566, 'Total loss': 0.8082009797193566}
2022-11-18 01:04:09,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:09,793 INFO:     Epoch: 87
2022-11-18 01:04:10,634 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8154530166225, 'Total loss': 0.8154530166225} | train loss {'Reaction outcome loss': 0.8045645060587903, 'Total loss': 0.8045645060587903}
2022-11-18 01:04:10,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:10,635 INFO:     Epoch: 88
2022-11-18 01:04:11,439 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8081368336623366, 'Total loss': 0.8081368336623366} | train loss {'Reaction outcome loss': 0.8105072376679401, 'Total loss': 0.8105072376679401}
2022-11-18 01:04:11,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:11,440 INFO:     Epoch: 89
2022-11-18 01:04:12,221 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8473652032288638, 'Total loss': 0.8473652032288638} | train loss {'Reaction outcome loss': 0.8075986790413759, 'Total loss': 0.8075986790413759}
2022-11-18 01:04:12,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:12,221 INFO:     Epoch: 90
2022-11-18 01:04:12,984 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8132234588265419, 'Total loss': 0.8132234588265419} | train loss {'Reaction outcome loss': 0.8078881863428622, 'Total loss': 0.8078881863428622}
2022-11-18 01:04:12,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:12,985 INFO:     Epoch: 91
2022-11-18 01:04:13,800 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8244765414433046, 'Total loss': 0.8244765414433046} | train loss {'Reaction outcome loss': 0.8076941530315244, 'Total loss': 0.8076941530315244}
2022-11-18 01:04:13,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:13,800 INFO:     Epoch: 92
2022-11-18 01:04:14,577 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8426784155043688, 'Total loss': 0.8426784155043688} | train loss {'Reaction outcome loss': 0.8053450765658398, 'Total loss': 0.8053450765658398}
2022-11-18 01:04:14,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:14,577 INFO:     Epoch: 93
2022-11-18 01:04:15,413 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8202769566665996, 'Total loss': 0.8202769566665996} | train loss {'Reaction outcome loss': 0.806640450078614, 'Total loss': 0.806640450078614}
2022-11-18 01:04:15,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:15,413 INFO:     Epoch: 94
2022-11-18 01:04:16,207 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8274651847102426, 'Total loss': 0.8274651847102426} | train loss {'Reaction outcome loss': 0.8063219431711703, 'Total loss': 0.8063219431711703}
2022-11-18 01:04:16,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:16,207 INFO:     Epoch: 95
2022-11-18 01:04:17,010 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8489720056002791, 'Total loss': 0.8489720056002791} | train loss {'Reaction outcome loss': 0.8088704876753748, 'Total loss': 0.8088704876753748}
2022-11-18 01:04:17,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:17,010 INFO:     Epoch: 96
2022-11-18 01:04:17,805 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8093833950432864, 'Total loss': 0.8093833950432864} | train loss {'Reaction outcome loss': 0.8042052267765513, 'Total loss': 0.8042052267765513}
2022-11-18 01:04:17,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:17,805 INFO:     Epoch: 97
2022-11-18 01:04:18,608 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8307328515432097, 'Total loss': 0.8307328515432097} | train loss {'Reaction outcome loss': 0.8091041453030645, 'Total loss': 0.8091041453030645}
2022-11-18 01:04:18,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:18,609 INFO:     Epoch: 98
2022-11-18 01:04:19,422 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8140134763988581, 'Total loss': 0.8140134763988581} | train loss {'Reaction outcome loss': 0.8089721824441637, 'Total loss': 0.8089721824441637}
2022-11-18 01:04:19,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:19,422 INFO:     Epoch: 99
2022-11-18 01:04:20,223 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.811540888114409, 'Total loss': 0.811540888114409} | train loss {'Reaction outcome loss': 0.8062671463100277, 'Total loss': 0.8062671463100277}
2022-11-18 01:04:20,223 INFO:     Best model found after epoch 49 of 100.
2022-11-18 01:04:20,223 INFO:   Done with stage: TRAINING
2022-11-18 01:04:20,223 INFO:   Starting stage: EVALUATION
2022-11-18 01:04:20,352 INFO:   Done with stage: EVALUATION
2022-11-18 01:04:20,352 INFO:   Leaving out SEQ value Fold_8
2022-11-18 01:04:20,365 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:04:20,365 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:04:21,035 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:04:21,035 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:04:21,105 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:04:21,106 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:04:21,106 INFO:     No hyperparam tuning for this model
2022-11-18 01:04:21,106 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:04:21,106 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:04:21,106 INFO:     None feature selector for col prot
2022-11-18 01:04:21,107 INFO:     None feature selector for col prot
2022-11-18 01:04:21,107 INFO:     None feature selector for col prot
2022-11-18 01:04:21,107 INFO:     None feature selector for col chem
2022-11-18 01:04:21,107 INFO:     None feature selector for col chem
2022-11-18 01:04:21,107 INFO:     None feature selector for col chem
2022-11-18 01:04:21,108 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:04:21,108 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:04:21,109 INFO:     Number of params in model 168571
2022-11-18 01:04:21,112 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:04:21,112 INFO:   Starting stage: TRAINING
2022-11-18 01:04:21,170 INFO:     Val loss before train {'Reaction outcome loss': 0.9751066199757836, 'Total loss': 0.9751066199757836}
2022-11-18 01:04:21,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:21,170 INFO:     Epoch: 0
2022-11-18 01:04:21,961 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8244009207595479, 'Total loss': 0.8244009207595479} | train loss {'Reaction outcome loss': 0.8781314672481629, 'Total loss': 0.8781314672481629}
2022-11-18 01:04:21,962 INFO:     Found new best model at epoch 0
2022-11-18 01:04:21,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:21,962 INFO:     Epoch: 1
2022-11-18 01:04:22,768 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8319292095574465, 'Total loss': 0.8319292095574465} | train loss {'Reaction outcome loss': 0.8570766796267801, 'Total loss': 0.8570766796267801}
2022-11-18 01:04:22,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:22,768 INFO:     Epoch: 2
2022-11-18 01:04:23,568 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8073356639255177, 'Total loss': 0.8073356639255177} | train loss {'Reaction outcome loss': 0.843677603309193, 'Total loss': 0.843677603309193}
2022-11-18 01:04:23,569 INFO:     Found new best model at epoch 2
2022-11-18 01:04:23,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:23,570 INFO:     Epoch: 3
2022-11-18 01:04:24,414 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.789514481682669, 'Total loss': 0.789514481682669} | train loss {'Reaction outcome loss': 0.8435169005345914, 'Total loss': 0.8435169005345914}
2022-11-18 01:04:24,415 INFO:     Found new best model at epoch 3
2022-11-18 01:04:24,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:24,415 INFO:     Epoch: 4
2022-11-18 01:04:25,236 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8211315836418759, 'Total loss': 0.8211315836418759} | train loss {'Reaction outcome loss': 0.8426234618790688, 'Total loss': 0.8426234618790688}
2022-11-18 01:04:25,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:25,236 INFO:     Epoch: 5
2022-11-18 01:04:26,027 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8001469692045992, 'Total loss': 0.8001469692045992} | train loss {'Reaction outcome loss': 0.8388473466038704, 'Total loss': 0.8388473466038704}
2022-11-18 01:04:26,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:26,027 INFO:     Epoch: 6
2022-11-18 01:04:26,845 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7974713905291124, 'Total loss': 0.7974713905291124} | train loss {'Reaction outcome loss': 0.829470030242397, 'Total loss': 0.829470030242397}
2022-11-18 01:04:26,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:26,845 INFO:     Epoch: 7
2022-11-18 01:04:27,638 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8199327059767463, 'Total loss': 0.8199327059767463} | train loss {'Reaction outcome loss': 0.8327788917287704, 'Total loss': 0.8327788917287704}
2022-11-18 01:04:27,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:27,639 INFO:     Epoch: 8
2022-11-18 01:04:28,459 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7882459935816851, 'Total loss': 0.7882459935816851} | train loss {'Reaction outcome loss': 0.8230060503607796, 'Total loss': 0.8230060503607796}
2022-11-18 01:04:28,459 INFO:     Found new best model at epoch 8
2022-11-18 01:04:28,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:28,460 INFO:     Epoch: 9
2022-11-18 01:04:29,292 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7838845205577937, 'Total loss': 0.7838845205577937} | train loss {'Reaction outcome loss': 0.828096737784724, 'Total loss': 0.828096737784724}
2022-11-18 01:04:29,292 INFO:     Found new best model at epoch 9
2022-11-18 01:04:29,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:29,293 INFO:     Epoch: 10
2022-11-18 01:04:30,136 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7841819314794107, 'Total loss': 0.7841819314794107} | train loss {'Reaction outcome loss': 0.8291957975635605, 'Total loss': 0.8291957975635605}
2022-11-18 01:04:30,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:30,136 INFO:     Epoch: 11
2022-11-18 01:04:30,892 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7943762974305586, 'Total loss': 0.7943762974305586} | train loss {'Reaction outcome loss': 0.8253370845510114, 'Total loss': 0.8253370845510114}
2022-11-18 01:04:30,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:30,892 INFO:     Epoch: 12
2022-11-18 01:04:31,682 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.786648572168567, 'Total loss': 0.786648572168567} | train loss {'Reaction outcome loss': 0.8223040802103858, 'Total loss': 0.8223040802103858}
2022-11-18 01:04:31,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:31,683 INFO:     Epoch: 13
2022-11-18 01:04:32,478 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.842138147489591, 'Total loss': 0.842138147489591} | train loss {'Reaction outcome loss': 0.8239283881360485, 'Total loss': 0.8239283881360485}
2022-11-18 01:04:32,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:32,479 INFO:     Epoch: 14
2022-11-18 01:04:33,275 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7899210493672978, 'Total loss': 0.7899210493672978} | train loss {'Reaction outcome loss': 0.8245580463159469, 'Total loss': 0.8245580463159469}
2022-11-18 01:04:33,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:33,275 INFO:     Epoch: 15
2022-11-18 01:04:34,065 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7937852902845903, 'Total loss': 0.7937852902845903} | train loss {'Reaction outcome loss': 0.8274043144718293, 'Total loss': 0.8274043144718293}
2022-11-18 01:04:34,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:34,066 INFO:     Epoch: 16
2022-11-18 01:04:34,864 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7848574099215594, 'Total loss': 0.7848574099215594} | train loss {'Reaction outcome loss': 0.8202041118375717, 'Total loss': 0.8202041118375717}
2022-11-18 01:04:34,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:34,865 INFO:     Epoch: 17
2022-11-18 01:04:35,646 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.793946189636534, 'Total loss': 0.793946189636534} | train loss {'Reaction outcome loss': 0.8189343896604353, 'Total loss': 0.8189343896604353}
2022-11-18 01:04:35,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:35,647 INFO:     Epoch: 18
2022-11-18 01:04:36,437 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8249616954814304, 'Total loss': 0.8249616954814304} | train loss {'Reaction outcome loss': 0.822425783521706, 'Total loss': 0.822425783521706}
2022-11-18 01:04:36,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:36,437 INFO:     Epoch: 19
2022-11-18 01:04:37,222 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.784896844490008, 'Total loss': 0.784896844490008} | train loss {'Reaction outcome loss': 0.8184704192944111, 'Total loss': 0.8184704192944111}
2022-11-18 01:04:37,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:37,222 INFO:     Epoch: 20
2022-11-18 01:04:38,044 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7869598757136952, 'Total loss': 0.7869598757136952} | train loss {'Reaction outcome loss': 0.820068521965896, 'Total loss': 0.820068521965896}
2022-11-18 01:04:38,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:38,044 INFO:     Epoch: 21
2022-11-18 01:04:38,873 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7898544384674593, 'Total loss': 0.7898544384674593} | train loss {'Reaction outcome loss': 0.8204634389089, 'Total loss': 0.8204634389089}
2022-11-18 01:04:38,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:38,873 INFO:     Epoch: 22
2022-11-18 01:04:39,721 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7886445373296738, 'Total loss': 0.7886445373296738} | train loss {'Reaction outcome loss': 0.82017648171994, 'Total loss': 0.82017648171994}
2022-11-18 01:04:39,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:39,721 INFO:     Epoch: 23
2022-11-18 01:04:40,510 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7901353734460744, 'Total loss': 0.7901353734460744} | train loss {'Reaction outcome loss': 0.8203098704257319, 'Total loss': 0.8203098704257319}
2022-11-18 01:04:40,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:40,511 INFO:     Epoch: 24
2022-11-18 01:04:41,289 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7874885275959969, 'Total loss': 0.7874885275959969} | train loss {'Reaction outcome loss': 0.8220146733426279, 'Total loss': 0.8220146733426279}
2022-11-18 01:04:41,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:41,289 INFO:     Epoch: 25
2022-11-18 01:04:42,082 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7918188775127585, 'Total loss': 0.7918188775127585} | train loss {'Reaction outcome loss': 0.8203187027285176, 'Total loss': 0.8203187027285176}
2022-11-18 01:04:42,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:42,083 INFO:     Epoch: 26
2022-11-18 01:04:42,877 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8303459584712982, 'Total loss': 0.8303459584712982} | train loss {'Reaction outcome loss': 0.8169606032390748, 'Total loss': 0.8169606032390748}
2022-11-18 01:04:42,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:42,877 INFO:     Epoch: 27
2022-11-18 01:04:43,665 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7830932580611922, 'Total loss': 0.7830932580611922} | train loss {'Reaction outcome loss': 0.8149352697355132, 'Total loss': 0.8149352697355132}
2022-11-18 01:04:43,666 INFO:     Found new best model at epoch 27
2022-11-18 01:04:43,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:43,666 INFO:     Epoch: 28
2022-11-18 01:04:44,417 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7837169773199342, 'Total loss': 0.7837169773199342} | train loss {'Reaction outcome loss': 0.8205292586597704, 'Total loss': 0.8205292586597704}
2022-11-18 01:04:44,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:44,417 INFO:     Epoch: 29
2022-11-18 01:04:45,213 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.779244488613172, 'Total loss': 0.779244488613172} | train loss {'Reaction outcome loss': 0.8131240590685799, 'Total loss': 0.8131240590685799}
2022-11-18 01:04:45,213 INFO:     Found new best model at epoch 29
2022-11-18 01:04:45,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:45,214 INFO:     Epoch: 30
2022-11-18 01:04:45,989 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7913515222343531, 'Total loss': 0.7913515222343531} | train loss {'Reaction outcome loss': 0.8182611799528522, 'Total loss': 0.8182611799528522}
2022-11-18 01:04:45,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:45,989 INFO:     Epoch: 31
2022-11-18 01:04:46,750 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7891777029091661, 'Total loss': 0.7891777029091661} | train loss {'Reaction outcome loss': 0.8161306190154245, 'Total loss': 0.8161306190154245}
2022-11-18 01:04:46,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:46,750 INFO:     Epoch: 32
2022-11-18 01:04:47,535 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8164341896772385, 'Total loss': 0.8164341896772385} | train loss {'Reaction outcome loss': 0.8175510021467363, 'Total loss': 0.8175510021467363}
2022-11-18 01:04:47,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:47,536 INFO:     Epoch: 33
2022-11-18 01:04:48,350 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7940065928480842, 'Total loss': 0.7940065928480842} | train loss {'Reaction outcome loss': 0.8153833374381065, 'Total loss': 0.8153833374381065}
2022-11-18 01:04:48,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:48,350 INFO:     Epoch: 34
2022-11-18 01:04:49,128 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7805087112567641, 'Total loss': 0.7805087112567641} | train loss {'Reaction outcome loss': 0.810941968653952, 'Total loss': 0.810941968653952}
2022-11-18 01:04:49,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:49,128 INFO:     Epoch: 35
2022-11-18 01:04:49,936 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7927970710125837, 'Total loss': 0.7927970710125837} | train loss {'Reaction outcome loss': 0.8161192769485135, 'Total loss': 0.8161192769485135}
2022-11-18 01:04:49,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:49,936 INFO:     Epoch: 36
2022-11-18 01:04:50,810 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8060166856104677, 'Total loss': 0.8060166856104677} | train loss {'Reaction outcome loss': 0.8192583091797367, 'Total loss': 0.8192583091797367}
2022-11-18 01:04:50,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:50,810 INFO:     Epoch: 37
2022-11-18 01:04:51,620 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7784677344289693, 'Total loss': 0.7784677344289693} | train loss {'Reaction outcome loss': 0.814993743574427, 'Total loss': 0.814993743574427}
2022-11-18 01:04:51,620 INFO:     Found new best model at epoch 37
2022-11-18 01:04:51,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:51,621 INFO:     Epoch: 38
2022-11-18 01:04:52,431 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7830460931767117, 'Total loss': 0.7830460931767117} | train loss {'Reaction outcome loss': 0.8152832088451232, 'Total loss': 0.8152832088451232}
2022-11-18 01:04:52,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:52,431 INFO:     Epoch: 39
2022-11-18 01:04:53,230 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8081748641350053, 'Total loss': 0.8081748641350053} | train loss {'Reaction outcome loss': 0.8144195791213743, 'Total loss': 0.8144195791213743}
2022-11-18 01:04:53,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:53,231 INFO:     Epoch: 40
2022-11-18 01:04:54,048 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7905385812575166, 'Total loss': 0.7905385812575166} | train loss {'Reaction outcome loss': 0.8197679347809284, 'Total loss': 0.8197679347809284}
2022-11-18 01:04:54,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:54,048 INFO:     Epoch: 41
2022-11-18 01:04:54,846 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7881633375178684, 'Total loss': 0.7881633375178684} | train loss {'Reaction outcome loss': 0.814660532580268, 'Total loss': 0.814660532580268}
2022-11-18 01:04:54,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:54,847 INFO:     Epoch: 42
2022-11-18 01:04:55,644 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8051480745727365, 'Total loss': 0.8051480745727365} | train loss {'Reaction outcome loss': 0.8074280327606586, 'Total loss': 0.8074280327606586}
2022-11-18 01:04:55,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:55,644 INFO:     Epoch: 43
2022-11-18 01:04:56,460 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7897556390274655, 'Total loss': 0.7897556390274655} | train loss {'Reaction outcome loss': 0.812799820856702, 'Total loss': 0.812799820856702}
2022-11-18 01:04:56,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:56,460 INFO:     Epoch: 44
2022-11-18 01:04:57,248 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8019553246823224, 'Total loss': 0.8019553246823224} | train loss {'Reaction outcome loss': 0.8124480043207446, 'Total loss': 0.8124480043207446}
2022-11-18 01:04:57,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:57,248 INFO:     Epoch: 45
2022-11-18 01:04:58,028 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7743447409434752, 'Total loss': 0.7743447409434752} | train loss {'Reaction outcome loss': 0.8141163191007029, 'Total loss': 0.8141163191007029}
2022-11-18 01:04:58,028 INFO:     Found new best model at epoch 45
2022-11-18 01:04:58,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:58,029 INFO:     Epoch: 46
2022-11-18 01:04:58,871 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7972115630453284, 'Total loss': 0.7972115630453284} | train loss {'Reaction outcome loss': 0.8125260359337253, 'Total loss': 0.8125260359337253}
2022-11-18 01:04:58,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:58,871 INFO:     Epoch: 47
2022-11-18 01:04:59,666 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7926323637366295, 'Total loss': 0.7926323637366295} | train loss {'Reaction outcome loss': 0.8159675308533253, 'Total loss': 0.8159675308533253}
2022-11-18 01:04:59,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:04:59,667 INFO:     Epoch: 48
2022-11-18 01:05:00,445 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8154187229546633, 'Total loss': 0.8154187229546633} | train loss {'Reaction outcome loss': 0.8116489851907376, 'Total loss': 0.8116489851907376}
2022-11-18 01:05:00,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:00,445 INFO:     Epoch: 49
2022-11-18 01:05:01,268 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8002967096187852, 'Total loss': 0.8002967096187852} | train loss {'Reaction outcome loss': 0.8095189810039536, 'Total loss': 0.8095189810039536}
2022-11-18 01:05:01,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:01,268 INFO:     Epoch: 50
2022-11-18 01:05:02,061 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7792867550795729, 'Total loss': 0.7792867550795729} | train loss {'Reaction outcome loss': 0.8150528419402338, 'Total loss': 0.8150528419402338}
2022-11-18 01:05:02,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:02,061 INFO:     Epoch: 51
2022-11-18 01:05:02,866 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7830900705673478, 'Total loss': 0.7830900705673478} | train loss {'Reaction outcome loss': 0.8147184954535577, 'Total loss': 0.8147184954535577}
2022-11-18 01:05:02,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:02,866 INFO:     Epoch: 52
2022-11-18 01:05:03,671 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8005185581066392, 'Total loss': 0.8005185581066392} | train loss {'Reaction outcome loss': 0.8149884707264362, 'Total loss': 0.8149884707264362}
2022-11-18 01:05:03,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:03,671 INFO:     Epoch: 53
2022-11-18 01:05:04,451 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8249835690314119, 'Total loss': 0.8249835690314119} | train loss {'Reaction outcome loss': 0.8178803553023646, 'Total loss': 0.8178803553023646}
2022-11-18 01:05:04,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:04,452 INFO:     Epoch: 54
2022-11-18 01:05:05,295 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7782735126939687, 'Total loss': 0.7782735126939687} | train loss {'Reaction outcome loss': 0.8189874356312137, 'Total loss': 0.8189874356312137}
2022-11-18 01:05:05,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:05,295 INFO:     Epoch: 55
2022-11-18 01:05:06,172 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8052746192975477, 'Total loss': 0.8052746192975477} | train loss {'Reaction outcome loss': 0.8163461534967346, 'Total loss': 0.8163461534967346}
2022-11-18 01:05:06,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:06,172 INFO:     Epoch: 56
2022-11-18 01:05:07,053 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.778065100312233, 'Total loss': 0.778065100312233} | train loss {'Reaction outcome loss': 0.8134196995487136, 'Total loss': 0.8134196995487136}
2022-11-18 01:05:07,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:07,055 INFO:     Epoch: 57
2022-11-18 01:05:07,856 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7800094099207358, 'Total loss': 0.7800094099207358} | train loss {'Reaction outcome loss': 0.813925914826893, 'Total loss': 0.813925914826893}
2022-11-18 01:05:07,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:07,856 INFO:     Epoch: 58
2022-11-18 01:05:08,685 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7882342812689868, 'Total loss': 0.7882342812689868} | train loss {'Reaction outcome loss': 0.8171653516830937, 'Total loss': 0.8171653516830937}
2022-11-18 01:05:08,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:08,685 INFO:     Epoch: 59
2022-11-18 01:05:09,473 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7703205787322738, 'Total loss': 0.7703205787322738} | train loss {'Reaction outcome loss': 0.8127805665135384, 'Total loss': 0.8127805665135384}
2022-11-18 01:05:09,473 INFO:     Found new best model at epoch 59
2022-11-18 01:05:09,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:09,474 INFO:     Epoch: 60
2022-11-18 01:05:10,242 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7846140577034517, 'Total loss': 0.7846140577034517} | train loss {'Reaction outcome loss': 0.8105895359429621, 'Total loss': 0.8105895359429621}
2022-11-18 01:05:10,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:10,242 INFO:     Epoch: 61
2022-11-18 01:05:11,069 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7783512886274945, 'Total loss': 0.7783512886274945} | train loss {'Reaction outcome loss': 0.8137815275019215, 'Total loss': 0.8137815275019215}
2022-11-18 01:05:11,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:11,069 INFO:     Epoch: 62
2022-11-18 01:05:11,852 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7899484377015721, 'Total loss': 0.7899484377015721} | train loss {'Reaction outcome loss': 0.8134242328664949, 'Total loss': 0.8134242328664949}
2022-11-18 01:05:11,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:11,853 INFO:     Epoch: 63
2022-11-18 01:05:12,674 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7911274270577864, 'Total loss': 0.7911274270577864} | train loss {'Reaction outcome loss': 0.8128441907465458, 'Total loss': 0.8128441907465458}
2022-11-18 01:05:12,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:12,675 INFO:     Epoch: 64
2022-11-18 01:05:13,500 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7896326583894816, 'Total loss': 0.7896326583894816} | train loss {'Reaction outcome loss': 0.8100572885765184, 'Total loss': 0.8100572885765184}
2022-11-18 01:05:13,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:13,501 INFO:     Epoch: 65
2022-11-18 01:05:14,301 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7826125235720114, 'Total loss': 0.7826125235720114} | train loss {'Reaction outcome loss': 0.8085713814343175, 'Total loss': 0.8085713814343175}
2022-11-18 01:05:14,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:14,301 INFO:     Epoch: 66
2022-11-18 01:05:15,136 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7849514755335721, 'Total loss': 0.7849514755335721} | train loss {'Reaction outcome loss': 0.811547018347248, 'Total loss': 0.811547018347248}
2022-11-18 01:05:15,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:15,136 INFO:     Epoch: 67
2022-11-18 01:05:15,951 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8061336766589772, 'Total loss': 0.8061336766589772} | train loss {'Reaction outcome loss': 0.8150477106532743, 'Total loss': 0.8150477106532743}
2022-11-18 01:05:15,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:15,951 INFO:     Epoch: 68
2022-11-18 01:05:16,753 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7898748896338723, 'Total loss': 0.7898748896338723} | train loss {'Reaction outcome loss': 0.812927873384568, 'Total loss': 0.812927873384568}
2022-11-18 01:05:16,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:16,753 INFO:     Epoch: 69
2022-11-18 01:05:17,521 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7795584852045233, 'Total loss': 0.7795584852045233} | train loss {'Reaction outcome loss': 0.8079892869197554, 'Total loss': 0.8079892869197554}
2022-11-18 01:05:17,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:17,521 INFO:     Epoch: 70
2022-11-18 01:05:18,315 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7923908883875067, 'Total loss': 0.7923908883875067} | train loss {'Reaction outcome loss': 0.8169787022615632, 'Total loss': 0.8169787022615632}
2022-11-18 01:05:18,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:18,315 INFO:     Epoch: 71
2022-11-18 01:05:19,104 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.775169853459705, 'Total loss': 0.775169853459705} | train loss {'Reaction outcome loss': 0.8095638779622893, 'Total loss': 0.8095638779622893}
2022-11-18 01:05:19,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:19,104 INFO:     Epoch: 72
2022-11-18 01:05:19,902 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7840553738854148, 'Total loss': 0.7840553738854148} | train loss {'Reaction outcome loss': 0.8126534973421404, 'Total loss': 0.8126534973421404}
2022-11-18 01:05:19,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:19,902 INFO:     Epoch: 73
2022-11-18 01:05:20,710 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7783559276299044, 'Total loss': 0.7783559276299044} | train loss {'Reaction outcome loss': 0.8106822385903327, 'Total loss': 0.8106822385903327}
2022-11-18 01:05:20,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:20,710 INFO:     Epoch: 74
2022-11-18 01:05:21,497 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8103841326453469, 'Total loss': 0.8103841326453469} | train loss {'Reaction outcome loss': 0.8175895519314273, 'Total loss': 0.8175895519314273}
2022-11-18 01:05:21,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:21,497 INFO:     Epoch: 75
2022-11-18 01:05:22,288 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8198422362858598, 'Total loss': 0.8198422362858598} | train loss {'Reaction outcome loss': 0.8156850848707461, 'Total loss': 0.8156850848707461}
2022-11-18 01:05:22,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:22,288 INFO:     Epoch: 76
2022-11-18 01:05:23,101 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7816800556399606, 'Total loss': 0.7816800556399606} | train loss {'Reaction outcome loss': 0.8147910106326303, 'Total loss': 0.8147910106326303}
2022-11-18 01:05:23,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:23,101 INFO:     Epoch: 77
2022-11-18 01:05:23,941 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7864470034837723, 'Total loss': 0.7864470034837723} | train loss {'Reaction outcome loss': 0.807465496683313, 'Total loss': 0.807465496683313}
2022-11-18 01:05:23,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:23,941 INFO:     Epoch: 78
2022-11-18 01:05:24,769 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7933041846210306, 'Total loss': 0.7933041846210306} | train loss {'Reaction outcome loss': 0.8052794517528626, 'Total loss': 0.8052794517528626}
2022-11-18 01:05:24,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:24,770 INFO:     Epoch: 79
2022-11-18 01:05:25,594 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7807515392249281, 'Total loss': 0.7807515392249281} | train loss {'Reaction outcome loss': 0.8126065058092917, 'Total loss': 0.8126065058092917}
2022-11-18 01:05:25,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:25,595 INFO:     Epoch: 80
2022-11-18 01:05:26,410 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7838766771284017, 'Total loss': 0.7838766771284017} | train loss {'Reaction outcome loss': 0.8099951032669314, 'Total loss': 0.8099951032669314}
2022-11-18 01:05:26,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:26,410 INFO:     Epoch: 81
2022-11-18 01:05:27,219 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8021255433559418, 'Total loss': 0.8021255433559418} | train loss {'Reaction outcome loss': 0.8066927299143807, 'Total loss': 0.8066927299143807}
2022-11-18 01:05:27,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:27,219 INFO:     Epoch: 82
2022-11-18 01:05:28,017 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7755382291295312, 'Total loss': 0.7755382291295312} | train loss {'Reaction outcome loss': 0.8105832082369635, 'Total loss': 0.8105832082369635}
2022-11-18 01:05:28,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:28,017 INFO:     Epoch: 83
2022-11-18 01:05:28,812 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7682671011848883, 'Total loss': 0.7682671011848883} | train loss {'Reaction outcome loss': 0.8093901776498363, 'Total loss': 0.8093901776498363}
2022-11-18 01:05:28,812 INFO:     Found new best model at epoch 83
2022-11-18 01:05:28,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:28,813 INFO:     Epoch: 84
2022-11-18 01:05:29,653 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7679114267230034, 'Total loss': 0.7679114267230034} | train loss {'Reaction outcome loss': 0.8103541970974014, 'Total loss': 0.8103541970974014}
2022-11-18 01:05:29,653 INFO:     Found new best model at epoch 84
2022-11-18 01:05:29,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:29,654 INFO:     Epoch: 85
2022-11-18 01:05:30,466 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7863328836180947, 'Total loss': 0.7863328836180947} | train loss {'Reaction outcome loss': 0.8085862940117237, 'Total loss': 0.8085862940117237}
2022-11-18 01:05:30,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:30,467 INFO:     Epoch: 86
2022-11-18 01:05:31,238 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7826450731266629, 'Total loss': 0.7826450731266629} | train loss {'Reaction outcome loss': 0.807293297061997, 'Total loss': 0.807293297061997}
2022-11-18 01:05:31,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:31,239 INFO:     Epoch: 87
2022-11-18 01:05:32,021 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7758633636615493, 'Total loss': 0.7758633636615493} | train loss {'Reaction outcome loss': 0.8081190175106449, 'Total loss': 0.8081190175106449}
2022-11-18 01:05:32,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:32,021 INFO:     Epoch: 88
2022-11-18 01:05:32,821 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7818966616283763, 'Total loss': 0.7818966616283763} | train loss {'Reaction outcome loss': 0.8069411629149991, 'Total loss': 0.8069411629149991}
2022-11-18 01:05:32,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:32,821 INFO:     Epoch: 89
2022-11-18 01:05:33,653 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7787613672288981, 'Total loss': 0.7787613672288981} | train loss {'Reaction outcome loss': 0.8050010192898973, 'Total loss': 0.8050010192898973}
2022-11-18 01:05:33,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:33,654 INFO:     Epoch: 90
2022-11-18 01:05:34,452 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7692406760020689, 'Total loss': 0.7692406760020689} | train loss {'Reaction outcome loss': 0.8017822163960626, 'Total loss': 0.8017822163960626}
2022-11-18 01:05:34,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:34,452 INFO:     Epoch: 91
2022-11-18 01:05:35,260 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7900220155715942, 'Total loss': 0.7900220155715942} | train loss {'Reaction outcome loss': 0.8101274931142407, 'Total loss': 0.8101274931142407}
2022-11-18 01:05:35,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:35,260 INFO:     Epoch: 92
2022-11-18 01:05:36,037 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7927089570598169, 'Total loss': 0.7927089570598169} | train loss {'Reaction outcome loss': 0.8023455231901138, 'Total loss': 0.8023455231901138}
2022-11-18 01:05:36,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:36,038 INFO:     Epoch: 93
2022-11-18 01:05:36,843 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7631492242217064, 'Total loss': 0.7631492242217064} | train loss {'Reaction outcome loss': 0.8039914387608728, 'Total loss': 0.8039914387608728}
2022-11-18 01:05:36,843 INFO:     Found new best model at epoch 93
2022-11-18 01:05:36,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:36,844 INFO:     Epoch: 94
2022-11-18 01:05:37,683 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7691721272739497, 'Total loss': 0.7691721272739497} | train loss {'Reaction outcome loss': 0.8042475850351395, 'Total loss': 0.8042475850351395}
2022-11-18 01:05:37,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:37,683 INFO:     Epoch: 95
2022-11-18 01:05:38,507 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8308771808039058, 'Total loss': 0.8308771808039058} | train loss {'Reaction outcome loss': 0.8049100455978224, 'Total loss': 0.8049100455978224}
2022-11-18 01:05:38,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:38,508 INFO:     Epoch: 96
2022-11-18 01:05:39,321 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7709888152100823, 'Total loss': 0.7709888152100823} | train loss {'Reaction outcome loss': 0.801645835200625, 'Total loss': 0.801645835200625}
2022-11-18 01:05:39,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:39,321 INFO:     Epoch: 97
2022-11-18 01:05:40,135 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7701905390078371, 'Total loss': 0.7701905390078371} | train loss {'Reaction outcome loss': 0.7950945479735252, 'Total loss': 0.7950945479735252}
2022-11-18 01:05:40,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:40,135 INFO:     Epoch: 98
2022-11-18 01:05:40,932 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7609517777507956, 'Total loss': 0.7609517777507956} | train loss {'Reaction outcome loss': 0.8001620512335531, 'Total loss': 0.8001620512335531}
2022-11-18 01:05:40,932 INFO:     Found new best model at epoch 98
2022-11-18 01:05:40,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:40,933 INFO:     Epoch: 99
2022-11-18 01:05:41,777 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8086944385008379, 'Total loss': 0.8086944385008379} | train loss {'Reaction outcome loss': 0.7940120680197593, 'Total loss': 0.7940120680197593}
2022-11-18 01:05:41,777 INFO:     Best model found after epoch 99 of 100.
2022-11-18 01:05:41,777 INFO:   Done with stage: TRAINING
2022-11-18 01:05:41,777 INFO:   Starting stage: EVALUATION
2022-11-18 01:05:41,894 INFO:   Done with stage: EVALUATION
2022-11-18 01:05:41,895 INFO:   Leaving out SEQ value Fold_9
2022-11-18 01:05:41,908 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:05:41,908 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:05:42,577 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:05:42,577 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:05:42,650 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:05:42,650 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:05:42,650 INFO:     No hyperparam tuning for this model
2022-11-18 01:05:42,650 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:05:42,650 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:05:42,651 INFO:     None feature selector for col prot
2022-11-18 01:05:42,651 INFO:     None feature selector for col prot
2022-11-18 01:05:42,651 INFO:     None feature selector for col prot
2022-11-18 01:05:42,652 INFO:     None feature selector for col chem
2022-11-18 01:05:42,652 INFO:     None feature selector for col chem
2022-11-18 01:05:42,652 INFO:     None feature selector for col chem
2022-11-18 01:05:42,652 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:05:42,652 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:05:42,654 INFO:     Number of params in model 168571
2022-11-18 01:05:42,657 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:05:42,657 INFO:   Starting stage: TRAINING
2022-11-18 01:05:42,715 INFO:     Val loss before train {'Reaction outcome loss': 1.034478951584209, 'Total loss': 1.034478951584209}
2022-11-18 01:05:42,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:42,715 INFO:     Epoch: 0
2022-11-18 01:05:43,519 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8600187640298497, 'Total loss': 0.8600187640298497} | train loss {'Reaction outcome loss': 0.8776644236344074, 'Total loss': 0.8776644236344074}
2022-11-18 01:05:43,519 INFO:     Found new best model at epoch 0
2022-11-18 01:05:43,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:43,520 INFO:     Epoch: 1
2022-11-18 01:05:44,335 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8661458905447613, 'Total loss': 0.8661458905447613} | train loss {'Reaction outcome loss': 0.8498007669622599, 'Total loss': 0.8498007669622599}
2022-11-18 01:05:44,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:44,336 INFO:     Epoch: 2
2022-11-18 01:05:45,167 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8360953032970428, 'Total loss': 0.8360953032970428} | train loss {'Reaction outcome loss': 0.8487328838722908, 'Total loss': 0.8487328838722908}
2022-11-18 01:05:45,168 INFO:     Found new best model at epoch 2
2022-11-18 01:05:45,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:45,169 INFO:     Epoch: 3
2022-11-18 01:05:45,949 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8657583350485022, 'Total loss': 0.8657583350485022} | train loss {'Reaction outcome loss': 0.8413071318676597, 'Total loss': 0.8413071318676597}
2022-11-18 01:05:45,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:45,949 INFO:     Epoch: 4
2022-11-18 01:05:46,742 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.859134083444422, 'Total loss': 0.859134083444422} | train loss {'Reaction outcome loss': 0.842568342140329, 'Total loss': 0.842568342140329}
2022-11-18 01:05:46,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:46,742 INFO:     Epoch: 5
2022-11-18 01:05:47,578 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.854027234017849, 'Total loss': 0.854027234017849} | train loss {'Reaction outcome loss': 0.8428618679886405, 'Total loss': 0.8428618679886405}
2022-11-18 01:05:47,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:47,578 INFO:     Epoch: 6
2022-11-18 01:05:48,424 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8401204699819739, 'Total loss': 0.8401204699819739} | train loss {'Reaction outcome loss': 0.8425567434866902, 'Total loss': 0.8425567434866902}
2022-11-18 01:05:48,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:48,424 INFO:     Epoch: 7
2022-11-18 01:05:49,201 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8439732437784021, 'Total loss': 0.8439732437784021} | train loss {'Reaction outcome loss': 0.833141303617462, 'Total loss': 0.833141303617462}
2022-11-18 01:05:49,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:49,202 INFO:     Epoch: 8
2022-11-18 01:05:49,987 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.840050914070823, 'Total loss': 0.840050914070823} | train loss {'Reaction outcome loss': 0.8349630744592381, 'Total loss': 0.8349630744592381}
2022-11-18 01:05:49,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:49,988 INFO:     Epoch: 9
2022-11-18 01:05:50,783 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8420850973237645, 'Total loss': 0.8420850973237645} | train loss {'Reaction outcome loss': 0.8288423750805951, 'Total loss': 0.8288423750805951}
2022-11-18 01:05:50,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:50,783 INFO:     Epoch: 10
2022-11-18 01:05:51,598 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8456451730294661, 'Total loss': 0.8456451730294661} | train loss {'Reaction outcome loss': 0.827988963770239, 'Total loss': 0.827988963770239}
2022-11-18 01:05:51,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:51,598 INFO:     Epoch: 11
2022-11-18 01:05:52,383 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8503649234771729, 'Total loss': 0.8503649234771729} | train loss {'Reaction outcome loss': 0.8251777555537128, 'Total loss': 0.8251777555537128}
2022-11-18 01:05:52,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:52,383 INFO:     Epoch: 12
2022-11-18 01:05:53,200 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8698348809372295, 'Total loss': 0.8698348809372295} | train loss {'Reaction outcome loss': 0.8272460393818767, 'Total loss': 0.8272460393818767}
2022-11-18 01:05:53,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:53,201 INFO:     Epoch: 13
2022-11-18 01:05:54,009 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8247507167133418, 'Total loss': 0.8247507167133418} | train loss {'Reaction outcome loss': 0.8300513093046814, 'Total loss': 0.8300513093046814}
2022-11-18 01:05:54,009 INFO:     Found new best model at epoch 13
2022-11-18 01:05:54,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:54,010 INFO:     Epoch: 14
2022-11-18 01:05:54,800 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8495834070173177, 'Total loss': 0.8495834070173177} | train loss {'Reaction outcome loss': 0.8265348316928153, 'Total loss': 0.8265348316928153}
2022-11-18 01:05:54,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:54,801 INFO:     Epoch: 15
2022-11-18 01:05:55,605 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8384965651414611, 'Total loss': 0.8384965651414611} | train loss {'Reaction outcome loss': 0.831748928256363, 'Total loss': 0.831748928256363}
2022-11-18 01:05:55,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:55,606 INFO:     Epoch: 16
2022-11-18 01:05:56,423 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8224779441952705, 'Total loss': 0.8224779441952705} | train loss {'Reaction outcome loss': 0.8327794466846385, 'Total loss': 0.8327794466846385}
2022-11-18 01:05:56,423 INFO:     Found new best model at epoch 16
2022-11-18 01:05:56,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:56,424 INFO:     Epoch: 17
2022-11-18 01:05:57,233 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8474989689209245, 'Total loss': 0.8474989689209245} | train loss {'Reaction outcome loss': 0.8281004816173059, 'Total loss': 0.8281004816173059}
2022-11-18 01:05:57,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:57,234 INFO:     Epoch: 18
2022-11-18 01:05:58,081 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8376710760322484, 'Total loss': 0.8376710760322484} | train loss {'Reaction outcome loss': 0.8366048751089737, 'Total loss': 0.8366048751089737}
2022-11-18 01:05:58,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:58,081 INFO:     Epoch: 19
2022-11-18 01:05:58,877 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8307236284017563, 'Total loss': 0.8307236284017563} | train loss {'Reaction outcome loss': 0.8223070489612185, 'Total loss': 0.8223070489612185}
2022-11-18 01:05:58,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:58,877 INFO:     Epoch: 20
2022-11-18 01:05:59,672 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8275937322865833, 'Total loss': 0.8275937322865833} | train loss {'Reaction outcome loss': 0.818979338837056, 'Total loss': 0.818979338837056}
2022-11-18 01:05:59,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:05:59,673 INFO:     Epoch: 21
2022-11-18 01:06:00,480 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8261779357086528, 'Total loss': 0.8261779357086528} | train loss {'Reaction outcome loss': 0.8146011542212143, 'Total loss': 0.8146011542212143}
2022-11-18 01:06:00,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:00,481 INFO:     Epoch: 22
2022-11-18 01:06:01,275 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8352963172576644, 'Total loss': 0.8352963172576644} | train loss {'Reaction outcome loss': 0.8281115452770279, 'Total loss': 0.8281115452770279}
2022-11-18 01:06:01,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:01,275 INFO:     Epoch: 23
2022-11-18 01:06:02,069 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8318880843845281, 'Total loss': 0.8318880843845281} | train loss {'Reaction outcome loss': 0.8188680799504523, 'Total loss': 0.8188680799504523}
2022-11-18 01:06:02,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:02,070 INFO:     Epoch: 24
2022-11-18 01:06:02,925 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8633531630039215, 'Total loss': 0.8633531630039215} | train loss {'Reaction outcome loss': 0.8233147175447179, 'Total loss': 0.8233147175447179}
2022-11-18 01:06:02,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:02,925 INFO:     Epoch: 25
2022-11-18 01:06:03,723 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8285707621411844, 'Total loss': 0.8285707621411844} | train loss {'Reaction outcome loss': 0.8222746350745923, 'Total loss': 0.8222746350745923}
2022-11-18 01:06:03,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:03,723 INFO:     Epoch: 26
2022-11-18 01:06:04,524 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8232338618148457, 'Total loss': 0.8232338618148457} | train loss {'Reaction outcome loss': 0.8260519762753475, 'Total loss': 0.8260519762753475}
2022-11-18 01:06:04,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:04,524 INFO:     Epoch: 27
2022-11-18 01:06:05,313 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8589995354413986, 'Total loss': 0.8589995354413986} | train loss {'Reaction outcome loss': 0.8254415994954978, 'Total loss': 0.8254415994954978}
2022-11-18 01:06:05,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:05,313 INFO:     Epoch: 28
2022-11-18 01:06:06,174 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8325742340900681, 'Total loss': 0.8325742340900681} | train loss {'Reaction outcome loss': 0.8238420763961699, 'Total loss': 0.8238420763961699}
2022-11-18 01:06:06,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:06,174 INFO:     Epoch: 29
2022-11-18 01:06:06,972 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8418574245138601, 'Total loss': 0.8418574245138601} | train loss {'Reaction outcome loss': 0.8220778502192092, 'Total loss': 0.8220778502192092}
2022-11-18 01:06:06,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:06,972 INFO:     Epoch: 30
2022-11-18 01:06:07,746 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8306338556788184, 'Total loss': 0.8306338556788184} | train loss {'Reaction outcome loss': 0.8225666315027094, 'Total loss': 0.8225666315027094}
2022-11-18 01:06:07,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:07,747 INFO:     Epoch: 31
2022-11-18 01:06:08,531 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8343996507200327, 'Total loss': 0.8343996507200327} | train loss {'Reaction outcome loss': 0.8195527347958522, 'Total loss': 0.8195527347958522}
2022-11-18 01:06:08,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:08,531 INFO:     Epoch: 32
2022-11-18 01:06:09,357 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8541444499384273, 'Total loss': 0.8541444499384273} | train loss {'Reaction outcome loss': 0.8212017699291831, 'Total loss': 0.8212017699291831}
2022-11-18 01:06:09,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:09,359 INFO:     Epoch: 33
2022-11-18 01:06:10,154 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8267759822986342, 'Total loss': 0.8267759822986342} | train loss {'Reaction outcome loss': 0.82012067698998, 'Total loss': 0.82012067698998}
2022-11-18 01:06:10,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:10,155 INFO:     Epoch: 34
2022-11-18 01:06:10,988 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8349281901663, 'Total loss': 0.8349281901663} | train loss {'Reaction outcome loss': 0.8171312551387409, 'Total loss': 0.8171312551387409}
2022-11-18 01:06:10,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:10,989 INFO:     Epoch: 35
2022-11-18 01:06:11,753 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.833402232690291, 'Total loss': 0.833402232690291} | train loss {'Reaction outcome loss': 0.8211598002958876, 'Total loss': 0.8211598002958876}
2022-11-18 01:06:11,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:11,753 INFO:     Epoch: 36
2022-11-18 01:06:12,554 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8343908773227171, 'Total loss': 0.8343908773227171} | train loss {'Reaction outcome loss': 0.8188210748709165, 'Total loss': 0.8188210748709165}
2022-11-18 01:06:12,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:12,554 INFO:     Epoch: 37
2022-11-18 01:06:13,380 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8328846401788972, 'Total loss': 0.8328846401788972} | train loss {'Reaction outcome loss': 0.82393279116646, 'Total loss': 0.82393279116646}
2022-11-18 01:06:13,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:13,380 INFO:     Epoch: 38
2022-11-18 01:06:14,178 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8412015715783293, 'Total loss': 0.8412015715783293} | train loss {'Reaction outcome loss': 0.8165544834938127, 'Total loss': 0.8165544834938127}
2022-11-18 01:06:14,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:14,178 INFO:     Epoch: 39
2022-11-18 01:06:14,987 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8889480463483117, 'Total loss': 0.8889480463483117} | train loss {'Reaction outcome loss': 0.8187326967474903, 'Total loss': 0.8187326967474903}
2022-11-18 01:06:14,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:14,987 INFO:     Epoch: 40
2022-11-18 01:06:15,805 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8393325128338553, 'Total loss': 0.8393325128338553} | train loss {'Reaction outcome loss': 0.8253915377474024, 'Total loss': 0.8253915377474024}
2022-11-18 01:06:15,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:15,807 INFO:     Epoch: 41
2022-11-18 01:06:16,619 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8419286500323903, 'Total loss': 0.8419286500323903} | train loss {'Reaction outcome loss': 0.8159265185476314, 'Total loss': 0.8159265185476314}
2022-11-18 01:06:16,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:16,619 INFO:     Epoch: 42
2022-11-18 01:06:17,433 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8251565335826441, 'Total loss': 0.8251565335826441} | train loss {'Reaction outcome loss': 0.8196707096418389, 'Total loss': 0.8196707096418389}
2022-11-18 01:06:17,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:17,434 INFO:     Epoch: 43
2022-11-18 01:06:18,218 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8261827230453491, 'Total loss': 0.8261827230453491} | train loss {'Reaction outcome loss': 0.8175886848918822, 'Total loss': 0.8175886848918822}
2022-11-18 01:06:18,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:18,218 INFO:     Epoch: 44
2022-11-18 01:06:19,066 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8412172882394358, 'Total loss': 0.8412172882394358} | train loss {'Reaction outcome loss': 0.8177862389367602, 'Total loss': 0.8177862389367602}
2022-11-18 01:06:19,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:19,067 INFO:     Epoch: 45
2022-11-18 01:06:19,878 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8319793235171925, 'Total loss': 0.8319793235171925} | train loss {'Reaction outcome loss': 0.8247520530272109, 'Total loss': 0.8247520530272109}
2022-11-18 01:06:19,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:19,878 INFO:     Epoch: 46
2022-11-18 01:06:20,711 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8291800543665886, 'Total loss': 0.8291800543665886} | train loss {'Reaction outcome loss': 0.8245052935382132, 'Total loss': 0.8245052935382132}
2022-11-18 01:06:20,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:20,711 INFO:     Epoch: 47
2022-11-18 01:06:21,502 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8375054970383644, 'Total loss': 0.8375054970383644} | train loss {'Reaction outcome loss': 0.8287587615883785, 'Total loss': 0.8287587615883785}
2022-11-18 01:06:21,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:21,502 INFO:     Epoch: 48
2022-11-18 01:06:22,336 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8204897791147232, 'Total loss': 0.8204897791147232} | train loss {'Reaction outcome loss': 0.8235512344460738, 'Total loss': 0.8235512344460738}
2022-11-18 01:06:22,336 INFO:     Found new best model at epoch 48
2022-11-18 01:06:22,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:22,337 INFO:     Epoch: 49
2022-11-18 01:06:23,168 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.833966157653115, 'Total loss': 0.833966157653115} | train loss {'Reaction outcome loss': 0.818655472897325, 'Total loss': 0.818655472897325}
2022-11-18 01:06:23,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:23,169 INFO:     Epoch: 50
2022-11-18 01:06:23,987 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8197783008217812, 'Total loss': 0.8197783008217812} | train loss {'Reaction outcome loss': 0.8177939054333729, 'Total loss': 0.8177939054333729}
2022-11-18 01:06:23,987 INFO:     Found new best model at epoch 50
2022-11-18 01:06:23,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:23,988 INFO:     Epoch: 51
2022-11-18 01:06:24,784 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8265751620585268, 'Total loss': 0.8265751620585268} | train loss {'Reaction outcome loss': 0.8181115038964429, 'Total loss': 0.8181115038964429}
2022-11-18 01:06:24,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:24,784 INFO:     Epoch: 52
2022-11-18 01:06:25,589 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8252032405950807, 'Total loss': 0.8252032405950807} | train loss {'Reaction outcome loss': 0.8207159027276252, 'Total loss': 0.8207159027276252}
2022-11-18 01:06:25,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:25,590 INFO:     Epoch: 53
2022-11-18 01:06:26,438 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8258821950717405, 'Total loss': 0.8258821950717405} | train loss {'Reaction outcome loss': 0.8113461189605446, 'Total loss': 0.8113461189605446}
2022-11-18 01:06:26,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:26,438 INFO:     Epoch: 54
2022-11-18 01:06:27,246 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8264711898836222, 'Total loss': 0.8264711898836222} | train loss {'Reaction outcome loss': 0.8193241614803128, 'Total loss': 0.8193241614803128}
2022-11-18 01:06:27,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:27,246 INFO:     Epoch: 55
2022-11-18 01:06:28,102 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8401901491663673, 'Total loss': 0.8401901491663673} | train loss {'Reaction outcome loss': 0.8198450915967888, 'Total loss': 0.8198450915967888}
2022-11-18 01:06:28,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:28,103 INFO:     Epoch: 56
2022-11-18 01:06:28,888 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8248416957530108, 'Total loss': 0.8248416957530108} | train loss {'Reaction outcome loss': 0.8171231220155833, 'Total loss': 0.8171231220155833}
2022-11-18 01:06:28,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:28,889 INFO:     Epoch: 57
2022-11-18 01:06:29,738 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8292136740955439, 'Total loss': 0.8292136740955439} | train loss {'Reaction outcome loss': 0.817100766216695, 'Total loss': 0.817100766216695}
2022-11-18 01:06:29,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:29,738 INFO:     Epoch: 58
2022-11-18 01:06:30,525 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8300976597449996, 'Total loss': 0.8300976597449996} | train loss {'Reaction outcome loss': 0.8165200884163621, 'Total loss': 0.8165200884163621}
2022-11-18 01:06:30,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:30,526 INFO:     Epoch: 59
2022-11-18 01:06:31,345 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8122876130721786, 'Total loss': 0.8122876130721786} | train loss {'Reaction outcome loss': 0.8251738154936415, 'Total loss': 0.8251738154936415}
2022-11-18 01:06:31,345 INFO:     Found new best model at epoch 59
2022-11-18 01:06:31,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:31,346 INFO:     Epoch: 60
2022-11-18 01:06:32,139 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8287510025230321, 'Total loss': 0.8287510025230321} | train loss {'Reaction outcome loss': 0.8112754479110965, 'Total loss': 0.8112754479110965}
2022-11-18 01:06:32,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:32,139 INFO:     Epoch: 61
2022-11-18 01:06:32,989 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8119041432033886, 'Total loss': 0.8119041432033886} | train loss {'Reaction outcome loss': 0.8223885835906272, 'Total loss': 0.8223885835906272}
2022-11-18 01:06:32,989 INFO:     Found new best model at epoch 61
2022-11-18 01:06:32,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:32,990 INFO:     Epoch: 62
2022-11-18 01:06:33,784 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8314280564134772, 'Total loss': 0.8314280564134772} | train loss {'Reaction outcome loss': 0.8205721114087201, 'Total loss': 0.8205721114087201}
2022-11-18 01:06:33,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:33,784 INFO:     Epoch: 63
2022-11-18 01:06:34,602 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.825426696376367, 'Total loss': 0.825426696376367} | train loss {'Reaction outcome loss': 0.8166759226787911, 'Total loss': 0.8166759226787911}
2022-11-18 01:06:34,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:34,602 INFO:     Epoch: 64
2022-11-18 01:06:35,406 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8131481097503142, 'Total loss': 0.8131481097503142} | train loss {'Reaction outcome loss': 0.8211692652480322, 'Total loss': 0.8211692652480322}
2022-11-18 01:06:35,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:35,406 INFO:     Epoch: 65
2022-11-18 01:06:36,217 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8526425761255351, 'Total loss': 0.8526425761255351} | train loss {'Reaction outcome loss': 0.8132592705398919, 'Total loss': 0.8132592705398919}
2022-11-18 01:06:36,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:36,217 INFO:     Epoch: 66
2022-11-18 01:06:37,013 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8237115063450553, 'Total loss': 0.8237115063450553} | train loss {'Reaction outcome loss': 0.8210009869776274, 'Total loss': 0.8210009869776274}
2022-11-18 01:06:37,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:37,014 INFO:     Epoch: 67
2022-11-18 01:06:37,823 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8312705206600103, 'Total loss': 0.8312705206600103} | train loss {'Reaction outcome loss': 0.8169233313938866, 'Total loss': 0.8169233313938866}
2022-11-18 01:06:37,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:37,824 INFO:     Epoch: 68
2022-11-18 01:06:38,605 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8140739622441205, 'Total loss': 0.8140739622441205} | train loss {'Reaction outcome loss': 0.823279211275008, 'Total loss': 0.823279211275008}
2022-11-18 01:06:38,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:38,606 INFO:     Epoch: 69
2022-11-18 01:06:39,404 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8108938830819997, 'Total loss': 0.8108938830819997} | train loss {'Reaction outcome loss': 0.8227624622916403, 'Total loss': 0.8227624622916403}
2022-11-18 01:06:39,404 INFO:     Found new best model at epoch 69
2022-11-18 01:06:39,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:39,405 INFO:     Epoch: 70
2022-11-18 01:06:40,223 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8383391187949614, 'Total loss': 0.8383391187949614} | train loss {'Reaction outcome loss': 0.8162943407410552, 'Total loss': 0.8162943407410552}
2022-11-18 01:06:40,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:40,225 INFO:     Epoch: 71
2022-11-18 01:06:41,032 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8199815939773213, 'Total loss': 0.8199815939773213} | train loss {'Reaction outcome loss': 0.8215985211283572, 'Total loss': 0.8215985211283572}
2022-11-18 01:06:41,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:41,033 INFO:     Epoch: 72
2022-11-18 01:06:41,841 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8191107179630887, 'Total loss': 0.8191107179630887} | train loss {'Reaction outcome loss': 0.8206059493516621, 'Total loss': 0.8206059493516621}
2022-11-18 01:06:41,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:41,841 INFO:     Epoch: 73
2022-11-18 01:06:42,651 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8328204649415883, 'Total loss': 0.8328204649415883} | train loss {'Reaction outcome loss': 0.8189573362771316, 'Total loss': 0.8189573362771316}
2022-11-18 01:06:42,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:42,652 INFO:     Epoch: 74
2022-11-18 01:06:43,464 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8207235525954854, 'Total loss': 0.8207235525954854} | train loss {'Reaction outcome loss': 0.8180218036116859, 'Total loss': 0.8180218036116859}
2022-11-18 01:06:43,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:43,465 INFO:     Epoch: 75
2022-11-18 01:06:44,275 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.836580017073588, 'Total loss': 0.836580017073588} | train loss {'Reaction outcome loss': 0.8201746265535895, 'Total loss': 0.8201746265535895}
2022-11-18 01:06:44,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:44,275 INFO:     Epoch: 76
2022-11-18 01:06:45,064 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8225247169082816, 'Total loss': 0.8225247169082816} | train loss {'Reaction outcome loss': 0.8163190470774647, 'Total loss': 0.8163190470774647}
2022-11-18 01:06:45,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:45,065 INFO:     Epoch: 77
2022-11-18 01:06:45,860 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8306906473907557, 'Total loss': 0.8306906473907557} | train loss {'Reaction outcome loss': 0.8149847770750764, 'Total loss': 0.8149847770750764}
2022-11-18 01:06:45,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:45,860 INFO:     Epoch: 78
2022-11-18 01:06:46,701 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8198128925128416, 'Total loss': 0.8198128925128416} | train loss {'Reaction outcome loss': 0.8174449224703708, 'Total loss': 0.8174449224703708}
2022-11-18 01:06:46,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:46,702 INFO:     Epoch: 79
2022-11-18 01:06:47,519 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8852415078065612, 'Total loss': 0.8852415078065612} | train loss {'Reaction outcome loss': 0.8097398183666743, 'Total loss': 0.8097398183666743}
2022-11-18 01:06:47,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:47,519 INFO:     Epoch: 80
2022-11-18 01:06:48,337 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8177855346690525, 'Total loss': 0.8177855346690525} | train loss {'Reaction outcome loss': 0.8216201106184408, 'Total loss': 0.8216201106184408}
2022-11-18 01:06:48,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:48,338 INFO:     Epoch: 81
2022-11-18 01:06:49,140 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8131211779334329, 'Total loss': 0.8131211779334329} | train loss {'Reaction outcome loss': 0.8175169744411943, 'Total loss': 0.8175169744411943}
2022-11-18 01:06:49,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:49,140 INFO:     Epoch: 82
2022-11-18 01:06:49,973 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8146579929373481, 'Total loss': 0.8146579929373481} | train loss {'Reaction outcome loss': 0.8106190147790832, 'Total loss': 0.8106190147790832}
2022-11-18 01:06:49,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:49,973 INFO:     Epoch: 83
2022-11-18 01:06:50,826 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8226326372135769, 'Total loss': 0.8226326372135769} | train loss {'Reaction outcome loss': 0.8198986130687389, 'Total loss': 0.8198986130687389}
2022-11-18 01:06:50,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:50,827 INFO:     Epoch: 84
2022-11-18 01:06:51,662 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8172510063106363, 'Total loss': 0.8172510063106363} | train loss {'Reaction outcome loss': 0.8234049034746069, 'Total loss': 0.8234049034746069}
2022-11-18 01:06:51,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:51,662 INFO:     Epoch: 85
2022-11-18 01:06:52,431 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8145477812398564, 'Total loss': 0.8145477812398564} | train loss {'Reaction outcome loss': 0.8230445533387574, 'Total loss': 0.8230445533387574}
2022-11-18 01:06:52,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:52,431 INFO:     Epoch: 86
2022-11-18 01:06:53,226 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8281244581395929, 'Total loss': 0.8281244581395929} | train loss {'Reaction outcome loss': 0.8108008395624065, 'Total loss': 0.8108008395624065}
2022-11-18 01:06:53,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:53,227 INFO:     Epoch: 87
2022-11-18 01:06:54,011 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8159391182390127, 'Total loss': 0.8159391182390127} | train loss {'Reaction outcome loss': 0.8209904461254475, 'Total loss': 0.8209904461254475}
2022-11-18 01:06:54,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:54,011 INFO:     Epoch: 88
2022-11-18 01:06:54,813 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8399957648732446, 'Total loss': 0.8399957648732446} | train loss {'Reaction outcome loss': 0.8194893631737242, 'Total loss': 0.8194893631737242}
2022-11-18 01:06:54,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:54,814 INFO:     Epoch: 89
2022-11-18 01:06:55,642 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8415447676723654, 'Total loss': 0.8415447676723654} | train loss {'Reaction outcome loss': 0.8257747969405371, 'Total loss': 0.8257747969405371}
2022-11-18 01:06:55,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:55,642 INFO:     Epoch: 90
2022-11-18 01:06:56,439 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.818580524487929, 'Total loss': 0.818580524487929} | train loss {'Reaction outcome loss': 0.8288731482558647, 'Total loss': 0.8288731482558647}
2022-11-18 01:06:56,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:56,439 INFO:     Epoch: 91
2022-11-18 01:06:57,257 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.867116817696528, 'Total loss': 0.867116817696528} | train loss {'Reaction outcome loss': 0.8196396521228527, 'Total loss': 0.8196396521228527}
2022-11-18 01:06:57,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:57,257 INFO:     Epoch: 92
2022-11-18 01:06:58,049 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8132993389259685, 'Total loss': 0.8132993389259685} | train loss {'Reaction outcome loss': 0.8170046262774873, 'Total loss': 0.8170046262774873}
2022-11-18 01:06:58,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:58,049 INFO:     Epoch: 93
2022-11-18 01:06:58,868 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8274998217821121, 'Total loss': 0.8274998217821121} | train loss {'Reaction outcome loss': 0.8163838514432251, 'Total loss': 0.8163838514432251}
2022-11-18 01:06:58,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:58,870 INFO:     Epoch: 94
2022-11-18 01:06:59,664 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8366852822628889, 'Total loss': 0.8366852822628889} | train loss {'Reaction outcome loss': 0.8164929124990455, 'Total loss': 0.8164929124990455}
2022-11-18 01:06:59,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:06:59,664 INFO:     Epoch: 95
2022-11-18 01:07:00,503 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8211720416491682, 'Total loss': 0.8211720416491682} | train loss {'Reaction outcome loss': 0.8151553533820488, 'Total loss': 0.8151553533820488}
2022-11-18 01:07:00,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:00,503 INFO:     Epoch: 96
2022-11-18 01:07:01,347 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.833841701800173, 'Total loss': 0.833841701800173} | train loss {'Reaction outcome loss': 0.8200378512081347, 'Total loss': 0.8200378512081347}
2022-11-18 01:07:01,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:01,347 INFO:     Epoch: 97
2022-11-18 01:07:02,151 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8291151896119118, 'Total loss': 0.8291151896119118} | train loss {'Reaction outcome loss': 0.815855127114516, 'Total loss': 0.815855127114516}
2022-11-18 01:07:02,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:02,151 INFO:     Epoch: 98
2022-11-18 01:07:02,935 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8230371001091871, 'Total loss': 0.8230371001091871} | train loss {'Reaction outcome loss': 0.8138209683330435, 'Total loss': 0.8138209683330435}
2022-11-18 01:07:02,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:02,936 INFO:     Epoch: 99
2022-11-18 01:07:03,742 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8321906765076247, 'Total loss': 0.8321906765076247} | train loss {'Reaction outcome loss': 0.8197831011373504, 'Total loss': 0.8197831011373504}
2022-11-18 01:07:03,742 INFO:     Best model found after epoch 70 of 100.
2022-11-18 01:07:03,742 INFO:   Done with stage: TRAINING
2022-11-18 01:07:03,742 INFO:   Starting stage: EVALUATION
2022-11-18 01:07:03,866 INFO:   Done with stage: EVALUATION
2022-11-18 01:07:03,874 INFO:   Leaving out SEQ value Fold_0
2022-11-18 01:07:03,888 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:07:03,888 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:07:04,554 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:07:04,554 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:07:04,626 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:07:04,626 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:07:04,626 INFO:     No hyperparam tuning for this model
2022-11-18 01:07:04,626 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:07:04,626 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:07:04,627 INFO:     None feature selector for col prot
2022-11-18 01:07:04,627 INFO:     None feature selector for col prot
2022-11-18 01:07:04,627 INFO:     None feature selector for col prot
2022-11-18 01:07:04,628 INFO:     None feature selector for col chem
2022-11-18 01:07:04,628 INFO:     None feature selector for col chem
2022-11-18 01:07:04,628 INFO:     None feature selector for col chem
2022-11-18 01:07:04,628 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:07:04,628 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:07:04,629 INFO:     Number of params in model 168571
2022-11-18 01:07:04,633 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:07:04,633 INFO:   Starting stage: TRAINING
2022-11-18 01:07:04,690 INFO:     Val loss before train {'Reaction outcome loss': 1.0782622573050586, 'Total loss': 1.0782622573050586}
2022-11-18 01:07:04,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:04,690 INFO:     Epoch: 0
2022-11-18 01:07:05,508 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.897766001522541, 'Total loss': 0.897766001522541} | train loss {'Reaction outcome loss': 0.861281704051154, 'Total loss': 0.861281704051154}
2022-11-18 01:07:05,508 INFO:     Found new best model at epoch 0
2022-11-18 01:07:05,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:05,509 INFO:     Epoch: 1
2022-11-18 01:07:06,287 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8926949711008505, 'Total loss': 0.8926949711008505} | train loss {'Reaction outcome loss': 0.8313186099334638, 'Total loss': 0.8313186099334638}
2022-11-18 01:07:06,287 INFO:     Found new best model at epoch 1
2022-11-18 01:07:06,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:06,288 INFO:     Epoch: 2
2022-11-18 01:07:07,070 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8812270232222297, 'Total loss': 0.8812270232222297} | train loss {'Reaction outcome loss': 0.8254933734329379, 'Total loss': 0.8254933734329379}
2022-11-18 01:07:07,070 INFO:     Found new best model at epoch 2
2022-11-18 01:07:07,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:07,071 INFO:     Epoch: 3
2022-11-18 01:07:07,869 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8662566176869653, 'Total loss': 0.8662566176869653} | train loss {'Reaction outcome loss': 0.82590841261708, 'Total loss': 0.82590841261708}
2022-11-18 01:07:07,869 INFO:     Found new best model at epoch 3
2022-11-18 01:07:07,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:07,870 INFO:     Epoch: 4
2022-11-18 01:07:08,657 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8918341222134504, 'Total loss': 0.8918341222134504} | train loss {'Reaction outcome loss': 0.8194442126215721, 'Total loss': 0.8194442126215721}
2022-11-18 01:07:08,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:08,657 INFO:     Epoch: 5
2022-11-18 01:07:09,500 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8827778087420897, 'Total loss': 0.8827778087420897} | train loss {'Reaction outcome loss': 0.8174142222015225, 'Total loss': 0.8174142222015225}
2022-11-18 01:07:09,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:09,501 INFO:     Epoch: 6
2022-11-18 01:07:10,275 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9075434065677903, 'Total loss': 0.9075434065677903} | train loss {'Reaction outcome loss': 0.8142778090068272, 'Total loss': 0.8142778090068272}
2022-11-18 01:07:10,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:10,275 INFO:     Epoch: 7
2022-11-18 01:07:11,084 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8833505856719884, 'Total loss': 0.8833505856719884} | train loss {'Reaction outcome loss': 0.8111546906889702, 'Total loss': 0.8111546906889702}
2022-11-18 01:07:11,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:11,085 INFO:     Epoch: 8
2022-11-18 01:07:11,872 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8770476288416169, 'Total loss': 0.8770476288416169} | train loss {'Reaction outcome loss': 0.809647379845989, 'Total loss': 0.809647379845989}
2022-11-18 01:07:11,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:11,872 INFO:     Epoch: 9
2022-11-18 01:07:12,642 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8795359662987969, 'Total loss': 0.8795359662987969} | train loss {'Reaction outcome loss': 0.8062528706326777, 'Total loss': 0.8062528706326777}
2022-11-18 01:07:12,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:12,642 INFO:     Epoch: 10
2022-11-18 01:07:13,449 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8919735266403719, 'Total loss': 0.8919735266403719} | train loss {'Reaction outcome loss': 0.8074327532125979, 'Total loss': 0.8074327532125979}
2022-11-18 01:07:13,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:13,449 INFO:     Epoch: 11
2022-11-18 01:07:14,192 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8526542068205096, 'Total loss': 0.8526542068205096} | train loss {'Reaction outcome loss': 0.8057258261709798, 'Total loss': 0.8057258261709798}
2022-11-18 01:07:14,192 INFO:     Found new best model at epoch 11
2022-11-18 01:07:14,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:14,193 INFO:     Epoch: 12
2022-11-18 01:07:15,031 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8666514788161624, 'Total loss': 0.8666514788161624} | train loss {'Reaction outcome loss': 0.8082895218109598, 'Total loss': 0.8082895218109598}
2022-11-18 01:07:15,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:15,032 INFO:     Epoch: 13
2022-11-18 01:07:15,856 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8695028552954848, 'Total loss': 0.8695028552954848} | train loss {'Reaction outcome loss': 0.8057266288874101, 'Total loss': 0.8057266288874101}
2022-11-18 01:07:15,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:15,857 INFO:     Epoch: 14
2022-11-18 01:07:16,698 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8738831989467144, 'Total loss': 0.8738831989467144} | train loss {'Reaction outcome loss': 0.8051350953627606, 'Total loss': 0.8051350953627606}
2022-11-18 01:07:16,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:16,698 INFO:     Epoch: 15
2022-11-18 01:07:17,534 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8711870129812848, 'Total loss': 0.8711870129812848} | train loss {'Reaction outcome loss': 0.8056316139746685, 'Total loss': 0.8056316139746685}
2022-11-18 01:07:17,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:17,535 INFO:     Epoch: 16
2022-11-18 01:07:18,302 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8550859120759097, 'Total loss': 0.8550859120759097} | train loss {'Reaction outcome loss': 0.7986922521980442, 'Total loss': 0.7986922521980442}
2022-11-18 01:07:18,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:18,302 INFO:     Epoch: 17
2022-11-18 01:07:19,152 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.865027284080332, 'Total loss': 0.865027284080332} | train loss {'Reaction outcome loss': 0.8016267654847126, 'Total loss': 0.8016267654847126}
2022-11-18 01:07:19,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:19,152 INFO:     Epoch: 18
2022-11-18 01:07:19,954 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8534831736575473, 'Total loss': 0.8534831736575473} | train loss {'Reaction outcome loss': 0.7998431826124386, 'Total loss': 0.7998431826124386}
2022-11-18 01:07:19,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:19,954 INFO:     Epoch: 19
2022-11-18 01:07:20,748 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8849732320417057, 'Total loss': 0.8849732320417057} | train loss {'Reaction outcome loss': 0.8032760142063607, 'Total loss': 0.8032760142063607}
2022-11-18 01:07:20,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:20,748 INFO:     Epoch: 20
2022-11-18 01:07:21,585 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8646182038567283, 'Total loss': 0.8646182038567283} | train loss {'Reaction outcome loss': 0.8049526538167681, 'Total loss': 0.8049526538167681}
2022-11-18 01:07:21,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:21,585 INFO:     Epoch: 21
2022-11-18 01:07:22,381 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8762273165312681, 'Total loss': 0.8762273165312681} | train loss {'Reaction outcome loss': 0.79642783768323, 'Total loss': 0.79642783768323}
2022-11-18 01:07:22,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:22,381 INFO:     Epoch: 22
2022-11-18 01:07:23,195 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8640945309942419, 'Total loss': 0.8640945309942419} | train loss {'Reaction outcome loss': 0.8003997774756685, 'Total loss': 0.8003997774756685}
2022-11-18 01:07:23,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:23,195 INFO:     Epoch: 23
2022-11-18 01:07:24,013 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8681688769297167, 'Total loss': 0.8681688769297167} | train loss {'Reaction outcome loss': 0.7993375823205832, 'Total loss': 0.7993375823205832}
2022-11-18 01:07:24,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:24,013 INFO:     Epoch: 24
2022-11-18 01:07:24,788 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8649510124867613, 'Total loss': 0.8649510124867613} | train loss {'Reaction outcome loss': 0.802599610844437, 'Total loss': 0.802599610844437}
2022-11-18 01:07:24,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:24,788 INFO:     Epoch: 25
2022-11-18 01:07:25,594 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.852289651605216, 'Total loss': 0.852289651605216} | train loss {'Reaction outcome loss': 0.7987681654034828, 'Total loss': 0.7987681654034828}
2022-11-18 01:07:25,594 INFO:     Found new best model at epoch 25
2022-11-18 01:07:25,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:25,595 INFO:     Epoch: 26
2022-11-18 01:07:26,449 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8542175272648985, 'Total loss': 0.8542175272648985} | train loss {'Reaction outcome loss': 0.7987591739819975, 'Total loss': 0.7987591739819975}
2022-11-18 01:07:26,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:26,449 INFO:     Epoch: 27
2022-11-18 01:07:27,237 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.9388850561597131, 'Total loss': 0.9388850561597131} | train loss {'Reaction outcome loss': 0.7995476043954187, 'Total loss': 0.7995476043954187}
2022-11-18 01:07:27,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:27,237 INFO:     Epoch: 28
2022-11-18 01:07:28,012 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8427683121778748, 'Total loss': 0.8427683121778748} | train loss {'Reaction outcome loss': 0.7991484346438428, 'Total loss': 0.7991484346438428}
2022-11-18 01:07:28,012 INFO:     Found new best model at epoch 28
2022-11-18 01:07:28,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:28,013 INFO:     Epoch: 29
2022-11-18 01:07:28,827 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8409844088283452, 'Total loss': 0.8409844088283452} | train loss {'Reaction outcome loss': 0.7990245828823167, 'Total loss': 0.7990245828823167}
2022-11-18 01:07:28,827 INFO:     Found new best model at epoch 29
2022-11-18 01:07:28,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:28,827 INFO:     Epoch: 30
2022-11-18 01:07:29,692 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.862211911515756, 'Total loss': 0.862211911515756} | train loss {'Reaction outcome loss': 0.8038771597706542, 'Total loss': 0.8038771597706542}
2022-11-18 01:07:29,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:29,693 INFO:     Epoch: 31
2022-11-18 01:07:30,473 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8833044151013548, 'Total loss': 0.8833044151013548} | train loss {'Reaction outcome loss': 0.7984822877815791, 'Total loss': 0.7984822877815791}
2022-11-18 01:07:30,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:30,473 INFO:     Epoch: 32
2022-11-18 01:07:31,284 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8575548800555143, 'Total loss': 0.8575548800555143} | train loss {'Reaction outcome loss': 0.8003144506289035, 'Total loss': 0.8003144506289035}
2022-11-18 01:07:31,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:31,284 INFO:     Epoch: 33
2022-11-18 01:07:32,087 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8682672293348745, 'Total loss': 0.8682672293348745} | train loss {'Reaction outcome loss': 0.8016454263609283, 'Total loss': 0.8016454263609283}
2022-11-18 01:07:32,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:32,087 INFO:     Epoch: 34
2022-11-18 01:07:32,888 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8764125271276995, 'Total loss': 0.8764125271276995} | train loss {'Reaction outcome loss': 0.8005268084759615, 'Total loss': 0.8005268084759615}
2022-11-18 01:07:32,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:32,888 INFO:     Epoch: 35
2022-11-18 01:07:33,678 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8553139845078642, 'Total loss': 0.8553139845078642} | train loss {'Reaction outcome loss': 0.7991172205428688, 'Total loss': 0.7991172205428688}
2022-11-18 01:07:33,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:33,678 INFO:     Epoch: 36
2022-11-18 01:07:34,510 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8708546595139937, 'Total loss': 0.8708546595139937} | train loss {'Reaction outcome loss': 0.802636565115987, 'Total loss': 0.802636565115987}
2022-11-18 01:07:34,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:34,510 INFO:     Epoch: 37
2022-11-18 01:07:35,353 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8686344020745971, 'Total loss': 0.8686344020745971} | train loss {'Reaction outcome loss': 0.798829796971107, 'Total loss': 0.798829796971107}
2022-11-18 01:07:35,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:35,353 INFO:     Epoch: 38
2022-11-18 01:07:36,129 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8955611911686984, 'Total loss': 0.8955611911686984} | train loss {'Reaction outcome loss': 0.7974676259926388, 'Total loss': 0.7974676259926388}
2022-11-18 01:07:36,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:36,129 INFO:     Epoch: 39
2022-11-18 01:07:36,887 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8706331700086594, 'Total loss': 0.8706331700086594} | train loss {'Reaction outcome loss': 0.7951429263669617, 'Total loss': 0.7951429263669617}
2022-11-18 01:07:36,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:36,887 INFO:     Epoch: 40
2022-11-18 01:07:37,701 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.9020371105183255, 'Total loss': 0.9020371105183255} | train loss {'Reaction outcome loss': 0.7942440927028656, 'Total loss': 0.7942440927028656}
2022-11-18 01:07:37,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:37,702 INFO:     Epoch: 41
2022-11-18 01:07:38,539 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.859921319918199, 'Total loss': 0.859921319918199} | train loss {'Reaction outcome loss': 0.8039589783366845, 'Total loss': 0.8039589783366845}
2022-11-18 01:07:38,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:38,540 INFO:     Epoch: 42
2022-11-18 01:07:39,342 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8673575073480606, 'Total loss': 0.8673575073480606} | train loss {'Reaction outcome loss': 0.7968565895849344, 'Total loss': 0.7968565895849344}
2022-11-18 01:07:39,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:39,343 INFO:     Epoch: 43
2022-11-18 01:07:40,192 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8453458879481662, 'Total loss': 0.8453458879481662} | train loss {'Reaction outcome loss': 0.7985900245150741, 'Total loss': 0.7985900245150741}
2022-11-18 01:07:40,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:40,192 INFO:     Epoch: 44
2022-11-18 01:07:40,997 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8558817546476017, 'Total loss': 0.8558817546476017} | train loss {'Reaction outcome loss': 0.7993751145747243, 'Total loss': 0.7993751145747243}
2022-11-18 01:07:40,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:40,998 INFO:     Epoch: 45
2022-11-18 01:07:41,789 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8638431037014181, 'Total loss': 0.8638431037014181} | train loss {'Reaction outcome loss': 0.7997730139566928, 'Total loss': 0.7997730139566928}
2022-11-18 01:07:41,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:41,791 INFO:     Epoch: 46
2022-11-18 01:07:42,577 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8644711415876042, 'Total loss': 0.8644711415876042} | train loss {'Reaction outcome loss': 0.7977798171189366, 'Total loss': 0.7977798171189366}
2022-11-18 01:07:42,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:42,577 INFO:     Epoch: 47
2022-11-18 01:07:43,377 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.860965219410983, 'Total loss': 0.860965219410983} | train loss {'Reaction outcome loss': 0.8015617798177563, 'Total loss': 0.8015617798177563}
2022-11-18 01:07:43,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:43,377 INFO:     Epoch: 48
2022-11-18 01:07:44,134 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8411033153533936, 'Total loss': 0.8411033153533936} | train loss {'Reaction outcome loss': 0.8021587216124243, 'Total loss': 0.8021587216124243}
2022-11-18 01:07:44,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:44,134 INFO:     Epoch: 49
2022-11-18 01:07:44,912 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8540714586322958, 'Total loss': 0.8540714586322958} | train loss {'Reaction outcome loss': 0.7999835903547248, 'Total loss': 0.7999835903547248}
2022-11-18 01:07:44,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:44,913 INFO:     Epoch: 50
2022-11-18 01:07:45,741 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.9106282598593018, 'Total loss': 0.9106282598593018} | train loss {'Reaction outcome loss': 0.7987818177865476, 'Total loss': 0.7987818177865476}
2022-11-18 01:07:45,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:45,741 INFO:     Epoch: 51
2022-11-18 01:07:46,556 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8530553315173496, 'Total loss': 0.8530553315173496} | train loss {'Reaction outcome loss': 0.7937497011252812, 'Total loss': 0.7937497011252812}
2022-11-18 01:07:46,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:46,556 INFO:     Epoch: 52
2022-11-18 01:07:47,384 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8935087329962037, 'Total loss': 0.8935087329962037} | train loss {'Reaction outcome loss': 0.79870249361408, 'Total loss': 0.79870249361408}
2022-11-18 01:07:47,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:47,385 INFO:     Epoch: 53
2022-11-18 01:07:48,216 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8552822199734774, 'Total loss': 0.8552822199734774} | train loss {'Reaction outcome loss': 0.8001435560839517, 'Total loss': 0.8001435560839517}
2022-11-18 01:07:48,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:48,217 INFO:     Epoch: 54
2022-11-18 01:07:49,000 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8623079772699963, 'Total loss': 0.8623079772699963} | train loss {'Reaction outcome loss': 0.7997288049483786, 'Total loss': 0.7997288049483786}
2022-11-18 01:07:49,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:49,000 INFO:     Epoch: 55
2022-11-18 01:07:49,800 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8523977215994488, 'Total loss': 0.8523977215994488} | train loss {'Reaction outcome loss': 0.7968908368324746, 'Total loss': 0.7968908368324746}
2022-11-18 01:07:49,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:49,800 INFO:     Epoch: 56
2022-11-18 01:07:50,597 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8557086891748689, 'Total loss': 0.8557086891748689} | train loss {'Reaction outcome loss': 0.7952363399826751, 'Total loss': 0.7952363399826751}
2022-11-18 01:07:50,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:50,597 INFO:     Epoch: 57
2022-11-18 01:07:51,360 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8649124476042661, 'Total loss': 0.8649124476042661} | train loss {'Reaction outcome loss': 0.8016002927507673, 'Total loss': 0.8016002927507673}
2022-11-18 01:07:51,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:51,360 INFO:     Epoch: 58
2022-11-18 01:07:52,194 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8551189018921419, 'Total loss': 0.8551189018921419} | train loss {'Reaction outcome loss': 0.7995206672318128, 'Total loss': 0.7995206672318128}
2022-11-18 01:07:52,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:52,195 INFO:     Epoch: 59
2022-11-18 01:07:52,997 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.875388810580427, 'Total loss': 0.875388810580427} | train loss {'Reaction outcome loss': 0.7989201291483276, 'Total loss': 0.7989201291483276}
2022-11-18 01:07:52,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:52,998 INFO:     Epoch: 60
2022-11-18 01:07:53,802 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8414780612696301, 'Total loss': 0.8414780612696301} | train loss {'Reaction outcome loss': 0.7949516865671897, 'Total loss': 0.7949516865671897}
2022-11-18 01:07:53,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:53,802 INFO:     Epoch: 61
2022-11-18 01:07:54,601 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.845156751234423, 'Total loss': 0.845156751234423} | train loss {'Reaction outcome loss': 0.7995143064430782, 'Total loss': 0.7995143064430782}
2022-11-18 01:07:54,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:54,602 INFO:     Epoch: 62
2022-11-18 01:07:55,402 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8819967901164835, 'Total loss': 0.8819967901164835} | train loss {'Reaction outcome loss': 0.795776662534597, 'Total loss': 0.795776662534597}
2022-11-18 01:07:55,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:55,402 INFO:     Epoch: 63
2022-11-18 01:07:56,208 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.854748665609143, 'Total loss': 0.854748665609143} | train loss {'Reaction outcome loss': 0.79910433924928, 'Total loss': 0.79910433924928}
2022-11-18 01:07:56,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:56,209 INFO:     Epoch: 64
2022-11-18 01:07:57,007 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8617423447695646, 'Total loss': 0.8617423447695646} | train loss {'Reaction outcome loss': 0.8009331682506873, 'Total loss': 0.8009331682506873}
2022-11-18 01:07:57,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:57,007 INFO:     Epoch: 65
2022-11-18 01:07:57,828 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8355570882558823, 'Total loss': 0.8355570882558823} | train loss {'Reaction outcome loss': 0.7981155725157991, 'Total loss': 0.7981155725157991}
2022-11-18 01:07:57,829 INFO:     Found new best model at epoch 65
2022-11-18 01:07:57,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:57,830 INFO:     Epoch: 66
2022-11-18 01:07:58,625 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8455974486741152, 'Total loss': 0.8455974486741152} | train loss {'Reaction outcome loss': 0.7922459018473722, 'Total loss': 0.7922459018473722}
2022-11-18 01:07:58,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:58,625 INFO:     Epoch: 67
2022-11-18 01:07:59,413 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.863855168223381, 'Total loss': 0.863855168223381} | train loss {'Reaction outcome loss': 0.7988866577343064, 'Total loss': 0.7988866577343064}
2022-11-18 01:07:59,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:07:59,413 INFO:     Epoch: 68
2022-11-18 01:08:00,218 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8797375505620783, 'Total loss': 0.8797375505620783} | train loss {'Reaction outcome loss': 0.7958432122152679, 'Total loss': 0.7958432122152679}
2022-11-18 01:08:00,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:00,220 INFO:     Epoch: 69
2022-11-18 01:08:01,012 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8538822890682654, 'Total loss': 0.8538822890682654} | train loss {'Reaction outcome loss': 0.80085054088612, 'Total loss': 0.80085054088612}
2022-11-18 01:08:01,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:01,013 INFO:     Epoch: 70
2022-11-18 01:08:01,856 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8567424172704871, 'Total loss': 0.8567424172704871} | train loss {'Reaction outcome loss': 0.7958910443344894, 'Total loss': 0.7958910443344894}
2022-11-18 01:08:01,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:01,857 INFO:     Epoch: 71
2022-11-18 01:08:02,688 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8525470637462356, 'Total loss': 0.8525470637462356} | train loss {'Reaction outcome loss': 0.7955747140913594, 'Total loss': 0.7955747140913594}
2022-11-18 01:08:02,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:02,689 INFO:     Epoch: 72
2022-11-18 01:08:03,507 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8707794181325219, 'Total loss': 0.8707794181325219} | train loss {'Reaction outcome loss': 0.796832244067776, 'Total loss': 0.796832244067776}
2022-11-18 01:08:03,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:03,508 INFO:     Epoch: 73
2022-11-18 01:08:04,286 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8441165746612982, 'Total loss': 0.8441165746612982} | train loss {'Reaction outcome loss': 0.8000755228558365, 'Total loss': 0.8000755228558365}
2022-11-18 01:08:04,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:04,286 INFO:     Epoch: 74
2022-11-18 01:08:05,095 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8632523031397299, 'Total loss': 0.8632523031397299} | train loss {'Reaction outcome loss': 0.7968681634688864, 'Total loss': 0.7968681634688864}
2022-11-18 01:08:05,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:05,096 INFO:     Epoch: 75
2022-11-18 01:08:05,889 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8623873306946321, 'Total loss': 0.8623873306946321} | train loss {'Reaction outcome loss': 0.7949912679438689, 'Total loss': 0.7949912679438689}
2022-11-18 01:08:05,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:05,890 INFO:     Epoch: 76
2022-11-18 01:08:06,672 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.859045454046943, 'Total loss': 0.859045454046943} | train loss {'Reaction outcome loss': 0.7907173201745871, 'Total loss': 0.7907173201745871}
2022-11-18 01:08:06,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:06,672 INFO:     Epoch: 77
2022-11-18 01:08:07,469 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8676766929301348, 'Total loss': 0.8676766929301348} | train loss {'Reaction outcome loss': 0.7985438041541041, 'Total loss': 0.7985438041541041}
2022-11-18 01:08:07,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:07,469 INFO:     Epoch: 78
2022-11-18 01:08:08,293 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8429785553704608, 'Total loss': 0.8429785553704608} | train loss {'Reaction outcome loss': 0.795363700389862, 'Total loss': 0.795363700389862}
2022-11-18 01:08:08,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:08,294 INFO:     Epoch: 79
2022-11-18 01:08:09,100 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8721570508046583, 'Total loss': 0.8721570508046583} | train loss {'Reaction outcome loss': 0.7994860068875916, 'Total loss': 0.7994860068875916}
2022-11-18 01:08:09,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:09,100 INFO:     Epoch: 80
2022-11-18 01:08:09,917 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.866091101007028, 'Total loss': 0.866091101007028} | train loss {'Reaction outcome loss': 0.7960026328661004, 'Total loss': 0.7960026328661004}
2022-11-18 01:08:09,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:09,917 INFO:     Epoch: 81
2022-11-18 01:08:10,730 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.900921496477994, 'Total loss': 0.900921496477994} | train loss {'Reaction outcome loss': 0.7920224506027844, 'Total loss': 0.7920224506027844}
2022-11-18 01:08:10,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:10,731 INFO:     Epoch: 82
2022-11-18 01:08:11,529 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8579901251941919, 'Total loss': 0.8579901251941919} | train loss {'Reaction outcome loss': 0.7964450547889788, 'Total loss': 0.7964450547889788}
2022-11-18 01:08:11,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:11,529 INFO:     Epoch: 83
2022-11-18 01:08:12,346 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8524262634190646, 'Total loss': 0.8524262634190646} | train loss {'Reaction outcome loss': 0.7993453382229319, 'Total loss': 0.7993453382229319}
2022-11-18 01:08:12,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:12,346 INFO:     Epoch: 84
2022-11-18 01:08:13,141 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8875081932002847, 'Total loss': 0.8875081932002847} | train loss {'Reaction outcome loss': 0.7952646133851032, 'Total loss': 0.7952646133851032}
2022-11-18 01:08:13,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:13,142 INFO:     Epoch: 85
2022-11-18 01:08:13,987 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8618097102100198, 'Total loss': 0.8618097102100198} | train loss {'Reaction outcome loss': 0.8012392675390049, 'Total loss': 0.8012392675390049}
2022-11-18 01:08:13,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:13,987 INFO:     Epoch: 86
2022-11-18 01:08:14,824 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8539884144609625, 'Total loss': 0.8539884144609625} | train loss {'Reaction outcome loss': 0.7958837651476568, 'Total loss': 0.7958837651476568}
2022-11-18 01:08:14,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:14,824 INFO:     Epoch: 87
2022-11-18 01:08:15,593 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8785849836739626, 'Total loss': 0.8785849836739626} | train loss {'Reaction outcome loss': 0.7991878547230545, 'Total loss': 0.7991878547230545}
2022-11-18 01:08:15,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:15,594 INFO:     Epoch: 88
2022-11-18 01:08:16,373 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8525391613895242, 'Total loss': 0.8525391613895242} | train loss {'Reaction outcome loss': 0.7975908036134681, 'Total loss': 0.7975908036134681}
2022-11-18 01:08:16,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:16,373 INFO:     Epoch: 89
2022-11-18 01:08:17,156 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8455793126062914, 'Total loss': 0.8455793126062914} | train loss {'Reaction outcome loss': 0.801472508785676, 'Total loss': 0.801472508785676}
2022-11-18 01:08:17,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:17,156 INFO:     Epoch: 90
2022-11-18 01:08:17,941 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8583329482512041, 'Total loss': 0.8583329482512041} | train loss {'Reaction outcome loss': 0.796503539474643, 'Total loss': 0.796503539474643}
2022-11-18 01:08:17,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:17,941 INFO:     Epoch: 91
2022-11-18 01:08:18,729 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8744767633351412, 'Total loss': 0.8744767633351412} | train loss {'Reaction outcome loss': 0.796002140276286, 'Total loss': 0.796002140276286}
2022-11-18 01:08:18,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:18,730 INFO:     Epoch: 92
2022-11-18 01:08:19,578 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8460610454732721, 'Total loss': 0.8460610454732721} | train loss {'Reaction outcome loss': 0.7973991636110812, 'Total loss': 0.7973991636110812}
2022-11-18 01:08:19,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:19,579 INFO:     Epoch: 93
2022-11-18 01:08:20,371 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8610779588872736, 'Total loss': 0.8610779588872736} | train loss {'Reaction outcome loss': 0.7963152875705641, 'Total loss': 0.7963152875705641}
2022-11-18 01:08:20,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:20,371 INFO:     Epoch: 94
2022-11-18 01:08:21,197 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8728042109446092, 'Total loss': 0.8728042109446092} | train loss {'Reaction outcome loss': 0.7920507355612152, 'Total loss': 0.7920507355612152}
2022-11-18 01:08:21,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:21,198 INFO:     Epoch: 95
2022-11-18 01:08:21,991 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8499295460906896, 'Total loss': 0.8499295460906896} | train loss {'Reaction outcome loss': 0.7975570154433348, 'Total loss': 0.7975570154433348}
2022-11-18 01:08:21,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:21,991 INFO:     Epoch: 96
2022-11-18 01:08:22,772 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8681746206500314, 'Total loss': 0.8681746206500314} | train loss {'Reaction outcome loss': 0.7977067822096299, 'Total loss': 0.7977067822096299}
2022-11-18 01:08:22,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:22,772 INFO:     Epoch: 97
2022-11-18 01:08:23,608 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8678606220267036, 'Total loss': 0.8678606220267036} | train loss {'Reaction outcome loss': 0.7965144264454744, 'Total loss': 0.7965144264454744}
2022-11-18 01:08:23,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:23,609 INFO:     Epoch: 98
2022-11-18 01:08:24,405 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8378720852461728, 'Total loss': 0.8378720852461728} | train loss {'Reaction outcome loss': 0.7952089067624539, 'Total loss': 0.7952089067624539}
2022-11-18 01:08:24,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:24,405 INFO:     Epoch: 99
2022-11-18 01:08:25,195 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8593358996916901, 'Total loss': 0.8593358996916901} | train loss {'Reaction outcome loss': 0.7970893653071657, 'Total loss': 0.7970893653071657}
2022-11-18 01:08:25,195 INFO:     Best model found after epoch 66 of 100.
2022-11-18 01:08:25,195 INFO:   Done with stage: TRAINING
2022-11-18 01:08:25,195 INFO:   Starting stage: EVALUATION
2022-11-18 01:08:25,326 INFO:   Done with stage: EVALUATION
2022-11-18 01:08:25,326 INFO:   Leaving out SEQ value Fold_1
2022-11-18 01:08:25,339 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:08:25,340 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:08:26,005 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:08:26,005 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:08:26,076 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:08:26,076 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:08:26,076 INFO:     No hyperparam tuning for this model
2022-11-18 01:08:26,076 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:08:26,076 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:08:26,077 INFO:     None feature selector for col prot
2022-11-18 01:08:26,077 INFO:     None feature selector for col prot
2022-11-18 01:08:26,077 INFO:     None feature selector for col prot
2022-11-18 01:08:26,078 INFO:     None feature selector for col chem
2022-11-18 01:08:26,078 INFO:     None feature selector for col chem
2022-11-18 01:08:26,078 INFO:     None feature selector for col chem
2022-11-18 01:08:26,078 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:08:26,078 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:08:26,079 INFO:     Number of params in model 168571
2022-11-18 01:08:26,083 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:08:26,083 INFO:   Starting stage: TRAINING
2022-11-18 01:08:26,141 INFO:     Val loss before train {'Reaction outcome loss': 0.9854938963597472, 'Total loss': 0.9854938963597472}
2022-11-18 01:08:26,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:26,141 INFO:     Epoch: 0
2022-11-18 01:08:26,934 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8398723033341494, 'Total loss': 0.8398723033341494} | train loss {'Reaction outcome loss': 0.8878837952808458, 'Total loss': 0.8878837952808458}
2022-11-18 01:08:26,934 INFO:     Found new best model at epoch 0
2022-11-18 01:08:26,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:26,935 INFO:     Epoch: 1
2022-11-18 01:08:27,762 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8422222882509232, 'Total loss': 0.8422222882509232} | train loss {'Reaction outcome loss': 0.8551265972001212, 'Total loss': 0.8551265972001212}
2022-11-18 01:08:27,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:27,763 INFO:     Epoch: 2
2022-11-18 01:08:28,559 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.826152579350905, 'Total loss': 0.826152579350905} | train loss {'Reaction outcome loss': 0.841045640196119, 'Total loss': 0.841045640196119}
2022-11-18 01:08:28,560 INFO:     Found new best model at epoch 2
2022-11-18 01:08:28,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:28,561 INFO:     Epoch: 3
2022-11-18 01:08:29,348 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8141168261116202, 'Total loss': 0.8141168261116202} | train loss {'Reaction outcome loss': 0.8414855478977671, 'Total loss': 0.8414855478977671}
2022-11-18 01:08:29,349 INFO:     Found new best model at epoch 3
2022-11-18 01:08:29,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:29,349 INFO:     Epoch: 4
2022-11-18 01:08:30,143 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8039989102293145, 'Total loss': 0.8039989102293145} | train loss {'Reaction outcome loss': 0.8336664022231589, 'Total loss': 0.8336664022231589}
2022-11-18 01:08:30,143 INFO:     Found new best model at epoch 4
2022-11-18 01:08:30,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:30,144 INFO:     Epoch: 5
2022-11-18 01:08:30,926 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8236276737668298, 'Total loss': 0.8236276737668298} | train loss {'Reaction outcome loss': 0.8325100224845263, 'Total loss': 0.8325100224845263}
2022-11-18 01:08:30,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:30,926 INFO:     Epoch: 6
2022-11-18 01:08:31,714 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.818222857334397, 'Total loss': 0.818222857334397} | train loss {'Reaction outcome loss': 0.8330167177988559, 'Total loss': 0.8330167177988559}
2022-11-18 01:08:31,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:31,716 INFO:     Epoch: 7
2022-11-18 01:08:32,573 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8236913816495375, 'Total loss': 0.8236913816495375} | train loss {'Reaction outcome loss': 0.8285377040201304, 'Total loss': 0.8285377040201304}
2022-11-18 01:08:32,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:32,573 INFO:     Epoch: 8
2022-11-18 01:08:33,371 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8289684572003104, 'Total loss': 0.8289684572003104} | train loss {'Reaction outcome loss': 0.8229432046413422, 'Total loss': 0.8229432046413422}
2022-11-18 01:08:33,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:33,371 INFO:     Epoch: 9
2022-11-18 01:08:34,147 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8028226975690235, 'Total loss': 0.8028226975690235} | train loss {'Reaction outcome loss': 0.8365765559430025, 'Total loss': 0.8365765559430025}
2022-11-18 01:08:34,147 INFO:     Found new best model at epoch 9
2022-11-18 01:08:34,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:34,148 INFO:     Epoch: 10
2022-11-18 01:08:34,939 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8131672475825656, 'Total loss': 0.8131672475825656} | train loss {'Reaction outcome loss': 0.8280473616658425, 'Total loss': 0.8280473616658425}
2022-11-18 01:08:34,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:34,939 INFO:     Epoch: 11
2022-11-18 01:08:35,763 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8197654343464158, 'Total loss': 0.8197654343464158} | train loss {'Reaction outcome loss': 0.8268449707907073, 'Total loss': 0.8268449707907073}
2022-11-18 01:08:35,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:35,763 INFO:     Epoch: 12
2022-11-18 01:08:36,556 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8029933002862063, 'Total loss': 0.8029933002862063} | train loss {'Reaction outcome loss': 0.8249397573422412, 'Total loss': 0.8249397573422412}
2022-11-18 01:08:36,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:36,556 INFO:     Epoch: 13
2022-11-18 01:08:37,395 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8155963068658655, 'Total loss': 0.8155963068658655} | train loss {'Reaction outcome loss': 0.8267201306868572, 'Total loss': 0.8267201306868572}
2022-11-18 01:08:37,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:37,395 INFO:     Epoch: 14
2022-11-18 01:08:38,209 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8338080055334351, 'Total loss': 0.8338080055334351} | train loss {'Reaction outcome loss': 0.8263181848185402, 'Total loss': 0.8263181848185402}
2022-11-18 01:08:38,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:38,209 INFO:     Epoch: 15
2022-11-18 01:08:39,025 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8070456277240406, 'Total loss': 0.8070456277240406} | train loss {'Reaction outcome loss': 0.8278273205367886, 'Total loss': 0.8278273205367886}
2022-11-18 01:08:39,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:39,026 INFO:     Epoch: 16
2022-11-18 01:08:39,830 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8107506493953142, 'Total loss': 0.8107506493953142} | train loss {'Reaction outcome loss': 0.8266374154966705, 'Total loss': 0.8266374154966705}
2022-11-18 01:08:39,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:39,830 INFO:     Epoch: 17
2022-11-18 01:08:40,635 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8360903432423418, 'Total loss': 0.8360903432423418} | train loss {'Reaction outcome loss': 0.8249431482383183, 'Total loss': 0.8249431482383183}
2022-11-18 01:08:40,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:40,635 INFO:     Epoch: 18
2022-11-18 01:08:41,453 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8202329305085269, 'Total loss': 0.8202329305085269} | train loss {'Reaction outcome loss': 0.8303407774896038, 'Total loss': 0.8303407774896038}
2022-11-18 01:08:41,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:41,453 INFO:     Epoch: 19
2022-11-18 01:08:42,271 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8099874203855341, 'Total loss': 0.8099874203855341} | train loss {'Reaction outcome loss': 0.8281950589345426, 'Total loss': 0.8281950589345426}
2022-11-18 01:08:42,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:42,271 INFO:     Epoch: 20
2022-11-18 01:08:43,065 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7982506117021496, 'Total loss': 0.7982506117021496} | train loss {'Reaction outcome loss': 0.8262097582525136, 'Total loss': 0.8262097582525136}
2022-11-18 01:08:43,065 INFO:     Found new best model at epoch 20
2022-11-18 01:08:43,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:43,066 INFO:     Epoch: 21
2022-11-18 01:08:43,877 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8092031973329458, 'Total loss': 0.8092031973329458} | train loss {'Reaction outcome loss': 0.8275789759597, 'Total loss': 0.8275789759597}
2022-11-18 01:08:43,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:43,877 INFO:     Epoch: 22
2022-11-18 01:08:44,691 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8053526549854062, 'Total loss': 0.8053526549854062} | train loss {'Reaction outcome loss': 0.8266131787883992, 'Total loss': 0.8266131787883992}
2022-11-18 01:08:44,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:44,692 INFO:     Epoch: 23
2022-11-18 01:08:45,498 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8195047270167958, 'Total loss': 0.8195047270167958} | train loss {'Reaction outcome loss': 0.8255623759055625, 'Total loss': 0.8255623759055625}
2022-11-18 01:08:45,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:45,498 INFO:     Epoch: 24
2022-11-18 01:08:46,322 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8300815712321888, 'Total loss': 0.8300815712321888} | train loss {'Reaction outcome loss': 0.8251742255930998, 'Total loss': 0.8251742255930998}
2022-11-18 01:08:46,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:46,323 INFO:     Epoch: 25
2022-11-18 01:08:47,128 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8322066420858557, 'Total loss': 0.8322066420858557} | train loss {'Reaction outcome loss': 0.8239118848528181, 'Total loss': 0.8239118848528181}
2022-11-18 01:08:47,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:47,129 INFO:     Epoch: 26
2022-11-18 01:08:47,924 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8374910564585165, 'Total loss': 0.8374910564585165} | train loss {'Reaction outcome loss': 0.8290446045447369, 'Total loss': 0.8290446045447369}
2022-11-18 01:08:47,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:47,924 INFO:     Epoch: 27
2022-11-18 01:08:48,717 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8257309713146903, 'Total loss': 0.8257309713146903} | train loss {'Reaction outcome loss': 0.8258026355383348, 'Total loss': 0.8258026355383348}
2022-11-18 01:08:48,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:48,717 INFO:     Epoch: 28
2022-11-18 01:08:49,540 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8100164573300969, 'Total loss': 0.8100164573300969} | train loss {'Reaction outcome loss': 0.8209354143969867, 'Total loss': 0.8209354143969867}
2022-11-18 01:08:49,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:49,541 INFO:     Epoch: 29
2022-11-18 01:08:50,333 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8174728493798863, 'Total loss': 0.8174728493798863} | train loss {'Reaction outcome loss': 0.823813870488381, 'Total loss': 0.823813870488381}
2022-11-18 01:08:50,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:50,334 INFO:     Epoch: 30
2022-11-18 01:08:51,126 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8074281784621152, 'Total loss': 0.8074281784621152} | train loss {'Reaction outcome loss': 0.8267580843701654, 'Total loss': 0.8267580843701654}
2022-11-18 01:08:51,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:51,127 INFO:     Epoch: 31
2022-11-18 01:08:51,952 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.799099943854592, 'Total loss': 0.799099943854592} | train loss {'Reaction outcome loss': 0.822967567979073, 'Total loss': 0.822967567979073}
2022-11-18 01:08:51,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:51,952 INFO:     Epoch: 32
2022-11-18 01:08:52,752 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8026671572165056, 'Total loss': 0.8026671572165056} | train loss {'Reaction outcome loss': 0.8202799964924248, 'Total loss': 0.8202799964924248}
2022-11-18 01:08:52,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:52,752 INFO:     Epoch: 33
2022-11-18 01:08:53,567 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7986908602443609, 'Total loss': 0.7986908602443609} | train loss {'Reaction outcome loss': 0.8216455953461783, 'Total loss': 0.8216455953461783}
2022-11-18 01:08:53,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:53,567 INFO:     Epoch: 34
2022-11-18 01:08:54,382 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8163642192428763, 'Total loss': 0.8163642192428763} | train loss {'Reaction outcome loss': 0.8281004844879617, 'Total loss': 0.8281004844879617}
2022-11-18 01:08:54,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:54,382 INFO:     Epoch: 35
2022-11-18 01:08:55,195 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8005554648962888, 'Total loss': 0.8005554648962888} | train loss {'Reaction outcome loss': 0.8269920009739545, 'Total loss': 0.8269920009739545}
2022-11-18 01:08:55,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:55,195 INFO:     Epoch: 36
2022-11-18 01:08:56,024 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8132091679356315, 'Total loss': 0.8132091679356315} | train loss {'Reaction outcome loss': 0.8212750385002214, 'Total loss': 0.8212750385002214}
2022-11-18 01:08:56,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:56,024 INFO:     Epoch: 37
2022-11-18 01:08:56,828 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8369150297208265, 'Total loss': 0.8369150297208265} | train loss {'Reaction outcome loss': 0.8218069812472986, 'Total loss': 0.8218069812472986}
2022-11-18 01:08:56,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:56,829 INFO:     Epoch: 38
2022-11-18 01:08:57,661 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8193793201988394, 'Total loss': 0.8193793201988394} | train loss {'Reaction outcome loss': 0.8229274328874082, 'Total loss': 0.8229274328874082}
2022-11-18 01:08:57,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:57,662 INFO:     Epoch: 39
2022-11-18 01:08:58,472 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8230697221376679, 'Total loss': 0.8230697221376679} | train loss {'Reaction outcome loss': 0.8231485697687889, 'Total loss': 0.8231485697687889}
2022-11-18 01:08:58,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:58,473 INFO:     Epoch: 40
2022-11-18 01:08:59,298 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8082526719028299, 'Total loss': 0.8082526719028299} | train loss {'Reaction outcome loss': 0.8237443364396387, 'Total loss': 0.8237443364396387}
2022-11-18 01:08:59,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:08:59,298 INFO:     Epoch: 41
2022-11-18 01:09:00,130 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7943456432020123, 'Total loss': 0.7943456432020123} | train loss {'Reaction outcome loss': 0.826621707726498, 'Total loss': 0.826621707726498}
2022-11-18 01:09:00,131 INFO:     Found new best model at epoch 41
2022-11-18 01:09:00,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:00,131 INFO:     Epoch: 42
2022-11-18 01:09:00,948 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8175056082281199, 'Total loss': 0.8175056082281199} | train loss {'Reaction outcome loss': 0.8237592649703123, 'Total loss': 0.8237592649703123}
2022-11-18 01:09:00,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:00,949 INFO:     Epoch: 43
2022-11-18 01:09:01,791 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8117890750819986, 'Total loss': 0.8117890750819986} | train loss {'Reaction outcome loss': 0.8192565162571109, 'Total loss': 0.8192565162571109}
2022-11-18 01:09:01,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:01,791 INFO:     Epoch: 44
2022-11-18 01:09:02,598 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8025211156769232, 'Total loss': 0.8025211156769232} | train loss {'Reaction outcome loss': 0.8218876226824157, 'Total loss': 0.8218876226824157}
2022-11-18 01:09:02,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:02,598 INFO:     Epoch: 45
2022-11-18 01:09:03,385 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8066380240700461, 'Total loss': 0.8066380240700461} | train loss {'Reaction outcome loss': 0.8229439676416164, 'Total loss': 0.8229439676416164}
2022-11-18 01:09:03,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:03,386 INFO:     Epoch: 46
2022-11-18 01:09:04,189 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.799313866279342, 'Total loss': 0.799313866279342} | train loss {'Reaction outcome loss': 0.8227666348827128, 'Total loss': 0.8227666348827128}
2022-11-18 01:09:04,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:04,189 INFO:     Epoch: 47
2022-11-18 01:09:04,953 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.804811416701837, 'Total loss': 0.804811416701837} | train loss {'Reaction outcome loss': 0.8200711388977207, 'Total loss': 0.8200711388977207}
2022-11-18 01:09:04,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:04,953 INFO:     Epoch: 48
2022-11-18 01:09:05,757 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8155041635036469, 'Total loss': 0.8155041635036469} | train loss {'Reaction outcome loss': 0.822646286414594, 'Total loss': 0.822646286414594}
2022-11-18 01:09:05,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:05,757 INFO:     Epoch: 49
2022-11-18 01:09:06,556 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8165034042163328, 'Total loss': 0.8165034042163328} | train loss {'Reaction outcome loss': 0.8221826515635665, 'Total loss': 0.8221826515635665}
2022-11-18 01:09:06,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:06,556 INFO:     Epoch: 50
2022-11-18 01:09:07,370 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8133566684343598, 'Total loss': 0.8133566684343598} | train loss {'Reaction outcome loss': 0.8247521893102295, 'Total loss': 0.8247521893102295}
2022-11-18 01:09:07,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:07,370 INFO:     Epoch: 51
2022-11-18 01:09:08,237 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8034873645414006, 'Total loss': 0.8034873645414006} | train loss {'Reaction outcome loss': 0.8221690405388268, 'Total loss': 0.8221690405388268}
2022-11-18 01:09:08,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:08,237 INFO:     Epoch: 52
2022-11-18 01:09:09,030 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8061486645178362, 'Total loss': 0.8061486645178362} | train loss {'Reaction outcome loss': 0.8203465399693469, 'Total loss': 0.8203465399693469}
2022-11-18 01:09:09,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:09,030 INFO:     Epoch: 53
2022-11-18 01:09:09,820 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7996149652383544, 'Total loss': 0.7996149652383544} | train loss {'Reaction outcome loss': 0.8239187707706374, 'Total loss': 0.8239187707706374}
2022-11-18 01:09:09,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:09,820 INFO:     Epoch: 54
2022-11-18 01:09:10,648 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8212756277485327, 'Total loss': 0.8212756277485327} | train loss {'Reaction outcome loss': 0.8247221042915266, 'Total loss': 0.8247221042915266}
2022-11-18 01:09:10,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:10,648 INFO:     Epoch: 55
2022-11-18 01:09:11,443 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7976919995112852, 'Total loss': 0.7976919995112852} | train loss {'Reaction outcome loss': 0.8225902374909848, 'Total loss': 0.8225902374909848}
2022-11-18 01:09:11,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:11,443 INFO:     Epoch: 56
2022-11-18 01:09:12,238 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8085813928734172, 'Total loss': 0.8085813928734172} | train loss {'Reaction outcome loss': 0.8224125927808333, 'Total loss': 0.8224125927808333}
2022-11-18 01:09:12,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:12,238 INFO:     Epoch: 57
2022-11-18 01:09:13,031 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8121819245544347, 'Total loss': 0.8121819245544347} | train loss {'Reaction outcome loss': 0.8294056583424003, 'Total loss': 0.8294056583424003}
2022-11-18 01:09:13,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:13,031 INFO:     Epoch: 58
2022-11-18 01:09:13,872 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8310814601453868, 'Total loss': 0.8310814601453868} | train loss {'Reaction outcome loss': 0.8233423458070172, 'Total loss': 0.8233423458070172}
2022-11-18 01:09:13,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:13,872 INFO:     Epoch: 59
2022-11-18 01:09:14,683 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8035333745858886, 'Total loss': 0.8035333745858886} | train loss {'Reaction outcome loss': 0.8205751455560022, 'Total loss': 0.8205751455560022}
2022-11-18 01:09:14,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:14,683 INFO:     Epoch: 60
2022-11-18 01:09:15,492 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8242802884091031, 'Total loss': 0.8242802884091031} | train loss {'Reaction outcome loss': 0.8218808483104316, 'Total loss': 0.8218808483104316}
2022-11-18 01:09:15,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:15,492 INFO:     Epoch: 61
2022-11-18 01:09:16,297 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7893445747481151, 'Total loss': 0.7893445747481151} | train loss {'Reaction outcome loss': 0.8171185499551344, 'Total loss': 0.8171185499551344}
2022-11-18 01:09:16,299 INFO:     Found new best model at epoch 61
2022-11-18 01:09:16,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:16,300 INFO:     Epoch: 62
2022-11-18 01:09:17,054 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8178626000881195, 'Total loss': 0.8178626000881195} | train loss {'Reaction outcome loss': 0.8242290951767747, 'Total loss': 0.8242290951767747}
2022-11-18 01:09:17,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:17,054 INFO:     Epoch: 63
2022-11-18 01:09:17,856 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8139435493133285, 'Total loss': 0.8139435493133285} | train loss {'Reaction outcome loss': 0.8261516860553196, 'Total loss': 0.8261516860553196}
2022-11-18 01:09:17,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:17,857 INFO:     Epoch: 64
2022-11-18 01:09:18,675 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7890782803297043, 'Total loss': 0.7890782803297043} | train loss {'Reaction outcome loss': 0.8220380926618771, 'Total loss': 0.8220380926618771}
2022-11-18 01:09:18,676 INFO:     Found new best model at epoch 64
2022-11-18 01:09:18,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:18,677 INFO:     Epoch: 65
2022-11-18 01:09:19,459 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8206982680342414, 'Total loss': 0.8206982680342414} | train loss {'Reaction outcome loss': 0.8251270871989581, 'Total loss': 0.8251270871989581}
2022-11-18 01:09:19,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:19,460 INFO:     Epoch: 66
2022-11-18 01:09:20,304 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8099269270896912, 'Total loss': 0.8099269270896912} | train loss {'Reaction outcome loss': 0.8239609609453046, 'Total loss': 0.8239609609453046}
2022-11-18 01:09:20,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:20,305 INFO:     Epoch: 67
2022-11-18 01:09:21,100 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7935797098008069, 'Total loss': 0.7935797098008069} | train loss {'Reaction outcome loss': 0.8207776393209185, 'Total loss': 0.8207776393209185}
2022-11-18 01:09:21,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:21,100 INFO:     Epoch: 68
2022-11-18 01:09:21,921 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8290975832126357, 'Total loss': 0.8290975832126357} | train loss {'Reaction outcome loss': 0.8217053211465174, 'Total loss': 0.8217053211465174}
2022-11-18 01:09:21,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:21,921 INFO:     Epoch: 69
2022-11-18 01:09:22,737 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.810891873457215, 'Total loss': 0.810891873457215} | train loss {'Reaction outcome loss': 0.8212573104975175, 'Total loss': 0.8212573104975175}
2022-11-18 01:09:22,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:22,738 INFO:     Epoch: 70
2022-11-18 01:09:23,557 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8157684843648564, 'Total loss': 0.8157684843648564} | train loss {'Reaction outcome loss': 0.8240048510687692, 'Total loss': 0.8240048510687692}
2022-11-18 01:09:23,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:23,557 INFO:     Epoch: 71
2022-11-18 01:09:24,376 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8320490209893747, 'Total loss': 0.8320490209893747} | train loss {'Reaction outcome loss': 0.8224020097936903, 'Total loss': 0.8224020097936903}
2022-11-18 01:09:24,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:24,376 INFO:     Epoch: 72
2022-11-18 01:09:25,208 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.804796732284806, 'Total loss': 0.804796732284806} | train loss {'Reaction outcome loss': 0.8224015665297606, 'Total loss': 0.8224015665297606}
2022-11-18 01:09:25,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:25,208 INFO:     Epoch: 73
2022-11-18 01:09:26,086 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8254808356816118, 'Total loss': 0.8254808356816118} | train loss {'Reaction outcome loss': 0.819945336726247, 'Total loss': 0.819945336726247}
2022-11-18 01:09:26,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:26,086 INFO:     Epoch: 74
2022-11-18 01:09:26,899 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8069364245642315, 'Total loss': 0.8069364245642315} | train loss {'Reaction outcome loss': 0.8178279093333654, 'Total loss': 0.8178279093333654}
2022-11-18 01:09:26,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:26,900 INFO:     Epoch: 75
2022-11-18 01:09:27,672 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8285518979484384, 'Total loss': 0.8285518979484384} | train loss {'Reaction outcome loss': 0.8254946490939783, 'Total loss': 0.8254946490939783}
2022-11-18 01:09:27,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:27,672 INFO:     Epoch: 76
2022-11-18 01:09:28,519 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8295316445556554, 'Total loss': 0.8295316445556554} | train loss {'Reaction outcome loss': 0.8248887073020545, 'Total loss': 0.8248887073020545}
2022-11-18 01:09:28,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:28,520 INFO:     Epoch: 77
2022-11-18 01:09:29,385 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8481562354347922, 'Total loss': 0.8481562354347922} | train loss {'Reaction outcome loss': 0.8207900837976105, 'Total loss': 0.8207900837976105}
2022-11-18 01:09:29,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:29,385 INFO:     Epoch: 78
2022-11-18 01:09:30,210 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7942429645494982, 'Total loss': 0.7942429645494982} | train loss {'Reaction outcome loss': 0.8206731776801908, 'Total loss': 0.8206731776801908}
2022-11-18 01:09:30,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:30,211 INFO:     Epoch: 79
2022-11-18 01:09:31,031 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8155969218774275, 'Total loss': 0.8155969218774275} | train loss {'Reaction outcome loss': 0.8210201666063192, 'Total loss': 0.8210201666063192}
2022-11-18 01:09:31,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:31,031 INFO:     Epoch: 80
2022-11-18 01:09:31,811 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8235120177268982, 'Total loss': 0.8235120177268982} | train loss {'Reaction outcome loss': 0.8201387854254976, 'Total loss': 0.8201387854254976}
2022-11-18 01:09:31,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:31,812 INFO:     Epoch: 81
2022-11-18 01:09:32,584 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8022634847597643, 'Total loss': 0.8022634847597643} | train loss {'Reaction outcome loss': 0.825440624538733, 'Total loss': 0.825440624538733}
2022-11-18 01:09:32,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:32,585 INFO:     Epoch: 82
2022-11-18 01:09:33,418 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.797020436687903, 'Total loss': 0.797020436687903} | train loss {'Reaction outcome loss': 0.8201904703159721, 'Total loss': 0.8201904703159721}
2022-11-18 01:09:33,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:33,419 INFO:     Epoch: 83
2022-11-18 01:09:34,258 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8228410976854238, 'Total loss': 0.8228410976854238} | train loss {'Reaction outcome loss': 0.8205528540270669, 'Total loss': 0.8205528540270669}
2022-11-18 01:09:34,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:34,258 INFO:     Epoch: 84
2022-11-18 01:09:35,038 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7933715212751519, 'Total loss': 0.7933715212751519} | train loss {'Reaction outcome loss': 0.8211038067632792, 'Total loss': 0.8211038067632792}
2022-11-18 01:09:35,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:35,039 INFO:     Epoch: 85
2022-11-18 01:09:35,873 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8253920586271719, 'Total loss': 0.8253920586271719} | train loss {'Reaction outcome loss': 0.8252235715486566, 'Total loss': 0.8252235715486566}
2022-11-18 01:09:35,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:35,873 INFO:     Epoch: 86
2022-11-18 01:09:36,684 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8121698871254921, 'Total loss': 0.8121698871254921} | train loss {'Reaction outcome loss': 0.8197573029265112, 'Total loss': 0.8197573029265112}
2022-11-18 01:09:36,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:36,684 INFO:     Epoch: 87
2022-11-18 01:09:37,503 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8092687685381282, 'Total loss': 0.8092687685381282} | train loss {'Reaction outcome loss': 0.8257944226264954, 'Total loss': 0.8257944226264954}
2022-11-18 01:09:37,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:37,503 INFO:     Epoch: 88
2022-11-18 01:09:38,285 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8022655546665192, 'Total loss': 0.8022655546665192} | train loss {'Reaction outcome loss': 0.827030669061505, 'Total loss': 0.827030669061505}
2022-11-18 01:09:38,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:38,286 INFO:     Epoch: 89
2022-11-18 01:09:39,108 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.799053007228808, 'Total loss': 0.799053007228808} | train loss {'Reaction outcome loss': 0.8218816251170878, 'Total loss': 0.8218816251170878}
2022-11-18 01:09:39,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:39,108 INFO:     Epoch: 90
2022-11-18 01:09:39,919 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8254810713908889, 'Total loss': 0.8254810713908889} | train loss {'Reaction outcome loss': 0.8225633963030212, 'Total loss': 0.8225633963030212}
2022-11-18 01:09:39,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:39,919 INFO:     Epoch: 91
2022-11-18 01:09:40,714 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8010597398335283, 'Total loss': 0.8010597398335283} | train loss {'Reaction outcome loss': 0.8245192630558598, 'Total loss': 0.8245192630558598}
2022-11-18 01:09:40,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:40,715 INFO:     Epoch: 92
2022-11-18 01:09:41,518 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8209316899830644, 'Total loss': 0.8209316899830644} | train loss {'Reaction outcome loss': 0.82307832107252, 'Total loss': 0.82307832107252}
2022-11-18 01:09:41,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:41,518 INFO:     Epoch: 93
2022-11-18 01:09:42,316 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.853753193535588, 'Total loss': 0.853753193535588} | train loss {'Reaction outcome loss': 0.8233459979903941, 'Total loss': 0.8233459979903941}
2022-11-18 01:09:42,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:42,317 INFO:     Epoch: 94
2022-11-18 01:09:43,189 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8063823438503526, 'Total loss': 0.8063823438503526} | train loss {'Reaction outcome loss': 0.8235929992734169, 'Total loss': 0.8235929992734169}
2022-11-18 01:09:43,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:43,189 INFO:     Epoch: 95
2022-11-18 01:09:43,990 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8275598612698641, 'Total loss': 0.8275598612698641} | train loss {'Reaction outcome loss': 0.8278977131356998, 'Total loss': 0.8278977131356998}
2022-11-18 01:09:43,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:43,991 INFO:     Epoch: 96
2022-11-18 01:09:44,806 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.814914654601704, 'Total loss': 0.814914654601704} | train loss {'Reaction outcome loss': 0.8238191717741441, 'Total loss': 0.8238191717741441}
2022-11-18 01:09:44,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:44,806 INFO:     Epoch: 97
2022-11-18 01:09:45,647 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8112578344616023, 'Total loss': 0.8112578344616023} | train loss {'Reaction outcome loss': 0.8221557345925545, 'Total loss': 0.8221557345925545}
2022-11-18 01:09:45,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:45,647 INFO:     Epoch: 98
2022-11-18 01:09:46,470 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8079695342616602, 'Total loss': 0.8079695342616602} | train loss {'Reaction outcome loss': 0.8253729083100144, 'Total loss': 0.8253729083100144}
2022-11-18 01:09:46,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:46,470 INFO:     Epoch: 99
2022-11-18 01:09:47,296 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.797709886323322, 'Total loss': 0.797709886323322} | train loss {'Reaction outcome loss': 0.8237966368393023, 'Total loss': 0.8237966368393023}
2022-11-18 01:09:47,296 INFO:     Best model found after epoch 65 of 100.
2022-11-18 01:09:47,296 INFO:   Done with stage: TRAINING
2022-11-18 01:09:47,296 INFO:   Starting stage: EVALUATION
2022-11-18 01:09:47,425 INFO:   Done with stage: EVALUATION
2022-11-18 01:09:47,426 INFO:   Leaving out SEQ value Fold_2
2022-11-18 01:09:47,439 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:09:47,439 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:09:48,128 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:09:48,130 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:09:48,200 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:09:48,200 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:09:48,200 INFO:     No hyperparam tuning for this model
2022-11-18 01:09:48,200 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:09:48,200 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:09:48,201 INFO:     None feature selector for col prot
2022-11-18 01:09:48,201 INFO:     None feature selector for col prot
2022-11-18 01:09:48,201 INFO:     None feature selector for col prot
2022-11-18 01:09:48,202 INFO:     None feature selector for col chem
2022-11-18 01:09:48,202 INFO:     None feature selector for col chem
2022-11-18 01:09:48,202 INFO:     None feature selector for col chem
2022-11-18 01:09:48,202 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:09:48,202 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:09:48,204 INFO:     Number of params in model 168571
2022-11-18 01:09:48,207 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:09:48,207 INFO:   Starting stage: TRAINING
2022-11-18 01:09:48,267 INFO:     Val loss before train {'Reaction outcome loss': 0.9769482788714495, 'Total loss': 0.9769482788714495}
2022-11-18 01:09:48,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:48,267 INFO:     Epoch: 0
2022-11-18 01:09:49,041 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8423150791363283, 'Total loss': 0.8423150791363283} | train loss {'Reaction outcome loss': 0.8902805084400331, 'Total loss': 0.8902805084400331}
2022-11-18 01:09:49,042 INFO:     Found new best model at epoch 0
2022-11-18 01:09:49,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:49,042 INFO:     Epoch: 1
2022-11-18 01:09:49,849 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8311369757760655, 'Total loss': 0.8311369757760655} | train loss {'Reaction outcome loss': 0.8591556533386833, 'Total loss': 0.8591556533386833}
2022-11-18 01:09:49,849 INFO:     Found new best model at epoch 1
2022-11-18 01:09:49,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:49,850 INFO:     Epoch: 2
2022-11-18 01:09:50,636 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8395884754982862, 'Total loss': 0.8395884754982862} | train loss {'Reaction outcome loss': 0.8552070720958324, 'Total loss': 0.8552070720958324}
2022-11-18 01:09:50,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:50,636 INFO:     Epoch: 3
2022-11-18 01:09:51,445 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8443507159298117, 'Total loss': 0.8443507159298117} | train loss {'Reaction outcome loss': 0.8590234927078972, 'Total loss': 0.8590234927078972}
2022-11-18 01:09:51,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:51,445 INFO:     Epoch: 4
2022-11-18 01:09:52,226 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8379651192914356, 'Total loss': 0.8379651192914356} | train loss {'Reaction outcome loss': 0.8527589983303054, 'Total loss': 0.8527589983303054}
2022-11-18 01:09:52,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:52,226 INFO:     Epoch: 5
2022-11-18 01:09:53,017 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8688570030710914, 'Total loss': 0.8688570030710914} | train loss {'Reaction outcome loss': 0.8462646762851761, 'Total loss': 0.8462646762851761}
2022-11-18 01:09:53,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:53,018 INFO:     Epoch: 6
2022-11-18 01:09:53,822 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8430352759632197, 'Total loss': 0.8430352759632197} | train loss {'Reaction outcome loss': 0.8471046365224398, 'Total loss': 0.8471046365224398}
2022-11-18 01:09:53,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:53,822 INFO:     Epoch: 7
2022-11-18 01:09:54,597 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8317226063121449, 'Total loss': 0.8317226063121449} | train loss {'Reaction outcome loss': 0.847943078409805, 'Total loss': 0.847943078409805}
2022-11-18 01:09:54,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:54,599 INFO:     Epoch: 8
2022-11-18 01:09:55,406 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8515354381366209, 'Total loss': 0.8515354381366209} | train loss {'Reaction outcome loss': 0.8352629753500826, 'Total loss': 0.8352629753500826}
2022-11-18 01:09:55,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:55,407 INFO:     Epoch: 9
2022-11-18 01:09:56,227 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8516051091931083, 'Total loss': 0.8516051091931083} | train loss {'Reaction outcome loss': 0.8432878074858353, 'Total loss': 0.8432878074858353}
2022-11-18 01:09:56,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:56,228 INFO:     Epoch: 10
2022-11-18 01:09:57,072 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8357577208768238, 'Total loss': 0.8357577208768238} | train loss {'Reaction outcome loss': 0.8352595941740492, 'Total loss': 0.8352595941740492}
2022-11-18 01:09:57,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:57,073 INFO:     Epoch: 11
2022-11-18 01:09:57,872 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.836975020441142, 'Total loss': 0.836975020441142} | train loss {'Reaction outcome loss': 0.827522668625541, 'Total loss': 0.827522668625541}
2022-11-18 01:09:57,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:57,872 INFO:     Epoch: 12
2022-11-18 01:09:58,679 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8198170418089087, 'Total loss': 0.8198170418089087} | train loss {'Reaction outcome loss': 0.8371186483244182, 'Total loss': 0.8371186483244182}
2022-11-18 01:09:58,679 INFO:     Found new best model at epoch 12
2022-11-18 01:09:58,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:58,680 INFO:     Epoch: 13
2022-11-18 01:09:59,475 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8553352891044184, 'Total loss': 0.8553352891044184} | train loss {'Reaction outcome loss': 0.8365965881328351, 'Total loss': 0.8365965881328351}
2022-11-18 01:09:59,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:09:59,475 INFO:     Epoch: 14
2022-11-18 01:10:00,321 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8530786890875209, 'Total loss': 0.8530786890875209} | train loss {'Reaction outcome loss': 0.8280167460200275, 'Total loss': 0.8280167460200275}
2022-11-18 01:10:00,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:00,322 INFO:     Epoch: 15
2022-11-18 01:10:01,102 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8508702110160481, 'Total loss': 0.8508702110160481} | train loss {'Reaction outcome loss': 0.8291323222370766, 'Total loss': 0.8291323222370766}
2022-11-18 01:10:01,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:01,102 INFO:     Epoch: 16
2022-11-18 01:10:01,937 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8440589261325923, 'Total loss': 0.8440589261325923} | train loss {'Reaction outcome loss': 0.8282041010345041, 'Total loss': 0.8282041010345041}
2022-11-18 01:10:01,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:01,937 INFO:     Epoch: 17
2022-11-18 01:10:02,784 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8370980600064452, 'Total loss': 0.8370980600064452} | train loss {'Reaction outcome loss': 0.8227350085611768, 'Total loss': 0.8227350085611768}
2022-11-18 01:10:02,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:02,784 INFO:     Epoch: 18
2022-11-18 01:10:03,601 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8399814882061698, 'Total loss': 0.8399814882061698} | train loss {'Reaction outcome loss': 0.8241681243002656, 'Total loss': 0.8241681243002656}
2022-11-18 01:10:03,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:03,601 INFO:     Epoch: 19
2022-11-18 01:10:04,443 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8618818494406614, 'Total loss': 0.8618818494406614} | train loss {'Reaction outcome loss': 0.8213204778881691, 'Total loss': 0.8213204778881691}
2022-11-18 01:10:04,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:04,443 INFO:     Epoch: 20
2022-11-18 01:10:05,277 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8310225971720435, 'Total loss': 0.8310225971720435} | train loss {'Reaction outcome loss': 0.8221502685504645, 'Total loss': 0.8221502685504645}
2022-11-18 01:10:05,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:05,277 INFO:     Epoch: 21
2022-11-18 01:10:06,063 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.83159469880841, 'Total loss': 0.83159469880841} | train loss {'Reaction outcome loss': 0.8206698049900503, 'Total loss': 0.8206698049900503}
2022-11-18 01:10:06,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:06,063 INFO:     Epoch: 22
2022-11-18 01:10:06,865 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8333442177284848, 'Total loss': 0.8333442177284848} | train loss {'Reaction outcome loss': 0.8297897577285767, 'Total loss': 0.8297897577285767}
2022-11-18 01:10:06,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:06,866 INFO:     Epoch: 23
2022-11-18 01:10:07,682 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8335337124087594, 'Total loss': 0.8335337124087594} | train loss {'Reaction outcome loss': 0.8249260155778182, 'Total loss': 0.8249260155778182}
2022-11-18 01:10:07,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:07,683 INFO:     Epoch: 24
2022-11-18 01:10:08,467 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.832086216319691, 'Total loss': 0.832086216319691} | train loss {'Reaction outcome loss': 0.8174983987260444, 'Total loss': 0.8174983987260444}
2022-11-18 01:10:08,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:08,467 INFO:     Epoch: 25
2022-11-18 01:10:09,247 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.868776108730923, 'Total loss': 0.868776108730923} | train loss {'Reaction outcome loss': 0.8221921344035068, 'Total loss': 0.8221921344035068}
2022-11-18 01:10:09,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:09,248 INFO:     Epoch: 26
2022-11-18 01:10:10,068 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.839818848804994, 'Total loss': 0.839818848804994} | train loss {'Reaction outcome loss': 0.8220657960847322, 'Total loss': 0.8220657960847322}
2022-11-18 01:10:10,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:10,068 INFO:     Epoch: 27
2022-11-18 01:10:10,917 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8504937961697578, 'Total loss': 0.8504937961697578} | train loss {'Reaction outcome loss': 0.8204250287430489, 'Total loss': 0.8204250287430489}
2022-11-18 01:10:10,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:10,917 INFO:     Epoch: 28
2022-11-18 01:10:11,714 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8485968837683852, 'Total loss': 0.8485968837683852} | train loss {'Reaction outcome loss': 0.8144836259425169, 'Total loss': 0.8144836259425169}
2022-11-18 01:10:11,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:11,714 INFO:     Epoch: 29
2022-11-18 01:10:12,518 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8184269646351988, 'Total loss': 0.8184269646351988} | train loss {'Reaction outcome loss': 0.8245322993892407, 'Total loss': 0.8245322993892407}
2022-11-18 01:10:12,518 INFO:     Found new best model at epoch 29
2022-11-18 01:10:12,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:12,519 INFO:     Epoch: 30
2022-11-18 01:10:13,328 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8294596705924381, 'Total loss': 0.8294596705924381} | train loss {'Reaction outcome loss': 0.8174005542930803, 'Total loss': 0.8174005542930803}
2022-11-18 01:10:13,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:13,328 INFO:     Epoch: 31
2022-11-18 01:10:14,148 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8205924907868559, 'Total loss': 0.8205924907868559} | train loss {'Reaction outcome loss': 0.8156029123073889, 'Total loss': 0.8156029123073889}
2022-11-18 01:10:14,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:14,148 INFO:     Epoch: 32
2022-11-18 01:10:14,986 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8280455334620043, 'Total loss': 0.8280455334620043} | train loss {'Reaction outcome loss': 0.8179950646241667, 'Total loss': 0.8179950646241667}
2022-11-18 01:10:14,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:14,986 INFO:     Epoch: 33
2022-11-18 01:10:15,776 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8489721837368879, 'Total loss': 0.8489721837368879} | train loss {'Reaction outcome loss': 0.8220724027890426, 'Total loss': 0.8220724027890426}
2022-11-18 01:10:15,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:15,777 INFO:     Epoch: 34
2022-11-18 01:10:16,566 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.823612929745154, 'Total loss': 0.823612929745154} | train loss {'Reaction outcome loss': 0.8314597426879744, 'Total loss': 0.8314597426879744}
2022-11-18 01:10:16,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:16,566 INFO:     Epoch: 35
2022-11-18 01:10:17,372 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8306819159876216, 'Total loss': 0.8306819159876216} | train loss {'Reaction outcome loss': 0.8257617951646025, 'Total loss': 0.8257617951646025}
2022-11-18 01:10:17,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:17,373 INFO:     Epoch: 36
2022-11-18 01:10:18,194 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.84844701804898, 'Total loss': 0.84844701804898} | train loss {'Reaction outcome loss': 0.8162004518122808, 'Total loss': 0.8162004518122808}
2022-11-18 01:10:18,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:18,194 INFO:     Epoch: 37
2022-11-18 01:10:19,052 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8253461041233756, 'Total loss': 0.8253461041233756} | train loss {'Reaction outcome loss': 0.8237399308063723, 'Total loss': 0.8237399308063723}
2022-11-18 01:10:19,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:19,053 INFO:     Epoch: 38
2022-11-18 01:10:19,859 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8196305280381982, 'Total loss': 0.8196305280381982} | train loss {'Reaction outcome loss': 0.8253024675344166, 'Total loss': 0.8253024675344166}
2022-11-18 01:10:19,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:19,859 INFO:     Epoch: 39
2022-11-18 01:10:20,684 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.840711238709363, 'Total loss': 0.840711238709363} | train loss {'Reaction outcome loss': 0.8176102901729736, 'Total loss': 0.8176102901729736}
2022-11-18 01:10:20,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:20,684 INFO:     Epoch: 40
2022-11-18 01:10:21,507 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8243876695632935, 'Total loss': 0.8243876695632935} | train loss {'Reaction outcome loss': 0.8182201498915792, 'Total loss': 0.8182201498915792}
2022-11-18 01:10:21,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:21,507 INFO:     Epoch: 41
2022-11-18 01:10:22,350 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8717846850102599, 'Total loss': 0.8717846850102599} | train loss {'Reaction outcome loss': 0.8253906464528459, 'Total loss': 0.8253906464528459}
2022-11-18 01:10:22,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:22,351 INFO:     Epoch: 42
2022-11-18 01:10:23,176 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8228587433695793, 'Total loss': 0.8228587433695793} | train loss {'Reaction outcome loss': 0.818533846769135, 'Total loss': 0.818533846769135}
2022-11-18 01:10:23,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:23,176 INFO:     Epoch: 43
2022-11-18 01:10:23,975 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8146486668424173, 'Total loss': 0.8146486668424173} | train loss {'Reaction outcome loss': 0.8195317160745381, 'Total loss': 0.8195317160745381}
2022-11-18 01:10:23,975 INFO:     Found new best model at epoch 43
2022-11-18 01:10:23,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:23,976 INFO:     Epoch: 44
2022-11-18 01:10:24,779 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8270947906104001, 'Total loss': 0.8270947906104001} | train loss {'Reaction outcome loss': 0.8197526258495655, 'Total loss': 0.8197526258495655}
2022-11-18 01:10:24,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:24,779 INFO:     Epoch: 45
2022-11-18 01:10:25,603 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8345191201025789, 'Total loss': 0.8345191201025789} | train loss {'Reaction outcome loss': 0.8307773440714307, 'Total loss': 0.8307773440714307}
2022-11-18 01:10:25,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:25,604 INFO:     Epoch: 46
2022-11-18 01:10:26,418 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.829252571544864, 'Total loss': 0.829252571544864} | train loss {'Reaction outcome loss': 0.816277261024062, 'Total loss': 0.816277261024062}
2022-11-18 01:10:26,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:26,418 INFO:     Epoch: 47
2022-11-18 01:10:27,241 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8307207396084612, 'Total loss': 0.8307207396084612} | train loss {'Reaction outcome loss': 0.8209958078890194, 'Total loss': 0.8209958078890194}
2022-11-18 01:10:27,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:27,242 INFO:     Epoch: 48
2022-11-18 01:10:28,051 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8228429406881332, 'Total loss': 0.8228429406881332} | train loss {'Reaction outcome loss': 0.8188544529591978, 'Total loss': 0.8188544529591978}
2022-11-18 01:10:28,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:28,051 INFO:     Epoch: 49
2022-11-18 01:10:28,863 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8236864012750712, 'Total loss': 0.8236864012750712} | train loss {'Reaction outcome loss': 0.8176278455054712, 'Total loss': 0.8176278455054712}
2022-11-18 01:10:28,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:28,863 INFO:     Epoch: 50
2022-11-18 01:10:29,670 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8157809363170103, 'Total loss': 0.8157809363170103} | train loss {'Reaction outcome loss': 0.8259097247229896, 'Total loss': 0.8259097247229896}
2022-11-18 01:10:29,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:29,670 INFO:     Epoch: 51
2022-11-18 01:10:30,498 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8187502283941616, 'Total loss': 0.8187502283941616} | train loss {'Reaction outcome loss': 0.8227313080055993, 'Total loss': 0.8227313080055993}
2022-11-18 01:10:30,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:30,498 INFO:     Epoch: 52
2022-11-18 01:10:31,334 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8239293450658972, 'Total loss': 0.8239293450658972} | train loss {'Reaction outcome loss': 0.8136489277909159, 'Total loss': 0.8136489277909159}
2022-11-18 01:10:31,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:31,334 INFO:     Epoch: 53
2022-11-18 01:10:32,155 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8383599275892432, 'Total loss': 0.8383599275892432} | train loss {'Reaction outcome loss': 0.8174807330374776, 'Total loss': 0.8174807330374776}
2022-11-18 01:10:32,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:32,156 INFO:     Epoch: 54
2022-11-18 01:10:32,968 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8204128721898253, 'Total loss': 0.8204128721898253} | train loss {'Reaction outcome loss': 0.8245309602152481, 'Total loss': 0.8245309602152481}
2022-11-18 01:10:32,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:32,968 INFO:     Epoch: 55
2022-11-18 01:10:33,770 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8427121788263321, 'Total loss': 0.8427121788263321} | train loss {'Reaction outcome loss': 0.8167093818788587, 'Total loss': 0.8167093818788587}
2022-11-18 01:10:33,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:33,770 INFO:     Epoch: 56
2022-11-18 01:10:34,596 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8184087655761025, 'Total loss': 0.8184087655761025} | train loss {'Reaction outcome loss': 0.8197192590728946, 'Total loss': 0.8197192590728946}
2022-11-18 01:10:34,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:34,596 INFO:     Epoch: 57
2022-11-18 01:10:35,426 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.813307402486151, 'Total loss': 0.813307402486151} | train loss {'Reaction outcome loss': 0.816586142971448, 'Total loss': 0.816586142971448}
2022-11-18 01:10:35,426 INFO:     Found new best model at epoch 57
2022-11-18 01:10:35,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:35,427 INFO:     Epoch: 58
2022-11-18 01:10:36,215 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8225979459556666, 'Total loss': 0.8225979459556666} | train loss {'Reaction outcome loss': 0.8235119576396247, 'Total loss': 0.8235119576396247}
2022-11-18 01:10:36,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:36,216 INFO:     Epoch: 59
2022-11-18 01:10:37,009 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8238076743754473, 'Total loss': 0.8238076743754473} | train loss {'Reaction outcome loss': 0.819172186407483, 'Total loss': 0.819172186407483}
2022-11-18 01:10:37,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:37,010 INFO:     Epoch: 60
2022-11-18 01:10:37,795 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8304341299967333, 'Total loss': 0.8304341299967333} | train loss {'Reaction outcome loss': 0.8179790077180515, 'Total loss': 0.8179790077180515}
2022-11-18 01:10:37,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:37,796 INFO:     Epoch: 61
2022-11-18 01:10:38,585 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8284212973984805, 'Total loss': 0.8284212973984805} | train loss {'Reaction outcome loss': 0.8136169121332979, 'Total loss': 0.8136169121332979}
2022-11-18 01:10:38,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:38,585 INFO:     Epoch: 62
2022-11-18 01:10:39,383 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8473373069004579, 'Total loss': 0.8473373069004579} | train loss {'Reaction outcome loss': 0.819060867855906, 'Total loss': 0.819060867855906}
2022-11-18 01:10:39,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:39,383 INFO:     Epoch: 63
2022-11-18 01:10:40,154 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.826123793694106, 'Total loss': 0.826123793694106} | train loss {'Reaction outcome loss': 0.8146535149711346, 'Total loss': 0.8146535149711346}
2022-11-18 01:10:40,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:40,155 INFO:     Epoch: 64
2022-11-18 01:10:40,934 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8199547244743868, 'Total loss': 0.8199547244743868} | train loss {'Reaction outcome loss': 0.8142270367999791, 'Total loss': 0.8142270367999791}
2022-11-18 01:10:40,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:40,934 INFO:     Epoch: 65
2022-11-18 01:10:41,704 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8142418915575201, 'Total loss': 0.8142418915575201} | train loss {'Reaction outcome loss': 0.8187576850898836, 'Total loss': 0.8187576850898836}
2022-11-18 01:10:41,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:41,704 INFO:     Epoch: 66
2022-11-18 01:10:42,508 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8304809785702012, 'Total loss': 0.8304809785702012} | train loss {'Reaction outcome loss': 0.81920777653393, 'Total loss': 0.81920777653393}
2022-11-18 01:10:42,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:42,509 INFO:     Epoch: 67
2022-11-18 01:10:43,289 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.826331299814311, 'Total loss': 0.826331299814311} | train loss {'Reaction outcome loss': 0.8142366707324982, 'Total loss': 0.8142366707324982}
2022-11-18 01:10:43,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:43,289 INFO:     Epoch: 68
2022-11-18 01:10:44,054 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8198955086144534, 'Total loss': 0.8198955086144534} | train loss {'Reaction outcome loss': 0.8181126123739157, 'Total loss': 0.8181126123739157}
2022-11-18 01:10:44,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:44,055 INFO:     Epoch: 69
2022-11-18 01:10:44,845 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8230312764644623, 'Total loss': 0.8230312764644623} | train loss {'Reaction outcome loss': 0.8186031836971097, 'Total loss': 0.8186031836971097}
2022-11-18 01:10:44,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:44,845 INFO:     Epoch: 70
2022-11-18 01:10:45,605 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8348777836019342, 'Total loss': 0.8348777836019342} | train loss {'Reaction outcome loss': 0.8159975341939734, 'Total loss': 0.8159975341939734}
2022-11-18 01:10:45,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:45,606 INFO:     Epoch: 71
2022-11-18 01:10:46,363 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8260988599874757, 'Total loss': 0.8260988599874757} | train loss {'Reaction outcome loss': 0.8173745926318743, 'Total loss': 0.8173745926318743}
2022-11-18 01:10:46,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:46,364 INFO:     Epoch: 72
2022-11-18 01:10:47,163 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8053437725386836, 'Total loss': 0.8053437725386836} | train loss {'Reaction outcome loss': 0.816828152790726, 'Total loss': 0.816828152790726}
2022-11-18 01:10:47,163 INFO:     Found new best model at epoch 72
2022-11-18 01:10:47,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:47,164 INFO:     Epoch: 73
2022-11-18 01:10:47,957 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8213893805037845, 'Total loss': 0.8213893805037845} | train loss {'Reaction outcome loss': 0.8169119563179943, 'Total loss': 0.8169119563179943}
2022-11-18 01:10:47,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:47,957 INFO:     Epoch: 74
2022-11-18 01:10:48,750 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8275681720538572, 'Total loss': 0.8275681720538572} | train loss {'Reaction outcome loss': 0.8180617909079139, 'Total loss': 0.8180617909079139}
2022-11-18 01:10:48,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:48,751 INFO:     Epoch: 75
2022-11-18 01:10:49,527 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8369824229316278, 'Total loss': 0.8369824229316278} | train loss {'Reaction outcome loss': 0.8176014324733121, 'Total loss': 0.8176014324733121}
2022-11-18 01:10:49,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:49,528 INFO:     Epoch: 76
2022-11-18 01:10:50,322 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8219244981353934, 'Total loss': 0.8219244981353934} | train loss {'Reaction outcome loss': 0.8172478350067911, 'Total loss': 0.8172478350067911}
2022-11-18 01:10:50,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:50,323 INFO:     Epoch: 77
2022-11-18 01:10:51,107 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8288760740648616, 'Total loss': 0.8288760740648616} | train loss {'Reaction outcome loss': 0.8156020227472792, 'Total loss': 0.8156020227472792}
2022-11-18 01:10:51,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:51,107 INFO:     Epoch: 78
2022-11-18 01:10:51,871 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8193150332028215, 'Total loss': 0.8193150332028215} | train loss {'Reaction outcome loss': 0.8169441903651002, 'Total loss': 0.8169441903651002}
2022-11-18 01:10:51,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:51,872 INFO:     Epoch: 79
2022-11-18 01:10:52,661 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8371607701886784, 'Total loss': 0.8371607701886784} | train loss {'Reaction outcome loss': 0.8172250382813365, 'Total loss': 0.8172250382813365}
2022-11-18 01:10:52,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:52,661 INFO:     Epoch: 80
2022-11-18 01:10:53,440 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8426749794320627, 'Total loss': 0.8426749794320627} | train loss {'Reaction outcome loss': 0.8198916557346762, 'Total loss': 0.8198916557346762}
2022-11-18 01:10:53,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:53,441 INFO:     Epoch: 81
2022-11-18 01:10:54,238 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8282930681651289, 'Total loss': 0.8282930681651289} | train loss {'Reaction outcome loss': 0.8196231232963593, 'Total loss': 0.8196231232963593}
2022-11-18 01:10:54,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:54,238 INFO:     Epoch: 82
2022-11-18 01:10:55,041 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8267659470438957, 'Total loss': 0.8267659470438957} | train loss {'Reaction outcome loss': 0.8191913039336803, 'Total loss': 0.8191913039336803}
2022-11-18 01:10:55,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:55,041 INFO:     Epoch: 83
2022-11-18 01:10:55,808 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8278243717822161, 'Total loss': 0.8278243717822161} | train loss {'Reaction outcome loss': 0.8204934241076712, 'Total loss': 0.8204934241076712}
2022-11-18 01:10:55,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:55,809 INFO:     Epoch: 84
2022-11-18 01:10:56,583 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8240157684141939, 'Total loss': 0.8240157684141939} | train loss {'Reaction outcome loss': 0.8236067456755078, 'Total loss': 0.8236067456755078}
2022-11-18 01:10:56,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:56,583 INFO:     Epoch: 85
2022-11-18 01:10:57,378 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.817349605939605, 'Total loss': 0.817349605939605} | train loss {'Reaction outcome loss': 0.822402280593208, 'Total loss': 0.822402280593208}
2022-11-18 01:10:57,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:57,378 INFO:     Epoch: 86
2022-11-18 01:10:58,171 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8297645070336082, 'Total loss': 0.8297645070336082} | train loss {'Reaction outcome loss': 0.8180638479317731, 'Total loss': 0.8180638479317731}
2022-11-18 01:10:58,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:58,172 INFO:     Epoch: 87
2022-11-18 01:10:58,954 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8317425494844263, 'Total loss': 0.8317425494844263} | train loss {'Reaction outcome loss': 0.8243560082758004, 'Total loss': 0.8243560082758004}
2022-11-18 01:10:58,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:58,955 INFO:     Epoch: 88
2022-11-18 01:10:59,752 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8115220794623549, 'Total loss': 0.8115220794623549} | train loss {'Reaction outcome loss': 0.8244809943896073, 'Total loss': 0.8244809943896073}
2022-11-18 01:10:59,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:10:59,752 INFO:     Epoch: 89
2022-11-18 01:11:00,545 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.823472033847462, 'Total loss': 0.823472033847462} | train loss {'Reaction outcome loss': 0.8172007007637487, 'Total loss': 0.8172007007637487}
2022-11-18 01:11:00,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:00,545 INFO:     Epoch: 90
2022-11-18 01:11:01,352 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8238503601063382, 'Total loss': 0.8238503601063382} | train loss {'Reaction outcome loss': 0.8149491194409397, 'Total loss': 0.8149491194409397}
2022-11-18 01:11:01,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:01,352 INFO:     Epoch: 91
2022-11-18 01:11:02,160 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8288559100844644, 'Total loss': 0.8288559100844644} | train loss {'Reaction outcome loss': 0.8187378565309501, 'Total loss': 0.8187378565309501}
2022-11-18 01:11:02,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:02,161 INFO:     Epoch: 92
2022-11-18 01:11:02,951 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.830981807275252, 'Total loss': 0.830981807275252} | train loss {'Reaction outcome loss': 0.817330142264424, 'Total loss': 0.817330142264424}
2022-11-18 01:11:02,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:02,951 INFO:     Epoch: 93
2022-11-18 01:11:03,747 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8242757144299421, 'Total loss': 0.8242757144299421} | train loss {'Reaction outcome loss': 0.8205555297343837, 'Total loss': 0.8205555297343837}
2022-11-18 01:11:03,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:03,747 INFO:     Epoch: 94
2022-11-18 01:11:04,540 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8295515491203829, 'Total loss': 0.8295515491203829} | train loss {'Reaction outcome loss': 0.8136138398396341, 'Total loss': 0.8136138398396341}
2022-11-18 01:11:04,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:04,540 INFO:     Epoch: 95
2022-11-18 01:11:05,326 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.829237587749958, 'Total loss': 0.829237587749958} | train loss {'Reaction outcome loss': 0.8185433981872281, 'Total loss': 0.8185433981872281}
2022-11-18 01:11:05,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:05,326 INFO:     Epoch: 96
2022-11-18 01:11:06,125 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8217710547826507, 'Total loss': 0.8217710547826507} | train loss {'Reaction outcome loss': 0.8194217534683012, 'Total loss': 0.8194217534683012}
2022-11-18 01:11:06,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:06,125 INFO:     Epoch: 97
2022-11-18 01:11:06,927 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8111744529821656, 'Total loss': 0.8111744529821656} | train loss {'Reaction outcome loss': 0.8196834556245611, 'Total loss': 0.8196834556245611}
2022-11-18 01:11:06,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:06,927 INFO:     Epoch: 98
2022-11-18 01:11:07,707 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.840006984770298, 'Total loss': 0.840006984770298} | train loss {'Reaction outcome loss': 0.816055078994528, 'Total loss': 0.816055078994528}
2022-11-18 01:11:07,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:07,707 INFO:     Epoch: 99
2022-11-18 01:11:08,499 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8155962350693616, 'Total loss': 0.8155962350693616} | train loss {'Reaction outcome loss': 0.8135890208697512, 'Total loss': 0.8135890208697512}
2022-11-18 01:11:08,500 INFO:     Best model found after epoch 73 of 100.
2022-11-18 01:11:08,501 INFO:   Done with stage: TRAINING
2022-11-18 01:11:08,501 INFO:   Starting stage: EVALUATION
2022-11-18 01:11:08,626 INFO:   Done with stage: EVALUATION
2022-11-18 01:11:08,626 INFO:   Leaving out SEQ value Fold_3
2022-11-18 01:11:08,639 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:11:08,640 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:11:09,309 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:11:09,310 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:11:09,380 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:11:09,380 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:11:09,380 INFO:     No hyperparam tuning for this model
2022-11-18 01:11:09,380 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:11:09,380 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:11:09,381 INFO:     None feature selector for col prot
2022-11-18 01:11:09,381 INFO:     None feature selector for col prot
2022-11-18 01:11:09,381 INFO:     None feature selector for col prot
2022-11-18 01:11:09,382 INFO:     None feature selector for col chem
2022-11-18 01:11:09,382 INFO:     None feature selector for col chem
2022-11-18 01:11:09,382 INFO:     None feature selector for col chem
2022-11-18 01:11:09,382 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:11:09,382 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:11:09,384 INFO:     Number of params in model 168571
2022-11-18 01:11:09,387 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:11:09,387 INFO:   Starting stage: TRAINING
2022-11-18 01:11:09,445 INFO:     Val loss before train {'Reaction outcome loss': 1.0072001828388735, 'Total loss': 1.0072001828388735}
2022-11-18 01:11:09,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:09,445 INFO:     Epoch: 0
2022-11-18 01:11:10,209 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8473307558081367, 'Total loss': 0.8473307558081367} | train loss {'Reaction outcome loss': 0.8661456043622932, 'Total loss': 0.8661456043622932}
2022-11-18 01:11:10,209 INFO:     Found new best model at epoch 0
2022-11-18 01:11:10,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:10,210 INFO:     Epoch: 1
2022-11-18 01:11:11,000 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8263915655287829, 'Total loss': 0.8263915655287829} | train loss {'Reaction outcome loss': 0.8363097048535639, 'Total loss': 0.8363097048535639}
2022-11-18 01:11:11,001 INFO:     Found new best model at epoch 1
2022-11-18 01:11:11,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:11,002 INFO:     Epoch: 2
2022-11-18 01:11:11,756 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.806033078242432, 'Total loss': 0.806033078242432} | train loss {'Reaction outcome loss': 0.8361251489240296, 'Total loss': 0.8361251489240296}
2022-11-18 01:11:11,756 INFO:     Found new best model at epoch 2
2022-11-18 01:11:11,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:11,757 INFO:     Epoch: 3
2022-11-18 01:11:12,545 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8575982370159843, 'Total loss': 0.8575982370159843} | train loss {'Reaction outcome loss': 0.8226163664642645, 'Total loss': 0.8226163664642645}
2022-11-18 01:11:12,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:12,545 INFO:     Epoch: 4
2022-11-18 01:11:13,299 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8579733154990457, 'Total loss': 0.8579733154990457} | train loss {'Reaction outcome loss': 0.8206258970863965, 'Total loss': 0.8206258970863965}
2022-11-18 01:11:13,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:13,299 INFO:     Epoch: 5
2022-11-18 01:11:14,086 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8102240792729638, 'Total loss': 0.8102240792729638} | train loss {'Reaction outcome loss': 0.8219952205005957, 'Total loss': 0.8219952205005957}
2022-11-18 01:11:14,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:14,087 INFO:     Epoch: 6
2022-11-18 01:11:14,858 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8281123428182169, 'Total loss': 0.8281123428182169} | train loss {'Reaction outcome loss': 0.8200189212147071, 'Total loss': 0.8200189212147071}
2022-11-18 01:11:14,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:14,858 INFO:     Epoch: 7
2022-11-18 01:11:15,640 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8151094236157157, 'Total loss': 0.8151094236157157} | train loss {'Reaction outcome loss': 0.8161618589138498, 'Total loss': 0.8161618589138498}
2022-11-18 01:11:15,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:15,641 INFO:     Epoch: 8
2022-11-18 01:11:16,419 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7981870338659395, 'Total loss': 0.7981870338659395} | train loss {'Reaction outcome loss': 0.815466007651115, 'Total loss': 0.815466007651115}
2022-11-18 01:11:16,419 INFO:     Found new best model at epoch 8
2022-11-18 01:11:16,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:16,420 INFO:     Epoch: 9
2022-11-18 01:11:17,195 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.794976295395331, 'Total loss': 0.794976295395331} | train loss {'Reaction outcome loss': 0.8145074322515604, 'Total loss': 0.8145074322515604}
2022-11-18 01:11:17,195 INFO:     Found new best model at epoch 9
2022-11-18 01:11:17,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:17,196 INFO:     Epoch: 10
2022-11-18 01:11:17,967 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8088831847364252, 'Total loss': 0.8088831847364252} | train loss {'Reaction outcome loss': 0.8115389078247304, 'Total loss': 0.8115389078247304}
2022-11-18 01:11:17,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:17,967 INFO:     Epoch: 11
2022-11-18 01:11:18,722 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8038985483687032, 'Total loss': 0.8038985483687032} | train loss {'Reaction outcome loss': 0.8072354297248685, 'Total loss': 0.8072354297248685}
2022-11-18 01:11:18,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:18,722 INFO:     Epoch: 12
2022-11-18 01:11:19,472 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.826325000687079, 'Total loss': 0.826325000687079} | train loss {'Reaction outcome loss': 0.8148252187942971, 'Total loss': 0.8148252187942971}
2022-11-18 01:11:19,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:19,472 INFO:     Epoch: 13
2022-11-18 01:11:20,279 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8199420422315598, 'Total loss': 0.8199420422315598} | train loss {'Reaction outcome loss': 0.8114180613537224, 'Total loss': 0.8114180613537224}
2022-11-18 01:11:20,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:20,279 INFO:     Epoch: 14
2022-11-18 01:11:21,060 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7945270213213834, 'Total loss': 0.7945270213213834} | train loss {'Reaction outcome loss': 0.8070046697344099, 'Total loss': 0.8070046697344099}
2022-11-18 01:11:21,061 INFO:     Found new best model at epoch 14
2022-11-18 01:11:21,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:21,063 INFO:     Epoch: 15
2022-11-18 01:11:21,830 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7962510829622095, 'Total loss': 0.7962510829622095} | train loss {'Reaction outcome loss': 0.8047420378850431, 'Total loss': 0.8047420378850431}
2022-11-18 01:11:21,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:21,831 INFO:     Epoch: 16
2022-11-18 01:11:22,595 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7930521358820525, 'Total loss': 0.7930521358820525} | train loss {'Reaction outcome loss': 0.8060342741255857, 'Total loss': 0.8060342741255857}
2022-11-18 01:11:22,595 INFO:     Found new best model at epoch 16
2022-11-18 01:11:22,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:22,596 INFO:     Epoch: 17
2022-11-18 01:11:23,387 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7973440844904293, 'Total loss': 0.7973440844904293} | train loss {'Reaction outcome loss': 0.8062867634150447, 'Total loss': 0.8062867634150447}
2022-11-18 01:11:23,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:23,387 INFO:     Epoch: 18
2022-11-18 01:11:24,198 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8125253861600702, 'Total loss': 0.8125253861600702} | train loss {'Reaction outcome loss': 0.8037898671870329, 'Total loss': 0.8037898671870329}
2022-11-18 01:11:24,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:24,198 INFO:     Epoch: 19
2022-11-18 01:11:25,003 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7838190726258538, 'Total loss': 0.7838190726258538} | train loss {'Reaction outcome loss': 0.8051497505635631, 'Total loss': 0.8051497505635631}
2022-11-18 01:11:25,003 INFO:     Found new best model at epoch 19
2022-11-18 01:11:25,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:25,004 INFO:     Epoch: 20
2022-11-18 01:11:25,867 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7984711223027923, 'Total loss': 0.7984711223027923} | train loss {'Reaction outcome loss': 0.8062735955325925, 'Total loss': 0.8062735955325925}
2022-11-18 01:11:25,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:25,868 INFO:     Epoch: 21
2022-11-18 01:11:26,687 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8089394122362137, 'Total loss': 0.8089394122362137} | train loss {'Reaction outcome loss': 0.8014472729089309, 'Total loss': 0.8014472729089309}
2022-11-18 01:11:26,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:26,688 INFO:     Epoch: 22
2022-11-18 01:11:27,493 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8118146495385603, 'Total loss': 0.8118146495385603} | train loss {'Reaction outcome loss': 0.8068097624243522, 'Total loss': 0.8068097624243522}
2022-11-18 01:11:27,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:27,494 INFO:     Epoch: 23
2022-11-18 01:11:28,286 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8002983609383757, 'Total loss': 0.8002983609383757} | train loss {'Reaction outcome loss': 0.8055199115860219, 'Total loss': 0.8055199115860219}
2022-11-18 01:11:28,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:28,287 INFO:     Epoch: 24
2022-11-18 01:11:29,063 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8293936584483493, 'Total loss': 0.8293936584483493} | train loss {'Reaction outcome loss': 0.800737137818823, 'Total loss': 0.800737137818823}
2022-11-18 01:11:29,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:29,064 INFO:     Epoch: 25
2022-11-18 01:11:29,886 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8019526715983044, 'Total loss': 0.8019526715983044} | train loss {'Reaction outcome loss': 0.8063127155206642, 'Total loss': 0.8063127155206642}
2022-11-18 01:11:29,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:29,886 INFO:     Epoch: 26
2022-11-18 01:11:30,687 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8053193925456568, 'Total loss': 0.8053193925456568} | train loss {'Reaction outcome loss': 0.802502616205994, 'Total loss': 0.802502616205994}
2022-11-18 01:11:30,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:30,687 INFO:     Epoch: 27
2022-11-18 01:11:31,454 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8288445770740509, 'Total loss': 0.8288445770740509} | train loss {'Reaction outcome loss': 0.8048244436176456, 'Total loss': 0.8048244436176456}
2022-11-18 01:11:31,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:31,454 INFO:     Epoch: 28
2022-11-18 01:11:32,308 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8152647411281412, 'Total loss': 0.8152647411281412} | train loss {'Reaction outcome loss': 0.8001887418785874, 'Total loss': 0.8001887418785874}
2022-11-18 01:11:32,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:32,309 INFO:     Epoch: 29
2022-11-18 01:11:33,144 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7897707393223589, 'Total loss': 0.7897707393223589} | train loss {'Reaction outcome loss': 0.8020744141267271, 'Total loss': 0.8020744141267271}
2022-11-18 01:11:33,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:33,144 INFO:     Epoch: 30
2022-11-18 01:11:33,915 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8165215714411302, 'Total loss': 0.8165215714411302} | train loss {'Reaction outcome loss': 0.7981628297543039, 'Total loss': 0.7981628297543039}
2022-11-18 01:11:33,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:33,915 INFO:     Epoch: 31
2022-11-18 01:11:34,779 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8102288693189621, 'Total loss': 0.8102288693189621} | train loss {'Reaction outcome loss': 0.8015733089982247, 'Total loss': 0.8015733089982247}
2022-11-18 01:11:34,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:34,779 INFO:     Epoch: 32
2022-11-18 01:11:35,548 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7924274551597509, 'Total loss': 0.7924274551597509} | train loss {'Reaction outcome loss': 0.8018284584794726, 'Total loss': 0.8018284584794726}
2022-11-18 01:11:35,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:35,548 INFO:     Epoch: 33
2022-11-18 01:11:36,318 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7869119102304633, 'Total loss': 0.7869119102304633} | train loss {'Reaction outcome loss': 0.8036098427918492, 'Total loss': 0.8036098427918492}
2022-11-18 01:11:36,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:36,318 INFO:     Epoch: 34
2022-11-18 01:11:37,080 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8087801093404944, 'Total loss': 0.8087801093404944} | train loss {'Reaction outcome loss': 0.8008341665170631, 'Total loss': 0.8008341665170631}
2022-11-18 01:11:37,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:37,080 INFO:     Epoch: 35
2022-11-18 01:11:37,876 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8439879728989168, 'Total loss': 0.8439879728989168} | train loss {'Reaction outcome loss': 0.8027124924319131, 'Total loss': 0.8027124924319131}
2022-11-18 01:11:37,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:37,876 INFO:     Epoch: 36
2022-11-18 01:11:38,652 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8114369714801962, 'Total loss': 0.8114369714801962} | train loss {'Reaction outcome loss': 0.8044384417485217, 'Total loss': 0.8044384417485217}
2022-11-18 01:11:38,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:38,652 INFO:     Epoch: 37
2022-11-18 01:11:39,427 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8026366193186153, 'Total loss': 0.8026366193186153} | train loss {'Reaction outcome loss': 0.8044933542913321, 'Total loss': 0.8044933542913321}
2022-11-18 01:11:39,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:39,427 INFO:     Epoch: 38
2022-11-18 01:11:40,191 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8122795908288523, 'Total loss': 0.8122795908288523} | train loss {'Reaction outcome loss': 0.8061283553133205, 'Total loss': 0.8061283553133205}
2022-11-18 01:11:40,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:40,192 INFO:     Epoch: 39
2022-11-18 01:11:40,969 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7910327152772383, 'Total loss': 0.7910327152772383} | train loss {'Reaction outcome loss': 0.7979537056416881, 'Total loss': 0.7979537056416881}
2022-11-18 01:11:40,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:40,970 INFO:     Epoch: 40
2022-11-18 01:11:41,742 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8112951862541112, 'Total loss': 0.8112951862541112} | train loss {'Reaction outcome loss': 0.8001068474078665, 'Total loss': 0.8001068474078665}
2022-11-18 01:11:41,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:41,742 INFO:     Epoch: 41
2022-11-18 01:11:42,500 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7961976731365378, 'Total loss': 0.7961976731365378} | train loss {'Reaction outcome loss': 0.8018714041126017, 'Total loss': 0.8018714041126017}
2022-11-18 01:11:42,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:42,500 INFO:     Epoch: 42
2022-11-18 01:11:43,270 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.800179667093537, 'Total loss': 0.800179667093537} | train loss {'Reaction outcome loss': 0.8007625495900913, 'Total loss': 0.8007625495900913}
2022-11-18 01:11:43,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:43,271 INFO:     Epoch: 43
2022-11-18 01:11:44,061 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8028526834466241, 'Total loss': 0.8028526834466241} | train loss {'Reaction outcome loss': 0.7995267110211509, 'Total loss': 0.7995267110211509}
2022-11-18 01:11:44,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:44,061 INFO:     Epoch: 44
2022-11-18 01:11:44,822 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7956383356993849, 'Total loss': 0.7956383356993849} | train loss {'Reaction outcome loss': 0.7985050528633352, 'Total loss': 0.7985050528633352}
2022-11-18 01:11:44,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:44,822 INFO:     Epoch: 45
2022-11-18 01:11:45,576 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.807392339814793, 'Total loss': 0.807392339814793} | train loss {'Reaction outcome loss': 0.7991505917237729, 'Total loss': 0.7991505917237729}
2022-11-18 01:11:45,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:45,576 INFO:     Epoch: 46
2022-11-18 01:11:46,342 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8013307777318087, 'Total loss': 0.8013307777318087} | train loss {'Reaction outcome loss': 0.7969566517946671, 'Total loss': 0.7969566517946671}
2022-11-18 01:11:46,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:46,343 INFO:     Epoch: 47
2022-11-18 01:11:47,123 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.798539328304204, 'Total loss': 0.798539328304204} | train loss {'Reaction outcome loss': 0.8046228102275303, 'Total loss': 0.8046228102275303}
2022-11-18 01:11:47,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:47,123 INFO:     Epoch: 48
2022-11-18 01:11:47,910 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8136392662470991, 'Total loss': 0.8136392662470991} | train loss {'Reaction outcome loss': 0.7995018409222973, 'Total loss': 0.7995018409222973}
2022-11-18 01:11:47,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:47,910 INFO:     Epoch: 49
2022-11-18 01:11:48,691 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7975541082295504, 'Total loss': 0.7975541082295504} | train loss {'Reaction outcome loss': 0.8022610519613539, 'Total loss': 0.8022610519613539}
2022-11-18 01:11:48,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:48,692 INFO:     Epoch: 50
2022-11-18 01:11:49,470 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7899977998300032, 'Total loss': 0.7899977998300032} | train loss {'Reaction outcome loss': 0.8032918152760486, 'Total loss': 0.8032918152760486}
2022-11-18 01:11:49,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:49,471 INFO:     Epoch: 51
2022-11-18 01:11:50,218 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8033783998001706, 'Total loss': 0.8033783998001706} | train loss {'Reaction outcome loss': 0.802424555043785, 'Total loss': 0.802424555043785}
2022-11-18 01:11:50,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:50,218 INFO:     Epoch: 52
2022-11-18 01:11:50,998 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7953039705753326, 'Total loss': 0.7953039705753326} | train loss {'Reaction outcome loss': 0.8002103893124327, 'Total loss': 0.8002103893124327}
2022-11-18 01:11:50,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:50,998 INFO:     Epoch: 53
2022-11-18 01:11:51,763 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8055108372460712, 'Total loss': 0.8055108372460712} | train loss {'Reaction outcome loss': 0.7979446257863726, 'Total loss': 0.7979446257863726}
2022-11-18 01:11:51,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:51,763 INFO:     Epoch: 54
2022-11-18 01:11:52,525 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8080290149558674, 'Total loss': 0.8080290149558674} | train loss {'Reaction outcome loss': 0.8026647616405876, 'Total loss': 0.8026647616405876}
2022-11-18 01:11:52,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:52,527 INFO:     Epoch: 55
2022-11-18 01:11:53,313 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.826931091194803, 'Total loss': 0.826931091194803} | train loss {'Reaction outcome loss': 0.802768262186829, 'Total loss': 0.802768262186829}
2022-11-18 01:11:53,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:53,314 INFO:     Epoch: 56
2022-11-18 01:11:54,100 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8075810169631784, 'Total loss': 0.8075810169631784} | train loss {'Reaction outcome loss': 0.7974774863038744, 'Total loss': 0.7974774863038744}
2022-11-18 01:11:54,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:54,101 INFO:     Epoch: 57
2022-11-18 01:11:54,870 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8058056824586608, 'Total loss': 0.8058056824586608} | train loss {'Reaction outcome loss': 0.8043876053119192, 'Total loss': 0.8043876053119192}
2022-11-18 01:11:54,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:54,870 INFO:     Epoch: 58
2022-11-18 01:11:55,613 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8509135097265244, 'Total loss': 0.8509135097265244} | train loss {'Reaction outcome loss': 0.8026897822107587, 'Total loss': 0.8026897822107587}
2022-11-18 01:11:55,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:55,614 INFO:     Epoch: 59
2022-11-18 01:11:56,403 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7899498736316507, 'Total loss': 0.7899498736316507} | train loss {'Reaction outcome loss': 0.7983271565972542, 'Total loss': 0.7983271565972542}
2022-11-18 01:11:56,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:56,404 INFO:     Epoch: 60
2022-11-18 01:11:57,160 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7895345498215068, 'Total loss': 0.7895345498215068} | train loss {'Reaction outcome loss': 0.8006435761646349, 'Total loss': 0.8006435761646349}
2022-11-18 01:11:57,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:57,160 INFO:     Epoch: 61
2022-11-18 01:11:57,958 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7997286123308268, 'Total loss': 0.7997286123308268} | train loss {'Reaction outcome loss': 0.8021905513442292, 'Total loss': 0.8021905513442292}
2022-11-18 01:11:57,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:57,959 INFO:     Epoch: 62
2022-11-18 01:11:58,743 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8327618112618272, 'Total loss': 0.8327618112618272} | train loss {'Reaction outcome loss': 0.8031743604309705, 'Total loss': 0.8031743604309705}
2022-11-18 01:11:58,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:58,744 INFO:     Epoch: 63
2022-11-18 01:11:59,538 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8093491332097487, 'Total loss': 0.8093491332097487} | train loss {'Reaction outcome loss': 0.7986140366719694, 'Total loss': 0.7986140366719694}
2022-11-18 01:11:59,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:11:59,539 INFO:     Epoch: 64
2022-11-18 01:12:00,337 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.79679900881919, 'Total loss': 0.79679900881919} | train loss {'Reaction outcome loss': 0.801988139444468, 'Total loss': 0.801988139444468}
2022-11-18 01:12:00,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:00,338 INFO:     Epoch: 65
2022-11-18 01:12:01,098 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8068048175085675, 'Total loss': 0.8068048175085675} | train loss {'Reaction outcome loss': 0.7984828495249456, 'Total loss': 0.7984828495249456}
2022-11-18 01:12:01,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:01,099 INFO:     Epoch: 66
2022-11-18 01:12:01,889 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8092916756868362, 'Total loss': 0.8092916756868362} | train loss {'Reaction outcome loss': 0.8001639923270868, 'Total loss': 0.8001639923270868}
2022-11-18 01:12:01,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:01,890 INFO:     Epoch: 67
2022-11-18 01:12:02,676 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7957209301265803, 'Total loss': 0.7957209301265803} | train loss {'Reaction outcome loss': 0.8000946873304795, 'Total loss': 0.8000946873304795}
2022-11-18 01:12:02,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:02,676 INFO:     Epoch: 68
2022-11-18 01:12:03,434 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.808174959637902, 'Total loss': 0.808174959637902} | train loss {'Reaction outcome loss': 0.7990094940273129, 'Total loss': 0.7990094940273129}
2022-11-18 01:12:03,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:03,434 INFO:     Epoch: 69
2022-11-18 01:12:04,199 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7986267310651866, 'Total loss': 0.7986267310651866} | train loss {'Reaction outcome loss': 0.7993438572299724, 'Total loss': 0.7993438572299724}
2022-11-18 01:12:04,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:04,199 INFO:     Epoch: 70
2022-11-18 01:12:04,978 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8343665613369509, 'Total loss': 0.8343665613369509} | train loss {'Reaction outcome loss': 0.8037501211069068, 'Total loss': 0.8037501211069068}
2022-11-18 01:12:04,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:04,978 INFO:     Epoch: 71
2022-11-18 01:12:05,751 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7920645560053262, 'Total loss': 0.7920645560053262} | train loss {'Reaction outcome loss': 0.8006373590352583, 'Total loss': 0.8006373590352583}
2022-11-18 01:12:05,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:05,751 INFO:     Epoch: 72
2022-11-18 01:12:06,535 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7909368723630905, 'Total loss': 0.7909368723630905} | train loss {'Reaction outcome loss': 0.7983361106746051, 'Total loss': 0.7983361106746051}
2022-11-18 01:12:06,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:06,535 INFO:     Epoch: 73
2022-11-18 01:12:07,312 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.791910473595966, 'Total loss': 0.791910473595966} | train loss {'Reaction outcome loss': 0.8003607228094217, 'Total loss': 0.8003607228094217}
2022-11-18 01:12:07,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:07,312 INFO:     Epoch: 74
2022-11-18 01:12:08,104 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8030820360237901, 'Total loss': 0.8030820360237901} | train loss {'Reaction outcome loss': 0.7976511233923387, 'Total loss': 0.7976511233923387}
2022-11-18 01:12:08,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:08,105 INFO:     Epoch: 75
2022-11-18 01:12:08,873 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7969629751010374, 'Total loss': 0.7969629751010374} | train loss {'Reaction outcome loss': 0.8010585364030332, 'Total loss': 0.8010585364030332}
2022-11-18 01:12:08,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:08,873 INFO:     Epoch: 76
2022-11-18 01:12:09,642 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8192082995718176, 'Total loss': 0.8192082995718176} | train loss {'Reaction outcome loss': 0.803927258447725, 'Total loss': 0.803927258447725}
2022-11-18 01:12:09,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:09,642 INFO:     Epoch: 77
2022-11-18 01:12:10,407 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8021702949296344, 'Total loss': 0.8021702949296344} | train loss {'Reaction outcome loss': 0.8044643832712758, 'Total loss': 0.8044643832712758}
2022-11-18 01:12:10,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:10,407 INFO:     Epoch: 78
2022-11-18 01:12:11,181 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8030590604652058, 'Total loss': 0.8030590604652058} | train loss {'Reaction outcome loss': 0.8003614938988978, 'Total loss': 0.8003614938988978}
2022-11-18 01:12:11,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:11,182 INFO:     Epoch: 79
2022-11-18 01:12:11,958 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7822451002218507, 'Total loss': 0.7822451002218507} | train loss {'Reaction outcome loss': 0.798067902788824, 'Total loss': 0.798067902788824}
2022-11-18 01:12:11,958 INFO:     Found new best model at epoch 79
2022-11-18 01:12:11,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:11,959 INFO:     Epoch: 80
2022-11-18 01:12:12,723 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8189529661427845, 'Total loss': 0.8189529661427845} | train loss {'Reaction outcome loss': 0.7976284040480244, 'Total loss': 0.7976284040480244}
2022-11-18 01:12:12,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:12,723 INFO:     Epoch: 81
2022-11-18 01:12:13,493 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8042821132323958, 'Total loss': 0.8042821132323958} | train loss {'Reaction outcome loss': 0.8024665679250444, 'Total loss': 0.8024665679250444}
2022-11-18 01:12:13,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:13,493 INFO:     Epoch: 82
2022-11-18 01:12:14,272 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.791785481301221, 'Total loss': 0.791785481301221} | train loss {'Reaction outcome loss': 0.7963795547582665, 'Total loss': 0.7963795547582665}
2022-11-18 01:12:14,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:14,272 INFO:     Epoch: 83
2022-11-18 01:12:15,022 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7981618398969824, 'Total loss': 0.7981618398969824} | train loss {'Reaction outcome loss': 0.8015361274991717, 'Total loss': 0.8015361274991717}
2022-11-18 01:12:15,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:15,022 INFO:     Epoch: 84
2022-11-18 01:12:15,795 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7906085889447819, 'Total loss': 0.7906085889447819} | train loss {'Reaction outcome loss': 0.7973952237440616, 'Total loss': 0.7973952237440616}
2022-11-18 01:12:15,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:15,795 INFO:     Epoch: 85
2022-11-18 01:12:16,557 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7837946279482408, 'Total loss': 0.7837946279482408} | train loss {'Reaction outcome loss': 0.8023744011411862, 'Total loss': 0.8023744011411862}
2022-11-18 01:12:16,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:16,557 INFO:     Epoch: 86
2022-11-18 01:12:17,320 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8374390629204836, 'Total loss': 0.8374390629204836} | train loss {'Reaction outcome loss': 0.8003975066603447, 'Total loss': 0.8003975066603447}
2022-11-18 01:12:17,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:17,321 INFO:     Epoch: 87
2022-11-18 01:12:18,090 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8043067103082483, 'Total loss': 0.8043067103082483} | train loss {'Reaction outcome loss': 0.7998796994588813, 'Total loss': 0.7998796994588813}
2022-11-18 01:12:18,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:18,090 INFO:     Epoch: 88
2022-11-18 01:12:18,859 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.78721848604354, 'Total loss': 0.78721848604354} | train loss {'Reaction outcome loss': 0.8037897085656925, 'Total loss': 0.8037897085656925}
2022-11-18 01:12:18,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:18,859 INFO:     Epoch: 89
2022-11-18 01:12:19,644 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7883147861469876, 'Total loss': 0.7883147861469876} | train loss {'Reaction outcome loss': 0.7999645904618866, 'Total loss': 0.7999645904618866}
2022-11-18 01:12:19,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:19,644 INFO:     Epoch: 90
2022-11-18 01:12:20,415 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.819778794592077, 'Total loss': 0.819778794592077} | train loss {'Reaction outcome loss': 0.8033218460423606, 'Total loss': 0.8033218460423606}
2022-11-18 01:12:20,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:20,415 INFO:     Epoch: 91
2022-11-18 01:12:21,214 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.820590464906259, 'Total loss': 0.820590464906259} | train loss {'Reaction outcome loss': 0.7970088525694243, 'Total loss': 0.7970088525694243}
2022-11-18 01:12:21,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:21,215 INFO:     Epoch: 92
2022-11-18 01:12:21,991 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.798559844493866, 'Total loss': 0.798559844493866} | train loss {'Reaction outcome loss': 0.7988244787770875, 'Total loss': 0.7988244787770875}
2022-11-18 01:12:21,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:21,992 INFO:     Epoch: 93
2022-11-18 01:12:22,738 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8037514131177556, 'Total loss': 0.8037514131177556} | train loss {'Reaction outcome loss': 0.803296921691116, 'Total loss': 0.803296921691116}
2022-11-18 01:12:22,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:22,739 INFO:     Epoch: 94
2022-11-18 01:12:23,478 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.80412688174031, 'Total loss': 0.80412688174031} | train loss {'Reaction outcome loss': 0.8036001290593828, 'Total loss': 0.8036001290593828}
2022-11-18 01:12:23,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:23,478 INFO:     Epoch: 95
2022-11-18 01:12:24,256 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7924231317910281, 'Total loss': 0.7924231317910281} | train loss {'Reaction outcome loss': 0.7953002374999377, 'Total loss': 0.7953002374999377}
2022-11-18 01:12:24,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:24,258 INFO:     Epoch: 96
2022-11-18 01:12:25,018 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.805884334851395, 'Total loss': 0.805884334851395} | train loss {'Reaction outcome loss': 0.7971998169714091, 'Total loss': 0.7971998169714091}
2022-11-18 01:12:25,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:25,018 INFO:     Epoch: 97
2022-11-18 01:12:25,805 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8103544840758498, 'Total loss': 0.8103544840758498} | train loss {'Reaction outcome loss': 0.7971258620826566, 'Total loss': 0.7971258620826566}
2022-11-18 01:12:25,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:25,805 INFO:     Epoch: 98
2022-11-18 01:12:26,579 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8154338530518792, 'Total loss': 0.8154338530518792} | train loss {'Reaction outcome loss': 0.7993869940845334, 'Total loss': 0.7993869940845334}
2022-11-18 01:12:26,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:26,579 INFO:     Epoch: 99
2022-11-18 01:12:27,373 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7886806455525485, 'Total loss': 0.7886806455525485} | train loss {'Reaction outcome loss': 0.796373682605977, 'Total loss': 0.796373682605977}
2022-11-18 01:12:27,373 INFO:     Best model found after epoch 80 of 100.
2022-11-18 01:12:27,373 INFO:   Done with stage: TRAINING
2022-11-18 01:12:27,373 INFO:   Starting stage: EVALUATION
2022-11-18 01:12:27,502 INFO:   Done with stage: EVALUATION
2022-11-18 01:12:27,502 INFO:   Leaving out SEQ value Fold_4
2022-11-18 01:12:27,515 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:12:27,515 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:12:28,183 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:12:28,183 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:12:28,254 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:12:28,254 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:12:28,254 INFO:     No hyperparam tuning for this model
2022-11-18 01:12:28,254 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:12:28,254 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:12:28,255 INFO:     None feature selector for col prot
2022-11-18 01:12:28,255 INFO:     None feature selector for col prot
2022-11-18 01:12:28,255 INFO:     None feature selector for col prot
2022-11-18 01:12:28,256 INFO:     None feature selector for col chem
2022-11-18 01:12:28,256 INFO:     None feature selector for col chem
2022-11-18 01:12:28,256 INFO:     None feature selector for col chem
2022-11-18 01:12:28,256 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:12:28,256 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:12:28,257 INFO:     Number of params in model 168571
2022-11-18 01:12:28,261 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:12:28,261 INFO:   Starting stage: TRAINING
2022-11-18 01:12:28,318 INFO:     Val loss before train {'Reaction outcome loss': 0.9765488613735546, 'Total loss': 0.9765488613735546}
2022-11-18 01:12:28,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:28,318 INFO:     Epoch: 0
2022-11-18 01:12:29,107 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8704394847154617, 'Total loss': 0.8704394847154617} | train loss {'Reaction outcome loss': 0.8877840045733973, 'Total loss': 0.8877840045733973}
2022-11-18 01:12:29,107 INFO:     Found new best model at epoch 0
2022-11-18 01:12:29,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:29,108 INFO:     Epoch: 1
2022-11-18 01:12:29,895 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8266343040899797, 'Total loss': 0.8266343040899797} | train loss {'Reaction outcome loss': 0.861893518612935, 'Total loss': 0.861893518612935}
2022-11-18 01:12:29,895 INFO:     Found new best model at epoch 1
2022-11-18 01:12:29,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:29,896 INFO:     Epoch: 2
2022-11-18 01:12:30,674 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8427362076260827, 'Total loss': 0.8427362076260827} | train loss {'Reaction outcome loss': 0.8490711906660906, 'Total loss': 0.8490711906660906}
2022-11-18 01:12:30,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:30,675 INFO:     Epoch: 3
2022-11-18 01:12:31,458 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8324316577477888, 'Total loss': 0.8324316577477888} | train loss {'Reaction outcome loss': 0.8472558622840445, 'Total loss': 0.8472558622840445}
2022-11-18 01:12:31,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:31,458 INFO:     Epoch: 4
2022-11-18 01:12:32,240 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8127613453702494, 'Total loss': 0.8127613453702494} | train loss {'Reaction outcome loss': 0.8404016036253709, 'Total loss': 0.8404016036253709}
2022-11-18 01:12:32,240 INFO:     Found new best model at epoch 4
2022-11-18 01:12:32,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:32,241 INFO:     Epoch: 5
2022-11-18 01:12:33,024 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.825807817957618, 'Total loss': 0.825807817957618} | train loss {'Reaction outcome loss': 0.8456531263556075, 'Total loss': 0.8456531263556075}
2022-11-18 01:12:33,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:33,024 INFO:     Epoch: 6
2022-11-18 01:12:33,797 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8198492323810403, 'Total loss': 0.8198492323810403} | train loss {'Reaction outcome loss': 0.84227693768648, 'Total loss': 0.84227693768648}
2022-11-18 01:12:33,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:33,797 INFO:     Epoch: 7
2022-11-18 01:12:34,551 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8068398955193433, 'Total loss': 0.8068398955193433} | train loss {'Reaction outcome loss': 0.8319615789270594, 'Total loss': 0.8319615789270594}
2022-11-18 01:12:34,551 INFO:     Found new best model at epoch 7
2022-11-18 01:12:34,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:34,552 INFO:     Epoch: 8
2022-11-18 01:12:35,305 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8089216913689267, 'Total loss': 0.8089216913689267} | train loss {'Reaction outcome loss': 0.8340636898390195, 'Total loss': 0.8340636898390195}
2022-11-18 01:12:35,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:35,305 INFO:     Epoch: 9
2022-11-18 01:12:36,090 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8117632953958078, 'Total loss': 0.8117632953958078} | train loss {'Reaction outcome loss': 0.8280467222094053, 'Total loss': 0.8280467222094053}
2022-11-18 01:12:36,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:36,090 INFO:     Epoch: 10
2022-11-18 01:12:36,898 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8099669143557549, 'Total loss': 0.8099669143557549} | train loss {'Reaction outcome loss': 0.8265651657513762, 'Total loss': 0.8265651657513762}
2022-11-18 01:12:36,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:36,898 INFO:     Epoch: 11
2022-11-18 01:12:37,662 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8025647124106233, 'Total loss': 0.8025647124106233} | train loss {'Reaction outcome loss': 0.8190701337840393, 'Total loss': 0.8190701337840393}
2022-11-18 01:12:37,663 INFO:     Found new best model at epoch 11
2022-11-18 01:12:37,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:37,663 INFO:     Epoch: 12
2022-11-18 01:12:38,431 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8076439872384071, 'Total loss': 0.8076439872384071} | train loss {'Reaction outcome loss': 0.8226867370035967, 'Total loss': 0.8226867370035967}
2022-11-18 01:12:38,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:38,432 INFO:     Epoch: 13
2022-11-18 01:12:39,213 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8127245808189566, 'Total loss': 0.8127245808189566} | train loss {'Reaction outcome loss': 0.8242967805640418, 'Total loss': 0.8242967805640418}
2022-11-18 01:12:39,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:39,214 INFO:     Epoch: 14
2022-11-18 01:12:39,995 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8159096335822885, 'Total loss': 0.8159096335822885} | train loss {'Reaction outcome loss': 0.8288895822005716, 'Total loss': 0.8288895822005716}
2022-11-18 01:12:39,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:39,996 INFO:     Epoch: 15
2022-11-18 01:12:40,778 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8247690410776571, 'Total loss': 0.8247690410776571} | train loss {'Reaction outcome loss': 0.832355759525106, 'Total loss': 0.832355759525106}
2022-11-18 01:12:40,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:40,778 INFO:     Epoch: 16
2022-11-18 01:12:41,548 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8123569901693951, 'Total loss': 0.8123569901693951} | train loss {'Reaction outcome loss': 0.8286977207612413, 'Total loss': 0.8286977207612413}
2022-11-18 01:12:41,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:41,548 INFO:     Epoch: 17
2022-11-18 01:12:42,360 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8131692138585177, 'Total loss': 0.8131692138585177} | train loss {'Reaction outcome loss': 0.8205253768425721, 'Total loss': 0.8205253768425721}
2022-11-18 01:12:42,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:42,361 INFO:     Epoch: 18
2022-11-18 01:12:43,117 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8102468360554088, 'Total loss': 0.8102468360554088} | train loss {'Reaction outcome loss': 0.8226259698269338, 'Total loss': 0.8226259698269338}
2022-11-18 01:12:43,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:43,118 INFO:     Epoch: 19
2022-11-18 01:12:43,898 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7972665219144388, 'Total loss': 0.7972665219144388} | train loss {'Reaction outcome loss': 0.8208585556460778, 'Total loss': 0.8208585556460778}
2022-11-18 01:12:43,898 INFO:     Found new best model at epoch 19
2022-11-18 01:12:43,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:43,899 INFO:     Epoch: 20
2022-11-18 01:12:44,670 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8301247202537276, 'Total loss': 0.8301247202537276} | train loss {'Reaction outcome loss': 0.8252060969590176, 'Total loss': 0.8252060969590176}
2022-11-18 01:12:44,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:44,671 INFO:     Epoch: 21
2022-11-18 01:12:45,467 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7994229983199727, 'Total loss': 0.7994229983199727} | train loss {'Reaction outcome loss': 0.8229398474036923, 'Total loss': 0.8229398474036923}
2022-11-18 01:12:45,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:45,467 INFO:     Epoch: 22
2022-11-18 01:12:46,222 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8157558014447038, 'Total loss': 0.8157558014447038} | train loss {'Reaction outcome loss': 0.8233083101660617, 'Total loss': 0.8233083101660617}
2022-11-18 01:12:46,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:46,223 INFO:     Epoch: 23
2022-11-18 01:12:46,984 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7930390570651401, 'Total loss': 0.7930390570651401} | train loss {'Reaction outcome loss': 0.820187903669199, 'Total loss': 0.820187903669199}
2022-11-18 01:12:46,985 INFO:     Found new best model at epoch 23
2022-11-18 01:12:46,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:46,986 INFO:     Epoch: 24
2022-11-18 01:12:47,768 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8008043203841556, 'Total loss': 0.8008043203841556} | train loss {'Reaction outcome loss': 0.8221147974975679, 'Total loss': 0.8221147974975679}
2022-11-18 01:12:47,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:47,768 INFO:     Epoch: 25
2022-11-18 01:12:48,559 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8053126037120819, 'Total loss': 0.8053126037120819} | train loss {'Reaction outcome loss': 0.8244440039159798, 'Total loss': 0.8244440039159798}
2022-11-18 01:12:48,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:48,559 INFO:     Epoch: 26
2022-11-18 01:12:49,344 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.803709706122225, 'Total loss': 0.803709706122225} | train loss {'Reaction outcome loss': 0.8232627736050108, 'Total loss': 0.8232627736050108}
2022-11-18 01:12:49,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:49,344 INFO:     Epoch: 27
2022-11-18 01:12:50,120 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8150281364267523, 'Total loss': 0.8150281364267523} | train loss {'Reaction outcome loss': 0.8190606611399998, 'Total loss': 0.8190606611399998}
2022-11-18 01:12:50,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:50,120 INFO:     Epoch: 28
2022-11-18 01:12:50,883 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8137928890911016, 'Total loss': 0.8137928890911016} | train loss {'Reaction outcome loss': 0.8195836753980351, 'Total loss': 0.8195836753980351}
2022-11-18 01:12:50,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:50,883 INFO:     Epoch: 29
2022-11-18 01:12:51,646 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8162640407681465, 'Total loss': 0.8162640407681465} | train loss {'Reaction outcome loss': 0.8271903392033055, 'Total loss': 0.8271903392033055}
2022-11-18 01:12:51,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:51,647 INFO:     Epoch: 30
2022-11-18 01:12:52,422 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8093108622865244, 'Total loss': 0.8093108622865244} | train loss {'Reaction outcome loss': 0.8360683691163777, 'Total loss': 0.8360683691163777}
2022-11-18 01:12:52,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:52,422 INFO:     Epoch: 31
2022-11-18 01:12:53,258 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7928531224077399, 'Total loss': 0.7928531224077399} | train loss {'Reaction outcome loss': 0.8298018639869535, 'Total loss': 0.8298018639869535}
2022-11-18 01:12:53,258 INFO:     Found new best model at epoch 31
2022-11-18 01:12:53,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:53,259 INFO:     Epoch: 32
2022-11-18 01:12:54,036 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8161831362680956, 'Total loss': 0.8161831362680956} | train loss {'Reaction outcome loss': 0.8253801827006012, 'Total loss': 0.8253801827006012}
2022-11-18 01:12:54,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:54,036 INFO:     Epoch: 33
2022-11-18 01:12:54,844 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8024144497784701, 'Total loss': 0.8024144497784701} | train loss {'Reaction outcome loss': 0.8216526449209283, 'Total loss': 0.8216526449209283}
2022-11-18 01:12:54,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:54,844 INFO:     Epoch: 34
2022-11-18 01:12:55,637 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8102023073218085, 'Total loss': 0.8102023073218085} | train loss {'Reaction outcome loss': 0.8201355313965184, 'Total loss': 0.8201355313965184}
2022-11-18 01:12:55,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:55,639 INFO:     Epoch: 35
2022-11-18 01:12:56,445 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7984562983567064, 'Total loss': 0.7984562983567064} | train loss {'Reaction outcome loss': 0.8254202348500611, 'Total loss': 0.8254202348500611}
2022-11-18 01:12:56,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:56,446 INFO:     Epoch: 36
2022-11-18 01:12:57,276 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7900770293040709, 'Total loss': 0.7900770293040709} | train loss {'Reaction outcome loss': 0.8260722489733445, 'Total loss': 0.8260722489733445}
2022-11-18 01:12:57,276 INFO:     Found new best model at epoch 36
2022-11-18 01:12:57,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:57,277 INFO:     Epoch: 37
2022-11-18 01:12:58,085 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8055861267176542, 'Total loss': 0.8055861267176542} | train loss {'Reaction outcome loss': 0.822218846816283, 'Total loss': 0.822218846816283}
2022-11-18 01:12:58,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:58,086 INFO:     Epoch: 38
2022-11-18 01:12:58,914 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7918021692471071, 'Total loss': 0.7918021692471071} | train loss {'Reaction outcome loss': 0.8296059098562248, 'Total loss': 0.8296059098562248}
2022-11-18 01:12:58,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:58,915 INFO:     Epoch: 39
2022-11-18 01:12:59,710 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.790428486737338, 'Total loss': 0.790428486737338} | train loss {'Reaction outcome loss': 0.8237387103590406, 'Total loss': 0.8237387103590406}
2022-11-18 01:12:59,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:12:59,710 INFO:     Epoch: 40
2022-11-18 01:13:00,554 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.798674887554212, 'Total loss': 0.798674887554212} | train loss {'Reaction outcome loss': 0.827396074407979, 'Total loss': 0.827396074407979}
2022-11-18 01:13:00,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:00,554 INFO:     Epoch: 41
2022-11-18 01:13:01,366 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7973972755399618, 'Total loss': 0.7973972755399618} | train loss {'Reaction outcome loss': 0.81887506014905, 'Total loss': 0.81887506014905}
2022-11-18 01:13:01,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:01,366 INFO:     Epoch: 42
2022-11-18 01:13:02,152 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8286140500144525, 'Total loss': 0.8286140500144525} | train loss {'Reaction outcome loss': 0.8216350166662502, 'Total loss': 0.8216350166662502}
2022-11-18 01:13:02,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:02,153 INFO:     Epoch: 43
2022-11-18 01:13:02,993 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8070645494894548, 'Total loss': 0.8070645494894548} | train loss {'Reaction outcome loss': 0.8164631770584385, 'Total loss': 0.8164631770584385}
2022-11-18 01:13:02,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:02,993 INFO:     Epoch: 44
2022-11-18 01:13:03,800 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8090049570257013, 'Total loss': 0.8090049570257013} | train loss {'Reaction outcome loss': 0.8295774704772934, 'Total loss': 0.8295774704772934}
2022-11-18 01:13:03,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:03,800 INFO:     Epoch: 45
2022-11-18 01:13:04,632 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8162880526347593, 'Total loss': 0.8162880526347593} | train loss {'Reaction outcome loss': 0.8182355930448061, 'Total loss': 0.8182355930448061}
2022-11-18 01:13:04,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:04,632 INFO:     Epoch: 46
2022-11-18 01:13:05,429 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8075650002468716, 'Total loss': 0.8075650002468716} | train loss {'Reaction outcome loss': 0.8160418685872545, 'Total loss': 0.8160418685872545}
2022-11-18 01:13:05,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:05,429 INFO:     Epoch: 47
2022-11-18 01:13:06,257 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8007781905206767, 'Total loss': 0.8007781905206767} | train loss {'Reaction outcome loss': 0.8231154377402564, 'Total loss': 0.8231154377402564}
2022-11-18 01:13:06,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:06,258 INFO:     Epoch: 48
2022-11-18 01:13:07,053 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8157472556287592, 'Total loss': 0.8157472556287592} | train loss {'Reaction outcome loss': 0.8129744749320181, 'Total loss': 0.8129744749320181}
2022-11-18 01:13:07,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:07,053 INFO:     Epoch: 49
2022-11-18 01:13:07,873 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8140069754286245, 'Total loss': 0.8140069754286245} | train loss {'Reaction outcome loss': 0.8203026929847624, 'Total loss': 0.8203026929847624}
2022-11-18 01:13:07,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:07,873 INFO:     Epoch: 50
2022-11-18 01:13:08,700 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7951095219362866, 'Total loss': 0.7951095219362866} | train loss {'Reaction outcome loss': 0.8193324614874264, 'Total loss': 0.8193324614874264}
2022-11-18 01:13:08,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:08,700 INFO:     Epoch: 51
2022-11-18 01:13:09,518 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8035493940114975, 'Total loss': 0.8035493940114975} | train loss {'Reaction outcome loss': 0.8161804344248675, 'Total loss': 0.8161804344248675}
2022-11-18 01:13:09,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:09,518 INFO:     Epoch: 52
2022-11-18 01:13:10,310 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7936030782081864, 'Total loss': 0.7936030782081864} | train loss {'Reaction outcome loss': 0.8189210582841263, 'Total loss': 0.8189210582841263}
2022-11-18 01:13:10,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:10,310 INFO:     Epoch: 53
2022-11-18 01:13:11,100 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7876786670901559, 'Total loss': 0.7876786670901559} | train loss {'Reaction outcome loss': 0.8204551777285845, 'Total loss': 0.8204551777285845}
2022-11-18 01:13:11,100 INFO:     Found new best model at epoch 53
2022-11-18 01:13:11,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:11,101 INFO:     Epoch: 54
2022-11-18 01:13:11,906 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8002466708421707, 'Total loss': 0.8002466708421707} | train loss {'Reaction outcome loss': 0.8196528529831273, 'Total loss': 0.8196528529831273}
2022-11-18 01:13:11,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:11,906 INFO:     Epoch: 55
2022-11-18 01:13:12,710 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8083716928958893, 'Total loss': 0.8083716928958893} | train loss {'Reaction outcome loss': 0.8291513331023305, 'Total loss': 0.8291513331023305}
2022-11-18 01:13:12,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:12,710 INFO:     Epoch: 56
2022-11-18 01:13:13,462 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8272121927954934, 'Total loss': 0.8272121927954934} | train loss {'Reaction outcome loss': 0.8206674757032741, 'Total loss': 0.8206674757032741}
2022-11-18 01:13:13,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:13,463 INFO:     Epoch: 57
2022-11-18 01:13:14,285 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8283207592639056, 'Total loss': 0.8283207592639056} | train loss {'Reaction outcome loss': 0.8411354533573876, 'Total loss': 0.8411354533573876}
2022-11-18 01:13:14,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:14,286 INFO:     Epoch: 58
2022-11-18 01:13:15,110 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.789268973198804, 'Total loss': 0.789268973198804} | train loss {'Reaction outcome loss': 0.8259416092262577, 'Total loss': 0.8259416092262577}
2022-11-18 01:13:15,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:15,111 INFO:     Epoch: 59
2022-11-18 01:13:15,901 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.791666679084301, 'Total loss': 0.791666679084301} | train loss {'Reaction outcome loss': 0.8178600303315924, 'Total loss': 0.8178600303315924}
2022-11-18 01:13:15,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:15,902 INFO:     Epoch: 60
2022-11-18 01:13:16,729 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8304347721013156, 'Total loss': 0.8304347721013156} | train loss {'Reaction outcome loss': 0.8219650846261245, 'Total loss': 0.8219650846261245}
2022-11-18 01:13:16,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:16,729 INFO:     Epoch: 61
2022-11-18 01:13:17,526 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7986527816815809, 'Total loss': 0.7986527816815809} | train loss {'Reaction outcome loss': 0.8222190048771831, 'Total loss': 0.8222190048771831}
2022-11-18 01:13:17,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:17,526 INFO:     Epoch: 62
2022-11-18 01:13:18,338 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7805690230293707, 'Total loss': 0.7805690230293707} | train loss {'Reaction outcome loss': 0.821470285234181, 'Total loss': 0.821470285234181}
2022-11-18 01:13:18,338 INFO:     Found new best model at epoch 62
2022-11-18 01:13:18,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:18,339 INFO:     Epoch: 63
2022-11-18 01:13:19,143 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7927363982254808, 'Total loss': 0.7927363982254808} | train loss {'Reaction outcome loss': 0.8202849278143542, 'Total loss': 0.8202849278143542}
2022-11-18 01:13:19,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:19,143 INFO:     Epoch: 64
2022-11-18 01:13:19,976 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8037740012461488, 'Total loss': 0.8037740012461488} | train loss {'Reaction outcome loss': 0.8162721126954927, 'Total loss': 0.8162721126954927}
2022-11-18 01:13:19,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:19,976 INFO:     Epoch: 65
2022-11-18 01:13:20,779 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7884723930196329, 'Total loss': 0.7884723930196329} | train loss {'Reaction outcome loss': 0.8204161589927519, 'Total loss': 0.8204161589927519}
2022-11-18 01:13:20,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:20,779 INFO:     Epoch: 66
2022-11-18 01:13:21,577 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8093099776994098, 'Total loss': 0.8093099776994098} | train loss {'Reaction outcome loss': 0.8204757046361684, 'Total loss': 0.8204757046361684}
2022-11-18 01:13:21,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:21,577 INFO:     Epoch: 67
2022-11-18 01:13:22,369 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7914912091060118, 'Total loss': 0.7914912091060118} | train loss {'Reaction outcome loss': 0.8224722745447506, 'Total loss': 0.8224722745447506}
2022-11-18 01:13:22,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:22,369 INFO:     Epoch: 68
2022-11-18 01:13:23,169 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7955517613074996, 'Total loss': 0.7955517613074996} | train loss {'Reaction outcome loss': 0.8156104915537815, 'Total loss': 0.8156104915537815}
2022-11-18 01:13:23,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:23,169 INFO:     Epoch: 69
2022-11-18 01:13:23,976 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8029180710965936, 'Total loss': 0.8029180710965936} | train loss {'Reaction outcome loss': 0.820762093853854, 'Total loss': 0.820762093853854}
2022-11-18 01:13:23,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:23,977 INFO:     Epoch: 70
2022-11-18 01:13:24,830 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8003429844975471, 'Total loss': 0.8003429844975471} | train loss {'Reaction outcome loss': 0.823529891760243, 'Total loss': 0.823529891760243}
2022-11-18 01:13:24,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:24,830 INFO:     Epoch: 71
2022-11-18 01:13:25,622 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8036455092104998, 'Total loss': 0.8036455092104998} | train loss {'Reaction outcome loss': 0.8180092619618906, 'Total loss': 0.8180092619618906}
2022-11-18 01:13:25,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:25,623 INFO:     Epoch: 72
2022-11-18 01:13:26,452 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8067548125982285, 'Total loss': 0.8067548125982285} | train loss {'Reaction outcome loss': 0.8294443081506351, 'Total loss': 0.8294443081506351}
2022-11-18 01:13:26,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:26,453 INFO:     Epoch: 73
2022-11-18 01:13:27,311 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7839435860514641, 'Total loss': 0.7839435860514641} | train loss {'Reaction outcome loss': 0.8230525868141699, 'Total loss': 0.8230525868141699}
2022-11-18 01:13:27,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:27,312 INFO:     Epoch: 74
2022-11-18 01:13:28,120 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7896370501680807, 'Total loss': 0.7896370501680807} | train loss {'Reaction outcome loss': 0.817216188077502, 'Total loss': 0.817216188077502}
2022-11-18 01:13:28,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:28,120 INFO:     Epoch: 75
2022-11-18 01:13:28,922 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8113099072467197, 'Total loss': 0.8113099072467197} | train loss {'Reaction outcome loss': 0.8152524098934915, 'Total loss': 0.8152524098934915}
2022-11-18 01:13:28,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:28,922 INFO:     Epoch: 76
2022-11-18 01:13:29,782 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7967047664252195, 'Total loss': 0.7967047664252195} | train loss {'Reaction outcome loss': 0.8149288219478932, 'Total loss': 0.8149288219478932}
2022-11-18 01:13:29,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:29,782 INFO:     Epoch: 77
2022-11-18 01:13:30,617 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7761064849116586, 'Total loss': 0.7761064849116586} | train loss {'Reaction outcome loss': 0.8182537654633464, 'Total loss': 0.8182537654633464}
2022-11-18 01:13:30,618 INFO:     Found new best model at epoch 77
2022-11-18 01:13:30,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:30,619 INFO:     Epoch: 78
2022-11-18 01:13:31,419 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8275219141082331, 'Total loss': 0.8275219141082331} | train loss {'Reaction outcome loss': 0.8138846958938398, 'Total loss': 0.8138846958938398}
2022-11-18 01:13:31,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:31,419 INFO:     Epoch: 79
2022-11-18 01:13:32,244 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7766254943880168, 'Total loss': 0.7766254943880168} | train loss {'Reaction outcome loss': 0.8220263345521471, 'Total loss': 0.8220263345521471}
2022-11-18 01:13:32,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:32,244 INFO:     Epoch: 80
2022-11-18 01:13:33,050 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7926061471754854, 'Total loss': 0.7926061471754854} | train loss {'Reaction outcome loss': 0.8151192259088702, 'Total loss': 0.8151192259088702}
2022-11-18 01:13:33,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:33,051 INFO:     Epoch: 81
2022-11-18 01:13:33,900 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7994003438136794, 'Total loss': 0.7994003438136794} | train loss {'Reaction outcome loss': 0.8167424515673989, 'Total loss': 0.8167424515673989}
2022-11-18 01:13:33,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:33,900 INFO:     Epoch: 82
2022-11-18 01:13:34,728 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.803866869346662, 'Total loss': 0.803866869346662} | train loss {'Reaction outcome loss': 0.8145152990393311, 'Total loss': 0.8145152990393311}
2022-11-18 01:13:34,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:34,728 INFO:     Epoch: 83
2022-11-18 01:13:35,574 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7977424548430876, 'Total loss': 0.7977424548430876} | train loss {'Reaction outcome loss': 0.8161735701174871, 'Total loss': 0.8161735701174871}
2022-11-18 01:13:35,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:35,574 INFO:     Epoch: 84
2022-11-18 01:13:36,402 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7826552120122042, 'Total loss': 0.7826552120122042} | train loss {'Reaction outcome loss': 0.8144258142482896, 'Total loss': 0.8144258142482896}
2022-11-18 01:13:36,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:36,402 INFO:     Epoch: 85
2022-11-18 01:13:37,238 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7884132130579515, 'Total loss': 0.7884132130579515} | train loss {'Reaction outcome loss': 0.8121161768703085, 'Total loss': 0.8121161768703085}
2022-11-18 01:13:37,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:37,239 INFO:     Epoch: 86
2022-11-18 01:13:38,096 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7839046506719156, 'Total loss': 0.7839046506719156} | train loss {'Reaction outcome loss': 0.8137557772610352, 'Total loss': 0.8137557772610352}
2022-11-18 01:13:38,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:38,096 INFO:     Epoch: 87
2022-11-18 01:13:38,916 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7917343330654231, 'Total loss': 0.7917343330654231} | train loss {'Reaction outcome loss': 0.8172221971668212, 'Total loss': 0.8172221971668212}
2022-11-18 01:13:38,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:38,917 INFO:     Epoch: 88
2022-11-18 01:13:39,684 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7963331524621357, 'Total loss': 0.7963331524621357} | train loss {'Reaction outcome loss': 0.8154492511862685, 'Total loss': 0.8154492511862685}
2022-11-18 01:13:39,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:39,685 INFO:     Epoch: 89
2022-11-18 01:13:40,482 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7992685748772188, 'Total loss': 0.7992685748772188} | train loss {'Reaction outcome loss': 0.8133247163493623, 'Total loss': 0.8133247163493623}
2022-11-18 01:13:40,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:40,483 INFO:     Epoch: 90
2022-11-18 01:13:41,280 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7754104753786867, 'Total loss': 0.7754104753786867} | train loss {'Reaction outcome loss': 0.8195514992663735, 'Total loss': 0.8195514992663735}
2022-11-18 01:13:41,280 INFO:     Found new best model at epoch 90
2022-11-18 01:13:41,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:41,281 INFO:     Epoch: 91
2022-11-18 01:13:42,069 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8095390424132347, 'Total loss': 0.8095390424132347} | train loss {'Reaction outcome loss': 0.815749935534319, 'Total loss': 0.815749935534319}
2022-11-18 01:13:42,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:42,069 INFO:     Epoch: 92
2022-11-18 01:13:42,848 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8103610250082883, 'Total loss': 0.8103610250082883} | train loss {'Reaction outcome loss': 0.8183200809395748, 'Total loss': 0.8183200809395748}
2022-11-18 01:13:42,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:42,848 INFO:     Epoch: 93
2022-11-18 01:13:43,689 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7878667624159292, 'Total loss': 0.7878667624159292} | train loss {'Reaction outcome loss': 0.8177250476501249, 'Total loss': 0.8177250476501249}
2022-11-18 01:13:43,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:43,689 INFO:     Epoch: 94
2022-11-18 01:13:44,491 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.782426921481436, 'Total loss': 0.782426921481436} | train loss {'Reaction outcome loss': 0.819668766578682, 'Total loss': 0.819668766578682}
2022-11-18 01:13:44,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:44,491 INFO:     Epoch: 95
2022-11-18 01:13:45,291 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7923936037854715, 'Total loss': 0.7923936037854715} | train loss {'Reaction outcome loss': 0.8132595924834009, 'Total loss': 0.8132595924834009}
2022-11-18 01:13:45,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:45,292 INFO:     Epoch: 96
2022-11-18 01:13:46,123 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.800142569298094, 'Total loss': 0.800142569298094} | train loss {'Reaction outcome loss': 0.8104129093378661, 'Total loss': 0.8104129093378661}
2022-11-18 01:13:46,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:46,123 INFO:     Epoch: 97
2022-11-18 01:13:46,913 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8080937760797414, 'Total loss': 0.8080937760797414} | train loss {'Reaction outcome loss': 0.812951019901013, 'Total loss': 0.812951019901013}
2022-11-18 01:13:46,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:46,913 INFO:     Epoch: 98
2022-11-18 01:13:47,700 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7824428528547287, 'Total loss': 0.7824428528547287} | train loss {'Reaction outcome loss': 0.816193794673271, 'Total loss': 0.816193794673271}
2022-11-18 01:13:47,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:47,700 INFO:     Epoch: 99
2022-11-18 01:13:48,483 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.795049025253816, 'Total loss': 0.795049025253816} | train loss {'Reaction outcome loss': 0.8146647690278799, 'Total loss': 0.8146647690278799}
2022-11-18 01:13:48,483 INFO:     Best model found after epoch 91 of 100.
2022-11-18 01:13:48,483 INFO:   Done with stage: TRAINING
2022-11-18 01:13:48,483 INFO:   Starting stage: EVALUATION
2022-11-18 01:13:48,608 INFO:   Done with stage: EVALUATION
2022-11-18 01:13:48,608 INFO:   Leaving out SEQ value Fold_5
2022-11-18 01:13:48,621 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:13:48,622 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:13:49,294 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:13:49,294 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:13:49,365 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:13:49,365 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:13:49,365 INFO:     No hyperparam tuning for this model
2022-11-18 01:13:49,365 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:13:49,365 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:13:49,366 INFO:     None feature selector for col prot
2022-11-18 01:13:49,366 INFO:     None feature selector for col prot
2022-11-18 01:13:49,366 INFO:     None feature selector for col prot
2022-11-18 01:13:49,367 INFO:     None feature selector for col chem
2022-11-18 01:13:49,367 INFO:     None feature selector for col chem
2022-11-18 01:13:49,367 INFO:     None feature selector for col chem
2022-11-18 01:13:49,367 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:13:49,367 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:13:49,369 INFO:     Number of params in model 168571
2022-11-18 01:13:49,372 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:13:49,372 INFO:   Starting stage: TRAINING
2022-11-18 01:13:49,431 INFO:     Val loss before train {'Reaction outcome loss': 0.9778643175959587, 'Total loss': 0.9778643175959587}
2022-11-18 01:13:49,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:49,431 INFO:     Epoch: 0
2022-11-18 01:13:50,249 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8562763306227598, 'Total loss': 0.8562763306227598} | train loss {'Reaction outcome loss': 0.8806839894142843, 'Total loss': 0.8806839894142843}
2022-11-18 01:13:50,249 INFO:     Found new best model at epoch 0
2022-11-18 01:13:50,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:50,250 INFO:     Epoch: 1
2022-11-18 01:13:51,060 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8545514101331885, 'Total loss': 0.8545514101331885} | train loss {'Reaction outcome loss': 0.8547657517896544, 'Total loss': 0.8547657517896544}
2022-11-18 01:13:51,060 INFO:     Found new best model at epoch 1
2022-11-18 01:13:51,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:51,061 INFO:     Epoch: 2
2022-11-18 01:13:51,831 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8315522149205208, 'Total loss': 0.8315522149205208} | train loss {'Reaction outcome loss': 0.8436614510513121, 'Total loss': 0.8436614510513121}
2022-11-18 01:13:51,831 INFO:     Found new best model at epoch 2
2022-11-18 01:13:51,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:51,832 INFO:     Epoch: 3
2022-11-18 01:13:52,673 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8327050669626757, 'Total loss': 0.8327050669626757} | train loss {'Reaction outcome loss': 0.8448786460343869, 'Total loss': 0.8448786460343869}
2022-11-18 01:13:52,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:52,673 INFO:     Epoch: 4
2022-11-18 01:13:53,517 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.827282919802449, 'Total loss': 0.827282919802449} | train loss {'Reaction outcome loss': 0.8388926758160514, 'Total loss': 0.8388926758160514}
2022-11-18 01:13:53,517 INFO:     Found new best model at epoch 4
2022-11-18 01:13:53,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:53,518 INFO:     Epoch: 5
2022-11-18 01:13:54,410 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8311365307732062, 'Total loss': 0.8311365307732062} | train loss {'Reaction outcome loss': 0.8290477075403736, 'Total loss': 0.8290477075403736}
2022-11-18 01:13:54,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:54,410 INFO:     Epoch: 6
2022-11-18 01:13:55,187 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.835707581856034, 'Total loss': 0.835707581856034} | train loss {'Reaction outcome loss': 0.8279261143217164, 'Total loss': 0.8279261143217164}
2022-11-18 01:13:55,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:55,187 INFO:     Epoch: 7
2022-11-18 01:13:56,015 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8222427171739665, 'Total loss': 0.8222427171739665} | train loss {'Reaction outcome loss': 0.8273580928723658, 'Total loss': 0.8273580928723658}
2022-11-18 01:13:56,015 INFO:     Found new best model at epoch 7
2022-11-18 01:13:56,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:56,016 INFO:     Epoch: 8
2022-11-18 01:13:56,800 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8388668610291048, 'Total loss': 0.8388668610291048} | train loss {'Reaction outcome loss': 0.8233264316354068, 'Total loss': 0.8233264316354068}
2022-11-18 01:13:56,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:56,800 INFO:     Epoch: 9
2022-11-18 01:13:57,599 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8240015019070018, 'Total loss': 0.8240015019070018} | train loss {'Reaction outcome loss': 0.8302425767385191, 'Total loss': 0.8302425767385191}
2022-11-18 01:13:57,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:57,600 INFO:     Epoch: 10
2022-11-18 01:13:58,435 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8360177786512808, 'Total loss': 0.8360177786512808} | train loss {'Reaction outcome loss': 0.8203424479692213, 'Total loss': 0.8203424479692213}
2022-11-18 01:13:58,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:58,436 INFO:     Epoch: 11
2022-11-18 01:13:59,216 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8392290093682029, 'Total loss': 0.8392290093682029} | train loss {'Reaction outcome loss': 0.826265882941023, 'Total loss': 0.826265882941023}
2022-11-18 01:13:59,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:13:59,216 INFO:     Epoch: 12
2022-11-18 01:14:00,042 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8341963643377478, 'Total loss': 0.8341963643377478} | train loss {'Reaction outcome loss': 0.8247346298829201, 'Total loss': 0.8247346298829201}
2022-11-18 01:14:00,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:00,043 INFO:     Epoch: 13
2022-11-18 01:14:00,850 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8217836875807155, 'Total loss': 0.8217836875807155} | train loss {'Reaction outcome loss': 0.8184683250804101, 'Total loss': 0.8184683250804101}
2022-11-18 01:14:00,850 INFO:     Found new best model at epoch 13
2022-11-18 01:14:00,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:00,851 INFO:     Epoch: 14
2022-11-18 01:14:01,647 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8159383955326948, 'Total loss': 0.8159383955326948} | train loss {'Reaction outcome loss': 0.8191997316335479, 'Total loss': 0.8191997316335479}
2022-11-18 01:14:01,647 INFO:     Found new best model at epoch 14
2022-11-18 01:14:01,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:01,648 INFO:     Epoch: 15
2022-11-18 01:14:02,521 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8412312817844477, 'Total loss': 0.8412312817844477} | train loss {'Reaction outcome loss': 0.8206326174399545, 'Total loss': 0.8206326174399545}
2022-11-18 01:14:02,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:02,521 INFO:     Epoch: 16
2022-11-18 01:14:03,317 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8254464566707611, 'Total loss': 0.8254464566707611} | train loss {'Reaction outcome loss': 0.8172232160164464, 'Total loss': 0.8172232160164464}
2022-11-18 01:14:03,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:03,317 INFO:     Epoch: 17
2022-11-18 01:14:04,085 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8288687799464572, 'Total loss': 0.8288687799464572} | train loss {'Reaction outcome loss': 0.824041148106898, 'Total loss': 0.824041148106898}
2022-11-18 01:14:04,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:04,086 INFO:     Epoch: 18
2022-11-18 01:14:04,854 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8100257800384001, 'Total loss': 0.8100257800384001} | train loss {'Reaction outcome loss': 0.8188384058735063, 'Total loss': 0.8188384058735063}
2022-11-18 01:14:04,855 INFO:     Found new best model at epoch 18
2022-11-18 01:14:04,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:04,856 INFO:     Epoch: 19
2022-11-18 01:14:05,688 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8218619925054637, 'Total loss': 0.8218619925054637} | train loss {'Reaction outcome loss': 0.81907007110215, 'Total loss': 0.81907007110215}
2022-11-18 01:14:05,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:05,688 INFO:     Epoch: 20
2022-11-18 01:14:06,499 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8288654705340212, 'Total loss': 0.8288654705340212} | train loss {'Reaction outcome loss': 0.8228553967370141, 'Total loss': 0.8228553967370141}
2022-11-18 01:14:06,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:06,499 INFO:     Epoch: 21
2022-11-18 01:14:07,299 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8156555789438161, 'Total loss': 0.8156555789438161} | train loss {'Reaction outcome loss': 0.8198445209812734, 'Total loss': 0.8198445209812734}
2022-11-18 01:14:07,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:07,299 INFO:     Epoch: 22
2022-11-18 01:14:08,100 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8116618381305174, 'Total loss': 0.8116618381305174} | train loss {'Reaction outcome loss': 0.8185314745191605, 'Total loss': 0.8185314745191605}
2022-11-18 01:14:08,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:08,100 INFO:     Epoch: 23
2022-11-18 01:14:08,951 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8232545453039083, 'Total loss': 0.8232545453039083} | train loss {'Reaction outcome loss': 0.8156311945809472, 'Total loss': 0.8156311945809472}
2022-11-18 01:14:08,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:08,951 INFO:     Epoch: 24
2022-11-18 01:14:09,767 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8349994326179678, 'Total loss': 0.8349994326179678} | train loss {'Reaction outcome loss': 0.8153469528882734, 'Total loss': 0.8153469528882734}
2022-11-18 01:14:09,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:09,767 INFO:     Epoch: 25
2022-11-18 01:14:10,571 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8266926157203588, 'Total loss': 0.8266926157203588} | train loss {'Reaction outcome loss': 0.8173334574507128, 'Total loss': 0.8173334574507128}
2022-11-18 01:14:10,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:10,571 INFO:     Epoch: 26
2022-11-18 01:14:11,397 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8201833245429125, 'Total loss': 0.8201833245429125} | train loss {'Reaction outcome loss': 0.8179892428940342, 'Total loss': 0.8179892428940342}
2022-11-18 01:14:11,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:11,397 INFO:     Epoch: 27
2022-11-18 01:14:12,175 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.823919106613506, 'Total loss': 0.823919106613506} | train loss {'Reaction outcome loss': 0.81787119469335, 'Total loss': 0.81787119469335}
2022-11-18 01:14:12,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:12,175 INFO:     Epoch: 28
2022-11-18 01:14:13,004 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.822275997562842, 'Total loss': 0.822275997562842} | train loss {'Reaction outcome loss': 0.821500371660917, 'Total loss': 0.821500371660917}
2022-11-18 01:14:13,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:13,004 INFO:     Epoch: 29
2022-11-18 01:14:13,814 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8263463946906003, 'Total loss': 0.8263463946906003} | train loss {'Reaction outcome loss': 0.8168416168660887, 'Total loss': 0.8168416168660887}
2022-11-18 01:14:13,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:13,814 INFO:     Epoch: 30
2022-11-18 01:14:14,661 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8285232281143015, 'Total loss': 0.8285232281143015} | train loss {'Reaction outcome loss': 0.8182640781085337, 'Total loss': 0.8182640781085337}
2022-11-18 01:14:14,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:14,662 INFO:     Epoch: 31
2022-11-18 01:14:15,482 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8225490416992794, 'Total loss': 0.8225490416992794} | train loss {'Reaction outcome loss': 0.816677030476351, 'Total loss': 0.816677030476351}
2022-11-18 01:14:15,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:15,482 INFO:     Epoch: 32
2022-11-18 01:14:16,306 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8204981190237132, 'Total loss': 0.8204981190237132} | train loss {'Reaction outcome loss': 0.813726992736901, 'Total loss': 0.813726992736901}
2022-11-18 01:14:16,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:16,306 INFO:     Epoch: 33
2022-11-18 01:14:17,100 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8041366501287981, 'Total loss': 0.8041366501287981} | train loss {'Reaction outcome loss': 0.8188332485095147, 'Total loss': 0.8188332485095147}
2022-11-18 01:14:17,101 INFO:     Found new best model at epoch 33
2022-11-18 01:14:17,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:17,102 INFO:     Epoch: 34
2022-11-18 01:14:17,883 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8111080432480032, 'Total loss': 0.8111080432480032} | train loss {'Reaction outcome loss': 0.817878705479445, 'Total loss': 0.817878705479445}
2022-11-18 01:14:17,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:17,883 INFO:     Epoch: 35
2022-11-18 01:14:18,670 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8562060730023817, 'Total loss': 0.8562060730023817} | train loss {'Reaction outcome loss': 0.814531379649716, 'Total loss': 0.814531379649716}
2022-11-18 01:14:18,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:18,670 INFO:     Epoch: 36
2022-11-18 01:14:19,453 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8249971907247197, 'Total loss': 0.8249971907247197} | train loss {'Reaction outcome loss': 0.8152532754165511, 'Total loss': 0.8152532754165511}
2022-11-18 01:14:19,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:19,453 INFO:     Epoch: 37
2022-11-18 01:14:20,248 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8063122528520498, 'Total loss': 0.8063122528520498} | train loss {'Reaction outcome loss': 0.8197635388182055, 'Total loss': 0.8197635388182055}
2022-11-18 01:14:20,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:20,249 INFO:     Epoch: 38
2022-11-18 01:14:21,095 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.839054365049709, 'Total loss': 0.839054365049709} | train loss {'Reaction outcome loss': 0.8134416628989481, 'Total loss': 0.8134416628989481}
2022-11-18 01:14:21,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:21,096 INFO:     Epoch: 39
2022-11-18 01:14:21,875 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8284441015937112, 'Total loss': 0.8284441015937112} | train loss {'Reaction outcome loss': 0.8171602417865107, 'Total loss': 0.8171602417865107}
2022-11-18 01:14:21,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:21,876 INFO:     Epoch: 40
2022-11-18 01:14:22,700 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8281334645368836, 'Total loss': 0.8281334645368836} | train loss {'Reaction outcome loss': 0.8164384851772939, 'Total loss': 0.8164384851772939}
2022-11-18 01:14:22,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:22,700 INFO:     Epoch: 41
2022-11-18 01:14:23,490 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8099400319836356, 'Total loss': 0.8099400319836356} | train loss {'Reaction outcome loss': 0.816958285147144, 'Total loss': 0.816958285147144}
2022-11-18 01:14:23,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:23,490 INFO:     Epoch: 42
2022-11-18 01:14:24,301 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8278028179298748, 'Total loss': 0.8278028179298748} | train loss {'Reaction outcome loss': 0.8169704241858374, 'Total loss': 0.8169704241858374}
2022-11-18 01:14:24,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:24,301 INFO:     Epoch: 43
2022-11-18 01:14:25,098 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.818582146005197, 'Total loss': 0.818582146005197} | train loss {'Reaction outcome loss': 0.8178475154263358, 'Total loss': 0.8178475154263358}
2022-11-18 01:14:25,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:25,098 INFO:     Epoch: 44
2022-11-18 01:14:25,863 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8196791877800768, 'Total loss': 0.8196791877800768} | train loss {'Reaction outcome loss': 0.8157758302986622, 'Total loss': 0.8157758302986622}
2022-11-18 01:14:25,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:25,864 INFO:     Epoch: 45
2022-11-18 01:14:26,649 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8192216571081768, 'Total loss': 0.8192216571081768} | train loss {'Reaction outcome loss': 0.815960540285995, 'Total loss': 0.815960540285995}
2022-11-18 01:14:26,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:26,649 INFO:     Epoch: 46
2022-11-18 01:14:27,476 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.810791165991263, 'Total loss': 0.810791165991263} | train loss {'Reaction outcome loss': 0.8159628285756034, 'Total loss': 0.8159628285756034}
2022-11-18 01:14:27,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:27,476 INFO:     Epoch: 47
2022-11-18 01:14:28,268 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.822154853831638, 'Total loss': 0.822154853831638} | train loss {'Reaction outcome loss': 0.815708454097471, 'Total loss': 0.815708454097471}
2022-11-18 01:14:28,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:28,268 INFO:     Epoch: 48
2022-11-18 01:14:29,096 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8074693564664234, 'Total loss': 0.8074693564664234} | train loss {'Reaction outcome loss': 0.8157678804089946, 'Total loss': 0.8157678804089946}
2022-11-18 01:14:29,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:29,098 INFO:     Epoch: 49
2022-11-18 01:14:29,915 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8127522753043608, 'Total loss': 0.8127522753043608} | train loss {'Reaction outcome loss': 0.8144546586178965, 'Total loss': 0.8144546586178965}
2022-11-18 01:14:29,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:29,915 INFO:     Epoch: 50
2022-11-18 01:14:30,730 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8221971182660623, 'Total loss': 0.8221971182660623} | train loss {'Reaction outcome loss': 0.8131597290836996, 'Total loss': 0.8131597290836996}
2022-11-18 01:14:30,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:30,730 INFO:     Epoch: 51
2022-11-18 01:14:31,546 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8368313651193272, 'Total loss': 0.8368313651193272} | train loss {'Reaction outcome loss': 0.8165181630080746, 'Total loss': 0.8165181630080746}
2022-11-18 01:14:31,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:31,546 INFO:     Epoch: 52
2022-11-18 01:14:32,311 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8457655351270329, 'Total loss': 0.8457655351270329} | train loss {'Reaction outcome loss': 0.8187651864943966, 'Total loss': 0.8187651864943966}
2022-11-18 01:14:32,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:32,311 INFO:     Epoch: 53
2022-11-18 01:14:33,118 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8095703077587214, 'Total loss': 0.8095703077587214} | train loss {'Reaction outcome loss': 0.8175321919543128, 'Total loss': 0.8175321919543128}
2022-11-18 01:14:33,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:33,118 INFO:     Epoch: 54
2022-11-18 01:14:33,896 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8136543678966436, 'Total loss': 0.8136543678966436} | train loss {'Reaction outcome loss': 0.8148828621112532, 'Total loss': 0.8148828621112532}
2022-11-18 01:14:33,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:33,896 INFO:     Epoch: 55
2022-11-18 01:14:34,707 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8178779530254278, 'Total loss': 0.8178779530254278} | train loss {'Reaction outcome loss': 0.8166911048033545, 'Total loss': 0.8166911048033545}
2022-11-18 01:14:34,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:34,708 INFO:     Epoch: 56
2022-11-18 01:14:35,525 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8232815915888007, 'Total loss': 0.8232815915888007} | train loss {'Reaction outcome loss': 0.8172603148606515, 'Total loss': 0.8172603148606515}
2022-11-18 01:14:35,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:35,526 INFO:     Epoch: 57
2022-11-18 01:14:36,297 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8096108395944942, 'Total loss': 0.8096108395944942} | train loss {'Reaction outcome loss': 0.8168434170224974, 'Total loss': 0.8168434170224974}
2022-11-18 01:14:36,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:36,298 INFO:     Epoch: 58
2022-11-18 01:14:37,104 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8250722871585325, 'Total loss': 0.8250722871585325} | train loss {'Reaction outcome loss': 0.8111301428608356, 'Total loss': 0.8111301428608356}
2022-11-18 01:14:37,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:37,104 INFO:     Epoch: 59
2022-11-18 01:14:37,899 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8433897468176755, 'Total loss': 0.8433897468176755} | train loss {'Reaction outcome loss': 0.8150898375578465, 'Total loss': 0.8150898375578465}
2022-11-18 01:14:37,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:37,899 INFO:     Epoch: 60
2022-11-18 01:14:38,696 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8233790627934716, 'Total loss': 0.8233790627934716} | train loss {'Reaction outcome loss': 0.8163059296146515, 'Total loss': 0.8163059296146515}
2022-11-18 01:14:38,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:38,696 INFO:     Epoch: 61
2022-11-18 01:14:39,475 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.826785989783027, 'Total loss': 0.826785989783027} | train loss {'Reaction outcome loss': 0.8145852617679104, 'Total loss': 0.8145852617679104}
2022-11-18 01:14:39,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:39,475 INFO:     Epoch: 62
2022-11-18 01:14:40,323 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8108662204308943, 'Total loss': 0.8108662204308943} | train loss {'Reaction outcome loss': 0.8159612834213241, 'Total loss': 0.8159612834213241}
2022-11-18 01:14:40,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:40,323 INFO:     Epoch: 63
2022-11-18 01:14:41,146 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8300169266083024, 'Total loss': 0.8300169266083024} | train loss {'Reaction outcome loss': 0.8131921260106948, 'Total loss': 0.8131921260106948}
2022-11-18 01:14:41,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:41,147 INFO:     Epoch: 64
2022-11-18 01:14:41,952 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8323515707796271, 'Total loss': 0.8323515707796271} | train loss {'Reaction outcome loss': 0.8155815357402447, 'Total loss': 0.8155815357402447}
2022-11-18 01:14:41,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:41,953 INFO:     Epoch: 65
2022-11-18 01:14:42,775 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8283245035193183, 'Total loss': 0.8283245035193183} | train loss {'Reaction outcome loss': 0.8188123937335706, 'Total loss': 0.8188123937335706}
2022-11-18 01:14:42,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:42,775 INFO:     Epoch: 66
2022-11-18 01:14:43,534 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8259410980072889, 'Total loss': 0.8259410980072889} | train loss {'Reaction outcome loss': 0.8152590027499583, 'Total loss': 0.8152590027499583}
2022-11-18 01:14:43,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:43,534 INFO:     Epoch: 67
2022-11-18 01:14:44,336 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8013265099037777, 'Total loss': 0.8013265099037777} | train loss {'Reaction outcome loss': 0.8191920159564864, 'Total loss': 0.8191920159564864}
2022-11-18 01:14:44,336 INFO:     Found new best model at epoch 67
2022-11-18 01:14:44,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:44,337 INFO:     Epoch: 68
2022-11-18 01:14:45,149 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8168574693528089, 'Total loss': 0.8168574693528089} | train loss {'Reaction outcome loss': 0.8185509979244201, 'Total loss': 0.8185509979244201}
2022-11-18 01:14:45,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:45,150 INFO:     Epoch: 69
2022-11-18 01:14:45,967 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.825382569974119, 'Total loss': 0.825382569974119} | train loss {'Reaction outcome loss': 0.8127486217887171, 'Total loss': 0.8127486217887171}
2022-11-18 01:14:45,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:45,967 INFO:     Epoch: 70
2022-11-18 01:14:46,785 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8087973885915496, 'Total loss': 0.8087973885915496} | train loss {'Reaction outcome loss': 0.8175267855967244, 'Total loss': 0.8175267855967244}
2022-11-18 01:14:46,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:46,785 INFO:     Epoch: 71
2022-11-18 01:14:47,571 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8100751401348547, 'Total loss': 0.8100751401348547} | train loss {'Reaction outcome loss': 0.813143294064268, 'Total loss': 0.813143294064268}
2022-11-18 01:14:47,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:47,572 INFO:     Epoch: 72
2022-11-18 01:14:48,371 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8365284692157399, 'Total loss': 0.8365284692157399} | train loss {'Reaction outcome loss': 0.8107972766362852, 'Total loss': 0.8107972766362852}
2022-11-18 01:14:48,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:48,371 INFO:     Epoch: 73
2022-11-18 01:14:49,154 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8206322064453905, 'Total loss': 0.8206322064453905} | train loss {'Reaction outcome loss': 0.8167433088585254, 'Total loss': 0.8167433088585254}
2022-11-18 01:14:49,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:49,154 INFO:     Epoch: 74
2022-11-18 01:14:49,965 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8187981843948364, 'Total loss': 0.8187981843948364} | train loss {'Reaction outcome loss': 0.8153960363518807, 'Total loss': 0.8153960363518807}
2022-11-18 01:14:49,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:49,965 INFO:     Epoch: 75
2022-11-18 01:14:50,778 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8078046319159594, 'Total loss': 0.8078046319159594} | train loss {'Reaction outcome loss': 0.8163887995385355, 'Total loss': 0.8163887995385355}
2022-11-18 01:14:50,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:50,778 INFO:     Epoch: 76
2022-11-18 01:14:51,622 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8220923515883359, 'Total loss': 0.8220923515883359} | train loss {'Reaction outcome loss': 0.8110633851780046, 'Total loss': 0.8110633851780046}
2022-11-18 01:14:51,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:51,622 INFO:     Epoch: 77
2022-11-18 01:14:52,441 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8262954164635051, 'Total loss': 0.8262954164635051} | train loss {'Reaction outcome loss': 0.8158763794889373, 'Total loss': 0.8158763794889373}
2022-11-18 01:14:52,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:52,441 INFO:     Epoch: 78
2022-11-18 01:14:53,259 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8236675418236039, 'Total loss': 0.8236675418236039} | train loss {'Reaction outcome loss': 0.8097031936049461, 'Total loss': 0.8097031936049461}
2022-11-18 01:14:53,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:53,259 INFO:     Epoch: 79
2022-11-18 01:14:54,076 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8542584268884226, 'Total loss': 0.8542584268884226} | train loss {'Reaction outcome loss': 0.8103795275092125, 'Total loss': 0.8103795275092125}
2022-11-18 01:14:54,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:54,076 INFO:     Epoch: 80
2022-11-18 01:14:54,850 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8150033016096462, 'Total loss': 0.8150033016096462} | train loss {'Reaction outcome loss': 0.8105100211837599, 'Total loss': 0.8105100211837599}
2022-11-18 01:14:54,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:54,851 INFO:     Epoch: 81
2022-11-18 01:14:55,674 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8235162144357507, 'Total loss': 0.8235162144357507} | train loss {'Reaction outcome loss': 0.8149890144986491, 'Total loss': 0.8149890144986491}
2022-11-18 01:14:55,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:55,674 INFO:     Epoch: 82
2022-11-18 01:14:56,468 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8164353777061809, 'Total loss': 0.8164353777061809} | train loss {'Reaction outcome loss': 0.810850240290165, 'Total loss': 0.810850240290165}
2022-11-18 01:14:56,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:56,468 INFO:     Epoch: 83
2022-11-18 01:14:57,271 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.817123303359205, 'Total loss': 0.817123303359205} | train loss {'Reaction outcome loss': 0.8121064292086709, 'Total loss': 0.8121064292086709}
2022-11-18 01:14:57,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:57,271 INFO:     Epoch: 84
2022-11-18 01:14:58,058 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8112823204560713, 'Total loss': 0.8112823204560713} | train loss {'Reaction outcome loss': 0.8189172809042277, 'Total loss': 0.8189172809042277}
2022-11-18 01:14:58,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:58,058 INFO:     Epoch: 85
2022-11-18 01:14:58,868 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8129879601977088, 'Total loss': 0.8129879601977088} | train loss {'Reaction outcome loss': 0.816714390271133, 'Total loss': 0.816714390271133}
2022-11-18 01:14:58,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:58,869 INFO:     Epoch: 86
2022-11-18 01:14:59,666 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.812272419306365, 'Total loss': 0.812272419306365} | train loss {'Reaction outcome loss': 0.8141339727707447, 'Total loss': 0.8141339727707447}
2022-11-18 01:14:59,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:14:59,666 INFO:     Epoch: 87
2022-11-18 01:15:00,472 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8172204359011217, 'Total loss': 0.8172204359011217} | train loss {'Reaction outcome loss': 0.810157315745469, 'Total loss': 0.810157315745469}
2022-11-18 01:15:00,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:00,474 INFO:     Epoch: 88
2022-11-18 01:15:01,297 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8192442113702948, 'Total loss': 0.8192442113702948} | train loss {'Reaction outcome loss': 0.8094527190250735, 'Total loss': 0.8094527190250735}
2022-11-18 01:15:01,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:01,297 INFO:     Epoch: 89
2022-11-18 01:15:02,140 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8031279329549182, 'Total loss': 0.8031279329549182} | train loss {'Reaction outcome loss': 0.8129664309803517, 'Total loss': 0.8129664309803517}
2022-11-18 01:15:02,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:02,141 INFO:     Epoch: 90
2022-11-18 01:15:02,962 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8338754732500423, 'Total loss': 0.8338754732500423} | train loss {'Reaction outcome loss': 0.811821673065424, 'Total loss': 0.811821673065424}
2022-11-18 01:15:02,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:02,963 INFO:     Epoch: 91
2022-11-18 01:15:03,755 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8180370811711658, 'Total loss': 0.8180370811711658} | train loss {'Reaction outcome loss': 0.8098020219514447, 'Total loss': 0.8098020219514447}
2022-11-18 01:15:03,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:03,756 INFO:     Epoch: 92
2022-11-18 01:15:04,541 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8262533382935957, 'Total loss': 0.8262533382935957} | train loss {'Reaction outcome loss': 0.8087632271551317, 'Total loss': 0.8087632271551317}
2022-11-18 01:15:04,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:04,541 INFO:     Epoch: 93
2022-11-18 01:15:05,398 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8148643415082585, 'Total loss': 0.8148643415082585} | train loss {'Reaction outcome loss': 0.8116233263525271, 'Total loss': 0.8116233263525271}
2022-11-18 01:15:05,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:05,398 INFO:     Epoch: 94
2022-11-18 01:15:06,199 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8207977806979959, 'Total loss': 0.8207977806979959} | train loss {'Reaction outcome loss': 0.8110965323303977, 'Total loss': 0.8110965323303977}
2022-11-18 01:15:06,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:06,199 INFO:     Epoch: 95
2022-11-18 01:15:07,005 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8043117238716646, 'Total loss': 0.8043117238716646} | train loss {'Reaction outcome loss': 0.8134203785129132, 'Total loss': 0.8134203785129132}
2022-11-18 01:15:07,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:07,006 INFO:     Epoch: 96
2022-11-18 01:15:07,766 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8339052904735912, 'Total loss': 0.8339052904735912} | train loss {'Reaction outcome loss': 0.8107171284575616, 'Total loss': 0.8107171284575616}
2022-11-18 01:15:07,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:07,766 INFO:     Epoch: 97
2022-11-18 01:15:08,571 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8158629367297346, 'Total loss': 0.8158629367297346} | train loss {'Reaction outcome loss': 0.8095243313620167, 'Total loss': 0.8095243313620167}
2022-11-18 01:15:08,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:08,571 INFO:     Epoch: 98
2022-11-18 01:15:09,379 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.814295270903544, 'Total loss': 0.814295270903544} | train loss {'Reaction outcome loss': 0.8135088759083902, 'Total loss': 0.8135088759083902}
2022-11-18 01:15:09,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:09,380 INFO:     Epoch: 99
2022-11-18 01:15:10,199 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8084890720519152, 'Total loss': 0.8084890720519152} | train loss {'Reaction outcome loss': 0.8156542199994287, 'Total loss': 0.8156542199994287}
2022-11-18 01:15:10,199 INFO:     Best model found after epoch 68 of 100.
2022-11-18 01:15:10,199 INFO:   Done with stage: TRAINING
2022-11-18 01:15:10,200 INFO:   Starting stage: EVALUATION
2022-11-18 01:15:10,317 INFO:   Done with stage: EVALUATION
2022-11-18 01:15:10,317 INFO:   Leaving out SEQ value Fold_6
2022-11-18 01:15:10,330 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:15:10,330 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:15:10,999 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:15:10,999 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:15:11,069 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:15:11,069 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:15:11,069 INFO:     No hyperparam tuning for this model
2022-11-18 01:15:11,069 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:15:11,069 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:15:11,070 INFO:     None feature selector for col prot
2022-11-18 01:15:11,070 INFO:     None feature selector for col prot
2022-11-18 01:15:11,070 INFO:     None feature selector for col prot
2022-11-18 01:15:11,071 INFO:     None feature selector for col chem
2022-11-18 01:15:11,071 INFO:     None feature selector for col chem
2022-11-18 01:15:11,071 INFO:     None feature selector for col chem
2022-11-18 01:15:11,071 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:15:11,071 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:15:11,073 INFO:     Number of params in model 168571
2022-11-18 01:15:11,076 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:15:11,076 INFO:   Starting stage: TRAINING
2022-11-18 01:15:11,134 INFO:     Val loss before train {'Reaction outcome loss': 1.007181311195547, 'Total loss': 1.007181311195547}
2022-11-18 01:15:11,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:11,134 INFO:     Epoch: 0
2022-11-18 01:15:11,938 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8396446393294767, 'Total loss': 0.8396446393294767} | train loss {'Reaction outcome loss': 0.89581497478099, 'Total loss': 0.89581497478099}
2022-11-18 01:15:11,938 INFO:     Found new best model at epoch 0
2022-11-18 01:15:11,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:11,939 INFO:     Epoch: 1
2022-11-18 01:15:12,735 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.838462845845656, 'Total loss': 0.838462845845656} | train loss {'Reaction outcome loss': 0.8529671513841219, 'Total loss': 0.8529671513841219}
2022-11-18 01:15:12,735 INFO:     Found new best model at epoch 1
2022-11-18 01:15:12,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:12,736 INFO:     Epoch: 2
2022-11-18 01:15:13,508 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8691328682682731, 'Total loss': 0.8691328682682731} | train loss {'Reaction outcome loss': 0.8470078590759623, 'Total loss': 0.8470078590759623}
2022-11-18 01:15:13,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:13,509 INFO:     Epoch: 3
2022-11-18 01:15:14,315 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8410676609386097, 'Total loss': 0.8410676609386097} | train loss {'Reaction outcome loss': 0.846427390087954, 'Total loss': 0.846427390087954}
2022-11-18 01:15:14,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:14,315 INFO:     Epoch: 4
2022-11-18 01:15:15,100 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8201907073909586, 'Total loss': 0.8201907073909586} | train loss {'Reaction outcome loss': 0.8414969608142429, 'Total loss': 0.8414969608142429}
2022-11-18 01:15:15,100 INFO:     Found new best model at epoch 4
2022-11-18 01:15:15,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:15,101 INFO:     Epoch: 5
2022-11-18 01:15:15,887 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8127175583080812, 'Total loss': 0.8127175583080812} | train loss {'Reaction outcome loss': 0.8336422347467438, 'Total loss': 0.8336422347467438}
2022-11-18 01:15:15,887 INFO:     Found new best model at epoch 5
2022-11-18 01:15:15,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:15,888 INFO:     Epoch: 6
2022-11-18 01:15:16,675 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8735501210797917, 'Total loss': 0.8735501210797917} | train loss {'Reaction outcome loss': 0.8291334849801141, 'Total loss': 0.8291334849801141}
2022-11-18 01:15:16,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:16,676 INFO:     Epoch: 7
2022-11-18 01:15:17,474 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8174247335303914, 'Total loss': 0.8174247335303914} | train loss {'Reaction outcome loss': 0.8258571831984558, 'Total loss': 0.8258571831984558}
2022-11-18 01:15:17,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:17,475 INFO:     Epoch: 8
2022-11-18 01:15:18,286 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8281230655583468, 'Total loss': 0.8281230655583468} | train loss {'Reaction outcome loss': 0.8320947969973329, 'Total loss': 0.8320947969973329}
2022-11-18 01:15:18,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:18,286 INFO:     Epoch: 9
2022-11-18 01:15:19,085 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8139822110533714, 'Total loss': 0.8139822110533714} | train loss {'Reaction outcome loss': 0.8268187293398236, 'Total loss': 0.8268187293398236}
2022-11-18 01:15:19,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:19,086 INFO:     Epoch: 10
2022-11-18 01:15:19,888 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8100929653102701, 'Total loss': 0.8100929653102701} | train loss {'Reaction outcome loss': 0.8264842231263999, 'Total loss': 0.8264842231263999}
2022-11-18 01:15:19,888 INFO:     Found new best model at epoch 10
2022-11-18 01:15:19,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:19,889 INFO:     Epoch: 11
2022-11-18 01:15:20,699 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8235519162633202, 'Total loss': 0.8235519162633202} | train loss {'Reaction outcome loss': 0.8243677991815666, 'Total loss': 0.8243677991815666}
2022-11-18 01:15:20,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:20,700 INFO:     Epoch: 12
2022-11-18 01:15:21,493 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8057312498038466, 'Total loss': 0.8057312498038466} | train loss {'Reaction outcome loss': 0.8181469210909929, 'Total loss': 0.8181469210909929}
2022-11-18 01:15:21,493 INFO:     Found new best model at epoch 12
2022-11-18 01:15:21,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:21,494 INFO:     Epoch: 13
2022-11-18 01:15:22,295 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8097606531598351, 'Total loss': 0.8097606531598351} | train loss {'Reaction outcome loss': 0.8268673436844397, 'Total loss': 0.8268673436844397}
2022-11-18 01:15:22,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:22,296 INFO:     Epoch: 14
2022-11-18 01:15:23,143 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8187995688481764, 'Total loss': 0.8187995688481764} | train loss {'Reaction outcome loss': 0.8307798082529292, 'Total loss': 0.8307798082529292}
2022-11-18 01:15:23,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:23,144 INFO:     Epoch: 15
2022-11-18 01:15:23,944 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8324058123610236, 'Total loss': 0.8324058123610236} | train loss {'Reaction outcome loss': 0.8238269834428543, 'Total loss': 0.8238269834428543}
2022-11-18 01:15:23,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:23,944 INFO:     Epoch: 16
2022-11-18 01:15:24,772 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8006939061663367, 'Total loss': 0.8006939061663367} | train loss {'Reaction outcome loss': 0.8245165037964037, 'Total loss': 0.8245165037964037}
2022-11-18 01:15:24,772 INFO:     Found new best model at epoch 16
2022-11-18 01:15:24,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:24,773 INFO:     Epoch: 17
2022-11-18 01:15:25,576 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8072190135717392, 'Total loss': 0.8072190135717392} | train loss {'Reaction outcome loss': 0.8191615188652687, 'Total loss': 0.8191615188652687}
2022-11-18 01:15:25,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:25,577 INFO:     Epoch: 18
2022-11-18 01:15:26,360 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8115383779460733, 'Total loss': 0.8115383779460733} | train loss {'Reaction outcome loss': 0.8160679059683794, 'Total loss': 0.8160679059683794}
2022-11-18 01:15:26,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:26,361 INFO:     Epoch: 19
2022-11-18 01:15:27,129 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.802793412045999, 'Total loss': 0.802793412045999} | train loss {'Reaction outcome loss': 0.8184760811357845, 'Total loss': 0.8184760811357845}
2022-11-18 01:15:27,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:27,129 INFO:     Epoch: 20
2022-11-18 01:15:27,946 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.818152750080282, 'Total loss': 0.818152750080282} | train loss {'Reaction outcome loss': 0.8237860444103658, 'Total loss': 0.8237860444103658}
2022-11-18 01:15:27,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:27,946 INFO:     Epoch: 21
2022-11-18 01:15:28,759 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8099232424389232, 'Total loss': 0.8099232424389232} | train loss {'Reaction outcome loss': 0.823109948562707, 'Total loss': 0.823109948562707}
2022-11-18 01:15:28,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:28,759 INFO:     Epoch: 22
2022-11-18 01:15:29,576 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8270106295293028, 'Total loss': 0.8270106295293028} | train loss {'Reaction outcome loss': 0.8155914350499508, 'Total loss': 0.8155914350499508}
2022-11-18 01:15:29,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:29,576 INFO:     Epoch: 23
2022-11-18 01:15:30,388 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7993743514472788, 'Total loss': 0.7993743514472788} | train loss {'Reaction outcome loss': 0.8234064973558974, 'Total loss': 0.8234064973558974}
2022-11-18 01:15:30,388 INFO:     Found new best model at epoch 23
2022-11-18 01:15:30,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:30,389 INFO:     Epoch: 24
2022-11-18 01:15:31,208 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8430148708549413, 'Total loss': 0.8430148708549413} | train loss {'Reaction outcome loss': 0.8227384130240452, 'Total loss': 0.8227384130240452}
2022-11-18 01:15:31,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:31,208 INFO:     Epoch: 25
2022-11-18 01:15:32,010 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8059748065742579, 'Total loss': 0.8059748065742579} | train loss {'Reaction outcome loss': 0.8216404408095819, 'Total loss': 0.8216404408095819}
2022-11-18 01:15:32,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:32,011 INFO:     Epoch: 26
2022-11-18 01:15:32,788 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8259959857572209, 'Total loss': 0.8259959857572209} | train loss {'Reaction outcome loss': 0.8265050679807239, 'Total loss': 0.8265050679807239}
2022-11-18 01:15:32,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:32,788 INFO:     Epoch: 27
2022-11-18 01:15:33,627 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8160824288021434, 'Total loss': 0.8160824288021434} | train loss {'Reaction outcome loss': 0.8242918086438044, 'Total loss': 0.8242918086438044}
2022-11-18 01:15:33,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:33,627 INFO:     Epoch: 28
2022-11-18 01:15:34,417 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7973048118027773, 'Total loss': 0.7973048118027773} | train loss {'Reaction outcome loss': 0.8189149297442031, 'Total loss': 0.8189149297442031}
2022-11-18 01:15:34,417 INFO:     Found new best model at epoch 28
2022-11-18 01:15:34,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:34,418 INFO:     Epoch: 29
2022-11-18 01:15:35,202 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8076898062771017, 'Total loss': 0.8076898062771017} | train loss {'Reaction outcome loss': 0.8182714135058013, 'Total loss': 0.8182714135058013}
2022-11-18 01:15:35,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:35,202 INFO:     Epoch: 30
2022-11-18 01:15:35,999 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8172593137080019, 'Total loss': 0.8172593137080019} | train loss {'Reaction outcome loss': 0.8132349276379777, 'Total loss': 0.8132349276379777}
2022-11-18 01:15:35,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:35,999 INFO:     Epoch: 31
2022-11-18 01:15:36,829 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8077856386927041, 'Total loss': 0.8077856386927041} | train loss {'Reaction outcome loss': 0.820715958652226, 'Total loss': 0.820715958652226}
2022-11-18 01:15:36,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:36,829 INFO:     Epoch: 32
2022-11-18 01:15:37,673 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8113970810716803, 'Total loss': 0.8113970810716803} | train loss {'Reaction outcome loss': 0.8164466939233093, 'Total loss': 0.8164466939233093}
2022-11-18 01:15:37,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:37,673 INFO:     Epoch: 33
2022-11-18 01:15:38,509 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8015798052603548, 'Total loss': 0.8015798052603548} | train loss {'Reaction outcome loss': 0.8248518196194761, 'Total loss': 0.8248518196194761}
2022-11-18 01:15:38,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:38,510 INFO:     Epoch: 34
2022-11-18 01:15:39,313 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8043757277456197, 'Total loss': 0.8043757277456197} | train loss {'Reaction outcome loss': 0.8194896435206719, 'Total loss': 0.8194896435206719}
2022-11-18 01:15:39,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:39,313 INFO:     Epoch: 35
2022-11-18 01:15:40,089 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8166761330582879, 'Total loss': 0.8166761330582879} | train loss {'Reaction outcome loss': 0.8180307118516219, 'Total loss': 0.8180307118516219}
2022-11-18 01:15:40,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:40,089 INFO:     Epoch: 36
2022-11-18 01:15:40,903 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8128251880407333, 'Total loss': 0.8128251880407333} | train loss {'Reaction outcome loss': 0.8164229436441954, 'Total loss': 0.8164229436441954}
2022-11-18 01:15:40,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:40,904 INFO:     Epoch: 37
2022-11-18 01:15:41,729 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8070609413764693, 'Total loss': 0.8070609413764693} | train loss {'Reaction outcome loss': 0.8175174374932702, 'Total loss': 0.8175174374932702}
2022-11-18 01:15:41,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:41,730 INFO:     Epoch: 38
2022-11-18 01:15:42,544 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.804082224314863, 'Total loss': 0.804082224314863} | train loss {'Reaction outcome loss': 0.8203663865805637, 'Total loss': 0.8203663865805637}
2022-11-18 01:15:42,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:42,544 INFO:     Epoch: 39
2022-11-18 01:15:43,370 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7966370250691067, 'Total loss': 0.7966370250691067} | train loss {'Reaction outcome loss': 0.8197894085515366, 'Total loss': 0.8197894085515366}
2022-11-18 01:15:43,371 INFO:     Found new best model at epoch 39
2022-11-18 01:15:43,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:43,371 INFO:     Epoch: 40
2022-11-18 01:15:44,215 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8005907291715796, 'Total loss': 0.8005907291715796} | train loss {'Reaction outcome loss': 0.8165879223631461, 'Total loss': 0.8165879223631461}
2022-11-18 01:15:44,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:44,215 INFO:     Epoch: 41
2022-11-18 01:15:45,018 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7988245683637533, 'Total loss': 0.7988245683637533} | train loss {'Reaction outcome loss': 0.8175301383200445, 'Total loss': 0.8175301383200445}
2022-11-18 01:15:45,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:45,019 INFO:     Epoch: 42
2022-11-18 01:15:45,826 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8229129612445831, 'Total loss': 0.8229129612445831} | train loss {'Reaction outcome loss': 0.8173244147286242, 'Total loss': 0.8173244147286242}
2022-11-18 01:15:45,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:45,826 INFO:     Epoch: 43
2022-11-18 01:15:46,604 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8141899894584309, 'Total loss': 0.8141899894584309} | train loss {'Reaction outcome loss': 0.8106994960713483, 'Total loss': 0.8106994960713483}
2022-11-18 01:15:46,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:46,604 INFO:     Epoch: 44
2022-11-18 01:15:47,404 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8238928697325967, 'Total loss': 0.8238928697325967} | train loss {'Reaction outcome loss': 0.8162663659827429, 'Total loss': 0.8162663659827429}
2022-11-18 01:15:47,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:47,404 INFO:     Epoch: 45
2022-11-18 01:15:48,234 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8046802661635659, 'Total loss': 0.8046802661635659} | train loss {'Reaction outcome loss': 0.8145208343682502, 'Total loss': 0.8145208343682502}
2022-11-18 01:15:48,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:48,235 INFO:     Epoch: 46
2022-11-18 01:15:49,063 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.809587303887714, 'Total loss': 0.809587303887714} | train loss {'Reaction outcome loss': 0.8148513490613173, 'Total loss': 0.8148513490613173}
2022-11-18 01:15:49,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:49,063 INFO:     Epoch: 47
2022-11-18 01:15:49,854 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8344271887432445, 'Total loss': 0.8344271887432445} | train loss {'Reaction outcome loss': 0.8128617230938514, 'Total loss': 0.8128617230938514}
2022-11-18 01:15:49,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:49,854 INFO:     Epoch: 48
2022-11-18 01:15:50,663 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8047352528030222, 'Total loss': 0.8047352528030222} | train loss {'Reaction outcome loss': 0.812663281253475, 'Total loss': 0.812663281253475}
2022-11-18 01:15:50,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:50,664 INFO:     Epoch: 49
2022-11-18 01:15:51,495 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8227850056507371, 'Total loss': 0.8227850056507371} | train loss {'Reaction outcome loss': 0.8195914504257774, 'Total loss': 0.8195914504257774}
2022-11-18 01:15:51,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:51,496 INFO:     Epoch: 50
2022-11-18 01:15:52,292 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.805681736631827, 'Total loss': 0.805681736631827} | train loss {'Reaction outcome loss': 0.8152027318352147, 'Total loss': 0.8152027318352147}
2022-11-18 01:15:52,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:52,292 INFO:     Epoch: 51
2022-11-18 01:15:53,107 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7986146624792706, 'Total loss': 0.7986146624792706} | train loss {'Reaction outcome loss': 0.8203786927678807, 'Total loss': 0.8203786927678807}
2022-11-18 01:15:53,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:53,107 INFO:     Epoch: 52
2022-11-18 01:15:53,926 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8003735528750853, 'Total loss': 0.8003735528750853} | train loss {'Reaction outcome loss': 0.8108162895176816, 'Total loss': 0.8108162895176816}
2022-11-18 01:15:53,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:53,926 INFO:     Epoch: 53
2022-11-18 01:15:54,733 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8137888048182834, 'Total loss': 0.8137888048182834} | train loss {'Reaction outcome loss': 0.8144333828316044, 'Total loss': 0.8144333828316044}
2022-11-18 01:15:54,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:54,733 INFO:     Epoch: 54
2022-11-18 01:15:55,560 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7941978140310808, 'Total loss': 0.7941978140310808} | train loss {'Reaction outcome loss': 0.8170024161095079, 'Total loss': 0.8170024161095079}
2022-11-18 01:15:55,560 INFO:     Found new best model at epoch 54
2022-11-18 01:15:55,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:55,561 INFO:     Epoch: 55
2022-11-18 01:15:56,332 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8296408023346554, 'Total loss': 0.8296408023346554} | train loss {'Reaction outcome loss': 0.811977987226687, 'Total loss': 0.811977987226687}
2022-11-18 01:15:56,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:56,333 INFO:     Epoch: 56
2022-11-18 01:15:57,120 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8065623065287416, 'Total loss': 0.8065623065287416} | train loss {'Reaction outcome loss': 0.8174662727576035, 'Total loss': 0.8174662727576035}
2022-11-18 01:15:57,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:57,121 INFO:     Epoch: 57
2022-11-18 01:15:57,969 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8132707463069395, 'Total loss': 0.8132707463069395} | train loss {'Reaction outcome loss': 0.8159768157883694, 'Total loss': 0.8159768157883694}
2022-11-18 01:15:57,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:57,969 INFO:     Epoch: 58
2022-11-18 01:15:58,769 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7972966317426075, 'Total loss': 0.7972966317426075} | train loss {'Reaction outcome loss': 0.8131309503968428, 'Total loss': 0.8131309503968428}
2022-11-18 01:15:58,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:58,769 INFO:     Epoch: 59
2022-11-18 01:15:59,563 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.803456730463288, 'Total loss': 0.803456730463288} | train loss {'Reaction outcome loss': 0.8237848257728917, 'Total loss': 0.8237848257728917}
2022-11-18 01:15:59,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:15:59,563 INFO:     Epoch: 60
2022-11-18 01:16:00,393 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8493209000338208, 'Total loss': 0.8493209000338208} | train loss {'Reaction outcome loss': 0.8117702269119772, 'Total loss': 0.8117702269119772}
2022-11-18 01:16:00,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:00,393 INFO:     Epoch: 61
2022-11-18 01:16:01,173 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8036572770638899, 'Total loss': 0.8036572770638899} | train loss {'Reaction outcome loss': 0.815585705674129, 'Total loss': 0.815585705674129}
2022-11-18 01:16:01,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:01,173 INFO:     Epoch: 62
2022-11-18 01:16:01,987 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8164061910726808, 'Total loss': 0.8164061910726808} | train loss {'Reaction outcome loss': 0.8128367162909103, 'Total loss': 0.8128367162909103}
2022-11-18 01:16:01,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:01,987 INFO:     Epoch: 63
2022-11-18 01:16:02,759 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8089144710790027, 'Total loss': 0.8089144710790027} | train loss {'Reaction outcome loss': 0.8112925083983523, 'Total loss': 0.8112925083983523}
2022-11-18 01:16:02,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:02,759 INFO:     Epoch: 64
2022-11-18 01:16:03,545 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8001507168466394, 'Total loss': 0.8001507168466394} | train loss {'Reaction outcome loss': 0.8160123662186055, 'Total loss': 0.8160123662186055}
2022-11-18 01:16:03,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:03,546 INFO:     Epoch: 65
2022-11-18 01:16:04,368 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7970040487972173, 'Total loss': 0.7970040487972173} | train loss {'Reaction outcome loss': 0.8154668804363683, 'Total loss': 0.8154668804363683}
2022-11-18 01:16:04,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:04,368 INFO:     Epoch: 66
2022-11-18 01:16:05,178 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8212017017331991, 'Total loss': 0.8212017017331991} | train loss {'Reaction outcome loss': 0.8190444123889753, 'Total loss': 0.8190444123889753}
2022-11-18 01:16:05,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:05,179 INFO:     Epoch: 67
2022-11-18 01:16:05,972 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8114071230996739, 'Total loss': 0.8114071230996739} | train loss {'Reaction outcome loss': 0.8217400055423922, 'Total loss': 0.8217400055423922}
2022-11-18 01:16:05,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:05,972 INFO:     Epoch: 68
2022-11-18 01:16:06,759 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7971123863350261, 'Total loss': 0.7971123863350261} | train loss {'Reaction outcome loss': 0.8225104743652498, 'Total loss': 0.8225104743652498}
2022-11-18 01:16:06,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:06,759 INFO:     Epoch: 69
2022-11-18 01:16:07,534 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.801096223294735, 'Total loss': 0.801096223294735} | train loss {'Reaction outcome loss': 0.816995186391871, 'Total loss': 0.816995186391871}
2022-11-18 01:16:07,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:07,535 INFO:     Epoch: 70
2022-11-18 01:16:08,349 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7965646629983728, 'Total loss': 0.7965646629983728} | train loss {'Reaction outcome loss': 0.8178741025779894, 'Total loss': 0.8178741025779894}
2022-11-18 01:16:08,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:08,349 INFO:     Epoch: 71
2022-11-18 01:16:09,134 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7953043153340166, 'Total loss': 0.7953043153340166} | train loss {'Reaction outcome loss': 0.8130522900023441, 'Total loss': 0.8130522900023441}
2022-11-18 01:16:09,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:09,134 INFO:     Epoch: 72
2022-11-18 01:16:09,921 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8038522811098532, 'Total loss': 0.8038522811098532} | train loss {'Reaction outcome loss': 0.8133445115465867, 'Total loss': 0.8133445115465867}
2022-11-18 01:16:09,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:09,922 INFO:     Epoch: 73
2022-11-18 01:16:10,758 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8205169981176202, 'Total loss': 0.8205169981176202} | train loss {'Reaction outcome loss': 0.8104018368098417, 'Total loss': 0.8104018368098417}
2022-11-18 01:16:10,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:10,758 INFO:     Epoch: 74
2022-11-18 01:16:11,592 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8147350292314183, 'Total loss': 0.8147350292314183} | train loss {'Reaction outcome loss': 0.8146927707832352, 'Total loss': 0.8146927707832352}
2022-11-18 01:16:11,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:11,592 INFO:     Epoch: 75
2022-11-18 01:16:12,407 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.824066078121012, 'Total loss': 0.824066078121012} | train loss {'Reaction outcome loss': 0.8255935399397182, 'Total loss': 0.8255935399397182}
2022-11-18 01:16:12,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:12,407 INFO:     Epoch: 76
2022-11-18 01:16:13,206 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8139578286897052, 'Total loss': 0.8139578286897052} | train loss {'Reaction outcome loss': 0.8185424554927146, 'Total loss': 0.8185424554927146}
2022-11-18 01:16:13,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:13,206 INFO:     Epoch: 77
2022-11-18 01:16:14,025 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8119539455934004, 'Total loss': 0.8119539455934004} | train loss {'Reaction outcome loss': 0.8146008370134995, 'Total loss': 0.8146008370134995}
2022-11-18 01:16:14,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:14,025 INFO:     Epoch: 78
2022-11-18 01:16:14,815 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7997943515127356, 'Total loss': 0.7997943515127356} | train loss {'Reaction outcome loss': 0.8236937813973619, 'Total loss': 0.8236937813973619}
2022-11-18 01:16:14,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:14,815 INFO:     Epoch: 79
2022-11-18 01:16:15,661 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8045973987741903, 'Total loss': 0.8045973987741903} | train loss {'Reaction outcome loss': 0.8191727595290674, 'Total loss': 0.8191727595290674}
2022-11-18 01:16:15,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:15,661 INFO:     Epoch: 80
2022-11-18 01:16:16,495 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8319573551416397, 'Total loss': 0.8319573551416397} | train loss {'Reaction outcome loss': 0.8140441795305805, 'Total loss': 0.8140441795305805}
2022-11-18 01:16:16,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:16,496 INFO:     Epoch: 81
2022-11-18 01:16:17,264 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8113827746022831, 'Total loss': 0.8113827746022831} | train loss {'Reaction outcome loss': 0.8166061482780617, 'Total loss': 0.8166061482780617}
2022-11-18 01:16:17,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:17,264 INFO:     Epoch: 82
2022-11-18 01:16:18,062 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.799659060483629, 'Total loss': 0.799659060483629} | train loss {'Reaction outcome loss': 0.8157856544019723, 'Total loss': 0.8157856544019723}
2022-11-18 01:16:18,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:18,063 INFO:     Epoch: 83
2022-11-18 01:16:18,885 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8150668428702788, 'Total loss': 0.8150668428702788} | train loss {'Reaction outcome loss': 0.8250177975608269, 'Total loss': 0.8250177975608269}
2022-11-18 01:16:18,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:18,885 INFO:     Epoch: 84
2022-11-18 01:16:19,683 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8068713708357378, 'Total loss': 0.8068713708357378} | train loss {'Reaction outcome loss': 0.8200855578488184, 'Total loss': 0.8200855578488184}
2022-11-18 01:16:19,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:19,683 INFO:     Epoch: 85
2022-11-18 01:16:20,466 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8120892467823896, 'Total loss': 0.8120892467823896} | train loss {'Reaction outcome loss': 0.8190620043861722, 'Total loss': 0.8190620043861722}
2022-11-18 01:16:20,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:20,467 INFO:     Epoch: 86
2022-11-18 01:16:21,295 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8380584852261976, 'Total loss': 0.8380584852261976} | train loss {'Reaction outcome loss': 0.8156636496063187, 'Total loss': 0.8156636496063187}
2022-11-18 01:16:21,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:21,295 INFO:     Epoch: 87
2022-11-18 01:16:22,132 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8339297324419022, 'Total loss': 0.8339297324419022} | train loss {'Reaction outcome loss': 0.8210167772615486, 'Total loss': 0.8210167772615486}
2022-11-18 01:16:22,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:22,133 INFO:     Epoch: 88
2022-11-18 01:16:22,954 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7961576269431547, 'Total loss': 0.7961576269431547} | train loss {'Reaction outcome loss': 0.8253469154811822, 'Total loss': 0.8253469154811822}
2022-11-18 01:16:22,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:22,954 INFO:     Epoch: 89
2022-11-18 01:16:23,766 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8038650886578993, 'Total loss': 0.8038650886578993} | train loss {'Reaction outcome loss': 0.8156946057732771, 'Total loss': 0.8156946057732771}
2022-11-18 01:16:23,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:23,766 INFO:     Epoch: 90
2022-11-18 01:16:24,563 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8098729171536185, 'Total loss': 0.8098729171536185} | train loss {'Reaction outcome loss': 0.8164105440682246, 'Total loss': 0.8164105440682246}
2022-11-18 01:16:24,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:24,563 INFO:     Epoch: 91
2022-11-18 01:16:25,375 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.788236143914136, 'Total loss': 0.788236143914136} | train loss {'Reaction outcome loss': 0.8145423940560113, 'Total loss': 0.8145423940560113}
2022-11-18 01:16:25,376 INFO:     Found new best model at epoch 91
2022-11-18 01:16:25,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:25,376 INFO:     Epoch: 92
2022-11-18 01:16:26,151 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.799666432494467, 'Total loss': 0.799666432494467} | train loss {'Reaction outcome loss': 0.8210577503872304, 'Total loss': 0.8210577503872304}
2022-11-18 01:16:26,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:26,151 INFO:     Epoch: 93
2022-11-18 01:16:26,974 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8048082739114761, 'Total loss': 0.8048082739114761} | train loss {'Reaction outcome loss': 0.8193448308991035, 'Total loss': 0.8193448308991035}
2022-11-18 01:16:26,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:26,975 INFO:     Epoch: 94
2022-11-18 01:16:27,759 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.811812318184159, 'Total loss': 0.811812318184159} | train loss {'Reaction outcome loss': 0.8299737080388706, 'Total loss': 0.8299737080388706}
2022-11-18 01:16:27,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:27,759 INFO:     Epoch: 95
2022-11-18 01:16:28,569 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7889755009250208, 'Total loss': 0.7889755009250208} | train loss {'Reaction outcome loss': 0.8171146611875368, 'Total loss': 0.8171146611875368}
2022-11-18 01:16:28,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:28,569 INFO:     Epoch: 96
2022-11-18 01:16:29,363 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8153489394621416, 'Total loss': 0.8153489394621416} | train loss {'Reaction outcome loss': 0.8160826519191989, 'Total loss': 0.8160826519191989}
2022-11-18 01:16:29,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:29,364 INFO:     Epoch: 97
2022-11-18 01:16:30,170 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.804610437290235, 'Total loss': 0.804610437290235} | train loss {'Reaction outcome loss': 0.8242133388876433, 'Total loss': 0.8242133388876433}
2022-11-18 01:16:30,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:30,171 INFO:     Epoch: 98
2022-11-18 01:16:30,953 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.813569114966826, 'Total loss': 0.813569114966826} | train loss {'Reaction outcome loss': 0.8168000832260379, 'Total loss': 0.8168000832260379}
2022-11-18 01:16:30,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:30,954 INFO:     Epoch: 99
2022-11-18 01:16:31,797 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8185618370771408, 'Total loss': 0.8185618370771408} | train loss {'Reaction outcome loss': 0.8148590153769443, 'Total loss': 0.8148590153769443}
2022-11-18 01:16:31,797 INFO:     Best model found after epoch 92 of 100.
2022-11-18 01:16:31,797 INFO:   Done with stage: TRAINING
2022-11-18 01:16:31,797 INFO:   Starting stage: EVALUATION
2022-11-18 01:16:31,920 INFO:   Done with stage: EVALUATION
2022-11-18 01:16:31,921 INFO:   Leaving out SEQ value Fold_7
2022-11-18 01:16:31,934 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:16:31,934 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:16:32,606 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:16:32,606 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:16:32,676 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:16:32,677 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:16:32,677 INFO:     No hyperparam tuning for this model
2022-11-18 01:16:32,677 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:16:32,677 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:16:32,678 INFO:     None feature selector for col prot
2022-11-18 01:16:32,678 INFO:     None feature selector for col prot
2022-11-18 01:16:32,678 INFO:     None feature selector for col prot
2022-11-18 01:16:32,678 INFO:     None feature selector for col chem
2022-11-18 01:16:32,679 INFO:     None feature selector for col chem
2022-11-18 01:16:32,679 INFO:     None feature selector for col chem
2022-11-18 01:16:32,679 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:16:32,679 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:16:32,680 INFO:     Number of params in model 168571
2022-11-18 01:16:32,684 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:16:32,684 INFO:   Starting stage: TRAINING
2022-11-18 01:16:32,742 INFO:     Val loss before train {'Reaction outcome loss': 1.0456096164204858, 'Total loss': 1.0456096164204858}
2022-11-18 01:16:32,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:32,742 INFO:     Epoch: 0
2022-11-18 01:16:33,513 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8970352966677059, 'Total loss': 0.8970352966677059} | train loss {'Reaction outcome loss': 0.8713104902250082, 'Total loss': 0.8713104902250082}
2022-11-18 01:16:33,513 INFO:     Found new best model at epoch 0
2022-11-18 01:16:33,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:33,514 INFO:     Epoch: 1
2022-11-18 01:16:34,289 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8912703462622382, 'Total loss': 0.8912703462622382} | train loss {'Reaction outcome loss': 0.8397600183844084, 'Total loss': 0.8397600183844084}
2022-11-18 01:16:34,290 INFO:     Found new best model at epoch 1
2022-11-18 01:16:34,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:34,291 INFO:     Epoch: 2
2022-11-18 01:16:35,101 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9123189164833589, 'Total loss': 0.9123189164833589} | train loss {'Reaction outcome loss': 0.8309220891249808, 'Total loss': 0.8309220891249808}
2022-11-18 01:16:35,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:35,101 INFO:     Epoch: 3
2022-11-18 01:16:35,908 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8745159174908291, 'Total loss': 0.8745159174908291} | train loss {'Reaction outcome loss': 0.8236934073601174, 'Total loss': 0.8236934073601174}
2022-11-18 01:16:35,908 INFO:     Found new best model at epoch 3
2022-11-18 01:16:35,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:35,909 INFO:     Epoch: 4
2022-11-18 01:16:36,710 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.873280247504061, 'Total loss': 0.873280247504061} | train loss {'Reaction outcome loss': 0.8319237047602773, 'Total loss': 0.8319237047602773}
2022-11-18 01:16:36,710 INFO:     Found new best model at epoch 4
2022-11-18 01:16:36,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:36,711 INFO:     Epoch: 5
2022-11-18 01:16:37,534 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8923597992821173, 'Total loss': 0.8923597992821173} | train loss {'Reaction outcome loss': 0.820379204821852, 'Total loss': 0.820379204821852}
2022-11-18 01:16:37,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:37,535 INFO:     Epoch: 6
2022-11-18 01:16:38,330 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8953903290358457, 'Total loss': 0.8953903290358457} | train loss {'Reaction outcome loss': 0.819284462373749, 'Total loss': 0.819284462373749}
2022-11-18 01:16:38,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:38,330 INFO:     Epoch: 7
2022-11-18 01:16:39,147 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8847088786688718, 'Total loss': 0.8847088786688718} | train loss {'Reaction outcome loss': 0.821261739561915, 'Total loss': 0.821261739561915}
2022-11-18 01:16:39,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:39,147 INFO:     Epoch: 8
2022-11-18 01:16:39,983 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8744082328948107, 'Total loss': 0.8744082328948107} | train loss {'Reaction outcome loss': 0.8113592609702817, 'Total loss': 0.8113592609702817}
2022-11-18 01:16:39,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:39,983 INFO:     Epoch: 9
2022-11-18 01:16:40,827 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.86401652070609, 'Total loss': 0.86401652070609} | train loss {'Reaction outcome loss': 0.8138838836297333, 'Total loss': 0.8138838836297333}
2022-11-18 01:16:40,828 INFO:     Found new best model at epoch 9
2022-11-18 01:16:40,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:40,829 INFO:     Epoch: 10
2022-11-18 01:16:41,661 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8723799830133264, 'Total loss': 0.8723799830133264} | train loss {'Reaction outcome loss': 0.8097172396536539, 'Total loss': 0.8097172396536539}
2022-11-18 01:16:41,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:41,661 INFO:     Epoch: 11
2022-11-18 01:16:42,486 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8632288764823567, 'Total loss': 0.8632288764823567} | train loss {'Reaction outcome loss': 0.8115042327386648, 'Total loss': 0.8115042327386648}
2022-11-18 01:16:42,486 INFO:     Found new best model at epoch 11
2022-11-18 01:16:42,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:42,487 INFO:     Epoch: 12
2022-11-18 01:16:43,294 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8702248057181184, 'Total loss': 0.8702248057181184} | train loss {'Reaction outcome loss': 0.8177050063725908, 'Total loss': 0.8177050063725908}
2022-11-18 01:16:43,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:43,294 INFO:     Epoch: 13
2022-11-18 01:16:44,152 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8691091103987261, 'Total loss': 0.8691091103987261} | train loss {'Reaction outcome loss': 0.8174044282330193, 'Total loss': 0.8174044282330193}
2022-11-18 01:16:44,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:44,152 INFO:     Epoch: 14
2022-11-18 01:16:44,927 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8826924968849529, 'Total loss': 0.8826924968849529} | train loss {'Reaction outcome loss': 0.8073645670886948, 'Total loss': 0.8073645670886948}
2022-11-18 01:16:44,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:44,927 INFO:     Epoch: 15
2022-11-18 01:16:45,746 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8697029487653212, 'Total loss': 0.8697029487653212} | train loss {'Reaction outcome loss': 0.8179441254872543, 'Total loss': 0.8179441254872543}
2022-11-18 01:16:45,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:45,746 INFO:     Epoch: 16
2022-11-18 01:16:46,563 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8868128962137483, 'Total loss': 0.8868128962137483} | train loss {'Reaction outcome loss': 0.8153192540894636, 'Total loss': 0.8153192540894636}
2022-11-18 01:16:46,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:46,563 INFO:     Epoch: 17
2022-11-18 01:16:47,391 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8639240190386772, 'Total loss': 0.8639240190386772} | train loss {'Reaction outcome loss': 0.8073548956544172, 'Total loss': 0.8073548956544172}
2022-11-18 01:16:47,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:47,391 INFO:     Epoch: 18
2022-11-18 01:16:48,234 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8776709532195871, 'Total loss': 0.8776709532195871} | train loss {'Reaction outcome loss': 0.8149653230360162, 'Total loss': 0.8149653230360162}
2022-11-18 01:16:48,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:48,235 INFO:     Epoch: 19
2022-11-18 01:16:49,030 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8928910818966952, 'Total loss': 0.8928910818966952} | train loss {'Reaction outcome loss': 0.8156868542736841, 'Total loss': 0.8156868542736841}
2022-11-18 01:16:49,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:49,030 INFO:     Epoch: 20
2022-11-18 01:16:49,848 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8877669098702344, 'Total loss': 0.8877669098702344} | train loss {'Reaction outcome loss': 0.8111667532911185, 'Total loss': 0.8111667532911185}
2022-11-18 01:16:49,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:49,848 INFO:     Epoch: 21
2022-11-18 01:16:50,609 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8877848955717954, 'Total loss': 0.8877848955717954} | train loss {'Reaction outcome loss': 0.8115650557041892, 'Total loss': 0.8115650557041892}
2022-11-18 01:16:50,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:50,609 INFO:     Epoch: 22
2022-11-18 01:16:51,418 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8672024716030468, 'Total loss': 0.8672024716030468} | train loss {'Reaction outcome loss': 0.8161526342876527, 'Total loss': 0.8161526342876527}
2022-11-18 01:16:51,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:51,418 INFO:     Epoch: 23
2022-11-18 01:16:52,178 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8538439598950472, 'Total loss': 0.8538439598950472} | train loss {'Reaction outcome loss': 0.8110783898878676, 'Total loss': 0.8110783898878676}
2022-11-18 01:16:52,178 INFO:     Found new best model at epoch 23
2022-11-18 01:16:52,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:52,179 INFO:     Epoch: 24
2022-11-18 01:16:52,989 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8580237017436461, 'Total loss': 0.8580237017436461} | train loss {'Reaction outcome loss': 0.8114115007010548, 'Total loss': 0.8114115007010548}
2022-11-18 01:16:52,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:52,991 INFO:     Epoch: 25
2022-11-18 01:16:53,756 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.868976313282143, 'Total loss': 0.868976313282143} | train loss {'Reaction outcome loss': 0.8070942526947149, 'Total loss': 0.8070942526947149}
2022-11-18 01:16:53,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:53,756 INFO:     Epoch: 26
2022-11-18 01:16:54,547 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8564501668919217, 'Total loss': 0.8564501668919217} | train loss {'Reaction outcome loss': 0.8050392538248768, 'Total loss': 0.8050392538248768}
2022-11-18 01:16:54,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:54,547 INFO:     Epoch: 27
2022-11-18 01:16:55,357 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8628648966550827, 'Total loss': 0.8628648966550827} | train loss {'Reaction outcome loss': 0.80563872328654, 'Total loss': 0.80563872328654}
2022-11-18 01:16:55,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:55,358 INFO:     Epoch: 28
2022-11-18 01:16:56,186 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.9092904539270834, 'Total loss': 0.9092904539270834} | train loss {'Reaction outcome loss': 0.8095233322984656, 'Total loss': 0.8095233322984656}
2022-11-18 01:16:56,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:56,187 INFO:     Epoch: 29
2022-11-18 01:16:57,015 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8534942675720562, 'Total loss': 0.8534942675720562} | train loss {'Reaction outcome loss': 0.8084325033884782, 'Total loss': 0.8084325033884782}
2022-11-18 01:16:57,015 INFO:     Found new best model at epoch 29
2022-11-18 01:16:57,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:57,016 INFO:     Epoch: 30
2022-11-18 01:16:57,828 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8858345692807977, 'Total loss': 0.8858345692807977} | train loss {'Reaction outcome loss': 0.8106032593047571, 'Total loss': 0.8106032593047571}
2022-11-18 01:16:57,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:57,828 INFO:     Epoch: 31
2022-11-18 01:16:58,605 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8714315119114789, 'Total loss': 0.8714315119114789} | train loss {'Reaction outcome loss': 0.8162112853787689, 'Total loss': 0.8162112853787689}
2022-11-18 01:16:58,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:58,606 INFO:     Epoch: 32
2022-11-18 01:16:59,413 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8610968765887347, 'Total loss': 0.8610968765887347} | train loss {'Reaction outcome loss': 0.8039436619050107, 'Total loss': 0.8039436619050107}
2022-11-18 01:16:59,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:16:59,413 INFO:     Epoch: 33
2022-11-18 01:17:00,223 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.879793990064751, 'Total loss': 0.879793990064751} | train loss {'Reaction outcome loss': 0.8094143458464851, 'Total loss': 0.8094143458464851}
2022-11-18 01:17:00,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:00,223 INFO:     Epoch: 34
2022-11-18 01:17:01,034 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8666712133721872, 'Total loss': 0.8666712133721872} | train loss {'Reaction outcome loss': 0.8064389630609196, 'Total loss': 0.8064389630609196}
2022-11-18 01:17:01,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:01,035 INFO:     Epoch: 35
2022-11-18 01:17:01,825 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8575711507688869, 'Total loss': 0.8575711507688869} | train loss {'Reaction outcome loss': 0.8060312735648291, 'Total loss': 0.8060312735648291}
2022-11-18 01:17:01,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:01,825 INFO:     Epoch: 36
2022-11-18 01:17:02,630 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8663826219060204, 'Total loss': 0.8663826219060204} | train loss {'Reaction outcome loss': 0.8115314684416118, 'Total loss': 0.8115314684416118}
2022-11-18 01:17:02,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:02,630 INFO:     Epoch: 37
2022-11-18 01:17:03,443 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8772330392490734, 'Total loss': 0.8772330392490734} | train loss {'Reaction outcome loss': 0.810154203219935, 'Total loss': 0.810154203219935}
2022-11-18 01:17:03,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:03,443 INFO:     Epoch: 38
2022-11-18 01:17:04,214 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8855844634500417, 'Total loss': 0.8855844634500417} | train loss {'Reaction outcome loss': 0.8056662916413203, 'Total loss': 0.8056662916413203}
2022-11-18 01:17:04,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:04,214 INFO:     Epoch: 39
2022-11-18 01:17:05,065 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8727818388830532, 'Total loss': 0.8727818388830532} | train loss {'Reaction outcome loss': 0.8083546953162684, 'Total loss': 0.8083546953162684}
2022-11-18 01:17:05,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:05,065 INFO:     Epoch: 40
2022-11-18 01:17:05,857 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8802235695448789, 'Total loss': 0.8802235695448789} | train loss {'Reaction outcome loss': 0.8079556562157295, 'Total loss': 0.8079556562157295}
2022-11-18 01:17:05,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:05,859 INFO:     Epoch: 41
2022-11-18 01:17:06,752 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8661205023527145, 'Total loss': 0.8661205023527145} | train loss {'Reaction outcome loss': 0.8077925348330123, 'Total loss': 0.8077925348330123}
2022-11-18 01:17:06,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:06,753 INFO:     Epoch: 42
2022-11-18 01:17:07,561 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8682116378437389, 'Total loss': 0.8682116378437389} | train loss {'Reaction outcome loss': 0.8095914208695956, 'Total loss': 0.8095914208695956}
2022-11-18 01:17:07,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:07,561 INFO:     Epoch: 43
2022-11-18 01:17:08,337 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8743547743017023, 'Total loss': 0.8743547743017023} | train loss {'Reaction outcome loss': 0.808323835433736, 'Total loss': 0.808323835433736}
2022-11-18 01:17:08,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:08,338 INFO:     Epoch: 44
2022-11-18 01:17:09,111 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8711058998649771, 'Total loss': 0.8711058998649771} | train loss {'Reaction outcome loss': 0.809863855753109, 'Total loss': 0.809863855753109}
2022-11-18 01:17:09,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:09,111 INFO:     Epoch: 45
2022-11-18 01:17:09,935 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8676682236519727, 'Total loss': 0.8676682236519727} | train loss {'Reaction outcome loss': 0.8077150883703579, 'Total loss': 0.8077150883703579}
2022-11-18 01:17:09,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:09,936 INFO:     Epoch: 46
2022-11-18 01:17:10,745 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8694981201128527, 'Total loss': 0.8694981201128527} | train loss {'Reaction outcome loss': 0.8074865319468232, 'Total loss': 0.8074865319468232}
2022-11-18 01:17:10,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:10,745 INFO:     Epoch: 47
2022-11-18 01:17:11,569 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8707222274758599, 'Total loss': 0.8707222274758599} | train loss {'Reaction outcome loss': 0.8036491478442663, 'Total loss': 0.8036491478442663}
2022-11-18 01:17:11,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:11,569 INFO:     Epoch: 48
2022-11-18 01:17:12,365 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8883884616873481, 'Total loss': 0.8883884616873481} | train loss {'Reaction outcome loss': 0.8175508290649909, 'Total loss': 0.8175508290649909}
2022-11-18 01:17:12,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:12,367 INFO:     Epoch: 49
2022-11-18 01:17:13,183 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8614085181192919, 'Total loss': 0.8614085181192919} | train loss {'Reaction outcome loss': 0.8122323817811031, 'Total loss': 0.8122323817811031}
2022-11-18 01:17:13,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:13,184 INFO:     Epoch: 50
2022-11-18 01:17:13,962 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8666754961013794, 'Total loss': 0.8666754961013794} | train loss {'Reaction outcome loss': 0.8153248995180554, 'Total loss': 0.8153248995180554}
2022-11-18 01:17:13,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:13,962 INFO:     Epoch: 51
2022-11-18 01:17:14,773 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.860039050606164, 'Total loss': 0.860039050606164} | train loss {'Reaction outcome loss': 0.8108987697222938, 'Total loss': 0.8108987697222938}
2022-11-18 01:17:14,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:14,773 INFO:     Epoch: 52
2022-11-18 01:17:15,574 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8608648600903425, 'Total loss': 0.8608648600903425} | train loss {'Reaction outcome loss': 0.8005249234527229, 'Total loss': 0.8005249234527229}
2022-11-18 01:17:15,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:15,574 INFO:     Epoch: 53
2022-11-18 01:17:16,335 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8696085566824133, 'Total loss': 0.8696085566824133} | train loss {'Reaction outcome loss': 0.8088120368086857, 'Total loss': 0.8088120368086857}
2022-11-18 01:17:16,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:16,335 INFO:     Epoch: 54
2022-11-18 01:17:17,120 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8814321675083854, 'Total loss': 0.8814321675083854} | train loss {'Reaction outcome loss': 0.8002116314554022, 'Total loss': 0.8002116314554022}
2022-11-18 01:17:17,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:17,120 INFO:     Epoch: 55
2022-11-18 01:17:17,950 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8699571138078516, 'Total loss': 0.8699571138078516} | train loss {'Reaction outcome loss': 0.8085411210291782, 'Total loss': 0.8085411210291782}
2022-11-18 01:17:17,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:17,950 INFO:     Epoch: 56
2022-11-18 01:17:18,742 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8606874810701067, 'Total loss': 0.8606874810701067} | train loss {'Reaction outcome loss': 0.8111553209030676, 'Total loss': 0.8111553209030676}
2022-11-18 01:17:18,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:18,742 INFO:     Epoch: 57
2022-11-18 01:17:19,547 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8587709380821749, 'Total loss': 0.8587709380821749} | train loss {'Reaction outcome loss': 0.8065695427207329, 'Total loss': 0.8065695427207329}
2022-11-18 01:17:19,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:19,547 INFO:     Epoch: 58
2022-11-18 01:17:20,335 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8609941669485786, 'Total loss': 0.8609941669485786} | train loss {'Reaction outcome loss': 0.8091223962635163, 'Total loss': 0.8091223962635163}
2022-11-18 01:17:20,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:20,335 INFO:     Epoch: 59
2022-11-18 01:17:21,142 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8598678281361406, 'Total loss': 0.8598678281361406} | train loss {'Reaction outcome loss': 0.8129979719517202, 'Total loss': 0.8129979719517202}
2022-11-18 01:17:21,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:21,142 INFO:     Epoch: 60
2022-11-18 01:17:21,921 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8708680129863999, 'Total loss': 0.8708680129863999} | train loss {'Reaction outcome loss': 0.8018093759774679, 'Total loss': 0.8018093759774679}
2022-11-18 01:17:21,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:21,922 INFO:     Epoch: 61
2022-11-18 01:17:22,678 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8597638986327432, 'Total loss': 0.8597638986327432} | train loss {'Reaction outcome loss': 0.8107229831971621, 'Total loss': 0.8107229831971621}
2022-11-18 01:17:22,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:22,678 INFO:     Epoch: 62
2022-11-18 01:17:23,473 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8671784184195779, 'Total loss': 0.8671784184195779} | train loss {'Reaction outcome loss': 0.8013269053055689, 'Total loss': 0.8013269053055689}
2022-11-18 01:17:23,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:23,473 INFO:     Epoch: 63
2022-11-18 01:17:24,278 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8699961277571592, 'Total loss': 0.8699961277571592} | train loss {'Reaction outcome loss': 0.8114950232177611, 'Total loss': 0.8114950232177611}
2022-11-18 01:17:24,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:24,278 INFO:     Epoch: 64
2022-11-18 01:17:25,056 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8825151778080247, 'Total loss': 0.8825151778080247} | train loss {'Reaction outcome loss': 0.8236749716082339, 'Total loss': 0.8236749716082339}
2022-11-18 01:17:25,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:25,058 INFO:     Epoch: 65
2022-11-18 01:17:25,872 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8795121095397256, 'Total loss': 0.8795121095397256} | train loss {'Reaction outcome loss': 0.8050985603559355, 'Total loss': 0.8050985603559355}
2022-11-18 01:17:25,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:25,872 INFO:     Epoch: 66
2022-11-18 01:17:26,666 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.857728745449673, 'Total loss': 0.857728745449673} | train loss {'Reaction outcome loss': 0.807182389111654, 'Total loss': 0.807182389111654}
2022-11-18 01:17:26,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:26,666 INFO:     Epoch: 67
2022-11-18 01:17:27,487 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8607896010984074, 'Total loss': 0.8607896010984074} | train loss {'Reaction outcome loss': 0.8001454419452652, 'Total loss': 0.8001454419452652}
2022-11-18 01:17:27,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:27,488 INFO:     Epoch: 68
2022-11-18 01:17:28,276 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8736051578413356, 'Total loss': 0.8736051578413356} | train loss {'Reaction outcome loss': 0.8009480225291812, 'Total loss': 0.8009480225291812}
2022-11-18 01:17:28,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:28,276 INFO:     Epoch: 69
2022-11-18 01:17:29,069 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8635948713530194, 'Total loss': 0.8635948713530194} | train loss {'Reaction outcome loss': 0.8010458437808854, 'Total loss': 0.8010458437808854}
2022-11-18 01:17:29,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:29,070 INFO:     Epoch: 70
2022-11-18 01:17:29,881 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8801232684742321, 'Total loss': 0.8801232684742321} | train loss {'Reaction outcome loss': 0.7999492241786077, 'Total loss': 0.7999492241786077}
2022-11-18 01:17:29,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:29,881 INFO:     Epoch: 71
2022-11-18 01:17:30,633 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8586951277472756, 'Total loss': 0.8586951277472756} | train loss {'Reaction outcome loss': 0.8071280045789263, 'Total loss': 0.8071280045789263}
2022-11-18 01:17:30,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:30,633 INFO:     Epoch: 72
2022-11-18 01:17:31,394 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8491623171351173, 'Total loss': 0.8491623171351173} | train loss {'Reaction outcome loss': 0.7990860505866618, 'Total loss': 0.7990860505866618}
2022-11-18 01:17:31,394 INFO:     Found new best model at epoch 72
2022-11-18 01:17:31,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:31,395 INFO:     Epoch: 73
2022-11-18 01:17:32,222 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8504163690588691, 'Total loss': 0.8504163690588691} | train loss {'Reaction outcome loss': 0.8025148349252307, 'Total loss': 0.8025148349252307}
2022-11-18 01:17:32,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:32,222 INFO:     Epoch: 74
2022-11-18 01:17:33,004 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8599894927306608, 'Total loss': 0.8599894927306608} | train loss {'Reaction outcome loss': 0.8050887338545641, 'Total loss': 0.8050887338545641}
2022-11-18 01:17:33,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:33,004 INFO:     Epoch: 75
2022-11-18 01:17:33,787 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.913023982535709, 'Total loss': 0.913023982535709} | train loss {'Reaction outcome loss': 0.7989015418749589, 'Total loss': 0.7989015418749589}
2022-11-18 01:17:33,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:33,787 INFO:     Epoch: 76
2022-11-18 01:17:34,557 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8463066884062507, 'Total loss': 0.8463066884062507} | train loss {'Reaction outcome loss': 0.8042075868077606, 'Total loss': 0.8042075868077606}
2022-11-18 01:17:34,557 INFO:     Found new best model at epoch 76
2022-11-18 01:17:34,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:34,558 INFO:     Epoch: 77
2022-11-18 01:17:35,366 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8704489713365381, 'Total loss': 0.8704489713365381} | train loss {'Reaction outcome loss': 0.8047137872168892, 'Total loss': 0.8047137872168892}
2022-11-18 01:17:35,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:35,367 INFO:     Epoch: 78
2022-11-18 01:17:36,179 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8717506527900696, 'Total loss': 0.8717506527900696} | train loss {'Reaction outcome loss': 0.7994782983774116, 'Total loss': 0.7994782983774116}
2022-11-18 01:17:36,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:36,179 INFO:     Epoch: 79
2022-11-18 01:17:37,036 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8665393428369002, 'Total loss': 0.8665393428369002} | train loss {'Reaction outcome loss': 0.8008255082586033, 'Total loss': 0.8008255082586033}
2022-11-18 01:17:37,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:37,041 INFO:     Epoch: 80
2022-11-18 01:17:37,853 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8456306728449735, 'Total loss': 0.8456306728449735} | train loss {'Reaction outcome loss': 0.8091249529890686, 'Total loss': 0.8091249529890686}
2022-11-18 01:17:37,853 INFO:     Found new best model at epoch 80
2022-11-18 01:17:37,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:37,854 INFO:     Epoch: 81
2022-11-18 01:17:38,690 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.885122923688455, 'Total loss': 0.885122923688455} | train loss {'Reaction outcome loss': 0.8042499583501083, 'Total loss': 0.8042499583501083}
2022-11-18 01:17:38,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:38,690 INFO:     Epoch: 82
2022-11-18 01:17:39,499 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8634980571540919, 'Total loss': 0.8634980571540919} | train loss {'Reaction outcome loss': 0.796576215157866, 'Total loss': 0.796576215157866}
2022-11-18 01:17:39,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:39,500 INFO:     Epoch: 83
2022-11-18 01:17:40,299 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8464274216781963, 'Total loss': 0.8464274216781963} | train loss {'Reaction outcome loss': 0.8032612362612597, 'Total loss': 0.8032612362612597}
2022-11-18 01:17:40,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:40,299 INFO:     Epoch: 84
2022-11-18 01:17:41,082 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8651948368007486, 'Total loss': 0.8651948368007486} | train loss {'Reaction outcome loss': 0.807594338288674, 'Total loss': 0.807594338288674}
2022-11-18 01:17:41,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:41,082 INFO:     Epoch: 85
2022-11-18 01:17:41,821 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.923364289782264, 'Total loss': 0.923364289782264} | train loss {'Reaction outcome loss': 0.8041084506492383, 'Total loss': 0.8041084506492383}
2022-11-18 01:17:41,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:41,821 INFO:     Epoch: 86
2022-11-18 01:17:42,585 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8734409538182345, 'Total loss': 0.8734409538182345} | train loss {'Reaction outcome loss': 0.7964883183057492, 'Total loss': 0.7964883183057492}
2022-11-18 01:17:42,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:42,585 INFO:     Epoch: 87
2022-11-18 01:17:43,357 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8536076477982781, 'Total loss': 0.8536076477982781} | train loss {'Reaction outcome loss': 0.8007483438924257, 'Total loss': 0.8007483438924257}
2022-11-18 01:17:43,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:43,358 INFO:     Epoch: 88
2022-11-18 01:17:44,114 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8777705471624028, 'Total loss': 0.8777705471624028} | train loss {'Reaction outcome loss': 0.8018903685243506, 'Total loss': 0.8018903685243506}
2022-11-18 01:17:44,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:44,114 INFO:     Epoch: 89
2022-11-18 01:17:44,894 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8505197966640646, 'Total loss': 0.8505197966640646} | train loss {'Reaction outcome loss': 0.8016721040372424, 'Total loss': 0.8016721040372424}
2022-11-18 01:17:44,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:44,895 INFO:     Epoch: 90
2022-11-18 01:17:45,642 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8516620058904995, 'Total loss': 0.8516620058904995} | train loss {'Reaction outcome loss': 0.79456441363825, 'Total loss': 0.79456441363825}
2022-11-18 01:17:45,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:45,642 INFO:     Epoch: 91
2022-11-18 01:17:46,393 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8656824549490755, 'Total loss': 0.8656824549490755} | train loss {'Reaction outcome loss': 0.8018687100786912, 'Total loss': 0.8018687100786912}
2022-11-18 01:17:46,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:46,394 INFO:     Epoch: 92
2022-11-18 01:17:47,183 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8458998799324036, 'Total loss': 0.8458998799324036} | train loss {'Reaction outcome loss': 0.7981634963499872, 'Total loss': 0.7981634963499872}
2022-11-18 01:17:47,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:47,183 INFO:     Epoch: 93
2022-11-18 01:17:47,968 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8655866221948103, 'Total loss': 0.8655866221948103} | train loss {'Reaction outcome loss': 0.7934814782715157, 'Total loss': 0.7934814782715157}
2022-11-18 01:17:47,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:47,969 INFO:     Epoch: 94
2022-11-18 01:17:48,733 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8791835165836595, 'Total loss': 0.8791835165836595} | train loss {'Reaction outcome loss': 0.8073587461039122, 'Total loss': 0.8073587461039122}
2022-11-18 01:17:48,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:48,733 INFO:     Epoch: 95
2022-11-18 01:17:49,498 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8456181199713186, 'Total loss': 0.8456181199713186} | train loss {'Reaction outcome loss': 0.8015370604239012, 'Total loss': 0.8015370604239012}
2022-11-18 01:17:49,499 INFO:     Found new best model at epoch 95
2022-11-18 01:17:49,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:49,499 INFO:     Epoch: 96
2022-11-18 01:17:50,261 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8420871773904021, 'Total loss': 0.8420871773904021} | train loss {'Reaction outcome loss': 0.8032985913608721, 'Total loss': 0.8032985913608721}
2022-11-18 01:17:50,261 INFO:     Found new best model at epoch 96
2022-11-18 01:17:50,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:50,262 INFO:     Epoch: 97
2022-11-18 01:17:51,051 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8603497364304282, 'Total loss': 0.8603497364304282} | train loss {'Reaction outcome loss': 0.802773993145599, 'Total loss': 0.802773993145599}
2022-11-18 01:17:51,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:51,052 INFO:     Epoch: 98
2022-11-18 01:17:51,815 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8420062627304684, 'Total loss': 0.8420062627304684} | train loss {'Reaction outcome loss': 0.8052123299977074, 'Total loss': 0.8052123299977074}
2022-11-18 01:17:51,815 INFO:     Found new best model at epoch 98
2022-11-18 01:17:51,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:51,816 INFO:     Epoch: 99
2022-11-18 01:17:52,574 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8490473824468526, 'Total loss': 0.8490473824468526} | train loss {'Reaction outcome loss': 0.806460321311526, 'Total loss': 0.806460321311526}
2022-11-18 01:17:52,574 INFO:     Best model found after epoch 99 of 100.
2022-11-18 01:17:52,574 INFO:   Done with stage: TRAINING
2022-11-18 01:17:52,574 INFO:   Starting stage: EVALUATION
2022-11-18 01:17:52,699 INFO:   Done with stage: EVALUATION
2022-11-18 01:17:52,699 INFO:   Leaving out SEQ value Fold_8
2022-11-18 01:17:52,712 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 01:17:52,712 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:17:53,375 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:17:53,375 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:17:53,445 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:17:53,445 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:17:53,445 INFO:     No hyperparam tuning for this model
2022-11-18 01:17:53,445 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:17:53,445 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:17:53,446 INFO:     None feature selector for col prot
2022-11-18 01:17:53,446 INFO:     None feature selector for col prot
2022-11-18 01:17:53,446 INFO:     None feature selector for col prot
2022-11-18 01:17:53,447 INFO:     None feature selector for col chem
2022-11-18 01:17:53,447 INFO:     None feature selector for col chem
2022-11-18 01:17:53,447 INFO:     None feature selector for col chem
2022-11-18 01:17:53,447 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:17:53,447 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:17:53,449 INFO:     Number of params in model 168571
2022-11-18 01:17:53,452 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:17:53,452 INFO:   Starting stage: TRAINING
2022-11-18 01:17:53,508 INFO:     Val loss before train {'Reaction outcome loss': 1.002616129642309, 'Total loss': 1.002616129642309}
2022-11-18 01:17:53,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:53,508 INFO:     Epoch: 0
2022-11-18 01:17:54,269 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8347656096136847, 'Total loss': 0.8347656096136847} | train loss {'Reaction outcome loss': 0.8725407404489205, 'Total loss': 0.8725407404489205}
2022-11-18 01:17:54,269 INFO:     Found new best model at epoch 0
2022-11-18 01:17:54,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:54,270 INFO:     Epoch: 1
2022-11-18 01:17:55,028 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.863587694805722, 'Total loss': 0.863587694805722} | train loss {'Reaction outcome loss': 0.8436594629873995, 'Total loss': 0.8436594629873995}
2022-11-18 01:17:55,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:55,028 INFO:     Epoch: 2
2022-11-18 01:17:55,791 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8343450600324676, 'Total loss': 0.8343450600324676} | train loss {'Reaction outcome loss': 0.8285604224341815, 'Total loss': 0.8285604224341815}
2022-11-18 01:17:55,792 INFO:     Found new best model at epoch 2
2022-11-18 01:17:55,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:55,793 INFO:     Epoch: 3
2022-11-18 01:17:56,533 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8835419957027879, 'Total loss': 0.8835419957027879} | train loss {'Reaction outcome loss': 0.8263691904359176, 'Total loss': 0.8263691904359176}
2022-11-18 01:17:56,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:56,534 INFO:     Epoch: 4
2022-11-18 01:17:57,322 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8241820293803548, 'Total loss': 0.8241820293803548} | train loss {'Reaction outcome loss': 0.8243516847246983, 'Total loss': 0.8243516847246983}
2022-11-18 01:17:57,322 INFO:     Found new best model at epoch 4
2022-11-18 01:17:57,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:57,323 INFO:     Epoch: 5
2022-11-18 01:17:58,079 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8122767729814663, 'Total loss': 0.8122767729814663} | train loss {'Reaction outcome loss': 0.8172483484520287, 'Total loss': 0.8172483484520287}
2022-11-18 01:17:58,079 INFO:     Found new best model at epoch 5
2022-11-18 01:17:58,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:58,080 INFO:     Epoch: 6
2022-11-18 01:17:58,852 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8683235763117324, 'Total loss': 0.8683235763117324} | train loss {'Reaction outcome loss': 0.819247054516292, 'Total loss': 0.819247054516292}
2022-11-18 01:17:58,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:58,852 INFO:     Epoch: 7
2022-11-18 01:17:59,625 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8360171359638835, 'Total loss': 0.8360171359638835} | train loss {'Reaction outcome loss': 0.818240402785481, 'Total loss': 0.818240402785481}
2022-11-18 01:17:59,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:17:59,626 INFO:     Epoch: 8
2022-11-18 01:18:00,432 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8112165255602016, 'Total loss': 0.8112165255602016} | train loss {'Reaction outcome loss': 0.8147359773760936, 'Total loss': 0.8147359773760936}
2022-11-18 01:18:00,432 INFO:     Found new best model at epoch 8
2022-11-18 01:18:00,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:00,433 INFO:     Epoch: 9
2022-11-18 01:18:01,194 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.817433737738188, 'Total loss': 0.817433737738188} | train loss {'Reaction outcome loss': 0.8170038390843595, 'Total loss': 0.8170038390843595}
2022-11-18 01:18:01,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:01,194 INFO:     Epoch: 10
2022-11-18 01:18:01,985 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8133012943489607, 'Total loss': 0.8133012943489607} | train loss {'Reaction outcome loss': 0.8102160604273687, 'Total loss': 0.8102160604273687}
2022-11-18 01:18:01,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:01,985 INFO:     Epoch: 11
2022-11-18 01:18:02,748 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8081610244373942, 'Total loss': 0.8081610244373942} | train loss {'Reaction outcome loss': 0.814253969637097, 'Total loss': 0.814253969637097}
2022-11-18 01:18:02,748 INFO:     Found new best model at epoch 11
2022-11-18 01:18:02,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:02,749 INFO:     Epoch: 12
2022-11-18 01:18:03,518 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8035184955874155, 'Total loss': 0.8035184955874155} | train loss {'Reaction outcome loss': 0.8098830677202491, 'Total loss': 0.8098830677202491}
2022-11-18 01:18:03,518 INFO:     Found new best model at epoch 12
2022-11-18 01:18:03,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:03,519 INFO:     Epoch: 13
2022-11-18 01:18:04,289 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8118835271790971, 'Total loss': 0.8118835271790971} | train loss {'Reaction outcome loss': 0.8143646640122914, 'Total loss': 0.8143646640122914}
2022-11-18 01:18:04,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:04,289 INFO:     Epoch: 14
2022-11-18 01:18:05,040 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8106719158416571, 'Total loss': 0.8106719158416571} | train loss {'Reaction outcome loss': 0.8113623044041337, 'Total loss': 0.8113623044041337}
2022-11-18 01:18:05,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:05,041 INFO:     Epoch: 15
2022-11-18 01:18:05,797 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8285732796025831, 'Total loss': 0.8285732796025831} | train loss {'Reaction outcome loss': 0.808370514238467, 'Total loss': 0.808370514238467}
2022-11-18 01:18:05,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:05,798 INFO:     Epoch: 16
2022-11-18 01:18:06,554 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8059786121512569, 'Total loss': 0.8059786121512569} | train loss {'Reaction outcome loss': 0.8082898020988605, 'Total loss': 0.8082898020988605}
2022-11-18 01:18:06,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:06,554 INFO:     Epoch: 17
2022-11-18 01:18:07,328 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8105861891147702, 'Total loss': 0.8105861891147702} | train loss {'Reaction outcome loss': 0.8089108910472667, 'Total loss': 0.8089108910472667}
2022-11-18 01:18:07,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:07,328 INFO:     Epoch: 18
2022-11-18 01:18:08,082 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8095557391643524, 'Total loss': 0.8095557391643524} | train loss {'Reaction outcome loss': 0.8110182905783418, 'Total loss': 0.8110182905783418}
2022-11-18 01:18:08,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:08,083 INFO:     Epoch: 19
2022-11-18 01:18:08,844 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8428872324699579, 'Total loss': 0.8428872324699579} | train loss {'Reaction outcome loss': 0.8054322931365888, 'Total loss': 0.8054322931365888}
2022-11-18 01:18:08,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:08,845 INFO:     Epoch: 20
2022-11-18 01:18:09,598 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8205383738806081, 'Total loss': 0.8205383738806081} | train loss {'Reaction outcome loss': 0.810876626338138, 'Total loss': 0.810876626338138}
2022-11-18 01:18:09,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:09,599 INFO:     Epoch: 21
2022-11-18 01:18:10,368 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8057093058907708, 'Total loss': 0.8057093058907708} | train loss {'Reaction outcome loss': 0.8099295810842123, 'Total loss': 0.8099295810842123}
2022-11-18 01:18:10,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:10,369 INFO:     Epoch: 22
2022-11-18 01:18:11,129 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8246080736781276, 'Total loss': 0.8246080736781276} | train loss {'Reaction outcome loss': 0.8063132773901596, 'Total loss': 0.8063132773901596}
2022-11-18 01:18:11,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:11,130 INFO:     Epoch: 23
2022-11-18 01:18:11,898 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8427532703377479, 'Total loss': 0.8427532703377479} | train loss {'Reaction outcome loss': 0.8090621090081872, 'Total loss': 0.8090621090081872}
2022-11-18 01:18:11,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:11,899 INFO:     Epoch: 24
2022-11-18 01:18:12,680 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8139013308425282, 'Total loss': 0.8139013308425282} | train loss {'Reaction outcome loss': 0.8062186480545607, 'Total loss': 0.8062186480545607}
2022-11-18 01:18:12,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:12,680 INFO:     Epoch: 25
2022-11-18 01:18:13,437 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8219695909078731, 'Total loss': 0.8219695909078731} | train loss {'Reaction outcome loss': 0.8068091027805062, 'Total loss': 0.8068091027805062}
2022-11-18 01:18:13,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:13,437 INFO:     Epoch: 26
2022-11-18 01:18:14,212 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8066785869210266, 'Total loss': 0.8066785869210266} | train loss {'Reaction outcome loss': 0.8042820235256289, 'Total loss': 0.8042820235256289}
2022-11-18 01:18:14,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:14,213 INFO:     Epoch: 27
2022-11-18 01:18:14,970 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8155102785243544, 'Total loss': 0.8155102785243544} | train loss {'Reaction outcome loss': 0.8079126378307577, 'Total loss': 0.8079126378307577}
2022-11-18 01:18:14,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:14,970 INFO:     Epoch: 28
2022-11-18 01:18:15,713 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8370630145072937, 'Total loss': 0.8370630145072937} | train loss {'Reaction outcome loss': 0.8064058096926721, 'Total loss': 0.8064058096926721}
2022-11-18 01:18:15,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:15,714 INFO:     Epoch: 29
2022-11-18 01:18:16,484 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8230460313863532, 'Total loss': 0.8230460313863532} | train loss {'Reaction outcome loss': 0.8068076941322108, 'Total loss': 0.8068076941322108}
2022-11-18 01:18:16,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:16,484 INFO:     Epoch: 30
2022-11-18 01:18:17,271 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.812349691640499, 'Total loss': 0.812349691640499} | train loss {'Reaction outcome loss': 0.8025641144543397, 'Total loss': 0.8025641144543397}
2022-11-18 01:18:17,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:17,271 INFO:     Epoch: 31
2022-11-18 01:18:18,036 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8060442777567132, 'Total loss': 0.8060442777567132} | train loss {'Reaction outcome loss': 0.8012564541375051, 'Total loss': 0.8012564541375051}
2022-11-18 01:18:18,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:18,037 INFO:     Epoch: 32
2022-11-18 01:18:18,822 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8188791822555453, 'Total loss': 0.8188791822555453} | train loss {'Reaction outcome loss': 0.8015026965590774, 'Total loss': 0.8015026965590774}
2022-11-18 01:18:18,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:18,822 INFO:     Epoch: 33
2022-11-18 01:18:19,599 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8041972247667091, 'Total loss': 0.8041972247667091} | train loss {'Reaction outcome loss': 0.8073201890363068, 'Total loss': 0.8073201890363068}
2022-11-18 01:18:19,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:19,599 INFO:     Epoch: 34
2022-11-18 01:18:20,333 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8151745421941891, 'Total loss': 0.8151745421941891} | train loss {'Reaction outcome loss': 0.7994156079214128, 'Total loss': 0.7994156079214128}
2022-11-18 01:18:20,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:20,333 INFO:     Epoch: 35
2022-11-18 01:18:21,107 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8077480883099312, 'Total loss': 0.8077480883099312} | train loss {'Reaction outcome loss': 0.8038493345995419, 'Total loss': 0.8038493345995419}
2022-11-18 01:18:21,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:21,107 INFO:     Epoch: 36
2022-11-18 01:18:21,896 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8002818420875905, 'Total loss': 0.8002818420875905} | train loss {'Reaction outcome loss': 0.8004306911445055, 'Total loss': 0.8004306911445055}
2022-11-18 01:18:21,897 INFO:     Found new best model at epoch 36
2022-11-18 01:18:21,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:21,897 INFO:     Epoch: 37
2022-11-18 01:18:22,657 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7945511181687199, 'Total loss': 0.7945511181687199} | train loss {'Reaction outcome loss': 0.7973090311298605, 'Total loss': 0.7973090311298605}
2022-11-18 01:18:22,658 INFO:     Found new best model at epoch 37
2022-11-18 01:18:22,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:22,658 INFO:     Epoch: 38
2022-11-18 01:18:23,413 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8185009769229001, 'Total loss': 0.8185009769229001} | train loss {'Reaction outcome loss': 0.8018797596947091, 'Total loss': 0.8018797596947091}
2022-11-18 01:18:23,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:23,413 INFO:     Epoch: 39
2022-11-18 01:18:24,189 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8201231311920077, 'Total loss': 0.8201231311920077} | train loss {'Reaction outcome loss': 0.7972057482502499, 'Total loss': 0.7972057482502499}
2022-11-18 01:18:24,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:24,189 INFO:     Epoch: 40
2022-11-18 01:18:24,958 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8556633896605913, 'Total loss': 0.8556633896605913} | train loss {'Reaction outcome loss': 0.8028844525335265, 'Total loss': 0.8028844525335265}
2022-11-18 01:18:24,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:24,958 INFO:     Epoch: 41
2022-11-18 01:18:25,723 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8141560291135034, 'Total loss': 0.8141560291135034} | train loss {'Reaction outcome loss': 0.8048964168448918, 'Total loss': 0.8048964168448918}
2022-11-18 01:18:25,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:25,724 INFO:     Epoch: 42
2022-11-18 01:18:26,495 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8102729029433672, 'Total loss': 0.8102729029433672} | train loss {'Reaction outcome loss': 0.8016363660820195, 'Total loss': 0.8016363660820195}
2022-11-18 01:18:26,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:26,496 INFO:     Epoch: 43
2022-11-18 01:18:27,280 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8162536059701165, 'Total loss': 0.8162536059701165} | train loss {'Reaction outcome loss': 0.7988446746937564, 'Total loss': 0.7988446746937564}
2022-11-18 01:18:27,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:27,280 INFO:     Epoch: 44
2022-11-18 01:18:28,065 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8178356823533081, 'Total loss': 0.8178356823533081} | train loss {'Reaction outcome loss': 0.7990526651017001, 'Total loss': 0.7990526651017001}
2022-11-18 01:18:28,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:28,065 INFO:     Epoch: 45
2022-11-18 01:18:28,819 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8061827587526899, 'Total loss': 0.8061827587526899} | train loss {'Reaction outcome loss': 0.8039100407088389, 'Total loss': 0.8039100407088389}
2022-11-18 01:18:28,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:28,819 INFO:     Epoch: 46
2022-11-18 01:18:29,577 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8034792972165484, 'Total loss': 0.8034792972165484} | train loss {'Reaction outcome loss': 0.7986197486275532, 'Total loss': 0.7986197486275532}
2022-11-18 01:18:29,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:29,577 INFO:     Epoch: 47
2022-11-18 01:18:30,332 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.82441134508266, 'Total loss': 0.82441134508266} | train loss {'Reaction outcome loss': 0.7987403234497445, 'Total loss': 0.7987403234497445}
2022-11-18 01:18:30,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:30,332 INFO:     Epoch: 48
2022-11-18 01:18:31,112 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7991276986377184, 'Total loss': 0.7991276986377184} | train loss {'Reaction outcome loss': 0.7984604571686417, 'Total loss': 0.7984604571686417}
2022-11-18 01:18:31,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:31,112 INFO:     Epoch: 49
2022-11-18 01:18:31,875 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7927433210749959, 'Total loss': 0.7927433210749959} | train loss {'Reaction outcome loss': 0.8013435387220539, 'Total loss': 0.8013435387220539}
2022-11-18 01:18:31,875 INFO:     Found new best model at epoch 49
2022-11-18 01:18:31,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:31,876 INFO:     Epoch: 50
2022-11-18 01:18:32,638 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.821282336878222, 'Total loss': 0.821282336878222} | train loss {'Reaction outcome loss': 0.7969700907830333, 'Total loss': 0.7969700907830333}
2022-11-18 01:18:32,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:32,638 INFO:     Epoch: 51
2022-11-18 01:18:33,412 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.807366831358089, 'Total loss': 0.807366831358089} | train loss {'Reaction outcome loss': 0.8051289098917461, 'Total loss': 0.8051289098917461}
2022-11-18 01:18:33,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:33,412 INFO:     Epoch: 52
2022-11-18 01:18:34,170 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8084281225537144, 'Total loss': 0.8084281225537144} | train loss {'Reaction outcome loss': 0.7971115442084484, 'Total loss': 0.7971115442084484}
2022-11-18 01:18:34,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:34,170 INFO:     Epoch: 53
2022-11-18 01:18:34,924 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8195436527562696, 'Total loss': 0.8195436527562696} | train loss {'Reaction outcome loss': 0.8020904850764353, 'Total loss': 0.8020904850764353}
2022-11-18 01:18:34,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:34,924 INFO:     Epoch: 54
2022-11-18 01:18:35,696 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.818161642828653, 'Total loss': 0.818161642828653} | train loss {'Reaction outcome loss': 0.8018959018050648, 'Total loss': 0.8018959018050648}
2022-11-18 01:18:35,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:35,696 INFO:     Epoch: 55
2022-11-18 01:18:36,454 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8245102555252785, 'Total loss': 0.8245102555252785} | train loss {'Reaction outcome loss': 0.7963901159094006, 'Total loss': 0.7963901159094006}
2022-11-18 01:18:36,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:36,454 INFO:     Epoch: 56
2022-11-18 01:18:37,238 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8060101464737294, 'Total loss': 0.8060101464737294} | train loss {'Reaction outcome loss': 0.8034209495440858, 'Total loss': 0.8034209495440858}
2022-11-18 01:18:37,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:37,238 INFO:     Epoch: 57
2022-11-18 01:18:37,999 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8053977246894393, 'Total loss': 0.8053977246894393} | train loss {'Reaction outcome loss': 0.7999958708638051, 'Total loss': 0.7999958708638051}
2022-11-18 01:18:37,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:37,999 INFO:     Epoch: 58
2022-11-18 01:18:38,751 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.823144257068634, 'Total loss': 0.823144257068634} | train loss {'Reaction outcome loss': 0.8022307191715866, 'Total loss': 0.8022307191715866}
2022-11-18 01:18:38,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:38,751 INFO:     Epoch: 59
2022-11-18 01:18:39,520 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8075030044067738, 'Total loss': 0.8075030044067738} | train loss {'Reaction outcome loss': 0.7998712490328023, 'Total loss': 0.7998712490328023}
2022-11-18 01:18:39,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:39,521 INFO:     Epoch: 60
2022-11-18 01:18:40,269 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7972025171268818, 'Total loss': 0.7972025171268818} | train loss {'Reaction outcome loss': 0.8036363566996622, 'Total loss': 0.8036363566996622}
2022-11-18 01:18:40,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:40,270 INFO:     Epoch: 61
2022-11-18 01:18:41,024 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8133001958214959, 'Total loss': 0.8133001958214959} | train loss {'Reaction outcome loss': 0.8018176781593777, 'Total loss': 0.8018176781593777}
2022-11-18 01:18:41,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:41,024 INFO:     Epoch: 62
2022-11-18 01:18:41,786 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.817250975342684, 'Total loss': 0.817250975342684} | train loss {'Reaction outcome loss': 0.7958331934985567, 'Total loss': 0.7958331934985567}
2022-11-18 01:18:41,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:41,786 INFO:     Epoch: 63
2022-11-18 01:18:42,553 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8179512391256731, 'Total loss': 0.8179512391256731} | train loss {'Reaction outcome loss': 0.802507857807347, 'Total loss': 0.802507857807347}
2022-11-18 01:18:42,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:42,554 INFO:     Epoch: 64
2022-11-18 01:18:43,323 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8094923184361569, 'Total loss': 0.8094923184361569} | train loss {'Reaction outcome loss': 0.7984762980190457, 'Total loss': 0.7984762980190457}
2022-11-18 01:18:43,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:43,324 INFO:     Epoch: 65
2022-11-18 01:18:44,104 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8462364216183507, 'Total loss': 0.8462364216183507} | train loss {'Reaction outcome loss': 0.7992526425934229, 'Total loss': 0.7992526425934229}
2022-11-18 01:18:44,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:44,104 INFO:     Epoch: 66
2022-11-18 01:18:44,900 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8116555602051491, 'Total loss': 0.8116555602051491} | train loss {'Reaction outcome loss': 0.8008374474087699, 'Total loss': 0.8008374474087699}
2022-11-18 01:18:44,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:44,900 INFO:     Epoch: 67
2022-11-18 01:18:45,661 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8382432384546413, 'Total loss': 0.8382432384546413} | train loss {'Reaction outcome loss': 0.7998014494288163, 'Total loss': 0.7998014494288163}
2022-11-18 01:18:45,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:45,662 INFO:     Epoch: 68
2022-11-18 01:18:46,444 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8064394704131193, 'Total loss': 0.8064394704131193} | train loss {'Reaction outcome loss': 0.8040333088548457, 'Total loss': 0.8040333088548457}
2022-11-18 01:18:46,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:46,444 INFO:     Epoch: 69
2022-11-18 01:18:47,225 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8131533466106238, 'Total loss': 0.8131533466106238} | train loss {'Reaction outcome loss': 0.8013633627627716, 'Total loss': 0.8013633627627716}
2022-11-18 01:18:47,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:47,226 INFO:     Epoch: 70
2022-11-18 01:18:48,025 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8150769028552743, 'Total loss': 0.8150769028552743} | train loss {'Reaction outcome loss': 0.7979502845250193, 'Total loss': 0.7979502845250193}
2022-11-18 01:18:48,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:48,025 INFO:     Epoch: 71
2022-11-18 01:18:48,820 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8179880519245946, 'Total loss': 0.8179880519245946} | train loss {'Reaction outcome loss': 0.8010780812531221, 'Total loss': 0.8010780812531221}
2022-11-18 01:18:48,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:48,821 INFO:     Epoch: 72
2022-11-18 01:18:49,596 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8100202166756918, 'Total loss': 0.8100202166756918} | train loss {'Reaction outcome loss': 0.8038292887513755, 'Total loss': 0.8038292887513755}
2022-11-18 01:18:49,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:49,597 INFO:     Epoch: 73
2022-11-18 01:18:50,392 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8122066799984422, 'Total loss': 0.8122066799984422} | train loss {'Reaction outcome loss': 0.8032142262234062, 'Total loss': 0.8032142262234062}
2022-11-18 01:18:50,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:50,392 INFO:     Epoch: 74
2022-11-18 01:18:51,189 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.805053417765817, 'Total loss': 0.805053417765817} | train loss {'Reaction outcome loss': 0.8034638617126668, 'Total loss': 0.8034638617126668}
2022-11-18 01:18:51,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:51,190 INFO:     Epoch: 75
2022-11-18 01:18:51,955 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8085639885691709, 'Total loss': 0.8085639885691709} | train loss {'Reaction outcome loss': 0.7999531399519717, 'Total loss': 0.7999531399519717}
2022-11-18 01:18:51,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:51,955 INFO:     Epoch: 76
2022-11-18 01:18:52,715 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8105298100515853, 'Total loss': 0.8105298100515853} | train loss {'Reaction outcome loss': 0.8018458102081643, 'Total loss': 0.8018458102081643}
2022-11-18 01:18:52,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:52,715 INFO:     Epoch: 77
2022-11-18 01:18:53,506 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7952035416004269, 'Total loss': 0.7952035416004269} | train loss {'Reaction outcome loss': 0.7986711115866411, 'Total loss': 0.7986711115866411}
2022-11-18 01:18:53,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:53,507 INFO:     Epoch: 78
2022-11-18 01:18:54,274 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8040929741637651, 'Total loss': 0.8040929741637651} | train loss {'Reaction outcome loss': 0.8036191702866163, 'Total loss': 0.8036191702866163}
2022-11-18 01:18:54,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:54,274 INFO:     Epoch: 79
2022-11-18 01:18:55,043 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8009181452351947, 'Total loss': 0.8009181452351947} | train loss {'Reaction outcome loss': 0.7969838057140834, 'Total loss': 0.7969838057140834}
2022-11-18 01:18:55,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:55,043 INFO:     Epoch: 80
2022-11-18 01:18:55,818 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8330617907435395, 'Total loss': 0.8330617907435395} | train loss {'Reaction outcome loss': 0.8003579109418587, 'Total loss': 0.8003579109418587}
2022-11-18 01:18:55,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:55,819 INFO:     Epoch: 81
2022-11-18 01:18:56,581 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8075742458188256, 'Total loss': 0.8075742458188256} | train loss {'Reaction outcome loss': 0.8049291047405024, 'Total loss': 0.8049291047405024}
2022-11-18 01:18:56,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:56,581 INFO:     Epoch: 82
2022-11-18 01:18:57,342 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8190527731596038, 'Total loss': 0.8190527731596038} | train loss {'Reaction outcome loss': 0.7967315721707265, 'Total loss': 0.7967315721707265}
2022-11-18 01:18:57,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:57,343 INFO:     Epoch: 83
2022-11-18 01:18:58,119 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7976683613865875, 'Total loss': 0.7976683613865875} | train loss {'Reaction outcome loss': 0.7965874579109129, 'Total loss': 0.7965874579109129}
2022-11-18 01:18:58,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:58,120 INFO:     Epoch: 84
2022-11-18 01:18:58,883 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8049579976603042, 'Total loss': 0.8049579976603042} | train loss {'Reaction outcome loss': 0.7988781672520716, 'Total loss': 0.7988781672520716}
2022-11-18 01:18:58,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:58,884 INFO:     Epoch: 85
2022-11-18 01:18:59,651 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8077579681263414, 'Total loss': 0.8077579681263414} | train loss {'Reaction outcome loss': 0.7989522041600259, 'Total loss': 0.7989522041600259}
2022-11-18 01:18:59,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:18:59,652 INFO:     Epoch: 86
2022-11-18 01:19:00,467 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8199365353861521, 'Total loss': 0.8199365353861521} | train loss {'Reaction outcome loss': 0.803065862323417, 'Total loss': 0.803065862323417}
2022-11-18 01:19:00,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:00,467 INFO:     Epoch: 87
2022-11-18 01:19:01,229 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8279125198375347, 'Total loss': 0.8279125198375347} | train loss {'Reaction outcome loss': 0.7995244694537804, 'Total loss': 0.7995244694537804}
2022-11-18 01:19:01,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:01,229 INFO:     Epoch: 88
2022-11-18 01:19:02,021 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8160067713537882, 'Total loss': 0.8160067713537882} | train loss {'Reaction outcome loss': 0.8038589049313889, 'Total loss': 0.8038589049313889}
2022-11-18 01:19:02,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:02,021 INFO:     Epoch: 89
2022-11-18 01:19:02,800 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8127841644508894, 'Total loss': 0.8127841644508894} | train loss {'Reaction outcome loss': 0.8011600204178544, 'Total loss': 0.8011600204178544}
2022-11-18 01:19:02,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:02,800 INFO:     Epoch: 90
2022-11-18 01:19:03,624 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8441408283488695, 'Total loss': 0.8441408283488695} | train loss {'Reaction outcome loss': 0.7976069682445682, 'Total loss': 0.7976069682445682}
2022-11-18 01:19:03,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:03,624 INFO:     Epoch: 91
2022-11-18 01:19:04,394 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8069003945173219, 'Total loss': 0.8069003945173219} | train loss {'Reaction outcome loss': 0.7985432606007232, 'Total loss': 0.7985432606007232}
2022-11-18 01:19:04,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:04,394 INFO:     Epoch: 92
2022-11-18 01:19:05,159 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8239273810109426, 'Total loss': 0.8239273810109426} | train loss {'Reaction outcome loss': 0.8044975309586916, 'Total loss': 0.8044975309586916}
2022-11-18 01:19:05,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:05,160 INFO:     Epoch: 93
2022-11-18 01:19:05,938 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8008028365844904, 'Total loss': 0.8008028365844904} | train loss {'Reaction outcome loss': 0.8001489171483478, 'Total loss': 0.8001489171483478}
2022-11-18 01:19:05,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:05,938 INFO:     Epoch: 94
2022-11-18 01:19:06,734 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8265440852143043, 'Total loss': 0.8265440852143043} | train loss {'Reaction outcome loss': 0.799621051818621, 'Total loss': 0.799621051818621}
2022-11-18 01:19:06,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:06,734 INFO:     Epoch: 95
2022-11-18 01:19:07,543 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.806483946567358, 'Total loss': 0.806483946567358} | train loss {'Reaction outcome loss': 0.8011070191860199, 'Total loss': 0.8011070191860199}
2022-11-18 01:19:07,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:07,543 INFO:     Epoch: 96
2022-11-18 01:19:08,338 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8161794595247092, 'Total loss': 0.8161794595247092} | train loss {'Reaction outcome loss': 0.8006217091909198, 'Total loss': 0.8006217091909198}
2022-11-18 01:19:08,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:08,338 INFO:     Epoch: 97
2022-11-18 01:19:09,159 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8223694008450175, 'Total loss': 0.8223694008450175} | train loss {'Reaction outcome loss': 0.8019052720705017, 'Total loss': 0.8019052720705017}
2022-11-18 01:19:09,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:09,159 INFO:     Epoch: 98
2022-11-18 01:19:09,965 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.81609644723493, 'Total loss': 0.81609644723493} | train loss {'Reaction outcome loss': 0.7993737102531996, 'Total loss': 0.7993737102531996}
2022-11-18 01:19:09,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:09,966 INFO:     Epoch: 99
2022-11-18 01:19:10,806 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8106393377448238, 'Total loss': 0.8106393377448238} | train loss {'Reaction outcome loss': 0.8027904777497542, 'Total loss': 0.8027904777497542}
2022-11-18 01:19:10,808 INFO:     Best model found after epoch 50 of 100.
2022-11-18 01:19:10,808 INFO:   Done with stage: TRAINING
2022-11-18 01:19:10,808 INFO:   Starting stage: EVALUATION
2022-11-18 01:19:10,947 INFO:   Done with stage: EVALUATION
2022-11-18 01:19:10,947 INFO:   Leaving out SEQ value Fold_9
2022-11-18 01:19:10,960 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:19:10,960 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:19:11,632 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:19:11,632 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:19:11,703 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:19:11,703 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:19:11,703 INFO:     No hyperparam tuning for this model
2022-11-18 01:19:11,703 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:19:11,703 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:19:11,704 INFO:     None feature selector for col prot
2022-11-18 01:19:11,704 INFO:     None feature selector for col prot
2022-11-18 01:19:11,705 INFO:     None feature selector for col prot
2022-11-18 01:19:11,705 INFO:     None feature selector for col chem
2022-11-18 01:19:11,705 INFO:     None feature selector for col chem
2022-11-18 01:19:11,705 INFO:     None feature selector for col chem
2022-11-18 01:19:11,705 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:19:11,705 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:19:11,707 INFO:     Number of params in model 168571
2022-11-18 01:19:11,710 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:19:11,710 INFO:   Starting stage: TRAINING
2022-11-18 01:19:11,768 INFO:     Val loss before train {'Reaction outcome loss': 1.0736418203874067, 'Total loss': 1.0736418203874067}
2022-11-18 01:19:11,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:11,768 INFO:     Epoch: 0
2022-11-18 01:19:12,543 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8845019096677954, 'Total loss': 0.8845019096677954} | train loss {'Reaction outcome loss': 0.8644027962134435, 'Total loss': 0.8644027962134435}
2022-11-18 01:19:12,544 INFO:     Found new best model at epoch 0
2022-11-18 01:19:12,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:12,545 INFO:     Epoch: 1
2022-11-18 01:19:13,328 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8689747175032442, 'Total loss': 0.8689747175032442} | train loss {'Reaction outcome loss': 0.8364605040926683, 'Total loss': 0.8364605040926683}
2022-11-18 01:19:13,328 INFO:     Found new best model at epoch 1
2022-11-18 01:19:13,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:13,329 INFO:     Epoch: 2
2022-11-18 01:19:14,113 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8604061102325266, 'Total loss': 0.8604061102325266} | train loss {'Reaction outcome loss': 0.8362066845903512, 'Total loss': 0.8362066845903512}
2022-11-18 01:19:14,113 INFO:     Found new best model at epoch 2
2022-11-18 01:19:14,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:14,114 INFO:     Epoch: 3
2022-11-18 01:19:14,925 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8746795735575936, 'Total loss': 0.8746795735575936} | train loss {'Reaction outcome loss': 0.8259701451007654, 'Total loss': 0.8259701451007654}
2022-11-18 01:19:14,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:14,925 INFO:     Epoch: 4
2022-11-18 01:19:15,784 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8855499029159546, 'Total loss': 0.8855499029159546} | train loss {'Reaction outcome loss': 0.8289974451306378, 'Total loss': 0.8289974451306378}
2022-11-18 01:19:15,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:15,785 INFO:     Epoch: 5
2022-11-18 01:19:16,650 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8704556890509345, 'Total loss': 0.8704556890509345} | train loss {'Reaction outcome loss': 0.8338613756272474, 'Total loss': 0.8338613756272474}
2022-11-18 01:19:16,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:16,650 INFO:     Epoch: 6
2022-11-18 01:19:17,460 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8375004773790186, 'Total loss': 0.8375004773790186} | train loss {'Reaction outcome loss': 0.8300135039124894, 'Total loss': 0.8300135039124894}
2022-11-18 01:19:17,461 INFO:     Found new best model at epoch 6
2022-11-18 01:19:17,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:17,461 INFO:     Epoch: 7
2022-11-18 01:19:18,275 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8510193743489005, 'Total loss': 0.8510193743489005} | train loss {'Reaction outcome loss': 0.8212845534659349, 'Total loss': 0.8212845534659349}
2022-11-18 01:19:18,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:18,275 INFO:     Epoch: 8
2022-11-18 01:19:19,057 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8716690228743986, 'Total loss': 0.8716690228743986} | train loss {'Reaction outcome loss': 0.8178166711951799, 'Total loss': 0.8178166711951799}
2022-11-18 01:19:19,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:19,057 INFO:     Epoch: 9
2022-11-18 01:19:19,875 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8454917858947407, 'Total loss': 0.8454917858947407} | train loss {'Reaction outcome loss': 0.8178442198979227, 'Total loss': 0.8178442198979227}
2022-11-18 01:19:19,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:19,875 INFO:     Epoch: 10
2022-11-18 01:19:20,674 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8595111823894761, 'Total loss': 0.8595111823894761} | train loss {'Reaction outcome loss': 0.8179312719989885, 'Total loss': 0.8179312719989885}
2022-11-18 01:19:20,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:20,675 INFO:     Epoch: 11
2022-11-18 01:19:21,482 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8584787913344123, 'Total loss': 0.8584787913344123} | train loss {'Reaction outcome loss': 0.819648824240032, 'Total loss': 0.819648824240032}
2022-11-18 01:19:21,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:21,483 INFO:     Epoch: 12
2022-11-18 01:19:22,272 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8449270305308428, 'Total loss': 0.8449270305308428} | train loss {'Reaction outcome loss': 0.8187554633689795, 'Total loss': 0.8187554633689795}
2022-11-18 01:19:22,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:22,273 INFO:     Epoch: 13
2022-11-18 01:19:23,103 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.852332276376811, 'Total loss': 0.852332276376811} | train loss {'Reaction outcome loss': 0.8185354803013898, 'Total loss': 0.8185354803013898}
2022-11-18 01:19:23,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:23,103 INFO:     Epoch: 14
2022-11-18 01:19:23,882 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8561601056294008, 'Total loss': 0.8561601056294008} | train loss {'Reaction outcome loss': 0.8123096823692322, 'Total loss': 0.8123096823692322}
2022-11-18 01:19:23,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:23,883 INFO:     Epoch: 15
2022-11-18 01:19:24,719 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8432076898488131, 'Total loss': 0.8432076898488131} | train loss {'Reaction outcome loss': 0.8128029070040474, 'Total loss': 0.8128029070040474}
2022-11-18 01:19:24,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:24,719 INFO:     Epoch: 16
2022-11-18 01:19:25,577 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8440200686454773, 'Total loss': 0.8440200686454773} | train loss {'Reaction outcome loss': 0.8092727028889212, 'Total loss': 0.8092727028889212}
2022-11-18 01:19:25,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:25,577 INFO:     Epoch: 17
2022-11-18 01:19:26,362 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8687037866223942, 'Total loss': 0.8687037866223942} | train loss {'Reaction outcome loss': 0.8057110429051434, 'Total loss': 0.8057110429051434}
2022-11-18 01:19:26,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:26,363 INFO:     Epoch: 18
2022-11-18 01:19:27,171 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8476512418551878, 'Total loss': 0.8476512418551878} | train loss {'Reaction outcome loss': 0.8141039550787041, 'Total loss': 0.8141039550787041}
2022-11-18 01:19:27,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:27,171 INFO:     Epoch: 19
2022-11-18 01:19:27,988 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8547357781366869, 'Total loss': 0.8547357781366869} | train loss {'Reaction outcome loss': 0.8147279340849232, 'Total loss': 0.8147279340849232}
2022-11-18 01:19:27,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:27,988 INFO:     Epoch: 20
2022-11-18 01:19:28,836 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8383773917501623, 'Total loss': 0.8383773917501623} | train loss {'Reaction outcome loss': 0.8083524472921001, 'Total loss': 0.8083524472921001}
2022-11-18 01:19:28,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:28,836 INFO:     Epoch: 21
2022-11-18 01:19:29,691 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.857061429457231, 'Total loss': 0.857061429457231} | train loss {'Reaction outcome loss': 0.8049826178594157, 'Total loss': 0.8049826178594157}
2022-11-18 01:19:29,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:29,692 INFO:     Epoch: 22
2022-11-18 01:19:30,525 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.84637301415205, 'Total loss': 0.84637301415205} | train loss {'Reaction outcome loss': 0.8109422688511944, 'Total loss': 0.8109422688511944}
2022-11-18 01:19:30,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:30,526 INFO:     Epoch: 23
2022-11-18 01:19:31,339 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8623135171153329, 'Total loss': 0.8623135171153329} | train loss {'Reaction outcome loss': 0.808799689597929, 'Total loss': 0.808799689597929}
2022-11-18 01:19:31,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:31,339 INFO:     Epoch: 24
2022-11-18 01:19:32,175 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8353220061822371, 'Total loss': 0.8353220061822371} | train loss {'Reaction outcome loss': 0.8090145637390584, 'Total loss': 0.8090145637390584}
2022-11-18 01:19:32,175 INFO:     Found new best model at epoch 24
2022-11-18 01:19:32,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:32,176 INFO:     Epoch: 25
2022-11-18 01:19:33,027 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.839648304337805, 'Total loss': 0.839648304337805} | train loss {'Reaction outcome loss': 0.8103887371206091, 'Total loss': 0.8103887371206091}
2022-11-18 01:19:33,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:33,027 INFO:     Epoch: 26
2022-11-18 01:19:33,865 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8779157203706828, 'Total loss': 0.8779157203706828} | train loss {'Reaction outcome loss': 0.8044265686470246, 'Total loss': 0.8044265686470246}
2022-11-18 01:19:33,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:33,866 INFO:     Epoch: 27
2022-11-18 01:19:34,700 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.839083536782048, 'Total loss': 0.839083536782048} | train loss {'Reaction outcome loss': 0.8104311734860242, 'Total loss': 0.8104311734860242}
2022-11-18 01:19:34,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:34,700 INFO:     Epoch: 28
2022-11-18 01:19:35,489 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8592537709257819, 'Total loss': 0.8592537709257819} | train loss {'Reaction outcome loss': 0.8141480497261773, 'Total loss': 0.8141480497261773}
2022-11-18 01:19:35,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:35,489 INFO:     Epoch: 29
2022-11-18 01:19:36,285 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8571871641007337, 'Total loss': 0.8571871641007337} | train loss {'Reaction outcome loss': 0.8076729566643113, 'Total loss': 0.8076729566643113}
2022-11-18 01:19:36,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:36,285 INFO:     Epoch: 30
2022-11-18 01:19:37,086 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8639214817773212, 'Total loss': 0.8639214817773212} | train loss {'Reaction outcome loss': 0.8153834825585246, 'Total loss': 0.8153834825585246}
2022-11-18 01:19:37,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:37,087 INFO:     Epoch: 31
2022-11-18 01:19:37,871 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8500002697110176, 'Total loss': 0.8500002697110176} | train loss {'Reaction outcome loss': 0.808152301953389, 'Total loss': 0.808152301953389}
2022-11-18 01:19:37,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:37,871 INFO:     Epoch: 32
2022-11-18 01:19:38,664 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8419263958930969, 'Total loss': 0.8419263958930969} | train loss {'Reaction outcome loss': 0.8154305814490145, 'Total loss': 0.8154305814490145}
2022-11-18 01:19:38,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:38,664 INFO:     Epoch: 33
2022-11-18 01:19:39,456 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8262075348333879, 'Total loss': 0.8262075348333879} | train loss {'Reaction outcome loss': 0.8080273726691118, 'Total loss': 0.8080273726691118}
2022-11-18 01:19:39,456 INFO:     Found new best model at epoch 33
2022-11-18 01:19:39,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:39,457 INFO:     Epoch: 34
2022-11-18 01:19:40,253 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8499349369244142, 'Total loss': 0.8499349369244142} | train loss {'Reaction outcome loss': 0.812883481322995, 'Total loss': 0.812883481322995}
2022-11-18 01:19:40,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:40,253 INFO:     Epoch: 35
2022-11-18 01:19:41,069 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.831860906698487, 'Total loss': 0.831860906698487} | train loss {'Reaction outcome loss': 0.8143662854968777, 'Total loss': 0.8143662854968777}
2022-11-18 01:19:41,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:41,069 INFO:     Epoch: 36
2022-11-18 01:19:41,894 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8470582664012909, 'Total loss': 0.8470582664012909} | train loss {'Reaction outcome loss': 0.8099497150071719, 'Total loss': 0.8099497150071719}
2022-11-18 01:19:41,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:41,895 INFO:     Epoch: 37
2022-11-18 01:19:42,731 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8767368468371305, 'Total loss': 0.8767368468371305} | train loss {'Reaction outcome loss': 0.8047047951202161, 'Total loss': 0.8047047951202161}
2022-11-18 01:19:42,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:42,731 INFO:     Epoch: 38
2022-11-18 01:19:43,549 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8315794102170251, 'Total loss': 0.8315794102170251} | train loss {'Reaction outcome loss': 0.806332839766012, 'Total loss': 0.806332839766012}
2022-11-18 01:19:43,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:43,550 INFO:     Epoch: 39
2022-11-18 01:19:44,355 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8578571921045129, 'Total loss': 0.8578571921045129} | train loss {'Reaction outcome loss': 0.8051380260511931, 'Total loss': 0.8051380260511931}
2022-11-18 01:19:44,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:44,356 INFO:     Epoch: 40
2022-11-18 01:19:45,161 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8324707069180228, 'Total loss': 0.8324707069180228} | train loss {'Reaction outcome loss': 0.8086010971773974, 'Total loss': 0.8086010971773974}
2022-11-18 01:19:45,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:45,161 INFO:     Epoch: 41
2022-11-18 01:19:45,962 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8474664972587065, 'Total loss': 0.8474664972587065} | train loss {'Reaction outcome loss': 0.8076649200819764, 'Total loss': 0.8076649200819764}
2022-11-18 01:19:45,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:45,962 INFO:     Epoch: 42
2022-11-18 01:19:46,737 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8486031537706201, 'Total loss': 0.8486031537706201} | train loss {'Reaction outcome loss': 0.8058285230567098, 'Total loss': 0.8058285230567098}
2022-11-18 01:19:46,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:46,737 INFO:     Epoch: 43
2022-11-18 01:19:47,529 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8193951066244732, 'Total loss': 0.8193951066244732} | train loss {'Reaction outcome loss': 0.8103047950789031, 'Total loss': 0.8103047950789031}
2022-11-18 01:19:47,529 INFO:     Found new best model at epoch 43
2022-11-18 01:19:47,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:47,530 INFO:     Epoch: 44
2022-11-18 01:19:48,330 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8311732492663644, 'Total loss': 0.8311732492663644} | train loss {'Reaction outcome loss': 0.8086012274871471, 'Total loss': 0.8086012274871471}
2022-11-18 01:19:48,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:48,331 INFO:     Epoch: 45
2022-11-18 01:19:49,121 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8446527956561609, 'Total loss': 0.8446527956561609} | train loss {'Reaction outcome loss': 0.8099867889755651, 'Total loss': 0.8099867889755651}
2022-11-18 01:19:49,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:49,122 INFO:     Epoch: 46
2022-11-18 01:19:49,929 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8343074355613102, 'Total loss': 0.8343074355613102} | train loss {'Reaction outcome loss': 0.8176409894155587, 'Total loss': 0.8176409894155587}
2022-11-18 01:19:49,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:49,929 INFO:     Epoch: 47
2022-11-18 01:19:50,693 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8344881236553192, 'Total loss': 0.8344881236553192} | train loss {'Reaction outcome loss': 0.8132051040045163, 'Total loss': 0.8132051040045163}
2022-11-18 01:19:50,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:50,693 INFO:     Epoch: 48
2022-11-18 01:19:51,499 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8373739258809523, 'Total loss': 0.8373739258809523} | train loss {'Reaction outcome loss': 0.8108266472575153, 'Total loss': 0.8108266472575153}
2022-11-18 01:19:51,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:51,499 INFO:     Epoch: 49
2022-11-18 01:19:52,277 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8519865044138648, 'Total loss': 0.8519865044138648} | train loss {'Reaction outcome loss': 0.8053016785667976, 'Total loss': 0.8053016785667976}
2022-11-18 01:19:52,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:52,277 INFO:     Epoch: 50
2022-11-18 01:19:53,062 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8213875456289812, 'Total loss': 0.8213875456289812} | train loss {'Reaction outcome loss': 0.80825542655551, 'Total loss': 0.80825542655551}
2022-11-18 01:19:53,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:53,062 INFO:     Epoch: 51
2022-11-18 01:19:53,859 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8376074230129068, 'Total loss': 0.8376074230129068} | train loss {'Reaction outcome loss': 0.8039485085830997, 'Total loss': 0.8039485085830997}
2022-11-18 01:19:53,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:53,859 INFO:     Epoch: 52
2022-11-18 01:19:54,672 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.863832376897335, 'Total loss': 0.863832376897335} | train loss {'Reaction outcome loss': 0.8022843431605984, 'Total loss': 0.8022843431605984}
2022-11-18 01:19:54,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:54,672 INFO:     Epoch: 53
2022-11-18 01:19:55,460 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8291347616098144, 'Total loss': 0.8291347616098144} | train loss {'Reaction outcome loss': 0.8097774127897946, 'Total loss': 0.8097774127897946}
2022-11-18 01:19:55,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:55,460 INFO:     Epoch: 54
2022-11-18 01:19:56,239 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8280834277922456, 'Total loss': 0.8280834277922456} | train loss {'Reaction outcome loss': 0.8049207566238126, 'Total loss': 0.8049207566238126}
2022-11-18 01:19:56,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:56,239 INFO:     Epoch: 55
2022-11-18 01:19:57,020 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8795970583503897, 'Total loss': 0.8795970583503897} | train loss {'Reaction outcome loss': 0.8057998865239533, 'Total loss': 0.8057998865239533}
2022-11-18 01:19:57,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:57,020 INFO:     Epoch: 56
2022-11-18 01:19:57,812 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8494487696073272, 'Total loss': 0.8494487696073272} | train loss {'Reaction outcome loss': 0.8089185843342229, 'Total loss': 0.8089185843342229}
2022-11-18 01:19:57,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:57,812 INFO:     Epoch: 57
2022-11-18 01:19:58,647 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8365327580408617, 'Total loss': 0.8365327580408617} | train loss {'Reaction outcome loss': 0.8169392113260895, 'Total loss': 0.8169392113260895}
2022-11-18 01:19:58,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:58,647 INFO:     Epoch: 58
2022-11-18 01:19:59,425 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8351941562511704, 'Total loss': 0.8351941562511704} | train loss {'Reaction outcome loss': 0.8097866975404473, 'Total loss': 0.8097866975404473}
2022-11-18 01:19:59,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:19:59,426 INFO:     Epoch: 59
2022-11-18 01:20:00,219 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8377440829168666, 'Total loss': 0.8377440829168666} | train loss {'Reaction outcome loss': 0.8052168778381367, 'Total loss': 0.8052168778381367}
2022-11-18 01:20:00,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:00,220 INFO:     Epoch: 60
2022-11-18 01:20:00,985 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8397589705207131, 'Total loss': 0.8397589705207131} | train loss {'Reaction outcome loss': 0.8151851063556517, 'Total loss': 0.8151851063556517}
2022-11-18 01:20:00,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:00,986 INFO:     Epoch: 61
2022-11-18 01:20:01,780 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.839323335073211, 'Total loss': 0.839323335073211} | train loss {'Reaction outcome loss': 0.8209775978254403, 'Total loss': 0.8209775978254403}
2022-11-18 01:20:01,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:01,780 INFO:     Epoch: 62
2022-11-18 01:20:02,585 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8428270850669254, 'Total loss': 0.8428270850669254} | train loss {'Reaction outcome loss': 0.8119986070553783, 'Total loss': 0.8119986070553783}
2022-11-18 01:20:02,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:02,585 INFO:     Epoch: 63
2022-11-18 01:20:03,373 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8449159386483106, 'Total loss': 0.8449159386483106} | train loss {'Reaction outcome loss': 0.8058495321857785, 'Total loss': 0.8058495321857785}
2022-11-18 01:20:03,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:03,373 INFO:     Epoch: 64
2022-11-18 01:20:04,205 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8434608219699427, 'Total loss': 0.8434608219699427} | train loss {'Reaction outcome loss': 0.8042314235377408, 'Total loss': 0.8042314235377408}
2022-11-18 01:20:04,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:04,205 INFO:     Epoch: 65
2022-11-18 01:20:05,006 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8360487805171446, 'Total loss': 0.8360487805171446} | train loss {'Reaction outcome loss': 0.8075345112727239, 'Total loss': 0.8075345112727239}
2022-11-18 01:20:05,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:05,006 INFO:     Epoch: 66
2022-11-18 01:20:05,820 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8398741781711578, 'Total loss': 0.8398741781711578} | train loss {'Reaction outcome loss': 0.8062650301919775, 'Total loss': 0.8062650301919775}
2022-11-18 01:20:05,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:05,820 INFO:     Epoch: 67
2022-11-18 01:20:06,649 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8418909081003882, 'Total loss': 0.8418909081003882} | train loss {'Reaction outcome loss': 0.8042049568433028, 'Total loss': 0.8042049568433028}
2022-11-18 01:20:06,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:06,649 INFO:     Epoch: 68
2022-11-18 01:20:07,478 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8255762593312697, 'Total loss': 0.8255762593312697} | train loss {'Reaction outcome loss': 0.8074962685359754, 'Total loss': 0.8074962685359754}
2022-11-18 01:20:07,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:07,479 INFO:     Epoch: 69
2022-11-18 01:20:08,302 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8365758095275272, 'Total loss': 0.8365758095275272} | train loss {'Reaction outcome loss': 0.8029331459931517, 'Total loss': 0.8029331459931517}
2022-11-18 01:20:08,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:08,302 INFO:     Epoch: 70
2022-11-18 01:20:09,098 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8365167453885078, 'Total loss': 0.8365167453885078} | train loss {'Reaction outcome loss': 0.8136544598017627, 'Total loss': 0.8136544598017627}
2022-11-18 01:20:09,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:09,098 INFO:     Epoch: 71
2022-11-18 01:20:09,886 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8458459241823717, 'Total loss': 0.8458459241823717} | train loss {'Reaction outcome loss': 0.8051526900003796, 'Total loss': 0.8051526900003796}
2022-11-18 01:20:09,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:09,886 INFO:     Epoch: 72
2022-11-18 01:20:10,686 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.850636019625447, 'Total loss': 0.850636019625447} | train loss {'Reaction outcome loss': 0.8111072826964653, 'Total loss': 0.8111072826964653}
2022-11-18 01:20:10,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:10,686 INFO:     Epoch: 73
2022-11-18 01:20:11,444 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8387980887835677, 'Total loss': 0.8387980887835677} | train loss {'Reaction outcome loss': 0.8075409438687298, 'Total loss': 0.8075409438687298}
2022-11-18 01:20:11,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:11,444 INFO:     Epoch: 74
2022-11-18 01:20:12,245 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8487339128147472, 'Total loss': 0.8487339128147472} | train loss {'Reaction outcome loss': 0.8025403509014531, 'Total loss': 0.8025403509014531}
2022-11-18 01:20:12,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:12,246 INFO:     Epoch: 75
2022-11-18 01:20:13,025 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8443727100437338, 'Total loss': 0.8443727100437338} | train loss {'Reaction outcome loss': 0.8095024559903241, 'Total loss': 0.8095024559903241}
2022-11-18 01:20:13,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:13,027 INFO:     Epoch: 76
2022-11-18 01:20:13,814 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8369137048721313, 'Total loss': 0.8369137048721313} | train loss {'Reaction outcome loss': 0.8126226038585308, 'Total loss': 0.8126226038585308}
2022-11-18 01:20:13,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:13,815 INFO:     Epoch: 77
2022-11-18 01:20:14,619 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8557352748784152, 'Total loss': 0.8557352748784152} | train loss {'Reaction outcome loss': 0.8082368356978845, 'Total loss': 0.8082368356978845}
2022-11-18 01:20:14,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:14,619 INFO:     Epoch: 78
2022-11-18 01:20:15,397 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8291139981963418, 'Total loss': 0.8291139981963418} | train loss {'Reaction outcome loss': 0.808284808025669, 'Total loss': 0.808284808025669}
2022-11-18 01:20:15,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:15,397 INFO:     Epoch: 79
2022-11-18 01:20:16,200 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8332258117469874, 'Total loss': 0.8332258117469874} | train loss {'Reaction outcome loss': 0.8115362549117702, 'Total loss': 0.8115362549117702}
2022-11-18 01:20:16,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:16,200 INFO:     Epoch: 80
2022-11-18 01:20:16,979 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8661434203386307, 'Total loss': 0.8661434203386307} | train loss {'Reaction outcome loss': 0.8135976498184899, 'Total loss': 0.8135976498184899}
2022-11-18 01:20:16,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:16,980 INFO:     Epoch: 81
2022-11-18 01:20:17,766 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8288816931572828, 'Total loss': 0.8288816931572828} | train loss {'Reaction outcome loss': 0.8103638723311637, 'Total loss': 0.8103638723311637}
2022-11-18 01:20:17,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:17,766 INFO:     Epoch: 82
2022-11-18 01:20:18,566 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8252858404408802, 'Total loss': 0.8252858404408802} | train loss {'Reaction outcome loss': 0.8036160195917494, 'Total loss': 0.8036160195917494}
2022-11-18 01:20:18,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:18,566 INFO:     Epoch: 83
2022-11-18 01:20:19,374 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8374052968892184, 'Total loss': 0.8374052968892184} | train loss {'Reaction outcome loss': 0.8073130800173833, 'Total loss': 0.8073130800173833}
2022-11-18 01:20:19,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:19,375 INFO:     Epoch: 84
2022-11-18 01:20:20,218 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8345443674109199, 'Total loss': 0.8345443674109199} | train loss {'Reaction outcome loss': 0.8088716719797265, 'Total loss': 0.8088716719797265}
2022-11-18 01:20:20,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:20,218 INFO:     Epoch: 85
2022-11-18 01:20:21,046 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.822567303749648, 'Total loss': 0.822567303749648} | train loss {'Reaction outcome loss': 0.8137364800159748, 'Total loss': 0.8137364800159748}
2022-11-18 01:20:21,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:21,046 INFO:     Epoch: 86
2022-11-18 01:20:21,911 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8351808921857313, 'Total loss': 0.8351808921857313} | train loss {'Reaction outcome loss': 0.8106445265323045, 'Total loss': 0.8106445265323045}
2022-11-18 01:20:21,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:21,911 INFO:     Epoch: 87
2022-11-18 01:20:22,737 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8515348759564486, 'Total loss': 0.8515348759564486} | train loss {'Reaction outcome loss': 0.8030192365771845, 'Total loss': 0.8030192365771845}
2022-11-18 01:20:22,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:22,737 INFO:     Epoch: 88
2022-11-18 01:20:23,570 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8189855448224328, 'Total loss': 0.8189855448224328} | train loss {'Reaction outcome loss': 0.8057853258573092, 'Total loss': 0.8057853258573092}
2022-11-18 01:20:23,570 INFO:     Found new best model at epoch 88
2022-11-18 01:20:23,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:23,571 INFO:     Epoch: 89
2022-11-18 01:20:24,381 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.821510982784358, 'Total loss': 0.821510982784358} | train loss {'Reaction outcome loss': 0.808662606033719, 'Total loss': 0.808662606033719}
2022-11-18 01:20:24,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:24,382 INFO:     Epoch: 90
2022-11-18 01:20:25,180 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8304786519570784, 'Total loss': 0.8304786519570784} | train loss {'Reaction outcome loss': 0.8115312408821785, 'Total loss': 0.8115312408821785}
2022-11-18 01:20:25,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:25,180 INFO:     Epoch: 91
2022-11-18 01:20:25,972 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8388191522522406, 'Total loss': 0.8388191522522406} | train loss {'Reaction outcome loss': 0.8138752243055506, 'Total loss': 0.8138752243055506}
2022-11-18 01:20:25,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:25,972 INFO:     Epoch: 92
2022-11-18 01:20:26,779 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.837684459306977, 'Total loss': 0.837684459306977} | train loss {'Reaction outcome loss': 0.7992226522461123, 'Total loss': 0.7992226522461123}
2022-11-18 01:20:26,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:26,779 INFO:     Epoch: 93
2022-11-18 01:20:27,570 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8356670452789827, 'Total loss': 0.8356670452789827} | train loss {'Reaction outcome loss': 0.813677248805158, 'Total loss': 0.813677248805158}
2022-11-18 01:20:27,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:27,570 INFO:     Epoch: 94
2022-11-18 01:20:28,397 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8313443078236147, 'Total loss': 0.8313443078236147} | train loss {'Reaction outcome loss': 0.8026548646360274, 'Total loss': 0.8026548646360274}
2022-11-18 01:20:28,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:28,398 INFO:     Epoch: 95
2022-11-18 01:20:29,201 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8430814214728095, 'Total loss': 0.8430814214728095} | train loss {'Reaction outcome loss': 0.8039314958610033, 'Total loss': 0.8039314958610033}
2022-11-18 01:20:29,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:29,201 INFO:     Epoch: 96
2022-11-18 01:20:29,979 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.84408215907487, 'Total loss': 0.84408215907487} | train loss {'Reaction outcome loss': 0.8082510328244584, 'Total loss': 0.8082510328244584}
2022-11-18 01:20:29,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:29,979 INFO:     Epoch: 97
2022-11-18 01:20:30,825 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8358465108004484, 'Total loss': 0.8358465108004484} | train loss {'Reaction outcome loss': 0.8111419259053976, 'Total loss': 0.8111419259053976}
2022-11-18 01:20:30,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:30,825 INFO:     Epoch: 98
2022-11-18 01:20:31,636 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8324021846055984, 'Total loss': 0.8324021846055984} | train loss {'Reaction outcome loss': 0.8078784573415996, 'Total loss': 0.8078784573415996}
2022-11-18 01:20:31,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:31,637 INFO:     Epoch: 99
2022-11-18 01:20:32,454 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8382794213565913, 'Total loss': 0.8382794213565913} | train loss {'Reaction outcome loss': 0.7985295007827311, 'Total loss': 0.7985295007827311}
2022-11-18 01:20:32,454 INFO:     Best model found after epoch 89 of 100.
2022-11-18 01:20:32,454 INFO:   Done with stage: TRAINING
2022-11-18 01:20:32,454 INFO:   Starting stage: EVALUATION
2022-11-18 01:20:32,577 INFO:   Done with stage: EVALUATION
2022-11-18 01:20:32,586 INFO:   Leaving out SEQ value Fold_0
2022-11-18 01:20:32,599 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:20:32,599 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:20:33,269 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:20:33,269 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:20:33,340 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:20:33,340 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:20:33,340 INFO:     No hyperparam tuning for this model
2022-11-18 01:20:33,340 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:20:33,340 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:20:33,341 INFO:     None feature selector for col prot
2022-11-18 01:20:33,341 INFO:     None feature selector for col prot
2022-11-18 01:20:33,341 INFO:     None feature selector for col prot
2022-11-18 01:20:33,342 INFO:     None feature selector for col chem
2022-11-18 01:20:33,342 INFO:     None feature selector for col chem
2022-11-18 01:20:33,342 INFO:     None feature selector for col chem
2022-11-18 01:20:33,342 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:20:33,342 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:20:33,344 INFO:     Number of params in model 168571
2022-11-18 01:20:33,347 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:20:33,347 INFO:   Starting stage: TRAINING
2022-11-18 01:20:33,405 INFO:     Val loss before train {'Reaction outcome loss': 0.9659444418820468, 'Total loss': 0.9659444418820468}
2022-11-18 01:20:33,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:33,405 INFO:     Epoch: 0
2022-11-18 01:20:34,246 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8066556690768762, 'Total loss': 0.8066556690768762} | train loss {'Reaction outcome loss': 0.8903103054535051, 'Total loss': 0.8903103054535051}
2022-11-18 01:20:34,246 INFO:     Found new best model at epoch 0
2022-11-18 01:20:34,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:34,247 INFO:     Epoch: 1
2022-11-18 01:20:35,085 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7849075137214228, 'Total loss': 0.7849075137214228} | train loss {'Reaction outcome loss': 0.8632199132008108, 'Total loss': 0.8632199132008108}
2022-11-18 01:20:35,085 INFO:     Found new best model at epoch 1
2022-11-18 01:20:35,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:35,086 INFO:     Epoch: 2
2022-11-18 01:20:35,930 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.808950581333854, 'Total loss': 0.808950581333854} | train loss {'Reaction outcome loss': 0.8431983361480689, 'Total loss': 0.8431983361480689}
2022-11-18 01:20:35,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:35,930 INFO:     Epoch: 3
2022-11-18 01:20:36,788 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8197123042561791, 'Total loss': 0.8197123042561791} | train loss {'Reaction outcome loss': 0.8346511391010362, 'Total loss': 0.8346511391010362}
2022-11-18 01:20:36,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:36,789 INFO:     Epoch: 4
2022-11-18 01:20:37,567 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7971044690771536, 'Total loss': 0.7971044690771536} | train loss {'Reaction outcome loss': 0.8397067083038299, 'Total loss': 0.8397067083038299}
2022-11-18 01:20:37,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:37,567 INFO:     Epoch: 5
2022-11-18 01:20:38,368 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7987040525132959, 'Total loss': 0.7987040525132959} | train loss {'Reaction outcome loss': 0.8336877393336432, 'Total loss': 0.8336877393336432}
2022-11-18 01:20:38,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:38,368 INFO:     Epoch: 6
2022-11-18 01:20:39,164 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.768495957959782, 'Total loss': 0.768495957959782} | train loss {'Reaction outcome loss': 0.8349505857176144, 'Total loss': 0.8349505857176144}
2022-11-18 01:20:39,164 INFO:     Found new best model at epoch 6
2022-11-18 01:20:39,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:39,165 INFO:     Epoch: 7
2022-11-18 01:20:39,983 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7994400432164018, 'Total loss': 0.7994400432164018} | train loss {'Reaction outcome loss': 0.8314346485292381, 'Total loss': 0.8314346485292381}
2022-11-18 01:20:39,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:39,983 INFO:     Epoch: 8
2022-11-18 01:20:40,779 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7972757328640331, 'Total loss': 0.7972757328640331} | train loss {'Reaction outcome loss': 0.8351275840027612, 'Total loss': 0.8351275840027612}
2022-11-18 01:20:40,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:40,779 INFO:     Epoch: 9
2022-11-18 01:20:41,591 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8159859336235307, 'Total loss': 0.8159859336235307} | train loss {'Reaction outcome loss': 0.8387182492476243, 'Total loss': 0.8387182492476243}
2022-11-18 01:20:41,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:41,592 INFO:     Epoch: 10
2022-11-18 01:20:42,391 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8061192672361027, 'Total loss': 0.8061192672361027} | train loss {'Reaction outcome loss': 0.8256562030025822, 'Total loss': 0.8256562030025822}
2022-11-18 01:20:42,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:42,391 INFO:     Epoch: 11
2022-11-18 01:20:43,196 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7811361219395291, 'Total loss': 0.7811361219395291} | train loss {'Reaction outcome loss': 0.825044221361639, 'Total loss': 0.825044221361639}
2022-11-18 01:20:43,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:43,196 INFO:     Epoch: 12
2022-11-18 01:20:44,002 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8074037154967134, 'Total loss': 0.8074037154967134} | train loss {'Reaction outcome loss': 0.8336792609952239, 'Total loss': 0.8336792609952239}
2022-11-18 01:20:44,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:44,004 INFO:     Epoch: 13
2022-11-18 01:20:44,778 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7779239206151529, 'Total loss': 0.7779239206151529} | train loss {'Reaction outcome loss': 0.8281536797280253, 'Total loss': 0.8281536797280253}
2022-11-18 01:20:44,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:44,779 INFO:     Epoch: 14
2022-11-18 01:20:45,590 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8013897477225824, 'Total loss': 0.8013897477225824} | train loss {'Reaction outcome loss': 0.819656266314298, 'Total loss': 0.819656266314298}
2022-11-18 01:20:45,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:45,590 INFO:     Epoch: 15
2022-11-18 01:20:46,379 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7848495962944898, 'Total loss': 0.7848495962944898} | train loss {'Reaction outcome loss': 0.825503929544557, 'Total loss': 0.825503929544557}
2022-11-18 01:20:46,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:46,380 INFO:     Epoch: 16
2022-11-18 01:20:47,185 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7834812009876425, 'Total loss': 0.7834812009876425} | train loss {'Reaction outcome loss': 0.8382116209881508, 'Total loss': 0.8382116209881508}
2022-11-18 01:20:47,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:47,186 INFO:     Epoch: 17
2022-11-18 01:20:47,982 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7878554781729524, 'Total loss': 0.7878554781729524} | train loss {'Reaction outcome loss': 0.8310876505577612, 'Total loss': 0.8310876505577612}
2022-11-18 01:20:47,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:47,982 INFO:     Epoch: 18
2022-11-18 01:20:48,803 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7971473376859318, 'Total loss': 0.7971473376859318} | train loss {'Reaction outcome loss': 0.8243210668023299, 'Total loss': 0.8243210668023299}
2022-11-18 01:20:48,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:48,803 INFO:     Epoch: 19
2022-11-18 01:20:49,641 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7751433053477244, 'Total loss': 0.7751433053477244} | train loss {'Reaction outcome loss': 0.8267004300466916, 'Total loss': 0.8267004300466916}
2022-11-18 01:20:49,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:49,641 INFO:     Epoch: 20
2022-11-18 01:20:50,456 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7893097224560651, 'Total loss': 0.7893097224560651} | train loss {'Reaction outcome loss': 0.8238952991209532, 'Total loss': 0.8238952991209532}
2022-11-18 01:20:50,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:50,457 INFO:     Epoch: 21
2022-11-18 01:20:51,245 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7850491641597315, 'Total loss': 0.7850491641597315} | train loss {'Reaction outcome loss': 0.8223034369076795, 'Total loss': 0.8223034369076795}
2022-11-18 01:20:51,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:51,245 INFO:     Epoch: 22
2022-11-18 01:20:52,069 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7762833047996868, 'Total loss': 0.7762833047996868} | train loss {'Reaction outcome loss': 0.8204662151906171, 'Total loss': 0.8204662151906171}
2022-11-18 01:20:52,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:52,070 INFO:     Epoch: 23
2022-11-18 01:20:52,900 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.771991416811943, 'Total loss': 0.771991416811943} | train loss {'Reaction outcome loss': 0.8291560100157734, 'Total loss': 0.8291560100157734}
2022-11-18 01:20:52,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:52,901 INFO:     Epoch: 24
2022-11-18 01:20:53,705 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7620890201492743, 'Total loss': 0.7620890201492743} | train loss {'Reaction outcome loss': 0.8236986487983209, 'Total loss': 0.8236986487983209}
2022-11-18 01:20:53,705 INFO:     Found new best model at epoch 24
2022-11-18 01:20:53,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:53,706 INFO:     Epoch: 25
2022-11-18 01:20:54,510 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7823605977676131, 'Total loss': 0.7823605977676131} | train loss {'Reaction outcome loss': 0.8224069151559822, 'Total loss': 0.8224069151559822}
2022-11-18 01:20:54,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:54,510 INFO:     Epoch: 26
2022-11-18 01:20:55,362 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7990872629664161, 'Total loss': 0.7990872629664161} | train loss {'Reaction outcome loss': 0.8259879584737152, 'Total loss': 0.8259879584737152}
2022-11-18 01:20:55,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:55,363 INFO:     Epoch: 27
2022-11-18 01:20:56,184 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7781815528869629, 'Total loss': 0.7781815528869629} | train loss {'Reaction outcome loss': 0.8215578964605987, 'Total loss': 0.8215578964605987}
2022-11-18 01:20:56,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:56,184 INFO:     Epoch: 28
2022-11-18 01:20:56,996 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7846204963597384, 'Total loss': 0.7846204963597384} | train loss {'Reaction outcome loss': 0.8263780613418533, 'Total loss': 0.8263780613418533}
2022-11-18 01:20:56,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:56,996 INFO:     Epoch: 29
2022-11-18 01:20:57,823 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8175419142300432, 'Total loss': 0.8175419142300432} | train loss {'Reaction outcome loss': 0.8225976900774458, 'Total loss': 0.8225976900774458}
2022-11-18 01:20:57,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:57,823 INFO:     Epoch: 30
2022-11-18 01:20:58,630 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.781830140135505, 'Total loss': 0.781830140135505} | train loss {'Reaction outcome loss': 0.8258805087944756, 'Total loss': 0.8258805087944756}
2022-11-18 01:20:58,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:58,631 INFO:     Epoch: 31
2022-11-18 01:20:59,418 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7791030718521639, 'Total loss': 0.7791030718521639} | train loss {'Reaction outcome loss': 0.8231985486953365, 'Total loss': 0.8231985486953365}
2022-11-18 01:20:59,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:20:59,419 INFO:     Epoch: 32
2022-11-18 01:21:00,212 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7860585098916834, 'Total loss': 0.7860585098916834} | train loss {'Reaction outcome loss': 0.8257770189630841, 'Total loss': 0.8257770189630841}
2022-11-18 01:21:00,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:00,212 INFO:     Epoch: 33
2022-11-18 01:21:01,044 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7673325105146929, 'Total loss': 0.7673325105146929} | train loss {'Reaction outcome loss': 0.8187909390520953, 'Total loss': 0.8187909390520953}
2022-11-18 01:21:01,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:01,044 INFO:     Epoch: 34
2022-11-18 01:21:01,901 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7715109620581974, 'Total loss': 0.7715109620581974} | train loss {'Reaction outcome loss': 0.8223261928510087, 'Total loss': 0.8223261928510087}
2022-11-18 01:21:01,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:01,902 INFO:     Epoch: 35
2022-11-18 01:21:02,694 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7827098762447183, 'Total loss': 0.7827098762447183} | train loss {'Reaction outcome loss': 0.8227825461611574, 'Total loss': 0.8227825461611574}
2022-11-18 01:21:02,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:02,695 INFO:     Epoch: 36
2022-11-18 01:21:03,527 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7742073474959894, 'Total loss': 0.7742073474959894} | train loss {'Reaction outcome loss': 0.8166740692337515, 'Total loss': 0.8166740692337515}
2022-11-18 01:21:03,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:03,527 INFO:     Epoch: 37
2022-11-18 01:21:04,367 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7711576927791942, 'Total loss': 0.7711576927791942} | train loss {'Reaction outcome loss': 0.8255012394928256, 'Total loss': 0.8255012394928256}
2022-11-18 01:21:04,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:04,367 INFO:     Epoch: 38
2022-11-18 01:21:05,204 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7913157181306318, 'Total loss': 0.7913157181306318} | train loss {'Reaction outcome loss': 0.8262655219809729, 'Total loss': 0.8262655219809729}
2022-11-18 01:21:05,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:05,204 INFO:     Epoch: 39
2022-11-18 01:21:06,033 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7848253900354559, 'Total loss': 0.7848253900354559} | train loss {'Reaction outcome loss': 0.8222824081718197, 'Total loss': 0.8222824081718197}
2022-11-18 01:21:06,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:06,033 INFO:     Epoch: 40
2022-11-18 01:21:06,885 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7815276519818739, 'Total loss': 0.7815276519818739} | train loss {'Reaction outcome loss': 0.8196257801673673, 'Total loss': 0.8196257801673673}
2022-11-18 01:21:06,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:06,885 INFO:     Epoch: 41
2022-11-18 01:21:07,742 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.777948992496187, 'Total loss': 0.777948992496187} | train loss {'Reaction outcome loss': 0.8227359292960843, 'Total loss': 0.8227359292960843}
2022-11-18 01:21:07,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:07,742 INFO:     Epoch: 42
2022-11-18 01:21:08,592 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7687282968651165, 'Total loss': 0.7687282968651165} | train loss {'Reaction outcome loss': 0.8221450801561718, 'Total loss': 0.8221450801561718}
2022-11-18 01:21:08,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:08,593 INFO:     Epoch: 43
2022-11-18 01:21:09,400 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7603540881113573, 'Total loss': 0.7603540881113573} | train loss {'Reaction outcome loss': 0.8208755360923798, 'Total loss': 0.8208755360923798}
2022-11-18 01:21:09,400 INFO:     Found new best model at epoch 43
2022-11-18 01:21:09,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:09,401 INFO:     Epoch: 44
2022-11-18 01:21:10,237 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7790196057070385, 'Total loss': 0.7790196057070385} | train loss {'Reaction outcome loss': 0.8190964207294499, 'Total loss': 0.8190964207294499}
2022-11-18 01:21:10,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:10,238 INFO:     Epoch: 45
2022-11-18 01:21:11,054 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7705630897120996, 'Total loss': 0.7705630897120996} | train loss {'Reaction outcome loss': 0.8193527387703962, 'Total loss': 0.8193527387703962}
2022-11-18 01:21:11,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:11,055 INFO:     Epoch: 46
2022-11-18 01:21:11,883 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7744064852595329, 'Total loss': 0.7744064852595329} | train loss {'Reaction outcome loss': 0.8240047032051241, 'Total loss': 0.8240047032051241}
2022-11-18 01:21:11,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:11,883 INFO:     Epoch: 47
2022-11-18 01:21:12,720 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7996070425618779, 'Total loss': 0.7996070425618779} | train loss {'Reaction outcome loss': 0.8208686668380551, 'Total loss': 0.8208686668380551}
2022-11-18 01:21:12,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:12,721 INFO:     Epoch: 48
2022-11-18 01:21:13,550 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7965902428735386, 'Total loss': 0.7965902428735386} | train loss {'Reaction outcome loss': 0.8168028409061162, 'Total loss': 0.8168028409061162}
2022-11-18 01:21:13,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:13,550 INFO:     Epoch: 49
2022-11-18 01:21:14,357 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7829550701108846, 'Total loss': 0.7829550701108846} | train loss {'Reaction outcome loss': 0.8283685255147185, 'Total loss': 0.8283685255147185}
2022-11-18 01:21:14,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:14,357 INFO:     Epoch: 50
2022-11-18 01:21:15,146 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7865069196982817, 'Total loss': 0.7865069196982817} | train loss {'Reaction outcome loss': 0.8218006188811561, 'Total loss': 0.8218006188811561}
2022-11-18 01:21:15,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:15,148 INFO:     Epoch: 51
2022-11-18 01:21:15,949 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7634222358465195, 'Total loss': 0.7634222358465195} | train loss {'Reaction outcome loss': 0.8239192404003761, 'Total loss': 0.8239192404003761}
2022-11-18 01:21:15,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:15,950 INFO:     Epoch: 52
2022-11-18 01:21:16,801 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.781875342130661, 'Total loss': 0.781875342130661} | train loss {'Reaction outcome loss': 0.8168222244964679, 'Total loss': 0.8168222244964679}
2022-11-18 01:21:16,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:16,801 INFO:     Epoch: 53
2022-11-18 01:21:17,649 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8384828851981596, 'Total loss': 0.8384828851981596} | train loss {'Reaction outcome loss': 0.8223433227915513, 'Total loss': 0.8223433227915513}
2022-11-18 01:21:17,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:17,649 INFO:     Epoch: 54
2022-11-18 01:21:18,473 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7805569551207803, 'Total loss': 0.7805569551207803} | train loss {'Reaction outcome loss': 0.8248919533331868, 'Total loss': 0.8248919533331868}
2022-11-18 01:21:18,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:18,474 INFO:     Epoch: 55
2022-11-18 01:21:19,303 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7650573036887429, 'Total loss': 0.7650573036887429} | train loss {'Reaction outcome loss': 0.8204423681444485, 'Total loss': 0.8204423681444485}
2022-11-18 01:21:19,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:19,303 INFO:     Epoch: 56
2022-11-18 01:21:20,083 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.784199749881571, 'Total loss': 0.784199749881571} | train loss {'Reaction outcome loss': 0.8295164888928294, 'Total loss': 0.8295164888928294}
2022-11-18 01:21:20,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:20,083 INFO:     Epoch: 57
2022-11-18 01:21:20,874 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7737616463141008, 'Total loss': 0.7737616463141008} | train loss {'Reaction outcome loss': 0.8227454392533553, 'Total loss': 0.8227454392533553}
2022-11-18 01:21:20,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:20,874 INFO:     Epoch: 58
2022-11-18 01:21:21,700 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.768550880253315, 'Total loss': 0.768550880253315} | train loss {'Reaction outcome loss': 0.8180864919052433, 'Total loss': 0.8180864919052433}
2022-11-18 01:21:21,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:21,701 INFO:     Epoch: 59
2022-11-18 01:21:22,517 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7787828851829875, 'Total loss': 0.7787828851829875} | train loss {'Reaction outcome loss': 0.8293419502042083, 'Total loss': 0.8293419502042083}
2022-11-18 01:21:22,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:22,517 INFO:     Epoch: 60
2022-11-18 01:21:23,343 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7803350050340999, 'Total loss': 0.7803350050340999} | train loss {'Reaction outcome loss': 0.8215407894600016, 'Total loss': 0.8215407894600016}
2022-11-18 01:21:23,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:23,343 INFO:     Epoch: 61
2022-11-18 01:21:24,156 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7726125324314291, 'Total loss': 0.7726125324314291} | train loss {'Reaction outcome loss': 0.8127372765287697, 'Total loss': 0.8127372765287697}
2022-11-18 01:21:24,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:24,157 INFO:     Epoch: 62
2022-11-18 01:21:24,936 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.806553527712822, 'Total loss': 0.806553527712822} | train loss {'Reaction outcome loss': 0.8181033542281703, 'Total loss': 0.8181033542281703}
2022-11-18 01:21:24,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:24,937 INFO:     Epoch: 63
2022-11-18 01:21:25,739 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7698929174379869, 'Total loss': 0.7698929174379869} | train loss {'Reaction outcome loss': 0.8244888228081498, 'Total loss': 0.8244888228081498}
2022-11-18 01:21:25,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:25,740 INFO:     Epoch: 64
2022-11-18 01:21:26,549 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.77207386019555, 'Total loss': 0.77207386019555} | train loss {'Reaction outcome loss': 0.8214273529979381, 'Total loss': 0.8214273529979381}
2022-11-18 01:21:26,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:26,549 INFO:     Epoch: 65
2022-11-18 01:21:27,336 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7771118879318237, 'Total loss': 0.7771118879318237} | train loss {'Reaction outcome loss': 0.8146348840553268, 'Total loss': 0.8146348840553268}
2022-11-18 01:21:27,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:27,336 INFO:     Epoch: 66
2022-11-18 01:21:28,119 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7812861786647276, 'Total loss': 0.7812861786647276} | train loss {'Reaction outcome loss': 0.8172183722740243, 'Total loss': 0.8172183722740243}
2022-11-18 01:21:28,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:28,119 INFO:     Epoch: 67
2022-11-18 01:21:28,887 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.777197505262765, 'Total loss': 0.777197505262765} | train loss {'Reaction outcome loss': 0.8211088620940683, 'Total loss': 0.8211088620940683}
2022-11-18 01:21:28,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:28,888 INFO:     Epoch: 68
2022-11-18 01:21:29,691 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7690016058358279, 'Total loss': 0.7690016058358279} | train loss {'Reaction outcome loss': 0.8196602443813795, 'Total loss': 0.8196602443813795}
2022-11-18 01:21:29,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:29,691 INFO:     Epoch: 69
2022-11-18 01:21:30,474 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7919429012320258, 'Total loss': 0.7919429012320258} | train loss {'Reaction outcome loss': 0.8186744008710992, 'Total loss': 0.8186744008710992}
2022-11-18 01:21:30,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:30,474 INFO:     Epoch: 70
2022-11-18 01:21:31,258 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7742761156775735, 'Total loss': 0.7742761156775735} | train loss {'Reaction outcome loss': 0.8178042830363942, 'Total loss': 0.8178042830363942}
2022-11-18 01:21:31,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:31,258 INFO:     Epoch: 71
2022-11-18 01:21:32,070 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7864778929136016, 'Total loss': 0.7864778929136016} | train loss {'Reaction outcome loss': 0.8304987920199328, 'Total loss': 0.8304987920199328}
2022-11-18 01:21:32,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:32,070 INFO:     Epoch: 72
2022-11-18 01:21:32,871 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7837649895386263, 'Total loss': 0.7837649895386263} | train loss {'Reaction outcome loss': 0.821846688807252, 'Total loss': 0.821846688807252}
2022-11-18 01:21:32,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:32,871 INFO:     Epoch: 73
2022-11-18 01:21:33,698 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8021840642799031, 'Total loss': 0.8021840642799031} | train loss {'Reaction outcome loss': 0.8285040242469263, 'Total loss': 0.8285040242469263}
2022-11-18 01:21:33,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:33,699 INFO:     Epoch: 74
2022-11-18 01:21:34,497 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7859671813520518, 'Total loss': 0.7859671813520518} | train loss {'Reaction outcome loss': 0.8207512832122293, 'Total loss': 0.8207512832122293}
2022-11-18 01:21:34,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:34,498 INFO:     Epoch: 75
2022-11-18 01:21:35,268 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7680947374213826, 'Total loss': 0.7680947374213826} | train loss {'Reaction outcome loss': 0.8167535991441865, 'Total loss': 0.8167535991441865}
2022-11-18 01:21:35,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:35,268 INFO:     Epoch: 76
2022-11-18 01:21:36,096 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7789801677519624, 'Total loss': 0.7789801677519624} | train loss {'Reaction outcome loss': 0.8185888784617065, 'Total loss': 0.8185888784617065}
2022-11-18 01:21:36,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:36,096 INFO:     Epoch: 77
2022-11-18 01:21:36,911 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.771938103843819, 'Total loss': 0.771938103843819} | train loss {'Reaction outcome loss': 0.8135911263073021, 'Total loss': 0.8135911263073021}
2022-11-18 01:21:36,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:36,912 INFO:     Epoch: 78
2022-11-18 01:21:37,731 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.780018379742449, 'Total loss': 0.780018379742449} | train loss {'Reaction outcome loss': 0.8215138129135857, 'Total loss': 0.8215138129135857}
2022-11-18 01:21:37,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:37,732 INFO:     Epoch: 79
2022-11-18 01:21:38,620 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7800251963463697, 'Total loss': 0.7800251963463697} | train loss {'Reaction outcome loss': 0.8203685343084548, 'Total loss': 0.8203685343084548}
2022-11-18 01:21:38,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:38,621 INFO:     Epoch: 80
2022-11-18 01:21:39,439 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.766463194381107, 'Total loss': 0.766463194381107} | train loss {'Reaction outcome loss': 0.8128917738191994, 'Total loss': 0.8128917738191994}
2022-11-18 01:21:39,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:39,439 INFO:     Epoch: 81
2022-11-18 01:21:40,247 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7667714072899385, 'Total loss': 0.7667714072899385} | train loss {'Reaction outcome loss': 0.8200962870468494, 'Total loss': 0.8200962870468494}
2022-11-18 01:21:40,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:40,247 INFO:     Epoch: 82
2022-11-18 01:21:41,055 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7623175071044401, 'Total loss': 0.7623175071044401} | train loss {'Reaction outcome loss': 0.8225360605639485, 'Total loss': 0.8225360605639485}
2022-11-18 01:21:41,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:41,056 INFO:     Epoch: 83
2022-11-18 01:21:41,924 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8107055530629375, 'Total loss': 0.8107055530629375} | train loss {'Reaction outcome loss': 0.8196671281748937, 'Total loss': 0.8196671281748937}
2022-11-18 01:21:41,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:41,924 INFO:     Epoch: 84
2022-11-18 01:21:42,749 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7764672054485842, 'Total loss': 0.7764672054485842} | train loss {'Reaction outcome loss': 0.8284334051705565, 'Total loss': 0.8284334051705565}
2022-11-18 01:21:42,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:42,750 INFO:     Epoch: 85
2022-11-18 01:21:43,575 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7784828645261851, 'Total loss': 0.7784828645261851} | train loss {'Reaction outcome loss': 0.8204081466323451, 'Total loss': 0.8204081466323451}
2022-11-18 01:21:43,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:43,576 INFO:     Epoch: 86
2022-11-18 01:21:44,390 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.76447689330036, 'Total loss': 0.76447689330036} | train loss {'Reaction outcome loss': 0.827350274995271, 'Total loss': 0.827350274995271}
2022-11-18 01:21:44,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:44,391 INFO:     Epoch: 87
2022-11-18 01:21:45,210 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7643285258249803, 'Total loss': 0.7643285258249803} | train loss {'Reaction outcome loss': 0.8224537803335228, 'Total loss': 0.8224537803335228}
2022-11-18 01:21:45,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:45,210 INFO:     Epoch: 88
2022-11-18 01:21:46,041 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7762136174873873, 'Total loss': 0.7762136174873873} | train loss {'Reaction outcome loss': 0.8158323017933108, 'Total loss': 0.8158323017933108}
2022-11-18 01:21:46,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:46,042 INFO:     Epoch: 89
2022-11-18 01:21:46,909 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7696544135158713, 'Total loss': 0.7696544135158713} | train loss {'Reaction outcome loss': 0.8195631499081729, 'Total loss': 0.8195631499081729}
2022-11-18 01:21:46,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:46,909 INFO:     Epoch: 90
2022-11-18 01:21:47,760 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7751919065009464, 'Total loss': 0.7751919065009464} | train loss {'Reaction outcome loss': 0.8155904111833225, 'Total loss': 0.8155904111833225}
2022-11-18 01:21:47,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:47,760 INFO:     Epoch: 91
2022-11-18 01:21:48,591 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7808026034723629, 'Total loss': 0.7808026034723629} | train loss {'Reaction outcome loss': 0.8145960028837567, 'Total loss': 0.8145960028837567}
2022-11-18 01:21:48,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:48,592 INFO:     Epoch: 92
2022-11-18 01:21:49,417 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.784787499091842, 'Total loss': 0.784787499091842} | train loss {'Reaction outcome loss': 0.8181913121026537, 'Total loss': 0.8181913121026537}
2022-11-18 01:21:49,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:49,418 INFO:     Epoch: 93
2022-11-18 01:21:50,226 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7696459896185182, 'Total loss': 0.7696459896185182} | train loss {'Reaction outcome loss': 0.8171807664035544, 'Total loss': 0.8171807664035544}
2022-11-18 01:21:50,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:50,226 INFO:     Epoch: 94
2022-11-18 01:21:51,066 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7758003053340045, 'Total loss': 0.7758003053340045} | train loss {'Reaction outcome loss': 0.8150041116635326, 'Total loss': 0.8150041116635326}
2022-11-18 01:21:51,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:51,066 INFO:     Epoch: 95
2022-11-18 01:21:51,897 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8179683245041154, 'Total loss': 0.8179683245041154} | train loss {'Reaction outcome loss': 0.8244643227050179, 'Total loss': 0.8244643227050179}
2022-11-18 01:21:51,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:51,897 INFO:     Epoch: 96
2022-11-18 01:21:52,727 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7883927043188702, 'Total loss': 0.7883927043188702} | train loss {'Reaction outcome loss': 0.8197446621140005, 'Total loss': 0.8197446621140005}
2022-11-18 01:21:52,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:52,728 INFO:     Epoch: 97
2022-11-18 01:21:53,550 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7789663780819286, 'Total loss': 0.7789663780819286} | train loss {'Reaction outcome loss': 0.8237502776418137, 'Total loss': 0.8237502776418137}
2022-11-18 01:21:53,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:53,551 INFO:     Epoch: 98
2022-11-18 01:21:54,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7755553444678133, 'Total loss': 0.7755553444678133} | train loss {'Reaction outcome loss': 0.8207175822151818, 'Total loss': 0.8207175822151818}
2022-11-18 01:21:54,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:54,388 INFO:     Epoch: 99
2022-11-18 01:21:55,214 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7943502156571909, 'Total loss': 0.7943502156571909} | train loss {'Reaction outcome loss': 0.8149065225713166, 'Total loss': 0.8149065225713166}
2022-11-18 01:21:55,215 INFO:     Best model found after epoch 44 of 100.
2022-11-18 01:21:55,215 INFO:   Done with stage: TRAINING
2022-11-18 01:21:55,215 INFO:   Starting stage: EVALUATION
2022-11-18 01:21:55,339 INFO:   Done with stage: EVALUATION
2022-11-18 01:21:55,339 INFO:   Leaving out SEQ value Fold_1
2022-11-18 01:21:55,352 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:21:55,352 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:21:56,025 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:21:56,025 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:21:56,098 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:21:56,099 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:21:56,099 INFO:     No hyperparam tuning for this model
2022-11-18 01:21:56,099 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:21:56,099 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:21:56,100 INFO:     None feature selector for col prot
2022-11-18 01:21:56,100 INFO:     None feature selector for col prot
2022-11-18 01:21:56,100 INFO:     None feature selector for col prot
2022-11-18 01:21:56,100 INFO:     None feature selector for col chem
2022-11-18 01:21:56,101 INFO:     None feature selector for col chem
2022-11-18 01:21:56,101 INFO:     None feature selector for col chem
2022-11-18 01:21:56,101 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:21:56,101 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:21:56,102 INFO:     Number of params in model 168571
2022-11-18 01:21:56,106 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:21:56,106 INFO:   Starting stage: TRAINING
2022-11-18 01:21:56,167 INFO:     Val loss before train {'Reaction outcome loss': 0.9849248718131672, 'Total loss': 0.9849248718131672}
2022-11-18 01:21:56,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:56,167 INFO:     Epoch: 0
2022-11-18 01:21:56,982 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8278436240824786, 'Total loss': 0.8278436240824786} | train loss {'Reaction outcome loss': 0.88258766560902, 'Total loss': 0.88258766560902}
2022-11-18 01:21:56,982 INFO:     Found new best model at epoch 0
2022-11-18 01:21:56,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:56,983 INFO:     Epoch: 1
2022-11-18 01:21:57,802 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8279897252267058, 'Total loss': 0.8279897252267058} | train loss {'Reaction outcome loss': 0.8419388468388603, 'Total loss': 0.8419388468388603}
2022-11-18 01:21:57,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:57,803 INFO:     Epoch: 2
2022-11-18 01:21:58,647 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8359664637934078, 'Total loss': 0.8359664637934078} | train loss {'Reaction outcome loss': 0.8404844311567453, 'Total loss': 0.8404844311567453}
2022-11-18 01:21:58,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:58,647 INFO:     Epoch: 3
2022-11-18 01:21:59,445 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8204712759364735, 'Total loss': 0.8204712759364735} | train loss {'Reaction outcome loss': 0.8402301770472816, 'Total loss': 0.8402301770472816}
2022-11-18 01:21:59,445 INFO:     Found new best model at epoch 3
2022-11-18 01:21:59,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:21:59,446 INFO:     Epoch: 4
2022-11-18 01:22:00,250 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8279668363657865, 'Total loss': 0.8279668363657865} | train loss {'Reaction outcome loss': 0.8306928622698494, 'Total loss': 0.8306928622698494}
2022-11-18 01:22:00,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:00,250 INFO:     Epoch: 5
2022-11-18 01:22:01,105 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8277916962450201, 'Total loss': 0.8277916962450201} | train loss {'Reaction outcome loss': 0.8345683379935832, 'Total loss': 0.8345683379935832}
2022-11-18 01:22:01,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:01,106 INFO:     Epoch: 6
2022-11-18 01:22:01,900 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8333055593750693, 'Total loss': 0.8333055593750693} | train loss {'Reaction outcome loss': 0.8296967949944469, 'Total loss': 0.8296967949944469}
2022-11-18 01:22:01,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:01,900 INFO:     Epoch: 7
2022-11-18 01:22:02,726 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8075184673070908, 'Total loss': 0.8075184673070908} | train loss {'Reaction outcome loss': 0.8301896471002324, 'Total loss': 0.8301896471002324}
2022-11-18 01:22:02,726 INFO:     Found new best model at epoch 7
2022-11-18 01:22:02,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:02,727 INFO:     Epoch: 8
2022-11-18 01:22:03,508 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8147996447303079, 'Total loss': 0.8147996447303079} | train loss {'Reaction outcome loss': 0.8311531167281302, 'Total loss': 0.8311531167281302}
2022-11-18 01:22:03,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:03,509 INFO:     Epoch: 9
2022-11-18 01:22:04,291 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.817761508578604, 'Total loss': 0.817761508578604} | train loss {'Reaction outcome loss': 0.8229924942317762, 'Total loss': 0.8229924942317762}
2022-11-18 01:22:04,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:04,291 INFO:     Epoch: 10
2022-11-18 01:22:05,120 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8449254618449644, 'Total loss': 0.8449254618449644} | train loss {'Reaction outcome loss': 0.8256369767642697, 'Total loss': 0.8256369767642697}
2022-11-18 01:22:05,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:05,121 INFO:     Epoch: 11
2022-11-18 01:22:05,896 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8061716116287492, 'Total loss': 0.8061716116287492} | train loss {'Reaction outcome loss': 0.8347151431477504, 'Total loss': 0.8347151431477504}
2022-11-18 01:22:05,896 INFO:     Found new best model at epoch 11
2022-11-18 01:22:05,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:05,897 INFO:     Epoch: 12
2022-11-18 01:22:06,701 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8166490691629323, 'Total loss': 0.8166490691629323} | train loss {'Reaction outcome loss': 0.8238401824404836, 'Total loss': 0.8238401824404836}
2022-11-18 01:22:06,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:06,701 INFO:     Epoch: 13
2022-11-18 01:22:07,537 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8208619545806538, 'Total loss': 0.8208619545806538} | train loss {'Reaction outcome loss': 0.8251710772996972, 'Total loss': 0.8251710772996972}
2022-11-18 01:22:07,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:07,538 INFO:     Epoch: 14
2022-11-18 01:22:08,352 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8113657656041059, 'Total loss': 0.8113657656041059} | train loss {'Reaction outcome loss': 0.8242657680501823, 'Total loss': 0.8242657680501823}
2022-11-18 01:22:08,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:08,352 INFO:     Epoch: 15
2022-11-18 01:22:09,154 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8599919798699293, 'Total loss': 0.8599919798699293} | train loss {'Reaction outcome loss': 0.8253019191475532, 'Total loss': 0.8253019191475532}
2022-11-18 01:22:09,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:09,154 INFO:     Epoch: 16
2022-11-18 01:22:09,976 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8286854706027291, 'Total loss': 0.8286854706027291} | train loss {'Reaction outcome loss': 0.8281593305861902, 'Total loss': 0.8281593305861902}
2022-11-18 01:22:09,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:09,976 INFO:     Epoch: 17
2022-11-18 01:22:10,741 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8046552782708948, 'Total loss': 0.8046552782708948} | train loss {'Reaction outcome loss': 0.8258468705542416, 'Total loss': 0.8258468705542416}
2022-11-18 01:22:10,741 INFO:     Found new best model at epoch 17
2022-11-18 01:22:10,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:10,742 INFO:     Epoch: 18
2022-11-18 01:22:11,525 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8276697031476281, 'Total loss': 0.8276697031476281} | train loss {'Reaction outcome loss': 0.8205822876349151, 'Total loss': 0.8205822876349151}
2022-11-18 01:22:11,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:11,525 INFO:     Epoch: 19
2022-11-18 01:22:12,305 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8286231397227808, 'Total loss': 0.8286231397227808} | train loss {'Reaction outcome loss': 0.8226842167165115, 'Total loss': 0.8226842167165115}
2022-11-18 01:22:12,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:12,305 INFO:     Epoch: 20
2022-11-18 01:22:13,081 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8235588541085069, 'Total loss': 0.8235588541085069} | train loss {'Reaction outcome loss': 0.8240907093291341, 'Total loss': 0.8240907093291341}
2022-11-18 01:22:13,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:13,081 INFO:     Epoch: 21
2022-11-18 01:22:13,897 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8240680145946416, 'Total loss': 0.8240680145946416} | train loss {'Reaction outcome loss': 0.8303038255888441, 'Total loss': 0.8303038255888441}
2022-11-18 01:22:13,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:13,897 INFO:     Epoch: 22
2022-11-18 01:22:14,715 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8102720494974743, 'Total loss': 0.8102720494974743} | train loss {'Reaction outcome loss': 0.8266967899403591, 'Total loss': 0.8266967899403591}
2022-11-18 01:22:14,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:14,716 INFO:     Epoch: 23
2022-11-18 01:22:15,517 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8108639574863694, 'Total loss': 0.8108639574863694} | train loss {'Reaction outcome loss': 0.81807097810724, 'Total loss': 0.81807097810724}
2022-11-18 01:22:15,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:15,517 INFO:     Epoch: 24
2022-11-18 01:22:16,349 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8195386373183944, 'Total loss': 0.8195386373183944} | train loss {'Reaction outcome loss': 0.8207077128201844, 'Total loss': 0.8207077128201844}
2022-11-18 01:22:16,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:16,349 INFO:     Epoch: 25
2022-11-18 01:22:17,183 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8062040345235304, 'Total loss': 0.8062040345235304} | train loss {'Reaction outcome loss': 0.8267257920643578, 'Total loss': 0.8267257920643578}
2022-11-18 01:22:17,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:17,185 INFO:     Epoch: 26
2022-11-18 01:22:18,001 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8074705214662985, 'Total loss': 0.8074705214662985} | train loss {'Reaction outcome loss': 0.8195379742605966, 'Total loss': 0.8195379742605966}
2022-11-18 01:22:18,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:18,002 INFO:     Epoch: 27
2022-11-18 01:22:18,837 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8471811664375392, 'Total loss': 0.8471811664375392} | train loss {'Reaction outcome loss': 0.8207357274858575, 'Total loss': 0.8207357274858575}
2022-11-18 01:22:18,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:18,838 INFO:     Epoch: 28
2022-11-18 01:22:19,644 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8125419081612066, 'Total loss': 0.8125419081612066} | train loss {'Reaction outcome loss': 0.8166475224832774, 'Total loss': 0.8166475224832774}
2022-11-18 01:22:19,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:19,645 INFO:     Epoch: 29
2022-11-18 01:22:20,439 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8201225623488426, 'Total loss': 0.8201225623488426} | train loss {'Reaction outcome loss': 0.8170030293194389, 'Total loss': 0.8170030293194389}
2022-11-18 01:22:20,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:20,440 INFO:     Epoch: 30
2022-11-18 01:22:21,226 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7946112196553837, 'Total loss': 0.7946112196553837} | train loss {'Reaction outcome loss': 0.818803167732259, 'Total loss': 0.818803167732259}
2022-11-18 01:22:21,226 INFO:     Found new best model at epoch 30
2022-11-18 01:22:21,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:21,227 INFO:     Epoch: 31
2022-11-18 01:22:22,029 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8292718238451264, 'Total loss': 0.8292718238451264} | train loss {'Reaction outcome loss': 0.8178261757379601, 'Total loss': 0.8178261757379601}
2022-11-18 01:22:22,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:22,030 INFO:     Epoch: 32
2022-11-18 01:22:22,824 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8095589124343612, 'Total loss': 0.8095589124343612} | train loss {'Reaction outcome loss': 0.8167914189247467, 'Total loss': 0.8167914189247467}
2022-11-18 01:22:22,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:22,824 INFO:     Epoch: 33
2022-11-18 01:22:23,634 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8223284218798984, 'Total loss': 0.8223284218798984} | train loss {'Reaction outcome loss': 0.8152999961786425, 'Total loss': 0.8152999961786425}
2022-11-18 01:22:23,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:23,635 INFO:     Epoch: 34
2022-11-18 01:22:24,439 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.805805042386055, 'Total loss': 0.805805042386055} | train loss {'Reaction outcome loss': 0.8227723742786207, 'Total loss': 0.8227723742786207}
2022-11-18 01:22:24,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:24,439 INFO:     Epoch: 35
2022-11-18 01:22:25,249 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7960959259759296, 'Total loss': 0.7960959259759296} | train loss {'Reaction outcome loss': 0.8226531968425642, 'Total loss': 0.8226531968425642}
2022-11-18 01:22:25,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:25,250 INFO:     Epoch: 36
2022-11-18 01:22:26,062 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8157685554840348, 'Total loss': 0.8157685554840348} | train loss {'Reaction outcome loss': 0.8184620398982816, 'Total loss': 0.8184620398982816}
2022-11-18 01:22:26,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:26,062 INFO:     Epoch: 37
2022-11-18 01:22:26,899 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8095913312651895, 'Total loss': 0.8095913312651895} | train loss {'Reaction outcome loss': 0.8155760031480056, 'Total loss': 0.8155760031480056}
2022-11-18 01:22:26,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:26,899 INFO:     Epoch: 38
2022-11-18 01:22:27,712 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8188033185221932, 'Total loss': 0.8188033185221932} | train loss {'Reaction outcome loss': 0.8180761764406675, 'Total loss': 0.8180761764406675}
2022-11-18 01:22:27,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:27,713 INFO:     Epoch: 39
2022-11-18 01:22:28,491 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8192359242926944, 'Total loss': 0.8192359242926944} | train loss {'Reaction outcome loss': 0.8189896022983891, 'Total loss': 0.8189896022983891}
2022-11-18 01:22:28,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:28,492 INFO:     Epoch: 40
2022-11-18 01:22:29,298 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.824116160246459, 'Total loss': 0.824116160246459} | train loss {'Reaction outcome loss': 0.8188637298369698, 'Total loss': 0.8188637298369698}
2022-11-18 01:22:29,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:29,298 INFO:     Epoch: 41
2022-11-18 01:22:30,072 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8134803961623799, 'Total loss': 0.8134803961623799} | train loss {'Reaction outcome loss': 0.8223566038888476, 'Total loss': 0.8223566038888476}
2022-11-18 01:22:30,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:30,073 INFO:     Epoch: 42
2022-11-18 01:22:30,856 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.822732921351086, 'Total loss': 0.822732921351086} | train loss {'Reaction outcome loss': 0.8121595385103573, 'Total loss': 0.8121595385103573}
2022-11-18 01:22:30,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:30,856 INFO:     Epoch: 43
2022-11-18 01:22:31,643 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8127850984985178, 'Total loss': 0.8127850984985178} | train loss {'Reaction outcome loss': 0.8137226210914643, 'Total loss': 0.8137226210914643}
2022-11-18 01:22:31,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:31,643 INFO:     Epoch: 44
2022-11-18 01:22:32,426 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8060295134782791, 'Total loss': 0.8060295134782791} | train loss {'Reaction outcome loss': 0.8139554549325333, 'Total loss': 0.8139554549325333}
2022-11-18 01:22:32,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:32,426 INFO:     Epoch: 45
2022-11-18 01:22:33,229 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8153475191105496, 'Total loss': 0.8153475191105496} | train loss {'Reaction outcome loss': 0.8165787512715529, 'Total loss': 0.8165787512715529}
2022-11-18 01:22:33,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:33,229 INFO:     Epoch: 46
2022-11-18 01:22:34,029 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8095461522991007, 'Total loss': 0.8095461522991007} | train loss {'Reaction outcome loss': 0.814558672790344, 'Total loss': 0.814558672790344}
2022-11-18 01:22:34,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:34,030 INFO:     Epoch: 47
2022-11-18 01:22:34,808 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8373296741734851, 'Total loss': 0.8373296741734851} | train loss {'Reaction outcome loss': 0.8194840684352134, 'Total loss': 0.8194840684352134}
2022-11-18 01:22:34,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:34,809 INFO:     Epoch: 48
2022-11-18 01:22:35,570 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7967569387771867, 'Total loss': 0.7967569387771867} | train loss {'Reaction outcome loss': 0.8193358588315215, 'Total loss': 0.8193358588315215}
2022-11-18 01:22:35,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:35,570 INFO:     Epoch: 49
2022-11-18 01:22:36,361 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.812233146618713, 'Total loss': 0.812233146618713} | train loss {'Reaction outcome loss': 0.816837243403983, 'Total loss': 0.816837243403983}
2022-11-18 01:22:36,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:36,362 INFO:     Epoch: 50
2022-11-18 01:22:37,162 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8313764652067964, 'Total loss': 0.8313764652067964} | train loss {'Reaction outcome loss': 0.8201418241508577, 'Total loss': 0.8201418241508577}
2022-11-18 01:22:37,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:37,162 INFO:     Epoch: 51
2022-11-18 01:22:37,957 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8000629767775536, 'Total loss': 0.8000629767775536} | train loss {'Reaction outcome loss': 0.8293815512164884, 'Total loss': 0.8293815512164884}
2022-11-18 01:22:37,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:37,957 INFO:     Epoch: 52
2022-11-18 01:22:38,746 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8205178244547411, 'Total loss': 0.8205178244547411} | train loss {'Reaction outcome loss': 0.8156275386028444, 'Total loss': 0.8156275386028444}
2022-11-18 01:22:38,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:38,746 INFO:     Epoch: 53
2022-11-18 01:22:39,504 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8050477579236031, 'Total loss': 0.8050477579236031} | train loss {'Reaction outcome loss': 0.8163341492535132, 'Total loss': 0.8163341492535132}
2022-11-18 01:22:39,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:39,504 INFO:     Epoch: 54
2022-11-18 01:22:40,294 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8106808879158713, 'Total loss': 0.8106808879158713} | train loss {'Reaction outcome loss': 0.8157704420810045, 'Total loss': 0.8157704420810045}
2022-11-18 01:22:40,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:40,295 INFO:     Epoch: 55
2022-11-18 01:22:41,071 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8041085865009915, 'Total loss': 0.8041085865009915} | train loss {'Reaction outcome loss': 0.8125581968620963, 'Total loss': 0.8125581968620963}
2022-11-18 01:22:41,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:41,072 INFO:     Epoch: 56
2022-11-18 01:22:41,847 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8125419521873648, 'Total loss': 0.8125419521873648} | train loss {'Reaction outcome loss': 0.8228721739309519, 'Total loss': 0.8228721739309519}
2022-11-18 01:22:41,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:41,847 INFO:     Epoch: 57
2022-11-18 01:22:42,626 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8002215874466029, 'Total loss': 0.8002215874466029} | train loss {'Reaction outcome loss': 0.822526657086635, 'Total loss': 0.822526657086635}
2022-11-18 01:22:42,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:42,626 INFO:     Epoch: 58
2022-11-18 01:22:43,412 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8238055550239303, 'Total loss': 0.8238055550239303} | train loss {'Reaction outcome loss': 0.8165047483345275, 'Total loss': 0.8165047483345275}
2022-11-18 01:22:43,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:43,412 INFO:     Epoch: 59
2022-11-18 01:22:44,193 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8161895248022947, 'Total loss': 0.8161895248022947} | train loss {'Reaction outcome loss': 0.8183450030411786, 'Total loss': 0.8183450030411786}
2022-11-18 01:22:44,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:44,193 INFO:     Epoch: 60
2022-11-18 01:22:44,987 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8146215961738066, 'Total loss': 0.8146215961738066} | train loss {'Reaction outcome loss': 0.8177515046316602, 'Total loss': 0.8177515046316602}
2022-11-18 01:22:44,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:44,987 INFO:     Epoch: 61
2022-11-18 01:22:45,758 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8029987561431798, 'Total loss': 0.8029987561431798} | train loss {'Reaction outcome loss': 0.818985520104165, 'Total loss': 0.818985520104165}
2022-11-18 01:22:45,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:45,758 INFO:     Epoch: 62
2022-11-18 01:22:46,521 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8095112930644642, 'Total loss': 0.8095112930644642} | train loss {'Reaction outcome loss': 0.8174436811795119, 'Total loss': 0.8174436811795119}
2022-11-18 01:22:46,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:46,521 INFO:     Epoch: 63
2022-11-18 01:22:47,308 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8131481205875223, 'Total loss': 0.8131481205875223} | train loss {'Reaction outcome loss': 0.8157209128986004, 'Total loss': 0.8157209128986004}
2022-11-18 01:22:47,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:47,308 INFO:     Epoch: 64
2022-11-18 01:22:48,099 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8000780587846582, 'Total loss': 0.8000780587846582} | train loss {'Reaction outcome loss': 0.8245114468128575, 'Total loss': 0.8245114468128575}
2022-11-18 01:22:48,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:48,100 INFO:     Epoch: 65
2022-11-18 01:22:48,864 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8110257211056623, 'Total loss': 0.8110257211056623} | train loss {'Reaction outcome loss': 0.8242441985288612, 'Total loss': 0.8242441985288612}
2022-11-18 01:22:48,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:48,864 INFO:     Epoch: 66
2022-11-18 01:22:49,628 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8520672768354416, 'Total loss': 0.8520672768354416} | train loss {'Reaction outcome loss': 0.819290938406338, 'Total loss': 0.819290938406338}
2022-11-18 01:22:49,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:49,628 INFO:     Epoch: 67
2022-11-18 01:22:50,418 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8042841126972978, 'Total loss': 0.8042841126972978} | train loss {'Reaction outcome loss': 0.8181660602148245, 'Total loss': 0.8181660602148245}
2022-11-18 01:22:50,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:50,418 INFO:     Epoch: 68
2022-11-18 01:22:51,190 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8086061816323887, 'Total loss': 0.8086061816323887} | train loss {'Reaction outcome loss': 0.8150278069229744, 'Total loss': 0.8150278069229744}
2022-11-18 01:22:51,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:51,190 INFO:     Epoch: 69
2022-11-18 01:22:51,991 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7981634099375118, 'Total loss': 0.7981634099375118} | train loss {'Reaction outcome loss': 0.8119580124915853, 'Total loss': 0.8119580124915853}
2022-11-18 01:22:51,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:51,991 INFO:     Epoch: 70
2022-11-18 01:22:52,761 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8050118427384984, 'Total loss': 0.8050118427384984} | train loss {'Reaction outcome loss': 0.8159212222104131, 'Total loss': 0.8159212222104131}
2022-11-18 01:22:52,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:52,761 INFO:     Epoch: 71
2022-11-18 01:22:53,537 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.838611211289059, 'Total loss': 0.838611211289059} | train loss {'Reaction outcome loss': 0.822629141300796, 'Total loss': 0.822629141300796}
2022-11-18 01:22:53,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:53,538 INFO:     Epoch: 72
2022-11-18 01:22:54,317 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8056616579944437, 'Total loss': 0.8056616579944437} | train loss {'Reaction outcome loss': 0.8118959597127158, 'Total loss': 0.8118959597127158}
2022-11-18 01:22:54,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:54,318 INFO:     Epoch: 73
2022-11-18 01:22:55,106 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8125934126702222, 'Total loss': 0.8125934126702222} | train loss {'Reaction outcome loss': 0.8087375224963856, 'Total loss': 0.8087375224963856}
2022-11-18 01:22:55,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:55,106 INFO:     Epoch: 74
2022-11-18 01:22:55,863 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7963937480341304, 'Total loss': 0.7963937480341304} | train loss {'Reaction outcome loss': 0.8157434883387947, 'Total loss': 0.8157434883387947}
2022-11-18 01:22:55,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:55,863 INFO:     Epoch: 75
2022-11-18 01:22:56,638 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8051325529813766, 'Total loss': 0.8051325529813766} | train loss {'Reaction outcome loss': 0.816232381803304, 'Total loss': 0.816232381803304}
2022-11-18 01:22:56,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:56,639 INFO:     Epoch: 76
2022-11-18 01:22:57,412 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8063370754772966, 'Total loss': 0.8063370754772966} | train loss {'Reaction outcome loss': 0.8155650596628304, 'Total loss': 0.8155650596628304}
2022-11-18 01:22:57,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:57,412 INFO:     Epoch: 77
2022-11-18 01:22:58,177 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8023912561210719, 'Total loss': 0.8023912561210719} | train loss {'Reaction outcome loss': 0.816953848489383, 'Total loss': 0.816953848489383}
2022-11-18 01:22:58,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:58,178 INFO:     Epoch: 78
2022-11-18 01:22:58,943 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8084352707320993, 'Total loss': 0.8084352707320993} | train loss {'Reaction outcome loss': 0.819089469760053, 'Total loss': 0.819089469760053}
2022-11-18 01:22:58,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:58,943 INFO:     Epoch: 79
2022-11-18 01:22:59,704 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8280077271840789, 'Total loss': 0.8280077271840789} | train loss {'Reaction outcome loss': 0.8126843403496964, 'Total loss': 0.8126843403496964}
2022-11-18 01:22:59,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:22:59,705 INFO:     Epoch: 80
2022-11-18 01:23:00,475 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8143579919229854, 'Total loss': 0.8143579919229854} | train loss {'Reaction outcome loss': 0.8169509547080106, 'Total loss': 0.8169509547080106}
2022-11-18 01:23:00,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:00,475 INFO:     Epoch: 81
2022-11-18 01:23:01,249 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.805825570767576, 'Total loss': 0.805825570767576} | train loss {'Reaction outcome loss': 0.8178054502135829, 'Total loss': 0.8178054502135829}
2022-11-18 01:23:01,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:01,249 INFO:     Epoch: 82
2022-11-18 01:23:02,036 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7943986728787422, 'Total loss': 0.7943986728787422} | train loss {'Reaction outcome loss': 0.8138276039498297, 'Total loss': 0.8138276039498297}
2022-11-18 01:23:02,036 INFO:     Found new best model at epoch 82
2022-11-18 01:23:02,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:02,037 INFO:     Epoch: 83
2022-11-18 01:23:02,810 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8302290019663897, 'Total loss': 0.8302290019663897} | train loss {'Reaction outcome loss': 0.8198438900926335, 'Total loss': 0.8198438900926335}
2022-11-18 01:23:02,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:02,810 INFO:     Epoch: 84
2022-11-18 01:23:03,566 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8073937323960391, 'Total loss': 0.8073937323960391} | train loss {'Reaction outcome loss': 0.815054858261757, 'Total loss': 0.815054858261757}
2022-11-18 01:23:03,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:03,567 INFO:     Epoch: 85
2022-11-18 01:23:04,343 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8176099359989166, 'Total loss': 0.8176099359989166} | train loss {'Reaction outcome loss': 0.8223810922279049, 'Total loss': 0.8223810922279049}
2022-11-18 01:23:04,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:04,344 INFO:     Epoch: 86
2022-11-18 01:23:05,127 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8302779339931228, 'Total loss': 0.8302779339931228} | train loss {'Reaction outcome loss': 0.8218332171922753, 'Total loss': 0.8218332171922753}
2022-11-18 01:23:05,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:05,127 INFO:     Epoch: 87
2022-11-18 01:23:05,918 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8687818267128684, 'Total loss': 0.8687818267128684} | train loss {'Reaction outcome loss': 0.8152929900387521, 'Total loss': 0.8152929900387521}
2022-11-18 01:23:05,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:05,919 INFO:     Epoch: 88
2022-11-18 01:23:06,697 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8142295716838404, 'Total loss': 0.8142295716838404} | train loss {'Reaction outcome loss': 0.828921122830889, 'Total loss': 0.828921122830889}
2022-11-18 01:23:06,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:06,698 INFO:     Epoch: 89
2022-11-18 01:23:07,467 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8013368878852237, 'Total loss': 0.8013368878852237} | train loss {'Reaction outcome loss': 0.8179146844124504, 'Total loss': 0.8179146844124504}
2022-11-18 01:23:07,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:07,467 INFO:     Epoch: 90
2022-11-18 01:23:08,243 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7994041564789686, 'Total loss': 0.7994041564789686} | train loss {'Reaction outcome loss': 0.8147957518636456, 'Total loss': 0.8147957518636456}
2022-11-18 01:23:08,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:08,243 INFO:     Epoch: 91
2022-11-18 01:23:09,018 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8232329528440129, 'Total loss': 0.8232329528440129} | train loss {'Reaction outcome loss': 0.8120372970456536, 'Total loss': 0.8120372970456536}
2022-11-18 01:23:09,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:09,018 INFO:     Epoch: 92
2022-11-18 01:23:09,823 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8086702600121498, 'Total loss': 0.8086702600121498} | train loss {'Reaction outcome loss': 0.8154294980682342, 'Total loss': 0.8154294980682342}
2022-11-18 01:23:09,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:09,824 INFO:     Epoch: 93
2022-11-18 01:23:10,624 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8059926182031631, 'Total loss': 0.8059926182031631} | train loss {'Reaction outcome loss': 0.8152364491586864, 'Total loss': 0.8152364491586864}
2022-11-18 01:23:10,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:10,624 INFO:     Epoch: 94
2022-11-18 01:23:11,394 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.823582498864694, 'Total loss': 0.823582498864694} | train loss {'Reaction outcome loss': 0.8149096901238206, 'Total loss': 0.8149096901238206}
2022-11-18 01:23:11,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:11,394 INFO:     Epoch: 95
2022-11-18 01:23:12,196 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8013156456026164, 'Total loss': 0.8013156456026164} | train loss {'Reaction outcome loss': 0.8148150737830985, 'Total loss': 0.8148150737830985}
2022-11-18 01:23:12,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:12,196 INFO:     Epoch: 96
2022-11-18 01:23:12,991 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7893900072032755, 'Total loss': 0.7893900072032755} | train loss {'Reaction outcome loss': 0.809311613169035, 'Total loss': 0.809311613169035}
2022-11-18 01:23:12,991 INFO:     Found new best model at epoch 96
2022-11-18 01:23:12,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:12,992 INFO:     Epoch: 97
2022-11-18 01:23:13,789 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8137109374458139, 'Total loss': 0.8137109374458139} | train loss {'Reaction outcome loss': 0.8202306380880023, 'Total loss': 0.8202306380880023}
2022-11-18 01:23:13,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:13,789 INFO:     Epoch: 98
2022-11-18 01:23:14,612 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7956497303464196, 'Total loss': 0.7956497303464196} | train loss {'Reaction outcome loss': 0.8142090964353519, 'Total loss': 0.8142090964353519}
2022-11-18 01:23:14,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:14,613 INFO:     Epoch: 99
2022-11-18 01:23:15,430 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8177606815641577, 'Total loss': 0.8177606815641577} | train loss {'Reaction outcome loss': 0.8095946723391653, 'Total loss': 0.8095946723391653}
2022-11-18 01:23:15,431 INFO:     Best model found after epoch 97 of 100.
2022-11-18 01:23:15,431 INFO:   Done with stage: TRAINING
2022-11-18 01:23:15,431 INFO:   Starting stage: EVALUATION
2022-11-18 01:23:15,554 INFO:   Done with stage: EVALUATION
2022-11-18 01:23:15,554 INFO:   Leaving out SEQ value Fold_2
2022-11-18 01:23:15,567 INFO:   examples: 20,544| examples in train: 15,422 | examples in val: 2,722| examples in test: 2,400
2022-11-18 01:23:15,567 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:23:16,222 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:23:16,222 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:23:16,292 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:23:16,292 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:23:16,292 INFO:     No hyperparam tuning for this model
2022-11-18 01:23:16,292 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:23:16,292 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:23:16,293 INFO:     None feature selector for col prot
2022-11-18 01:23:16,293 INFO:     None feature selector for col prot
2022-11-18 01:23:16,293 INFO:     None feature selector for col prot
2022-11-18 01:23:16,294 INFO:     None feature selector for col chem
2022-11-18 01:23:16,294 INFO:     None feature selector for col chem
2022-11-18 01:23:16,294 INFO:     None feature selector for col chem
2022-11-18 01:23:16,294 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:23:16,294 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:23:16,296 INFO:     Number of params in model 168571
2022-11-18 01:23:16,299 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:23:16,299 INFO:   Starting stage: TRAINING
2022-11-18 01:23:16,355 INFO:     Val loss before train {'Reaction outcome loss': 1.0103132600008056, 'Total loss': 1.0103132600008056}
2022-11-18 01:23:16,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:16,356 INFO:     Epoch: 0
2022-11-18 01:23:17,111 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.843570547741513, 'Total loss': 0.843570547741513} | train loss {'Reaction outcome loss': 0.8644061752622059, 'Total loss': 0.8644061752622059}
2022-11-18 01:23:17,111 INFO:     Found new best model at epoch 0
2022-11-18 01:23:17,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:17,112 INFO:     Epoch: 1
2022-11-18 01:23:17,900 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8490567456844241, 'Total loss': 0.8490567456844241} | train loss {'Reaction outcome loss': 0.8375832708050106, 'Total loss': 0.8375832708050106}
2022-11-18 01:23:17,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:17,900 INFO:     Epoch: 2
2022-11-18 01:23:18,672 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8648584013761476, 'Total loss': 0.8648584013761476} | train loss {'Reaction outcome loss': 0.8350243162812039, 'Total loss': 0.8350243162812039}
2022-11-18 01:23:18,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:18,672 INFO:     Epoch: 3
2022-11-18 01:23:19,464 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8321495291798614, 'Total loss': 0.8321495291798614} | train loss {'Reaction outcome loss': 0.826042443142887, 'Total loss': 0.826042443142887}
2022-11-18 01:23:19,467 INFO:     Found new best model at epoch 3
2022-11-18 01:23:19,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:19,468 INFO:     Epoch: 4
2022-11-18 01:23:20,265 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.839536305083785, 'Total loss': 0.839536305083785} | train loss {'Reaction outcome loss': 0.8292792617532723, 'Total loss': 0.8292792617532723}
2022-11-18 01:23:20,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:20,266 INFO:     Epoch: 5
2022-11-18 01:23:21,060 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8253556739452274, 'Total loss': 0.8253556739452274} | train loss {'Reaction outcome loss': 0.820362242796609, 'Total loss': 0.820362242796609}
2022-11-18 01:23:21,060 INFO:     Found new best model at epoch 5
2022-11-18 01:23:21,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:21,061 INFO:     Epoch: 6
2022-11-18 01:23:21,847 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8026368063549663, 'Total loss': 0.8026368063549663} | train loss {'Reaction outcome loss': 0.821229781723616, 'Total loss': 0.821229781723616}
2022-11-18 01:23:21,847 INFO:     Found new best model at epoch 6
2022-11-18 01:23:21,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:21,848 INFO:     Epoch: 7
2022-11-18 01:23:22,615 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8611154618651368, 'Total loss': 0.8611154618651368} | train loss {'Reaction outcome loss': 0.8208798339505413, 'Total loss': 0.8208798339505413}
2022-11-18 01:23:22,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:22,615 INFO:     Epoch: 8
2022-11-18 01:23:23,406 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8129204490850138, 'Total loss': 0.8129204490850138} | train loss {'Reaction outcome loss': 0.8152615916432187, 'Total loss': 0.8152615916432187}
2022-11-18 01:23:23,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:23,407 INFO:     Epoch: 9
2022-11-18 01:23:24,203 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8167971282504326, 'Total loss': 0.8167971282504326} | train loss {'Reaction outcome loss': 0.8170564183308375, 'Total loss': 0.8170564183308375}
2022-11-18 01:23:24,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:24,204 INFO:     Epoch: 10
2022-11-18 01:23:24,957 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8158381810021955, 'Total loss': 0.8158381810021955} | train loss {'Reaction outcome loss': 0.8147494017583206, 'Total loss': 0.8147494017583206}
2022-11-18 01:23:24,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:24,958 INFO:     Epoch: 11
2022-11-18 01:23:25,719 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8157371421192967, 'Total loss': 0.8157371421192967} | train loss {'Reaction outcome loss': 0.812563261921475, 'Total loss': 0.812563261921475}
2022-11-18 01:23:25,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:25,720 INFO:     Epoch: 12
2022-11-18 01:23:26,512 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8517971413080082, 'Total loss': 0.8517971413080082} | train loss {'Reaction outcome loss': 0.8127504809763422, 'Total loss': 0.8127504809763422}
2022-11-18 01:23:26,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:26,513 INFO:     Epoch: 13
2022-11-18 01:23:27,312 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8039886338073153, 'Total loss': 0.8039886338073153} | train loss {'Reaction outcome loss': 0.811765135323853, 'Total loss': 0.811765135323853}
2022-11-18 01:23:27,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:27,312 INFO:     Epoch: 14
2022-11-18 01:23:28,105 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8321646694527116, 'Total loss': 0.8321646694527116} | train loss {'Reaction outcome loss': 0.8156556640423185, 'Total loss': 0.8156556640423185}
2022-11-18 01:23:28,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:28,105 INFO:     Epoch: 15
2022-11-18 01:23:28,934 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8155480498491332, 'Total loss': 0.8155480498491332} | train loss {'Reaction outcome loss': 0.8094789286866723, 'Total loss': 0.8094789286866723}
2022-11-18 01:23:28,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:28,934 INFO:     Epoch: 16
2022-11-18 01:23:29,722 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7990005598511807, 'Total loss': 0.7990005598511807} | train loss {'Reaction outcome loss': 0.8139369308453872, 'Total loss': 0.8139369308453872}
2022-11-18 01:23:29,723 INFO:     Found new best model at epoch 16
2022-11-18 01:23:29,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:29,723 INFO:     Epoch: 17
2022-11-18 01:23:30,540 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8126295278238695, 'Total loss': 0.8126295278238695} | train loss {'Reaction outcome loss': 0.809242026563502, 'Total loss': 0.809242026563502}
2022-11-18 01:23:30,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:30,540 INFO:     Epoch: 18
2022-11-18 01:23:31,334 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8293051068172899, 'Total loss': 0.8293051068172899} | train loss {'Reaction outcome loss': 0.8106396545760365, 'Total loss': 0.8106396545760365}
2022-11-18 01:23:31,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:31,334 INFO:     Epoch: 19
2022-11-18 01:23:32,131 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8210330376791399, 'Total loss': 0.8210330376791399} | train loss {'Reaction outcome loss': 0.8090969792787465, 'Total loss': 0.8090969792787465}
2022-11-18 01:23:32,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:32,132 INFO:     Epoch: 20
2022-11-18 01:23:32,922 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8063217872797057, 'Total loss': 0.8063217872797057} | train loss {'Reaction outcome loss': 0.8157898311298418, 'Total loss': 0.8157898311298418}
2022-11-18 01:23:32,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:32,922 INFO:     Epoch: 21
2022-11-18 01:23:33,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8051286249659783, 'Total loss': 0.8051286249659783} | train loss {'Reaction outcome loss': 0.8067500029856733, 'Total loss': 0.8067500029856733}
2022-11-18 01:23:33,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:33,705 INFO:     Epoch: 22
2022-11-18 01:23:34,467 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8076016805892767, 'Total loss': 0.8076016805892767} | train loss {'Reaction outcome loss': 0.8105946289553188, 'Total loss': 0.8105946289553188}
2022-11-18 01:23:34,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:34,468 INFO:     Epoch: 23
2022-11-18 01:23:35,254 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8226514652717946, 'Total loss': 0.8226514652717946} | train loss {'Reaction outcome loss': 0.81151234856285, 'Total loss': 0.81151234856285}
2022-11-18 01:23:35,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:35,254 INFO:     Epoch: 24
2022-11-18 01:23:36,070 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8074321344841359, 'Total loss': 0.8074321344841359} | train loss {'Reaction outcome loss': 0.8116395759137339, 'Total loss': 0.8116395759137339}
2022-11-18 01:23:36,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:36,070 INFO:     Epoch: 25
2022-11-18 01:23:36,864 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8012133143668951, 'Total loss': 0.8012133143668951} | train loss {'Reaction outcome loss': 0.8118351169888904, 'Total loss': 0.8118351169888904}
2022-11-18 01:23:36,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:36,864 INFO:     Epoch: 26
2022-11-18 01:23:37,679 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8083456082399502, 'Total loss': 0.8083456082399502} | train loss {'Reaction outcome loss': 0.8064788677633056, 'Total loss': 0.8064788677633056}
2022-11-18 01:23:37,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:37,679 INFO:     Epoch: 27
2022-11-18 01:23:38,493 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8060624765795331, 'Total loss': 0.8060624765795331} | train loss {'Reaction outcome loss': 0.8101456781145943, 'Total loss': 0.8101456781145943}
2022-11-18 01:23:38,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:38,495 INFO:     Epoch: 28
2022-11-18 01:23:39,271 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8175684269084487, 'Total loss': 0.8175684269084487} | train loss {'Reaction outcome loss': 0.8086968091513606, 'Total loss': 0.8086968091513606}
2022-11-18 01:23:39,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:39,271 INFO:     Epoch: 29
2022-11-18 01:23:40,068 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8015495836734772, 'Total loss': 0.8015495836734772} | train loss {'Reaction outcome loss': 0.8090175360564869, 'Total loss': 0.8090175360564869}
2022-11-18 01:23:40,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:40,069 INFO:     Epoch: 30
2022-11-18 01:23:40,856 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8149935339772424, 'Total loss': 0.8149935339772424} | train loss {'Reaction outcome loss': 0.8076951862370819, 'Total loss': 0.8076951862370819}
2022-11-18 01:23:40,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:40,856 INFO:     Epoch: 31
2022-11-18 01:23:41,619 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8073973946793135, 'Total loss': 0.8073973946793135} | train loss {'Reaction outcome loss': 0.8098005280207796, 'Total loss': 0.8098005280207796}
2022-11-18 01:23:41,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:41,619 INFO:     Epoch: 32
2022-11-18 01:23:42,368 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8192027606243311, 'Total loss': 0.8192027606243311} | train loss {'Reaction outcome loss': 0.8061751154448481, 'Total loss': 0.8061751154448481}
2022-11-18 01:23:42,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:42,368 INFO:     Epoch: 33
2022-11-18 01:23:43,183 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.803812102522961, 'Total loss': 0.803812102522961} | train loss {'Reaction outcome loss': 0.8051918956501355, 'Total loss': 0.8051918956501355}
2022-11-18 01:23:43,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:43,184 INFO:     Epoch: 34
2022-11-18 01:23:43,938 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8192126307376596, 'Total loss': 0.8192126307376596} | train loss {'Reaction outcome loss': 0.8110672690561698, 'Total loss': 0.8110672690561698}
2022-11-18 01:23:43,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:43,939 INFO:     Epoch: 35
2022-11-18 01:23:44,736 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8208208146483399, 'Total loss': 0.8208208146483399} | train loss {'Reaction outcome loss': 0.8069446681693382, 'Total loss': 0.8069446681693382}
2022-11-18 01:23:44,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:44,736 INFO:     Epoch: 36
2022-11-18 01:23:45,531 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8116362545379373, 'Total loss': 0.8116362545379373} | train loss {'Reaction outcome loss': 0.8122247848273313, 'Total loss': 0.8122247848273313}
2022-11-18 01:23:45,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:45,531 INFO:     Epoch: 37
2022-11-18 01:23:46,318 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.830911259318507, 'Total loss': 0.830911259318507} | train loss {'Reaction outcome loss': 0.8088619242812588, 'Total loss': 0.8088619242812588}
2022-11-18 01:23:46,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:46,319 INFO:     Epoch: 38
2022-11-18 01:23:47,141 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.799651479305223, 'Total loss': 0.799651479305223} | train loss {'Reaction outcome loss': 0.8090502112732884, 'Total loss': 0.8090502112732884}
2022-11-18 01:23:47,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:47,141 INFO:     Epoch: 39
2022-11-18 01:23:47,965 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7983800734198371, 'Total loss': 0.7983800734198371} | train loss {'Reaction outcome loss': 0.8070761225035576, 'Total loss': 0.8070761225035576}
2022-11-18 01:23:47,965 INFO:     Found new best model at epoch 39
2022-11-18 01:23:47,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:47,966 INFO:     Epoch: 40
2022-11-18 01:23:48,767 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8008500039577484, 'Total loss': 0.8008500039577484} | train loss {'Reaction outcome loss': 0.805217637313352, 'Total loss': 0.805217637313352}
2022-11-18 01:23:48,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:48,768 INFO:     Epoch: 41
2022-11-18 01:23:49,544 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.82134802743446, 'Total loss': 0.82134802743446} | train loss {'Reaction outcome loss': 0.8083771167949028, 'Total loss': 0.8083771167949028}
2022-11-18 01:23:49,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:49,544 INFO:     Epoch: 42
2022-11-18 01:23:50,345 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8272125790285509, 'Total loss': 0.8272125790285509} | train loss {'Reaction outcome loss': 0.8089642783170914, 'Total loss': 0.8089642783170914}
2022-11-18 01:23:50,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:50,347 INFO:     Epoch: 43
2022-11-18 01:23:51,174 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7987775622412215, 'Total loss': 0.7987775622412215} | train loss {'Reaction outcome loss': 0.8097424461386511, 'Total loss': 0.8097424461386511}
2022-11-18 01:23:51,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:51,175 INFO:     Epoch: 44
2022-11-18 01:23:51,965 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8184324620768081, 'Total loss': 0.8184324620768081} | train loss {'Reaction outcome loss': 0.8075707358196068, 'Total loss': 0.8075707358196068}
2022-11-18 01:23:51,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:51,965 INFO:     Epoch: 45
2022-11-18 01:23:52,803 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8290259775727294, 'Total loss': 0.8290259775727294} | train loss {'Reaction outcome loss': 0.8054617556793561, 'Total loss': 0.8054617556793561}
2022-11-18 01:23:52,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:52,803 INFO:     Epoch: 46
2022-11-18 01:23:53,623 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8246318794960199, 'Total loss': 0.8246318794960199} | train loss {'Reaction outcome loss': 0.8078059678997737, 'Total loss': 0.8078059678997737}
2022-11-18 01:23:53,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:53,624 INFO:     Epoch: 47
2022-11-18 01:23:54,405 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8087110055047412, 'Total loss': 0.8087110055047412} | train loss {'Reaction outcome loss': 0.8024048848518197, 'Total loss': 0.8024048848518197}
2022-11-18 01:23:54,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:54,406 INFO:     Epoch: 48
2022-11-18 01:23:55,225 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8062145044637281, 'Total loss': 0.8062145044637281} | train loss {'Reaction outcome loss': 0.8071751091242826, 'Total loss': 0.8071751091242826}
2022-11-18 01:23:55,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:55,225 INFO:     Epoch: 49
2022-11-18 01:23:56,014 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8041487571805023, 'Total loss': 0.8041487571805023} | train loss {'Reaction outcome loss': 0.8024328743026464, 'Total loss': 0.8024328743026464}
2022-11-18 01:23:56,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:56,014 INFO:     Epoch: 50
2022-11-18 01:23:56,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7970169373722964, 'Total loss': 0.7970169373722964} | train loss {'Reaction outcome loss': 0.8102680857745443, 'Total loss': 0.8102680857745443}
2022-11-18 01:23:56,803 INFO:     Found new best model at epoch 50
2022-11-18 01:23:56,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:56,803 INFO:     Epoch: 51
2022-11-18 01:23:57,594 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8089407640834188, 'Total loss': 0.8089407640834188} | train loss {'Reaction outcome loss': 0.8001577563552935, 'Total loss': 0.8001577563552935}
2022-11-18 01:23:57,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:57,594 INFO:     Epoch: 52
2022-11-18 01:23:58,362 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8653090208075768, 'Total loss': 0.8653090208075768} | train loss {'Reaction outcome loss': 0.8042771845932324, 'Total loss': 0.8042771845932324}
2022-11-18 01:23:58,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:58,363 INFO:     Epoch: 53
2022-11-18 01:23:59,169 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8009555603182593, 'Total loss': 0.8009555603182593} | train loss {'Reaction outcome loss': 0.8053678468302572, 'Total loss': 0.8053678468302572}
2022-11-18 01:23:59,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:59,169 INFO:     Epoch: 54
2022-11-18 01:23:59,958 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8104202054267706, 'Total loss': 0.8104202054267706} | train loss {'Reaction outcome loss': 0.8063024168687243, 'Total loss': 0.8063024168687243}
2022-11-18 01:23:59,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:23:59,959 INFO:     Epoch: 55
2022-11-18 01:24:00,754 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8034417601518853, 'Total loss': 0.8034417601518853} | train loss {'Reaction outcome loss': 0.8032890079674384, 'Total loss': 0.8032890079674384}
2022-11-18 01:24:00,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:00,754 INFO:     Epoch: 56
2022-11-18 01:24:01,531 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7963306418685026, 'Total loss': 0.7963306418685026} | train loss {'Reaction outcome loss': 0.8051211763467037, 'Total loss': 0.8051211763467037}
2022-11-18 01:24:01,531 INFO:     Found new best model at epoch 56
2022-11-18 01:24:01,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:01,532 INFO:     Epoch: 57
2022-11-18 01:24:02,303 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8191915057426276, 'Total loss': 0.8191915057426276} | train loss {'Reaction outcome loss': 0.8065667685384078, 'Total loss': 0.8065667685384078}
2022-11-18 01:24:02,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:02,303 INFO:     Epoch: 58
2022-11-18 01:24:03,066 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.851974755525589, 'Total loss': 0.851974755525589} | train loss {'Reaction outcome loss': 0.8034333883479423, 'Total loss': 0.8034333883479423}
2022-11-18 01:24:03,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:03,066 INFO:     Epoch: 59
2022-11-18 01:24:03,883 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8138263537440189, 'Total loss': 0.8138263537440189} | train loss {'Reaction outcome loss': 0.8048822270142092, 'Total loss': 0.8048822270142092}
2022-11-18 01:24:03,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:03,883 INFO:     Epoch: 60
2022-11-18 01:24:04,667 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7897103297155957, 'Total loss': 0.7897103297155957} | train loss {'Reaction outcome loss': 0.8053794818547751, 'Total loss': 0.8053794818547751}
2022-11-18 01:24:04,667 INFO:     Found new best model at epoch 60
2022-11-18 01:24:04,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:04,668 INFO:     Epoch: 61
2022-11-18 01:24:05,435 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7919402101705241, 'Total loss': 0.7919402101705241} | train loss {'Reaction outcome loss': 0.8048895660525041, 'Total loss': 0.8048895660525041}
2022-11-18 01:24:05,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:05,436 INFO:     Epoch: 62
2022-11-18 01:24:06,228 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8189676161422286, 'Total loss': 0.8189676161422286} | train loss {'Reaction outcome loss': 0.8038281449638461, 'Total loss': 0.8038281449638461}
2022-11-18 01:24:06,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:06,228 INFO:     Epoch: 63
2022-11-18 01:24:07,015 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8023997836334761, 'Total loss': 0.8023997836334761} | train loss {'Reaction outcome loss': 0.8062334546657024, 'Total loss': 0.8062334546657024}
2022-11-18 01:24:07,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:07,015 INFO:     Epoch: 64
2022-11-18 01:24:07,816 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8076911173587622, 'Total loss': 0.8076911173587622} | train loss {'Reaction outcome loss': 0.8033020862405231, 'Total loss': 0.8033020862405231}
2022-11-18 01:24:07,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:07,816 INFO:     Epoch: 65
2022-11-18 01:24:08,639 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8377079000306684, 'Total loss': 0.8377079000306684} | train loss {'Reaction outcome loss': 0.8015843527198332, 'Total loss': 0.8015843527198332}
2022-11-18 01:24:08,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:08,639 INFO:     Epoch: 66
2022-11-18 01:24:09,425 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8375628188598988, 'Total loss': 0.8375628188598988} | train loss {'Reaction outcome loss': 0.8045941143609676, 'Total loss': 0.8045941143609676}
2022-11-18 01:24:09,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:09,426 INFO:     Epoch: 67
2022-11-18 01:24:10,184 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8016880681348402, 'Total loss': 0.8016880681348402} | train loss {'Reaction outcome loss': 0.8066115897473458, 'Total loss': 0.8066115897473458}
2022-11-18 01:24:10,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:10,185 INFO:     Epoch: 68
2022-11-18 01:24:11,005 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8067769075548926, 'Total loss': 0.8067769075548926} | train loss {'Reaction outcome loss': 0.8070341940984687, 'Total loss': 0.8070341940984687}
2022-11-18 01:24:11,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:11,005 INFO:     Epoch: 69
2022-11-18 01:24:11,803 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8021341562271118, 'Total loss': 0.8021341562271118} | train loss {'Reaction outcome loss': 0.8020204687761568, 'Total loss': 0.8020204687761568}
2022-11-18 01:24:11,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:11,804 INFO:     Epoch: 70
2022-11-18 01:24:12,608 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7966582664223605, 'Total loss': 0.7966582664223605} | train loss {'Reaction outcome loss': 0.8023711634622075, 'Total loss': 0.8023711634622075}
2022-11-18 01:24:12,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:12,609 INFO:     Epoch: 71
2022-11-18 01:24:13,392 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.793544705524001, 'Total loss': 0.793544705524001} | train loss {'Reaction outcome loss': 0.8025867943941805, 'Total loss': 0.8025867943941805}
2022-11-18 01:24:13,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:13,392 INFO:     Epoch: 72
2022-11-18 01:24:14,181 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8260628421639287, 'Total loss': 0.8260628421639287} | train loss {'Reaction outcome loss': 0.803436068949363, 'Total loss': 0.803436068949363}
2022-11-18 01:24:14,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:14,182 INFO:     Epoch: 73
2022-11-18 01:24:14,945 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8104721224585245, 'Total loss': 0.8104721224585245} | train loss {'Reaction outcome loss': 0.8020746242950566, 'Total loss': 0.8020746242950566}
2022-11-18 01:24:14,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:14,945 INFO:     Epoch: 74
2022-11-18 01:24:15,750 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8019904147746951, 'Total loss': 0.8019904147746951} | train loss {'Reaction outcome loss': 0.7978771700527658, 'Total loss': 0.7978771700527658}
2022-11-18 01:24:15,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:15,750 INFO:     Epoch: 75
2022-11-18 01:24:16,557 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8330593802208124, 'Total loss': 0.8330593802208124} | train loss {'Reaction outcome loss': 0.8015896294621511, 'Total loss': 0.8015896294621511}
2022-11-18 01:24:16,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:16,557 INFO:     Epoch: 76
2022-11-18 01:24:17,361 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7962692158166752, 'Total loss': 0.7962692158166752} | train loss {'Reaction outcome loss': 0.8062374695084402, 'Total loss': 0.8062374695084402}
2022-11-18 01:24:17,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:17,362 INFO:     Epoch: 77
2022-11-18 01:24:18,154 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7927307354849439, 'Total loss': 0.7927307354849439} | train loss {'Reaction outcome loss': 0.8060238194416173, 'Total loss': 0.8060238194416173}
2022-11-18 01:24:18,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:18,155 INFO:     Epoch: 78
2022-11-18 01:24:18,957 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8016262470289718, 'Total loss': 0.8016262470289718} | train loss {'Reaction outcome loss': 0.8028197361473226, 'Total loss': 0.8028197361473226}
2022-11-18 01:24:18,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:18,957 INFO:     Epoch: 79
2022-11-18 01:24:19,752 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7966087127840796, 'Total loss': 0.7966087127840796} | train loss {'Reaction outcome loss': 0.7983130418166086, 'Total loss': 0.7983130418166086}
2022-11-18 01:24:19,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:19,752 INFO:     Epoch: 80
2022-11-18 01:24:20,552 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7984784148460211, 'Total loss': 0.7984784148460211} | train loss {'Reaction outcome loss': 0.800850149754172, 'Total loss': 0.800850149754172}
2022-11-18 01:24:20,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:20,552 INFO:     Epoch: 81
2022-11-18 01:24:21,385 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8076542123805645, 'Total loss': 0.8076542123805645} | train loss {'Reaction outcome loss': 0.8019683725853679, 'Total loss': 0.8019683725853679}
2022-11-18 01:24:21,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:21,387 INFO:     Epoch: 82
2022-11-18 01:24:22,181 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.803644013959308, 'Total loss': 0.803644013959308} | train loss {'Reaction outcome loss': 0.7995467878476218, 'Total loss': 0.7995467878476218}
2022-11-18 01:24:22,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:22,181 INFO:     Epoch: 83
2022-11-18 01:24:22,962 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8026735352915387, 'Total loss': 0.8026735352915387} | train loss {'Reaction outcome loss': 0.8020374502878466, 'Total loss': 0.8020374502878466}
2022-11-18 01:24:22,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:22,962 INFO:     Epoch: 84
2022-11-18 01:24:23,713 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7925124639688537, 'Total loss': 0.7925124639688537} | train loss {'Reaction outcome loss': 0.8009940293072665, 'Total loss': 0.8009940293072665}
2022-11-18 01:24:23,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:23,713 INFO:     Epoch: 85
2022-11-18 01:24:24,497 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7976920639359674, 'Total loss': 0.7976920639359674} | train loss {'Reaction outcome loss': 0.8046078479141615, 'Total loss': 0.8046078479141615}
2022-11-18 01:24:24,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:24,497 INFO:     Epoch: 86
2022-11-18 01:24:25,285 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7918415062649306, 'Total loss': 0.7918415062649306} | train loss {'Reaction outcome loss': 0.8022403205084109, 'Total loss': 0.8022403205084109}
2022-11-18 01:24:25,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:25,285 INFO:     Epoch: 87
2022-11-18 01:24:26,078 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8010113592757735, 'Total loss': 0.8010113592757735} | train loss {'Reaction outcome loss': 0.8008374309638724, 'Total loss': 0.8008374309638724}
2022-11-18 01:24:26,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:26,078 INFO:     Epoch: 88
2022-11-18 01:24:26,896 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7896839595118235, 'Total loss': 0.7896839595118235} | train loss {'Reaction outcome loss': 0.8048425651932158, 'Total loss': 0.8048425651932158}
2022-11-18 01:24:26,896 INFO:     Found new best model at epoch 88
2022-11-18 01:24:26,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:26,897 INFO:     Epoch: 89
2022-11-18 01:24:27,682 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8052016344181326, 'Total loss': 0.8052016344181326} | train loss {'Reaction outcome loss': 0.8020387669074585, 'Total loss': 0.8020387669074585}
2022-11-18 01:24:27,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:27,684 INFO:     Epoch: 90
2022-11-18 01:24:28,466 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8190502434275871, 'Total loss': 0.8190502434275871} | train loss {'Reaction outcome loss': 0.8008936461818663, 'Total loss': 0.8008936461818663}
2022-11-18 01:24:28,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:28,466 INFO:     Epoch: 91
2022-11-18 01:24:29,278 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8514231526574423, 'Total loss': 0.8514231526574423} | train loss {'Reaction outcome loss': 0.7985005812773566, 'Total loss': 0.7985005812773566}
2022-11-18 01:24:29,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:29,278 INFO:     Epoch: 92
2022-11-18 01:24:30,116 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8054050297238106, 'Total loss': 0.8054050297238106} | train loss {'Reaction outcome loss': 0.8050118108508003, 'Total loss': 0.8050118108508003}
2022-11-18 01:24:30,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:30,116 INFO:     Epoch: 93
2022-11-18 01:24:30,900 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8037991995035216, 'Total loss': 0.8037991995035216} | train loss {'Reaction outcome loss': 0.7997969832905101, 'Total loss': 0.7997969832905101}
2022-11-18 01:24:30,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:30,900 INFO:     Epoch: 94
2022-11-18 01:24:31,678 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7887124474658522, 'Total loss': 0.7887124474658522} | train loss {'Reaction outcome loss': 0.8071867666551187, 'Total loss': 0.8071867666551187}
2022-11-18 01:24:31,678 INFO:     Found new best model at epoch 94
2022-11-18 01:24:31,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:31,679 INFO:     Epoch: 95
2022-11-18 01:24:32,445 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8029184847377068, 'Total loss': 0.8029184847377068} | train loss {'Reaction outcome loss': 0.7999592934159322, 'Total loss': 0.7999592934159322}
2022-11-18 01:24:32,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:32,446 INFO:     Epoch: 96
2022-11-18 01:24:33,221 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8005776273649793, 'Total loss': 0.8005776273649793} | train loss {'Reaction outcome loss': 0.8004131923078007, 'Total loss': 0.8004131923078007}
2022-11-18 01:24:33,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:33,222 INFO:     Epoch: 97
2022-11-18 01:24:34,028 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8282035734764365, 'Total loss': 0.8282035734764365} | train loss {'Reaction outcome loss': 0.800505358648498, 'Total loss': 0.800505358648498}
2022-11-18 01:24:34,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:34,028 INFO:     Epoch: 98
2022-11-18 01:24:34,785 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7987027798974237, 'Total loss': 0.7987027798974237} | train loss {'Reaction outcome loss': 0.8004656781546803, 'Total loss': 0.8004656781546803}
2022-11-18 01:24:34,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:34,786 INFO:     Epoch: 99
2022-11-18 01:24:35,592 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8139700709387313, 'Total loss': 0.8139700709387313} | train loss {'Reaction outcome loss': 0.8053793622745024, 'Total loss': 0.8053793622745024}
2022-11-18 01:24:35,592 INFO:     Best model found after epoch 95 of 100.
2022-11-18 01:24:35,592 INFO:   Done with stage: TRAINING
2022-11-18 01:24:35,592 INFO:   Starting stage: EVALUATION
2022-11-18 01:24:35,739 INFO:   Done with stage: EVALUATION
2022-11-18 01:24:35,739 INFO:   Leaving out SEQ value Fold_3
2022-11-18 01:24:35,753 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 01:24:35,753 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:24:36,412 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:24:36,412 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:24:36,481 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:24:36,481 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:24:36,481 INFO:     No hyperparam tuning for this model
2022-11-18 01:24:36,481 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:24:36,482 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:24:36,482 INFO:     None feature selector for col prot
2022-11-18 01:24:36,482 INFO:     None feature selector for col prot
2022-11-18 01:24:36,483 INFO:     None feature selector for col prot
2022-11-18 01:24:36,483 INFO:     None feature selector for col chem
2022-11-18 01:24:36,483 INFO:     None feature selector for col chem
2022-11-18 01:24:36,483 INFO:     None feature selector for col chem
2022-11-18 01:24:36,483 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:24:36,483 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:24:36,485 INFO:     Number of params in model 168571
2022-11-18 01:24:36,488 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:24:36,488 INFO:   Starting stage: TRAINING
2022-11-18 01:24:36,545 INFO:     Val loss before train {'Reaction outcome loss': 1.0041225677312806, 'Total loss': 1.0041225677312806}
2022-11-18 01:24:36,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:36,546 INFO:     Epoch: 0
2022-11-18 01:24:37,338 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8134046446445377, 'Total loss': 0.8134046446445377} | train loss {'Reaction outcome loss': 0.8787014701815902, 'Total loss': 0.8787014701815902}
2022-11-18 01:24:37,338 INFO:     Found new best model at epoch 0
2022-11-18 01:24:37,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:37,339 INFO:     Epoch: 1
2022-11-18 01:24:38,149 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8178021588990855, 'Total loss': 0.8178021588990855} | train loss {'Reaction outcome loss': 0.841514339701074, 'Total loss': 0.841514339701074}
2022-11-18 01:24:38,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:38,149 INFO:     Epoch: 2
2022-11-18 01:24:38,964 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8090919873049093, 'Total loss': 0.8090919873049093} | train loss {'Reaction outcome loss': 0.8407281220692103, 'Total loss': 0.8407281220692103}
2022-11-18 01:24:38,964 INFO:     Found new best model at epoch 2
2022-11-18 01:24:38,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:38,965 INFO:     Epoch: 3
2022-11-18 01:24:39,765 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.807336779527886, 'Total loss': 0.807336779527886} | train loss {'Reaction outcome loss': 0.8331771902129298, 'Total loss': 0.8331771902129298}
2022-11-18 01:24:39,766 INFO:     Found new best model at epoch 3
2022-11-18 01:24:39,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:39,767 INFO:     Epoch: 4
2022-11-18 01:24:40,596 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8027949534183325, 'Total loss': 0.8027949534183325} | train loss {'Reaction outcome loss': 0.8252795138319985, 'Total loss': 0.8252795138319985}
2022-11-18 01:24:40,597 INFO:     Found new best model at epoch 4
2022-11-18 01:24:40,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:40,598 INFO:     Epoch: 5
2022-11-18 01:24:41,377 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7965785916461501, 'Total loss': 0.7965785916461501} | train loss {'Reaction outcome loss': 0.8216497865123827, 'Total loss': 0.8216497865123827}
2022-11-18 01:24:41,377 INFO:     Found new best model at epoch 5
2022-11-18 01:24:41,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:41,378 INFO:     Epoch: 6
2022-11-18 01:24:42,192 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7913507749867994, 'Total loss': 0.7913507749867994} | train loss {'Reaction outcome loss': 0.8233004970872988, 'Total loss': 0.8233004970872988}
2022-11-18 01:24:42,193 INFO:     Found new best model at epoch 6
2022-11-18 01:24:42,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:42,194 INFO:     Epoch: 7
2022-11-18 01:24:42,977 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8026031740876132, 'Total loss': 0.8026031740876132} | train loss {'Reaction outcome loss': 0.8174244959334858, 'Total loss': 0.8174244959334858}
2022-11-18 01:24:42,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:42,977 INFO:     Epoch: 8
2022-11-18 01:24:43,767 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7939386568790259, 'Total loss': 0.7939386568790259} | train loss {'Reaction outcome loss': 0.8196103837890704, 'Total loss': 0.8196103837890704}
2022-11-18 01:24:43,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:43,767 INFO:     Epoch: 9
2022-11-18 01:24:44,519 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7965815039568169, 'Total loss': 0.7965815039568169} | train loss {'Reaction outcome loss': 0.8166321728561745, 'Total loss': 0.8166321728561745}
2022-11-18 01:24:44,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:44,520 INFO:     Epoch: 10
2022-11-18 01:24:45,307 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8079850438029267, 'Total loss': 0.8079850438029267} | train loss {'Reaction outcome loss': 0.8119448358651067, 'Total loss': 0.8119448358651067}
2022-11-18 01:24:45,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:45,307 INFO:     Epoch: 11
2022-11-18 01:24:46,082 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8048174000063608, 'Total loss': 0.8048174000063608} | train loss {'Reaction outcome loss': 0.8182833439013997, 'Total loss': 0.8182833439013997}
2022-11-18 01:24:46,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:46,083 INFO:     Epoch: 12
2022-11-18 01:24:46,850 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7947377222915029, 'Total loss': 0.7947377222915029} | train loss {'Reaction outcome loss': 0.8140815674770073, 'Total loss': 0.8140815674770073}
2022-11-18 01:24:46,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:46,850 INFO:     Epoch: 13
2022-11-18 01:24:47,609 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.820123155449712, 'Total loss': 0.820123155449712} | train loss {'Reaction outcome loss': 0.8158338565806873, 'Total loss': 0.8158338565806873}
2022-11-18 01:24:47,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:47,609 INFO:     Epoch: 14
2022-11-18 01:24:48,365 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8061659363813178, 'Total loss': 0.8061659363813178} | train loss {'Reaction outcome loss': 0.8178015321981712, 'Total loss': 0.8178015321981712}
2022-11-18 01:24:48,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:48,365 INFO:     Epoch: 15
2022-11-18 01:24:49,143 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7924330352350722, 'Total loss': 0.7924330352350722} | train loss {'Reaction outcome loss': 0.8135685049852387, 'Total loss': 0.8135685049852387}
2022-11-18 01:24:49,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:49,143 INFO:     Epoch: 16
2022-11-18 01:24:49,913 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7850193811017413, 'Total loss': 0.7850193811017413} | train loss {'Reaction outcome loss': 0.8159964303257036, 'Total loss': 0.8159964303257036}
2022-11-18 01:24:49,913 INFO:     Found new best model at epoch 16
2022-11-18 01:24:49,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:49,914 INFO:     Epoch: 17
2022-11-18 01:24:50,716 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7958163840826168, 'Total loss': 0.7958163840826168} | train loss {'Reaction outcome loss': 0.8162142920200942, 'Total loss': 0.8162142920200942}
2022-11-18 01:24:50,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:50,716 INFO:     Epoch: 18
2022-11-18 01:24:51,497 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7911214287890944, 'Total loss': 0.7911214287890944} | train loss {'Reaction outcome loss': 0.8132038755250759, 'Total loss': 0.8132038755250759}
2022-11-18 01:24:51,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:51,497 INFO:     Epoch: 19
2022-11-18 01:24:52,278 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8056742465773294, 'Total loss': 0.8056742465773294} | train loss {'Reaction outcome loss': 0.8143161778322986, 'Total loss': 0.8143161778322986}
2022-11-18 01:24:52,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:52,280 INFO:     Epoch: 20
2022-11-18 01:24:53,063 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7912731586500655, 'Total loss': 0.7912731586500655} | train loss {'Reaction outcome loss': 0.813740149873202, 'Total loss': 0.813740149873202}
2022-11-18 01:24:53,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:53,063 INFO:     Epoch: 21
2022-11-18 01:24:53,835 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7933723697828692, 'Total loss': 0.7933723697828692} | train loss {'Reaction outcome loss': 0.8159445055195542, 'Total loss': 0.8159445055195542}
2022-11-18 01:24:53,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:53,835 INFO:     Epoch: 22
2022-11-18 01:24:54,586 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8170759844225507, 'Total loss': 0.8170759844225507} | train loss {'Reaction outcome loss': 0.8098093809895828, 'Total loss': 0.8098093809895828}
2022-11-18 01:24:54,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:54,586 INFO:     Epoch: 23
2022-11-18 01:24:55,350 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7880327618399332, 'Total loss': 0.7880327618399332} | train loss {'Reaction outcome loss': 0.814165787374387, 'Total loss': 0.814165787374387}
2022-11-18 01:24:55,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:55,350 INFO:     Epoch: 24
2022-11-18 01:24:56,108 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7886178410330484, 'Total loss': 0.7886178410330484} | train loss {'Reaction outcome loss': 0.8115982438941471, 'Total loss': 0.8115982438941471}
2022-11-18 01:24:56,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:56,108 INFO:     Epoch: 25
2022-11-18 01:24:56,870 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7964598183021989, 'Total loss': 0.7964598183021989} | train loss {'Reaction outcome loss': 0.8145136772120585, 'Total loss': 0.8145136772120585}
2022-11-18 01:24:56,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:56,870 INFO:     Epoch: 26
2022-11-18 01:24:57,673 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7831555168296016, 'Total loss': 0.7831555168296016} | train loss {'Reaction outcome loss': 0.8153823169528461, 'Total loss': 0.8153823169528461}
2022-11-18 01:24:57,673 INFO:     Found new best model at epoch 26
2022-11-18 01:24:57,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:57,674 INFO:     Epoch: 27
2022-11-18 01:24:58,430 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7981137647185215, 'Total loss': 0.7981137647185215} | train loss {'Reaction outcome loss': 0.8098005873502278, 'Total loss': 0.8098005873502278}
2022-11-18 01:24:58,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:58,431 INFO:     Epoch: 28
2022-11-18 01:24:59,195 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7872127460878949, 'Total loss': 0.7872127460878949} | train loss {'Reaction outcome loss': 0.8109428260902889, 'Total loss': 0.8109428260902889}
2022-11-18 01:24:59,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:59,196 INFO:     Epoch: 29
2022-11-18 01:24:59,963 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7818112622859866, 'Total loss': 0.7818112622859866} | train loss {'Reaction outcome loss': 0.8111399075046914, 'Total loss': 0.8111399075046914}
2022-11-18 01:24:59,963 INFO:     Found new best model at epoch 29
2022-11-18 01:24:59,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:24:59,964 INFO:     Epoch: 30
2022-11-18 01:25:00,752 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8093638988428338, 'Total loss': 0.8093638988428338} | train loss {'Reaction outcome loss': 0.8099978342652321, 'Total loss': 0.8099978342652321}
2022-11-18 01:25:00,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:00,752 INFO:     Epoch: 31
2022-11-18 01:25:01,550 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7887952258420545, 'Total loss': 0.7887952258420545} | train loss {'Reaction outcome loss': 0.8105677026705663, 'Total loss': 0.8105677026705663}
2022-11-18 01:25:01,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:01,550 INFO:     Epoch: 32
2022-11-18 01:25:02,390 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8115263220875762, 'Total loss': 0.8115263220875762} | train loss {'Reaction outcome loss': 0.8100877346806838, 'Total loss': 0.8100877346806838}
2022-11-18 01:25:02,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:02,390 INFO:     Epoch: 33
2022-11-18 01:25:03,205 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.779405488524326, 'Total loss': 0.779405488524326} | train loss {'Reaction outcome loss': 0.8123025614462915, 'Total loss': 0.8123025614462915}
2022-11-18 01:25:03,206 INFO:     Found new best model at epoch 33
2022-11-18 01:25:03,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:03,206 INFO:     Epoch: 34
2022-11-18 01:25:04,003 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8038385136182918, 'Total loss': 0.8038385136182918} | train loss {'Reaction outcome loss': 0.8091312197388195, 'Total loss': 0.8091312197388195}
2022-11-18 01:25:04,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:04,004 INFO:     Epoch: 35
2022-11-18 01:25:04,811 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7914213649062223, 'Total loss': 0.7914213649062223} | train loss {'Reaction outcome loss': 0.8149839703176842, 'Total loss': 0.8149839703176842}
2022-11-18 01:25:04,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:04,811 INFO:     Epoch: 36
2022-11-18 01:25:05,608 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7889290937157565, 'Total loss': 0.7889290937157565} | train loss {'Reaction outcome loss': 0.8062033095076436, 'Total loss': 0.8062033095076436}
2022-11-18 01:25:05,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:05,609 INFO:     Epoch: 37
2022-11-18 01:25:06,393 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7798008385092713, 'Total loss': 0.7798008385092713} | train loss {'Reaction outcome loss': 0.8086038636135273, 'Total loss': 0.8086038636135273}
2022-11-18 01:25:06,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:06,393 INFO:     Epoch: 38
2022-11-18 01:25:07,227 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7996006566424703, 'Total loss': 0.7996006566424703} | train loss {'Reaction outcome loss': 0.8090689686722443, 'Total loss': 0.8090689686722443}
2022-11-18 01:25:07,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:07,227 INFO:     Epoch: 39
2022-11-18 01:25:08,056 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7927575416343157, 'Total loss': 0.7927575416343157} | train loss {'Reaction outcome loss': 0.8063066644502468, 'Total loss': 0.8063066644502468}
2022-11-18 01:25:08,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:08,056 INFO:     Epoch: 40
2022-11-18 01:25:08,837 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7789068734923075, 'Total loss': 0.7789068734923075} | train loss {'Reaction outcome loss': 0.808943580897128, 'Total loss': 0.808943580897128}
2022-11-18 01:25:08,837 INFO:     Found new best model at epoch 40
2022-11-18 01:25:08,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:08,838 INFO:     Epoch: 41
2022-11-18 01:25:09,647 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7855584170929221, 'Total loss': 0.7855584170929221} | train loss {'Reaction outcome loss': 0.8117009866677347, 'Total loss': 0.8117009866677347}
2022-11-18 01:25:09,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:09,648 INFO:     Epoch: 42
2022-11-18 01:25:10,457 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7900063804415769, 'Total loss': 0.7900063804415769} | train loss {'Reaction outcome loss': 0.8078145664490637, 'Total loss': 0.8078145664490637}
2022-11-18 01:25:10,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:10,458 INFO:     Epoch: 43
2022-11-18 01:25:11,257 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.790042809968771, 'Total loss': 0.790042809968771} | train loss {'Reaction outcome loss': 0.8061425600384102, 'Total loss': 0.8061425600384102}
2022-11-18 01:25:11,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:11,258 INFO:     Epoch: 44
2022-11-18 01:25:12,057 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.779754712138065, 'Total loss': 0.779754712138065} | train loss {'Reaction outcome loss': 0.8096029184392242, 'Total loss': 0.8096029184392242}
2022-11-18 01:25:12,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:12,057 INFO:     Epoch: 45
2022-11-18 01:25:12,851 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8032579643781795, 'Total loss': 0.8032579643781795} | train loss {'Reaction outcome loss': 0.8052832451267321, 'Total loss': 0.8052832451267321}
2022-11-18 01:25:12,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:12,851 INFO:     Epoch: 46
2022-11-18 01:25:13,676 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8105779345645461, 'Total loss': 0.8105779345645461} | train loss {'Reaction outcome loss': 0.8120693028217456, 'Total loss': 0.8120693028217456}
2022-11-18 01:25:13,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:13,677 INFO:     Epoch: 47
2022-11-18 01:25:14,439 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7922013748523801, 'Total loss': 0.7922013748523801} | train loss {'Reaction outcome loss': 0.8109834851300131, 'Total loss': 0.8109834851300131}
2022-11-18 01:25:14,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:14,440 INFO:     Epoch: 48
2022-11-18 01:25:15,284 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7950652283291484, 'Total loss': 0.7950652283291484} | train loss {'Reaction outcome loss': 0.805506374992308, 'Total loss': 0.805506374992308}
2022-11-18 01:25:15,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:15,284 INFO:     Epoch: 49
2022-11-18 01:25:16,104 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8071518228497616, 'Total loss': 0.8071518228497616} | train loss {'Reaction outcome loss': 0.8099776810554208, 'Total loss': 0.8099776810554208}
2022-11-18 01:25:16,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:16,104 INFO:     Epoch: 50
2022-11-18 01:25:16,858 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.783331586177959, 'Total loss': 0.783331586177959} | train loss {'Reaction outcome loss': 0.8108073045484355, 'Total loss': 0.8108073045484355}
2022-11-18 01:25:16,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:16,859 INFO:     Epoch: 51
2022-11-18 01:25:17,629 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7857882519100987, 'Total loss': 0.7857882519100987} | train loss {'Reaction outcome loss': 0.8074375061226673, 'Total loss': 0.8074375061226673}
2022-11-18 01:25:17,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:17,629 INFO:     Epoch: 52
2022-11-18 01:25:18,415 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8055304025494775, 'Total loss': 0.8055304025494775} | train loss {'Reaction outcome loss': 0.811994059164016, 'Total loss': 0.811994059164016}
2022-11-18 01:25:18,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:18,415 INFO:     Epoch: 53
2022-11-18 01:25:19,179 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8069374090017274, 'Total loss': 0.8069374090017274} | train loss {'Reaction outcome loss': 0.8109996262632433, 'Total loss': 0.8109996262632433}
2022-11-18 01:25:19,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:19,179 INFO:     Epoch: 54
2022-11-18 01:25:19,966 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7812667904898177, 'Total loss': 0.7812667904898177} | train loss {'Reaction outcome loss': 0.812460796144165, 'Total loss': 0.812460796144165}
2022-11-18 01:25:19,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:19,966 INFO:     Epoch: 55
2022-11-18 01:25:20,753 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7859698430050251, 'Total loss': 0.7859698430050251} | train loss {'Reaction outcome loss': 0.807939246541164, 'Total loss': 0.807939246541164}
2022-11-18 01:25:20,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:20,754 INFO:     Epoch: 56
2022-11-18 01:25:21,516 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7903303878251896, 'Total loss': 0.7903303878251896} | train loss {'Reaction outcome loss': 0.8060983885995677, 'Total loss': 0.8060983885995677}
2022-11-18 01:25:21,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:21,516 INFO:     Epoch: 57
2022-11-18 01:25:22,273 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7905111222766167, 'Total loss': 0.7905111222766167} | train loss {'Reaction outcome loss': 0.8109418688738932, 'Total loss': 0.8109418688738932}
2022-11-18 01:25:22,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:22,273 INFO:     Epoch: 58
2022-11-18 01:25:23,059 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7825811186502146, 'Total loss': 0.7825811186502146} | train loss {'Reaction outcome loss': 0.8104324899003154, 'Total loss': 0.8104324899003154}
2022-11-18 01:25:23,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:23,060 INFO:     Epoch: 59
2022-11-18 01:25:23,876 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7936353274556094, 'Total loss': 0.7936353274556094} | train loss {'Reaction outcome loss': 0.8048158190289482, 'Total loss': 0.8048158190289482}
2022-11-18 01:25:23,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:23,876 INFO:     Epoch: 60
2022-11-18 01:25:24,642 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7824417692284251, 'Total loss': 0.7824417692284251} | train loss {'Reaction outcome loss': 0.8132259534274946, 'Total loss': 0.8132259534274946}
2022-11-18 01:25:24,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:24,642 INFO:     Epoch: 61
2022-11-18 01:25:25,444 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7928950440051944, 'Total loss': 0.7928950440051944} | train loss {'Reaction outcome loss': 0.8101421907299855, 'Total loss': 0.8101421907299855}
2022-11-18 01:25:25,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:25,444 INFO:     Epoch: 62
2022-11-18 01:25:26,226 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7861991621727167, 'Total loss': 0.7861991621727167} | train loss {'Reaction outcome loss': 0.8080968229008503, 'Total loss': 0.8080968229008503}
2022-11-18 01:25:26,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:26,226 INFO:     Epoch: 63
2022-11-18 01:25:26,986 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.787482272746951, 'Total loss': 0.787482272746951} | train loss {'Reaction outcome loss': 0.8086633104525629, 'Total loss': 0.8086633104525629}
2022-11-18 01:25:26,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:26,987 INFO:     Epoch: 64
2022-11-18 01:25:27,790 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7921542414399081, 'Total loss': 0.7921542414399081} | train loss {'Reaction outcome loss': 0.8048521534341281, 'Total loss': 0.8048521534341281}
2022-11-18 01:25:27,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:27,790 INFO:     Epoch: 65
2022-11-18 01:25:28,600 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7892887911131216, 'Total loss': 0.7892887911131216} | train loss {'Reaction outcome loss': 0.8128590635100349, 'Total loss': 0.8128590635100349}
2022-11-18 01:25:28,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:28,601 INFO:     Epoch: 66
2022-11-18 01:25:29,373 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.808813672426135, 'Total loss': 0.808813672426135} | train loss {'Reaction outcome loss': 0.8112998470419743, 'Total loss': 0.8112998470419743}
2022-11-18 01:25:29,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:29,374 INFO:     Epoch: 67
2022-11-18 01:25:30,198 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7806528799755629, 'Total loss': 0.7806528799755629} | train loss {'Reaction outcome loss': 0.8089860347939319, 'Total loss': 0.8089860347939319}
2022-11-18 01:25:30,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:30,199 INFO:     Epoch: 68
2022-11-18 01:25:30,971 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7787428941837576, 'Total loss': 0.7787428941837576} | train loss {'Reaction outcome loss': 0.8060607756259012, 'Total loss': 0.8060607756259012}
2022-11-18 01:25:30,972 INFO:     Found new best model at epoch 68
2022-11-18 01:25:30,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:30,973 INFO:     Epoch: 69
2022-11-18 01:25:31,776 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7893605544123539, 'Total loss': 0.7893605544123539} | train loss {'Reaction outcome loss': 0.8053047059745085, 'Total loss': 0.8053047059745085}
2022-11-18 01:25:31,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:31,776 INFO:     Epoch: 70
2022-11-18 01:25:32,564 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7804554271143537, 'Total loss': 0.7804554271143537} | train loss {'Reaction outcome loss': 0.8077281643865538, 'Total loss': 0.8077281643865538}
2022-11-18 01:25:32,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:32,564 INFO:     Epoch: 71
2022-11-18 01:25:33,356 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7871001563793005, 'Total loss': 0.7871001563793005} | train loss {'Reaction outcome loss': 0.8107516019315016, 'Total loss': 0.8107516019315016}
2022-11-18 01:25:33,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:33,356 INFO:     Epoch: 72
2022-11-18 01:25:34,171 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8411907331888065, 'Total loss': 0.8411907331888065} | train loss {'Reaction outcome loss': 0.8065136661295031, 'Total loss': 0.8065136661295031}
2022-11-18 01:25:34,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:34,171 INFO:     Epoch: 73
2022-11-18 01:25:34,962 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7920471201109331, 'Total loss': 0.7920471201109331} | train loss {'Reaction outcome loss': 0.8093741511712309, 'Total loss': 0.8093741511712309}
2022-11-18 01:25:34,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:34,962 INFO:     Epoch: 74
2022-11-18 01:25:35,784 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7948390959307204, 'Total loss': 0.7948390959307204} | train loss {'Reaction outcome loss': 0.8029929721941713, 'Total loss': 0.8029929721941713}
2022-11-18 01:25:35,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:35,784 INFO:     Epoch: 75
2022-11-18 01:25:36,544 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7744727065396864, 'Total loss': 0.7744727065396864} | train loss {'Reaction outcome loss': 0.8095277591806943, 'Total loss': 0.8095277591806943}
2022-11-18 01:25:36,544 INFO:     Found new best model at epoch 75
2022-11-18 01:25:36,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:36,545 INFO:     Epoch: 76
2022-11-18 01:25:37,339 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8027767150901085, 'Total loss': 0.8027767150901085} | train loss {'Reaction outcome loss': 0.8053035766619151, 'Total loss': 0.8053035766619151}
2022-11-18 01:25:37,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:37,339 INFO:     Epoch: 77
2022-11-18 01:25:38,159 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7950791813606439, 'Total loss': 0.7950791813606439} | train loss {'Reaction outcome loss': 0.8128927271874224, 'Total loss': 0.8128927271874224}
2022-11-18 01:25:38,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:38,160 INFO:     Epoch: 78
2022-11-18 01:25:38,969 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7883946611437687, 'Total loss': 0.7883946611437687} | train loss {'Reaction outcome loss': 0.8046738048557376, 'Total loss': 0.8046738048557376}
2022-11-18 01:25:38,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:38,969 INFO:     Epoch: 79
2022-11-18 01:25:39,777 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7702825346658396, 'Total loss': 0.7702825346658396} | train loss {'Reaction outcome loss': 0.8045821126367225, 'Total loss': 0.8045821126367225}
2022-11-18 01:25:39,777 INFO:     Found new best model at epoch 79
2022-11-18 01:25:39,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:39,778 INFO:     Epoch: 80
2022-11-18 01:25:40,564 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7888189124506574, 'Total loss': 0.7888189124506574} | train loss {'Reaction outcome loss': 0.8062646315723169, 'Total loss': 0.8062646315723169}
2022-11-18 01:25:40,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:40,564 INFO:     Epoch: 81
2022-11-18 01:25:41,328 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7924219210480534, 'Total loss': 0.7924219210480534} | train loss {'Reaction outcome loss': 0.8105174111293965, 'Total loss': 0.8105174111293965}
2022-11-18 01:25:41,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:41,328 INFO:     Epoch: 82
2022-11-18 01:25:42,116 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7785080754479696, 'Total loss': 0.7785080754479696} | train loss {'Reaction outcome loss': 0.8047922414834382, 'Total loss': 0.8047922414834382}
2022-11-18 01:25:42,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:42,117 INFO:     Epoch: 83
2022-11-18 01:25:42,878 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7753363404163095, 'Total loss': 0.7753363404163095} | train loss {'Reaction outcome loss': 0.8036990526025413, 'Total loss': 0.8036990526025413}
2022-11-18 01:25:42,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:42,878 INFO:     Epoch: 84
2022-11-18 01:25:43,666 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7770134363063547, 'Total loss': 0.7770134363063547} | train loss {'Reaction outcome loss': 0.8099049405484903, 'Total loss': 0.8099049405484903}
2022-11-18 01:25:43,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:43,667 INFO:     Epoch: 85
2022-11-18 01:25:44,441 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7941140546355137, 'Total loss': 0.7941140546355137} | train loss {'Reaction outcome loss': 0.8070853852102013, 'Total loss': 0.8070853852102013}
2022-11-18 01:25:44,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:44,441 INFO:     Epoch: 86
2022-11-18 01:25:45,210 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7899184913136238, 'Total loss': 0.7899184913136238} | train loss {'Reaction outcome loss': 0.8060058466479426, 'Total loss': 0.8060058466479426}
2022-11-18 01:25:45,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:45,211 INFO:     Epoch: 87
2022-11-18 01:25:45,981 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7858932843041975, 'Total loss': 0.7858932843041975} | train loss {'Reaction outcome loss': 0.8053667595396277, 'Total loss': 0.8053667595396277}
2022-11-18 01:25:45,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:45,981 INFO:     Epoch: 88
2022-11-18 01:25:46,734 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7851046864376512, 'Total loss': 0.7851046864376512} | train loss {'Reaction outcome loss': 0.8114299147588308, 'Total loss': 0.8114299147588308}
2022-11-18 01:25:46,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:46,734 INFO:     Epoch: 89
2022-11-18 01:25:47,486 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7879082220931386, 'Total loss': 0.7879082220931386} | train loss {'Reaction outcome loss': 0.8070418868885666, 'Total loss': 0.8070418868885666}
2022-11-18 01:25:47,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:47,486 INFO:     Epoch: 90
2022-11-18 01:25:48,248 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7823612170163975, 'Total loss': 0.7823612170163975} | train loss {'Reaction outcome loss': 0.8127571521479575, 'Total loss': 0.8127571521479575}
2022-11-18 01:25:48,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:48,248 INFO:     Epoch: 91
2022-11-18 01:25:49,012 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7881465886914453, 'Total loss': 0.7881465886914453} | train loss {'Reaction outcome loss': 0.8113408646866923, 'Total loss': 0.8113408646866923}
2022-11-18 01:25:49,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:49,012 INFO:     Epoch: 92
2022-11-18 01:25:49,804 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.780972191067629, 'Total loss': 0.780972191067629} | train loss {'Reaction outcome loss': 0.8043964148544874, 'Total loss': 0.8043964148544874}
2022-11-18 01:25:49,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:49,804 INFO:     Epoch: 93
2022-11-18 01:25:50,541 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7793633036835249, 'Total loss': 0.7793633036835249} | train loss {'Reaction outcome loss': 0.8064857814155642, 'Total loss': 0.8064857814155642}
2022-11-18 01:25:50,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:50,541 INFO:     Epoch: 94
2022-11-18 01:25:51,323 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7911047478054845, 'Total loss': 0.7911047478054845} | train loss {'Reaction outcome loss': 0.8027980457075307, 'Total loss': 0.8027980457075307}
2022-11-18 01:25:51,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:51,324 INFO:     Epoch: 95
2022-11-18 01:25:52,098 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7976489455200905, 'Total loss': 0.7976489455200905} | train loss {'Reaction outcome loss': 0.8048146792122575, 'Total loss': 0.8048146792122575}
2022-11-18 01:25:52,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:52,098 INFO:     Epoch: 96
2022-11-18 01:25:52,857 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7907559538996497, 'Total loss': 0.7907559538996497} | train loss {'Reaction outcome loss': 0.8078120734359397, 'Total loss': 0.8078120734359397}
2022-11-18 01:25:52,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:52,857 INFO:     Epoch: 97
2022-11-18 01:25:53,607 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7641059160232544, 'Total loss': 0.7641059160232544} | train loss {'Reaction outcome loss': 0.8105911776179173, 'Total loss': 0.8105911776179173}
2022-11-18 01:25:53,608 INFO:     Found new best model at epoch 97
2022-11-18 01:25:53,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:53,608 INFO:     Epoch: 98
2022-11-18 01:25:54,370 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7914110616196034, 'Total loss': 0.7914110616196034} | train loss {'Reaction outcome loss': 0.8104565513671421, 'Total loss': 0.8104565513671421}
2022-11-18 01:25:54,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:54,370 INFO:     Epoch: 99
2022-11-18 01:25:55,149 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8135854255321414, 'Total loss': 0.8135854255321414} | train loss {'Reaction outcome loss': 0.8067042502712031, 'Total loss': 0.8067042502712031}
2022-11-18 01:25:55,151 INFO:     Best model found after epoch 98 of 100.
2022-11-18 01:25:55,151 INFO:   Done with stage: TRAINING
2022-11-18 01:25:55,151 INFO:   Starting stage: EVALUATION
2022-11-18 01:25:55,285 INFO:   Done with stage: EVALUATION
2022-11-18 01:25:55,286 INFO:   Leaving out SEQ value Fold_4
2022-11-18 01:25:55,299 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:25:55,299 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:25:55,965 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:25:55,965 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:25:56,036 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:25:56,036 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:25:56,036 INFO:     No hyperparam tuning for this model
2022-11-18 01:25:56,036 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:25:56,036 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:25:56,037 INFO:     None feature selector for col prot
2022-11-18 01:25:56,037 INFO:     None feature selector for col prot
2022-11-18 01:25:56,037 INFO:     None feature selector for col prot
2022-11-18 01:25:56,038 INFO:     None feature selector for col chem
2022-11-18 01:25:56,038 INFO:     None feature selector for col chem
2022-11-18 01:25:56,038 INFO:     None feature selector for col chem
2022-11-18 01:25:56,038 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:25:56,038 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:25:56,040 INFO:     Number of params in model 168571
2022-11-18 01:25:56,043 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:25:56,043 INFO:   Starting stage: TRAINING
2022-11-18 01:25:56,100 INFO:     Val loss before train {'Reaction outcome loss': 0.9829215901819143, 'Total loss': 0.9829215901819143}
2022-11-18 01:25:56,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:56,101 INFO:     Epoch: 0
2022-11-18 01:25:56,888 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8085762628100135, 'Total loss': 0.8085762628100135} | train loss {'Reaction outcome loss': 0.8842744407383537, 'Total loss': 0.8842744407383537}
2022-11-18 01:25:56,888 INFO:     Found new best model at epoch 0
2022-11-18 01:25:56,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:56,889 INFO:     Epoch: 1
2022-11-18 01:25:57,654 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8441231955181469, 'Total loss': 0.8441231955181469} | train loss {'Reaction outcome loss': 0.8480582765722082, 'Total loss': 0.8480582765722082}
2022-11-18 01:25:57,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:57,655 INFO:     Epoch: 2
2022-11-18 01:25:58,415 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.796763001517816, 'Total loss': 0.796763001517816} | train loss {'Reaction outcome loss': 0.8448721588351708, 'Total loss': 0.8448721588351708}
2022-11-18 01:25:58,415 INFO:     Found new best model at epoch 2
2022-11-18 01:25:58,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:58,417 INFO:     Epoch: 3
2022-11-18 01:25:59,174 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8387523198669607, 'Total loss': 0.8387523198669607} | train loss {'Reaction outcome loss': 0.8417010184844979, 'Total loss': 0.8417010184844979}
2022-11-18 01:25:59,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:59,174 INFO:     Epoch: 4
2022-11-18 01:25:59,967 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8160122660073367, 'Total loss': 0.8160122660073367} | train loss {'Reaction outcome loss': 0.8375895036618236, 'Total loss': 0.8375895036618236}
2022-11-18 01:25:59,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:25:59,967 INFO:     Epoch: 5
2022-11-18 01:26:00,759 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8086273033510555, 'Total loss': 0.8086273033510555} | train loss {'Reaction outcome loss': 0.8424637316450899, 'Total loss': 0.8424637316450899}
2022-11-18 01:26:00,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:00,759 INFO:     Epoch: 6
2022-11-18 01:26:01,549 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7919533306902106, 'Total loss': 0.7919533306902106} | train loss {'Reaction outcome loss': 0.8383430549007679, 'Total loss': 0.8383430549007679}
2022-11-18 01:26:01,549 INFO:     Found new best model at epoch 6
2022-11-18 01:26:01,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:01,550 INFO:     Epoch: 7
2022-11-18 01:26:02,302 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7902589751915499, 'Total loss': 0.7902589751915499} | train loss {'Reaction outcome loss': 0.834147555384076, 'Total loss': 0.834147555384076}
2022-11-18 01:26:02,302 INFO:     Found new best model at epoch 7
2022-11-18 01:26:02,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:02,303 INFO:     Epoch: 8
2022-11-18 01:26:03,102 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8131406801668081, 'Total loss': 0.8131406801668081} | train loss {'Reaction outcome loss': 0.8331688626816398, 'Total loss': 0.8331688626816398}
2022-11-18 01:26:03,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:03,102 INFO:     Epoch: 9
2022-11-18 01:26:03,904 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7931318411772902, 'Total loss': 0.7931318411772902} | train loss {'Reaction outcome loss': 0.8281633915447513, 'Total loss': 0.8281633915447513}
2022-11-18 01:26:03,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:03,905 INFO:     Epoch: 10
2022-11-18 01:26:04,675 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8019820140166716, 'Total loss': 0.8019820140166716} | train loss {'Reaction outcome loss': 0.8245251018267411, 'Total loss': 0.8245251018267411}
2022-11-18 01:26:04,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:04,676 INFO:     Epoch: 11
2022-11-18 01:26:05,422 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7828032692725008, 'Total loss': 0.7828032692725008} | train loss {'Reaction outcome loss': 0.8335924497258808, 'Total loss': 0.8335924497258808}
2022-11-18 01:26:05,422 INFO:     Found new best model at epoch 11
2022-11-18 01:26:05,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:05,423 INFO:     Epoch: 12
2022-11-18 01:26:06,202 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7929042557423766, 'Total loss': 0.7929042557423766} | train loss {'Reaction outcome loss': 0.8401630879172429, 'Total loss': 0.8401630879172429}
2022-11-18 01:26:06,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:06,202 INFO:     Epoch: 13
2022-11-18 01:26:06,956 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8110979985107075, 'Total loss': 0.8110979985107075} | train loss {'Reaction outcome loss': 0.8281704321322654, 'Total loss': 0.8281704321322654}
2022-11-18 01:26:06,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:06,957 INFO:     Epoch: 14
2022-11-18 01:26:07,744 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7850377945737406, 'Total loss': 0.7850377945737406} | train loss {'Reaction outcome loss': 0.8245007515798214, 'Total loss': 0.8245007515798214}
2022-11-18 01:26:07,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:07,745 INFO:     Epoch: 15
2022-11-18 01:26:08,527 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7914370833472772, 'Total loss': 0.7914370833472772} | train loss {'Reaction outcome loss': 0.8186137129662008, 'Total loss': 0.8186137129662008}
2022-11-18 01:26:08,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:08,528 INFO:     Epoch: 16
2022-11-18 01:26:09,318 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7768796953287992, 'Total loss': 0.7768796953287992} | train loss {'Reaction outcome loss': 0.8257564694775261, 'Total loss': 0.8257564694775261}
2022-11-18 01:26:09,318 INFO:     Found new best model at epoch 16
2022-11-18 01:26:09,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:09,319 INFO:     Epoch: 17
2022-11-18 01:26:10,091 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7901514897292311, 'Total loss': 0.7901514897292311} | train loss {'Reaction outcome loss': 0.8175321396907814, 'Total loss': 0.8175321396907814}
2022-11-18 01:26:10,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:10,091 INFO:     Epoch: 18
2022-11-18 01:26:10,882 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7818862132050775, 'Total loss': 0.7818862132050775} | train loss {'Reaction outcome loss': 0.819967138743111, 'Total loss': 0.819967138743111}
2022-11-18 01:26:10,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:10,883 INFO:     Epoch: 19
2022-11-18 01:26:11,659 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7843547368591482, 'Total loss': 0.7843547368591482} | train loss {'Reaction outcome loss': 0.8253908743742506, 'Total loss': 0.8253908743742506}
2022-11-18 01:26:11,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:11,659 INFO:     Epoch: 20
2022-11-18 01:26:12,456 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.80573775077408, 'Total loss': 0.80573775077408} | train loss {'Reaction outcome loss': 0.8313578468585304, 'Total loss': 0.8313578468585304}
2022-11-18 01:26:12,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:12,457 INFO:     Epoch: 21
2022-11-18 01:26:13,238 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7934409766034647, 'Total loss': 0.7934409766034647} | train loss {'Reaction outcome loss': 0.8217508528637982, 'Total loss': 0.8217508528637982}
2022-11-18 01:26:13,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:13,238 INFO:     Epoch: 22
2022-11-18 01:26:14,007 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7944058518518101, 'Total loss': 0.7944058518518101} | train loss {'Reaction outcome loss': 0.819306806755452, 'Total loss': 0.819306806755452}
2022-11-18 01:26:14,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:14,008 INFO:     Epoch: 23
2022-11-18 01:26:14,809 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8009910637682135, 'Total loss': 0.8009910637682135} | train loss {'Reaction outcome loss': 0.8214690700505185, 'Total loss': 0.8214690700505185}
2022-11-18 01:26:14,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:14,809 INFO:     Epoch: 24
2022-11-18 01:26:15,567 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.805660067634149, 'Total loss': 0.805660067634149} | train loss {'Reaction outcome loss': 0.8180919887445234, 'Total loss': 0.8180919887445234}
2022-11-18 01:26:15,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:15,568 INFO:     Epoch: 25
2022-11-18 01:26:16,376 INFO:     After epoch 25, val loss {'Reaction outcome loss': 1.0785020535642451, 'Total loss': 1.0785020535642451} | train loss {'Reaction outcome loss': 0.8211520802878175, 'Total loss': 0.8211520802878175}
2022-11-18 01:26:16,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:16,376 INFO:     Epoch: 26
2022-11-18 01:26:17,170 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8017585914243351, 'Total loss': 0.8017585914243351} | train loss {'Reaction outcome loss': 0.8211718995561484, 'Total loss': 0.8211718995561484}
2022-11-18 01:26:17,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:17,171 INFO:     Epoch: 27
2022-11-18 01:26:17,926 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7836246097629721, 'Total loss': 0.7836246097629721} | train loss {'Reaction outcome loss': 0.8193115079209872, 'Total loss': 0.8193115079209872}
2022-11-18 01:26:17,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:17,927 INFO:     Epoch: 28
2022-11-18 01:26:18,714 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7778732736002315, 'Total loss': 0.7778732736002315} | train loss {'Reaction outcome loss': 0.8204896761036595, 'Total loss': 0.8204896761036595}
2022-11-18 01:26:18,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:18,714 INFO:     Epoch: 29
2022-11-18 01:26:19,482 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7921470512043346, 'Total loss': 0.7921470512043346} | train loss {'Reaction outcome loss': 0.8208121506550051, 'Total loss': 0.8208121506550051}
2022-11-18 01:26:19,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:19,483 INFO:     Epoch: 30
2022-11-18 01:26:20,246 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7849462669004094, 'Total loss': 0.7849462669004094} | train loss {'Reaction outcome loss': 0.8266088136053278, 'Total loss': 0.8266088136053278}
2022-11-18 01:26:20,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:20,246 INFO:     Epoch: 31
2022-11-18 01:26:21,030 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7983077344569293, 'Total loss': 0.7983077344569293} | train loss {'Reaction outcome loss': 0.8176900083236849, 'Total loss': 0.8176900083236849}
2022-11-18 01:26:21,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:21,030 INFO:     Epoch: 32
2022-11-18 01:26:21,821 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7902458520098166, 'Total loss': 0.7902458520098166} | train loss {'Reaction outcome loss': 0.823917367197724, 'Total loss': 0.823917367197724}
2022-11-18 01:26:21,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:21,821 INFO:     Epoch: 33
2022-11-18 01:26:22,579 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7837568528272889, 'Total loss': 0.7837568528272889} | train loss {'Reaction outcome loss': 0.8161076698226002, 'Total loss': 0.8161076698226002}
2022-11-18 01:26:22,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:22,579 INFO:     Epoch: 34
2022-11-18 01:26:23,376 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7811644954437559, 'Total loss': 0.7811644954437559} | train loss {'Reaction outcome loss': 0.8159498122298283, 'Total loss': 0.8159498122298283}
2022-11-18 01:26:23,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:23,376 INFO:     Epoch: 35
2022-11-18 01:26:24,142 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7886988642540845, 'Total loss': 0.7886988642540845} | train loss {'Reaction outcome loss': 0.8280232080563843, 'Total loss': 0.8280232080563843}
2022-11-18 01:26:24,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:24,142 INFO:     Epoch: 36
2022-11-18 01:26:24,931 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7796222235668789, 'Total loss': 0.7796222235668789} | train loss {'Reaction outcome loss': 0.8288228599890041, 'Total loss': 0.8288228599890041}
2022-11-18 01:26:24,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:24,931 INFO:     Epoch: 37
2022-11-18 01:26:25,716 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7917466881600294, 'Total loss': 0.7917466881600294} | train loss {'Reaction outcome loss': 0.8169584452864612, 'Total loss': 0.8169584452864612}
2022-11-18 01:26:25,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:25,717 INFO:     Epoch: 38
2022-11-18 01:26:26,499 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7853983484885909, 'Total loss': 0.7853983484885909} | train loss {'Reaction outcome loss': 0.8194605930131457, 'Total loss': 0.8194605930131457}
2022-11-18 01:26:26,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:26,499 INFO:     Epoch: 39
2022-11-18 01:26:27,299 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7979391982609575, 'Total loss': 0.7979391982609575} | train loss {'Reaction outcome loss': 0.8183304584219389, 'Total loss': 0.8183304584219389}
2022-11-18 01:26:27,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:27,299 INFO:     Epoch: 40
2022-11-18 01:26:28,071 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7693482678044926, 'Total loss': 0.7693482678044926} | train loss {'Reaction outcome loss': 0.8219581184840878, 'Total loss': 0.8219581184840878}
2022-11-18 01:26:28,071 INFO:     Found new best model at epoch 40
2022-11-18 01:26:28,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:28,072 INFO:     Epoch: 41
2022-11-18 01:26:28,858 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7914494750174609, 'Total loss': 0.7914494750174609} | train loss {'Reaction outcome loss': 0.8252939388819551, 'Total loss': 0.8252939388819551}
2022-11-18 01:26:28,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:28,859 INFO:     Epoch: 42
2022-11-18 01:26:29,638 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.777008293704553, 'Total loss': 0.777008293704553} | train loss {'Reaction outcome loss': 0.8179401219615087, 'Total loss': 0.8179401219615087}
2022-11-18 01:26:29,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:29,638 INFO:     Epoch: 43
2022-11-18 01:26:30,408 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8104203248565848, 'Total loss': 0.8104203248565848} | train loss {'Reaction outcome loss': 0.8211866760784797, 'Total loss': 0.8211866760784797}
2022-11-18 01:26:30,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:30,409 INFO:     Epoch: 44
2022-11-18 01:26:31,180 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7875059592452917, 'Total loss': 0.7875059592452917} | train loss {'Reaction outcome loss': 0.8145609379176669, 'Total loss': 0.8145609379176669}
2022-11-18 01:26:31,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:31,180 INFO:     Epoch: 45
2022-11-18 01:26:31,979 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7779038209806789, 'Total loss': 0.7779038209806789} | train loss {'Reaction outcome loss': 0.814764594742161, 'Total loss': 0.814764594742161}
2022-11-18 01:26:31,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:31,979 INFO:     Epoch: 46
2022-11-18 01:26:32,761 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7873157987540419, 'Total loss': 0.7873157987540419} | train loss {'Reaction outcome loss': 0.8228448865867337, 'Total loss': 0.8228448865867337}
2022-11-18 01:26:32,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:32,761 INFO:     Epoch: 47
2022-11-18 01:26:33,551 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7825433110648935, 'Total loss': 0.7825433110648935} | train loss {'Reaction outcome loss': 0.8165774560771007, 'Total loss': 0.8165774560771007}
2022-11-18 01:26:33,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:33,551 INFO:     Epoch: 48
2022-11-18 01:26:34,344 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7791389694268053, 'Total loss': 0.7791389694268053} | train loss {'Reaction outcome loss': 0.8145046574384095, 'Total loss': 0.8145046574384095}
2022-11-18 01:26:34,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:34,345 INFO:     Epoch: 49
2022-11-18 01:26:35,147 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7716001516038721, 'Total loss': 0.7716001516038721} | train loss {'Reaction outcome loss': 0.8160632072763163, 'Total loss': 0.8160632072763163}
2022-11-18 01:26:35,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:35,148 INFO:     Epoch: 50
2022-11-18 01:26:35,911 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.787170375612649, 'Total loss': 0.787170375612649} | train loss {'Reaction outcome loss': 0.8128875433222243, 'Total loss': 0.8128875433222243}
2022-11-18 01:26:35,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:35,911 INFO:     Epoch: 51
2022-11-18 01:26:36,695 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7877562201835893, 'Total loss': 0.7877562201835893} | train loss {'Reaction outcome loss': 0.818957138037392, 'Total loss': 0.818957138037392}
2022-11-18 01:26:36,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:36,695 INFO:     Epoch: 52
2022-11-18 01:26:37,459 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7731024927713654, 'Total loss': 0.7731024927713654} | train loss {'Reaction outcome loss': 0.8210742824714676, 'Total loss': 0.8210742824714676}
2022-11-18 01:26:37,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:37,459 INFO:     Epoch: 53
2022-11-18 01:26:38,249 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8114957538518038, 'Total loss': 0.8114957538518038} | train loss {'Reaction outcome loss': 0.8230970659960619, 'Total loss': 0.8230970659960619}
2022-11-18 01:26:38,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:38,250 INFO:     Epoch: 54
2022-11-18 01:26:39,022 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7966124354438349, 'Total loss': 0.7966124354438349} | train loss {'Reaction outcome loss': 0.8205457971646235, 'Total loss': 0.8205457971646235}
2022-11-18 01:26:39,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:39,023 INFO:     Epoch: 55
2022-11-18 01:26:39,825 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7998543882911856, 'Total loss': 0.7998543882911856} | train loss {'Reaction outcome loss': 0.8128389266097111, 'Total loss': 0.8128389266097111}
2022-11-18 01:26:39,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:39,825 INFO:     Epoch: 56
2022-11-18 01:26:40,585 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8087651092897762, 'Total loss': 0.8087651092897762} | train loss {'Reaction outcome loss': 0.812148037408045, 'Total loss': 0.812148037408045}
2022-11-18 01:26:40,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:40,586 INFO:     Epoch: 57
2022-11-18 01:26:41,371 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7840339446609671, 'Total loss': 0.7840339446609671} | train loss {'Reaction outcome loss': 0.8171729928086161, 'Total loss': 0.8171729928086161}
2022-11-18 01:26:41,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:41,371 INFO:     Epoch: 58
2022-11-18 01:26:42,159 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7747552916407585, 'Total loss': 0.7747552916407585} | train loss {'Reaction outcome loss': 0.8136295957965889, 'Total loss': 0.8136295957965889}
2022-11-18 01:26:42,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:42,159 INFO:     Epoch: 59
2022-11-18 01:26:42,936 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7991897084496238, 'Total loss': 0.7991897084496238} | train loss {'Reaction outcome loss': 0.8104960213788608, 'Total loss': 0.8104960213788608}
2022-11-18 01:26:42,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:42,936 INFO:     Epoch: 60
2022-11-18 01:26:43,706 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7983294495127418, 'Total loss': 0.7983294495127418} | train loss {'Reaction outcome loss': 0.8193392752394503, 'Total loss': 0.8193392752394503}
2022-11-18 01:26:43,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:43,707 INFO:     Epoch: 61
2022-11-18 01:26:44,498 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.785292237997055, 'Total loss': 0.785292237997055} | train loss {'Reaction outcome loss': 0.8161762992319791, 'Total loss': 0.8161762992319791}
2022-11-18 01:26:44,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:44,498 INFO:     Epoch: 62
2022-11-18 01:26:45,256 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7681860395453193, 'Total loss': 0.7681860395453193} | train loss {'Reaction outcome loss': 0.8134588743541163, 'Total loss': 0.8134588743541163}
2022-11-18 01:26:45,256 INFO:     Found new best model at epoch 62
2022-11-18 01:26:45,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:45,257 INFO:     Epoch: 63
2022-11-18 01:26:46,039 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7788280235095457, 'Total loss': 0.7788280235095457} | train loss {'Reaction outcome loss': 0.8119164757159075, 'Total loss': 0.8119164757159075}
2022-11-18 01:26:46,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:46,039 INFO:     Epoch: 64
2022-11-18 01:26:46,826 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7823432981967926, 'Total loss': 0.7823432981967926} | train loss {'Reaction outcome loss': 0.8168916169569077, 'Total loss': 0.8168916169569077}
2022-11-18 01:26:46,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:46,826 INFO:     Epoch: 65
2022-11-18 01:26:47,593 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7969630794091658, 'Total loss': 0.7969630794091658} | train loss {'Reaction outcome loss': 0.8179033074060432, 'Total loss': 0.8179033074060432}
2022-11-18 01:26:47,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:47,594 INFO:     Epoch: 66
2022-11-18 01:26:48,407 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7806262983517214, 'Total loss': 0.7806262983517214} | train loss {'Reaction outcome loss': 0.8310830324043629, 'Total loss': 0.8310830324043629}
2022-11-18 01:26:48,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:48,408 INFO:     Epoch: 67
2022-11-18 01:26:49,211 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7779072313146158, 'Total loss': 0.7779072313146158} | train loss {'Reaction outcome loss': 0.8206275747372553, 'Total loss': 0.8206275747372553}
2022-11-18 01:26:49,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:49,212 INFO:     Epoch: 68
2022-11-18 01:26:50,011 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7741652117534117, 'Total loss': 0.7741652117534117} | train loss {'Reaction outcome loss': 0.8124121469766022, 'Total loss': 0.8124121469766022}
2022-11-18 01:26:50,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:50,012 INFO:     Epoch: 69
2022-11-18 01:26:50,809 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7854163362221285, 'Total loss': 0.7854163362221285} | train loss {'Reaction outcome loss': 0.8228275033867793, 'Total loss': 0.8228275033867793}
2022-11-18 01:26:50,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:50,810 INFO:     Epoch: 70
2022-11-18 01:26:51,641 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7899816503578966, 'Total loss': 0.7899816503578966} | train loss {'Reaction outcome loss': 0.8138788490884217, 'Total loss': 0.8138788490884217}
2022-11-18 01:26:51,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:51,642 INFO:     Epoch: 71
2022-11-18 01:26:52,508 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8024523664604534, 'Total loss': 0.8024523664604534} | train loss {'Reaction outcome loss': 0.8123200435025489, 'Total loss': 0.8123200435025489}
2022-11-18 01:26:52,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:52,508 INFO:     Epoch: 72
2022-11-18 01:26:53,331 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7853278023275462, 'Total loss': 0.7853278023275462} | train loss {'Reaction outcome loss': 0.8189128911205632, 'Total loss': 0.8189128911205632}
2022-11-18 01:26:53,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:53,331 INFO:     Epoch: 73
2022-11-18 01:26:54,140 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7789351344108582, 'Total loss': 0.7789351344108582} | train loss {'Reaction outcome loss': 0.8188950152773606, 'Total loss': 0.8188950152773606}
2022-11-18 01:26:54,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:54,140 INFO:     Epoch: 74
2022-11-18 01:26:54,941 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7677151614969427, 'Total loss': 0.7677151614969427} | train loss {'Reaction outcome loss': 0.8190551970893072, 'Total loss': 0.8190551970893072}
2022-11-18 01:26:54,942 INFO:     Found new best model at epoch 74
2022-11-18 01:26:54,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:54,942 INFO:     Epoch: 75
2022-11-18 01:26:55,747 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.778130748055198, 'Total loss': 0.778130748055198} | train loss {'Reaction outcome loss': 0.8163093557724586, 'Total loss': 0.8163093557724586}
2022-11-18 01:26:55,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:55,747 INFO:     Epoch: 76
2022-11-18 01:26:56,550 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7724831680005247, 'Total loss': 0.7724831680005247} | train loss {'Reaction outcome loss': 0.8113989306515769, 'Total loss': 0.8113989306515769}
2022-11-18 01:26:56,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:56,550 INFO:     Epoch: 77
2022-11-18 01:26:57,378 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7786552966995672, 'Total loss': 0.7786552966995672} | train loss {'Reaction outcome loss': 0.8087447080534962, 'Total loss': 0.8087447080534962}
2022-11-18 01:26:57,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:57,380 INFO:     Epoch: 78
2022-11-18 01:26:58,196 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7858231805942275, 'Total loss': 0.7858231805942275} | train loss {'Reaction outcome loss': 0.8189169414612928, 'Total loss': 0.8189169414612928}
2022-11-18 01:26:58,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:58,197 INFO:     Epoch: 79
2022-11-18 01:26:59,012 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7764705832708966, 'Total loss': 0.7764705832708966} | train loss {'Reaction outcome loss': 0.8145755647647719, 'Total loss': 0.8145755647647719}
2022-11-18 01:26:59,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:59,012 INFO:     Epoch: 80
2022-11-18 01:26:59,831 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7829566631804813, 'Total loss': 0.7829566631804813} | train loss {'Reaction outcome loss': 0.8159055813604038, 'Total loss': 0.8159055813604038}
2022-11-18 01:26:59,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:26:59,831 INFO:     Epoch: 81
2022-11-18 01:27:00,616 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.770483057607304, 'Total loss': 0.770483057607304} | train loss {'Reaction outcome loss': 0.820201772909898, 'Total loss': 0.820201772909898}
2022-11-18 01:27:00,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:00,616 INFO:     Epoch: 82
2022-11-18 01:27:01,437 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7862532917748798, 'Total loss': 0.7862532917748798} | train loss {'Reaction outcome loss': 0.822941595967482, 'Total loss': 0.822941595967482}
2022-11-18 01:27:01,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:01,437 INFO:     Epoch: 83
2022-11-18 01:27:02,282 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7786079441959207, 'Total loss': 0.7786079441959207} | train loss {'Reaction outcome loss': 0.8097431516116448, 'Total loss': 0.8097431516116448}
2022-11-18 01:27:02,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:02,282 INFO:     Epoch: 84
2022-11-18 01:27:03,091 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8435117947784337, 'Total loss': 0.8435117947784337} | train loss {'Reaction outcome loss': 0.8147917083098821, 'Total loss': 0.8147917083098821}
2022-11-18 01:27:03,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:03,092 INFO:     Epoch: 85
2022-11-18 01:27:03,911 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7732591331005096, 'Total loss': 0.7732591331005096} | train loss {'Reaction outcome loss': 0.8160158214781449, 'Total loss': 0.8160158214781449}
2022-11-18 01:27:03,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:03,912 INFO:     Epoch: 86
2022-11-18 01:27:04,707 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7761194733056155, 'Total loss': 0.7761194733056155} | train loss {'Reaction outcome loss': 0.8127283318805308, 'Total loss': 0.8127283318805308}
2022-11-18 01:27:04,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:04,707 INFO:     Epoch: 87
2022-11-18 01:27:05,509 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7854936488650062, 'Total loss': 0.7854936488650062} | train loss {'Reaction outcome loss': 0.8128372779500629, 'Total loss': 0.8128372779500629}
2022-11-18 01:27:05,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:05,510 INFO:     Epoch: 88
2022-11-18 01:27:06,314 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8222826021638784, 'Total loss': 0.8222826021638784} | train loss {'Reaction outcome loss': 0.8079541923425458, 'Total loss': 0.8079541923425458}
2022-11-18 01:27:06,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:06,314 INFO:     Epoch: 89
2022-11-18 01:27:07,127 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7767341570420698, 'Total loss': 0.7767341570420698} | train loss {'Reaction outcome loss': 0.8184234787095414, 'Total loss': 0.8184234787095414}
2022-11-18 01:27:07,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:07,127 INFO:     Epoch: 90
2022-11-18 01:27:07,940 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.776581039482897, 'Total loss': 0.776581039482897} | train loss {'Reaction outcome loss': 0.8151535129981485, 'Total loss': 0.8151535129981485}
2022-11-18 01:27:07,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:07,941 INFO:     Epoch: 91
2022-11-18 01:27:08,733 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.780407044020566, 'Total loss': 0.780407044020566} | train loss {'Reaction outcome loss': 0.8094723770613612, 'Total loss': 0.8094723770613612}
2022-11-18 01:27:08,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:08,734 INFO:     Epoch: 92
2022-11-18 01:27:09,539 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7911490947008133, 'Total loss': 0.7911490947008133} | train loss {'Reaction outcome loss': 0.8092119813206707, 'Total loss': 0.8092119813206707}
2022-11-18 01:27:09,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:09,539 INFO:     Epoch: 93
2022-11-18 01:27:10,320 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8001106909730218, 'Total loss': 0.8001106909730218} | train loss {'Reaction outcome loss': 0.8191680500381872, 'Total loss': 0.8191680500381872}
2022-11-18 01:27:10,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:10,320 INFO:     Epoch: 94
2022-11-18 01:27:11,151 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7765086205168203, 'Total loss': 0.7765086205168203} | train loss {'Reaction outcome loss': 0.8161065649648427, 'Total loss': 0.8161065649648427}
2022-11-18 01:27:11,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:11,151 INFO:     Epoch: 95
2022-11-18 01:27:11,946 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8410413576798006, 'Total loss': 0.8410413576798006} | train loss {'Reaction outcome loss': 0.8124217239589344, 'Total loss': 0.8124217239589344}
2022-11-18 01:27:11,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:11,946 INFO:     Epoch: 96
2022-11-18 01:27:12,764 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7868873151865873, 'Total loss': 0.7868873151865873} | train loss {'Reaction outcome loss': 0.8184721509696018, 'Total loss': 0.8184721509696018}
2022-11-18 01:27:12,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:12,764 INFO:     Epoch: 97
2022-11-18 01:27:13,587 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7790206372737885, 'Total loss': 0.7790206372737885} | train loss {'Reaction outcome loss': 0.8074160943388456, 'Total loss': 0.8074160943388456}
2022-11-18 01:27:13,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:13,587 INFO:     Epoch: 98
2022-11-18 01:27:14,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7892174084078182, 'Total loss': 0.7892174084078182} | train loss {'Reaction outcome loss': 0.8121387398677317, 'Total loss': 0.8121387398677317}
2022-11-18 01:27:14,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:14,388 INFO:     Epoch: 99
2022-11-18 01:27:15,224 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7875374325297095, 'Total loss': 0.7875374325297095} | train loss {'Reaction outcome loss': 0.8103348637670882, 'Total loss': 0.8103348637670882}
2022-11-18 01:27:15,224 INFO:     Best model found after epoch 75 of 100.
2022-11-18 01:27:15,225 INFO:   Done with stage: TRAINING
2022-11-18 01:27:15,225 INFO:   Starting stage: EVALUATION
2022-11-18 01:27:15,348 INFO:   Done with stage: EVALUATION
2022-11-18 01:27:15,348 INFO:   Leaving out SEQ value Fold_5
2022-11-18 01:27:15,361 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:27:15,361 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:27:16,035 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:27:16,036 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:27:16,107 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:27:16,107 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:27:16,107 INFO:     No hyperparam tuning for this model
2022-11-18 01:27:16,107 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:27:16,107 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:27:16,108 INFO:     None feature selector for col prot
2022-11-18 01:27:16,108 INFO:     None feature selector for col prot
2022-11-18 01:27:16,108 INFO:     None feature selector for col prot
2022-11-18 01:27:16,109 INFO:     None feature selector for col chem
2022-11-18 01:27:16,109 INFO:     None feature selector for col chem
2022-11-18 01:27:16,109 INFO:     None feature selector for col chem
2022-11-18 01:27:16,109 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:27:16,109 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:27:16,111 INFO:     Number of params in model 168571
2022-11-18 01:27:16,114 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:27:16,114 INFO:   Starting stage: TRAINING
2022-11-18 01:27:16,172 INFO:     Val loss before train {'Reaction outcome loss': 1.0431810983202674, 'Total loss': 1.0431810983202674}
2022-11-18 01:27:16,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:16,172 INFO:     Epoch: 0
2022-11-18 01:27:16,962 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9004863371903246, 'Total loss': 0.9004863371903246} | train loss {'Reaction outcome loss': 0.8732899818946476, 'Total loss': 0.8732899818946476}
2022-11-18 01:27:16,962 INFO:     Found new best model at epoch 0
2022-11-18 01:27:16,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:16,963 INFO:     Epoch: 1
2022-11-18 01:27:17,759 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9006536250764673, 'Total loss': 0.9006536250764673} | train loss {'Reaction outcome loss': 0.8517547318568597, 'Total loss': 0.8517547318568597}
2022-11-18 01:27:17,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:17,759 INFO:     Epoch: 2
2022-11-18 01:27:18,568 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9002950116991997, 'Total loss': 0.9002950116991997} | train loss {'Reaction outcome loss': 0.8399702744324681, 'Total loss': 0.8399702744324681}
2022-11-18 01:27:18,568 INFO:     Found new best model at epoch 2
2022-11-18 01:27:18,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:18,569 INFO:     Epoch: 3
2022-11-18 01:27:19,350 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.873779600316828, 'Total loss': 0.873779600316828} | train loss {'Reaction outcome loss': 0.8285098303908761, 'Total loss': 0.8285098303908761}
2022-11-18 01:27:19,350 INFO:     Found new best model at epoch 3
2022-11-18 01:27:19,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:19,351 INFO:     Epoch: 4
2022-11-18 01:27:20,140 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9160616878758777, 'Total loss': 0.9160616878758777} | train loss {'Reaction outcome loss': 0.8346460677592861, 'Total loss': 0.8346460677592861}
2022-11-18 01:27:20,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:20,140 INFO:     Epoch: 5
2022-11-18 01:27:20,948 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.878259992057627, 'Total loss': 0.878259992057627} | train loss {'Reaction outcome loss': 0.8355466432658284, 'Total loss': 0.8355466432658284}
2022-11-18 01:27:20,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:20,948 INFO:     Epoch: 6
2022-11-18 01:27:21,722 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8795418725772337, 'Total loss': 0.8795418725772337} | train loss {'Reaction outcome loss': 0.8226859422913386, 'Total loss': 0.8226859422913386}
2022-11-18 01:27:21,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:21,722 INFO:     Epoch: 7
2022-11-18 01:27:22,489 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.865690799599344, 'Total loss': 0.865690799599344} | train loss {'Reaction outcome loss': 0.8191918170283198, 'Total loss': 0.8191918170283198}
2022-11-18 01:27:22,489 INFO:     Found new best model at epoch 7
2022-11-18 01:27:22,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:22,490 INFO:     Epoch: 8
2022-11-18 01:27:23,258 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8706134015863592, 'Total loss': 0.8706134015863592} | train loss {'Reaction outcome loss': 0.8232934737977712, 'Total loss': 0.8232934737977712}
2022-11-18 01:27:23,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:23,258 INFO:     Epoch: 9
2022-11-18 01:27:24,026 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8920761983502995, 'Total loss': 0.8920761983502995} | train loss {'Reaction outcome loss': 0.8294340543418761, 'Total loss': 0.8294340543418761}
2022-11-18 01:27:24,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:24,026 INFO:     Epoch: 10
2022-11-18 01:27:24,807 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8682448376308788, 'Total loss': 0.8682448376308788} | train loss {'Reaction outcome loss': 0.818261467659401, 'Total loss': 0.818261467659401}
2022-11-18 01:27:24,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:24,807 INFO:     Epoch: 11
2022-11-18 01:27:25,602 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.854355511340228, 'Total loss': 0.854355511340228} | train loss {'Reaction outcome loss': 0.8214499356775631, 'Total loss': 0.8214499356775631}
2022-11-18 01:27:25,603 INFO:     Found new best model at epoch 11
2022-11-18 01:27:25,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:25,604 INFO:     Epoch: 12
2022-11-18 01:27:26,359 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8740972355008125, 'Total loss': 0.8740972355008125} | train loss {'Reaction outcome loss': 0.815577768000514, 'Total loss': 0.815577768000514}
2022-11-18 01:27:26,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:26,359 INFO:     Epoch: 13
2022-11-18 01:27:27,117 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8873380585150286, 'Total loss': 0.8873380585150286} | train loss {'Reaction outcome loss': 0.8200054403982664, 'Total loss': 0.8200054403982664}
2022-11-18 01:27:27,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:27,117 INFO:     Epoch: 14
2022-11-18 01:27:27,882 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.9090634354136207, 'Total loss': 0.9090634354136207} | train loss {'Reaction outcome loss': 0.8128199459087511, 'Total loss': 0.8128199459087511}
2022-11-18 01:27:27,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:27,882 INFO:     Epoch: 15
2022-11-18 01:27:28,658 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8929794986139644, 'Total loss': 0.8929794986139644} | train loss {'Reaction outcome loss': 0.8177478507402455, 'Total loss': 0.8177478507402455}
2022-11-18 01:27:28,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:28,658 INFO:     Epoch: 16
2022-11-18 01:27:29,417 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8562619144266302, 'Total loss': 0.8562619144266302} | train loss {'Reaction outcome loss': 0.8178705810776606, 'Total loss': 0.8178705810776606}
2022-11-18 01:27:29,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:29,419 INFO:     Epoch: 17
2022-11-18 01:27:30,207 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8620918149297888, 'Total loss': 0.8620918149297888} | train loss {'Reaction outcome loss': 0.8159077532800586, 'Total loss': 0.8159077532800586}
2022-11-18 01:27:30,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:30,207 INFO:     Epoch: 18
2022-11-18 01:27:30,985 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8838778910311785, 'Total loss': 0.8838778910311785} | train loss {'Reaction outcome loss': 0.8170832078225216, 'Total loss': 0.8170832078225216}
2022-11-18 01:27:30,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:30,986 INFO:     Epoch: 19
2022-11-18 01:27:31,777 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8879017640243877, 'Total loss': 0.8879017640243877} | train loss {'Reaction outcome loss': 0.82020790748268, 'Total loss': 0.82020790748268}
2022-11-18 01:27:31,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:31,777 INFO:     Epoch: 20
2022-11-18 01:27:32,556 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8702979548410936, 'Total loss': 0.8702979548410936} | train loss {'Reaction outcome loss': 0.8141787318806899, 'Total loss': 0.8141787318806899}
2022-11-18 01:27:32,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:32,557 INFO:     Epoch: 21
2022-11-18 01:27:33,343 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8859607225114648, 'Total loss': 0.8859607225114648} | train loss {'Reaction outcome loss': 0.8162625480578979, 'Total loss': 0.8162625480578979}
2022-11-18 01:27:33,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:33,343 INFO:     Epoch: 22
2022-11-18 01:27:34,133 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8655126894062216, 'Total loss': 0.8655126894062216} | train loss {'Reaction outcome loss': 0.8123654613218568, 'Total loss': 0.8123654613218568}
2022-11-18 01:27:34,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:34,133 INFO:     Epoch: 23
2022-11-18 01:27:34,951 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8660008026794954, 'Total loss': 0.8660008026794954} | train loss {'Reaction outcome loss': 0.8136380066273183, 'Total loss': 0.8136380066273183}
2022-11-18 01:27:34,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:34,951 INFO:     Epoch: 24
2022-11-18 01:27:35,730 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8683950887484984, 'Total loss': 0.8683950887484984} | train loss {'Reaction outcome loss': 0.8160227727793489, 'Total loss': 0.8160227727793489}
2022-11-18 01:27:35,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:35,732 INFO:     Epoch: 25
2022-11-18 01:27:36,501 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8784718378023668, 'Total loss': 0.8784718378023668} | train loss {'Reaction outcome loss': 0.8129285838198566, 'Total loss': 0.8129285838198566}
2022-11-18 01:27:36,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:36,501 INFO:     Epoch: 26
2022-11-18 01:27:37,253 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8628632974895564, 'Total loss': 0.8628632974895564} | train loss {'Reaction outcome loss': 0.8158255718980241, 'Total loss': 0.8158255718980241}
2022-11-18 01:27:37,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:37,253 INFO:     Epoch: 27
2022-11-18 01:27:38,024 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8595580824396827, 'Total loss': 0.8595580824396827} | train loss {'Reaction outcome loss': 0.8118529809631316, 'Total loss': 0.8118529809631316}
2022-11-18 01:27:38,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:38,024 INFO:     Epoch: 28
2022-11-18 01:27:38,799 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8600122928619385, 'Total loss': 0.8600122928619385} | train loss {'Reaction outcome loss': 0.8169698272398126, 'Total loss': 0.8169698272398126}
2022-11-18 01:27:38,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:38,799 INFO:     Epoch: 29
2022-11-18 01:27:39,566 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8645615696229718, 'Total loss': 0.8645615696229718} | train loss {'Reaction outcome loss': 0.8141609269839066, 'Total loss': 0.8141609269839066}
2022-11-18 01:27:39,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:39,567 INFO:     Epoch: 30
2022-11-18 01:27:40,353 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8723044876347888, 'Total loss': 0.8723044876347888} | train loss {'Reaction outcome loss': 0.8137107861910754, 'Total loss': 0.8137107861910754}
2022-11-18 01:27:40,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:40,353 INFO:     Epoch: 31
2022-11-18 01:27:41,150 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8585999628359621, 'Total loss': 0.8585999628359621} | train loss {'Reaction outcome loss': 0.8125065597007993, 'Total loss': 0.8125065597007993}
2022-11-18 01:27:41,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:41,150 INFO:     Epoch: 32
2022-11-18 01:27:41,921 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8768665953115984, 'Total loss': 0.8768665953115984} | train loss {'Reaction outcome loss': 0.82032408152032, 'Total loss': 0.82032408152032}
2022-11-18 01:27:41,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:41,921 INFO:     Epoch: 33
2022-11-18 01:27:42,720 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8589687902819026, 'Total loss': 0.8589687902819026} | train loss {'Reaction outcome loss': 0.8206569042041717, 'Total loss': 0.8206569042041717}
2022-11-18 01:27:42,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:42,721 INFO:     Epoch: 34
2022-11-18 01:27:43,486 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8697400336915796, 'Total loss': 0.8697400336915796} | train loss {'Reaction outcome loss': 0.8112986808122411, 'Total loss': 0.8112986808122411}
2022-11-18 01:27:43,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:43,487 INFO:     Epoch: 35
2022-11-18 01:27:44,290 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.857656480236487, 'Total loss': 0.857656480236487} | train loss {'Reaction outcome loss': 0.8091865089997227, 'Total loss': 0.8091865089997227}
2022-11-18 01:27:44,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:44,291 INFO:     Epoch: 36
2022-11-18 01:27:45,060 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8601192737167532, 'Total loss': 0.8601192737167532} | train loss {'Reaction outcome loss': 0.8111541390057034, 'Total loss': 0.8111541390057034}
2022-11-18 01:27:45,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:45,061 INFO:     Epoch: 37
2022-11-18 01:27:45,858 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8541858060793444, 'Total loss': 0.8541858060793444} | train loss {'Reaction outcome loss': 0.8118871640157603, 'Total loss': 0.8118871640157603}
2022-11-18 01:27:45,858 INFO:     Found new best model at epoch 37
2022-11-18 01:27:45,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:45,859 INFO:     Epoch: 38
2022-11-18 01:27:46,706 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8504939648238096, 'Total loss': 0.8504939648238096} | train loss {'Reaction outcome loss': 0.8163384935151228, 'Total loss': 0.8163384935151228}
2022-11-18 01:27:46,706 INFO:     Found new best model at epoch 38
2022-11-18 01:27:46,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:46,707 INFO:     Epoch: 39
2022-11-18 01:27:47,543 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8580907576463439, 'Total loss': 0.8580907576463439} | train loss {'Reaction outcome loss': 0.8159201322538168, 'Total loss': 0.8159201322538168}
2022-11-18 01:27:47,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:47,543 INFO:     Epoch: 40
2022-11-18 01:27:48,373 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8612981059334495, 'Total loss': 0.8612981059334495} | train loss {'Reaction outcome loss': 0.8161211138070836, 'Total loss': 0.8161211138070836}
2022-11-18 01:27:48,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:48,374 INFO:     Epoch: 41
2022-11-18 01:27:49,189 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8678217929872599, 'Total loss': 0.8678217929872599} | train loss {'Reaction outcome loss': 0.8126956884436279, 'Total loss': 0.8126956884436279}
2022-11-18 01:27:49,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:49,189 INFO:     Epoch: 42
2022-11-18 01:27:50,008 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8461065387183969, 'Total loss': 0.8461065387183969} | train loss {'Reaction outcome loss': 0.8157190568292672, 'Total loss': 0.8157190568292672}
2022-11-18 01:27:50,008 INFO:     Found new best model at epoch 42
2022-11-18 01:27:50,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:50,009 INFO:     Epoch: 43
2022-11-18 01:27:50,778 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.871749838644808, 'Total loss': 0.871749838644808} | train loss {'Reaction outcome loss': 0.8167245138270652, 'Total loss': 0.8167245138270652}
2022-11-18 01:27:50,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:50,778 INFO:     Epoch: 44
2022-11-18 01:27:51,540 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8687939278104089, 'Total loss': 0.8687939278104089} | train loss {'Reaction outcome loss': 0.8178450664286672, 'Total loss': 0.8178450664286672}
2022-11-18 01:27:51,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:51,540 INFO:     Epoch: 45
2022-11-18 01:27:52,307 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8761033693497832, 'Total loss': 0.8761033693497832} | train loss {'Reaction outcome loss': 0.8134488966542217, 'Total loss': 0.8134488966542217}
2022-11-18 01:27:52,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:52,308 INFO:     Epoch: 46
2022-11-18 01:27:53,071 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8620492639866743, 'Total loss': 0.8620492639866743} | train loss {'Reaction outcome loss': 0.8191291200004609, 'Total loss': 0.8191291200004609}
2022-11-18 01:27:53,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:53,071 INFO:     Epoch: 47
2022-11-18 01:27:53,869 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8542292443188754, 'Total loss': 0.8542292443188754} | train loss {'Reaction outcome loss': 0.8118657080026773, 'Total loss': 0.8118657080026773}
2022-11-18 01:27:53,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:53,869 INFO:     Epoch: 48
2022-11-18 01:27:54,649 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8698434734886343, 'Total loss': 0.8698434734886343} | train loss {'Reaction outcome loss': 0.8095264055950921, 'Total loss': 0.8095264055950921}
2022-11-18 01:27:54,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:54,649 INFO:     Epoch: 49
2022-11-18 01:27:55,436 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8785507110032168, 'Total loss': 0.8785507110032168} | train loss {'Reaction outcome loss': 0.8129541881171315, 'Total loss': 0.8129541881171315}
2022-11-18 01:27:55,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:55,437 INFO:     Epoch: 50
2022-11-18 01:27:56,192 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.9123419035564769, 'Total loss': 0.9123419035564769} | train loss {'Reaction outcome loss': 0.8106954473594905, 'Total loss': 0.8106954473594905}
2022-11-18 01:27:56,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:56,192 INFO:     Epoch: 51
2022-11-18 01:27:56,955 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8522911600091241, 'Total loss': 0.8522911600091241} | train loss {'Reaction outcome loss': 0.8194965909608463, 'Total loss': 0.8194965909608463}
2022-11-18 01:27:56,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:56,955 INFO:     Epoch: 52
2022-11-18 01:27:57,771 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8513019186529246, 'Total loss': 0.8513019186529246} | train loss {'Reaction outcome loss': 0.8125558785098767, 'Total loss': 0.8125558785098767}
2022-11-18 01:27:57,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:57,771 INFO:     Epoch: 53
2022-11-18 01:27:58,531 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8610339069908316, 'Total loss': 0.8610339069908316} | train loss {'Reaction outcome loss': 0.8114078987223899, 'Total loss': 0.8114078987223899}
2022-11-18 01:27:58,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:58,531 INFO:     Epoch: 54
2022-11-18 01:27:59,313 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8863870074803178, 'Total loss': 0.8863870074803178} | train loss {'Reaction outcome loss': 0.8066309391848954, 'Total loss': 0.8066309391848954}
2022-11-18 01:27:59,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:27:59,313 INFO:     Epoch: 55
2022-11-18 01:28:00,115 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8482834182002328, 'Total loss': 0.8482834182002328} | train loss {'Reaction outcome loss': 0.8138170819427923, 'Total loss': 0.8138170819427923}
2022-11-18 01:28:00,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:00,115 INFO:     Epoch: 56
2022-11-18 01:28:00,887 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.878855671394955, 'Total loss': 0.878855671394955} | train loss {'Reaction outcome loss': 0.8092744053616697, 'Total loss': 0.8092744053616697}
2022-11-18 01:28:00,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:00,889 INFO:     Epoch: 57
2022-11-18 01:28:01,694 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8633056797764518, 'Total loss': 0.8633056797764518} | train loss {'Reaction outcome loss': 0.8160310160775899, 'Total loss': 0.8160310160775899}
2022-11-18 01:28:01,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:01,694 INFO:     Epoch: 58
2022-11-18 01:28:02,471 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8762240193106912, 'Total loss': 0.8762240193106912} | train loss {'Reaction outcome loss': 0.8143944559309647, 'Total loss': 0.8143944559309647}
2022-11-18 01:28:02,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:02,471 INFO:     Epoch: 59
2022-11-18 01:28:03,237 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8664881580255248, 'Total loss': 0.8664881580255248} | train loss {'Reaction outcome loss': 0.8127224494209174, 'Total loss': 0.8127224494209174}
2022-11-18 01:28:03,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:03,237 INFO:     Epoch: 60
2022-11-18 01:28:04,015 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.867982763458382, 'Total loss': 0.867982763458382} | train loss {'Reaction outcome loss': 0.8144087538062802, 'Total loss': 0.8144087538062802}
2022-11-18 01:28:04,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:04,015 INFO:     Epoch: 61
2022-11-18 01:28:04,800 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8482328978451815, 'Total loss': 0.8482328978451815} | train loss {'Reaction outcome loss': 0.8143508615281417, 'Total loss': 0.8143508615281417}
2022-11-18 01:28:04,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:04,800 INFO:     Epoch: 62
2022-11-18 01:28:05,545 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8577517122030258, 'Total loss': 0.8577517122030258} | train loss {'Reaction outcome loss': 0.8196603870584898, 'Total loss': 0.8196603870584898}
2022-11-18 01:28:05,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:05,546 INFO:     Epoch: 63
2022-11-18 01:28:06,334 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8544697551564737, 'Total loss': 0.8544697551564737} | train loss {'Reaction outcome loss': 0.8112040285156806, 'Total loss': 0.8112040285156806}
2022-11-18 01:28:06,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:06,335 INFO:     Epoch: 64
2022-11-18 01:28:07,114 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8694045787507837, 'Total loss': 0.8694045787507837} | train loss {'Reaction outcome loss': 0.8141450927807734, 'Total loss': 0.8141450927807734}
2022-11-18 01:28:07,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:07,115 INFO:     Epoch: 65
2022-11-18 01:28:07,897 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8611182611096989, 'Total loss': 0.8611182611096989} | train loss {'Reaction outcome loss': 0.8161083476142845, 'Total loss': 0.8161083476142845}
2022-11-18 01:28:07,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:07,897 INFO:     Epoch: 66
2022-11-18 01:28:08,656 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8652785271406174, 'Total loss': 0.8652785271406174} | train loss {'Reaction outcome loss': 0.8106628393354686, 'Total loss': 0.8106628393354686}
2022-11-18 01:28:08,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:08,656 INFO:     Epoch: 67
2022-11-18 01:28:09,408 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8711445947939699, 'Total loss': 0.8711445947939699} | train loss {'Reaction outcome loss': 0.8070189729031281, 'Total loss': 0.8070189729031281}
2022-11-18 01:28:09,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:09,408 INFO:     Epoch: 68
2022-11-18 01:28:10,177 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8721185692332007, 'Total loss': 0.8721185692332007} | train loss {'Reaction outcome loss': 0.8159118227147864, 'Total loss': 0.8159118227147864}
2022-11-18 01:28:10,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:10,178 INFO:     Epoch: 69
2022-11-18 01:28:10,943 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8631958053870634, 'Total loss': 0.8631958053870634} | train loss {'Reaction outcome loss': 0.8105310220950046, 'Total loss': 0.8105310220950046}
2022-11-18 01:28:10,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:10,943 INFO:     Epoch: 70
2022-11-18 01:28:11,725 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8753113543445413, 'Total loss': 0.8753113543445413} | train loss {'Reaction outcome loss': 0.8093520349743757, 'Total loss': 0.8093520349743757}
2022-11-18 01:28:11,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:11,725 INFO:     Epoch: 71
2022-11-18 01:28:12,496 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8857391117648645, 'Total loss': 0.8857391117648645} | train loss {'Reaction outcome loss': 0.8096407892009024, 'Total loss': 0.8096407892009024}
2022-11-18 01:28:12,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:12,496 INFO:     Epoch: 72
2022-11-18 01:28:13,273 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8768727616830305, 'Total loss': 0.8768727616830305} | train loss {'Reaction outcome loss': 0.8102307646622059, 'Total loss': 0.8102307646622059}
2022-11-18 01:28:13,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:13,274 INFO:     Epoch: 73
2022-11-18 01:28:14,023 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8461765470829877, 'Total loss': 0.8461765470829877} | train loss {'Reaction outcome loss': 0.8110051990037987, 'Total loss': 0.8110051990037987}
2022-11-18 01:28:14,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:14,023 INFO:     Epoch: 74
2022-11-18 01:28:14,780 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8713266646320169, 'Total loss': 0.8713266646320169} | train loss {'Reaction outcome loss': 0.8102019741708933, 'Total loss': 0.8102019741708933}
2022-11-18 01:28:14,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:14,781 INFO:     Epoch: 75
2022-11-18 01:28:15,553 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8471232307228175, 'Total loss': 0.8471232307228175} | train loss {'Reaction outcome loss': 0.8115341831677356, 'Total loss': 0.8115341831677356}
2022-11-18 01:28:15,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:15,553 INFO:     Epoch: 76
2022-11-18 01:28:16,337 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8500076552683656, 'Total loss': 0.8500076552683656} | train loss {'Reaction outcome loss': 0.8233196276884812, 'Total loss': 0.8233196276884812}
2022-11-18 01:28:16,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:16,337 INFO:     Epoch: 77
2022-11-18 01:28:17,123 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8670055690136823, 'Total loss': 0.8670055690136823} | train loss {'Reaction outcome loss': 0.8174368812125704, 'Total loss': 0.8174368812125704}
2022-11-18 01:28:17,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:17,123 INFO:     Epoch: 78
2022-11-18 01:28:17,894 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.86317532712763, 'Total loss': 0.86317532712763} | train loss {'Reaction outcome loss': 0.8135996248557983, 'Total loss': 0.8135996248557983}
2022-11-18 01:28:17,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:17,894 INFO:     Epoch: 79
2022-11-18 01:28:18,715 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8830187334255739, 'Total loss': 0.8830187334255739} | train loss {'Reaction outcome loss': 0.8196883078528802, 'Total loss': 0.8196883078528802}
2022-11-18 01:28:18,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:18,715 INFO:     Epoch: 80
2022-11-18 01:28:19,463 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8609943078322844, 'Total loss': 0.8609943078322844} | train loss {'Reaction outcome loss': 0.812612389384011, 'Total loss': 0.812612389384011}
2022-11-18 01:28:19,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:19,464 INFO:     Epoch: 81
2022-11-18 01:28:20,262 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.871934481642463, 'Total loss': 0.871934481642463} | train loss {'Reaction outcome loss': 0.8158074722357607, 'Total loss': 0.8158074722357607}
2022-11-18 01:28:20,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:20,262 INFO:     Epoch: 82
2022-11-18 01:28:21,046 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8561600406061519, 'Total loss': 0.8561600406061519} | train loss {'Reaction outcome loss': 0.8198582994551794, 'Total loss': 0.8198582994551794}
2022-11-18 01:28:21,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:21,046 INFO:     Epoch: 83
2022-11-18 01:28:21,859 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8719045269218358, 'Total loss': 0.8719045269218358} | train loss {'Reaction outcome loss': 0.8210264743580992, 'Total loss': 0.8210264743580992}
2022-11-18 01:28:21,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:21,859 INFO:     Epoch: 84
2022-11-18 01:28:22,652 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8542925309051167, 'Total loss': 0.8542925309051167} | train loss {'Reaction outcome loss': 0.8103038242712677, 'Total loss': 0.8103038242712677}
2022-11-18 01:28:22,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:22,652 INFO:     Epoch: 85
2022-11-18 01:28:23,429 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8774286190217192, 'Total loss': 0.8774286190217192} | train loss {'Reaction outcome loss': 0.8078004670770544, 'Total loss': 0.8078004670770544}
2022-11-18 01:28:23,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:23,429 INFO:     Epoch: 86
2022-11-18 01:28:24,219 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8759773258458484, 'Total loss': 0.8759773258458484} | train loss {'Reaction outcome loss': 0.8115642610107839, 'Total loss': 0.8115642610107839}
2022-11-18 01:28:24,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:24,220 INFO:     Epoch: 87
2022-11-18 01:28:24,961 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8734751479192213, 'Total loss': 0.8734751479192213} | train loss {'Reaction outcome loss': 0.8096225574190318, 'Total loss': 0.8096225574190318}
2022-11-18 01:28:24,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:24,962 INFO:     Epoch: 88
2022-11-18 01:28:25,739 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8373504077846353, 'Total loss': 0.8373504077846353} | train loss {'Reaction outcome loss': 0.8153506864902944, 'Total loss': 0.8153506864902944}
2022-11-18 01:28:25,739 INFO:     Found new best model at epoch 88
2022-11-18 01:28:25,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:25,740 INFO:     Epoch: 89
2022-11-18 01:28:26,500 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8508636897260492, 'Total loss': 0.8508636897260492} | train loss {'Reaction outcome loss': 0.8131724633125641, 'Total loss': 0.8131724633125641}
2022-11-18 01:28:26,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:26,500 INFO:     Epoch: 90
2022-11-18 01:28:27,279 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8542614010247317, 'Total loss': 0.8542614010247317} | train loss {'Reaction outcome loss': 0.8130723638573156, 'Total loss': 0.8130723638573156}
2022-11-18 01:28:27,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:27,279 INFO:     Epoch: 91
2022-11-18 01:28:28,056 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8487607559019869, 'Total loss': 0.8487607559019869} | train loss {'Reaction outcome loss': 0.8140995308213871, 'Total loss': 0.8140995308213871}
2022-11-18 01:28:28,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:28,057 INFO:     Epoch: 92
2022-11-18 01:28:28,824 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8611745861443606, 'Total loss': 0.8611745861443606} | train loss {'Reaction outcome loss': 0.8114791162583509, 'Total loss': 0.8114791162583509}
2022-11-18 01:28:28,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:28,824 INFO:     Epoch: 93
2022-11-18 01:28:29,591 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.865352986888452, 'Total loss': 0.865352986888452} | train loss {'Reaction outcome loss': 0.8107967886485552, 'Total loss': 0.8107967886485552}
2022-11-18 01:28:29,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:29,591 INFO:     Epoch: 94
2022-11-18 01:28:30,359 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8702097873796116, 'Total loss': 0.8702097873796116} | train loss {'Reaction outcome loss': 0.8116631400488649, 'Total loss': 0.8116631400488649}
2022-11-18 01:28:30,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:30,359 INFO:     Epoch: 95
2022-11-18 01:28:31,146 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8722012327475981, 'Total loss': 0.8722012327475981} | train loss {'Reaction outcome loss': 0.815589367498753, 'Total loss': 0.815589367498753}
2022-11-18 01:28:31,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:31,146 INFO:     Epoch: 96
2022-11-18 01:28:31,916 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8515025553378192, 'Total loss': 0.8515025553378192} | train loss {'Reaction outcome loss': 0.8122113198041916, 'Total loss': 0.8122113198041916}
2022-11-18 01:28:31,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:31,918 INFO:     Epoch: 97
2022-11-18 01:28:32,675 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8591863160783594, 'Total loss': 0.8591863160783594} | train loss {'Reaction outcome loss': 0.8177488236292171, 'Total loss': 0.8177488236292171}
2022-11-18 01:28:32,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:32,676 INFO:     Epoch: 98
2022-11-18 01:28:33,443 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8800889700651169, 'Total loss': 0.8800889700651169} | train loss {'Reaction outcome loss': 0.8108045371920474, 'Total loss': 0.8108045371920474}
2022-11-18 01:28:33,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:33,444 INFO:     Epoch: 99
2022-11-18 01:28:34,248 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8644035011529922, 'Total loss': 0.8644035011529922} | train loss {'Reaction outcome loss': 0.8087159274259077, 'Total loss': 0.8087159274259077}
2022-11-18 01:28:34,248 INFO:     Best model found after epoch 89 of 100.
2022-11-18 01:28:34,248 INFO:   Done with stage: TRAINING
2022-11-18 01:28:34,248 INFO:   Starting stage: EVALUATION
2022-11-18 01:28:34,374 INFO:   Done with stage: EVALUATION
2022-11-18 01:28:34,374 INFO:   Leaving out SEQ value Fold_6
2022-11-18 01:28:34,387 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:28:34,387 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:28:35,050 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:28:35,051 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:28:35,125 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:28:35,125 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:28:35,126 INFO:     No hyperparam tuning for this model
2022-11-18 01:28:35,126 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:28:35,126 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:28:35,127 INFO:     None feature selector for col prot
2022-11-18 01:28:35,127 INFO:     None feature selector for col prot
2022-11-18 01:28:35,127 INFO:     None feature selector for col prot
2022-11-18 01:28:35,127 INFO:     None feature selector for col chem
2022-11-18 01:28:35,127 INFO:     None feature selector for col chem
2022-11-18 01:28:35,128 INFO:     None feature selector for col chem
2022-11-18 01:28:35,128 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:28:35,128 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:28:35,129 INFO:     Number of params in model 168571
2022-11-18 01:28:35,133 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:28:35,133 INFO:   Starting stage: TRAINING
2022-11-18 01:28:35,190 INFO:     Val loss before train {'Reaction outcome loss': 1.0386779111894695, 'Total loss': 1.0386779111894695}
2022-11-18 01:28:35,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:35,190 INFO:     Epoch: 0
2022-11-18 01:28:35,986 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.889948074113239, 'Total loss': 0.889948074113239} | train loss {'Reaction outcome loss': 0.8754571112181976, 'Total loss': 0.8754571112181976}
2022-11-18 01:28:35,986 INFO:     Found new best model at epoch 0
2022-11-18 01:28:35,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:35,987 INFO:     Epoch: 1
2022-11-18 01:28:36,763 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8562312634153799, 'Total loss': 0.8562312634153799} | train loss {'Reaction outcome loss': 0.8385838756435796, 'Total loss': 0.8385838756435796}
2022-11-18 01:28:36,763 INFO:     Found new best model at epoch 1
2022-11-18 01:28:36,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:36,764 INFO:     Epoch: 2
2022-11-18 01:28:37,513 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8591315800493414, 'Total loss': 0.8591315800493414} | train loss {'Reaction outcome loss': 0.830620885739925, 'Total loss': 0.830620885739925}
2022-11-18 01:28:37,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:37,513 INFO:     Epoch: 3
2022-11-18 01:28:38,288 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8485823923891241, 'Total loss': 0.8485823923891241} | train loss {'Reaction outcome loss': 0.8231484029698468, 'Total loss': 0.8231484029698468}
2022-11-18 01:28:38,289 INFO:     Found new best model at epoch 3
2022-11-18 01:28:38,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:38,290 INFO:     Epoch: 4
2022-11-18 01:28:39,089 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8723739541389726, 'Total loss': 0.8723739541389726} | train loss {'Reaction outcome loss': 0.8168774019127433, 'Total loss': 0.8168774019127433}
2022-11-18 01:28:39,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:39,089 INFO:     Epoch: 5
2022-11-18 01:28:39,882 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8602571500973268, 'Total loss': 0.8602571500973268} | train loss {'Reaction outcome loss': 0.8202640495078284, 'Total loss': 0.8202640495078284}
2022-11-18 01:28:39,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:39,882 INFO:     Epoch: 6
2022-11-18 01:28:40,639 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8599377796053886, 'Total loss': 0.8599377796053886} | train loss {'Reaction outcome loss': 0.8140297871128268, 'Total loss': 0.8140297871128268}
2022-11-18 01:28:40,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:40,639 INFO:     Epoch: 7
2022-11-18 01:28:41,401 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8267063999717886, 'Total loss': 0.8267063999717886} | train loss {'Reaction outcome loss': 0.8193964467116213, 'Total loss': 0.8193964467116213}
2022-11-18 01:28:41,401 INFO:     Found new best model at epoch 7
2022-11-18 01:28:41,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:41,402 INFO:     Epoch: 8
2022-11-18 01:28:42,177 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8304587548429315, 'Total loss': 0.8304587548429315} | train loss {'Reaction outcome loss': 0.8145209930927647, 'Total loss': 0.8145209930927647}
2022-11-18 01:28:42,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:42,177 INFO:     Epoch: 9
2022-11-18 01:28:42,977 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8621498461474072, 'Total loss': 0.8621498461474072} | train loss {'Reaction outcome loss': 0.8049302185896919, 'Total loss': 0.8049302185896919}
2022-11-18 01:28:42,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:42,978 INFO:     Epoch: 10
2022-11-18 01:28:43,770 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8324476656588641, 'Total loss': 0.8324476656588641} | train loss {'Reaction outcome loss': 0.817524162260627, 'Total loss': 0.817524162260627}
2022-11-18 01:28:43,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:43,771 INFO:     Epoch: 11
2022-11-18 01:28:44,541 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8341854350133375, 'Total loss': 0.8341854350133375} | train loss {'Reaction outcome loss': 0.8135110393226871, 'Total loss': 0.8135110393226871}
2022-11-18 01:28:44,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:44,541 INFO:     Epoch: 12
2022-11-18 01:28:45,322 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8324923752383753, 'Total loss': 0.8324923752383753} | train loss {'Reaction outcome loss': 0.810589088843419, 'Total loss': 0.810589088843419}
2022-11-18 01:28:45,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:45,322 INFO:     Epoch: 13
2022-11-18 01:28:46,078 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8682335818355734, 'Total loss': 0.8682335818355734} | train loss {'Reaction outcome loss': 0.8089979164272185, 'Total loss': 0.8089979164272185}
2022-11-18 01:28:46,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:46,078 INFO:     Epoch: 14
2022-11-18 01:28:46,858 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8383239636367018, 'Total loss': 0.8383239636367018} | train loss {'Reaction outcome loss': 0.8146258089465168, 'Total loss': 0.8146258089465168}
2022-11-18 01:28:46,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:46,858 INFO:     Epoch: 15
2022-11-18 01:28:47,649 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8369364609772508, 'Total loss': 0.8369364609772508} | train loss {'Reaction outcome loss': 0.8050220631259052, 'Total loss': 0.8050220631259052}
2022-11-18 01:28:47,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:47,649 INFO:     Epoch: 16
2022-11-18 01:28:48,434 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8387799777767875, 'Total loss': 0.8387799777767875} | train loss {'Reaction outcome loss': 0.81202465066543, 'Total loss': 0.81202465066543}
2022-11-18 01:28:48,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:48,434 INFO:     Epoch: 17
2022-11-18 01:28:49,214 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8197501599788666, 'Total loss': 0.8197501599788666} | train loss {'Reaction outcome loss': 0.8058106042670938, 'Total loss': 0.8058106042670938}
2022-11-18 01:28:49,214 INFO:     Found new best model at epoch 17
2022-11-18 01:28:49,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:49,216 INFO:     Epoch: 18
2022-11-18 01:28:49,979 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8280136354944923, 'Total loss': 0.8280136354944923} | train loss {'Reaction outcome loss': 0.8043276089647038, 'Total loss': 0.8043276089647038}
2022-11-18 01:28:49,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:49,979 INFO:     Epoch: 19
2022-11-18 01:28:50,761 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8414877294139429, 'Total loss': 0.8414877294139429} | train loss {'Reaction outcome loss': 0.8103427447770771, 'Total loss': 0.8103427447770771}
2022-11-18 01:28:50,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:50,762 INFO:     Epoch: 20
2022-11-18 01:28:51,525 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8312857841903513, 'Total loss': 0.8312857841903513} | train loss {'Reaction outcome loss': 0.8103807286212319, 'Total loss': 0.8103807286212319}
2022-11-18 01:28:51,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:51,525 INFO:     Epoch: 21
2022-11-18 01:28:52,296 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8222235278649763, 'Total loss': 0.8222235278649763} | train loss {'Reaction outcome loss': 0.8066619177337601, 'Total loss': 0.8066619177337601}
2022-11-18 01:28:52,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:52,296 INFO:     Epoch: 22
2022-11-18 01:28:53,064 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8438141034408049, 'Total loss': 0.8438141034408049} | train loss {'Reaction outcome loss': 0.8074406226154281, 'Total loss': 0.8074406226154281}
2022-11-18 01:28:53,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:53,064 INFO:     Epoch: 23
2022-11-18 01:28:53,847 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.831992777233774, 'Total loss': 0.831992777233774} | train loss {'Reaction outcome loss': 0.8030219575774814, 'Total loss': 0.8030219575774814}
2022-11-18 01:28:53,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:53,848 INFO:     Epoch: 24
2022-11-18 01:28:54,633 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8213001733476465, 'Total loss': 0.8213001733476465} | train loss {'Reaction outcome loss': 0.810072626058872, 'Total loss': 0.810072626058872}
2022-11-18 01:28:54,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:54,633 INFO:     Epoch: 25
2022-11-18 01:28:55,419 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8344452862035144, 'Total loss': 0.8344452862035144} | train loss {'Reaction outcome loss': 0.805717756873683, 'Total loss': 0.805717756873683}
2022-11-18 01:28:55,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:55,420 INFO:     Epoch: 26
2022-11-18 01:28:56,198 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8226116441867568, 'Total loss': 0.8226116441867568} | train loss {'Reaction outcome loss': 0.807344592655236, 'Total loss': 0.807344592655236}
2022-11-18 01:28:56,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:56,198 INFO:     Epoch: 27
2022-11-18 01:28:57,003 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8218502483584664, 'Total loss': 0.8218502483584664} | train loss {'Reaction outcome loss': 0.8036311940866926, 'Total loss': 0.8036311940866926}
2022-11-18 01:28:57,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:57,003 INFO:     Epoch: 28
2022-11-18 01:28:57,786 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8356660767035051, 'Total loss': 0.8356660767035051} | train loss {'Reaction outcome loss': 0.8051558864502771, 'Total loss': 0.8051558864502771}
2022-11-18 01:28:57,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:57,786 INFO:     Epoch: 29
2022-11-18 01:28:58,532 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8446974347938191, 'Total loss': 0.8446974347938191} | train loss {'Reaction outcome loss': 0.8103790310954275, 'Total loss': 0.8103790310954275}
2022-11-18 01:28:58,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:58,532 INFO:     Epoch: 30
2022-11-18 01:28:59,294 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8332214707678015, 'Total loss': 0.8332214707678015} | train loss {'Reaction outcome loss': 0.8060790640622498, 'Total loss': 0.8060790640622498}
2022-11-18 01:28:59,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:28:59,294 INFO:     Epoch: 31
2022-11-18 01:29:00,065 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8176004859534177, 'Total loss': 0.8176004859534177} | train loss {'Reaction outcome loss': 0.8029552596783348, 'Total loss': 0.8029552596783348}
2022-11-18 01:29:00,066 INFO:     Found new best model at epoch 31
2022-11-18 01:29:00,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:00,066 INFO:     Epoch: 32
2022-11-18 01:29:00,865 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8488559743220155, 'Total loss': 0.8488559743220155} | train loss {'Reaction outcome loss': 0.8046517752201451, 'Total loss': 0.8046517752201451}
2022-11-18 01:29:00,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:00,865 INFO:     Epoch: 33
2022-11-18 01:29:01,641 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8232227143916216, 'Total loss': 0.8232227143916216} | train loss {'Reaction outcome loss': 0.8012648808208072, 'Total loss': 0.8012648808208072}
2022-11-18 01:29:01,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:01,641 INFO:     Epoch: 34
2022-11-18 01:29:02,410 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8364942812106826, 'Total loss': 0.8364942812106826} | train loss {'Reaction outcome loss': 0.7982998825760506, 'Total loss': 0.7982998825760506}
2022-11-18 01:29:02,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:02,410 INFO:     Epoch: 35
2022-11-18 01:29:03,147 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8239181177182631, 'Total loss': 0.8239181177182631} | train loss {'Reaction outcome loss': 0.8120140142527669, 'Total loss': 0.8120140142527669}
2022-11-18 01:29:03,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:03,149 INFO:     Epoch: 36
2022-11-18 01:29:03,943 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8209685276855122, 'Total loss': 0.8209685276855122} | train loss {'Reaction outcome loss': 0.8034024011750935, 'Total loss': 0.8034024011750935}
2022-11-18 01:29:03,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:03,944 INFO:     Epoch: 37
2022-11-18 01:29:04,720 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8286290101029656, 'Total loss': 0.8286290101029656} | train loss {'Reaction outcome loss': 0.8003046973514171, 'Total loss': 0.8003046973514171}
2022-11-18 01:29:04,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:04,720 INFO:     Epoch: 38
2022-11-18 01:29:05,504 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8215226300738074, 'Total loss': 0.8215226300738074} | train loss {'Reaction outcome loss': 0.8155297834863547, 'Total loss': 0.8155297834863547}
2022-11-18 01:29:05,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:05,504 INFO:     Epoch: 39
2022-11-18 01:29:06,282 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8244805241172964, 'Total loss': 0.8244805241172964} | train loss {'Reaction outcome loss': 0.8078549658721276, 'Total loss': 0.8078549658721276}
2022-11-18 01:29:06,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:06,282 INFO:     Epoch: 40
2022-11-18 01:29:07,095 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8343452580950477, 'Total loss': 0.8343452580950477} | train loss {'Reaction outcome loss': 0.8018845605102145, 'Total loss': 0.8018845605102145}
2022-11-18 01:29:07,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:07,095 INFO:     Epoch: 41
2022-11-18 01:29:07,856 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8182943673296408, 'Total loss': 0.8182943673296408} | train loss {'Reaction outcome loss': 0.8048417725061116, 'Total loss': 0.8048417725061116}
2022-11-18 01:29:07,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:07,856 INFO:     Epoch: 42
2022-11-18 01:29:08,613 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8314284133640203, 'Total loss': 0.8314284133640203} | train loss {'Reaction outcome loss': 0.8077241894204606, 'Total loss': 0.8077241894204606}
2022-11-18 01:29:08,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:08,614 INFO:     Epoch: 43
2022-11-18 01:29:09,371 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8282015113668009, 'Total loss': 0.8282015113668009} | train loss {'Reaction outcome loss': 0.7970165529774751, 'Total loss': 0.7970165529774751}
2022-11-18 01:29:09,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:09,372 INFO:     Epoch: 44
2022-11-18 01:29:10,173 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.846344689076597, 'Total loss': 0.846344689076597} | train loss {'Reaction outcome loss': 0.799874739155837, 'Total loss': 0.799874739155837}
2022-11-18 01:29:10,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:10,173 INFO:     Epoch: 45
2022-11-18 01:29:10,963 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8214442005211656, 'Total loss': 0.8214442005211656} | train loss {'Reaction outcome loss': 0.801944055658603, 'Total loss': 0.801944055658603}
2022-11-18 01:29:10,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:10,963 INFO:     Epoch: 46
2022-11-18 01:29:11,735 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8166152455589988, 'Total loss': 0.8166152455589988} | train loss {'Reaction outcome loss': 0.8029743553354189, 'Total loss': 0.8029743553354189}
2022-11-18 01:29:11,735 INFO:     Found new best model at epoch 46
2022-11-18 01:29:11,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:11,736 INFO:     Epoch: 47
2022-11-18 01:29:12,518 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8247395421970974, 'Total loss': 0.8247395421970974} | train loss {'Reaction outcome loss': 0.8060848611569115, 'Total loss': 0.8060848611569115}
2022-11-18 01:29:12,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:12,518 INFO:     Epoch: 48
2022-11-18 01:29:13,280 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8278203999454324, 'Total loss': 0.8278203999454324} | train loss {'Reaction outcome loss': 0.8021818953245757, 'Total loss': 0.8021818953245757}
2022-11-18 01:29:13,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:13,280 INFO:     Epoch: 49
2022-11-18 01:29:14,061 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8332477090033618, 'Total loss': 0.8332477090033618} | train loss {'Reaction outcome loss': 0.7995722225984099, 'Total loss': 0.7995722225984099}
2022-11-18 01:29:14,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:14,061 INFO:     Epoch: 50
2022-11-18 01:29:14,834 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8195404403588988, 'Total loss': 0.8195404403588988} | train loss {'Reaction outcome loss': 0.7990059045403592, 'Total loss': 0.7990059045403592}
2022-11-18 01:29:14,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:14,834 INFO:     Epoch: 51
2022-11-18 01:29:15,597 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8379904681986029, 'Total loss': 0.8379904681986029} | train loss {'Reaction outcome loss': 0.799799201957248, 'Total loss': 0.799799201957248}
2022-11-18 01:29:15,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:15,597 INFO:     Epoch: 52
2022-11-18 01:29:16,396 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8354966870763085, 'Total loss': 0.8354966870763085} | train loss {'Reaction outcome loss': 0.8015152765551077, 'Total loss': 0.8015152765551077}
2022-11-18 01:29:16,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:16,397 INFO:     Epoch: 53
2022-11-18 01:29:17,170 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8271606801585718, 'Total loss': 0.8271606801585718} | train loss {'Reaction outcome loss': 0.8045582189733683, 'Total loss': 0.8045582189733683}
2022-11-18 01:29:17,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:17,170 INFO:     Epoch: 54
2022-11-18 01:29:17,974 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8244769166816365, 'Total loss': 0.8244769166816365} | train loss {'Reaction outcome loss': 0.8000673625150673, 'Total loss': 0.8000673625150673}
2022-11-18 01:29:17,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:17,974 INFO:     Epoch: 55
2022-11-18 01:29:18,758 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8264046521349386, 'Total loss': 0.8264046521349386} | train loss {'Reaction outcome loss': 0.8061941048876959, 'Total loss': 0.8061941048876959}
2022-11-18 01:29:18,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:18,758 INFO:     Epoch: 56
2022-11-18 01:29:19,555 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8544525375420396, 'Total loss': 0.8544525375420396} | train loss {'Reaction outcome loss': 0.8013928031269838, 'Total loss': 0.8013928031269838}
2022-11-18 01:29:19,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:19,555 INFO:     Epoch: 57
2022-11-18 01:29:20,329 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8386113277890466, 'Total loss': 0.8386113277890466} | train loss {'Reaction outcome loss': 0.8011067957892591, 'Total loss': 0.8011067957892591}
2022-11-18 01:29:20,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:20,330 INFO:     Epoch: 58
2022-11-18 01:29:21,125 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8735438754612749, 'Total loss': 0.8735438754612749} | train loss {'Reaction outcome loss': 0.7952213351905104, 'Total loss': 0.7952213351905104}
2022-11-18 01:29:21,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:21,126 INFO:     Epoch: 59
2022-11-18 01:29:21,892 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8385332802479918, 'Total loss': 0.8385332802479918} | train loss {'Reaction outcome loss': 0.8044243446487164, 'Total loss': 0.8044243446487164}
2022-11-18 01:29:21,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:21,893 INFO:     Epoch: 60
2022-11-18 01:29:22,671 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8408036624843424, 'Total loss': 0.8408036624843424} | train loss {'Reaction outcome loss': 0.8086992876249769, 'Total loss': 0.8086992876249769}
2022-11-18 01:29:22,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:22,671 INFO:     Epoch: 61
2022-11-18 01:29:23,451 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.865872014652599, 'Total loss': 0.865872014652599} | train loss {'Reaction outcome loss': 0.8044680957097997, 'Total loss': 0.8044680957097997}
2022-11-18 01:29:23,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:23,451 INFO:     Epoch: 62
2022-11-18 01:29:24,206 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8326054838570681, 'Total loss': 0.8326054838570681} | train loss {'Reaction outcome loss': 0.8013454778836324, 'Total loss': 0.8013454778836324}
2022-11-18 01:29:24,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:24,206 INFO:     Epoch: 63
2022-11-18 01:29:24,971 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8304978683590889, 'Total loss': 0.8304978683590889} | train loss {'Reaction outcome loss': 0.8077901951697192, 'Total loss': 0.8077901951697192}
2022-11-18 01:29:24,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:24,972 INFO:     Epoch: 64
2022-11-18 01:29:25,741 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.839450401338664, 'Total loss': 0.839450401338664} | train loss {'Reaction outcome loss': 0.8122906521988301, 'Total loss': 0.8122906521988301}
2022-11-18 01:29:25,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:25,741 INFO:     Epoch: 65
2022-11-18 01:29:26,512 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8564318879084154, 'Total loss': 0.8564318879084154} | train loss {'Reaction outcome loss': 0.8081804104300163, 'Total loss': 0.8081804104300163}
2022-11-18 01:29:26,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:26,512 INFO:     Epoch: 66
2022-11-18 01:29:27,339 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8453647223385897, 'Total loss': 0.8453647223385897} | train loss {'Reaction outcome loss': 0.8040748340254913, 'Total loss': 0.8040748340254913}
2022-11-18 01:29:27,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:27,339 INFO:     Epoch: 67
2022-11-18 01:29:28,116 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8274989520961588, 'Total loss': 0.8274989520961588} | train loss {'Reaction outcome loss': 0.7966530152901947, 'Total loss': 0.7966530152901947}
2022-11-18 01:29:28,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:28,116 INFO:     Epoch: 68
2022-11-18 01:29:28,936 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8305401991714131, 'Total loss': 0.8305401991714131} | train loss {'Reaction outcome loss': 0.8007771659355897, 'Total loss': 0.8007771659355897}
2022-11-18 01:29:28,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:28,936 INFO:     Epoch: 69
2022-11-18 01:29:29,742 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8211210397156802, 'Total loss': 0.8211210397156802} | train loss {'Reaction outcome loss': 0.7998817290824193, 'Total loss': 0.7998817290824193}
2022-11-18 01:29:29,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:29,742 INFO:     Epoch: 70
2022-11-18 01:29:30,570 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8215625949881293, 'Total loss': 0.8215625949881293} | train loss {'Reaction outcome loss': 0.8018630107163418, 'Total loss': 0.8018630107163418}
2022-11-18 01:29:30,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:30,571 INFO:     Epoch: 71
2022-11-18 01:29:31,377 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8357730961658738, 'Total loss': 0.8357730961658738} | train loss {'Reaction outcome loss': 0.80862964587173, 'Total loss': 0.80862964587173}
2022-11-18 01:29:31,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:31,377 INFO:     Epoch: 72
2022-11-18 01:29:32,199 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.821774347261949, 'Total loss': 0.821774347261949} | train loss {'Reaction outcome loss': 0.8046015856659364, 'Total loss': 0.8046015856659364}
2022-11-18 01:29:32,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:32,200 INFO:     Epoch: 73
2022-11-18 01:29:33,026 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8518040654334155, 'Total loss': 0.8518040654334155} | train loss {'Reaction outcome loss': 0.8069251264155153, 'Total loss': 0.8069251264155153}
2022-11-18 01:29:33,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:33,026 INFO:     Epoch: 74
2022-11-18 01:29:33,818 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8203231529756025, 'Total loss': 0.8203231529756025} | train loss {'Reaction outcome loss': 0.8015496892786702, 'Total loss': 0.8015496892786702}
2022-11-18 01:29:33,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:33,818 INFO:     Epoch: 75
2022-11-18 01:29:34,648 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8274387676607479, 'Total loss': 0.8274387676607479} | train loss {'Reaction outcome loss': 0.8008061657067735, 'Total loss': 0.8008061657067735}
2022-11-18 01:29:34,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:34,650 INFO:     Epoch: 76
2022-11-18 01:29:35,427 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8110089444301345, 'Total loss': 0.8110089444301345} | train loss {'Reaction outcome loss': 0.8044454796835478, 'Total loss': 0.8044454796835478}
2022-11-18 01:29:35,427 INFO:     Found new best model at epoch 76
2022-11-18 01:29:35,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:35,428 INFO:     Epoch: 77
2022-11-18 01:29:36,200 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8376937129280784, 'Total loss': 0.8376937129280784} | train loss {'Reaction outcome loss': 0.8033685479388546, 'Total loss': 0.8033685479388546}
2022-11-18 01:29:36,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:36,200 INFO:     Epoch: 78
2022-11-18 01:29:37,036 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8181739002466202, 'Total loss': 0.8181739002466202} | train loss {'Reaction outcome loss': 0.8038658000800291, 'Total loss': 0.8038658000800291}
2022-11-18 01:29:37,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:37,036 INFO:     Epoch: 79
2022-11-18 01:29:37,810 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8492093099789186, 'Total loss': 0.8492093099789186} | train loss {'Reaction outcome loss': 0.8119064468121239, 'Total loss': 0.8119064468121239}
2022-11-18 01:29:37,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:37,811 INFO:     Epoch: 80
2022-11-18 01:29:38,584 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8251424817876383, 'Total loss': 0.8251424817876383} | train loss {'Reaction outcome loss': 0.8031787878347312, 'Total loss': 0.8031787878347312}
2022-11-18 01:29:38,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:38,585 INFO:     Epoch: 81
2022-11-18 01:29:39,401 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.835978858850219, 'Total loss': 0.835978858850219} | train loss {'Reaction outcome loss': 0.8000697748139802, 'Total loss': 0.8000697748139802}
2022-11-18 01:29:39,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:39,402 INFO:     Epoch: 82
2022-11-18 01:29:40,205 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8493761068040674, 'Total loss': 0.8493761068040674} | train loss {'Reaction outcome loss': 0.8030401694509182, 'Total loss': 0.8030401694509182}
2022-11-18 01:29:40,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:40,205 INFO:     Epoch: 83
2022-11-18 01:29:41,011 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8416995853185654, 'Total loss': 0.8416995853185654} | train loss {'Reaction outcome loss': 0.8070752486767556, 'Total loss': 0.8070752486767556}
2022-11-18 01:29:41,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:41,012 INFO:     Epoch: 84
2022-11-18 01:29:41,833 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8339851247993383, 'Total loss': 0.8339851247993383} | train loss {'Reaction outcome loss': 0.8098626706281654, 'Total loss': 0.8098626706281654}
2022-11-18 01:29:41,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:41,833 INFO:     Epoch: 85
2022-11-18 01:29:42,666 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8289831152016466, 'Total loss': 0.8289831152016466} | train loss {'Reaction outcome loss': 0.8032955930903856, 'Total loss': 0.8032955930903856}
2022-11-18 01:29:42,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:42,667 INFO:     Epoch: 86
2022-11-18 01:29:43,496 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8586023741147735, 'Total loss': 0.8586023741147735} | train loss {'Reaction outcome loss': 0.804081873493156, 'Total loss': 0.804081873493156}
2022-11-18 01:29:43,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:43,496 INFO:     Epoch: 87
2022-11-18 01:29:44,331 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8374019624157385, 'Total loss': 0.8374019624157385} | train loss {'Reaction outcome loss': 0.8046736064468801, 'Total loss': 0.8046736064468801}
2022-11-18 01:29:44,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:44,332 INFO:     Epoch: 88
2022-11-18 01:29:45,130 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8132585530931299, 'Total loss': 0.8132585530931299} | train loss {'Reaction outcome loss': 0.8026723998036944, 'Total loss': 0.8026723998036944}
2022-11-18 01:29:45,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:45,130 INFO:     Epoch: 89
2022-11-18 01:29:45,925 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8398497863249346, 'Total loss': 0.8398497863249346} | train loss {'Reaction outcome loss': 0.7976262616483789, 'Total loss': 0.7976262616483789}
2022-11-18 01:29:45,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:45,925 INFO:     Epoch: 90
2022-11-18 01:29:46,743 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8441813188520345, 'Total loss': 0.8441813188520345} | train loss {'Reaction outcome loss': 0.8021229115816263, 'Total loss': 0.8021229115816263}
2022-11-18 01:29:46,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:46,744 INFO:     Epoch: 91
2022-11-18 01:29:47,555 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8417847779664126, 'Total loss': 0.8417847779664126} | train loss {'Reaction outcome loss': 0.8025825221528892, 'Total loss': 0.8025825221528892}
2022-11-18 01:29:47,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:47,555 INFO:     Epoch: 92
2022-11-18 01:29:48,402 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8262407312339003, 'Total loss': 0.8262407312339003} | train loss {'Reaction outcome loss': 0.813841082306526, 'Total loss': 0.813841082306526}
2022-11-18 01:29:48,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:48,402 INFO:     Epoch: 93
2022-11-18 01:29:49,157 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.845883540131829, 'Total loss': 0.845883540131829} | train loss {'Reaction outcome loss': 0.8011002065199107, 'Total loss': 0.8011002065199107}
2022-11-18 01:29:49,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:49,158 INFO:     Epoch: 94
2022-11-18 01:29:49,956 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8537909334356134, 'Total loss': 0.8537909334356134} | train loss {'Reaction outcome loss': 0.8070809918376598, 'Total loss': 0.8070809918376598}
2022-11-18 01:29:49,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:49,957 INFO:     Epoch: 95
2022-11-18 01:29:50,746 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8220765157179399, 'Total loss': 0.8220765157179399} | train loss {'Reaction outcome loss': 0.801817408698773, 'Total loss': 0.801817408698773}
2022-11-18 01:29:50,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:50,747 INFO:     Epoch: 96
2022-11-18 01:29:51,548 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8258757347410376, 'Total loss': 0.8258757347410376} | train loss {'Reaction outcome loss': 0.7997621373850324, 'Total loss': 0.7997621373850324}
2022-11-18 01:29:51,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:51,549 INFO:     Epoch: 97
2022-11-18 01:29:52,355 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8371514671228149, 'Total loss': 0.8371514671228149} | train loss {'Reaction outcome loss': 0.8056581979579771, 'Total loss': 0.8056581979579771}
2022-11-18 01:29:52,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:52,355 INFO:     Epoch: 98
2022-11-18 01:29:53,172 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8329287394881248, 'Total loss': 0.8329287394881248} | train loss {'Reaction outcome loss': 0.7977976795391515, 'Total loss': 0.7977976795391515}
2022-11-18 01:29:53,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:53,173 INFO:     Epoch: 99
2022-11-18 01:29:53,953 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8275893615050749, 'Total loss': 0.8275893615050749} | train loss {'Reaction outcome loss': 0.7995981862429182, 'Total loss': 0.7995981862429182}
2022-11-18 01:29:53,953 INFO:     Best model found after epoch 77 of 100.
2022-11-18 01:29:53,954 INFO:   Done with stage: TRAINING
2022-11-18 01:29:53,954 INFO:   Starting stage: EVALUATION
2022-11-18 01:29:54,078 INFO:   Done with stage: EVALUATION
2022-11-18 01:29:54,079 INFO:   Leaving out SEQ value Fold_7
2022-11-18 01:29:54,092 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:29:54,092 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:29:54,760 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:29:54,760 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:29:54,830 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:29:54,831 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:29:54,831 INFO:     No hyperparam tuning for this model
2022-11-18 01:29:54,831 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:29:54,831 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:29:54,832 INFO:     None feature selector for col prot
2022-11-18 01:29:54,832 INFO:     None feature selector for col prot
2022-11-18 01:29:54,832 INFO:     None feature selector for col prot
2022-11-18 01:29:54,833 INFO:     None feature selector for col chem
2022-11-18 01:29:54,833 INFO:     None feature selector for col chem
2022-11-18 01:29:54,833 INFO:     None feature selector for col chem
2022-11-18 01:29:54,833 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:29:54,833 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:29:54,834 INFO:     Number of params in model 168571
2022-11-18 01:29:54,838 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:29:54,838 INFO:   Starting stage: TRAINING
2022-11-18 01:29:54,895 INFO:     Val loss before train {'Reaction outcome loss': 0.9378290636972948, 'Total loss': 0.9378290636972948}
2022-11-18 01:29:54,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:54,895 INFO:     Epoch: 0
2022-11-18 01:29:55,682 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7903232797980309, 'Total loss': 0.7903232797980309} | train loss {'Reaction outcome loss': 0.8903974997660806, 'Total loss': 0.8903974997660806}
2022-11-18 01:29:55,683 INFO:     Found new best model at epoch 0
2022-11-18 01:29:55,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:55,683 INFO:     Epoch: 1
2022-11-18 01:29:56,466 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8071886836127802, 'Total loss': 0.8071886836127802} | train loss {'Reaction outcome loss': 0.8521396055096581, 'Total loss': 0.8521396055096581}
2022-11-18 01:29:56,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:56,466 INFO:     Epoch: 2
2022-11-18 01:29:57,232 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7990249415690248, 'Total loss': 0.7990249415690248} | train loss {'Reaction outcome loss': 0.8506212065056447, 'Total loss': 0.8506212065056447}
2022-11-18 01:29:57,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:57,233 INFO:     Epoch: 3
2022-11-18 01:29:57,996 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7948251833969896, 'Total loss': 0.7948251833969896} | train loss {'Reaction outcome loss': 0.8460836865969242, 'Total loss': 0.8460836865969242}
2022-11-18 01:29:57,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:57,996 INFO:     Epoch: 4
2022-11-18 01:29:58,774 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7691540250724013, 'Total loss': 0.7691540250724013} | train loss {'Reaction outcome loss': 0.8403884808142339, 'Total loss': 0.8403884808142339}
2022-11-18 01:29:58,774 INFO:     Found new best model at epoch 4
2022-11-18 01:29:58,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:58,775 INFO:     Epoch: 5
2022-11-18 01:29:59,573 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7748010023073717, 'Total loss': 0.7748010023073717} | train loss {'Reaction outcome loss': 0.8386733968171382, 'Total loss': 0.8386733968171382}
2022-11-18 01:29:59,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:29:59,574 INFO:     Epoch: 6
2022-11-18 01:30:00,405 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7688119668852199, 'Total loss': 0.7688119668852199} | train loss {'Reaction outcome loss': 0.8293386056057869, 'Total loss': 0.8293386056057869}
2022-11-18 01:30:00,405 INFO:     Found new best model at epoch 6
2022-11-18 01:30:00,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:00,406 INFO:     Epoch: 7
2022-11-18 01:30:01,207 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7791079330173406, 'Total loss': 0.7791079330173406} | train loss {'Reaction outcome loss': 0.827772521924588, 'Total loss': 0.827772521924588}
2022-11-18 01:30:01,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:01,207 INFO:     Epoch: 8
2022-11-18 01:30:02,000 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7714756537567485, 'Total loss': 0.7714756537567485} | train loss {'Reaction outcome loss': 0.8285289424802026, 'Total loss': 0.8285289424802026}
2022-11-18 01:30:02,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:02,000 INFO:     Epoch: 9
2022-11-18 01:30:02,763 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7674761753190648, 'Total loss': 0.7674761753190648} | train loss {'Reaction outcome loss': 0.8283909892122592, 'Total loss': 0.8283909892122592}
2022-11-18 01:30:02,763 INFO:     Found new best model at epoch 9
2022-11-18 01:30:02,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:02,764 INFO:     Epoch: 10
2022-11-18 01:30:03,515 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7659017159180208, 'Total loss': 0.7659017159180208} | train loss {'Reaction outcome loss': 0.8252563504201751, 'Total loss': 0.8252563504201751}
2022-11-18 01:30:03,515 INFO:     Found new best model at epoch 10
2022-11-18 01:30:03,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:03,516 INFO:     Epoch: 11
2022-11-18 01:30:04,297 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7657376663251356, 'Total loss': 0.7657376663251356} | train loss {'Reaction outcome loss': 0.8251596404419791, 'Total loss': 0.8251596404419791}
2022-11-18 01:30:04,297 INFO:     Found new best model at epoch 11
2022-11-18 01:30:04,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:04,298 INFO:     Epoch: 12
2022-11-18 01:30:05,076 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.762667374854738, 'Total loss': 0.762667374854738} | train loss {'Reaction outcome loss': 0.8242211709580114, 'Total loss': 0.8242211709580114}
2022-11-18 01:30:05,076 INFO:     Found new best model at epoch 12
2022-11-18 01:30:05,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:05,077 INFO:     Epoch: 13
2022-11-18 01:30:05,866 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7590048800815236, 'Total loss': 0.7590048800815236} | train loss {'Reaction outcome loss': 0.8213129436537143, 'Total loss': 0.8213129436537143}
2022-11-18 01:30:05,867 INFO:     Found new best model at epoch 13
2022-11-18 01:30:05,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:05,868 INFO:     Epoch: 14
2022-11-18 01:30:06,658 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7557514824650504, 'Total loss': 0.7557514824650504} | train loss {'Reaction outcome loss': 0.8242659312823126, 'Total loss': 0.8242659312823126}
2022-11-18 01:30:06,658 INFO:     Found new best model at epoch 14
2022-11-18 01:30:06,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:06,659 INFO:     Epoch: 15
2022-11-18 01:30:07,464 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7646546668627046, 'Total loss': 0.7646546668627046} | train loss {'Reaction outcome loss': 0.821159748781112, 'Total loss': 0.821159748781112}
2022-11-18 01:30:07,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:07,465 INFO:     Epoch: 16
2022-11-18 01:30:08,254 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7688069174235518, 'Total loss': 0.7688069174235518} | train loss {'Reaction outcome loss': 0.8250147992324445, 'Total loss': 0.8250147992324445}
2022-11-18 01:30:08,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:08,254 INFO:     Epoch: 17
2022-11-18 01:30:09,041 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7798158777031031, 'Total loss': 0.7798158777031031} | train loss {'Reaction outcome loss': 0.8226209256437517, 'Total loss': 0.8226209256437517}
2022-11-18 01:30:09,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:09,042 INFO:     Epoch: 18
2022-11-18 01:30:09,808 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7656395496292547, 'Total loss': 0.7656395496292547} | train loss {'Reaction outcome loss': 0.8284596990673773, 'Total loss': 0.8284596990673773}
2022-11-18 01:30:09,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:09,809 INFO:     Epoch: 19
2022-11-18 01:30:10,575 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7867157506671819, 'Total loss': 0.7867157506671819} | train loss {'Reaction outcome loss': 0.8218185362075606, 'Total loss': 0.8218185362075606}
2022-11-18 01:30:10,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:10,575 INFO:     Epoch: 20
2022-11-18 01:30:11,359 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7603298364715143, 'Total loss': 0.7603298364715143} | train loss {'Reaction outcome loss': 0.8229126260886269, 'Total loss': 0.8229126260886269}
2022-11-18 01:30:11,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:11,359 INFO:     Epoch: 21
2022-11-18 01:30:12,147 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7600543580271981, 'Total loss': 0.7600543580271981} | train loss {'Reaction outcome loss': 0.822230022280447, 'Total loss': 0.822230022280447}
2022-11-18 01:30:12,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:12,148 INFO:     Epoch: 22
2022-11-18 01:30:12,930 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7692171667109836, 'Total loss': 0.7692171667109836} | train loss {'Reaction outcome loss': 0.8246359153380317, 'Total loss': 0.8246359153380317}
2022-11-18 01:30:12,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:12,931 INFO:     Epoch: 23
2022-11-18 01:30:13,719 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7877139591357925, 'Total loss': 0.7877139591357925} | train loss {'Reaction outcome loss': 0.8228239603340626, 'Total loss': 0.8228239603340626}
2022-11-18 01:30:13,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:13,719 INFO:     Epoch: 24
2022-11-18 01:30:14,495 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7544131414456801, 'Total loss': 0.7544131414456801} | train loss {'Reaction outcome loss': 0.8206663577546996, 'Total loss': 0.8206663577546996}
2022-11-18 01:30:14,495 INFO:     Found new best model at epoch 24
2022-11-18 01:30:14,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:14,496 INFO:     Epoch: 25
2022-11-18 01:30:15,265 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7639837712049484, 'Total loss': 0.7639837712049484} | train loss {'Reaction outcome loss': 0.8184279382469193, 'Total loss': 0.8184279382469193}
2022-11-18 01:30:15,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:15,265 INFO:     Epoch: 26
2022-11-18 01:30:16,041 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8035059517080133, 'Total loss': 0.8035059517080133} | train loss {'Reaction outcome loss': 0.816246218859188, 'Total loss': 0.816246218859188}
2022-11-18 01:30:16,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:16,041 INFO:     Epoch: 27
2022-11-18 01:30:16,795 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.767812354998155, 'Total loss': 0.767812354998155} | train loss {'Reaction outcome loss': 0.8268428167268154, 'Total loss': 0.8268428167268154}
2022-11-18 01:30:16,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:16,795 INFO:     Epoch: 28
2022-11-18 01:30:17,571 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7655426060611551, 'Total loss': 0.7655426060611551} | train loss {'Reaction outcome loss': 0.8201866134280159, 'Total loss': 0.8201866134280159}
2022-11-18 01:30:17,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:17,571 INFO:     Epoch: 29
2022-11-18 01:30:18,357 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8049702007662166, 'Total loss': 0.8049702007662166} | train loss {'Reaction outcome loss': 0.8177564668078576, 'Total loss': 0.8177564668078576}
2022-11-18 01:30:18,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:18,357 INFO:     Epoch: 30
2022-11-18 01:30:19,132 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7794574831019748, 'Total loss': 0.7794574831019748} | train loss {'Reaction outcome loss': 0.8257708426925444, 'Total loss': 0.8257708426925444}
2022-11-18 01:30:19,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:19,133 INFO:     Epoch: 31
2022-11-18 01:30:19,901 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.775743228468028, 'Total loss': 0.775743228468028} | train loss {'Reaction outcome loss': 0.8194204734698418, 'Total loss': 0.8194204734698418}
2022-11-18 01:30:19,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:19,901 INFO:     Epoch: 32
2022-11-18 01:30:20,661 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7658537754958327, 'Total loss': 0.7658537754958327} | train loss {'Reaction outcome loss': 0.8237097697152246, 'Total loss': 0.8237097697152246}
2022-11-18 01:30:20,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:20,661 INFO:     Epoch: 33
2022-11-18 01:30:21,439 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7627052224495194, 'Total loss': 0.7627052224495194} | train loss {'Reaction outcome loss': 0.8228271729763477, 'Total loss': 0.8228271729763477}
2022-11-18 01:30:21,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:21,439 INFO:     Epoch: 34
2022-11-18 01:30:22,224 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7552630474621599, 'Total loss': 0.7552630474621599} | train loss {'Reaction outcome loss': 0.8257461507474223, 'Total loss': 0.8257461507474223}
2022-11-18 01:30:22,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:22,224 INFO:     Epoch: 35
2022-11-18 01:30:23,018 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7741133509711786, 'Total loss': 0.7741133509711786} | train loss {'Reaction outcome loss': 0.8247644493897115, 'Total loss': 0.8247644493897115}
2022-11-18 01:30:23,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:23,018 INFO:     Epoch: 36
2022-11-18 01:30:23,785 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7714592943137343, 'Total loss': 0.7714592943137343} | train loss {'Reaction outcome loss': 0.8204536456013879, 'Total loss': 0.8204536456013879}
2022-11-18 01:30:23,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:23,786 INFO:     Epoch: 37
2022-11-18 01:30:24,568 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7788273583758961, 'Total loss': 0.7788273583758961} | train loss {'Reaction outcome loss': 0.8192938673159769, 'Total loss': 0.8192938673159769}
2022-11-18 01:30:24,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:24,569 INFO:     Epoch: 38
2022-11-18 01:30:25,346 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7664294019341469, 'Total loss': 0.7664294019341469} | train loss {'Reaction outcome loss': 0.821845381130134, 'Total loss': 0.821845381130134}
2022-11-18 01:30:25,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:25,346 INFO:     Epoch: 39
2022-11-18 01:30:26,107 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7616142122582956, 'Total loss': 0.7616142122582956} | train loss {'Reaction outcome loss': 0.8190058654835147, 'Total loss': 0.8190058654835147}
2022-11-18 01:30:26,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:26,107 INFO:     Epoch: 40
2022-11-18 01:30:26,879 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7665045071731914, 'Total loss': 0.7665045071731914} | train loss {'Reaction outcome loss': 0.8192781894317558, 'Total loss': 0.8192781894317558}
2022-11-18 01:30:26,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:26,879 INFO:     Epoch: 41
2022-11-18 01:30:27,678 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7867437262426723, 'Total loss': 0.7867437262426723} | train loss {'Reaction outcome loss': 0.8233573911411147, 'Total loss': 0.8233573911411147}
2022-11-18 01:30:27,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:27,679 INFO:     Epoch: 42
2022-11-18 01:30:28,450 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7883745113557036, 'Total loss': 0.7883745113557036} | train loss {'Reaction outcome loss': 0.823723092675209, 'Total loss': 0.823723092675209}
2022-11-18 01:30:28,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:28,450 INFO:     Epoch: 43
2022-11-18 01:30:29,239 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7726165774193677, 'Total loss': 0.7726165774193677} | train loss {'Reaction outcome loss': 0.8190625112864279, 'Total loss': 0.8190625112864279}
2022-11-18 01:30:29,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:29,240 INFO:     Epoch: 44
2022-11-18 01:30:29,996 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7637873535806482, 'Total loss': 0.7637873535806482} | train loss {'Reaction outcome loss': 0.8181767467289202, 'Total loss': 0.8181767467289202}
2022-11-18 01:30:29,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:29,996 INFO:     Epoch: 45
2022-11-18 01:30:30,781 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7665614241903479, 'Total loss': 0.7665614241903479} | train loss {'Reaction outcome loss': 0.8208404668877202, 'Total loss': 0.8208404668877202}
2022-11-18 01:30:30,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:30,782 INFO:     Epoch: 46
2022-11-18 01:30:31,579 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7830896113406528, 'Total loss': 0.7830896113406528} | train loss {'Reaction outcome loss': 0.8202300146222115, 'Total loss': 0.8202300146222115}
2022-11-18 01:30:31,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:31,580 INFO:     Epoch: 47
2022-11-18 01:30:32,367 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7607044272802093, 'Total loss': 0.7607044272802093} | train loss {'Reaction outcome loss': 0.820533987495207, 'Total loss': 0.820533987495207}
2022-11-18 01:30:32,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:32,367 INFO:     Epoch: 48
2022-11-18 01:30:33,145 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7659004100344398, 'Total loss': 0.7659004100344398} | train loss {'Reaction outcome loss': 0.8214437688790983, 'Total loss': 0.8214437688790983}
2022-11-18 01:30:33,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:33,145 INFO:     Epoch: 49
2022-11-18 01:30:33,911 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7754697393287312, 'Total loss': 0.7754697393287312} | train loss {'Reaction outcome loss': 0.8184672574843129, 'Total loss': 0.8184672574843129}
2022-11-18 01:30:33,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:33,911 INFO:     Epoch: 50
2022-11-18 01:30:34,699 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7566258968277411, 'Total loss': 0.7566258968277411} | train loss {'Reaction outcome loss': 0.8172193304184945, 'Total loss': 0.8172193304184945}
2022-11-18 01:30:34,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:34,699 INFO:     Epoch: 51
2022-11-18 01:30:35,479 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.760258325798945, 'Total loss': 0.760258325798945} | train loss {'Reaction outcome loss': 0.8195013841313701, 'Total loss': 0.8195013841313701}
2022-11-18 01:30:35,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:35,480 INFO:     Epoch: 52
2022-11-18 01:30:36,299 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7629351453347639, 'Total loss': 0.7629351453347639} | train loss {'Reaction outcome loss': 0.8166003377447205, 'Total loss': 0.8166003377447205}
2022-11-18 01:30:36,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:36,299 INFO:     Epoch: 53
2022-11-18 01:30:37,090 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8003372658382762, 'Total loss': 0.8003372658382762} | train loss {'Reaction outcome loss': 0.8220853435416375, 'Total loss': 0.8220853435416375}
2022-11-18 01:30:37,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:37,091 INFO:     Epoch: 54
2022-11-18 01:30:37,902 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7959323200312528, 'Total loss': 0.7959323200312528} | train loss {'Reaction outcome loss': 0.82345155181904, 'Total loss': 0.82345155181904}
2022-11-18 01:30:37,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:37,902 INFO:     Epoch: 55
2022-11-18 01:30:38,699 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7725251344117251, 'Total loss': 0.7725251344117251} | train loss {'Reaction outcome loss': 0.8180545646577112, 'Total loss': 0.8180545646577112}
2022-11-18 01:30:38,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:38,700 INFO:     Epoch: 56
2022-11-18 01:30:39,472 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7526470917192373, 'Total loss': 0.7526470917192373} | train loss {'Reaction outcome loss': 0.8211020800855852, 'Total loss': 0.8211020800855852}
2022-11-18 01:30:39,472 INFO:     Found new best model at epoch 56
2022-11-18 01:30:39,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:39,473 INFO:     Epoch: 57
2022-11-18 01:30:40,231 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7562112083489244, 'Total loss': 0.7562112083489244} | train loss {'Reaction outcome loss': 0.8186097447910616, 'Total loss': 0.8186097447910616}
2022-11-18 01:30:40,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:40,232 INFO:     Epoch: 58
2022-11-18 01:30:41,019 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7701791043985974, 'Total loss': 0.7701791043985974} | train loss {'Reaction outcome loss': 0.8230372437786672, 'Total loss': 0.8230372437786672}
2022-11-18 01:30:41,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:41,020 INFO:     Epoch: 59
2022-11-18 01:30:41,826 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7646931768818335, 'Total loss': 0.7646931768818335} | train loss {'Reaction outcome loss': 0.8247042007503971, 'Total loss': 0.8247042007503971}
2022-11-18 01:30:41,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:41,826 INFO:     Epoch: 60
2022-11-18 01:30:42,663 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7832237380472097, 'Total loss': 0.7832237380472097} | train loss {'Reaction outcome loss': 0.8228055628076676, 'Total loss': 0.8228055628076676}
2022-11-18 01:30:42,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:42,663 INFO:     Epoch: 61
2022-11-18 01:30:43,443 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7611788003282114, 'Total loss': 0.7611788003282114} | train loss {'Reaction outcome loss': 0.8224108638542313, 'Total loss': 0.8224108638542313}
2022-11-18 01:30:43,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:43,444 INFO:     Epoch: 62
2022-11-18 01:30:44,208 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7655946368520911, 'Total loss': 0.7655946368520911} | train loss {'Reaction outcome loss': 0.8193486038475267, 'Total loss': 0.8193486038475267}
2022-11-18 01:30:44,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:44,208 INFO:     Epoch: 63
2022-11-18 01:30:44,978 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7927272197875109, 'Total loss': 0.7927272197875109} | train loss {'Reaction outcome loss': 0.816567514812754, 'Total loss': 0.816567514812754}
2022-11-18 01:30:44,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:44,978 INFO:     Epoch: 64
2022-11-18 01:30:45,784 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7643824341622266, 'Total loss': 0.7643824341622266} | train loss {'Reaction outcome loss': 0.822047365889434, 'Total loss': 0.822047365889434}
2022-11-18 01:30:45,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:45,785 INFO:     Epoch: 65
2022-11-18 01:30:46,580 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7629432447931983, 'Total loss': 0.7629432447931983} | train loss {'Reaction outcome loss': 0.8199084771256293, 'Total loss': 0.8199084771256293}
2022-11-18 01:30:46,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:46,581 INFO:     Epoch: 66
2022-11-18 01:30:47,376 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7565344307910312, 'Total loss': 0.7565344307910312} | train loss {'Reaction outcome loss': 0.8223332953789542, 'Total loss': 0.8223332953789542}
2022-11-18 01:30:47,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:47,376 INFO:     Epoch: 67
2022-11-18 01:30:48,172 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7492355453697118, 'Total loss': 0.7492355453697118} | train loss {'Reaction outcome loss': 0.8178424010834386, 'Total loss': 0.8178424010834386}
2022-11-18 01:30:48,172 INFO:     Found new best model at epoch 67
2022-11-18 01:30:48,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:48,173 INFO:     Epoch: 68
2022-11-18 01:30:48,995 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7520008385181427, 'Total loss': 0.7520008385181427} | train loss {'Reaction outcome loss': 0.8216332139507416, 'Total loss': 0.8216332139507416}
2022-11-18 01:30:48,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:48,995 INFO:     Epoch: 69
2022-11-18 01:30:49,781 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7677347565239127, 'Total loss': 0.7677347565239127} | train loss {'Reaction outcome loss': 0.8254193802995067, 'Total loss': 0.8254193802995067}
2022-11-18 01:30:49,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:49,781 INFO:     Epoch: 70
2022-11-18 01:30:50,581 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7535943619229577, 'Total loss': 0.7535943619229577} | train loss {'Reaction outcome loss': 0.8153330568344362, 'Total loss': 0.8153330568344362}
2022-11-18 01:30:50,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:50,582 INFO:     Epoch: 71
2022-11-18 01:30:51,377 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7642395022240552, 'Total loss': 0.7642395022240552} | train loss {'Reaction outcome loss': 0.8190494754141376, 'Total loss': 0.8190494754141376}
2022-11-18 01:30:51,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:51,377 INFO:     Epoch: 72
2022-11-18 01:30:52,156 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.773747904734178, 'Total loss': 0.773747904734178} | train loss {'Reaction outcome loss': 0.818415671707161, 'Total loss': 0.818415671707161}
2022-11-18 01:30:52,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:52,157 INFO:     Epoch: 73
2022-11-18 01:30:52,951 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8106638870456002, 'Total loss': 0.8106638870456002} | train loss {'Reaction outcome loss': 0.8266869779195516, 'Total loss': 0.8266869779195516}
2022-11-18 01:30:52,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:52,951 INFO:     Epoch: 74
2022-11-18 01:30:53,736 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7704050405458971, 'Total loss': 0.7704050405458971} | train loss {'Reaction outcome loss': 0.8214150788562913, 'Total loss': 0.8214150788562913}
2022-11-18 01:30:53,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:53,736 INFO:     Epoch: 75
2022-11-18 01:30:54,515 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7828648638996211, 'Total loss': 0.7828648638996211} | train loss {'Reaction outcome loss': 0.8160208980402639, 'Total loss': 0.8160208980402639}
2022-11-18 01:30:54,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:54,515 INFO:     Epoch: 76
2022-11-18 01:30:55,292 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7714840722354975, 'Total loss': 0.7714840722354975} | train loss {'Reaction outcome loss': 0.8203108030701837, 'Total loss': 0.8203108030701837}
2022-11-18 01:30:55,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:55,292 INFO:     Epoch: 77
2022-11-18 01:30:56,092 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7607465386390686, 'Total loss': 0.7607465386390686} | train loss {'Reaction outcome loss': 0.8231800422072411, 'Total loss': 0.8231800422072411}
2022-11-18 01:30:56,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:56,093 INFO:     Epoch: 78
2022-11-18 01:30:56,902 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7902378406036984, 'Total loss': 0.7902378406036984} | train loss {'Reaction outcome loss': 0.8144835592998613, 'Total loss': 0.8144835592998613}
2022-11-18 01:30:56,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:56,903 INFO:     Epoch: 79
2022-11-18 01:30:57,688 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7594590749252926, 'Total loss': 0.7594590749252926} | train loss {'Reaction outcome loss': 0.8184995666867302, 'Total loss': 0.8184995666867302}
2022-11-18 01:30:57,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:57,688 INFO:     Epoch: 80
2022-11-18 01:30:58,483 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.773058645427227, 'Total loss': 0.773058645427227} | train loss {'Reaction outcome loss': 0.8212811883178449, 'Total loss': 0.8212811883178449}
2022-11-18 01:30:58,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:58,483 INFO:     Epoch: 81
2022-11-18 01:30:59,269 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.765727657486092, 'Total loss': 0.765727657486092} | train loss {'Reaction outcome loss': 0.8225968721653184, 'Total loss': 0.8225968721653184}
2022-11-18 01:30:59,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:30:59,269 INFO:     Epoch: 82
2022-11-18 01:31:00,069 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7579602199521932, 'Total loss': 0.7579602199521932} | train loss {'Reaction outcome loss': 0.8176268989280346, 'Total loss': 0.8176268989280346}
2022-11-18 01:31:00,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:00,069 INFO:     Epoch: 83
2022-11-18 01:31:00,852 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7563965591517362, 'Total loss': 0.7563965591517362} | train loss {'Reaction outcome loss': 0.8227680359155901, 'Total loss': 0.8227680359155901}
2022-11-18 01:31:00,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:00,852 INFO:     Epoch: 84
2022-11-18 01:31:01,660 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7739487134597518, 'Total loss': 0.7739487134597518} | train loss {'Reaction outcome loss': 0.8206268094720379, 'Total loss': 0.8206268094720379}
2022-11-18 01:31:01,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:01,660 INFO:     Epoch: 85
2022-11-18 01:31:02,438 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7707115337252617, 'Total loss': 0.7707115337252617} | train loss {'Reaction outcome loss': 0.8156108666331537, 'Total loss': 0.8156108666331537}
2022-11-18 01:31:02,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:02,439 INFO:     Epoch: 86
2022-11-18 01:31:03,217 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7612831849943508, 'Total loss': 0.7612831849943508} | train loss {'Reaction outcome loss': 0.8199706011481823, 'Total loss': 0.8199706011481823}
2022-11-18 01:31:03,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:03,218 INFO:     Epoch: 87
2022-11-18 01:31:04,030 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7557045444846153, 'Total loss': 0.7557045444846153} | train loss {'Reaction outcome loss': 0.8192441331282738, 'Total loss': 0.8192441331282738}
2022-11-18 01:31:04,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:04,030 INFO:     Epoch: 88
2022-11-18 01:31:04,856 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8088294159282338, 'Total loss': 0.8088294159282338} | train loss {'Reaction outcome loss': 0.8213931891706682, 'Total loss': 0.8213931891706682}
2022-11-18 01:31:04,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:04,856 INFO:     Epoch: 89
2022-11-18 01:31:05,631 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7534874386408112, 'Total loss': 0.7534874386408112} | train loss {'Reaction outcome loss': 0.8202149273166733, 'Total loss': 0.8202149273166733}
2022-11-18 01:31:05,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:05,632 INFO:     Epoch: 90
2022-11-18 01:31:06,429 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7801878208463843, 'Total loss': 0.7801878208463843} | train loss {'Reaction outcome loss': 0.8183541690870639, 'Total loss': 0.8183541690870639}
2022-11-18 01:31:06,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:06,429 INFO:     Epoch: 91
2022-11-18 01:31:07,237 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7866902690042149, 'Total loss': 0.7866902690042149} | train loss {'Reaction outcome loss': 0.817299586149954, 'Total loss': 0.817299586149954}
2022-11-18 01:31:07,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:07,237 INFO:     Epoch: 92
2022-11-18 01:31:08,032 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7574608312411741, 'Total loss': 0.7574608312411741} | train loss {'Reaction outcome loss': 0.8189352598161467, 'Total loss': 0.8189352598161467}
2022-11-18 01:31:08,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:08,034 INFO:     Epoch: 93
2022-11-18 01:31:08,825 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7735156118869781, 'Total loss': 0.7735156118869781} | train loss {'Reaction outcome loss': 0.8210344749592966, 'Total loss': 0.8210344749592966}
2022-11-18 01:31:08,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:08,825 INFO:     Epoch: 94
2022-11-18 01:31:09,612 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8072832870212469, 'Total loss': 0.8072832870212469} | train loss {'Reaction outcome loss': 0.822186907332751, 'Total loss': 0.822186907332751}
2022-11-18 01:31:09,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:09,612 INFO:     Epoch: 95
2022-11-18 01:31:10,379 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7692300582473929, 'Total loss': 0.7692300582473929} | train loss {'Reaction outcome loss': 0.8185942302788457, 'Total loss': 0.8185942302788457}
2022-11-18 01:31:10,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:10,379 INFO:     Epoch: 96
2022-11-18 01:31:11,199 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7601220770315691, 'Total loss': 0.7601220770315691} | train loss {'Reaction outcome loss': 0.8195750249489662, 'Total loss': 0.8195750249489662}
2022-11-18 01:31:11,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:11,199 INFO:     Epoch: 97
2022-11-18 01:31:11,980 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7538275244561109, 'Total loss': 0.7538275244561109} | train loss {'Reaction outcome loss': 0.8183565842768838, 'Total loss': 0.8183565842768838}
2022-11-18 01:31:11,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:11,981 INFO:     Epoch: 98
2022-11-18 01:31:12,781 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7734902921048078, 'Total loss': 0.7734902921048078} | train loss {'Reaction outcome loss': 0.8249706482935336, 'Total loss': 0.8249706482935336}
2022-11-18 01:31:12,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:12,781 INFO:     Epoch: 99
2022-11-18 01:31:13,599 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7831906019286676, 'Total loss': 0.7831906019286676} | train loss {'Reaction outcome loss': 0.8206170412801927, 'Total loss': 0.8206170412801927}
2022-11-18 01:31:13,599 INFO:     Best model found after epoch 68 of 100.
2022-11-18 01:31:13,599 INFO:   Done with stage: TRAINING
2022-11-18 01:31:13,599 INFO:   Starting stage: EVALUATION
2022-11-18 01:31:13,717 INFO:   Done with stage: EVALUATION
2022-11-18 01:31:13,717 INFO:   Leaving out SEQ value Fold_8
2022-11-18 01:31:13,730 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:31:13,730 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:31:14,402 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:31:14,403 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:31:14,473 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:31:14,474 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:31:14,474 INFO:     No hyperparam tuning for this model
2022-11-18 01:31:14,474 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:31:14,474 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:31:14,474 INFO:     None feature selector for col prot
2022-11-18 01:31:14,475 INFO:     None feature selector for col prot
2022-11-18 01:31:14,475 INFO:     None feature selector for col prot
2022-11-18 01:31:14,475 INFO:     None feature selector for col chem
2022-11-18 01:31:14,475 INFO:     None feature selector for col chem
2022-11-18 01:31:14,475 INFO:     None feature selector for col chem
2022-11-18 01:31:14,476 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:31:14,476 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:31:14,477 INFO:     Number of params in model 168571
2022-11-18 01:31:14,480 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:31:14,480 INFO:   Starting stage: TRAINING
2022-11-18 01:31:14,538 INFO:     Val loss before train {'Reaction outcome loss': 1.033967917615717, 'Total loss': 1.033967917615717}
2022-11-18 01:31:14,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:14,539 INFO:     Epoch: 0
2022-11-18 01:31:15,354 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9111091616478834, 'Total loss': 0.9111091616478834} | train loss {'Reaction outcome loss': 0.8849513223094325, 'Total loss': 0.8849513223094325}
2022-11-18 01:31:15,354 INFO:     Found new best model at epoch 0
2022-11-18 01:31:15,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:15,355 INFO:     Epoch: 1
2022-11-18 01:31:16,185 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8859665746038611, 'Total loss': 0.8859665746038611} | train loss {'Reaction outcome loss': 0.8518166949431742, 'Total loss': 0.8518166949431742}
2022-11-18 01:31:16,185 INFO:     Found new best model at epoch 1
2022-11-18 01:31:16,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:16,186 INFO:     Epoch: 2
2022-11-18 01:31:16,970 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8718014102090489, 'Total loss': 0.8718014102090489} | train loss {'Reaction outcome loss': 0.8532583261689832, 'Total loss': 0.8532583261689832}
2022-11-18 01:31:16,970 INFO:     Found new best model at epoch 2
2022-11-18 01:31:16,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:16,971 INFO:     Epoch: 3
2022-11-18 01:31:17,807 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8521069416945631, 'Total loss': 0.8521069416945631} | train loss {'Reaction outcome loss': 0.8443461583266335, 'Total loss': 0.8443461583266335}
2022-11-18 01:31:17,807 INFO:     Found new best model at epoch 3
2022-11-18 01:31:17,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:17,809 INFO:     Epoch: 4
2022-11-18 01:31:18,617 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8549611453305591, 'Total loss': 0.8549611453305591} | train loss {'Reaction outcome loss': 0.8383487892006675, 'Total loss': 0.8383487892006675}
2022-11-18 01:31:18,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:18,618 INFO:     Epoch: 5
2022-11-18 01:31:19,465 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.9126358377662572, 'Total loss': 0.9126358377662572} | train loss {'Reaction outcome loss': 0.8363034999178302, 'Total loss': 0.8363034999178302}
2022-11-18 01:31:19,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:19,465 INFO:     Epoch: 6
2022-11-18 01:31:20,246 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8776594752615149, 'Total loss': 0.8776594752615149} | train loss {'Reaction outcome loss': 0.8320159097352335, 'Total loss': 0.8320159097352335}
2022-11-18 01:31:20,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:20,246 INFO:     Epoch: 7
2022-11-18 01:31:21,063 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8820387666875665, 'Total loss': 0.8820387666875665} | train loss {'Reaction outcome loss': 0.8330515148418565, 'Total loss': 0.8330515148418565}
2022-11-18 01:31:21,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:21,064 INFO:     Epoch: 8
2022-11-18 01:31:21,869 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8686985339630734, 'Total loss': 0.8686985339630734} | train loss {'Reaction outcome loss': 0.8310010696370755, 'Total loss': 0.8310010696370755}
2022-11-18 01:31:21,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:21,869 INFO:     Epoch: 9
2022-11-18 01:31:22,689 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8588302196426825, 'Total loss': 0.8588302196426825} | train loss {'Reaction outcome loss': 0.8308145437509783, 'Total loss': 0.8308145437509783}
2022-11-18 01:31:22,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:22,689 INFO:     Epoch: 10
2022-11-18 01:31:23,493 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8514553281393918, 'Total loss': 0.8514553281393918} | train loss {'Reaction outcome loss': 0.8312391028288872, 'Total loss': 0.8312391028288872}
2022-11-18 01:31:23,493 INFO:     Found new best model at epoch 10
2022-11-18 01:31:23,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:23,494 INFO:     Epoch: 11
2022-11-18 01:31:24,323 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8740263364531777, 'Total loss': 0.8740263364531777} | train loss {'Reaction outcome loss': 0.8273625954264595, 'Total loss': 0.8273625954264595}
2022-11-18 01:31:24,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:24,323 INFO:     Epoch: 12
2022-11-18 01:31:25,137 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8704157837412574, 'Total loss': 0.8704157837412574} | train loss {'Reaction outcome loss': 0.8300133416008565, 'Total loss': 0.8300133416008565}
2022-11-18 01:31:25,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:25,137 INFO:     Epoch: 13
2022-11-18 01:31:25,956 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.870155013420365, 'Total loss': 0.870155013420365} | train loss {'Reaction outcome loss': 0.8262483042574698, 'Total loss': 0.8262483042574698}
2022-11-18 01:31:25,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:25,956 INFO:     Epoch: 14
2022-11-18 01:31:26,783 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8710960705171932, 'Total loss': 0.8710960705171932} | train loss {'Reaction outcome loss': 0.8205450598991686, 'Total loss': 0.8205450598991686}
2022-11-18 01:31:26,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:26,784 INFO:     Epoch: 15
2022-11-18 01:31:27,586 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8755965104157274, 'Total loss': 0.8755965104157274} | train loss {'Reaction outcome loss': 0.8247167245755272, 'Total loss': 0.8247167245755272}
2022-11-18 01:31:27,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:27,586 INFO:     Epoch: 16
2022-11-18 01:31:28,414 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8430626365271482, 'Total loss': 0.8430626365271482} | train loss {'Reaction outcome loss': 0.8234397212584172, 'Total loss': 0.8234397212584172}
2022-11-18 01:31:28,414 INFO:     Found new best model at epoch 16
2022-11-18 01:31:28,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:28,415 INFO:     Epoch: 17
2022-11-18 01:31:29,219 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8493017676201734, 'Total loss': 0.8493017676201734} | train loss {'Reaction outcome loss': 0.8265253998819859, 'Total loss': 0.8265253998819859}
2022-11-18 01:31:29,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:29,219 INFO:     Epoch: 18
2022-11-18 01:31:29,988 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8544448837637901, 'Total loss': 0.8544448837637901} | train loss {'Reaction outcome loss': 0.8297778691255278, 'Total loss': 0.8297778691255278}
2022-11-18 01:31:29,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:29,989 INFO:     Epoch: 19
2022-11-18 01:31:30,797 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.9043017307465727, 'Total loss': 0.9043017307465727} | train loss {'Reaction outcome loss': 0.8246340624267056, 'Total loss': 0.8246340624267056}
2022-11-18 01:31:30,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:30,797 INFO:     Epoch: 20
2022-11-18 01:31:31,582 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8505035191774368, 'Total loss': 0.8505035191774368} | train loss {'Reaction outcome loss': 0.8247191008300551, 'Total loss': 0.8247191008300551}
2022-11-18 01:31:31,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:31,583 INFO:     Epoch: 21
2022-11-18 01:31:32,400 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8574922653761777, 'Total loss': 0.8574922653761777} | train loss {'Reaction outcome loss': 0.8222440604360834, 'Total loss': 0.8222440604360834}
2022-11-18 01:31:32,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:32,401 INFO:     Epoch: 22
2022-11-18 01:31:33,229 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8538481403480876, 'Total loss': 0.8538481403480876} | train loss {'Reaction outcome loss': 0.8206317681939371, 'Total loss': 0.8206317681939371}
2022-11-18 01:31:33,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:33,230 INFO:     Epoch: 23
2022-11-18 01:31:34,040 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8524086008017714, 'Total loss': 0.8524086008017714} | train loss {'Reaction outcome loss': 0.8267652749294235, 'Total loss': 0.8267652749294235}
2022-11-18 01:31:34,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:34,041 INFO:     Epoch: 24
2022-11-18 01:31:34,832 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8640504682605917, 'Total loss': 0.8640504682605917} | train loss {'Reaction outcome loss': 0.8181982566752741, 'Total loss': 0.8181982566752741}
2022-11-18 01:31:34,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:34,832 INFO:     Epoch: 25
2022-11-18 01:31:35,644 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8823993226343935, 'Total loss': 0.8823993226343935} | train loss {'Reaction outcome loss': 0.8188569915871466, 'Total loss': 0.8188569915871466}
2022-11-18 01:31:35,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:35,644 INFO:     Epoch: 26
2022-11-18 01:31:36,458 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8353919630700891, 'Total loss': 0.8353919630700891} | train loss {'Reaction outcome loss': 0.8220294544533375, 'Total loss': 0.8220294544533375}
2022-11-18 01:31:36,458 INFO:     Found new best model at epoch 26
2022-11-18 01:31:36,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:36,459 INFO:     Epoch: 27
2022-11-18 01:31:37,287 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8486978919668631, 'Total loss': 0.8486978919668631} | train loss {'Reaction outcome loss': 0.8229629100570756, 'Total loss': 0.8229629100570756}
2022-11-18 01:31:37,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:37,287 INFO:     Epoch: 28
2022-11-18 01:31:38,102 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8517875088886782, 'Total loss': 0.8517875088886782} | train loss {'Reaction outcome loss': 0.8196411523367128, 'Total loss': 0.8196411523367128}
2022-11-18 01:31:38,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:38,102 INFO:     Epoch: 29
2022-11-18 01:31:38,930 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8545950908552516, 'Total loss': 0.8545950908552516} | train loss {'Reaction outcome loss': 0.8268782729583402, 'Total loss': 0.8268782729583402}
2022-11-18 01:31:38,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:38,931 INFO:     Epoch: 30
2022-11-18 01:31:39,742 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.908066367561167, 'Total loss': 0.908066367561167} | train loss {'Reaction outcome loss': 0.8162127446022726, 'Total loss': 0.8162127446022726}
2022-11-18 01:31:39,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:39,742 INFO:     Epoch: 31
2022-11-18 01:31:40,548 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.862542868337848, 'Total loss': 0.862542868337848} | train loss {'Reaction outcome loss': 0.8225554397269603, 'Total loss': 0.8225554397269603}
2022-11-18 01:31:40,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:40,549 INFO:     Epoch: 32
2022-11-18 01:31:41,377 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8417508358305151, 'Total loss': 0.8417508358305151} | train loss {'Reaction outcome loss': 0.820114548768728, 'Total loss': 0.820114548768728}
2022-11-18 01:31:41,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:41,378 INFO:     Epoch: 33
2022-11-18 01:31:42,179 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8631161871281537, 'Total loss': 0.8631161871281537} | train loss {'Reaction outcome loss': 0.8182682467083777, 'Total loss': 0.8182682467083777}
2022-11-18 01:31:42,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:42,179 INFO:     Epoch: 34
2022-11-18 01:31:42,990 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8326741619543596, 'Total loss': 0.8326741619543596} | train loss {'Reaction outcome loss': 0.8216067599433083, 'Total loss': 0.8216067599433083}
2022-11-18 01:31:42,991 INFO:     Found new best model at epoch 34
2022-11-18 01:31:42,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:42,991 INFO:     Epoch: 35
2022-11-18 01:31:43,812 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.856629683890126, 'Total loss': 0.856629683890126} | train loss {'Reaction outcome loss': 0.8191387044085611, 'Total loss': 0.8191387044085611}
2022-11-18 01:31:43,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:43,812 INFO:     Epoch: 36
2022-11-18 01:31:44,669 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.868276990272782, 'Total loss': 0.868276990272782} | train loss {'Reaction outcome loss': 0.8193663303409854, 'Total loss': 0.8193663303409854}
2022-11-18 01:31:44,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:44,669 INFO:     Epoch: 37
2022-11-18 01:31:45,478 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8487995382059704, 'Total loss': 0.8487995382059704} | train loss {'Reaction outcome loss': 0.8195155801311615, 'Total loss': 0.8195155801311615}
2022-11-18 01:31:45,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:45,479 INFO:     Epoch: 38
2022-11-18 01:31:46,256 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8580757223746993, 'Total loss': 0.8580757223746993} | train loss {'Reaction outcome loss': 0.8149543336081889, 'Total loss': 0.8149543336081889}
2022-11-18 01:31:46,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:46,256 INFO:     Epoch: 39
2022-11-18 01:31:47,073 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8631934543902223, 'Total loss': 0.8631934543902223} | train loss {'Reaction outcome loss': 0.8169574932225289, 'Total loss': 0.8169574932225289}
2022-11-18 01:31:47,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:47,073 INFO:     Epoch: 40
2022-11-18 01:31:47,871 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8656398857181723, 'Total loss': 0.8656398857181723} | train loss {'Reaction outcome loss': 0.8171541742499797, 'Total loss': 0.8171541742499797}
2022-11-18 01:31:47,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:47,871 INFO:     Epoch: 41
2022-11-18 01:31:48,678 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8474729318510402, 'Total loss': 0.8474729318510402} | train loss {'Reaction outcome loss': 0.8202584032570163, 'Total loss': 0.8202584032570163}
2022-11-18 01:31:48,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:48,678 INFO:     Epoch: 42
2022-11-18 01:31:49,515 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8644621223211288, 'Total loss': 0.8644621223211288} | train loss {'Reaction outcome loss': 0.8153512182254945, 'Total loss': 0.8153512182254945}
2022-11-18 01:31:49,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:49,515 INFO:     Epoch: 43
2022-11-18 01:31:50,310 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8540388481183485, 'Total loss': 0.8540388481183485} | train loss {'Reaction outcome loss': 0.8189093069203438, 'Total loss': 0.8189093069203438}
2022-11-18 01:31:50,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:50,310 INFO:     Epoch: 44
2022-11-18 01:31:51,094 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8404600064862858, 'Total loss': 0.8404600064862858} | train loss {'Reaction outcome loss': 0.8194524615762695, 'Total loss': 0.8194524615762695}
2022-11-18 01:31:51,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:51,095 INFO:     Epoch: 45
2022-11-18 01:31:51,880 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8321343077854677, 'Total loss': 0.8321343077854677} | train loss {'Reaction outcome loss': 0.817721436581304, 'Total loss': 0.817721436581304}
2022-11-18 01:31:51,880 INFO:     Found new best model at epoch 45
2022-11-18 01:31:51,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:51,881 INFO:     Epoch: 46
2022-11-18 01:31:52,681 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8511047566478903, 'Total loss': 0.8511047566478903} | train loss {'Reaction outcome loss': 0.8195819056803181, 'Total loss': 0.8195819056803181}
2022-11-18 01:31:52,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:52,681 INFO:     Epoch: 47
2022-11-18 01:31:53,513 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8373484184796159, 'Total loss': 0.8373484184796159} | train loss {'Reaction outcome loss': 0.8202648630305645, 'Total loss': 0.8202648630305645}
2022-11-18 01:31:53,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:53,513 INFO:     Epoch: 48
2022-11-18 01:31:54,323 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8596211522817612, 'Total loss': 0.8596211522817612} | train loss {'Reaction outcome loss': 0.8237924522930576, 'Total loss': 0.8237924522930576}
2022-11-18 01:31:54,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:54,324 INFO:     Epoch: 49
2022-11-18 01:31:55,122 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8703541972420432, 'Total loss': 0.8703541972420432} | train loss {'Reaction outcome loss': 0.8132860093347488, 'Total loss': 0.8132860093347488}
2022-11-18 01:31:55,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:55,122 INFO:     Epoch: 50
2022-11-18 01:31:55,955 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8569351068951867, 'Total loss': 0.8569351068951867} | train loss {'Reaction outcome loss': 0.8184337317943573, 'Total loss': 0.8184337317943573}
2022-11-18 01:31:55,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:55,955 INFO:     Epoch: 51
2022-11-18 01:31:56,817 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8448665379123255, 'Total loss': 0.8448665379123255} | train loss {'Reaction outcome loss': 0.8189812186023882, 'Total loss': 0.8189812186023882}
2022-11-18 01:31:56,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:56,817 INFO:     Epoch: 52
2022-11-18 01:31:57,687 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.850653278556737, 'Total loss': 0.850653278556737} | train loss {'Reaction outcome loss': 0.8246617904834209, 'Total loss': 0.8246617904834209}
2022-11-18 01:31:57,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:57,688 INFO:     Epoch: 53
2022-11-18 01:31:58,502 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8388523865829814, 'Total loss': 0.8388523865829814} | train loss {'Reaction outcome loss': 0.8201489116876356, 'Total loss': 0.8201489116876356}
2022-11-18 01:31:58,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:58,503 INFO:     Epoch: 54
2022-11-18 01:31:59,266 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.839862269434062, 'Total loss': 0.839862269434062} | train loss {'Reaction outcome loss': 0.8149880055458315, 'Total loss': 0.8149880055458315}
2022-11-18 01:31:59,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:31:59,267 INFO:     Epoch: 55
2022-11-18 01:32:00,121 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.837882440875877, 'Total loss': 0.837882440875877} | train loss {'Reaction outcome loss': 0.8172145345278324, 'Total loss': 0.8172145345278324}
2022-11-18 01:32:00,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:00,121 INFO:     Epoch: 56
2022-11-18 01:32:00,956 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8454209931872108, 'Total loss': 0.8454209931872108} | train loss {'Reaction outcome loss': 0.8182193665735183, 'Total loss': 0.8182193665735183}
2022-11-18 01:32:00,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:00,957 INFO:     Epoch: 57
2022-11-18 01:32:01,777 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8522990196943283, 'Total loss': 0.8522990196943283} | train loss {'Reaction outcome loss': 0.8169011253743402, 'Total loss': 0.8169011253743402}
2022-11-18 01:32:01,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:01,777 INFO:     Epoch: 58
2022-11-18 01:32:02,580 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8647745393893935, 'Total loss': 0.8647745393893935} | train loss {'Reaction outcome loss': 0.8172641233090432, 'Total loss': 0.8172641233090432}
2022-11-18 01:32:02,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:02,580 INFO:     Epoch: 59
2022-11-18 01:32:03,418 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8541579625823281, 'Total loss': 0.8541579625823281} | train loss {'Reaction outcome loss': 0.8197133922048153, 'Total loss': 0.8197133922048153}
2022-11-18 01:32:03,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:03,418 INFO:     Epoch: 60
2022-11-18 01:32:04,251 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8322785781188444, 'Total loss': 0.8322785781188444} | train loss {'Reaction outcome loss': 0.8182434387985738, 'Total loss': 0.8182434387985738}
2022-11-18 01:32:04,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:04,251 INFO:     Epoch: 61
2022-11-18 01:32:05,060 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8477846113118258, 'Total loss': 0.8477846113118258} | train loss {'Reaction outcome loss': 0.8182274499727834, 'Total loss': 0.8182274499727834}
2022-11-18 01:32:05,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:05,060 INFO:     Epoch: 62
2022-11-18 01:32:05,848 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8416929746215994, 'Total loss': 0.8416929746215994} | train loss {'Reaction outcome loss': 0.8216228810769897, 'Total loss': 0.8216228810769897}
2022-11-18 01:32:05,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:05,849 INFO:     Epoch: 63
2022-11-18 01:32:06,617 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8434974219311367, 'Total loss': 0.8434974219311367} | train loss {'Reaction outcome loss': 0.8156019618674633, 'Total loss': 0.8156019618674633}
2022-11-18 01:32:06,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:06,617 INFO:     Epoch: 64
2022-11-18 01:32:07,399 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8276585482738235, 'Total loss': 0.8276585482738235} | train loss {'Reaction outcome loss': 0.8131758404835578, 'Total loss': 0.8131758404835578}
2022-11-18 01:32:07,399 INFO:     Found new best model at epoch 64
2022-11-18 01:32:07,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:07,400 INFO:     Epoch: 65
2022-11-18 01:32:08,200 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8421853740106929, 'Total loss': 0.8421853740106929} | train loss {'Reaction outcome loss': 0.8185605672338316, 'Total loss': 0.8185605672338316}
2022-11-18 01:32:08,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:08,201 INFO:     Epoch: 66
2022-11-18 01:32:08,994 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8695860748941248, 'Total loss': 0.8695860748941248} | train loss {'Reaction outcome loss': 0.8217774011915729, 'Total loss': 0.8217774011915729}
2022-11-18 01:32:08,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:08,994 INFO:     Epoch: 67
2022-11-18 01:32:09,779 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.848917200484059, 'Total loss': 0.848917200484059} | train loss {'Reaction outcome loss': 0.8184838025800644, 'Total loss': 0.8184838025800644}
2022-11-18 01:32:09,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:09,781 INFO:     Epoch: 68
2022-11-18 01:32:10,558 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8382973630319942, 'Total loss': 0.8382973630319942} | train loss {'Reaction outcome loss': 0.8212744650100509, 'Total loss': 0.8212744650100509}
2022-11-18 01:32:10,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:10,558 INFO:     Epoch: 69
2022-11-18 01:32:11,332 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8576427115635439, 'Total loss': 0.8576427115635439} | train loss {'Reaction outcome loss': 0.8209330016566861, 'Total loss': 0.8209330016566861}
2022-11-18 01:32:11,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:11,332 INFO:     Epoch: 70
2022-11-18 01:32:12,110 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8354624035683546, 'Total loss': 0.8354624035683546} | train loss {'Reaction outcome loss': 0.8179982912636572, 'Total loss': 0.8179982912636572}
2022-11-18 01:32:12,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:12,110 INFO:     Epoch: 71
2022-11-18 01:32:12,891 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8428595892407678, 'Total loss': 0.8428595892407678} | train loss {'Reaction outcome loss': 0.8177789761534622, 'Total loss': 0.8177789761534622}
2022-11-18 01:32:12,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:12,892 INFO:     Epoch: 72
2022-11-18 01:32:13,666 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8508291244506836, 'Total loss': 0.8508291244506836} | train loss {'Reaction outcome loss': 0.8189497009640739, 'Total loss': 0.8189497009640739}
2022-11-18 01:32:13,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:13,667 INFO:     Epoch: 73
2022-11-18 01:32:14,447 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8553703684698452, 'Total loss': 0.8553703684698452} | train loss {'Reaction outcome loss': 0.8115731548638113, 'Total loss': 0.8115731548638113}
2022-11-18 01:32:14,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:14,447 INFO:     Epoch: 74
2022-11-18 01:32:15,220 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8566078882325779, 'Total loss': 0.8566078882325779} | train loss {'Reaction outcome loss': 0.8151065381544251, 'Total loss': 0.8151065381544251}
2022-11-18 01:32:15,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:15,220 INFO:     Epoch: 75
2022-11-18 01:32:15,994 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8464950878511776, 'Total loss': 0.8464950878511776} | train loss {'Reaction outcome loss': 0.8167168228856979, 'Total loss': 0.8167168228856979}
2022-11-18 01:32:15,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:15,995 INFO:     Epoch: 76
2022-11-18 01:32:16,782 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8467830182476477, 'Total loss': 0.8467830182476477} | train loss {'Reaction outcome loss': 0.8186545283082993, 'Total loss': 0.8186545283082993}
2022-11-18 01:32:16,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:16,782 INFO:     Epoch: 77
2022-11-18 01:32:17,600 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8495086783712561, 'Total loss': 0.8495086783712561} | train loss {'Reaction outcome loss': 0.8215165572060693, 'Total loss': 0.8215165572060693}
2022-11-18 01:32:17,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:17,600 INFO:     Epoch: 78
2022-11-18 01:32:18,402 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8562917052344843, 'Total loss': 0.8562917052344843} | train loss {'Reaction outcome loss': 0.8195719691293855, 'Total loss': 0.8195719691293855}
2022-11-18 01:32:18,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:18,402 INFO:     Epoch: 79
2022-11-18 01:32:19,159 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8750724751840938, 'Total loss': 0.8750724751840938} | train loss {'Reaction outcome loss': 0.8147305228537128, 'Total loss': 0.8147305228537128}
2022-11-18 01:32:19,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:19,159 INFO:     Epoch: 80
2022-11-18 01:32:19,954 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8395659855820916, 'Total loss': 0.8395659855820916} | train loss {'Reaction outcome loss': 0.8183080281221098, 'Total loss': 0.8183080281221098}
2022-11-18 01:32:19,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:19,954 INFO:     Epoch: 81
2022-11-18 01:32:20,714 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8555994406342506, 'Total loss': 0.8555994406342506} | train loss {'Reaction outcome loss': 0.8155717167162126, 'Total loss': 0.8155717167162126}
2022-11-18 01:32:20,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:20,714 INFO:     Epoch: 82
2022-11-18 01:32:21,494 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8334590548818762, 'Total loss': 0.8334590548818762} | train loss {'Reaction outcome loss': 0.8150109061070027, 'Total loss': 0.8150109061070027}
2022-11-18 01:32:21,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:21,494 INFO:     Epoch: 83
2022-11-18 01:32:22,278 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8303060965104536, 'Total loss': 0.8303060965104536} | train loss {'Reaction outcome loss': 0.8158619012082776, 'Total loss': 0.8158619012082776}
2022-11-18 01:32:22,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:22,278 INFO:     Epoch: 84
2022-11-18 01:32:23,129 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8406847356395288, 'Total loss': 0.8406847356395288} | train loss {'Reaction outcome loss': 0.816297902815765, 'Total loss': 0.816297902815765}
2022-11-18 01:32:23,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:23,129 INFO:     Epoch: 85
2022-11-18 01:32:23,929 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8512181748043407, 'Total loss': 0.8512181748043407} | train loss {'Reaction outcome loss': 0.8161830075325505, 'Total loss': 0.8161830075325505}
2022-11-18 01:32:23,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:23,929 INFO:     Epoch: 86
2022-11-18 01:32:24,738 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8751556074077432, 'Total loss': 0.8751556074077432} | train loss {'Reaction outcome loss': 0.8172047926533607, 'Total loss': 0.8172047926533607}
2022-11-18 01:32:24,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:24,739 INFO:     Epoch: 87
2022-11-18 01:32:25,553 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8522587675939907, 'Total loss': 0.8522587675939907} | train loss {'Reaction outcome loss': 0.8156622308156183, 'Total loss': 0.8156622308156183}
2022-11-18 01:32:25,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:25,553 INFO:     Epoch: 88
2022-11-18 01:32:26,335 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8452354845675555, 'Total loss': 0.8452354845675555} | train loss {'Reaction outcome loss': 0.8158252865316407, 'Total loss': 0.8158252865316407}
2022-11-18 01:32:26,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:26,335 INFO:     Epoch: 89
2022-11-18 01:32:27,121 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8335123983296481, 'Total loss': 0.8335123983296481} | train loss {'Reaction outcome loss': 0.8244340815130742, 'Total loss': 0.8244340815130742}
2022-11-18 01:32:27,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:27,121 INFO:     Epoch: 90
2022-11-18 01:32:27,897 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8478996713053096, 'Total loss': 0.8478996713053096} | train loss {'Reaction outcome loss': 0.8127518115985778, 'Total loss': 0.8127518115985778}
2022-11-18 01:32:27,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:27,897 INFO:     Epoch: 91
2022-11-18 01:32:28,682 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8504158420996233, 'Total loss': 0.8504158420996233} | train loss {'Reaction outcome loss': 0.8146167808482724, 'Total loss': 0.8146167808482724}
2022-11-18 01:32:28,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:28,683 INFO:     Epoch: 92
2022-11-18 01:32:29,471 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8505200838500803, 'Total loss': 0.8505200838500803} | train loss {'Reaction outcome loss': 0.8170977629000141, 'Total loss': 0.8170977629000141}
2022-11-18 01:32:29,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:29,472 INFO:     Epoch: 93
2022-11-18 01:32:30,278 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8631500364704565, 'Total loss': 0.8631500364704565} | train loss {'Reaction outcome loss': 0.8157413906507915, 'Total loss': 0.8157413906507915}
2022-11-18 01:32:30,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:30,278 INFO:     Epoch: 94
2022-11-18 01:32:31,077 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8660552163015712, 'Total loss': 0.8660552163015712} | train loss {'Reaction outcome loss': 0.815920011771302, 'Total loss': 0.815920011771302}
2022-11-18 01:32:31,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:31,078 INFO:     Epoch: 95
2022-11-18 01:32:31,920 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8359297690066424, 'Total loss': 0.8359297690066424} | train loss {'Reaction outcome loss': 0.818070819661502, 'Total loss': 0.818070819661502}
2022-11-18 01:32:31,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:31,921 INFO:     Epoch: 96
2022-11-18 01:32:32,729 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8342521028085188, 'Total loss': 0.8342521028085188} | train loss {'Reaction outcome loss': 0.816364289411614, 'Total loss': 0.816364289411614}
2022-11-18 01:32:32,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:32,730 INFO:     Epoch: 97
2022-11-18 01:32:33,522 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8525718836621805, 'Total loss': 0.8525718836621805} | train loss {'Reaction outcome loss': 0.8149677374430241, 'Total loss': 0.8149677374430241}
2022-11-18 01:32:33,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:33,522 INFO:     Epoch: 98
2022-11-18 01:32:34,292 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8462789966301485, 'Total loss': 0.8462789966301485} | train loss {'Reaction outcome loss': 0.817667494137441, 'Total loss': 0.817667494137441}
2022-11-18 01:32:34,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:34,292 INFO:     Epoch: 99
2022-11-18 01:32:35,148 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8367386182600801, 'Total loss': 0.8367386182600801} | train loss {'Reaction outcome loss': 0.8116824510357072, 'Total loss': 0.8116824510357072}
2022-11-18 01:32:35,148 INFO:     Best model found after epoch 65 of 100.
2022-11-18 01:32:35,148 INFO:   Done with stage: TRAINING
2022-11-18 01:32:35,148 INFO:   Starting stage: EVALUATION
2022-11-18 01:32:35,266 INFO:   Done with stage: EVALUATION
2022-11-18 01:32:35,266 INFO:   Leaving out SEQ value Fold_9
2022-11-18 01:32:35,279 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:32:35,279 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:32:35,956 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:32:35,956 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:32:36,027 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:32:36,028 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:32:36,028 INFO:     No hyperparam tuning for this model
2022-11-18 01:32:36,028 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:32:36,028 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:32:36,029 INFO:     None feature selector for col prot
2022-11-18 01:32:36,029 INFO:     None feature selector for col prot
2022-11-18 01:32:36,029 INFO:     None feature selector for col prot
2022-11-18 01:32:36,029 INFO:     None feature selector for col chem
2022-11-18 01:32:36,030 INFO:     None feature selector for col chem
2022-11-18 01:32:36,030 INFO:     None feature selector for col chem
2022-11-18 01:32:36,030 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:32:36,030 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:32:36,031 INFO:     Number of params in model 168571
2022-11-18 01:32:36,035 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:32:36,035 INFO:   Starting stage: TRAINING
2022-11-18 01:32:36,093 INFO:     Val loss before train {'Reaction outcome loss': 0.9938375448638742, 'Total loss': 0.9938375448638742}
2022-11-18 01:32:36,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:36,093 INFO:     Epoch: 0
2022-11-18 01:32:36,874 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8212036314335737, 'Total loss': 0.8212036314335737} | train loss {'Reaction outcome loss': 0.8895999497247611, 'Total loss': 0.8895999497247611}
2022-11-18 01:32:36,874 INFO:     Found new best model at epoch 0
2022-11-18 01:32:36,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:36,874 INFO:     Epoch: 1
2022-11-18 01:32:37,642 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8221595124764876, 'Total loss': 0.8221595124764876} | train loss {'Reaction outcome loss': 0.8630299738302887, 'Total loss': 0.8630299738302887}
2022-11-18 01:32:37,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:37,642 INFO:     Epoch: 2
2022-11-18 01:32:38,414 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.801335794004527, 'Total loss': 0.801335794004527} | train loss {'Reaction outcome loss': 0.8517530561549219, 'Total loss': 0.8517530561549219}
2022-11-18 01:32:38,414 INFO:     Found new best model at epoch 2
2022-11-18 01:32:38,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:38,415 INFO:     Epoch: 3
2022-11-18 01:32:39,220 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8284387703646313, 'Total loss': 0.8284387703646313} | train loss {'Reaction outcome loss': 0.8490164323223506, 'Total loss': 0.8490164323223506}
2022-11-18 01:32:39,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:39,220 INFO:     Epoch: 4
2022-11-18 01:32:40,094 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8048910437659784, 'Total loss': 0.8048910437659784} | train loss {'Reaction outcome loss': 0.8418477791764958, 'Total loss': 0.8418477791764958}
2022-11-18 01:32:40,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:40,095 INFO:     Epoch: 5
2022-11-18 01:32:40,878 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7906696091998707, 'Total loss': 0.7906696091998707} | train loss {'Reaction outcome loss': 0.8468350854962461, 'Total loss': 0.8468350854962461}
2022-11-18 01:32:40,880 INFO:     Found new best model at epoch 5
2022-11-18 01:32:40,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:40,881 INFO:     Epoch: 6
2022-11-18 01:32:41,662 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.801969058134339, 'Total loss': 0.801969058134339} | train loss {'Reaction outcome loss': 0.8319543472185791, 'Total loss': 0.8319543472185791}
2022-11-18 01:32:41,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:41,663 INFO:     Epoch: 7
2022-11-18 01:32:42,440 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8187460885806517, 'Total loss': 0.8187460885806517} | train loss {'Reaction outcome loss': 0.8358024176557054, 'Total loss': 0.8358024176557054}
2022-11-18 01:32:42,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:42,441 INFO:     Epoch: 8
2022-11-18 01:32:43,225 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8190659907731143, 'Total loss': 0.8190659907731143} | train loss {'Reaction outcome loss': 0.8386799218924904, 'Total loss': 0.8386799218924904}
2022-11-18 01:32:43,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:43,226 INFO:     Epoch: 9
2022-11-18 01:32:44,028 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8099303374236281, 'Total loss': 0.8099303374236281} | train loss {'Reaction outcome loss': 0.8363575959495204, 'Total loss': 0.8363575959495204}
2022-11-18 01:32:44,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:44,028 INFO:     Epoch: 10
2022-11-18 01:32:44,856 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8113246031782844, 'Total loss': 0.8113246031782844} | train loss {'Reaction outcome loss': 0.8352259391473855, 'Total loss': 0.8352259391473855}
2022-11-18 01:32:44,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:44,856 INFO:     Epoch: 11
2022-11-18 01:32:45,655 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7929451194676486, 'Total loss': 0.7929451194676486} | train loss {'Reaction outcome loss': 0.8379505025713068, 'Total loss': 0.8379505025713068}
2022-11-18 01:32:45,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:45,655 INFO:     Epoch: 12
2022-11-18 01:32:46,458 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7901566123420541, 'Total loss': 0.7901566123420541} | train loss {'Reaction outcome loss': 0.8260806834528803, 'Total loss': 0.8260806834528803}
2022-11-18 01:32:46,459 INFO:     Found new best model at epoch 12
2022-11-18 01:32:46,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:46,459 INFO:     Epoch: 13
2022-11-18 01:32:47,258 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7964795191179622, 'Total loss': 0.7964795191179622} | train loss {'Reaction outcome loss': 0.8371431258043297, 'Total loss': 0.8371431258043297}
2022-11-18 01:32:47,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:47,259 INFO:     Epoch: 14
2022-11-18 01:32:48,115 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7838744080879472, 'Total loss': 0.7838744080879472} | train loss {'Reaction outcome loss': 0.8309228209107511, 'Total loss': 0.8309228209107511}
2022-11-18 01:32:48,115 INFO:     Found new best model at epoch 14
2022-11-18 01:32:48,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:48,116 INFO:     Epoch: 15
2022-11-18 01:32:48,904 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.824692195112055, 'Total loss': 0.824692195112055} | train loss {'Reaction outcome loss': 0.8325946581991095, 'Total loss': 0.8325946581991095}
2022-11-18 01:32:48,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:48,904 INFO:     Epoch: 16
2022-11-18 01:32:49,712 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7846950577063994, 'Total loss': 0.7846950577063994} | train loss {'Reaction outcome loss': 0.8304813048134931, 'Total loss': 0.8304813048134931}
2022-11-18 01:32:49,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:49,713 INFO:     Epoch: 17
2022-11-18 01:32:50,502 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8007257228547876, 'Total loss': 0.8007257228547876} | train loss {'Reaction outcome loss': 0.820039385846752, 'Total loss': 0.820039385846752}
2022-11-18 01:32:50,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:50,503 INFO:     Epoch: 18
2022-11-18 01:32:51,297 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8084577694535255, 'Total loss': 0.8084577694535255} | train loss {'Reaction outcome loss': 0.8260128236251322, 'Total loss': 0.8260128236251322}
2022-11-18 01:32:51,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:51,297 INFO:     Epoch: 19
2022-11-18 01:32:52,105 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7861745540391315, 'Total loss': 0.7861745540391315} | train loss {'Reaction outcome loss': 0.8229990001873448, 'Total loss': 0.8229990001873448}
2022-11-18 01:32:52,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:52,105 INFO:     Epoch: 20
2022-11-18 01:32:52,926 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8032152808525346, 'Total loss': 0.8032152808525346} | train loss {'Reaction outcome loss': 0.8240556117252782, 'Total loss': 0.8240556117252782}
2022-11-18 01:32:52,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:52,926 INFO:     Epoch: 21
2022-11-18 01:32:53,746 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8033987202427604, 'Total loss': 0.8033987202427604} | train loss {'Reaction outcome loss': 0.8195523480896042, 'Total loss': 0.8195523480896042}
2022-11-18 01:32:53,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:53,746 INFO:     Epoch: 22
2022-11-18 01:32:54,538 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7918758202682842, 'Total loss': 0.7918758202682842} | train loss {'Reaction outcome loss': 0.8345787575853015, 'Total loss': 0.8345787575853015}
2022-11-18 01:32:54,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:54,538 INFO:     Epoch: 23
2022-11-18 01:32:55,317 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7955065654082731, 'Total loss': 0.7955065654082731} | train loss {'Reaction outcome loss': 0.8184918074714027, 'Total loss': 0.8184918074714027}
2022-11-18 01:32:55,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:55,317 INFO:     Epoch: 24
2022-11-18 01:32:56,123 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7791326452385295, 'Total loss': 0.7791326452385295} | train loss {'Reaction outcome loss': 0.8208427122729992, 'Total loss': 0.8208427122729992}
2022-11-18 01:32:56,123 INFO:     Found new best model at epoch 24
2022-11-18 01:32:56,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:56,124 INFO:     Epoch: 25
2022-11-18 01:32:56,954 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7880928245457736, 'Total loss': 0.7880928245457736} | train loss {'Reaction outcome loss': 0.8238043055119302, 'Total loss': 0.8238043055119302}
2022-11-18 01:32:56,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:56,954 INFO:     Epoch: 26
2022-11-18 01:32:57,755 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7822816371917725, 'Total loss': 0.7822816371917725} | train loss {'Reaction outcome loss': 0.8320629287827835, 'Total loss': 0.8320629287827835}
2022-11-18 01:32:57,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:57,755 INFO:     Epoch: 27
2022-11-18 01:32:58,536 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7806240293112668, 'Total loss': 0.7806240293112668} | train loss {'Reaction outcome loss': 0.8277240228435772, 'Total loss': 0.8277240228435772}
2022-11-18 01:32:58,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:58,536 INFO:     Epoch: 28
2022-11-18 01:32:59,345 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7837640006433834, 'Total loss': 0.7837640006433834} | train loss {'Reaction outcome loss': 0.8129384160524438, 'Total loss': 0.8129384160524438}
2022-11-18 01:32:59,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:32:59,346 INFO:     Epoch: 29
2022-11-18 01:33:00,143 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8006099970503286, 'Total loss': 0.8006099970503286} | train loss {'Reaction outcome loss': 0.8280501205187577, 'Total loss': 0.8280501205187577}
2022-11-18 01:33:00,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:00,143 INFO:     Epoch: 30
2022-11-18 01:33:00,940 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.784289694645188, 'Total loss': 0.784289694645188} | train loss {'Reaction outcome loss': 0.8181011494595994, 'Total loss': 0.8181011494595994}
2022-11-18 01:33:00,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:00,940 INFO:     Epoch: 31
2022-11-18 01:33:01,742 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7924399355595763, 'Total loss': 0.7924399355595763} | train loss {'Reaction outcome loss': 0.8272419813190878, 'Total loss': 0.8272419813190878}
2022-11-18 01:33:01,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:01,742 INFO:     Epoch: 32
2022-11-18 01:33:02,528 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7903946563601494, 'Total loss': 0.7903946563601494} | train loss {'Reaction outcome loss': 0.8202042067461168, 'Total loss': 0.8202042067461168}
2022-11-18 01:33:02,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:02,528 INFO:     Epoch: 33
2022-11-18 01:33:03,329 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8038980141282082, 'Total loss': 0.8038980141282082} | train loss {'Reaction outcome loss': 0.8149552766369422, 'Total loss': 0.8149552766369422}
2022-11-18 01:33:03,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:03,329 INFO:     Epoch: 34
2022-11-18 01:33:04,104 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7811716239560734, 'Total loss': 0.7811716239560734} | train loss {'Reaction outcome loss': 0.8230704028114133, 'Total loss': 0.8230704028114133}
2022-11-18 01:33:04,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:04,104 INFO:     Epoch: 35
2022-11-18 01:33:04,902 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8056083457036451, 'Total loss': 0.8056083457036451} | train loss {'Reaction outcome loss': 0.8262646513187933, 'Total loss': 0.8262646513187933}
2022-11-18 01:33:04,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:04,902 INFO:     Epoch: 36
2022-11-18 01:33:05,711 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7895266494967721, 'Total loss': 0.7895266494967721} | train loss {'Reaction outcome loss': 0.8230550049046274, 'Total loss': 0.8230550049046274}
2022-11-18 01:33:05,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:05,711 INFO:     Epoch: 37
2022-11-18 01:33:06,520 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7904066727920012, 'Total loss': 0.7904066727920012} | train loss {'Reaction outcome loss': 0.814580135379243, 'Total loss': 0.814580135379243}
2022-11-18 01:33:06,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:06,521 INFO:     Epoch: 38
2022-11-18 01:33:07,339 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7794182215901938, 'Total loss': 0.7794182215901938} | train loss {'Reaction outcome loss': 0.8150788297054739, 'Total loss': 0.8150788297054739}
2022-11-18 01:33:07,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:07,339 INFO:     Epoch: 39
2022-11-18 01:33:08,142 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8100297315554186, 'Total loss': 0.8100297315554186} | train loss {'Reaction outcome loss': 0.8181725846611054, 'Total loss': 0.8181725846611054}
2022-11-18 01:33:08,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:08,143 INFO:     Epoch: 40
2022-11-18 01:33:08,927 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7756680270487611, 'Total loss': 0.7756680270487611} | train loss {'Reaction outcome loss': 0.8265722698045646, 'Total loss': 0.8265722698045646}
2022-11-18 01:33:08,927 INFO:     Found new best model at epoch 40
2022-11-18 01:33:08,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:08,928 INFO:     Epoch: 41
2022-11-18 01:33:09,777 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7918061356652867, 'Total loss': 0.7918061356652867} | train loss {'Reaction outcome loss': 0.8169479197577426, 'Total loss': 0.8169479197577426}
2022-11-18 01:33:09,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:09,777 INFO:     Epoch: 42
2022-11-18 01:33:10,563 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.781458551233465, 'Total loss': 0.781458551233465} | train loss {'Reaction outcome loss': 0.8158013414033511, 'Total loss': 0.8158013414033511}
2022-11-18 01:33:10,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:10,564 INFO:     Epoch: 43
2022-11-18 01:33:11,376 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7791336530988867, 'Total loss': 0.7791336530988867} | train loss {'Reaction outcome loss': 0.8178455691467895, 'Total loss': 0.8178455691467895}
2022-11-18 01:33:11,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:11,377 INFO:     Epoch: 44
2022-11-18 01:33:12,167 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7875944091515108, 'Total loss': 0.7875944091515108} | train loss {'Reaction outcome loss': 0.81512761236685, 'Total loss': 0.81512761236685}
2022-11-18 01:33:12,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:12,168 INFO:     Epoch: 45
2022-11-18 01:33:13,004 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.786261223256588, 'Total loss': 0.786261223256588} | train loss {'Reaction outcome loss': 0.8145582281384873, 'Total loss': 0.8145582281384873}
2022-11-18 01:33:13,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:13,005 INFO:     Epoch: 46
2022-11-18 01:33:13,828 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.777404553510926, 'Total loss': 0.777404553510926} | train loss {'Reaction outcome loss': 0.8222127342031069, 'Total loss': 0.8222127342031069}
2022-11-18 01:33:13,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:13,828 INFO:     Epoch: 47
2022-11-18 01:33:14,673 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7901711870323528, 'Total loss': 0.7901711870323528} | train loss {'Reaction outcome loss': 0.8227710678027227, 'Total loss': 0.8227710678027227}
2022-11-18 01:33:14,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:14,673 INFO:     Epoch: 48
2022-11-18 01:33:15,469 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7858870828693564, 'Total loss': 0.7858870828693564} | train loss {'Reaction outcome loss': 0.815522487286614, 'Total loss': 0.815522487286614}
2022-11-18 01:33:15,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:15,469 INFO:     Epoch: 49
2022-11-18 01:33:16,307 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7915890487757596, 'Total loss': 0.7915890487757596} | train loss {'Reaction outcome loss': 0.8226825645578052, 'Total loss': 0.8226825645578052}
2022-11-18 01:33:16,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:16,307 INFO:     Epoch: 50
2022-11-18 01:33:17,123 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7675253369591453, 'Total loss': 0.7675253369591453} | train loss {'Reaction outcome loss': 0.8340216058227214, 'Total loss': 0.8340216058227214}
2022-11-18 01:33:17,123 INFO:     Found new best model at epoch 50
2022-11-18 01:33:17,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:17,124 INFO:     Epoch: 51
2022-11-18 01:33:17,922 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8012792081995443, 'Total loss': 0.8012792081995443} | train loss {'Reaction outcome loss': 0.815768111210603, 'Total loss': 0.815768111210603}
2022-11-18 01:33:17,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:17,922 INFO:     Epoch: 52
2022-11-18 01:33:18,703 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7910251305861906, 'Total loss': 0.7910251305861906} | train loss {'Reaction outcome loss': 0.8254349071245927, 'Total loss': 0.8254349071245927}
2022-11-18 01:33:18,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:18,704 INFO:     Epoch: 53
2022-11-18 01:33:19,494 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7815136069601233, 'Total loss': 0.7815136069601233} | train loss {'Reaction outcome loss': 0.8193122072499773, 'Total loss': 0.8193122072499773}
2022-11-18 01:33:19,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:19,494 INFO:     Epoch: 54
2022-11-18 01:33:20,307 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7818614623763345, 'Total loss': 0.7818614623763345} | train loss {'Reaction outcome loss': 0.8137479755077285, 'Total loss': 0.8137479755077285}
2022-11-18 01:33:20,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:20,307 INFO:     Epoch: 55
2022-11-18 01:33:21,128 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7996000342748382, 'Total loss': 0.7996000342748382} | train loss {'Reaction outcome loss': 0.8188880007517966, 'Total loss': 0.8188880007517966}
2022-11-18 01:33:21,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:21,128 INFO:     Epoch: 56
2022-11-18 01:33:21,929 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7992653724822131, 'Total loss': 0.7992653724822131} | train loss {'Reaction outcome loss': 0.8108589527939978, 'Total loss': 0.8108589527939978}
2022-11-18 01:33:21,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:21,929 INFO:     Epoch: 57
2022-11-18 01:33:22,717 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.788177261298353, 'Total loss': 0.788177261298353} | train loss {'Reaction outcome loss': 0.816386131863845, 'Total loss': 0.816386131863845}
2022-11-18 01:33:22,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:22,718 INFO:     Epoch: 58
2022-11-18 01:33:23,506 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7866791479966857, 'Total loss': 0.7866791479966857} | train loss {'Reaction outcome loss': 0.8212592207227158, 'Total loss': 0.8212592207227158}
2022-11-18 01:33:23,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:23,506 INFO:     Epoch: 59
2022-11-18 01:33:24,340 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7800555622035806, 'Total loss': 0.7800555622035806} | train loss {'Reaction outcome loss': 0.8088576741788068, 'Total loss': 0.8088576741788068}
2022-11-18 01:33:24,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:24,341 INFO:     Epoch: 60
2022-11-18 01:33:25,153 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7770890519022942, 'Total loss': 0.7770890519022942} | train loss {'Reaction outcome loss': 0.806346211341108, 'Total loss': 0.806346211341108}
2022-11-18 01:33:25,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:25,153 INFO:     Epoch: 61
2022-11-18 01:33:26,022 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8071905117143284, 'Total loss': 0.8071905117143284} | train loss {'Reaction outcome loss': 0.8171426314815335, 'Total loss': 0.8171426314815335}
2022-11-18 01:33:26,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:26,023 INFO:     Epoch: 62
2022-11-18 01:33:26,843 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7754956436428156, 'Total loss': 0.7754956436428156} | train loss {'Reaction outcome loss': 0.8136833376187061, 'Total loss': 0.8136833376187061}
2022-11-18 01:33:26,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:26,843 INFO:     Epoch: 63
2022-11-18 01:33:27,640 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7822337861765515, 'Total loss': 0.7822337861765515} | train loss {'Reaction outcome loss': 0.814788404867234, 'Total loss': 0.814788404867234}
2022-11-18 01:33:27,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:27,640 INFO:     Epoch: 64
2022-11-18 01:33:28,444 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7684592022137209, 'Total loss': 0.7684592022137209} | train loss {'Reaction outcome loss': 0.8129094612260579, 'Total loss': 0.8129094612260579}
2022-11-18 01:33:28,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:28,444 INFO:     Epoch: 65
2022-11-18 01:33:29,247 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7859049263325605, 'Total loss': 0.7859049263325605} | train loss {'Reaction outcome loss': 0.8157444746885826, 'Total loss': 0.8157444746885826}
2022-11-18 01:33:29,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:29,248 INFO:     Epoch: 66
2022-11-18 01:33:30,010 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7912530546838586, 'Total loss': 0.7912530546838586} | train loss {'Reaction outcome loss': 0.8083582623345167, 'Total loss': 0.8083582623345167}
2022-11-18 01:33:30,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:30,010 INFO:     Epoch: 67
2022-11-18 01:33:30,778 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8000240806828846, 'Total loss': 0.8000240806828846} | train loss {'Reaction outcome loss': 0.8127593909680602, 'Total loss': 0.8127593909680602}
2022-11-18 01:33:30,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:30,779 INFO:     Epoch: 68
2022-11-18 01:33:31,558 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7878544459288771, 'Total loss': 0.7878544459288771} | train loss {'Reaction outcome loss': 0.8170273797775087, 'Total loss': 0.8170273797775087}
2022-11-18 01:33:31,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:31,559 INFO:     Epoch: 69
2022-11-18 01:33:32,332 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7669931839812886, 'Total loss': 0.7669931839812886} | train loss {'Reaction outcome loss': 0.8047918093349287, 'Total loss': 0.8047918093349287}
2022-11-18 01:33:32,333 INFO:     Found new best model at epoch 69
2022-11-18 01:33:32,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:32,334 INFO:     Epoch: 70
2022-11-18 01:33:33,093 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7812464426864277, 'Total loss': 0.7812464426864277} | train loss {'Reaction outcome loss': 0.8127422484791713, 'Total loss': 0.8127422484791713}
2022-11-18 01:33:33,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:33,093 INFO:     Epoch: 71
2022-11-18 01:33:33,859 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7880052951249209, 'Total loss': 0.7880052951249209} | train loss {'Reaction outcome loss': 0.8245840901546633, 'Total loss': 0.8245840901546633}
2022-11-18 01:33:33,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:33,859 INFO:     Epoch: 72
2022-11-18 01:33:34,646 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7660121971910651, 'Total loss': 0.7660121971910651} | train loss {'Reaction outcome loss': 0.8189989336830402, 'Total loss': 0.8189989336830402}
2022-11-18 01:33:34,646 INFO:     Found new best model at epoch 72
2022-11-18 01:33:34,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:34,647 INFO:     Epoch: 73
2022-11-18 01:33:35,440 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7634109949523752, 'Total loss': 0.7634109949523752} | train loss {'Reaction outcome loss': 0.8114774990902256, 'Total loss': 0.8114774990902256}
2022-11-18 01:33:35,440 INFO:     Found new best model at epoch 73
2022-11-18 01:33:35,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:35,441 INFO:     Epoch: 74
2022-11-18 01:33:36,216 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7840234176679091, 'Total loss': 0.7840234176679091} | train loss {'Reaction outcome loss': 0.8182376697961136, 'Total loss': 0.8182376697961136}
2022-11-18 01:33:36,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:36,216 INFO:     Epoch: 75
2022-11-18 01:33:36,996 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7812511399388313, 'Total loss': 0.7812511399388313} | train loss {'Reaction outcome loss': 0.8122257697678771, 'Total loss': 0.8122257697678771}
2022-11-18 01:33:36,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:36,996 INFO:     Epoch: 76
2022-11-18 01:33:37,795 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7930678027597341, 'Total loss': 0.7930678027597341} | train loss {'Reaction outcome loss': 0.8130889246579607, 'Total loss': 0.8130889246579607}
2022-11-18 01:33:37,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:37,795 INFO:     Epoch: 77
2022-11-18 01:33:38,588 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7893604561686516, 'Total loss': 0.7893604561686516} | train loss {'Reaction outcome loss': 0.8082262197969413, 'Total loss': 0.8082262197969413}
2022-11-18 01:33:38,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:38,589 INFO:     Epoch: 78
2022-11-18 01:33:39,350 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7845517098903656, 'Total loss': 0.7845517098903656} | train loss {'Reaction outcome loss': 0.8116702408443096, 'Total loss': 0.8116702408443096}
2022-11-18 01:33:39,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:39,350 INFO:     Epoch: 79
2022-11-18 01:33:40,128 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7902818620204926, 'Total loss': 0.7902818620204926} | train loss {'Reaction outcome loss': 0.8127865261635799, 'Total loss': 0.8127865261635799}
2022-11-18 01:33:40,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:40,128 INFO:     Epoch: 80
2022-11-18 01:33:40,930 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.775814837352796, 'Total loss': 0.775814837352796} | train loss {'Reaction outcome loss': 0.8182847591546866, 'Total loss': 0.8182847591546866}
2022-11-18 01:33:40,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:40,930 INFO:     Epoch: 81
2022-11-18 01:33:41,716 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7722794515165415, 'Total loss': 0.7722794515165415} | train loss {'Reaction outcome loss': 0.8120966347364279, 'Total loss': 0.8120966347364279}
2022-11-18 01:33:41,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:41,716 INFO:     Epoch: 82
2022-11-18 01:33:42,496 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7985556681047786, 'Total loss': 0.7985556681047786} | train loss {'Reaction outcome loss': 0.8105399193702197, 'Total loss': 0.8105399193702197}
2022-11-18 01:33:42,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:42,496 INFO:     Epoch: 83
2022-11-18 01:33:43,294 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.805258533494039, 'Total loss': 0.805258533494039} | train loss {'Reaction outcome loss': 0.8094729105470634, 'Total loss': 0.8094729105470634}
2022-11-18 01:33:43,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:43,295 INFO:     Epoch: 84
2022-11-18 01:33:44,077 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8156368149952455, 'Total loss': 0.8156368149952455} | train loss {'Reaction outcome loss': 0.8129181299916646, 'Total loss': 0.8129181299916646}
2022-11-18 01:33:44,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:44,077 INFO:     Epoch: 85
2022-11-18 01:33:44,852 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7724428651007739, 'Total loss': 0.7724428651007739} | train loss {'Reaction outcome loss': 0.8211207562371304, 'Total loss': 0.8211207562371304}
2022-11-18 01:33:44,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:44,853 INFO:     Epoch: 86
2022-11-18 01:33:45,632 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8051842796531591, 'Total loss': 0.8051842796531591} | train loss {'Reaction outcome loss': 0.8089979405888179, 'Total loss': 0.8089979405888179}
2022-11-18 01:33:45,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:45,632 INFO:     Epoch: 87
2022-11-18 01:33:46,421 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8066441938281059, 'Total loss': 0.8066441938281059} | train loss {'Reaction outcome loss': 0.8111683388470639, 'Total loss': 0.8111683388470639}
2022-11-18 01:33:46,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:46,421 INFO:     Epoch: 88
2022-11-18 01:33:47,232 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7751380090009082, 'Total loss': 0.7751380090009082} | train loss {'Reaction outcome loss': 0.8150612341488904, 'Total loss': 0.8150612341488904}
2022-11-18 01:33:47,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:47,232 INFO:     Epoch: 89
2022-11-18 01:33:48,027 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8049480786377733, 'Total loss': 0.8049480786377733} | train loss {'Reaction outcome loss': 0.8093865774421074, 'Total loss': 0.8093865774421074}
2022-11-18 01:33:48,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:48,027 INFO:     Epoch: 90
2022-11-18 01:33:48,844 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7955111353234812, 'Total loss': 0.7955111353234812} | train loss {'Reaction outcome loss': 0.8083521856470146, 'Total loss': 0.8083521856470146}
2022-11-18 01:33:48,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:48,844 INFO:     Epoch: 91
2022-11-18 01:33:49,692 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7779583375562321, 'Total loss': 0.7779583375562321} | train loss {'Reaction outcome loss': 0.8202306544973783, 'Total loss': 0.8202306544973783}
2022-11-18 01:33:49,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:49,693 INFO:     Epoch: 92
2022-11-18 01:33:50,487 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7901949775828556, 'Total loss': 0.7901949775828556} | train loss {'Reaction outcome loss': 0.8143454853460373, 'Total loss': 0.8143454853460373}
2022-11-18 01:33:50,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:50,487 INFO:     Epoch: 93
2022-11-18 01:33:51,271 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7983262599869207, 'Total loss': 0.7983262599869207} | train loss {'Reaction outcome loss': 0.8101309283300933, 'Total loss': 0.8101309283300933}
2022-11-18 01:33:51,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:51,271 INFO:     Epoch: 94
2022-11-18 01:33:52,113 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.779331009496342, 'Total loss': 0.779331009496342} | train loss {'Reaction outcome loss': 0.8156641876166649, 'Total loss': 0.8156641876166649}
2022-11-18 01:33:52,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:52,114 INFO:     Epoch: 95
2022-11-18 01:33:52,897 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.75755148651925, 'Total loss': 0.75755148651925} | train loss {'Reaction outcome loss': 0.8105620247149757, 'Total loss': 0.8105620247149757}
2022-11-18 01:33:52,897 INFO:     Found new best model at epoch 95
2022-11-18 01:33:52,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:52,898 INFO:     Epoch: 96
2022-11-18 01:33:53,709 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7696445042436774, 'Total loss': 0.7696445042436774} | train loss {'Reaction outcome loss': 0.8042730240656538, 'Total loss': 0.8042730240656538}
2022-11-18 01:33:53,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:53,710 INFO:     Epoch: 97
2022-11-18 01:33:54,536 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7858582098375667, 'Total loss': 0.7858582098375667} | train loss {'Reaction outcome loss': 0.8122508553599539, 'Total loss': 0.8122508553599539}
2022-11-18 01:33:54,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:54,536 INFO:     Epoch: 98
2022-11-18 01:33:55,318 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8339444493705576, 'Total loss': 0.8339444493705576} | train loss {'Reaction outcome loss': 0.8127155762452346, 'Total loss': 0.8127155762452346}
2022-11-18 01:33:55,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:33:55,318 INFO:     Epoch: 99
2022-11-18 01:33:56,126 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8083112747831778, 'Total loss': 0.8083112747831778} | train loss {'Reaction outcome loss': 0.814249287974014, 'Total loss': 0.814249287974014}
2022-11-18 01:33:56,126 INFO:     Best model found after epoch 96 of 100.
2022-11-18 01:33:56,126 INFO:   Done with stage: TRAINING
2022-11-18 01:33:56,127 INFO:   Starting stage: EVALUATION
2022-11-18 01:33:56,250 INFO:   Done with stage: EVALUATION
2022-11-18 01:33:56,250 INFO: Done with stage: RUNNING SPLITS
2022-11-18 01:33:56,250 INFO: Starting stage: COMPUTE METRICS
2022-11-18 01:33:57,459 INFO: Done with stage: COMPUTE METRICS
2022-11-18 01:33:57,459 INFO: Starting stage: EXPORT RESULTS
2022-11-18 01:33:57,477 INFO:   Final results averaged over 50 folds: 
2022-11-18 01:33:57,481 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.254702           NaN  0.344383       NaN
2022-11-18 01:33:59,213 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-18 01:33:59,220 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-18 01:33:59,222 DEBUG:   interactive is False
2022-11-18 01:33:59,222 DEBUG:   platform is linux
2022-11-18 01:33:59,222 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-18 01:33:59,405 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-18 01:33:59,408 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-18 01:33:59,886 DEBUG:   Loaded backend agg version unknown.
2022-11-18 01:33:59,889 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-18 01:33:59,890 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,890 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,890 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,890 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,890 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,890 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,891 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,892 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 01:33:59,893 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,894 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 01:33:59,895 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,895 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 01:33:59,946 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-18 01:33:59,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,946 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,947 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,948 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,949 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 01:33:59,950 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,950 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 01:33:59,959 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-18 01:33:59,959 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,959 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,959 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,959 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,960 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,961 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,962 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 01:33:59,963 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 01:33:59,963 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 01:34:00,391 INFO: Done with stage: EXPORT RESULTS
2022-11-18 01:34:00,391 INFO: Starting stage: SAVE MODEL
2022-11-18 01:34:00,459 INFO: Done with stage: SAVE MODEL
2022-11-18 01:34:00,459 INFO: Wall time for program:  4040.61 seconds
