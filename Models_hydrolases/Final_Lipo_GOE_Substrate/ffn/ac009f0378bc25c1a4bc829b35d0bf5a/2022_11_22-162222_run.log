2022-11-22 23:23:55,490 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/ac009f0378bc25c1a4bc829b35d0bf5a/2022_11_22-162222",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "cat",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-22 23:23:55,500 INFO: Starting stage: BUILD FEATURIZERS
2022-11-22 23:23:55,503 INFO:   Creating esm representation model
2022-11-22 23:23:55,504 INFO:   Done esm representation model
2022-11-22 23:23:55,504 INFO: Done with stage: BUILD FEATURIZERS
2022-11-22 23:23:55,504 INFO: Starting stage: BUILDING DATASET
2022-11-22 23:23:55,561 INFO: Done with stage: BUILDING DATASET
2022-11-22 23:23:55,561 INFO: Starting stage: FEATURIZING DATA
2022-11-22 23:23:55,561 INFO:   Featurizing proteins
2022-11-22 23:23:55,563 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-22 23:23:55,608 INFO:   Loaded feature cache of size 204
2022-11-22 23:23:55,610 INFO:   Starting to pool ESM Embeddings
2022-11-22 23:23:55,729 INFO:   Featurizing molecules
2022-11-22 23:23:56,121 INFO: Done with stage: FEATURIZING DATA
2022-11-22 23:23:56,121 INFO: Starting stage: RUNNING SPLITS
2022-11-22 23:23:56,130 INFO:   Leaving out SEQ value Fold_0
2022-11-22 23:23:56,145 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 23:23:56,145 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:23:56,832 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:23:56,832 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:23:56,900 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:23:56,901 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:23:56,901 INFO:     No hyperparam tuning for this model
2022-11-22 23:23:56,901 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:23:56,901 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:23:56,902 INFO:     None feature selector for col prot
2022-11-22 23:23:56,902 INFO:     None feature selector for col prot
2022-11-22 23:23:56,902 INFO:     None feature selector for col prot
2022-11-22 23:23:56,903 INFO:     None feature selector for col chem
2022-11-22 23:23:56,903 INFO:     None feature selector for col chem
2022-11-22 23:23:56,903 INFO:     None feature selector for col chem
2022-11-22 23:23:56,903 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:23:56,903 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:23:56,905 INFO:     Number of params in model 168571
2022-11-22 23:23:56,905 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:23:56,905 INFO:   Starting stage: TRAINING
2022-11-22 23:23:58,503 INFO:     Val loss before train {'Reaction outcome loss': 1.0277251226957453, 'Total loss': 1.0277251226957453}
2022-11-22 23:23:58,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:23:58,504 INFO:     Epoch: 0
2022-11-22 23:23:59,278 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8679935724236244, 'Total loss': 0.8679935724236244} | train loss {'Reaction outcome loss': 0.8736774114067437, 'Total loss': 0.8736774114067437}
2022-11-22 23:23:59,278 INFO:     Found new best model at epoch 0
2022-11-22 23:23:59,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:23:59,279 INFO:     Epoch: 1
2022-11-22 23:24:00,097 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.844205848006315, 'Total loss': 0.844205848006315} | train loss {'Reaction outcome loss': 0.8398793339729309, 'Total loss': 0.8398793339729309}
2022-11-22 23:24:00,097 INFO:     Found new best model at epoch 1
2022-11-22 23:24:00,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:00,098 INFO:     Epoch: 2
2022-11-22 23:24:00,874 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8645237420880517, 'Total loss': 0.8645237420880517} | train loss {'Reaction outcome loss': 0.8320116564387181, 'Total loss': 0.8320116564387181}
2022-11-22 23:24:00,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:00,875 INFO:     Epoch: 3
2022-11-22 23:24:01,687 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8447123363960621, 'Total loss': 0.8447123363960621} | train loss {'Reaction outcome loss': 0.8252040272364851, 'Total loss': 0.8252040272364851}
2022-11-22 23:24:01,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:01,687 INFO:     Epoch: 4
2022-11-22 23:24:02,538 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.831501925407454, 'Total loss': 0.831501925407454} | train loss {'Reaction outcome loss': 0.8267925473876664, 'Total loss': 0.8267925473876664}
2022-11-22 23:24:02,538 INFO:     Found new best model at epoch 4
2022-11-22 23:24:02,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:02,539 INFO:     Epoch: 5
2022-11-22 23:24:03,333 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8390702390393545, 'Total loss': 0.8390702390393545} | train loss {'Reaction outcome loss': 0.8214991803540558, 'Total loss': 0.8214991803540558}
2022-11-22 23:24:03,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:03,333 INFO:     Epoch: 6
2022-11-22 23:24:04,119 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8433689211690149, 'Total loss': 0.8433689211690149} | train loss {'Reaction outcome loss': 0.8239749887439071, 'Total loss': 0.8239749887439071}
2022-11-22 23:24:04,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:04,119 INFO:     Epoch: 7
2022-11-22 23:24:04,889 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8390500490055528, 'Total loss': 0.8390500490055528} | train loss {'Reaction outcome loss': 0.8243392710802985, 'Total loss': 0.8243392710802985}
2022-11-22 23:24:04,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:04,890 INFO:     Epoch: 8
2022-11-22 23:24:05,755 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.832591851090276, 'Total loss': 0.832591851090276} | train loss {'Reaction outcome loss': 0.8120056340684656, 'Total loss': 0.8120056340684656}
2022-11-22 23:24:05,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:05,756 INFO:     Epoch: 9
2022-11-22 23:24:06,560 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8334409303443376, 'Total loss': 0.8334409303443376} | train loss {'Reaction outcome loss': 0.8166161175878321, 'Total loss': 0.8166161175878321}
2022-11-22 23:24:06,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:06,561 INFO:     Epoch: 10
2022-11-22 23:24:07,369 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8441761995470801, 'Total loss': 0.8441761995470801} | train loss {'Reaction outcome loss': 0.811400400566273, 'Total loss': 0.811400400566273}
2022-11-22 23:24:07,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:07,369 INFO:     Epoch: 11
2022-11-22 23:24:08,158 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8320099953995195, 'Total loss': 0.8320099953995195} | train loss {'Reaction outcome loss': 0.8184764167813005, 'Total loss': 0.8184764167813005}
2022-11-22 23:24:08,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:08,158 INFO:     Epoch: 12
2022-11-22 23:24:08,940 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.850609768268674, 'Total loss': 0.850609768268674} | train loss {'Reaction outcome loss': 0.8101787827298289, 'Total loss': 0.8101787827298289}
2022-11-22 23:24:08,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:08,941 INFO:     Epoch: 13
2022-11-22 23:24:09,696 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8291825624399407, 'Total loss': 0.8291825624399407} | train loss {'Reaction outcome loss': 0.8123609088971967, 'Total loss': 0.8123609088971967}
2022-11-22 23:24:09,697 INFO:     Found new best model at epoch 13
2022-11-22 23:24:09,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:09,697 INFO:     Epoch: 14
2022-11-22 23:24:10,483 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8248666400133178, 'Total loss': 0.8248666400133178} | train loss {'Reaction outcome loss': 0.8111585467809537, 'Total loss': 0.8111585467809537}
2022-11-22 23:24:10,484 INFO:     Found new best model at epoch 14
2022-11-22 23:24:10,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:10,484 INFO:     Epoch: 15
2022-11-22 23:24:11,272 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8470872294071109, 'Total loss': 0.8470872294071109} | train loss {'Reaction outcome loss': 0.8146572623585091, 'Total loss': 0.8146572623585091}
2022-11-22 23:24:11,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:11,273 INFO:     Epoch: 16
2022-11-22 23:24:12,064 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8381475688413133, 'Total loss': 0.8381475688413133} | train loss {'Reaction outcome loss': 0.8119218978481214, 'Total loss': 0.8119218978481214}
2022-11-22 23:24:12,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:12,064 INFO:     Epoch: 17
2022-11-22 23:24:12,915 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.852090131404788, 'Total loss': 0.852090131404788} | train loss {'Reaction outcome loss': 0.8092219297026024, 'Total loss': 0.8092219297026024}
2022-11-22 23:24:12,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:12,915 INFO:     Epoch: 18
2022-11-22 23:24:13,700 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8201066657554271, 'Total loss': 0.8201066657554271} | train loss {'Reaction outcome loss': 0.8130317952056401, 'Total loss': 0.8130317952056401}
2022-11-22 23:24:13,700 INFO:     Found new best model at epoch 18
2022-11-22 23:24:13,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:13,701 INFO:     Epoch: 19
2022-11-22 23:24:14,483 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8334537037583285, 'Total loss': 0.8334537037583285} | train loss {'Reaction outcome loss': 0.8154348282784712, 'Total loss': 0.8154348282784712}
2022-11-22 23:24:14,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:14,483 INFO:     Epoch: 20
2022-11-22 23:24:15,276 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8274980783462524, 'Total loss': 0.8274980783462524} | train loss {'Reaction outcome loss': 0.8134951783252544, 'Total loss': 0.8134951783252544}
2022-11-22 23:24:15,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:15,276 INFO:     Epoch: 21
2022-11-22 23:24:16,085 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8218248833057492, 'Total loss': 0.8218248833057492} | train loss {'Reaction outcome loss': 0.8082754630290094, 'Total loss': 0.8082754630290094}
2022-11-22 23:24:16,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:16,086 INFO:     Epoch: 22
2022-11-22 23:24:16,857 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8385079433751661, 'Total loss': 0.8385079433751661} | train loss {'Reaction outcome loss': 0.8111865985833231, 'Total loss': 0.8111865985833231}
2022-11-22 23:24:16,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:16,858 INFO:     Epoch: 23
2022-11-22 23:24:17,660 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8241359480591708, 'Total loss': 0.8241359480591708} | train loss {'Reaction outcome loss': 0.8131873522137032, 'Total loss': 0.8131873522137032}
2022-11-22 23:24:17,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:17,662 INFO:     Epoch: 24
2022-11-22 23:24:18,456 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8279858564221582, 'Total loss': 0.8279858564221582} | train loss {'Reaction outcome loss': 0.8094539721725417, 'Total loss': 0.8094539721725417}
2022-11-22 23:24:18,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:18,456 INFO:     Epoch: 25
2022-11-22 23:24:19,273 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.813383245883986, 'Total loss': 0.813383245883986} | train loss {'Reaction outcome loss': 0.8138664351379286, 'Total loss': 0.8138664351379286}
2022-11-22 23:24:19,273 INFO:     Found new best model at epoch 25
2022-11-22 23:24:19,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:19,274 INFO:     Epoch: 26
2022-11-22 23:24:20,047 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8342017101687055, 'Total loss': 0.8342017101687055} | train loss {'Reaction outcome loss': 0.8124720909800686, 'Total loss': 0.8124720909800686}
2022-11-22 23:24:20,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:20,047 INFO:     Epoch: 27
2022-11-22 23:24:20,856 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8273850298205088, 'Total loss': 0.8273850298205088} | train loss {'Reaction outcome loss': 0.8069900574742771, 'Total loss': 0.8069900574742771}
2022-11-22 23:24:20,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:20,857 INFO:     Epoch: 28
2022-11-22 23:24:21,625 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.832880359056384, 'Total loss': 0.832880359056384} | train loss {'Reaction outcome loss': 0.8056765103437862, 'Total loss': 0.8056765103437862}
2022-11-22 23:24:21,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:21,625 INFO:     Epoch: 29
2022-11-22 23:24:22,413 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8484245469403822, 'Total loss': 0.8484245469403822} | train loss {'Reaction outcome loss': 0.8153497797788166, 'Total loss': 0.8153497797788166}
2022-11-22 23:24:22,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:22,414 INFO:     Epoch: 30
2022-11-22 23:24:23,190 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8219246566295624, 'Total loss': 0.8219246566295624} | train loss {'Reaction outcome loss': 0.8085738483999596, 'Total loss': 0.8085738483999596}
2022-11-22 23:24:23,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:23,190 INFO:     Epoch: 31
2022-11-22 23:24:24,001 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8341951072216034, 'Total loss': 0.8341951072216034} | train loss {'Reaction outcome loss': 0.8080928070379085, 'Total loss': 0.8080928070379085}
2022-11-22 23:24:24,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:24,002 INFO:     Epoch: 32
2022-11-22 23:24:24,750 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8173159395539483, 'Total loss': 0.8173159395539483} | train loss {'Reaction outcome loss': 0.8062702356303324, 'Total loss': 0.8062702356303324}
2022-11-22 23:24:24,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:24,751 INFO:     Epoch: 33
2022-11-22 23:24:25,585 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.821186920931173, 'Total loss': 0.821186920931173} | train loss {'Reaction outcome loss': 0.8077793476767228, 'Total loss': 0.8077793476767228}
2022-11-22 23:24:25,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:25,585 INFO:     Epoch: 34
2022-11-22 23:24:26,371 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8311534849710243, 'Total loss': 0.8311534849710243} | train loss {'Reaction outcome loss': 0.8111598750606912, 'Total loss': 0.8111598750606912}
2022-11-22 23:24:26,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:26,371 INFO:     Epoch: 35
2022-11-22 23:24:27,141 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.825183532958807, 'Total loss': 0.825183532958807} | train loss {'Reaction outcome loss': 0.8111308571256575, 'Total loss': 0.8111308571256575}
2022-11-22 23:24:27,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:27,141 INFO:     Epoch: 36
2022-11-22 23:24:27,956 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8165087034535963, 'Total loss': 0.8165087034535963} | train loss {'Reaction outcome loss': 0.8084926060477241, 'Total loss': 0.8084926060477241}
2022-11-22 23:24:27,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:27,956 INFO:     Epoch: 37
2022-11-22 23:24:28,770 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8216089890446774, 'Total loss': 0.8216089890446774} | train loss {'Reaction outcome loss': 0.8093184775016347, 'Total loss': 0.8093184775016347}
2022-11-22 23:24:28,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:28,771 INFO:     Epoch: 38
2022-11-22 23:24:29,589 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8147252860457398, 'Total loss': 0.8147252860457398} | train loss {'Reaction outcome loss': 0.8106065117677704, 'Total loss': 0.8106065117677704}
2022-11-22 23:24:29,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:29,589 INFO:     Epoch: 39
2022-11-22 23:24:30,383 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8255986453488816, 'Total loss': 0.8255986453488816} | train loss {'Reaction outcome loss': 0.8102910213294576, 'Total loss': 0.8102910213294576}
2022-11-22 23:24:30,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:30,383 INFO:     Epoch: 40
2022-11-22 23:24:31,156 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8290037609810053, 'Total loss': 0.8290037609810053} | train loss {'Reaction outcome loss': 0.8095884913059531, 'Total loss': 0.8095884913059531}
2022-11-22 23:24:31,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:31,157 INFO:     Epoch: 41
2022-11-22 23:24:31,939 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8253924860510715, 'Total loss': 0.8253924860510715} | train loss {'Reaction outcome loss': 0.806894134424749, 'Total loss': 0.806894134424749}
2022-11-22 23:24:31,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:31,941 INFO:     Epoch: 42
2022-11-22 23:24:32,758 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8220953289852586, 'Total loss': 0.8220953289852586} | train loss {'Reaction outcome loss': 0.8091820760584268, 'Total loss': 0.8091820760584268}
2022-11-22 23:24:32,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:32,758 INFO:     Epoch: 43
2022-11-22 23:24:33,548 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8222662848095561, 'Total loss': 0.8222662848095561} | train loss {'Reaction outcome loss': 0.8045297257724355, 'Total loss': 0.8045297257724355}
2022-11-22 23:24:33,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:33,549 INFO:     Epoch: 44
2022-11-22 23:24:34,375 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8222664809504221, 'Total loss': 0.8222664809504221} | train loss {'Reaction outcome loss': 0.8069589477582056, 'Total loss': 0.8069589477582056}
2022-11-22 23:24:34,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:34,375 INFO:     Epoch: 45
2022-11-22 23:24:35,151 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8166319353635921, 'Total loss': 0.8166319353635921} | train loss {'Reaction outcome loss': 0.809953896359342, 'Total loss': 0.809953896359342}
2022-11-22 23:24:35,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:35,152 INFO:     Epoch: 46
2022-11-22 23:24:35,927 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8322208315827125, 'Total loss': 0.8322208315827125} | train loss {'Reaction outcome loss': 0.8079232737177708, 'Total loss': 0.8079232737177708}
2022-11-22 23:24:35,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:35,927 INFO:     Epoch: 47
2022-11-22 23:24:36,744 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8353520063466804, 'Total loss': 0.8353520063466804} | train loss {'Reaction outcome loss': 0.8086445202104381, 'Total loss': 0.8086445202104381}
2022-11-22 23:24:36,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:36,744 INFO:     Epoch: 48
2022-11-22 23:24:37,605 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8316308114417764, 'Total loss': 0.8316308114417764} | train loss {'Reaction outcome loss': 0.8089961396133314, 'Total loss': 0.8089961396133314}
2022-11-22 23:24:37,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:37,606 INFO:     Epoch: 49
2022-11-22 23:24:38,462 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8235288206921068, 'Total loss': 0.8235288206921068} | train loss {'Reaction outcome loss': 0.8099690196944065, 'Total loss': 0.8099690196944065}
2022-11-22 23:24:38,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:38,463 INFO:     Epoch: 50
2022-11-22 23:24:39,307 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.840967849243519, 'Total loss': 0.840967849243519} | train loss {'Reaction outcome loss': 0.8117766057858702, 'Total loss': 0.8117766057858702}
2022-11-22 23:24:39,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:39,307 INFO:     Epoch: 51
2022-11-22 23:24:40,130 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8142696972503218, 'Total loss': 0.8142696972503218} | train loss {'Reaction outcome loss': 0.810317217692977, 'Total loss': 0.810317217692977}
2022-11-22 23:24:40,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:40,130 INFO:     Epoch: 52
2022-11-22 23:24:40,904 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8376429857209672, 'Total loss': 0.8376429857209672} | train loss {'Reaction outcome loss': 0.8096121283339672, 'Total loss': 0.8096121283339672}
2022-11-22 23:24:40,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:40,904 INFO:     Epoch: 53
2022-11-22 23:24:41,710 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8266511164432349, 'Total loss': 0.8266511164432349} | train loss {'Reaction outcome loss': 0.8114552602904742, 'Total loss': 0.8114552602904742}
2022-11-22 23:24:41,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:41,710 INFO:     Epoch: 54
2022-11-22 23:24:42,496 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8520738898321639, 'Total loss': 0.8520738898321639} | train loss {'Reaction outcome loss': 0.8037102798946568, 'Total loss': 0.8037102798946568}
2022-11-22 23:24:42,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:42,497 INFO:     Epoch: 55
2022-11-22 23:24:43,303 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8330262289490811, 'Total loss': 0.8330262289490811} | train loss {'Reaction outcome loss': 0.8130480735028376, 'Total loss': 0.8130480735028376}
2022-11-22 23:24:43,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:43,304 INFO:     Epoch: 56
2022-11-22 23:24:44,125 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8170682011648666, 'Total loss': 0.8170682011648666} | train loss {'Reaction outcome loss': 0.8059008246073958, 'Total loss': 0.8059008246073958}
2022-11-22 23:24:44,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:44,125 INFO:     Epoch: 57
2022-11-22 23:24:44,915 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8425544167673865, 'Total loss': 0.8425544167673865} | train loss {'Reaction outcome loss': 0.8086005831595326, 'Total loss': 0.8086005831595326}
2022-11-22 23:24:44,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:44,916 INFO:     Epoch: 58
2022-11-22 23:24:45,728 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8184905426446781, 'Total loss': 0.8184905426446781} | train loss {'Reaction outcome loss': 0.8111625857284812, 'Total loss': 0.8111625857284812}
2022-11-22 23:24:45,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:45,728 INFO:     Epoch: 59
2022-11-22 23:24:46,534 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8169084607168685, 'Total loss': 0.8169084607168685} | train loss {'Reaction outcome loss': 0.8065521943031765, 'Total loss': 0.8065521943031765}
2022-11-22 23:24:46,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:46,534 INFO:     Epoch: 60
2022-11-22 23:24:47,290 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8253899230513462, 'Total loss': 0.8253899230513462} | train loss {'Reaction outcome loss': 0.804191355211813, 'Total loss': 0.804191355211813}
2022-11-22 23:24:47,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:47,290 INFO:     Epoch: 61
2022-11-22 23:24:48,083 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8310956691586694, 'Total loss': 0.8310956691586694} | train loss {'Reaction outcome loss': 0.8106494614335357, 'Total loss': 0.8106494614335357}
2022-11-22 23:24:48,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:48,083 INFO:     Epoch: 62
2022-11-22 23:24:48,850 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8226350033006002, 'Total loss': 0.8226350033006002} | train loss {'Reaction outcome loss': 0.8068563023307285, 'Total loss': 0.8068563023307285}
2022-11-22 23:24:48,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:48,851 INFO:     Epoch: 63
2022-11-22 23:24:49,620 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8272289841674095, 'Total loss': 0.8272289841674095} | train loss {'Reaction outcome loss': 0.8109492096500318, 'Total loss': 0.8109492096500318}
2022-11-22 23:24:49,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:49,620 INFO:     Epoch: 64
2022-11-22 23:24:50,393 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8507949994053952, 'Total loss': 0.8507949994053952} | train loss {'Reaction outcome loss': 0.8052222624909683, 'Total loss': 0.8052222624909683}
2022-11-22 23:24:50,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:50,394 INFO:     Epoch: 65
2022-11-22 23:24:51,183 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.820719649625379, 'Total loss': 0.820719649625379} | train loss {'Reaction outcome loss': 0.8054987752779585, 'Total loss': 0.8054987752779585}
2022-11-22 23:24:51,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:51,184 INFO:     Epoch: 66
2022-11-22 23:24:51,970 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8286559782748999, 'Total loss': 0.8286559782748999} | train loss {'Reaction outcome loss': 0.8102507762244491, 'Total loss': 0.8102507762244491}
2022-11-22 23:24:51,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:51,971 INFO:     Epoch: 67
2022-11-22 23:24:52,751 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8263715789761654, 'Total loss': 0.8263715789761654} | train loss {'Reaction outcome loss': 0.8061040505522588, 'Total loss': 0.8061040505522588}
2022-11-22 23:24:52,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:52,751 INFO:     Epoch: 68
2022-11-22 23:24:53,526 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8398086865280949, 'Total loss': 0.8398086865280949} | train loss {'Reaction outcome loss': 0.8071790116487957, 'Total loss': 0.8071790116487957}
2022-11-22 23:24:53,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:53,527 INFO:     Epoch: 69
2022-11-22 23:24:54,289 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8476142904093099, 'Total loss': 0.8476142904093099} | train loss {'Reaction outcome loss': 0.8044824258225863, 'Total loss': 0.8044824258225863}
2022-11-22 23:24:54,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:54,289 INFO:     Epoch: 70
2022-11-22 23:24:55,078 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8270695632280305, 'Total loss': 0.8270695632280305} | train loss {'Reaction outcome loss': 0.8080584404409908, 'Total loss': 0.8080584404409908}
2022-11-22 23:24:55,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:55,078 INFO:     Epoch: 71
2022-11-22 23:24:55,866 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.82344037502311, 'Total loss': 0.82344037502311} | train loss {'Reaction outcome loss': 0.8102818158317785, 'Total loss': 0.8102818158317785}
2022-11-22 23:24:55,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:55,866 INFO:     Epoch: 72
2022-11-22 23:24:56,675 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.822618363208549, 'Total loss': 0.822618363208549} | train loss {'Reaction outcome loss': 0.8080781110730327, 'Total loss': 0.8080781110730327}
2022-11-22 23:24:56,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:56,675 INFO:     Epoch: 73
2022-11-22 23:24:57,505 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8225403393423835, 'Total loss': 0.8225403393423835} | train loss {'Reaction outcome loss': 0.8099517144384931, 'Total loss': 0.8099517144384931}
2022-11-22 23:24:57,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:57,505 INFO:     Epoch: 74
2022-11-22 23:24:58,318 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8332522851090098, 'Total loss': 0.8332522851090098} | train loss {'Reaction outcome loss': 0.8101834051433157, 'Total loss': 0.8101834051433157}
2022-11-22 23:24:58,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:58,319 INFO:     Epoch: 75
2022-11-22 23:24:59,097 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8246706391489783, 'Total loss': 0.8246706391489783} | train loss {'Reaction outcome loss': 0.8078831088591795, 'Total loss': 0.8078831088591795}
2022-11-22 23:24:59,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:59,098 INFO:     Epoch: 76
2022-11-22 23:24:59,887 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8245921301287275, 'Total loss': 0.8245921301287275} | train loss {'Reaction outcome loss': 0.8118235089006971, 'Total loss': 0.8118235089006971}
2022-11-22 23:24:59,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:24:59,887 INFO:     Epoch: 77
2022-11-22 23:25:00,661 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8330761208090671, 'Total loss': 0.8330761208090671} | train loss {'Reaction outcome loss': 0.8128058204396826, 'Total loss': 0.8128058204396826}
2022-11-22 23:25:00,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:00,662 INFO:     Epoch: 78
2022-11-22 23:25:01,445 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8208270523437234, 'Total loss': 0.8208270523437234} | train loss {'Reaction outcome loss': 0.8092117524537884, 'Total loss': 0.8092117524537884}
2022-11-22 23:25:01,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:01,445 INFO:     Epoch: 79
2022-11-22 23:25:02,238 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.821920070537301, 'Total loss': 0.821920070537301} | train loss {'Reaction outcome loss': 0.8079656153673032, 'Total loss': 0.8079656153673032}
2022-11-22 23:25:02,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:02,239 INFO:     Epoch: 80
2022-11-22 23:25:03,013 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8175983297270398, 'Total loss': 0.8175983297270398} | train loss {'Reaction outcome loss': 0.8102248748306369, 'Total loss': 0.8102248748306369}
2022-11-22 23:25:03,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:03,014 INFO:     Epoch: 81
2022-11-22 23:25:03,778 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8275099791759668, 'Total loss': 0.8275099791759668} | train loss {'Reaction outcome loss': 0.8075173310324794, 'Total loss': 0.8075173310324794}
2022-11-22 23:25:03,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:03,779 INFO:     Epoch: 82
2022-11-22 23:25:04,551 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8191968833291253, 'Total loss': 0.8191968833291253} | train loss {'Reaction outcome loss': 0.8088227578851043, 'Total loss': 0.8088227578851043}
2022-11-22 23:25:04,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:04,551 INFO:     Epoch: 83
2022-11-22 23:25:05,347 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8257841246072636, 'Total loss': 0.8257841246072636} | train loss {'Reaction outcome loss': 0.8077710182940374, 'Total loss': 0.8077710182940374}
2022-11-22 23:25:05,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:05,347 INFO:     Epoch: 84
2022-11-22 23:25:06,166 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8281996763029764, 'Total loss': 0.8281996763029764} | train loss {'Reaction outcome loss': 0.8063574970745649, 'Total loss': 0.8063574970745649}
2022-11-22 23:25:06,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:06,167 INFO:     Epoch: 85
2022-11-22 23:25:06,946 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8224887896415799, 'Total loss': 0.8224887896415799} | train loss {'Reaction outcome loss': 0.8100869899279759, 'Total loss': 0.8100869899279759}
2022-11-22 23:25:06,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:06,947 INFO:     Epoch: 86
2022-11-22 23:25:07,783 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8282185938469199, 'Total loss': 0.8282185938469199} | train loss {'Reaction outcome loss': 0.8093420585892239, 'Total loss': 0.8093420585892239}
2022-11-22 23:25:07,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:07,783 INFO:     Epoch: 87
2022-11-22 23:25:08,605 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8365921031597049, 'Total loss': 0.8365921031597049} | train loss {'Reaction outcome loss': 0.8065777618865497, 'Total loss': 0.8065777618865497}
2022-11-22 23:25:08,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:08,605 INFO:     Epoch: 88
2022-11-22 23:25:09,396 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8446425719316616, 'Total loss': 0.8446425719316616} | train loss {'Reaction outcome loss': 0.8115769909297834, 'Total loss': 0.8115769909297834}
2022-11-22 23:25:09,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:09,398 INFO:     Epoch: 89
2022-11-22 23:25:10,243 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8448522520619769, 'Total loss': 0.8448522520619769} | train loss {'Reaction outcome loss': 0.8052313076179536, 'Total loss': 0.8052313076179536}
2022-11-22 23:25:10,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:10,243 INFO:     Epoch: 90
2022-11-22 23:25:11,068 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8136757258758989, 'Total loss': 0.8136757258758989} | train loss {'Reaction outcome loss': 0.8064776964363505, 'Total loss': 0.8064776964363505}
2022-11-22 23:25:11,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:11,069 INFO:     Epoch: 91
2022-11-22 23:25:11,893 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8262179895888927, 'Total loss': 0.8262179895888927} | train loss {'Reaction outcome loss': 0.8063409622819697, 'Total loss': 0.8063409622819697}
2022-11-22 23:25:11,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:11,893 INFO:     Epoch: 92
2022-11-22 23:25:12,716 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8294984732949456, 'Total loss': 0.8294984732949456} | train loss {'Reaction outcome loss': 0.8091404310992507, 'Total loss': 0.8091404310992507}
2022-11-22 23:25:12,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:12,717 INFO:     Epoch: 93
2022-11-22 23:25:13,494 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8330329698185588, 'Total loss': 0.8330329698185588} | train loss {'Reaction outcome loss': 0.8095366350207173, 'Total loss': 0.8095366350207173}
2022-11-22 23:25:13,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:13,495 INFO:     Epoch: 94
2022-11-22 23:25:14,287 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.83330493541651, 'Total loss': 0.83330493541651} | train loss {'Reaction outcome loss': 0.8048481403804216, 'Total loss': 0.8048481403804216}
2022-11-22 23:25:14,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:14,288 INFO:     Epoch: 95
2022-11-22 23:25:15,083 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8368381573710331, 'Total loss': 0.8368381573710331} | train loss {'Reaction outcome loss': 0.8059049826420721, 'Total loss': 0.8059049826420721}
2022-11-22 23:25:15,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:15,084 INFO:     Epoch: 96
2022-11-22 23:25:15,870 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8234326964200929, 'Total loss': 0.8234326964200929} | train loss {'Reaction outcome loss': 0.8076134570797936, 'Total loss': 0.8076134570797936}
2022-11-22 23:25:15,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:15,870 INFO:     Epoch: 97
2022-11-22 23:25:16,698 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8414364824461382, 'Total loss': 0.8414364824461382} | train loss {'Reaction outcome loss': 0.8045547268674021, 'Total loss': 0.8045547268674021}
2022-11-22 23:25:16,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:16,699 INFO:     Epoch: 98
2022-11-22 23:25:17,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8364213885262956, 'Total loss': 0.8364213885262956} | train loss {'Reaction outcome loss': 0.8104405415351273, 'Total loss': 0.8104405415351273}
2022-11-22 23:25:17,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:17,480 INFO:     Epoch: 99
2022-11-22 23:25:18,311 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8299680317557135, 'Total loss': 0.8299680317557135} | train loss {'Reaction outcome loss': 0.8080563418200759, 'Total loss': 0.8080563418200759}
2022-11-22 23:25:18,311 INFO:     Best model found after epoch 26 of 100.
2022-11-22 23:25:18,311 INFO:   Done with stage: TRAINING
2022-11-22 23:25:18,311 INFO:   Starting stage: EVALUATION
2022-11-22 23:25:18,448 INFO:   Done with stage: EVALUATION
2022-11-22 23:25:18,448 INFO:   Leaving out SEQ value Fold_1
2022-11-22 23:25:18,461 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:25:18,462 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:25:19,149 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:25:19,150 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:25:19,219 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:25:19,219 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:25:19,219 INFO:     No hyperparam tuning for this model
2022-11-22 23:25:19,219 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:25:19,219 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:25:19,220 INFO:     None feature selector for col prot
2022-11-22 23:25:19,220 INFO:     None feature selector for col prot
2022-11-22 23:25:19,220 INFO:     None feature selector for col prot
2022-11-22 23:25:19,221 INFO:     None feature selector for col chem
2022-11-22 23:25:19,221 INFO:     None feature selector for col chem
2022-11-22 23:25:19,221 INFO:     None feature selector for col chem
2022-11-22 23:25:19,221 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:25:19,221 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:25:19,223 INFO:     Number of params in model 168571
2022-11-22 23:25:19,226 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:25:19,226 INFO:   Starting stage: TRAINING
2022-11-22 23:25:19,284 INFO:     Val loss before train {'Reaction outcome loss': 1.0385093932802028, 'Total loss': 1.0385093932802028}
2022-11-22 23:25:19,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:19,284 INFO:     Epoch: 0
2022-11-22 23:25:20,096 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8633339919827201, 'Total loss': 0.8633339919827201} | train loss {'Reaction outcome loss': 0.8711378695028513, 'Total loss': 0.8711378695028513}
2022-11-22 23:25:20,096 INFO:     Found new best model at epoch 0
2022-11-22 23:25:20,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:20,097 INFO:     Epoch: 1
2022-11-22 23:25:20,896 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8779140114784241, 'Total loss': 0.8779140114784241} | train loss {'Reaction outcome loss': 0.8422628873996889, 'Total loss': 0.8422628873996889}
2022-11-22 23:25:20,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:20,896 INFO:     Epoch: 2
2022-11-22 23:25:21,700 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8562725186347961, 'Total loss': 0.8562725186347961} | train loss {'Reaction outcome loss': 0.8376529139545765, 'Total loss': 0.8376529139545765}
2022-11-22 23:25:21,701 INFO:     Found new best model at epoch 2
2022-11-22 23:25:21,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:21,702 INFO:     Epoch: 3
2022-11-22 23:25:22,507 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8557375899770043, 'Total loss': 0.8557375899770043} | train loss {'Reaction outcome loss': 0.8356275200119868, 'Total loss': 0.8356275200119868}
2022-11-22 23:25:22,507 INFO:     Found new best model at epoch 3
2022-11-22 23:25:22,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:22,508 INFO:     Epoch: 4
2022-11-22 23:25:23,297 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8432113582437689, 'Total loss': 0.8432113582437689} | train loss {'Reaction outcome loss': 0.8303129314652339, 'Total loss': 0.8303129314652339}
2022-11-22 23:25:23,297 INFO:     Found new best model at epoch 4
2022-11-22 23:25:23,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:23,298 INFO:     Epoch: 5
2022-11-22 23:25:24,080 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8464848439801823, 'Total loss': 0.8464848439801823} | train loss {'Reaction outcome loss': 0.8315885117662097, 'Total loss': 0.8315885117662097}
2022-11-22 23:25:24,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:24,080 INFO:     Epoch: 6
2022-11-22 23:25:24,869 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8452658206224442, 'Total loss': 0.8452658206224442} | train loss {'Reaction outcome loss': 0.830819051878655, 'Total loss': 0.830819051878655}
2022-11-22 23:25:24,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:24,869 INFO:     Epoch: 7
2022-11-22 23:25:25,654 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8314938396215439, 'Total loss': 0.8314938396215439} | train loss {'Reaction outcome loss': 0.8209827457844969, 'Total loss': 0.8209827457844969}
2022-11-22 23:25:25,654 INFO:     Found new best model at epoch 7
2022-11-22 23:25:25,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:25,655 INFO:     Epoch: 8
2022-11-22 23:25:26,497 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8400142639875412, 'Total loss': 0.8400142639875412} | train loss {'Reaction outcome loss': 0.8171003865085633, 'Total loss': 0.8171003865085633}
2022-11-22 23:25:26,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:26,497 INFO:     Epoch: 9
2022-11-22 23:25:27,281 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.832932728596709, 'Total loss': 0.832932728596709} | train loss {'Reaction outcome loss': 0.8162163593749768, 'Total loss': 0.8162163593749768}
2022-11-22 23:25:27,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:27,281 INFO:     Epoch: 10
2022-11-22 23:25:28,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8362006192857568, 'Total loss': 0.8362006192857568} | train loss {'Reaction outcome loss': 0.8119309400981255, 'Total loss': 0.8119309400981255}
2022-11-22 23:25:28,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:28,061 INFO:     Epoch: 11
2022-11-22 23:25:28,854 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8535549586469476, 'Total loss': 0.8535549586469476} | train loss {'Reaction outcome loss': 0.8147872606752372, 'Total loss': 0.8147872606752372}
2022-11-22 23:25:28,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:28,854 INFO:     Epoch: 12
2022-11-22 23:25:29,688 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8219696974212473, 'Total loss': 0.8219696974212473} | train loss {'Reaction outcome loss': 0.8120635931308453, 'Total loss': 0.8120635931308453}
2022-11-22 23:25:29,688 INFO:     Found new best model at epoch 12
2022-11-22 23:25:29,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:29,689 INFO:     Epoch: 13
2022-11-22 23:25:30,500 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8365997529842637, 'Total loss': 0.8365997529842637} | train loss {'Reaction outcome loss': 0.8067512502252814, 'Total loss': 0.8067512502252814}
2022-11-22 23:25:30,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:30,500 INFO:     Epoch: 14
2022-11-22 23:25:31,317 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8318712528456341, 'Total loss': 0.8318712528456341} | train loss {'Reaction outcome loss': 0.8101599227320327, 'Total loss': 0.8101599227320327}
2022-11-22 23:25:31,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:31,317 INFO:     Epoch: 15
2022-11-22 23:25:32,117 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8230196312069893, 'Total loss': 0.8230196312069893} | train loss {'Reaction outcome loss': 0.804803350857395, 'Total loss': 0.804803350857395}
2022-11-22 23:25:32,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:32,118 INFO:     Epoch: 16
2022-11-22 23:25:32,941 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8513387373902581, 'Total loss': 0.8513387373902581} | train loss {'Reaction outcome loss': 0.8116311807381479, 'Total loss': 0.8116311807381479}
2022-11-22 23:25:32,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:32,942 INFO:     Epoch: 17
2022-11-22 23:25:33,739 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8294260813431307, 'Total loss': 0.8294260813431307} | train loss {'Reaction outcome loss': 0.8063031669087738, 'Total loss': 0.8063031669087738}
2022-11-22 23:25:33,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:33,741 INFO:     Epoch: 18
2022-11-22 23:25:34,553 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.867765177379955, 'Total loss': 0.867765177379955} | train loss {'Reaction outcome loss': 0.8015052559465049, 'Total loss': 0.8015052559465049}
2022-11-22 23:25:34,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:34,554 INFO:     Epoch: 19
2022-11-22 23:25:35,340 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8585073974999514, 'Total loss': 0.8585073974999514} | train loss {'Reaction outcome loss': 0.8020332120811409, 'Total loss': 0.8020332120811409}
2022-11-22 23:25:35,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:35,340 INFO:     Epoch: 20
2022-11-22 23:25:36,112 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8192444403063167, 'Total loss': 0.8192444403063167} | train loss {'Reaction outcome loss': 0.8073405572759961, 'Total loss': 0.8073405572759961}
2022-11-22 23:25:36,113 INFO:     Found new best model at epoch 20
2022-11-22 23:25:36,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:36,113 INFO:     Epoch: 21
2022-11-22 23:25:36,882 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8300294550982389, 'Total loss': 0.8300294550982389} | train loss {'Reaction outcome loss': 0.8090149021824362, 'Total loss': 0.8090149021824362}
2022-11-22 23:25:36,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:36,882 INFO:     Epoch: 22
2022-11-22 23:25:37,733 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.83460037748922, 'Total loss': 0.83460037748922} | train loss {'Reaction outcome loss': 0.810850393313628, 'Total loss': 0.810850393313628}
2022-11-22 23:25:37,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:37,734 INFO:     Epoch: 23
2022-11-22 23:25:38,596 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8302848772569136, 'Total loss': 0.8302848772569136} | train loss {'Reaction outcome loss': 0.808752613270331, 'Total loss': 0.808752613270331}
2022-11-22 23:25:38,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:38,596 INFO:     Epoch: 24
2022-11-22 23:25:39,417 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8346435048363425, 'Total loss': 0.8346435048363425} | train loss {'Reaction outcome loss': 0.805630627793339, 'Total loss': 0.805630627793339}
2022-11-22 23:25:39,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:39,417 INFO:     Epoch: 25
2022-11-22 23:25:40,273 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8271116560155695, 'Total loss': 0.8271116560155695} | train loss {'Reaction outcome loss': 0.799346403192412, 'Total loss': 0.799346403192412}
2022-11-22 23:25:40,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:40,274 INFO:     Epoch: 26
2022-11-22 23:25:41,052 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8505775928497314, 'Total loss': 0.8505775928497314} | train loss {'Reaction outcome loss': 0.8096906460731136, 'Total loss': 0.8096906460731136}
2022-11-22 23:25:41,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:41,052 INFO:     Epoch: 27
2022-11-22 23:25:41,873 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8503021177920428, 'Total loss': 0.8503021177920428} | train loss {'Reaction outcome loss': 0.7985068734599511, 'Total loss': 0.7985068734599511}
2022-11-22 23:25:41,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:41,873 INFO:     Epoch: 28
2022-11-22 23:25:42,726 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8251179483803835, 'Total loss': 0.8251179483803835} | train loss {'Reaction outcome loss': 0.8040076594362374, 'Total loss': 0.8040076594362374}
2022-11-22 23:25:42,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:42,727 INFO:     Epoch: 29
2022-11-22 23:25:43,535 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8437300297346982, 'Total loss': 0.8437300297346982} | train loss {'Reaction outcome loss': 0.8075301898153204, 'Total loss': 0.8075301898153204}
2022-11-22 23:25:43,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:43,535 INFO:     Epoch: 30
2022-11-22 23:25:44,335 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8544638834216378, 'Total loss': 0.8544638834216378} | train loss {'Reaction outcome loss': 0.8064534318622066, 'Total loss': 0.8064534318622066}
2022-11-22 23:25:44,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:44,335 INFO:     Epoch: 31
2022-11-22 23:25:45,165 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8367234082384543, 'Total loss': 0.8367234082384543} | train loss {'Reaction outcome loss': 0.8038839403434321, 'Total loss': 0.8038839403434321}
2022-11-22 23:25:45,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:45,165 INFO:     Epoch: 32
2022-11-22 23:25:45,971 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8346188285134055, 'Total loss': 0.8346188285134055} | train loss {'Reaction outcome loss': 0.8082210627885965, 'Total loss': 0.8082210627885965}
2022-11-22 23:25:45,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:45,971 INFO:     Epoch: 33
2022-11-22 23:25:46,746 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8403689800338312, 'Total loss': 0.8403689800338312} | train loss {'Reaction outcome loss': 0.8136282588547541, 'Total loss': 0.8136282588547541}
2022-11-22 23:25:46,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:46,746 INFO:     Epoch: 34
2022-11-22 23:25:47,559 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8247155926444314, 'Total loss': 0.8247155926444314} | train loss {'Reaction outcome loss': 0.7986043976386067, 'Total loss': 0.7986043976386067}
2022-11-22 23:25:47,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:47,559 INFO:     Epoch: 35
2022-11-22 23:25:48,351 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8249765607443723, 'Total loss': 0.8249765607443723} | train loss {'Reaction outcome loss': 0.8068305209339389, 'Total loss': 0.8068305209339389}
2022-11-22 23:25:48,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:48,351 INFO:     Epoch: 36
2022-11-22 23:25:49,142 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8226868848909031, 'Total loss': 0.8226868848909031} | train loss {'Reaction outcome loss': 0.8027972329845313, 'Total loss': 0.8027972329845313}
2022-11-22 23:25:49,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:49,143 INFO:     Epoch: 37
2022-11-22 23:25:49,933 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8244408707727086, 'Total loss': 0.8244408707727086} | train loss {'Reaction outcome loss': 0.8034741981068121, 'Total loss': 0.8034741981068121}
2022-11-22 23:25:49,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:49,933 INFO:     Epoch: 38
2022-11-22 23:25:50,703 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8187103461135518, 'Total loss': 0.8187103461135518} | train loss {'Reaction outcome loss': 0.8068716918167315, 'Total loss': 0.8068716918167315}
2022-11-22 23:25:50,703 INFO:     Found new best model at epoch 38
2022-11-22 23:25:50,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:50,704 INFO:     Epoch: 39
2022-11-22 23:25:51,466 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8352671611038122, 'Total loss': 0.8352671611038122} | train loss {'Reaction outcome loss': 0.8090237210154051, 'Total loss': 0.8090237210154051}
2022-11-22 23:25:51,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:51,467 INFO:     Epoch: 40
2022-11-22 23:25:52,234 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8337646871805191, 'Total loss': 0.8337646871805191} | train loss {'Reaction outcome loss': 0.8040926275465653, 'Total loss': 0.8040926275465653}
2022-11-22 23:25:52,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:52,234 INFO:     Epoch: 41
2022-11-22 23:25:53,012 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8227087394757704, 'Total loss': 0.8227087394757704} | train loss {'Reaction outcome loss': 0.8025933204271533, 'Total loss': 0.8025933204271533}
2022-11-22 23:25:53,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:53,013 INFO:     Epoch: 42
2022-11-22 23:25:53,780 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8253528130325404, 'Total loss': 0.8253528130325404} | train loss {'Reaction outcome loss': 0.8040717939133586, 'Total loss': 0.8040717939133586}
2022-11-22 23:25:53,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:53,781 INFO:     Epoch: 43
2022-11-22 23:25:54,551 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.813335079361092, 'Total loss': 0.813335079361092} | train loss {'Reaction outcome loss': 0.8125655135886389, 'Total loss': 0.8125655135886389}
2022-11-22 23:25:54,551 INFO:     Found new best model at epoch 43
2022-11-22 23:25:54,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:54,552 INFO:     Epoch: 44
2022-11-22 23:25:55,342 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8362069177356634, 'Total loss': 0.8362069177356634} | train loss {'Reaction outcome loss': 0.8089390065867891, 'Total loss': 0.8089390065867891}
2022-11-22 23:25:55,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:55,342 INFO:     Epoch: 45
2022-11-22 23:25:56,108 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8475371158935807, 'Total loss': 0.8475371158935807} | train loss {'Reaction outcome loss': 0.8080535078579597, 'Total loss': 0.8080535078579597}
2022-11-22 23:25:56,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:56,109 INFO:     Epoch: 46
2022-11-22 23:25:56,908 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8430964608084072, 'Total loss': 0.8430964608084072} | train loss {'Reaction outcome loss': 0.804993557061261, 'Total loss': 0.804993557061261}
2022-11-22 23:25:56,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:56,908 INFO:     Epoch: 47
2022-11-22 23:25:57,712 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8242663375355981, 'Total loss': 0.8242663375355981} | train loss {'Reaction outcome loss': 0.8012123862017504, 'Total loss': 0.8012123862017504}
2022-11-22 23:25:57,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:57,712 INFO:     Epoch: 48
2022-11-22 23:25:58,508 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8593070859258826, 'Total loss': 0.8593070859258826} | train loss {'Reaction outcome loss': 0.8007563043099183, 'Total loss': 0.8007563043099183}
2022-11-22 23:25:58,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:58,509 INFO:     Epoch: 49
2022-11-22 23:25:59,299 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.828987567262216, 'Total loss': 0.828987567262216} | train loss {'Reaction outcome loss': 0.8034567814848201, 'Total loss': 0.8034567814848201}
2022-11-22 23:25:59,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:25:59,299 INFO:     Epoch: 50
2022-11-22 23:26:00,119 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8484398302706805, 'Total loss': 0.8484398302706805} | train loss {'Reaction outcome loss': 0.8080578980899533, 'Total loss': 0.8080578980899533}
2022-11-22 23:26:00,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:00,120 INFO:     Epoch: 51
2022-11-22 23:26:00,928 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8249865492636507, 'Total loss': 0.8249865492636507} | train loss {'Reaction outcome loss': 0.8075538944860219, 'Total loss': 0.8075538944860219}
2022-11-22 23:26:00,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:00,929 INFO:     Epoch: 52
2022-11-22 23:26:01,721 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8392242762175474, 'Total loss': 0.8392242762175474} | train loss {'Reaction outcome loss': 0.8025178444771631, 'Total loss': 0.8025178444771631}
2022-11-22 23:26:01,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:01,722 INFO:     Epoch: 53
2022-11-22 23:26:02,526 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.824584231457927, 'Total loss': 0.824584231457927} | train loss {'Reaction outcome loss': 0.8022466517894374, 'Total loss': 0.8022466517894374}
2022-11-22 23:26:02,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:02,527 INFO:     Epoch: 54
2022-11-22 23:26:03,359 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8357218612324108, 'Total loss': 0.8357218612324108} | train loss {'Reaction outcome loss': 0.8100046800215718, 'Total loss': 0.8100046800215718}
2022-11-22 23:26:03,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:03,360 INFO:     Epoch: 55
2022-11-22 23:26:04,186 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8216830315915021, 'Total loss': 0.8216830315915021} | train loss {'Reaction outcome loss': 0.8060413762353934, 'Total loss': 0.8060413762353934}
2022-11-22 23:26:04,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:04,186 INFO:     Epoch: 56
2022-11-22 23:26:05,055 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8266565257852728, 'Total loss': 0.8266565257852728} | train loss {'Reaction outcome loss': 0.8032209470204497, 'Total loss': 0.8032209470204497}
2022-11-22 23:26:05,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:05,057 INFO:     Epoch: 57
2022-11-22 23:26:05,902 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8384439951994203, 'Total loss': 0.8384439951994203} | train loss {'Reaction outcome loss': 0.8021332958207922, 'Total loss': 0.8021332958207922}
2022-11-22 23:26:05,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:05,902 INFO:     Epoch: 58
2022-11-22 23:26:06,768 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8481451767412099, 'Total loss': 0.8481451767412099} | train loss {'Reaction outcome loss': 0.8074910590040539, 'Total loss': 0.8074910590040539}
2022-11-22 23:26:06,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:06,768 INFO:     Epoch: 59
2022-11-22 23:26:07,613 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8438306003808975, 'Total loss': 0.8438306003808975} | train loss {'Reaction outcome loss': 0.8037552192565883, 'Total loss': 0.8037552192565883}
2022-11-22 23:26:07,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:07,613 INFO:     Epoch: 60
2022-11-22 23:26:08,431 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.82749650424177, 'Total loss': 0.82749650424177} | train loss {'Reaction outcome loss': 0.8031335057999923, 'Total loss': 0.8031335057999923}
2022-11-22 23:26:08,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:08,431 INFO:     Epoch: 61
2022-11-22 23:26:09,253 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8291126333854415, 'Total loss': 0.8291126333854415} | train loss {'Reaction outcome loss': 0.8061034585300245, 'Total loss': 0.8061034585300245}
2022-11-22 23:26:09,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:09,254 INFO:     Epoch: 62
2022-11-22 23:26:10,111 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8202806291255084, 'Total loss': 0.8202806291255084} | train loss {'Reaction outcome loss': 0.8005407751813108, 'Total loss': 0.8005407751813108}
2022-11-22 23:26:10,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:10,111 INFO:     Epoch: 63
2022-11-22 23:26:10,947 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8170982856642116, 'Total loss': 0.8170982856642116} | train loss {'Reaction outcome loss': 0.8016177446012073, 'Total loss': 0.8016177446012073}
2022-11-22 23:26:10,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:10,947 INFO:     Epoch: 64
2022-11-22 23:26:11,762 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.828887321732261, 'Total loss': 0.828887321732261} | train loss {'Reaction outcome loss': 0.8076428698624677, 'Total loss': 0.8076428698624677}
2022-11-22 23:26:11,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:11,763 INFO:     Epoch: 65
2022-11-22 23:26:12,596 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8491399403322827, 'Total loss': 0.8491399403322827} | train loss {'Reaction outcome loss': 0.8030502705680214, 'Total loss': 0.8030502705680214}
2022-11-22 23:26:12,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:12,596 INFO:     Epoch: 66
2022-11-22 23:26:13,382 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8181536143476312, 'Total loss': 0.8181536143476312} | train loss {'Reaction outcome loss': 0.8022104097522704, 'Total loss': 0.8022104097522704}
2022-11-22 23:26:13,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:13,383 INFO:     Epoch: 67
2022-11-22 23:26:14,224 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8317770517685197, 'Total loss': 0.8317770517685197} | train loss {'Reaction outcome loss': 0.8040842528526599, 'Total loss': 0.8040842528526599}
2022-11-22 23:26:14,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:14,225 INFO:     Epoch: 68
2022-11-22 23:26:15,010 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8415431786667217, 'Total loss': 0.8415431786667217} | train loss {'Reaction outcome loss': 0.8079433008002849, 'Total loss': 0.8079433008002849}
2022-11-22 23:26:15,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:15,011 INFO:     Epoch: 69
2022-11-22 23:26:15,828 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8371091485023499, 'Total loss': 0.8371091485023499} | train loss {'Reaction outcome loss': 0.8076548383605142, 'Total loss': 0.8076548383605142}
2022-11-22 23:26:15,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:15,828 INFO:     Epoch: 70
2022-11-22 23:26:16,642 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8487565693530169, 'Total loss': 0.8487565693530169} | train loss {'Reaction outcome loss': 0.8037329352336374, 'Total loss': 0.8037329352336374}
2022-11-22 23:26:16,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:16,642 INFO:     Epoch: 71
2022-11-22 23:26:17,426 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8233512341976166, 'Total loss': 0.8233512341976166} | train loss {'Reaction outcome loss': 0.8043697705635657, 'Total loss': 0.8043697705635657}
2022-11-22 23:26:17,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:17,426 INFO:     Epoch: 72
2022-11-22 23:26:18,217 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8349107591943308, 'Total loss': 0.8349107591943308} | train loss {'Reaction outcome loss': 0.803150835971118, 'Total loss': 0.803150835971118}
2022-11-22 23:26:18,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:18,217 INFO:     Epoch: 73
2022-11-22 23:26:19,050 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8418572219935331, 'Total loss': 0.8418572219935331} | train loss {'Reaction outcome loss': 0.8013288277363487, 'Total loss': 0.8013288277363487}
2022-11-22 23:26:19,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:19,050 INFO:     Epoch: 74
2022-11-22 23:26:19,844 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8325225385752592, 'Total loss': 0.8325225385752592} | train loss {'Reaction outcome loss': 0.8058472504982581, 'Total loss': 0.8058472504982581}
2022-11-22 23:26:19,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:19,845 INFO:     Epoch: 75
2022-11-22 23:26:20,667 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.9369832141832872, 'Total loss': 0.9369832141832872} | train loss {'Reaction outcome loss': 0.8018306126961341, 'Total loss': 0.8018306126961341}
2022-11-22 23:26:20,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:20,667 INFO:     Epoch: 76
2022-11-22 23:26:21,481 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8290488699620421, 'Total loss': 0.8290488699620421} | train loss {'Reaction outcome loss': 0.8068629240217479, 'Total loss': 0.8068629240217479}
2022-11-22 23:26:21,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:21,481 INFO:     Epoch: 77
2022-11-22 23:26:22,291 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8258335007862612, 'Total loss': 0.8258335007862612} | train loss {'Reaction outcome loss': 0.8058737384886877, 'Total loss': 0.8058737384886877}
2022-11-22 23:26:22,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:22,291 INFO:     Epoch: 78
2022-11-22 23:26:23,107 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8212520906871016, 'Total loss': 0.8212520906871016} | train loss {'Reaction outcome loss': 0.8077538152214004, 'Total loss': 0.8077538152214004}
2022-11-22 23:26:23,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:23,107 INFO:     Epoch: 79
2022-11-22 23:26:23,913 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8426580347798087, 'Total loss': 0.8426580347798087} | train loss {'Reaction outcome loss': 0.8114375683218844, 'Total loss': 0.8114375683218844}
2022-11-22 23:26:23,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:23,914 INFO:     Epoch: 80
2022-11-22 23:26:24,724 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8227760730819269, 'Total loss': 0.8227760730819269} | train loss {'Reaction outcome loss': 0.803565270112835, 'Total loss': 0.803565270112835}
2022-11-22 23:26:24,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:24,724 INFO:     Epoch: 81
2022-11-22 23:26:25,540 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8243632262403314, 'Total loss': 0.8243632262403314} | train loss {'Reaction outcome loss': 0.7995476680487273, 'Total loss': 0.7995476680487273}
2022-11-22 23:26:25,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:25,540 INFO:     Epoch: 82
2022-11-22 23:26:26,316 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8526584113186056, 'Total loss': 0.8526584113186056} | train loss {'Reaction outcome loss': 0.8005094541470531, 'Total loss': 0.8005094541470531}
2022-11-22 23:26:26,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:26,316 INFO:     Epoch: 83
2022-11-22 23:26:27,087 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8265499689362266, 'Total loss': 0.8265499689362266} | train loss {'Reaction outcome loss': 0.8026068210601807, 'Total loss': 0.8026068210601807}
2022-11-22 23:26:27,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:27,087 INFO:     Epoch: 84
2022-11-22 23:26:27,875 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8363096097653563, 'Total loss': 0.8363096097653563} | train loss {'Reaction outcome loss': 0.8065049753256655, 'Total loss': 0.8065049753256655}
2022-11-22 23:26:27,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:27,875 INFO:     Epoch: 85
2022-11-22 23:26:28,697 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8296122530644591, 'Total loss': 0.8296122530644591} | train loss {'Reaction outcome loss': 0.8033503569240271, 'Total loss': 0.8033503569240271}
2022-11-22 23:26:28,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:28,697 INFO:     Epoch: 86
2022-11-22 23:26:29,501 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8685043603181839, 'Total loss': 0.8685043603181839} | train loss {'Reaction outcome loss': 0.805359563967477, 'Total loss': 0.805359563967477}
2022-11-22 23:26:29,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:29,501 INFO:     Epoch: 87
2022-11-22 23:26:30,317 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8274524807929993, 'Total loss': 0.8274524807929993} | train loss {'Reaction outcome loss': 0.812158381649357, 'Total loss': 0.812158381649357}
2022-11-22 23:26:30,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:30,318 INFO:     Epoch: 88
2022-11-22 23:26:31,120 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8400841890410944, 'Total loss': 0.8400841890410944} | train loss {'Reaction outcome loss': 0.8051696465565608, 'Total loss': 0.8051696465565608}
2022-11-22 23:26:31,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:31,120 INFO:     Epoch: 89
2022-11-22 23:26:31,908 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8374926800077612, 'Total loss': 0.8374926800077612} | train loss {'Reaction outcome loss': 0.8038215058052588, 'Total loss': 0.8038215058052588}
2022-11-22 23:26:31,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:31,908 INFO:     Epoch: 90
2022-11-22 23:26:32,698 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8487998599355872, 'Total loss': 0.8487998599355872} | train loss {'Reaction outcome loss': 0.8018872781321105, 'Total loss': 0.8018872781321105}
2022-11-22 23:26:32,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:32,698 INFO:     Epoch: 91
2022-11-22 23:26:33,522 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8216414641250264, 'Total loss': 0.8216414641250264} | train loss {'Reaction outcome loss': 0.8024713060392542, 'Total loss': 0.8024713060392542}
2022-11-22 23:26:33,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:33,522 INFO:     Epoch: 92
2022-11-22 23:26:34,358 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8122201236811551, 'Total loss': 0.8122201236811551} | train loss {'Reaction outcome loss': 0.8018526282870335, 'Total loss': 0.8018526282870335}
2022-11-22 23:26:34,358 INFO:     Found new best model at epoch 92
2022-11-22 23:26:34,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:34,359 INFO:     Epoch: 93
2022-11-22 23:26:35,153 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8309765031391924, 'Total loss': 0.8309765031391924} | train loss {'Reaction outcome loss': 0.8009802138033183, 'Total loss': 0.8009802138033183}
2022-11-22 23:26:35,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:35,153 INFO:     Epoch: 94
2022-11-22 23:26:35,961 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8176803947849707, 'Total loss': 0.8176803947849707} | train loss {'Reaction outcome loss': 0.8035850050418001, 'Total loss': 0.8035850050418001}
2022-11-22 23:26:35,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:35,961 INFO:     Epoch: 95
2022-11-22 23:26:36,743 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.840848368677226, 'Total loss': 0.840848368677226} | train loss {'Reaction outcome loss': 0.8045961184781573, 'Total loss': 0.8045961184781573}
2022-11-22 23:26:36,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:36,745 INFO:     Epoch: 96
2022-11-22 23:26:37,566 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8363050114024769, 'Total loss': 0.8363050114024769} | train loss {'Reaction outcome loss': 0.804103177930662, 'Total loss': 0.804103177930662}
2022-11-22 23:26:37,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:37,566 INFO:     Epoch: 97
2022-11-22 23:26:38,363 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8580736666917801, 'Total loss': 0.8580736666917801} | train loss {'Reaction outcome loss': 0.7938924300586164, 'Total loss': 0.7938924300586164}
2022-11-22 23:26:38,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:38,363 INFO:     Epoch: 98
2022-11-22 23:26:39,178 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8323969759724357, 'Total loss': 0.8323969759724357} | train loss {'Reaction outcome loss': 0.8082019888196397, 'Total loss': 0.8082019888196397}
2022-11-22 23:26:39,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:39,179 INFO:     Epoch: 99
2022-11-22 23:26:39,980 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8352436558766798, 'Total loss': 0.8352436558766798} | train loss {'Reaction outcome loss': 0.7981586999256118, 'Total loss': 0.7981586999256118}
2022-11-22 23:26:39,980 INFO:     Best model found after epoch 93 of 100.
2022-11-22 23:26:39,980 INFO:   Done with stage: TRAINING
2022-11-22 23:26:39,980 INFO:   Starting stage: EVALUATION
2022-11-22 23:26:40,104 INFO:   Done with stage: EVALUATION
2022-11-22 23:26:40,105 INFO:   Leaving out SEQ value Fold_2
2022-11-22 23:26:40,118 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 23:26:40,118 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:26:40,789 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:26:40,789 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:26:40,859 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:26:40,859 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:26:40,859 INFO:     No hyperparam tuning for this model
2022-11-22 23:26:40,859 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:26:40,859 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:26:40,860 INFO:     None feature selector for col prot
2022-11-22 23:26:40,860 INFO:     None feature selector for col prot
2022-11-22 23:26:40,860 INFO:     None feature selector for col prot
2022-11-22 23:26:40,861 INFO:     None feature selector for col chem
2022-11-22 23:26:40,861 INFO:     None feature selector for col chem
2022-11-22 23:26:40,861 INFO:     None feature selector for col chem
2022-11-22 23:26:40,861 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:26:40,861 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:26:40,863 INFO:     Number of params in model 168571
2022-11-22 23:26:40,866 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:26:40,866 INFO:   Starting stage: TRAINING
2022-11-22 23:26:40,923 INFO:     Val loss before train {'Reaction outcome loss': 0.9302500885995951, 'Total loss': 0.9302500885995951}
2022-11-22 23:26:40,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:40,924 INFO:     Epoch: 0
2022-11-22 23:26:41,705 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7788871855221011, 'Total loss': 0.7788871855221011} | train loss {'Reaction outcome loss': 0.8847770681186599, 'Total loss': 0.8847770681186599}
2022-11-22 23:26:41,705 INFO:     Found new best model at epoch 0
2022-11-22 23:26:41,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:41,706 INFO:     Epoch: 1
2022-11-22 23:26:42,511 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7975316819819537, 'Total loss': 0.7975316819819537} | train loss {'Reaction outcome loss': 0.8551386228629521, 'Total loss': 0.8551386228629521}
2022-11-22 23:26:42,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:42,511 INFO:     Epoch: 2
2022-11-22 23:26:43,284 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7925396663221446, 'Total loss': 0.7925396663221446} | train loss {'Reaction outcome loss': 0.8536176147509594, 'Total loss': 0.8536176147509594}
2022-11-22 23:26:43,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:43,285 INFO:     Epoch: 3
2022-11-22 23:26:44,069 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7825603268363259, 'Total loss': 0.7825603268363259} | train loss {'Reaction outcome loss': 0.8454330776418958, 'Total loss': 0.8454330776418958}
2022-11-22 23:26:44,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:44,069 INFO:     Epoch: 4
2022-11-22 23:26:44,887 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7845191630450162, 'Total loss': 0.7845191630450162} | train loss {'Reaction outcome loss': 0.842618841784341, 'Total loss': 0.842618841784341}
2022-11-22 23:26:44,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:44,887 INFO:     Epoch: 5
2022-11-22 23:26:45,680 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8098146231337027, 'Total loss': 0.8098146231337027} | train loss {'Reaction outcome loss': 0.8378034041852367, 'Total loss': 0.8378034041852367}
2022-11-22 23:26:45,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:45,680 INFO:     Epoch: 6
2022-11-22 23:26:46,544 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7842891683632677, 'Total loss': 0.7842891683632677} | train loss {'Reaction outcome loss': 0.8359406324065461, 'Total loss': 0.8359406324065461}
2022-11-22 23:26:46,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:46,544 INFO:     Epoch: 7
2022-11-22 23:26:47,299 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8028124117038467, 'Total loss': 0.8028124117038467} | train loss {'Reaction outcome loss': 0.8326618456110663, 'Total loss': 0.8326618456110663}
2022-11-22 23:26:47,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:47,300 INFO:     Epoch: 8
2022-11-22 23:26:48,136 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7813666286793622, 'Total loss': 0.7813666286793622} | train loss {'Reaction outcome loss': 0.8280206613394678, 'Total loss': 0.8280206613394678}
2022-11-22 23:26:48,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:48,136 INFO:     Epoch: 9
2022-11-22 23:26:48,935 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7817027707668868, 'Total loss': 0.7817027707668868} | train loss {'Reaction outcome loss': 0.8338173323748063, 'Total loss': 0.8338173323748063}
2022-11-22 23:26:48,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:48,936 INFO:     Epoch: 10
2022-11-22 23:26:49,700 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7795949517325922, 'Total loss': 0.7795949517325922} | train loss {'Reaction outcome loss': 0.8265501174391533, 'Total loss': 0.8265501174391533}
2022-11-22 23:26:49,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:49,701 INFO:     Epoch: 11
2022-11-22 23:26:50,517 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.751582611690868, 'Total loss': 0.751582611690868} | train loss {'Reaction outcome loss': 0.8254604848063722, 'Total loss': 0.8254604848063722}
2022-11-22 23:26:50,517 INFO:     Found new best model at epoch 11
2022-11-22 23:26:50,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:50,518 INFO:     Epoch: 12
2022-11-22 23:26:51,335 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7763140824708071, 'Total loss': 0.7763140824708071} | train loss {'Reaction outcome loss': 0.8268980139372301, 'Total loss': 0.8268980139372301}
2022-11-22 23:26:51,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:51,335 INFO:     Epoch: 13
2022-11-22 23:26:52,124 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7546888047998602, 'Total loss': 0.7546888047998602} | train loss {'Reaction outcome loss': 0.8254580216748374, 'Total loss': 0.8254580216748374}
2022-11-22 23:26:52,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:52,124 INFO:     Epoch: 14
2022-11-22 23:26:52,989 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7511925636367365, 'Total loss': 0.7511925636367365} | train loss {'Reaction outcome loss': 0.8216000964446943, 'Total loss': 0.8216000964446943}
2022-11-22 23:26:52,989 INFO:     Found new best model at epoch 14
2022-11-22 23:26:52,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:52,990 INFO:     Epoch: 15
2022-11-22 23:26:53,832 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7832482707771388, 'Total loss': 0.7832482707771388} | train loss {'Reaction outcome loss': 0.8233817516540994, 'Total loss': 0.8233817516540994}
2022-11-22 23:26:53,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:53,833 INFO:     Epoch: 16
2022-11-22 23:26:54,698 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7606839287010106, 'Total loss': 0.7606839287010106} | train loss {'Reaction outcome loss': 0.8242506696253407, 'Total loss': 0.8242506696253407}
2022-11-22 23:26:54,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:54,699 INFO:     Epoch: 17
2022-11-22 23:26:55,568 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7745351405306296, 'Total loss': 0.7745351405306296} | train loss {'Reaction outcome loss': 0.8246071679251534, 'Total loss': 0.8246071679251534}
2022-11-22 23:26:55,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:55,569 INFO:     Epoch: 18
2022-11-22 23:26:56,378 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7587061388926073, 'Total loss': 0.7587061388926073} | train loss {'Reaction outcome loss': 0.824909593864363, 'Total loss': 0.824909593864363}
2022-11-22 23:26:56,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:56,378 INFO:     Epoch: 19
2022-11-22 23:26:57,251 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7575858208266172, 'Total loss': 0.7575858208266172} | train loss {'Reaction outcome loss': 0.8237562438663171, 'Total loss': 0.8237562438663171}
2022-11-22 23:26:57,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:57,251 INFO:     Epoch: 20
2022-11-22 23:26:58,072 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7720779898491773, 'Total loss': 0.7720779898491773} | train loss {'Reaction outcome loss': 0.8222226956669165, 'Total loss': 0.8222226956669165}
2022-11-22 23:26:58,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:58,072 INFO:     Epoch: 21
2022-11-22 23:26:58,899 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7628710784695365, 'Total loss': 0.7628710784695365} | train loss {'Reaction outcome loss': 0.8226831207470018, 'Total loss': 0.8226831207470018}
2022-11-22 23:26:58,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:58,900 INFO:     Epoch: 22
2022-11-22 23:26:59,796 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7688973627307198, 'Total loss': 0.7688973627307198} | train loss {'Reaction outcome loss': 0.8207712826680164, 'Total loss': 0.8207712826680164}
2022-11-22 23:26:59,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:26:59,797 INFO:     Epoch: 23
2022-11-22 23:27:00,671 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7664955908601935, 'Total loss': 0.7664955908601935} | train loss {'Reaction outcome loss': 0.8239765404438486, 'Total loss': 0.8239765404438486}
2022-11-22 23:27:00,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:00,672 INFO:     Epoch: 24
2022-11-22 23:27:01,529 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7542391324585135, 'Total loss': 0.7542391324585135} | train loss {'Reaction outcome loss': 0.8190048549856458, 'Total loss': 0.8190048549856458}
2022-11-22 23:27:01,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:01,529 INFO:     Epoch: 25
2022-11-22 23:27:02,375 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7545970569957386, 'Total loss': 0.7545970569957386} | train loss {'Reaction outcome loss': 0.8184999248202967, 'Total loss': 0.8184999248202967}
2022-11-22 23:27:02,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:02,376 INFO:     Epoch: 26
2022-11-22 23:27:03,261 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7716283303770152, 'Total loss': 0.7716283303770152} | train loss {'Reaction outcome loss': 0.8195763820288132, 'Total loss': 0.8195763820288132}
2022-11-22 23:27:03,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:03,261 INFO:     Epoch: 27
2022-11-22 23:27:04,155 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7452129081568934, 'Total loss': 0.7452129081568934} | train loss {'Reaction outcome loss': 0.8175002006851897, 'Total loss': 0.8175002006851897}
2022-11-22 23:27:04,155 INFO:     Found new best model at epoch 27
2022-11-22 23:27:04,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:04,156 INFO:     Epoch: 28
2022-11-22 23:27:05,032 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7691286592320963, 'Total loss': 0.7691286592320963} | train loss {'Reaction outcome loss': 0.8262098744207499, 'Total loss': 0.8262098744207499}
2022-11-22 23:27:05,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:05,033 INFO:     Epoch: 29
2022-11-22 23:27:05,934 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7525975900617513, 'Total loss': 0.7525975900617513} | train loss {'Reaction outcome loss': 0.8169507285770105, 'Total loss': 0.8169507285770105}
2022-11-22 23:27:05,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:05,935 INFO:     Epoch: 30
2022-11-22 23:27:06,801 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7722594324838031, 'Total loss': 0.7722594324838031} | train loss {'Reaction outcome loss': 0.820169794681121, 'Total loss': 0.820169794681121}
2022-11-22 23:27:06,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:06,802 INFO:     Epoch: 31
2022-11-22 23:27:07,660 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7609591233459386, 'Total loss': 0.7609591233459386} | train loss {'Reaction outcome loss': 0.8181216665676662, 'Total loss': 0.8181216665676662}
2022-11-22 23:27:07,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:07,662 INFO:     Epoch: 32
2022-11-22 23:27:08,539 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7559685564853929, 'Total loss': 0.7559685564853929} | train loss {'Reaction outcome loss': 0.8163503275842082, 'Total loss': 0.8163503275842082}
2022-11-22 23:27:08,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:08,539 INFO:     Epoch: 33
2022-11-22 23:27:09,416 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7547938816926696, 'Total loss': 0.7547938816926696} | train loss {'Reaction outcome loss': 0.8162067064217159, 'Total loss': 0.8162067064217159}
2022-11-22 23:27:09,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:09,416 INFO:     Epoch: 34
2022-11-22 23:27:10,304 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7613513869318095, 'Total loss': 0.7613513869318095} | train loss {'Reaction outcome loss': 0.8130697632322506, 'Total loss': 0.8130697632322506}
2022-11-22 23:27:10,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:10,304 INFO:     Epoch: 35
2022-11-22 23:27:11,159 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7604513391852379, 'Total loss': 0.7604513391852379} | train loss {'Reaction outcome loss': 0.8209710649081639, 'Total loss': 0.8209710649081639}
2022-11-22 23:27:11,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:11,159 INFO:     Epoch: 36
2022-11-22 23:27:12,104 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7643548853018067, 'Total loss': 0.7643548853018067} | train loss {'Reaction outcome loss': 0.8155296426646563, 'Total loss': 0.8155296426646563}
2022-11-22 23:27:12,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:12,104 INFO:     Epoch: 37
2022-11-22 23:27:12,997 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7648744915019382, 'Total loss': 0.7648744915019382} | train loss {'Reaction outcome loss': 0.8186404476360399, 'Total loss': 0.8186404476360399}
2022-11-22 23:27:12,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:12,997 INFO:     Epoch: 38
2022-11-22 23:27:13,838 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7586852244355462, 'Total loss': 0.7586852244355462} | train loss {'Reaction outcome loss': 0.8202677600237788, 'Total loss': 0.8202677600237788}
2022-11-22 23:27:13,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:13,839 INFO:     Epoch: 39
2022-11-22 23:27:14,740 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7634940621527758, 'Total loss': 0.7634940621527758} | train loss {'Reaction outcome loss': 0.8186905685736209, 'Total loss': 0.8186905685736209}
2022-11-22 23:27:14,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:14,740 INFO:     Epoch: 40
2022-11-22 23:27:15,625 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.759237261658365, 'Total loss': 0.759237261658365} | train loss {'Reaction outcome loss': 0.8175339965187773, 'Total loss': 0.8175339965187773}
2022-11-22 23:27:15,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:15,625 INFO:     Epoch: 41
2022-11-22 23:27:16,443 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7527551214126024, 'Total loss': 0.7527551214126024} | train loss {'Reaction outcome loss': 0.8171681298285115, 'Total loss': 0.8171681298285115}
2022-11-22 23:27:16,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:16,443 INFO:     Epoch: 42
2022-11-22 23:27:17,311 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7627506174824454, 'Total loss': 0.7627506174824454} | train loss {'Reaction outcome loss': 0.8193111587543876, 'Total loss': 0.8193111587543876}
2022-11-22 23:27:17,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:17,312 INFO:     Epoch: 43
2022-11-22 23:27:18,178 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7556838196786967, 'Total loss': 0.7556838196786967} | train loss {'Reaction outcome loss': 0.8181334247394484, 'Total loss': 0.8181334247394484}
2022-11-22 23:27:18,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:18,179 INFO:     Epoch: 44
2022-11-22 23:27:19,027 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7888817482373931, 'Total loss': 0.7888817482373931} | train loss {'Reaction outcome loss': 0.8172312509040444, 'Total loss': 0.8172312509040444}
2022-11-22 23:27:19,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:19,027 INFO:     Epoch: 45
2022-11-22 23:27:19,907 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7464607120914892, 'Total loss': 0.7464607120914892} | train loss {'Reaction outcome loss': 0.8168958825724465, 'Total loss': 0.8168958825724465}
2022-11-22 23:27:19,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:19,907 INFO:     Epoch: 46
2022-11-22 23:27:20,856 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7883248247883536, 'Total loss': 0.7883248247883536} | train loss {'Reaction outcome loss': 0.8178703872524962, 'Total loss': 0.8178703872524962}
2022-11-22 23:27:20,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:20,856 INFO:     Epoch: 47
2022-11-22 23:27:21,705 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7689229893413457, 'Total loss': 0.7689229893413457} | train loss {'Reaction outcome loss': 0.819431033791328, 'Total loss': 0.819431033791328}
2022-11-22 23:27:21,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:21,705 INFO:     Epoch: 48
2022-11-22 23:27:22,583 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7603403743017804, 'Total loss': 0.7603403743017804} | train loss {'Reaction outcome loss': 0.8134613539491381, 'Total loss': 0.8134613539491381}
2022-11-22 23:27:22,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:22,584 INFO:     Epoch: 49
2022-11-22 23:27:23,372 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7521414804187688, 'Total loss': 0.7521414804187688} | train loss {'Reaction outcome loss': 0.8163987585476467, 'Total loss': 0.8163987585476467}
2022-11-22 23:27:23,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:23,372 INFO:     Epoch: 50
2022-11-22 23:27:24,235 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7600630074739456, 'Total loss': 0.7600630074739456} | train loss {'Reaction outcome loss': 0.8228979426987317, 'Total loss': 0.8228979426987317}
2022-11-22 23:27:24,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:24,236 INFO:     Epoch: 51
2022-11-22 23:27:25,102 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7547254210168665, 'Total loss': 0.7547254210168665} | train loss {'Reaction outcome loss': 0.8169321337524725, 'Total loss': 0.8169321337524725}
2022-11-22 23:27:25,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:25,102 INFO:     Epoch: 52
2022-11-22 23:27:25,982 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7620731077410958, 'Total loss': 0.7620731077410958} | train loss {'Reaction outcome loss': 0.8157768288437202, 'Total loss': 0.8157768288437202}
2022-11-22 23:27:25,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:25,983 INFO:     Epoch: 53
2022-11-22 23:27:26,876 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7546096423810179, 'Total loss': 0.7546096423810179} | train loss {'Reaction outcome loss': 0.8153817632976843, 'Total loss': 0.8153817632976843}
2022-11-22 23:27:26,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:26,876 INFO:     Epoch: 54
2022-11-22 23:27:27,745 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7725413333285939, 'Total loss': 0.7725413333285939} | train loss {'Reaction outcome loss': 0.8180357486617809, 'Total loss': 0.8180357486617809}
2022-11-22 23:27:27,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:27,745 INFO:     Epoch: 55
2022-11-22 23:27:28,595 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7551855478774417, 'Total loss': 0.7551855478774417} | train loss {'Reaction outcome loss': 0.8185341904357988, 'Total loss': 0.8185341904357988}
2022-11-22 23:27:28,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:28,596 INFO:     Epoch: 56
2022-11-22 23:27:29,433 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7751744179563089, 'Total loss': 0.7751744179563089} | train loss {'Reaction outcome loss': 0.8163989013555099, 'Total loss': 0.8163989013555099}
2022-11-22 23:27:29,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:29,433 INFO:     Epoch: 57
2022-11-22 23:27:30,290 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.743306231092323, 'Total loss': 0.743306231092323} | train loss {'Reaction outcome loss': 0.8187402788473636, 'Total loss': 0.8187402788473636}
2022-11-22 23:27:30,290 INFO:     Found new best model at epoch 57
2022-11-22 23:27:30,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:30,291 INFO:     Epoch: 58
2022-11-22 23:27:31,162 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.762028921734203, 'Total loss': 0.762028921734203} | train loss {'Reaction outcome loss': 0.8197396355015891, 'Total loss': 0.8197396355015891}
2022-11-22 23:27:31,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:31,162 INFO:     Epoch: 59
2022-11-22 23:27:32,050 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7659198059277101, 'Total loss': 0.7659198059277101} | train loss {'Reaction outcome loss': 0.81785841377414, 'Total loss': 0.81785841377414}
2022-11-22 23:27:32,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:32,050 INFO:     Epoch: 60
2022-11-22 23:27:32,883 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7648707797581499, 'Total loss': 0.7648707797581499} | train loss {'Reaction outcome loss': 0.820843812275906, 'Total loss': 0.820843812275906}
2022-11-22 23:27:32,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:32,883 INFO:     Epoch: 61
2022-11-22 23:27:33,752 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7497663409872488, 'Total loss': 0.7497663409872488} | train loss {'Reaction outcome loss': 0.8126732683911615, 'Total loss': 0.8126732683911615}
2022-11-22 23:27:33,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:33,753 INFO:     Epoch: 62
2022-11-22 23:27:34,616 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7531119087202982, 'Total loss': 0.7531119087202982} | train loss {'Reaction outcome loss': 0.8178708117835376, 'Total loss': 0.8178708117835376}
2022-11-22 23:27:34,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:34,616 INFO:     Epoch: 63
2022-11-22 23:27:35,454 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.739478138698773, 'Total loss': 0.739478138698773} | train loss {'Reaction outcome loss': 0.8173787174176197, 'Total loss': 0.8173787174176197}
2022-11-22 23:27:35,454 INFO:     Found new best model at epoch 63
2022-11-22 23:27:35,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:35,455 INFO:     Epoch: 64
2022-11-22 23:27:36,272 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.77375858344815, 'Total loss': 0.77375858344815} | train loss {'Reaction outcome loss': 0.8148757483278002, 'Total loss': 0.8148757483278002}
2022-11-22 23:27:36,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:36,272 INFO:     Epoch: 65
2022-11-22 23:27:37,133 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7912106066942215, 'Total loss': 0.7912106066942215} | train loss {'Reaction outcome loss': 0.8185879627052619, 'Total loss': 0.8185879627052619}
2022-11-22 23:27:37,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:37,133 INFO:     Epoch: 66
2022-11-22 23:27:37,976 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7415430054745891, 'Total loss': 0.7415430054745891} | train loss {'Reaction outcome loss': 0.8143579509793496, 'Total loss': 0.8143579509793496}
2022-11-22 23:27:37,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:37,976 INFO:     Epoch: 67
2022-11-22 23:27:38,848 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7727240269834345, 'Total loss': 0.7727240269834345} | train loss {'Reaction outcome loss': 0.8171417051432084, 'Total loss': 0.8171417051432084}
2022-11-22 23:27:38,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:38,850 INFO:     Epoch: 68
2022-11-22 23:27:39,740 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7563510767438195, 'Total loss': 0.7563510767438195} | train loss {'Reaction outcome loss': 0.8218945526346868, 'Total loss': 0.8218945526346868}
2022-11-22 23:27:39,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:39,741 INFO:     Epoch: 69
2022-11-22 23:27:40,604 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7601234702901407, 'Total loss': 0.7601234702901407} | train loss {'Reaction outcome loss': 0.8136340654626184, 'Total loss': 0.8136340654626184}
2022-11-22 23:27:40,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:40,604 INFO:     Epoch: 70
2022-11-22 23:27:41,444 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7565282122655348, 'Total loss': 0.7565282122655348} | train loss {'Reaction outcome loss': 0.8119157024792263, 'Total loss': 0.8119157024792263}
2022-11-22 23:27:41,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:41,444 INFO:     Epoch: 71
2022-11-22 23:27:42,309 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7592621012167498, 'Total loss': 0.7592621012167498} | train loss {'Reaction outcome loss': 0.8181739816860277, 'Total loss': 0.8181739816860277}
2022-11-22 23:27:42,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:42,309 INFO:     Epoch: 72
2022-11-22 23:27:43,169 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7489975907585837, 'Total loss': 0.7489975907585837} | train loss {'Reaction outcome loss': 0.813249666897618, 'Total loss': 0.813249666897618}
2022-11-22 23:27:43,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:43,169 INFO:     Epoch: 73
2022-11-22 23:27:44,050 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7565803622657602, 'Total loss': 0.7565803622657602} | train loss {'Reaction outcome loss': 0.817063957452774, 'Total loss': 0.817063957452774}
2022-11-22 23:27:44,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:44,050 INFO:     Epoch: 74
2022-11-22 23:27:44,882 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7545800473202359, 'Total loss': 0.7545800473202359} | train loss {'Reaction outcome loss': 0.8124813595596625, 'Total loss': 0.8124813595596625}
2022-11-22 23:27:44,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:44,883 INFO:     Epoch: 75
2022-11-22 23:27:45,745 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7392498444427144, 'Total loss': 0.7392498444427144} | train loss {'Reaction outcome loss': 0.8146910669852276, 'Total loss': 0.8146910669852276}
2022-11-22 23:27:45,745 INFO:     Found new best model at epoch 75
2022-11-22 23:27:45,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:45,746 INFO:     Epoch: 76
2022-11-22 23:27:46,566 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7573333328420465, 'Total loss': 0.7573333328420465} | train loss {'Reaction outcome loss': 0.8173153469757158, 'Total loss': 0.8173153469757158}
2022-11-22 23:27:46,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:46,566 INFO:     Epoch: 77
2022-11-22 23:27:47,355 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7520973394540224, 'Total loss': 0.7520973394540224} | train loss {'Reaction outcome loss': 0.809910824834084, 'Total loss': 0.809910824834084}
2022-11-22 23:27:47,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:47,356 INFO:     Epoch: 78
2022-11-22 23:27:48,209 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7713566503741525, 'Total loss': 0.7713566503741525} | train loss {'Reaction outcome loss': 0.8117905108296142, 'Total loss': 0.8117905108296142}
2022-11-22 23:27:48,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:48,209 INFO:     Epoch: 79
2022-11-22 23:27:49,017 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7794976938854564, 'Total loss': 0.7794976938854564} | train loss {'Reaction outcome loss': 0.8105192774412583, 'Total loss': 0.8105192774412583}
2022-11-22 23:27:49,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:49,018 INFO:     Epoch: 80
2022-11-22 23:27:49,909 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7695049000057307, 'Total loss': 0.7695049000057307} | train loss {'Reaction outcome loss': 0.8163003079745235, 'Total loss': 0.8163003079745235}
2022-11-22 23:27:49,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:49,909 INFO:     Epoch: 81
2022-11-22 23:27:50,770 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7753912339156325, 'Total loss': 0.7753912339156325} | train loss {'Reaction outcome loss': 0.815381517337293, 'Total loss': 0.815381517337293}
2022-11-22 23:27:50,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:50,771 INFO:     Epoch: 82
2022-11-22 23:27:51,638 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7761215499856255, 'Total loss': 0.7761215499856255} | train loss {'Reaction outcome loss': 0.8162955694052638, 'Total loss': 0.8162955694052638}
2022-11-22 23:27:51,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:51,638 INFO:     Epoch: 83
2022-11-22 23:27:52,474 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.760425322435119, 'Total loss': 0.760425322435119} | train loss {'Reaction outcome loss': 0.8178930235152342, 'Total loss': 0.8178930235152342}
2022-11-22 23:27:52,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:52,475 INFO:     Epoch: 84
2022-11-22 23:27:53,356 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7661453824151646, 'Total loss': 0.7661453824151646} | train loss {'Reaction outcome loss': 0.8149082872332359, 'Total loss': 0.8149082872332359}
2022-11-22 23:27:53,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:53,357 INFO:     Epoch: 85
2022-11-22 23:27:54,233 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7597303051840175, 'Total loss': 0.7597303051840175} | train loss {'Reaction outcome loss': 0.8148815950568842, 'Total loss': 0.8148815950568842}
2022-11-22 23:27:54,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:54,234 INFO:     Epoch: 86
2022-11-22 23:27:55,093 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7535243718461557, 'Total loss': 0.7535243718461557} | train loss {'Reaction outcome loss': 0.8138744058657665, 'Total loss': 0.8138744058657665}
2022-11-22 23:27:55,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:55,094 INFO:     Epoch: 87
2022-11-22 23:27:55,971 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7374458865008571, 'Total loss': 0.7374458865008571} | train loss {'Reaction outcome loss': 0.816936990801169, 'Total loss': 0.816936990801169}
2022-11-22 23:27:55,971 INFO:     Found new best model at epoch 87
2022-11-22 23:27:55,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:55,972 INFO:     Epoch: 88
2022-11-22 23:27:56,839 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7558592876250093, 'Total loss': 0.7558592876250093} | train loss {'Reaction outcome loss': 0.8124633500770647, 'Total loss': 0.8124633500770647}
2022-11-22 23:27:56,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:56,839 INFO:     Epoch: 89
2022-11-22 23:27:57,737 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7759415845979344, 'Total loss': 0.7759415845979344} | train loss {'Reaction outcome loss': 0.8130549885788743, 'Total loss': 0.8130549885788743}
2022-11-22 23:27:57,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:57,738 INFO:     Epoch: 90
2022-11-22 23:27:58,635 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7545152733271773, 'Total loss': 0.7545152733271773} | train loss {'Reaction outcome loss': 0.8177152196971738, 'Total loss': 0.8177152196971738}
2022-11-22 23:27:58,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:58,636 INFO:     Epoch: 91
2022-11-22 23:27:59,484 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7677420540289446, 'Total loss': 0.7677420540289446} | train loss {'Reaction outcome loss': 0.8147863391710788, 'Total loss': 0.8147863391710788}
2022-11-22 23:27:59,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:27:59,484 INFO:     Epoch: 92
2022-11-22 23:28:00,326 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7687277678738941, 'Total loss': 0.7687277678738941} | train loss {'Reaction outcome loss': 0.8188822084543657, 'Total loss': 0.8188822084543657}
2022-11-22 23:28:00,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:00,327 INFO:     Epoch: 93
2022-11-22 23:28:01,161 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.745510304516012, 'Total loss': 0.745510304516012} | train loss {'Reaction outcome loss': 0.814129554982088, 'Total loss': 0.814129554982088}
2022-11-22 23:28:01,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:01,161 INFO:     Epoch: 94
2022-11-22 23:28:02,008 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7645049413496797, 'Total loss': 0.7645049413496797} | train loss {'Reaction outcome loss': 0.8114447194702771, 'Total loss': 0.8114447194702771}
2022-11-22 23:28:02,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:02,008 INFO:     Epoch: 95
2022-11-22 23:28:02,837 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7712860432538119, 'Total loss': 0.7712860432538119} | train loss {'Reaction outcome loss': 0.815342847911679, 'Total loss': 0.815342847911679}
2022-11-22 23:28:02,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:02,837 INFO:     Epoch: 96
2022-11-22 23:28:03,675 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7537916529585015, 'Total loss': 0.7537916529585015} | train loss {'Reaction outcome loss': 0.8126326157122242, 'Total loss': 0.8126326157122242}
2022-11-22 23:28:03,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:03,676 INFO:     Epoch: 97
2022-11-22 23:28:04,505 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7497763572768732, 'Total loss': 0.7497763572768732} | train loss {'Reaction outcome loss': 0.8167340281058331, 'Total loss': 0.8167340281058331}
2022-11-22 23:28:04,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:04,505 INFO:     Epoch: 98
2022-11-22 23:28:05,332 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.750329548662359, 'Total loss': 0.750329548662359} | train loss {'Reaction outcome loss': 0.8146942676330099, 'Total loss': 0.8146942676330099}
2022-11-22 23:28:05,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:05,332 INFO:     Epoch: 99
2022-11-22 23:28:06,138 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7529577619650147, 'Total loss': 0.7529577619650147} | train loss {'Reaction outcome loss': 0.8150511016651075, 'Total loss': 0.8150511016651075}
2022-11-22 23:28:06,138 INFO:     Best model found after epoch 88 of 100.
2022-11-22 23:28:06,139 INFO:   Done with stage: TRAINING
2022-11-22 23:28:06,139 INFO:   Starting stage: EVALUATION
2022-11-22 23:28:06,270 INFO:   Done with stage: EVALUATION
2022-11-22 23:28:06,270 INFO:   Leaving out SEQ value Fold_3
2022-11-22 23:28:06,283 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 23:28:06,283 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:28:06,958 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:28:06,958 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:28:07,028 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:28:07,029 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:28:07,029 INFO:     No hyperparam tuning for this model
2022-11-22 23:28:07,029 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:28:07,029 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:28:07,030 INFO:     None feature selector for col prot
2022-11-22 23:28:07,030 INFO:     None feature selector for col prot
2022-11-22 23:28:07,030 INFO:     None feature selector for col prot
2022-11-22 23:28:07,031 INFO:     None feature selector for col chem
2022-11-22 23:28:07,031 INFO:     None feature selector for col chem
2022-11-22 23:28:07,031 INFO:     None feature selector for col chem
2022-11-22 23:28:07,031 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:28:07,031 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:28:07,033 INFO:     Number of params in model 168571
2022-11-22 23:28:07,036 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:28:07,036 INFO:   Starting stage: TRAINING
2022-11-22 23:28:07,094 INFO:     Val loss before train {'Reaction outcome loss': 0.9547580019994215, 'Total loss': 0.9547580019994215}
2022-11-22 23:28:07,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:07,094 INFO:     Epoch: 0
2022-11-22 23:28:07,937 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8317414386705919, 'Total loss': 0.8317414386705919} | train loss {'Reaction outcome loss': 0.8826600063820275, 'Total loss': 0.8826600063820275}
2022-11-22 23:28:07,937 INFO:     Found new best model at epoch 0
2022-11-22 23:28:07,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:07,938 INFO:     Epoch: 1
2022-11-22 23:28:08,730 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8183471042324196, 'Total loss': 0.8183471042324196} | train loss {'Reaction outcome loss': 0.8555856281397294, 'Total loss': 0.8555856281397294}
2022-11-22 23:28:08,730 INFO:     Found new best model at epoch 1
2022-11-22 23:28:08,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:08,731 INFO:     Epoch: 2
2022-11-22 23:28:09,552 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8083098219199614, 'Total loss': 0.8083098219199614} | train loss {'Reaction outcome loss': 0.8500523089146127, 'Total loss': 0.8500523089146127}
2022-11-22 23:28:09,552 INFO:     Found new best model at epoch 2
2022-11-22 23:28:09,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:09,553 INFO:     Epoch: 3
2022-11-22 23:28:10,370 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.800663295794617, 'Total loss': 0.800663295794617} | train loss {'Reaction outcome loss': 0.8463142030093135, 'Total loss': 0.8463142030093135}
2022-11-22 23:28:10,371 INFO:     Found new best model at epoch 3
2022-11-22 23:28:10,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:10,372 INFO:     Epoch: 4
2022-11-22 23:28:11,166 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7983569299632852, 'Total loss': 0.7983569299632852} | train loss {'Reaction outcome loss': 0.8417992374118494, 'Total loss': 0.8417992374118494}
2022-11-22 23:28:11,166 INFO:     Found new best model at epoch 4
2022-11-22 23:28:11,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:11,167 INFO:     Epoch: 5
2022-11-22 23:28:11,967 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8186436160044237, 'Total loss': 0.8186436160044237} | train loss {'Reaction outcome loss': 0.8290464897545017, 'Total loss': 0.8290464897545017}
2022-11-22 23:28:11,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:11,967 INFO:     Epoch: 6
2022-11-22 23:28:12,765 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7967657744884491, 'Total loss': 0.7967657744884491} | train loss {'Reaction outcome loss': 0.8291367544203389, 'Total loss': 0.8291367544203389}
2022-11-22 23:28:12,765 INFO:     Found new best model at epoch 6
2022-11-22 23:28:12,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:12,766 INFO:     Epoch: 7
2022-11-22 23:28:13,600 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8023910786617886, 'Total loss': 0.8023910786617886} | train loss {'Reaction outcome loss': 0.8254082779495083, 'Total loss': 0.8254082779495083}
2022-11-22 23:28:13,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:13,600 INFO:     Epoch: 8
2022-11-22 23:28:14,408 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.804820949381048, 'Total loss': 0.804820949381048} | train loss {'Reaction outcome loss': 0.8272273389660583, 'Total loss': 0.8272273389660583}
2022-11-22 23:28:14,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:14,409 INFO:     Epoch: 9
2022-11-22 23:28:15,218 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8212233951145952, 'Total loss': 0.8212233951145952} | train loss {'Reaction outcome loss': 0.8254008323562388, 'Total loss': 0.8254008323562388}
2022-11-22 23:28:15,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:15,218 INFO:     Epoch: 10
2022-11-22 23:28:16,033 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8156985024159605, 'Total loss': 0.8156985024159605} | train loss {'Reaction outcome loss': 0.8261868090045695, 'Total loss': 0.8261868090045695}
2022-11-22 23:28:16,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:16,034 INFO:     Epoch: 11
2022-11-22 23:28:16,844 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8000579767606475, 'Total loss': 0.8000579767606475} | train loss {'Reaction outcome loss': 0.8241896963241149, 'Total loss': 0.8241896963241149}
2022-11-22 23:28:16,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:16,846 INFO:     Epoch: 12
2022-11-22 23:28:17,624 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8422753743150018, 'Total loss': 0.8422753743150018} | train loss {'Reaction outcome loss': 0.8234585989494713, 'Total loss': 0.8234585989494713}
2022-11-22 23:28:17,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:17,624 INFO:     Epoch: 13
2022-11-22 23:28:18,460 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7967023388905958, 'Total loss': 0.7967023388905958} | train loss {'Reaction outcome loss': 0.8271224519427942, 'Total loss': 0.8271224519427942}
2022-11-22 23:28:18,460 INFO:     Found new best model at epoch 13
2022-11-22 23:28:18,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:18,461 INFO:     Epoch: 14
2022-11-22 23:28:19,282 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.792750979011709, 'Total loss': 0.792750979011709} | train loss {'Reaction outcome loss': 0.8190903269514745, 'Total loss': 0.8190903269514745}
2022-11-22 23:28:19,282 INFO:     Found new best model at epoch 14
2022-11-22 23:28:19,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:19,283 INFO:     Epoch: 15
2022-11-22 23:28:20,138 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.792070711878213, 'Total loss': 0.792070711878213} | train loss {'Reaction outcome loss': 0.8203651617984382, 'Total loss': 0.8203651617984382}
2022-11-22 23:28:20,138 INFO:     Found new best model at epoch 15
2022-11-22 23:28:20,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:20,139 INFO:     Epoch: 16
2022-11-22 23:28:20,932 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7933227189562537, 'Total loss': 0.7933227189562537} | train loss {'Reaction outcome loss': 0.8263850832472042, 'Total loss': 0.8263850832472042}
2022-11-22 23:28:20,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:20,932 INFO:     Epoch: 17
2022-11-22 23:28:21,758 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8044052584604784, 'Total loss': 0.8044052584604784} | train loss {'Reaction outcome loss': 0.8217237226817072, 'Total loss': 0.8217237226817072}
2022-11-22 23:28:21,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:21,758 INFO:     Epoch: 18
2022-11-22 23:28:22,604 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7919756912372329, 'Total loss': 0.7919756912372329} | train loss {'Reaction outcome loss': 0.8237053601109252, 'Total loss': 0.8237053601109252}
2022-11-22 23:28:22,604 INFO:     Found new best model at epoch 18
2022-11-22 23:28:22,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:22,605 INFO:     Epoch: 19
2022-11-22 23:28:23,391 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7934950529174372, 'Total loss': 0.7934950529174372} | train loss {'Reaction outcome loss': 0.8234645785117636, 'Total loss': 0.8234645785117636}
2022-11-22 23:28:23,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:23,392 INFO:     Epoch: 20
2022-11-22 23:28:24,226 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8372836153615605, 'Total loss': 0.8372836153615605} | train loss {'Reaction outcome loss': 0.8174375896551171, 'Total loss': 0.8174375896551171}
2022-11-22 23:28:24,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:24,227 INFO:     Epoch: 21
2022-11-22 23:28:25,008 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7936290597373789, 'Total loss': 0.7936290597373789} | train loss {'Reaction outcome loss': 0.8223852414257672, 'Total loss': 0.8223852414257672}
2022-11-22 23:28:25,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:25,008 INFO:     Epoch: 22
2022-11-22 23:28:25,814 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8006385517391291, 'Total loss': 0.8006385517391291} | train loss {'Reaction outcome loss': 0.8222252365277738, 'Total loss': 0.8222252365277738}
2022-11-22 23:28:25,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:25,815 INFO:     Epoch: 23
2022-11-22 23:28:26,647 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8257823207161643, 'Total loss': 0.8257823207161643} | train loss {'Reaction outcome loss': 0.8253766329921022, 'Total loss': 0.8253766329921022}
2022-11-22 23:28:26,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:26,647 INFO:     Epoch: 24
2022-11-22 23:28:27,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7848802947185256, 'Total loss': 0.7848802947185256} | train loss {'Reaction outcome loss': 0.8222100801005655, 'Total loss': 0.8222100801005655}
2022-11-22 23:28:27,477 INFO:     Found new best model at epoch 24
2022-11-22 23:28:27,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:27,478 INFO:     Epoch: 25
2022-11-22 23:28:28,309 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7815315625206991, 'Total loss': 0.7815315625206991} | train loss {'Reaction outcome loss': 0.8213518449238368, 'Total loss': 0.8213518449238368}
2022-11-22 23:28:28,309 INFO:     Found new best model at epoch 25
2022-11-22 23:28:28,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:28,310 INFO:     Epoch: 26
2022-11-22 23:28:29,151 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7761356928809122, 'Total loss': 0.7761356928809122} | train loss {'Reaction outcome loss': 0.8202813519507038, 'Total loss': 0.8202813519507038}
2022-11-22 23:28:29,152 INFO:     Found new best model at epoch 26
2022-11-22 23:28:29,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:29,153 INFO:     Epoch: 27
2022-11-22 23:28:30,026 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8124740265987136, 'Total loss': 0.8124740265987136} | train loss {'Reaction outcome loss': 0.8207575023174286, 'Total loss': 0.8207575023174286}
2022-11-22 23:28:30,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:30,026 INFO:     Epoch: 28
2022-11-22 23:28:30,839 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8260808729312636, 'Total loss': 0.8260808729312636} | train loss {'Reaction outcome loss': 0.8185013510742966, 'Total loss': 0.8185013510742966}
2022-11-22 23:28:30,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:30,840 INFO:     Epoch: 29
2022-11-22 23:28:31,642 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8489455655217171, 'Total loss': 0.8489455655217171} | train loss {'Reaction outcome loss': 0.8199780054238378, 'Total loss': 0.8199780054238378}
2022-11-22 23:28:31,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:31,642 INFO:     Epoch: 30
2022-11-22 23:28:32,459 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8089682080528953, 'Total loss': 0.8089682080528953} | train loss {'Reaction outcome loss': 0.8247396409511566, 'Total loss': 0.8247396409511566}
2022-11-22 23:28:32,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:32,460 INFO:     Epoch: 31
2022-11-22 23:28:33,273 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7855815982276743, 'Total loss': 0.7855815982276743} | train loss {'Reaction outcome loss': 0.82129832858942, 'Total loss': 0.82129832858942}
2022-11-22 23:28:33,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:33,273 INFO:     Epoch: 32
2022-11-22 23:28:34,107 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7898957709019835, 'Total loss': 0.7898957709019835} | train loss {'Reaction outcome loss': 0.8220192406858716, 'Total loss': 0.8220192406858716}
2022-11-22 23:28:34,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:34,107 INFO:     Epoch: 33
2022-11-22 23:28:34,897 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8122353560545228, 'Total loss': 0.8122353560545228} | train loss {'Reaction outcome loss': 0.817107242467452, 'Total loss': 0.817107242467452}
2022-11-22 23:28:34,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:34,898 INFO:     Epoch: 34
2022-11-22 23:28:35,745 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7907060330564325, 'Total loss': 0.7907060330564325} | train loss {'Reaction outcome loss': 0.8212488210931116, 'Total loss': 0.8212488210931116}
2022-11-22 23:28:35,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:35,745 INFO:     Epoch: 35
2022-11-22 23:28:36,511 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8335239169272509, 'Total loss': 0.8335239169272509} | train loss {'Reaction outcome loss': 0.8179599794806266, 'Total loss': 0.8179599794806266}
2022-11-22 23:28:36,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:36,511 INFO:     Epoch: 36
2022-11-22 23:28:37,359 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8019343235275962, 'Total loss': 0.8019343235275962} | train loss {'Reaction outcome loss': 0.823483647618975, 'Total loss': 0.823483647618975}
2022-11-22 23:28:37,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:37,360 INFO:     Epoch: 37
2022-11-22 23:28:38,165 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7815599365329201, 'Total loss': 0.7815599365329201} | train loss {'Reaction outcome loss': 0.8189306294431492, 'Total loss': 0.8189306294431492}
2022-11-22 23:28:38,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:38,165 INFO:     Epoch: 38
2022-11-22 23:28:38,971 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8332224555990912, 'Total loss': 0.8332224555990912} | train loss {'Reaction outcome loss': 0.8185080602460978, 'Total loss': 0.8185080602460978}
2022-11-22 23:28:38,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:38,971 INFO:     Epoch: 39
2022-11-22 23:28:39,754 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.818415954709053, 'Total loss': 0.818415954709053} | train loss {'Reaction outcome loss': 0.8145104291487714, 'Total loss': 0.8145104291487714}
2022-11-22 23:28:39,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:39,754 INFO:     Epoch: 40
2022-11-22 23:28:40,545 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8143574480306018, 'Total loss': 0.8143574480306018} | train loss {'Reaction outcome loss': 0.8202763846942357, 'Total loss': 0.8202763846942357}
2022-11-22 23:28:40,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:40,545 INFO:     Epoch: 41
2022-11-22 23:28:41,391 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7743347934023901, 'Total loss': 0.7743347934023901} | train loss {'Reaction outcome loss': 0.8148360856941768, 'Total loss': 0.8148360856941768}
2022-11-22 23:28:41,393 INFO:     Found new best model at epoch 41
2022-11-22 23:28:41,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:41,395 INFO:     Epoch: 42
2022-11-22 23:28:42,230 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8117606287652795, 'Total loss': 0.8117606287652795} | train loss {'Reaction outcome loss': 0.8131323826556303, 'Total loss': 0.8131323826556303}
2022-11-22 23:28:42,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:42,230 INFO:     Epoch: 43
2022-11-22 23:28:43,115 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8143736747178164, 'Total loss': 0.8143736747178164} | train loss {'Reaction outcome loss': 0.8150602545057024, 'Total loss': 0.8150602545057024}
2022-11-22 23:28:43,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:43,116 INFO:     Epoch: 44
2022-11-22 23:28:43,979 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7950907999818976, 'Total loss': 0.7950907999818976} | train loss {'Reaction outcome loss': 0.812669235589553, 'Total loss': 0.812669235589553}
2022-11-22 23:28:43,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:43,979 INFO:     Epoch: 45
2022-11-22 23:28:44,821 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7778005742213943, 'Total loss': 0.7778005742213943} | train loss {'Reaction outcome loss': 0.8162672259369675, 'Total loss': 0.8162672259369675}
2022-11-22 23:28:44,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:44,822 INFO:     Epoch: 46
2022-11-22 23:28:45,622 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8018299259922721, 'Total loss': 0.8018299259922721} | train loss {'Reaction outcome loss': 0.8115085196738341, 'Total loss': 0.8115085196738341}
2022-11-22 23:28:45,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:45,622 INFO:     Epoch: 47
2022-11-22 23:28:46,458 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7700120672922243, 'Total loss': 0.7700120672922243} | train loss {'Reaction outcome loss': 0.8132672797660438, 'Total loss': 0.8132672797660438}
2022-11-22 23:28:46,458 INFO:     Found new best model at epoch 47
2022-11-22 23:28:46,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:46,459 INFO:     Epoch: 48
2022-11-22 23:28:47,305 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7764846696095034, 'Total loss': 0.7764846696095034} | train loss {'Reaction outcome loss': 0.8082980890663303, 'Total loss': 0.8082980890663303}
2022-11-22 23:28:47,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:47,305 INFO:     Epoch: 49
2022-11-22 23:28:48,168 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8375345752997831, 'Total loss': 0.8375345752997831} | train loss {'Reaction outcome loss': 0.8114622689631521, 'Total loss': 0.8114622689631521}
2022-11-22 23:28:48,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:48,169 INFO:     Epoch: 50
2022-11-22 23:28:48,988 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7871704413132234, 'Total loss': 0.7871704413132234} | train loss {'Reaction outcome loss': 0.812632250177617, 'Total loss': 0.812632250177617}
2022-11-22 23:28:48,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:48,988 INFO:     Epoch: 51
2022-11-22 23:28:49,811 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8036556264216249, 'Total loss': 0.8036556264216249} | train loss {'Reaction outcome loss': 0.8112928721369529, 'Total loss': 0.8112928721369529}
2022-11-22 23:28:49,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:49,811 INFO:     Epoch: 52
2022-11-22 23:28:50,618 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8882219330831007, 'Total loss': 0.8882219330831007} | train loss {'Reaction outcome loss': 0.8047975733572122, 'Total loss': 0.8047975733572122}
2022-11-22 23:28:50,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:50,619 INFO:     Epoch: 53
2022-11-22 23:28:51,481 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7922951971942728, 'Total loss': 0.7922951971942728} | train loss {'Reaction outcome loss': 0.8119276809449099, 'Total loss': 0.8119276809449099}
2022-11-22 23:28:51,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:51,482 INFO:     Epoch: 54
2022-11-22 23:28:52,347 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7920499132438139, 'Total loss': 0.7920499132438139} | train loss {'Reaction outcome loss': 0.8093099349615526, 'Total loss': 0.8093099349615526}
2022-11-22 23:28:52,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:52,347 INFO:     Epoch: 55
2022-11-22 23:28:53,162 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8325340890071609, 'Total loss': 0.8325340890071609} | train loss {'Reaction outcome loss': 0.799350306330895, 'Total loss': 0.799350306330895}
2022-11-22 23:28:53,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:53,162 INFO:     Epoch: 56
2022-11-22 23:28:54,009 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8273393166336146, 'Total loss': 0.8273393166336146} | train loss {'Reaction outcome loss': 0.8088925080639976, 'Total loss': 0.8088925080639976}
2022-11-22 23:28:54,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:54,009 INFO:     Epoch: 57
2022-11-22 23:28:54,794 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7670164528218183, 'Total loss': 0.7670164528218183} | train loss {'Reaction outcome loss': 0.8059913961254821, 'Total loss': 0.8059913961254821}
2022-11-22 23:28:54,794 INFO:     Found new best model at epoch 57
2022-11-22 23:28:54,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:54,795 INFO:     Epoch: 58
2022-11-22 23:28:55,581 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7690661305730994, 'Total loss': 0.7690661305730994} | train loss {'Reaction outcome loss': 0.7983421690609991, 'Total loss': 0.7983421690609991}
2022-11-22 23:28:55,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:55,582 INFO:     Epoch: 59
2022-11-22 23:28:56,387 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7960179942575368, 'Total loss': 0.7960179942575368} | train loss {'Reaction outcome loss': 0.7990917221624024, 'Total loss': 0.7990917221624024}
2022-11-22 23:28:56,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:56,387 INFO:     Epoch: 60
2022-11-22 23:28:57,169 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7870408486236226, 'Total loss': 0.7870408486236226} | train loss {'Reaction outcome loss': 0.7953345444737648, 'Total loss': 0.7953345444737648}
2022-11-22 23:28:57,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:57,169 INFO:     Epoch: 61
2022-11-22 23:28:57,960 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7735249867493456, 'Total loss': 0.7735249867493456} | train loss {'Reaction outcome loss': 0.7999004986821389, 'Total loss': 0.7999004986821389}
2022-11-22 23:28:57,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:57,960 INFO:     Epoch: 62
2022-11-22 23:28:58,775 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7713881896978075, 'Total loss': 0.7713881896978075} | train loss {'Reaction outcome loss': 0.796541144288316, 'Total loss': 0.796541144288316}
2022-11-22 23:28:58,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:58,776 INFO:     Epoch: 63
2022-11-22 23:28:59,550 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7839196155017073, 'Total loss': 0.7839196155017073} | train loss {'Reaction outcome loss': 0.7936797410857921, 'Total loss': 0.7936797410857921}
2022-11-22 23:28:59,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:28:59,550 INFO:     Epoch: 64
2022-11-22 23:29:00,372 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7645378695292906, 'Total loss': 0.7645378695292906} | train loss {'Reaction outcome loss': 0.7923870321439237, 'Total loss': 0.7923870321439237}
2022-11-22 23:29:00,373 INFO:     Found new best model at epoch 64
2022-11-22 23:29:00,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:00,374 INFO:     Epoch: 65
2022-11-22 23:29:01,176 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7724473517049443, 'Total loss': 0.7724473517049443} | train loss {'Reaction outcome loss': 0.7961031204583694, 'Total loss': 0.7961031204583694}
2022-11-22 23:29:01,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:01,176 INFO:     Epoch: 66
2022-11-22 23:29:02,008 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7759115909310904, 'Total loss': 0.7759115909310904} | train loss {'Reaction outcome loss': 0.7888046522529758, 'Total loss': 0.7888046522529758}
2022-11-22 23:29:02,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:02,009 INFO:     Epoch: 67
2022-11-22 23:29:02,788 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7891537303274329, 'Total loss': 0.7891537303274329} | train loss {'Reaction outcome loss': 0.7831086141722543, 'Total loss': 0.7831086141722543}
2022-11-22 23:29:02,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:02,788 INFO:     Epoch: 68
2022-11-22 23:29:03,590 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7842331887646155, 'Total loss': 0.7842331887646155} | train loss {'Reaction outcome loss': 0.7894489040180128, 'Total loss': 0.7894489040180128}
2022-11-22 23:29:03,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:03,590 INFO:     Epoch: 69
2022-11-22 23:29:04,396 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7527990524064411, 'Total loss': 0.7527990524064411} | train loss {'Reaction outcome loss': 0.7793759298567869, 'Total loss': 0.7793759298567869}
2022-11-22 23:29:04,396 INFO:     Found new best model at epoch 69
2022-11-22 23:29:04,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:04,397 INFO:     Epoch: 70
2022-11-22 23:29:05,184 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7602065043015913, 'Total loss': 0.7602065043015913} | train loss {'Reaction outcome loss': 0.7802723891881047, 'Total loss': 0.7802723891881047}
2022-11-22 23:29:05,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:05,184 INFO:     Epoch: 71
2022-11-22 23:29:05,977 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7607827823270451, 'Total loss': 0.7607827823270451} | train loss {'Reaction outcome loss': 0.7778054878419759, 'Total loss': 0.7778054878419759}
2022-11-22 23:29:05,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:05,977 INFO:     Epoch: 72
2022-11-22 23:29:06,762 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7589540081945333, 'Total loss': 0.7589540081945333} | train loss {'Reaction outcome loss': 0.7784388369443466, 'Total loss': 0.7784388369443466}
2022-11-22 23:29:06,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:06,762 INFO:     Epoch: 73
2022-11-22 23:29:07,563 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7540466717698358, 'Total loss': 0.7540466717698358} | train loss {'Reaction outcome loss': 0.7730973045436703, 'Total loss': 0.7730973045436703}
2022-11-22 23:29:07,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:07,564 INFO:     Epoch: 74
2022-11-22 23:29:08,350 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7417971620505507, 'Total loss': 0.7417971620505507} | train loss {'Reaction outcome loss': 0.7690276270010034, 'Total loss': 0.7690276270010034}
2022-11-22 23:29:08,351 INFO:     Found new best model at epoch 74
2022-11-22 23:29:08,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:08,351 INFO:     Epoch: 75
2022-11-22 23:29:09,138 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7912528948350386, 'Total loss': 0.7912528948350386} | train loss {'Reaction outcome loss': 0.7657012967430815, 'Total loss': 0.7657012967430815}
2022-11-22 23:29:09,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:09,139 INFO:     Epoch: 76
2022-11-22 23:29:09,953 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7530802423981103, 'Total loss': 0.7530802423981103} | train loss {'Reaction outcome loss': 0.7619767983349002, 'Total loss': 0.7619767983349002}
2022-11-22 23:29:09,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:09,953 INFO:     Epoch: 77
2022-11-22 23:29:10,770 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7397127998146144, 'Total loss': 0.7397127998146144} | train loss {'Reaction outcome loss': 0.7578343757561274, 'Total loss': 0.7578343757561274}
2022-11-22 23:29:10,770 INFO:     Found new best model at epoch 77
2022-11-22 23:29:10,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:10,771 INFO:     Epoch: 78
2022-11-22 23:29:11,563 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7615779394453223, 'Total loss': 0.7615779394453223} | train loss {'Reaction outcome loss': 0.7559022412008168, 'Total loss': 0.7559022412008168}
2022-11-22 23:29:11,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:11,563 INFO:     Epoch: 79
2022-11-22 23:29:12,369 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7426530664617365, 'Total loss': 0.7426530664617365} | train loss {'Reaction outcome loss': 0.7442013430352113, 'Total loss': 0.7442013430352113}
2022-11-22 23:29:12,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:12,371 INFO:     Epoch: 80
2022-11-22 23:29:13,167 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8526329858736559, 'Total loss': 0.8526329858736559} | train loss {'Reaction outcome loss': 0.7415115833282471, 'Total loss': 0.7415115833282471}
2022-11-22 23:29:13,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:13,167 INFO:     Epoch: 81
2022-11-22 23:29:13,967 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7779247002168135, 'Total loss': 0.7779247002168135} | train loss {'Reaction outcome loss': 0.7238777018323237, 'Total loss': 0.7238777018323237}
2022-11-22 23:29:13,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:13,967 INFO:     Epoch: 82
2022-11-22 23:29:14,764 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7424928749149496, 'Total loss': 0.7424928749149496} | train loss {'Reaction outcome loss': 0.7315920023285613, 'Total loss': 0.7315920023285613}
2022-11-22 23:29:14,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:14,764 INFO:     Epoch: 83
2022-11-22 23:29:15,561 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6989321620626883, 'Total loss': 0.6989321620626883} | train loss {'Reaction outcome loss': 0.7104111030393717, 'Total loss': 0.7104111030393717}
2022-11-22 23:29:15,561 INFO:     Found new best model at epoch 83
2022-11-22 23:29:15,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:15,562 INFO:     Epoch: 84
2022-11-22 23:29:16,360 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.671617486260154, 'Total loss': 0.671617486260154} | train loss {'Reaction outcome loss': 0.701548468215125, 'Total loss': 0.701548468215125}
2022-11-22 23:29:16,360 INFO:     Found new best model at epoch 84
2022-11-22 23:29:16,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:16,361 INFO:     Epoch: 85
2022-11-22 23:29:17,161 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.6995346065271985, 'Total loss': 0.6995346065271985} | train loss {'Reaction outcome loss': 0.6843764562387855, 'Total loss': 0.6843764562387855}
2022-11-22 23:29:17,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:17,161 INFO:     Epoch: 86
2022-11-22 23:29:17,940 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6524573530663144, 'Total loss': 0.6524573530663144} | train loss {'Reaction outcome loss': 0.6705257271017347, 'Total loss': 0.6705257271017347}
2022-11-22 23:29:17,941 INFO:     Found new best model at epoch 86
2022-11-22 23:29:17,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:17,942 INFO:     Epoch: 87
2022-11-22 23:29:18,723 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6498940885066986, 'Total loss': 0.6498940885066986} | train loss {'Reaction outcome loss': 0.6641914024644968, 'Total loss': 0.6641914024644968}
2022-11-22 23:29:18,724 INFO:     Found new best model at epoch 87
2022-11-22 23:29:18,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:18,725 INFO:     Epoch: 88
2022-11-22 23:29:19,504 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6393542438745499, 'Total loss': 0.6393542438745499} | train loss {'Reaction outcome loss': 0.6339936569028971, 'Total loss': 0.6339936569028971}
2022-11-22 23:29:19,505 INFO:     Found new best model at epoch 88
2022-11-22 23:29:19,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:19,505 INFO:     Epoch: 89
2022-11-22 23:29:20,295 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6227286024527117, 'Total loss': 0.6227286024527117} | train loss {'Reaction outcome loss': 0.6280613039221082, 'Total loss': 0.6280613039221082}
2022-11-22 23:29:20,296 INFO:     Found new best model at epoch 89
2022-11-22 23:29:20,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:20,296 INFO:     Epoch: 90
2022-11-22 23:29:21,072 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6518758987499909, 'Total loss': 0.6518758987499909} | train loss {'Reaction outcome loss': 0.6246657418961428, 'Total loss': 0.6246657418961428}
2022-11-22 23:29:21,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:21,072 INFO:     Epoch: 91
2022-11-22 23:29:21,852 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6219462156295776, 'Total loss': 0.6219462156295776} | train loss {'Reaction outcome loss': 0.6133281491848888, 'Total loss': 0.6133281491848888}
2022-11-22 23:29:21,852 INFO:     Found new best model at epoch 91
2022-11-22 23:29:21,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:21,853 INFO:     Epoch: 92
2022-11-22 23:29:22,641 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6084367287429896, 'Total loss': 0.6084367287429896} | train loss {'Reaction outcome loss': 0.5802044802174277, 'Total loss': 0.5802044802174277}
2022-11-22 23:29:22,641 INFO:     Found new best model at epoch 92
2022-11-22 23:29:22,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:22,642 INFO:     Epoch: 93
2022-11-22 23:29:23,405 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.6158825369043783, 'Total loss': 0.6158825369043783} | train loss {'Reaction outcome loss': 0.5903277429999138, 'Total loss': 0.5903277429999138}
2022-11-22 23:29:23,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:23,405 INFO:     Epoch: 94
2022-11-22 23:29:24,176 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5531207472085953, 'Total loss': 0.5531207472085953} | train loss {'Reaction outcome loss': 0.583427091763944, 'Total loss': 0.583427091763944}
2022-11-22 23:29:24,177 INFO:     Found new best model at epoch 94
2022-11-22 23:29:24,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:24,178 INFO:     Epoch: 95
2022-11-22 23:29:25,028 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6208777089010585, 'Total loss': 0.6208777089010585} | train loss {'Reaction outcome loss': 0.5925364033300049, 'Total loss': 0.5925364033300049}
2022-11-22 23:29:25,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:25,028 INFO:     Epoch: 96
2022-11-22 23:29:25,918 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5822051194581118, 'Total loss': 0.5822051194581118} | train loss {'Reaction outcome loss': 0.580157582127318, 'Total loss': 0.580157582127318}
2022-11-22 23:29:25,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:25,918 INFO:     Epoch: 97
2022-11-22 23:29:26,776 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6457740887999535, 'Total loss': 0.6457740887999535} | train loss {'Reaction outcome loss': 0.5735841339340015, 'Total loss': 0.5735841339340015}
2022-11-22 23:29:26,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:26,776 INFO:     Epoch: 98
2022-11-22 23:29:27,548 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5576573447747664, 'Total loss': 0.5576573447747664} | train loss {'Reaction outcome loss': 0.5909575358945496, 'Total loss': 0.5909575358945496}
2022-11-22 23:29:27,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:27,548 INFO:     Epoch: 99
2022-11-22 23:29:28,356 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7381773418323561, 'Total loss': 0.7381773418323561} | train loss {'Reaction outcome loss': 0.583196228377673, 'Total loss': 0.583196228377673}
2022-11-22 23:29:28,356 INFO:     Best model found after epoch 95 of 100.
2022-11-22 23:29:28,356 INFO:   Done with stage: TRAINING
2022-11-22 23:29:28,356 INFO:   Starting stage: EVALUATION
2022-11-22 23:29:28,486 INFO:   Done with stage: EVALUATION
2022-11-22 23:29:28,486 INFO:   Leaving out SEQ value Fold_4
2022-11-22 23:29:28,499 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 23:29:28,499 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:29:29,172 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:29:29,173 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:29:29,242 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:29:29,242 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:29:29,242 INFO:     No hyperparam tuning for this model
2022-11-22 23:29:29,242 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:29:29,242 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:29:29,243 INFO:     None feature selector for col prot
2022-11-22 23:29:29,243 INFO:     None feature selector for col prot
2022-11-22 23:29:29,243 INFO:     None feature selector for col prot
2022-11-22 23:29:29,244 INFO:     None feature selector for col chem
2022-11-22 23:29:29,244 INFO:     None feature selector for col chem
2022-11-22 23:29:29,244 INFO:     None feature selector for col chem
2022-11-22 23:29:29,244 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:29:29,244 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:29:29,246 INFO:     Number of params in model 168571
2022-11-22 23:29:29,249 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:29:29,249 INFO:   Starting stage: TRAINING
2022-11-22 23:29:29,308 INFO:     Val loss before train {'Reaction outcome loss': 0.9798403111371127, 'Total loss': 0.9798403111371127}
2022-11-22 23:29:29,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:29,308 INFO:     Epoch: 0
2022-11-22 23:29:30,160 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8127573444084688, 'Total loss': 0.8127573444084688} | train loss {'Reaction outcome loss': 0.8758743969761595, 'Total loss': 0.8758743969761595}
2022-11-22 23:29:30,160 INFO:     Found new best model at epoch 0
2022-11-22 23:29:30,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:30,161 INFO:     Epoch: 1
2022-11-22 23:29:31,017 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7854405641555786, 'Total loss': 0.7854405641555786} | train loss {'Reaction outcome loss': 0.8426188204969679, 'Total loss': 0.8426188204969679}
2022-11-22 23:29:31,018 INFO:     Found new best model at epoch 1
2022-11-22 23:29:31,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:31,020 INFO:     Epoch: 2
2022-11-22 23:29:31,798 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.77996991913427, 'Total loss': 0.77996991913427} | train loss {'Reaction outcome loss': 0.8286905527114868, 'Total loss': 0.8286905527114868}
2022-11-22 23:29:31,798 INFO:     Found new best model at epoch 2
2022-11-22 23:29:31,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:31,799 INFO:     Epoch: 3
2022-11-22 23:29:32,602 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8009230995720084, 'Total loss': 0.8009230995720084} | train loss {'Reaction outcome loss': 0.8218145364401291, 'Total loss': 0.8218145364401291}
2022-11-22 23:29:32,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:32,602 INFO:     Epoch: 4
2022-11-22 23:29:33,386 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7939222543077036, 'Total loss': 0.7939222543077036} | train loss {'Reaction outcome loss': 0.8193290351604928, 'Total loss': 0.8193290351604928}
2022-11-22 23:29:33,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:33,387 INFO:     Epoch: 5
2022-11-22 23:29:34,223 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7884461161765185, 'Total loss': 0.7884461161765185} | train loss {'Reaction outcome loss': 0.8182215728321854, 'Total loss': 0.8182215728321854}
2022-11-22 23:29:34,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:34,224 INFO:     Epoch: 6
2022-11-22 23:29:35,040 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7874562692913142, 'Total loss': 0.7874562692913142} | train loss {'Reaction outcome loss': 0.8145125031471252, 'Total loss': 0.8145125031471252}
2022-11-22 23:29:35,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:35,040 INFO:     Epoch: 7
2022-11-22 23:29:35,862 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7886943979696794, 'Total loss': 0.7886943979696794} | train loss {'Reaction outcome loss': 0.8137133931627079, 'Total loss': 0.8137133931627079}
2022-11-22 23:29:35,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:35,863 INFO:     Epoch: 8
2022-11-22 23:29:36,693 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7755435373295437, 'Total loss': 0.7755435373295437} | train loss {'Reaction outcome loss': 0.8128019684431504, 'Total loss': 0.8128019684431504}
2022-11-22 23:29:36,694 INFO:     Found new best model at epoch 8
2022-11-22 23:29:36,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:36,695 INFO:     Epoch: 9
2022-11-22 23:29:37,516 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8116726584055207, 'Total loss': 0.8116726584055207} | train loss {'Reaction outcome loss': 0.8086489423197143, 'Total loss': 0.8086489423197143}
2022-11-22 23:29:37,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:37,516 INFO:     Epoch: 10
2022-11-22 23:29:38,337 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7865495072169737, 'Total loss': 0.7865495072169737} | train loss {'Reaction outcome loss': 0.8135160623764505, 'Total loss': 0.8135160623764505}
2022-11-22 23:29:38,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:38,337 INFO:     Epoch: 11
2022-11-22 23:29:39,172 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7812184569510546, 'Total loss': 0.7812184569510546} | train loss {'Reaction outcome loss': 0.8064671701314498, 'Total loss': 0.8064671701314498}
2022-11-22 23:29:39,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:39,172 INFO:     Epoch: 12
2022-11-22 23:29:40,031 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7705877077850428, 'Total loss': 0.7705877077850428} | train loss {'Reaction outcome loss': 0.8066399175293592, 'Total loss': 0.8066399175293592}
2022-11-22 23:29:40,031 INFO:     Found new best model at epoch 12
2022-11-22 23:29:40,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:40,032 INFO:     Epoch: 13
2022-11-22 23:29:40,869 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.800558480349454, 'Total loss': 0.800558480349454} | train loss {'Reaction outcome loss': 0.8080271147951787, 'Total loss': 0.8080271147951787}
2022-11-22 23:29:40,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:40,870 INFO:     Epoch: 14
2022-11-22 23:29:41,691 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7832571213895624, 'Total loss': 0.7832571213895624} | train loss {'Reaction outcome loss': 0.8083980674646338, 'Total loss': 0.8083980674646338}
2022-11-22 23:29:41,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:41,691 INFO:     Epoch: 15
2022-11-22 23:29:42,503 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7723502984101122, 'Total loss': 0.7723502984101122} | train loss {'Reaction outcome loss': 0.8132946723577927, 'Total loss': 0.8132946723577927}
2022-11-22 23:29:42,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:42,503 INFO:     Epoch: 16
2022-11-22 23:29:43,311 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7996561893007972, 'Total loss': 0.7996561893007972} | train loss {'Reaction outcome loss': 0.8038123180671614, 'Total loss': 0.8038123180671614}
2022-11-22 23:29:43,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:43,313 INFO:     Epoch: 17
2022-11-22 23:29:44,108 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7767348120158369, 'Total loss': 0.7767348120158369} | train loss {'Reaction outcome loss': 0.8075348785945348, 'Total loss': 0.8075348785945348}
2022-11-22 23:29:44,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:44,108 INFO:     Epoch: 18
2022-11-22 23:29:44,926 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.776744948530739, 'Total loss': 0.776744948530739} | train loss {'Reaction outcome loss': 0.8092949575307418, 'Total loss': 0.8092949575307418}
2022-11-22 23:29:44,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:44,926 INFO:     Epoch: 19
2022-11-22 23:29:45,727 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7729968835007061, 'Total loss': 0.7729968835007061} | train loss {'Reaction outcome loss': 0.8112336201327187, 'Total loss': 0.8112336201327187}
2022-11-22 23:29:45,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:45,727 INFO:     Epoch: 20
2022-11-22 23:29:46,599 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7713398797945543, 'Total loss': 0.7713398797945543} | train loss {'Reaction outcome loss': 0.8071437626468893, 'Total loss': 0.8071437626468893}
2022-11-22 23:29:46,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:46,599 INFO:     Epoch: 21
2022-11-22 23:29:47,400 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8103396716442975, 'Total loss': 0.8103396716442975} | train loss {'Reaction outcome loss': 0.8040424756857814, 'Total loss': 0.8040424756857814}
2022-11-22 23:29:47,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:47,400 INFO:     Epoch: 22
2022-11-22 23:29:48,242 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7866366715593771, 'Total loss': 0.7866366715593771} | train loss {'Reaction outcome loss': 0.80546050339329, 'Total loss': 0.80546050339329}
2022-11-22 23:29:48,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:48,243 INFO:     Epoch: 23
2022-11-22 23:29:49,053 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.76965586299246, 'Total loss': 0.76965586299246} | train loss {'Reaction outcome loss': 0.8081146917781051, 'Total loss': 0.8081146917781051}
2022-11-22 23:29:49,053 INFO:     Found new best model at epoch 23
2022-11-22 23:29:49,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:49,054 INFO:     Epoch: 24
2022-11-22 23:29:49,888 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8073921650648117, 'Total loss': 0.8073921650648117} | train loss {'Reaction outcome loss': 0.8076310292798645, 'Total loss': 0.8076310292798645}
2022-11-22 23:29:49,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:49,889 INFO:     Epoch: 25
2022-11-22 23:29:50,729 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7881496900861914, 'Total loss': 0.7881496900861914} | train loss {'Reaction outcome loss': 0.8053247824007151, 'Total loss': 0.8053247824007151}
2022-11-22 23:29:50,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:50,730 INFO:     Epoch: 26
2022-11-22 23:29:51,532 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8127922788262367, 'Total loss': 0.8127922788262367} | train loss {'Reaction outcome loss': 0.8013022731761543, 'Total loss': 0.8013022731761543}
2022-11-22 23:29:51,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:51,533 INFO:     Epoch: 27
2022-11-22 23:29:52,327 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7858459502458572, 'Total loss': 0.7858459502458572} | train loss {'Reaction outcome loss': 0.8036619683917687, 'Total loss': 0.8036619683917687}
2022-11-22 23:29:52,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:52,328 INFO:     Epoch: 28
2022-11-22 23:29:53,184 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7986426814035936, 'Total loss': 0.7986426814035936} | train loss {'Reaction outcome loss': 0.8063649737105077, 'Total loss': 0.8063649737105077}
2022-11-22 23:29:53,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:53,185 INFO:     Epoch: 29
2022-11-22 23:29:54,053 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7676767259836197, 'Total loss': 0.7676767259836197} | train loss {'Reaction outcome loss': 0.805176387636029, 'Total loss': 0.805176387636029}
2022-11-22 23:29:54,054 INFO:     Found new best model at epoch 29
2022-11-22 23:29:54,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:54,054 INFO:     Epoch: 30
2022-11-22 23:29:54,850 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8251606693322008, 'Total loss': 0.8251606693322008} | train loss {'Reaction outcome loss': 0.8036322881980819, 'Total loss': 0.8036322881980819}
2022-11-22 23:29:54,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:54,851 INFO:     Epoch: 31
2022-11-22 23:29:55,698 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8168364031748339, 'Total loss': 0.8168364031748339} | train loss {'Reaction outcome loss': 0.8061692666034309, 'Total loss': 0.8061692666034309}
2022-11-22 23:29:55,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:55,698 INFO:     Epoch: 32
2022-11-22 23:29:56,544 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7826733921061862, 'Total loss': 0.7826733921061862} | train loss {'Reaction outcome loss': 0.807587920402994, 'Total loss': 0.807587920402994}
2022-11-22 23:29:56,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:56,544 INFO:     Epoch: 33
2022-11-22 23:29:57,363 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7741846625100482, 'Total loss': 0.7741846625100482} | train loss {'Reaction outcome loss': 0.806358925663695, 'Total loss': 0.806358925663695}
2022-11-22 23:29:57,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:57,364 INFO:     Epoch: 34
2022-11-22 23:29:58,201 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7896654768423601, 'Total loss': 0.7896654768423601} | train loss {'Reaction outcome loss': 0.8036881658495689, 'Total loss': 0.8036881658495689}
2022-11-22 23:29:58,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:58,202 INFO:     Epoch: 35
2022-11-22 23:29:58,997 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7992898713458668, 'Total loss': 0.7992898713458668} | train loss {'Reaction outcome loss': 0.8035904838114368, 'Total loss': 0.8035904838114368}
2022-11-22 23:29:58,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:58,998 INFO:     Epoch: 36
2022-11-22 23:29:59,851 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7817913178693164, 'Total loss': 0.7817913178693164} | train loss {'Reaction outcome loss': 0.800726924745404, 'Total loss': 0.800726924745404}
2022-11-22 23:29:59,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:29:59,851 INFO:     Epoch: 37
2022-11-22 23:30:00,687 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8124686283144084, 'Total loss': 0.8124686283144084} | train loss {'Reaction outcome loss': 0.8047375636441367, 'Total loss': 0.8047375636441367}
2022-11-22 23:30:00,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:00,687 INFO:     Epoch: 38
2022-11-22 23:30:01,547 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8229908103292639, 'Total loss': 0.8229908103292639} | train loss {'Reaction outcome loss': 0.8008362464758815, 'Total loss': 0.8008362464758815}
2022-11-22 23:30:01,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:01,547 INFO:     Epoch: 39
2022-11-22 23:30:02,406 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7882886366410689, 'Total loss': 0.7882886366410689} | train loss {'Reaction outcome loss': 0.8041259796035533, 'Total loss': 0.8041259796035533}
2022-11-22 23:30:02,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:02,407 INFO:     Epoch: 40
2022-11-22 23:30:03,200 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7969288609244607, 'Total loss': 0.7969288609244607} | train loss {'Reaction outcome loss': 0.8031542889925898, 'Total loss': 0.8031542889925898}
2022-11-22 23:30:03,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:03,200 INFO:     Epoch: 41
2022-11-22 23:30:03,989 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7746489901434291, 'Total loss': 0.7746489901434291} | train loss {'Reaction outcome loss': 0.806792379155451, 'Total loss': 0.806792379155451}
2022-11-22 23:30:03,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:03,989 INFO:     Epoch: 42
2022-11-22 23:30:04,865 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7938118908892978, 'Total loss': 0.7938118908892978} | train loss {'Reaction outcome loss': 0.8014060160335229, 'Total loss': 0.8014060160335229}
2022-11-22 23:30:04,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:04,866 INFO:     Epoch: 43
2022-11-22 23:30:05,674 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7936047816818411, 'Total loss': 0.7936047816818411} | train loss {'Reaction outcome loss': 0.8031762506280626, 'Total loss': 0.8031762506280626}
2022-11-22 23:30:05,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:05,674 INFO:     Epoch: 44
2022-11-22 23:30:06,464 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8062300871719014, 'Total loss': 0.8062300871719014} | train loss {'Reaction outcome loss': 0.8069070502203338, 'Total loss': 0.8069070502203338}
2022-11-22 23:30:06,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:06,465 INFO:     Epoch: 45
2022-11-22 23:30:07,311 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7808899073438211, 'Total loss': 0.7808899073438211} | train loss {'Reaction outcome loss': 0.8027954905616994, 'Total loss': 0.8027954905616994}
2022-11-22 23:30:07,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:07,311 INFO:     Epoch: 46
2022-11-22 23:30:08,143 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7702021334658969, 'Total loss': 0.7702021334658969} | train loss {'Reaction outcome loss': 0.8014501063191161, 'Total loss': 0.8014501063191161}
2022-11-22 23:30:08,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:08,143 INFO:     Epoch: 47
2022-11-22 23:30:08,965 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7869003625078634, 'Total loss': 0.7869003625078634} | train loss {'Reaction outcome loss': 0.8017866722175053, 'Total loss': 0.8017866722175053}
2022-11-22 23:30:08,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:08,965 INFO:     Epoch: 48
2022-11-22 23:30:09,812 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7832854410464113, 'Total loss': 0.7832854410464113} | train loss {'Reaction outcome loss': 0.803976176831187, 'Total loss': 0.803976176831187}
2022-11-22 23:30:09,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:09,812 INFO:     Epoch: 49
2022-11-22 23:30:10,609 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7960051833228632, 'Total loss': 0.7960051833228632} | train loss {'Reaction outcome loss': 0.8061042477889937, 'Total loss': 0.8061042477889937}
2022-11-22 23:30:10,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:10,610 INFO:     Epoch: 50
2022-11-22 23:30:11,428 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7762329253283414, 'Total loss': 0.7762329253283414} | train loss {'Reaction outcome loss': 0.8021505022535519, 'Total loss': 0.8021505022535519}
2022-11-22 23:30:11,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:11,429 INFO:     Epoch: 51
2022-11-22 23:30:12,238 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7829533977942034, 'Total loss': 0.7829533977942034} | train loss {'Reaction outcome loss': 0.8020507784522309, 'Total loss': 0.8020507784522309}
2022-11-22 23:30:12,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:12,238 INFO:     Epoch: 52
2022-11-22 23:30:13,046 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7727979943156242, 'Total loss': 0.7727979943156242} | train loss {'Reaction outcome loss': 0.801375941962612, 'Total loss': 0.801375941962612}
2022-11-22 23:30:13,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:13,047 INFO:     Epoch: 53
2022-11-22 23:30:13,866 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8005777848037806, 'Total loss': 0.8005777848037806} | train loss {'Reaction outcome loss': 0.8000752736111076, 'Total loss': 0.8000752736111076}
2022-11-22 23:30:13,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:13,868 INFO:     Epoch: 54
2022-11-22 23:30:14,677 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7830365842038934, 'Total loss': 0.7830365842038934} | train loss {'Reaction outcome loss': 0.8060200378602865, 'Total loss': 0.8060200378602865}
2022-11-22 23:30:14,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:14,677 INFO:     Epoch: 55
2022-11-22 23:30:15,460 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7738208096813072, 'Total loss': 0.7738208096813072} | train loss {'Reaction outcome loss': 0.8036329044371235, 'Total loss': 0.8036329044371235}
2022-11-22 23:30:15,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:15,460 INFO:     Epoch: 56
2022-11-22 23:30:16,249 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8032709495587782, 'Total loss': 0.8032709495587782} | train loss {'Reaction outcome loss': 0.8043747800953535, 'Total loss': 0.8043747800953535}
2022-11-22 23:30:16,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:16,249 INFO:     Epoch: 57
2022-11-22 23:30:17,038 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8055062144994736, 'Total loss': 0.8055062144994736} | train loss {'Reaction outcome loss': 0.7967621324013691, 'Total loss': 0.7967621324013691}
2022-11-22 23:30:17,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:17,038 INFO:     Epoch: 58
2022-11-22 23:30:17,843 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7706500535661523, 'Total loss': 0.7706500535661523} | train loss {'Reaction outcome loss': 0.8039964542096975, 'Total loss': 0.8039964542096975}
2022-11-22 23:30:17,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:17,843 INFO:     Epoch: 59
2022-11-22 23:30:18,670 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7788510613820769, 'Total loss': 0.7788510613820769} | train loss {'Reaction outcome loss': 0.8000531903335026, 'Total loss': 0.8000531903335026}
2022-11-22 23:30:18,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:18,670 INFO:     Epoch: 60
2022-11-22 23:30:19,450 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.771307192065499, 'Total loss': 0.771307192065499} | train loss {'Reaction outcome loss': 0.8029809383713469, 'Total loss': 0.8029809383713469}
2022-11-22 23:30:19,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:19,451 INFO:     Epoch: 61
2022-11-22 23:30:20,231 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8076294660568237, 'Total loss': 0.8076294660568237} | train loss {'Reaction outcome loss': 0.7979233308714263, 'Total loss': 0.7979233308714263}
2022-11-22 23:30:20,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:20,232 INFO:     Epoch: 62
2022-11-22 23:30:21,047 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7872041247107766, 'Total loss': 0.7872041247107766} | train loss {'Reaction outcome loss': 0.801883679385088, 'Total loss': 0.801883679385088}
2022-11-22 23:30:21,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:21,048 INFO:     Epoch: 63
2022-11-22 23:30:21,915 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7795374549248002, 'Total loss': 0.7795374549248002} | train loss {'Reaction outcome loss': 0.8021102955146712, 'Total loss': 0.8021102955146712}
2022-11-22 23:30:21,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:21,915 INFO:     Epoch: 64
2022-11-22 23:30:22,766 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7966515110297636, 'Total loss': 0.7966515110297636} | train loss {'Reaction outcome loss': 0.8011854708194732, 'Total loss': 0.8011854708194732}
2022-11-22 23:30:22,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:22,767 INFO:     Epoch: 65
2022-11-22 23:30:23,618 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7802162969654257, 'Total loss': 0.7802162969654257} | train loss {'Reaction outcome loss': 0.800125227412399, 'Total loss': 0.800125227412399}
2022-11-22 23:30:23,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:23,618 INFO:     Epoch: 66
2022-11-22 23:30:24,389 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7802749987352978, 'Total loss': 0.7802749987352978} | train loss {'Reaction outcome loss': 0.8024761348354573, 'Total loss': 0.8024761348354573}
2022-11-22 23:30:24,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:24,389 INFO:     Epoch: 67
2022-11-22 23:30:25,168 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7952517013658177, 'Total loss': 0.7952517013658177} | train loss {'Reaction outcome loss': 0.7977333523789231, 'Total loss': 0.7977333523789231}
2022-11-22 23:30:25,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:25,169 INFO:     Epoch: 68
2022-11-22 23:30:25,948 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7819580286741257, 'Total loss': 0.7819580286741257} | train loss {'Reaction outcome loss': 0.8016830744792004, 'Total loss': 0.8016830744792004}
2022-11-22 23:30:25,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:25,948 INFO:     Epoch: 69
2022-11-22 23:30:26,756 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7843890020793135, 'Total loss': 0.7843890020793135} | train loss {'Reaction outcome loss': 0.8002486749571197, 'Total loss': 0.8002486749571197}
2022-11-22 23:30:26,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:26,756 INFO:     Epoch: 70
2022-11-22 23:30:27,549 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7838103662837635, 'Total loss': 0.7838103662837635} | train loss {'Reaction outcome loss': 0.7939561896178187, 'Total loss': 0.7939561896178187}
2022-11-22 23:30:27,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:27,550 INFO:     Epoch: 71
2022-11-22 23:30:28,327 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8005626215176149, 'Total loss': 0.8005626215176149} | train loss {'Reaction outcome loss': 0.7949644785754535, 'Total loss': 0.7949644785754535}
2022-11-22 23:30:28,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:28,328 INFO:     Epoch: 72
2022-11-22 23:30:29,171 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7940514148636297, 'Total loss': 0.7940514148636297} | train loss {'Reaction outcome loss': 0.8028491236725632, 'Total loss': 0.8028491236725632}
2022-11-22 23:30:29,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:29,172 INFO:     Epoch: 73
2022-11-22 23:30:29,955 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7843829616904259, 'Total loss': 0.7843829616904259} | train loss {'Reaction outcome loss': 0.8006688167854231, 'Total loss': 0.8006688167854231}
2022-11-22 23:30:29,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:29,956 INFO:     Epoch: 74
2022-11-22 23:30:30,796 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7723415107889608, 'Total loss': 0.7723415107889608} | train loss {'Reaction outcome loss': 0.7937923220955596, 'Total loss': 0.7937923220955596}
2022-11-22 23:30:30,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:30,796 INFO:     Epoch: 75
2022-11-22 23:30:31,640 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8024838776750998, 'Total loss': 0.8024838776750998} | train loss {'Reaction outcome loss': 0.803391136441912, 'Total loss': 0.803391136441912}
2022-11-22 23:30:31,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:31,640 INFO:     Epoch: 76
2022-11-22 23:30:32,440 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7629623961719599, 'Total loss': 0.7629623961719599} | train loss {'Reaction outcome loss': 0.8020755809180591, 'Total loss': 0.8020755809180591}
2022-11-22 23:30:32,441 INFO:     Found new best model at epoch 76
2022-11-22 23:30:32,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:32,442 INFO:     Epoch: 77
2022-11-22 23:30:33,295 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7745840048248117, 'Total loss': 0.7745840048248117} | train loss {'Reaction outcome loss': 0.7963965640992534, 'Total loss': 0.7963965640992534}
2022-11-22 23:30:33,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:33,295 INFO:     Epoch: 78
2022-11-22 23:30:34,083 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7760952216657725, 'Total loss': 0.7760952216657725} | train loss {'Reaction outcome loss': 0.8024437383729585, 'Total loss': 0.8024437383729585}
2022-11-22 23:30:34,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:34,083 INFO:     Epoch: 79
2022-11-22 23:30:34,956 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8014345961538228, 'Total loss': 0.8014345961538228} | train loss {'Reaction outcome loss': 0.8008957090426464, 'Total loss': 0.8008957090426464}
2022-11-22 23:30:34,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:34,957 INFO:     Epoch: 80
2022-11-22 23:30:35,738 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7780012112449516, 'Total loss': 0.7780012112449516} | train loss {'Reaction outcome loss': 0.7960213613753416, 'Total loss': 0.7960213613753416}
2022-11-22 23:30:35,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:35,738 INFO:     Epoch: 81
2022-11-22 23:30:36,517 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.803612426600673, 'Total loss': 0.803612426600673} | train loss {'Reaction outcome loss': 0.8031744228333842, 'Total loss': 0.8031744228333842}
2022-11-22 23:30:36,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:36,517 INFO:     Epoch: 82
2022-11-22 23:30:37,327 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7769923054359176, 'Total loss': 0.7769923054359176} | train loss {'Reaction outcome loss': 0.8003725250156558, 'Total loss': 0.8003725250156558}
2022-11-22 23:30:37,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:37,327 INFO:     Epoch: 83
2022-11-22 23:30:38,122 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7825848135081205, 'Total loss': 0.7825848135081205} | train loss {'Reaction outcome loss': 0.7995726663239148, 'Total loss': 0.7995726663239148}
2022-11-22 23:30:38,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:38,123 INFO:     Epoch: 84
2022-11-22 23:30:38,874 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8020993606610731, 'Total loss': 0.8020993606610731} | train loss {'Reaction outcome loss': 0.8017970697003968, 'Total loss': 0.8017970697003968}
2022-11-22 23:30:38,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:38,874 INFO:     Epoch: 85
2022-11-22 23:30:39,689 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7906930494037542, 'Total loss': 0.7906930494037542} | train loss {'Reaction outcome loss': 0.796285987265256, 'Total loss': 0.796285987265256}
2022-11-22 23:30:39,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:39,690 INFO:     Epoch: 86
2022-11-22 23:30:40,490 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7742962315678596, 'Total loss': 0.7742962315678596} | train loss {'Reaction outcome loss': 0.7985249572870683, 'Total loss': 0.7985249572870683}
2022-11-22 23:30:40,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:40,490 INFO:     Epoch: 87
2022-11-22 23:30:41,310 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7766196172345768, 'Total loss': 0.7766196172345768} | train loss {'Reaction outcome loss': 0.7993374217529686, 'Total loss': 0.7993374217529686}
2022-11-22 23:30:41,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:41,311 INFO:     Epoch: 88
2022-11-22 23:30:42,117 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7732067948037927, 'Total loss': 0.7732067948037927} | train loss {'Reaction outcome loss': 0.7926350813739154, 'Total loss': 0.7926350813739154}
2022-11-22 23:30:42,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:42,117 INFO:     Epoch: 89
2022-11-22 23:30:42,936 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7606421963057735, 'Total loss': 0.7606421963057735} | train loss {'Reaction outcome loss': 0.8005282629509362, 'Total loss': 0.8005282629509362}
2022-11-22 23:30:42,936 INFO:     Found new best model at epoch 89
2022-11-22 23:30:42,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:42,937 INFO:     Epoch: 90
2022-11-22 23:30:43,713 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7839310352097858, 'Total loss': 0.7839310352097858} | train loss {'Reaction outcome loss': 0.7984021509180264, 'Total loss': 0.7984021509180264}
2022-11-22 23:30:43,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:43,713 INFO:     Epoch: 91
2022-11-22 23:30:44,516 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7691389688036658, 'Total loss': 0.7691389688036658} | train loss {'Reaction outcome loss': 0.7952701019997499, 'Total loss': 0.7952701019997499}
2022-11-22 23:30:44,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:44,516 INFO:     Epoch: 92
2022-11-22 23:30:45,330 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.789606009694663, 'Total loss': 0.789606009694663} | train loss {'Reaction outcome loss': 0.8072091894490379, 'Total loss': 0.8072091894490379}
2022-11-22 23:30:45,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:45,331 INFO:     Epoch: 93
2022-11-22 23:30:46,179 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7777446007186716, 'Total loss': 0.7777446007186716} | train loss {'Reaction outcome loss': 0.8006720415183476, 'Total loss': 0.8006720415183476}
2022-11-22 23:30:46,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:46,179 INFO:     Epoch: 94
2022-11-22 23:30:46,969 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7773805240338499, 'Total loss': 0.7773805240338499} | train loss {'Reaction outcome loss': 0.8001108676803356, 'Total loss': 0.8001108676803356}
2022-11-22 23:30:46,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:46,969 INFO:     Epoch: 95
2022-11-22 23:30:47,761 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.801472510126504, 'Total loss': 0.801472510126504} | train loss {'Reaction outcome loss': 0.8003827199643972, 'Total loss': 0.8003827199643972}
2022-11-22 23:30:47,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:47,761 INFO:     Epoch: 96
2022-11-22 23:30:48,531 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7699801786379381, 'Total loss': 0.7699801786379381} | train loss {'Reaction outcome loss': 0.8038267240232351, 'Total loss': 0.8038267240232351}
2022-11-22 23:30:48,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:48,531 INFO:     Epoch: 97
2022-11-22 23:30:49,328 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7712267630479552, 'Total loss': 0.7712267630479552} | train loss {'Reaction outcome loss': 0.7981057960159924, 'Total loss': 0.7981057960159924}
2022-11-22 23:30:49,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:49,328 INFO:     Epoch: 98
2022-11-22 23:30:50,098 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7635459425774488, 'Total loss': 0.7635459425774488} | train loss {'Reaction outcome loss': 0.7978120118987804, 'Total loss': 0.7978120118987804}
2022-11-22 23:30:50,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:50,098 INFO:     Epoch: 99
2022-11-22 23:30:50,906 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8259074904701926, 'Total loss': 0.8259074904701926} | train loss {'Reaction outcome loss': 0.7955559445887196, 'Total loss': 0.7955559445887196}
2022-11-22 23:30:50,906 INFO:     Best model found after epoch 90 of 100.
2022-11-22 23:30:50,906 INFO:   Done with stage: TRAINING
2022-11-22 23:30:50,906 INFO:   Starting stage: EVALUATION
2022-11-22 23:30:51,037 INFO:   Done with stage: EVALUATION
2022-11-22 23:30:51,037 INFO:   Leaving out SEQ value Fold_5
2022-11-22 23:30:51,050 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:30:51,050 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:30:51,721 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:30:51,722 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:30:51,792 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:30:51,792 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:30:51,792 INFO:     No hyperparam tuning for this model
2022-11-22 23:30:51,792 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:30:51,792 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:30:51,793 INFO:     None feature selector for col prot
2022-11-22 23:30:51,793 INFO:     None feature selector for col prot
2022-11-22 23:30:51,793 INFO:     None feature selector for col prot
2022-11-22 23:30:51,794 INFO:     None feature selector for col chem
2022-11-22 23:30:51,794 INFO:     None feature selector for col chem
2022-11-22 23:30:51,794 INFO:     None feature selector for col chem
2022-11-22 23:30:51,794 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:30:51,794 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:30:51,796 INFO:     Number of params in model 168571
2022-11-22 23:30:51,799 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:30:51,799 INFO:   Starting stage: TRAINING
2022-11-22 23:30:51,857 INFO:     Val loss before train {'Reaction outcome loss': 1.0401870676062324, 'Total loss': 1.0401870676062324}
2022-11-22 23:30:51,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:51,857 INFO:     Epoch: 0
2022-11-22 23:30:52,678 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8511777208610014, 'Total loss': 0.8511777208610014} | train loss {'Reaction outcome loss': 0.8748792306433323, 'Total loss': 0.8748792306433323}
2022-11-22 23:30:52,678 INFO:     Found new best model at epoch 0
2022-11-22 23:30:52,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:52,679 INFO:     Epoch: 1
2022-11-22 23:30:53,486 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8595934347672896, 'Total loss': 0.8595934347672896} | train loss {'Reaction outcome loss': 0.8511822717151178, 'Total loss': 0.8511822717151178}
2022-11-22 23:30:53,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:53,486 INFO:     Epoch: 2
2022-11-22 23:30:54,309 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8518477522514083, 'Total loss': 0.8518477522514083} | train loss {'Reaction outcome loss': 0.8507319767224161, 'Total loss': 0.8507319767224161}
2022-11-22 23:30:54,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:54,310 INFO:     Epoch: 3
2022-11-22 23:30:55,102 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8334584960883314, 'Total loss': 0.8334584960883314} | train loss {'Reaction outcome loss': 0.8419695323114453, 'Total loss': 0.8419695323114453}
2022-11-22 23:30:55,102 INFO:     Found new best model at epoch 3
2022-11-22 23:30:55,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:55,103 INFO:     Epoch: 4
2022-11-22 23:30:55,928 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8726530434055761, 'Total loss': 0.8726530434055761} | train loss {'Reaction outcome loss': 0.8373642525209589, 'Total loss': 0.8373642525209589}
2022-11-22 23:30:55,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:55,929 INFO:     Epoch: 5
2022-11-22 23:30:56,778 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.83041616122831, 'Total loss': 0.83041616122831} | train loss {'Reaction outcome loss': 0.8356234556448604, 'Total loss': 0.8356234556448604}
2022-11-22 23:30:56,779 INFO:     Found new best model at epoch 5
2022-11-22 23:30:56,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:56,779 INFO:     Epoch: 6
2022-11-22 23:30:57,609 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8335866657170382, 'Total loss': 0.8335866657170382} | train loss {'Reaction outcome loss': 0.8357668194452278, 'Total loss': 0.8357668194452278}
2022-11-22 23:30:57,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:57,609 INFO:     Epoch: 7
2022-11-22 23:30:58,456 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8421888026324186, 'Total loss': 0.8421888026324186} | train loss {'Reaction outcome loss': 0.83139300539426, 'Total loss': 0.83139300539426}
2022-11-22 23:30:58,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:58,457 INFO:     Epoch: 8
2022-11-22 23:30:59,265 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8332512385465882, 'Total loss': 0.8332512385465882} | train loss {'Reaction outcome loss': 0.8284226100937075, 'Total loss': 0.8284226100937075}
2022-11-22 23:30:59,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:30:59,265 INFO:     Epoch: 9
2022-11-22 23:31:00,104 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8345380479639227, 'Total loss': 0.8345380479639227} | train loss {'Reaction outcome loss': 0.823137816147283, 'Total loss': 0.823137816147283}
2022-11-22 23:31:00,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:00,104 INFO:     Epoch: 10
2022-11-22 23:31:00,936 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8381991250948473, 'Total loss': 0.8381991250948473} | train loss {'Reaction outcome loss': 0.8255738827139742, 'Total loss': 0.8255738827139742}
2022-11-22 23:31:00,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:00,936 INFO:     Epoch: 11
2022-11-22 23:31:01,752 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8265710405328057, 'Total loss': 0.8265710405328057} | train loss {'Reaction outcome loss': 0.8255798693610589, 'Total loss': 0.8255798693610589}
2022-11-22 23:31:01,753 INFO:     Found new best model at epoch 11
2022-11-22 23:31:01,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:01,754 INFO:     Epoch: 12
2022-11-22 23:31:02,573 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8301174383271824, 'Total loss': 0.8301174383271824} | train loss {'Reaction outcome loss': 0.8242000428891858, 'Total loss': 0.8242000428891858}
2022-11-22 23:31:02,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:02,573 INFO:     Epoch: 13
2022-11-22 23:31:03,408 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8403782722624865, 'Total loss': 0.8403782722624865} | train loss {'Reaction outcome loss': 0.8169286115932078, 'Total loss': 0.8169286115932078}
2022-11-22 23:31:03,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:03,408 INFO:     Epoch: 14
2022-11-22 23:31:04,330 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8287465193054893, 'Total loss': 0.8287465193054893} | train loss {'Reaction outcome loss': 0.8304200623682153, 'Total loss': 0.8304200623682153}
2022-11-22 23:31:04,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:04,331 INFO:     Epoch: 15
2022-11-22 23:31:05,234 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8313651755452156, 'Total loss': 0.8313651755452156} | train loss {'Reaction outcome loss': 0.8200849349561491, 'Total loss': 0.8200849349561491}
2022-11-22 23:31:05,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:05,234 INFO:     Epoch: 16
2022-11-22 23:31:06,098 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8365180126645348, 'Total loss': 0.8365180126645348} | train loss {'Reaction outcome loss': 0.8239404312994799, 'Total loss': 0.8239404312994799}
2022-11-22 23:31:06,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:06,098 INFO:     Epoch: 17
2022-11-22 23:31:06,890 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8260925466364081, 'Total loss': 0.8260925466364081} | train loss {'Reaction outcome loss': 0.8219259859096666, 'Total loss': 0.8219259859096666}
2022-11-22 23:31:06,890 INFO:     Found new best model at epoch 17
2022-11-22 23:31:06,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:06,891 INFO:     Epoch: 18
2022-11-22 23:31:07,687 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.841802371496504, 'Total loss': 0.841802371496504} | train loss {'Reaction outcome loss': 0.8190692648713888, 'Total loss': 0.8190692648713888}
2022-11-22 23:31:07,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:07,688 INFO:     Epoch: 19
2022-11-22 23:31:08,517 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8368486965244467, 'Total loss': 0.8368486965244467} | train loss {'Reaction outcome loss': 0.8235180397265354, 'Total loss': 0.8235180397265354}
2022-11-22 23:31:08,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:08,518 INFO:     Epoch: 20
2022-11-22 23:31:09,360 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8440679514949972, 'Total loss': 0.8440679514949972} | train loss {'Reaction outcome loss': 0.8192270288341924, 'Total loss': 0.8192270288341924}
2022-11-22 23:31:09,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:09,360 INFO:     Epoch: 21
2022-11-22 23:31:10,156 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8154675303535028, 'Total loss': 0.8154675303535028} | train loss {'Reaction outcome loss': 0.821528325151456, 'Total loss': 0.821528325151456}
2022-11-22 23:31:10,156 INFO:     Found new best model at epoch 21
2022-11-22 23:31:10,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:10,157 INFO:     Epoch: 22
2022-11-22 23:31:10,962 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8326831040057269, 'Total loss': 0.8326831040057269} | train loss {'Reaction outcome loss': 0.817586553362217, 'Total loss': 0.817586553362217}
2022-11-22 23:31:10,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:10,962 INFO:     Epoch: 23
2022-11-22 23:31:11,778 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8407844169573351, 'Total loss': 0.8407844169573351} | train loss {'Reaction outcome loss': 0.8241572396354637, 'Total loss': 0.8241572396354637}
2022-11-22 23:31:11,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:11,778 INFO:     Epoch: 24
2022-11-22 23:31:12,574 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8317042474042285, 'Total loss': 0.8317042474042285} | train loss {'Reaction outcome loss': 0.8200488492303531, 'Total loss': 0.8200488492303531}
2022-11-22 23:31:12,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:12,575 INFO:     Epoch: 25
2022-11-22 23:31:13,369 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8268491368402134, 'Total loss': 0.8268491368402134} | train loss {'Reaction outcome loss': 0.8154659060995105, 'Total loss': 0.8154659060995105}
2022-11-22 23:31:13,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:13,370 INFO:     Epoch: 26
2022-11-22 23:31:14,157 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8345558826218952, 'Total loss': 0.8345558826218952} | train loss {'Reaction outcome loss': 0.82065627799343, 'Total loss': 0.82065627799343}
2022-11-22 23:31:14,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:14,158 INFO:     Epoch: 27
2022-11-22 23:31:14,914 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8270556100390174, 'Total loss': 0.8270556100390174} | train loss {'Reaction outcome loss': 0.8178995445913632, 'Total loss': 0.8178995445913632}
2022-11-22 23:31:14,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:14,914 INFO:     Epoch: 28
2022-11-22 23:31:15,715 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8164354786276817, 'Total loss': 0.8164354786276817} | train loss {'Reaction outcome loss': 0.8194049289110701, 'Total loss': 0.8194049289110701}
2022-11-22 23:31:15,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:15,715 INFO:     Epoch: 29
2022-11-22 23:31:16,503 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8277751220898195, 'Total loss': 0.8277751220898195} | train loss {'Reaction outcome loss': 0.814254744362976, 'Total loss': 0.814254744362976}
2022-11-22 23:31:16,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:16,504 INFO:     Epoch: 30
2022-11-22 23:31:17,321 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8239296187054027, 'Total loss': 0.8239296187054027} | train loss {'Reaction outcome loss': 0.8196226452526293, 'Total loss': 0.8196226452526293}
2022-11-22 23:31:17,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:17,321 INFO:     Epoch: 31
2022-11-22 23:31:18,117 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.821487230333415, 'Total loss': 0.821487230333415} | train loss {'Reaction outcome loss': 0.8178024708259444, 'Total loss': 0.8178024708259444}
2022-11-22 23:31:18,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:18,118 INFO:     Epoch: 32
2022-11-22 23:31:18,970 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8337105092677203, 'Total loss': 0.8337105092677203} | train loss {'Reaction outcome loss': 0.8190103485758006, 'Total loss': 0.8190103485758006}
2022-11-22 23:31:18,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:18,971 INFO:     Epoch: 33
2022-11-22 23:31:19,801 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8253955096006393, 'Total loss': 0.8253955096006393} | train loss {'Reaction outcome loss': 0.8177490767679716, 'Total loss': 0.8177490767679716}
2022-11-22 23:31:19,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:19,801 INFO:     Epoch: 34
2022-11-22 23:31:20,625 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8145029483871027, 'Total loss': 0.8145029483871027} | train loss {'Reaction outcome loss': 0.8184095878108792, 'Total loss': 0.8184095878108792}
2022-11-22 23:31:20,625 INFO:     Found new best model at epoch 34
2022-11-22 23:31:20,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:20,627 INFO:     Epoch: 35
2022-11-22 23:31:21,407 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8195033926855434, 'Total loss': 0.8195033926855434} | train loss {'Reaction outcome loss': 0.816438430173677, 'Total loss': 0.816438430173677}
2022-11-22 23:31:21,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:21,407 INFO:     Epoch: 36
2022-11-22 23:31:22,214 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8073931085792455, 'Total loss': 0.8073931085792455} | train loss {'Reaction outcome loss': 0.8153836629410022, 'Total loss': 0.8153836629410022}
2022-11-22 23:31:22,214 INFO:     Found new best model at epoch 36
2022-11-22 23:31:22,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:22,215 INFO:     Epoch: 37
2022-11-22 23:31:23,041 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8088473203507337, 'Total loss': 0.8088473203507337} | train loss {'Reaction outcome loss': 0.8150704552528829, 'Total loss': 0.8150704552528829}
2022-11-22 23:31:23,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:23,042 INFO:     Epoch: 38
2022-11-22 23:31:23,877 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8186364234848456, 'Total loss': 0.8186364234848456} | train loss {'Reaction outcome loss': 0.8140608172426339, 'Total loss': 0.8140608172426339}
2022-11-22 23:31:23,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:23,878 INFO:     Epoch: 39
2022-11-22 23:31:24,743 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8274016712199558, 'Total loss': 0.8274016712199558} | train loss {'Reaction outcome loss': 0.8169420331957852, 'Total loss': 0.8169420331957852}
2022-11-22 23:31:24,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:24,743 INFO:     Epoch: 40
2022-11-22 23:31:25,561 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8207222521305084, 'Total loss': 0.8207222521305084} | train loss {'Reaction outcome loss': 0.8175619719964773, 'Total loss': 0.8175619719964773}
2022-11-22 23:31:25,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:25,561 INFO:     Epoch: 41
2022-11-22 23:31:26,368 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8420628688552163, 'Total loss': 0.8420628688552163} | train loss {'Reaction outcome loss': 0.8118991382450227, 'Total loss': 0.8118991382450227}
2022-11-22 23:31:26,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:26,369 INFO:     Epoch: 42
2022-11-22 23:31:27,165 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.833647994832559, 'Total loss': 0.833647994832559} | train loss {'Reaction outcome loss': 0.8149746130352561, 'Total loss': 0.8149746130352561}
2022-11-22 23:31:27,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:27,165 INFO:     Epoch: 43
2022-11-22 23:31:27,978 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.820427267388864, 'Total loss': 0.820427267388864} | train loss {'Reaction outcome loss': 0.8231909014435432, 'Total loss': 0.8231909014435432}
2022-11-22 23:31:27,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:27,978 INFO:     Epoch: 44
2022-11-22 23:31:28,802 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8293125162070448, 'Total loss': 0.8293125162070448} | train loss {'Reaction outcome loss': 0.811969364099657, 'Total loss': 0.811969364099657}
2022-11-22 23:31:28,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:28,802 INFO:     Epoch: 45
2022-11-22 23:31:29,604 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8334407359361649, 'Total loss': 0.8334407359361649} | train loss {'Reaction outcome loss': 0.8117022743591895, 'Total loss': 0.8117022743591895}
2022-11-22 23:31:29,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:29,605 INFO:     Epoch: 46
2022-11-22 23:31:30,474 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8275762999599631, 'Total loss': 0.8275762999599631} | train loss {'Reaction outcome loss': 0.8139347415040379, 'Total loss': 0.8139347415040379}
2022-11-22 23:31:30,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:30,475 INFO:     Epoch: 47
2022-11-22 23:31:31,335 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.831046153198589, 'Total loss': 0.831046153198589} | train loss {'Reaction outcome loss': 0.8179417388883197, 'Total loss': 0.8179417388883197}
2022-11-22 23:31:31,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:31,336 INFO:     Epoch: 48
2022-11-22 23:31:32,177 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8180517473004081, 'Total loss': 0.8180517473004081} | train loss {'Reaction outcome loss': 0.8175895576655623, 'Total loss': 0.8175895576655623}
2022-11-22 23:31:32,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:32,178 INFO:     Epoch: 49
2022-11-22 23:31:32,950 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8371154611760919, 'Total loss': 0.8371154611760919} | train loss {'Reaction outcome loss': 0.8160832946599736, 'Total loss': 0.8160832946599736}
2022-11-22 23:31:32,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:32,950 INFO:     Epoch: 50
2022-11-22 23:31:33,778 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8140922784805298, 'Total loss': 0.8140922784805298} | train loss {'Reaction outcome loss': 0.8211542340033209, 'Total loss': 0.8211542340033209}
2022-11-22 23:31:33,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:33,778 INFO:     Epoch: 51
2022-11-22 23:31:34,636 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8345235057852485, 'Total loss': 0.8345235057852485} | train loss {'Reaction outcome loss': 0.8099891747298994, 'Total loss': 0.8099891747298994}
2022-11-22 23:31:34,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:34,637 INFO:     Epoch: 52
2022-11-22 23:31:35,497 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8310439532453363, 'Total loss': 0.8310439532453363} | train loss {'Reaction outcome loss': 0.8116427479756747, 'Total loss': 0.8116427479756747}
2022-11-22 23:31:35,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:35,499 INFO:     Epoch: 53
2022-11-22 23:31:36,273 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8110516152598641, 'Total loss': 0.8110516152598641} | train loss {'Reaction outcome loss': 0.8087106442403215, 'Total loss': 0.8087106442403215}
2022-11-22 23:31:36,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:36,273 INFO:     Epoch: 54
2022-11-22 23:31:37,109 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.81326885656877, 'Total loss': 0.81326885656877} | train loss {'Reaction outcome loss': 0.8091274326146856, 'Total loss': 0.8091274326146856}
2022-11-22 23:31:37,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:37,110 INFO:     Epoch: 55
2022-11-22 23:31:37,921 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8141668113795194, 'Total loss': 0.8141668113795194} | train loss {'Reaction outcome loss': 0.8150150489046989, 'Total loss': 0.8150150489046989}
2022-11-22 23:31:37,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:37,921 INFO:     Epoch: 56
2022-11-22 23:31:38,703 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8161076754331589, 'Total loss': 0.8161076754331589} | train loss {'Reaction outcome loss': 0.8094822252206957, 'Total loss': 0.8094822252206957}
2022-11-22 23:31:38,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:38,703 INFO:     Epoch: 57
2022-11-22 23:31:39,512 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8125843595374714, 'Total loss': 0.8125843595374714} | train loss {'Reaction outcome loss': 0.8058403998251386, 'Total loss': 0.8058403998251386}
2022-11-22 23:31:39,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:39,513 INFO:     Epoch: 58
2022-11-22 23:31:40,349 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.82317408377474, 'Total loss': 0.82317408377474} | train loss {'Reaction outcome loss': 0.8103125056907957, 'Total loss': 0.8103125056907957}
2022-11-22 23:31:40,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:40,350 INFO:     Epoch: 59
2022-11-22 23:31:41,189 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8121503198688681, 'Total loss': 0.8121503198688681} | train loss {'Reaction outcome loss': 0.8098943095714578, 'Total loss': 0.8098943095714578}
2022-11-22 23:31:41,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:41,189 INFO:     Epoch: 60
2022-11-22 23:31:41,949 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8255369338122281, 'Total loss': 0.8255369338122281} | train loss {'Reaction outcome loss': 0.805216973519277, 'Total loss': 0.805216973519277}
2022-11-22 23:31:41,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:41,949 INFO:     Epoch: 61
2022-11-22 23:31:42,809 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8272716660391201, 'Total loss': 0.8272716660391201} | train loss {'Reaction outcome loss': 0.8129765421815729, 'Total loss': 0.8129765421815729}
2022-11-22 23:31:42,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:42,809 INFO:     Epoch: 62
2022-11-22 23:31:43,613 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8146138184449889, 'Total loss': 0.8146138184449889} | train loss {'Reaction outcome loss': 0.8164235057859768, 'Total loss': 0.8164235057859768}
2022-11-22 23:31:43,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:43,613 INFO:     Epoch: 63
2022-11-22 23:31:44,437 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8451927168802782, 'Total loss': 0.8451927168802782} | train loss {'Reaction outcome loss': 0.8089832084381628, 'Total loss': 0.8089832084381628}
2022-11-22 23:31:44,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:44,437 INFO:     Epoch: 64
2022-11-22 23:31:45,214 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8194329711523923, 'Total loss': 0.8194329711523923} | train loss {'Reaction outcome loss': 0.8108589890514791, 'Total loss': 0.8108589890514791}
2022-11-22 23:31:45,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:45,215 INFO:     Epoch: 65
2022-11-22 23:31:46,066 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8176123357631944, 'Total loss': 0.8176123357631944} | train loss {'Reaction outcome loss': 0.8090789084009796, 'Total loss': 0.8090789084009796}
2022-11-22 23:31:46,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:46,066 INFO:     Epoch: 66
2022-11-22 23:31:46,899 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.824581497094848, 'Total loss': 0.824581497094848} | train loss {'Reaction outcome loss': 0.8117911105575831, 'Total loss': 0.8117911105575831}
2022-11-22 23:31:46,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:46,899 INFO:     Epoch: 67
2022-11-22 23:31:47,763 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8170180402018807, 'Total loss': 0.8170180402018807} | train loss {'Reaction outcome loss': 0.8139110872378716, 'Total loss': 0.8139110872378716}
2022-11-22 23:31:47,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:47,764 INFO:     Epoch: 68
2022-11-22 23:31:48,577 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8292276385155591, 'Total loss': 0.8292276385155591} | train loss {'Reaction outcome loss': 0.8174257236212371, 'Total loss': 0.8174257236212371}
2022-11-22 23:31:48,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:48,578 INFO:     Epoch: 69
2022-11-22 23:31:49,376 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8310824382034215, 'Total loss': 0.8310824382034215} | train loss {'Reaction outcome loss': 0.8149419464321754, 'Total loss': 0.8149419464321754}
2022-11-22 23:31:49,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:49,377 INFO:     Epoch: 70
2022-11-22 23:31:50,208 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8297616744583304, 'Total loss': 0.8297616744583304} | train loss {'Reaction outcome loss': 0.8154383679391884, 'Total loss': 0.8154383679391884}
2022-11-22 23:31:50,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:50,208 INFO:     Epoch: 71
2022-11-22 23:31:51,009 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8257006027481772, 'Total loss': 0.8257006027481772} | train loss {'Reaction outcome loss': 0.8166494550492599, 'Total loss': 0.8166494550492599}
2022-11-22 23:31:51,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:51,009 INFO:     Epoch: 72
2022-11-22 23:31:51,824 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8202036795291033, 'Total loss': 0.8202036795291033} | train loss {'Reaction outcome loss': 0.8083573387943299, 'Total loss': 0.8083573387943299}
2022-11-22 23:31:51,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:51,824 INFO:     Epoch: 73
2022-11-22 23:31:52,661 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8154431479898366, 'Total loss': 0.8154431479898366} | train loss {'Reaction outcome loss': 0.8087606077131472, 'Total loss': 0.8087606077131472}
2022-11-22 23:31:52,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:52,661 INFO:     Epoch: 74
2022-11-22 23:31:53,452 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8368927856737917, 'Total loss': 0.8368927856737917} | train loss {'Reaction outcome loss': 0.81528790596767, 'Total loss': 0.81528790596767}
2022-11-22 23:31:53,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:53,452 INFO:     Epoch: 75
2022-11-22 23:31:54,255 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8350729231129993, 'Total loss': 0.8350729231129993} | train loss {'Reaction outcome loss': 0.8106571203059996, 'Total loss': 0.8106571203059996}
2022-11-22 23:31:54,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:54,256 INFO:     Epoch: 76
2022-11-22 23:31:55,051 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8374070200053129, 'Total loss': 0.8374070200053129} | train loss {'Reaction outcome loss': 0.8127401140537339, 'Total loss': 0.8127401140537339}
2022-11-22 23:31:55,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:55,051 INFO:     Epoch: 77
2022-11-22 23:31:55,971 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8037417287176306, 'Total loss': 0.8037417287176306} | train loss {'Reaction outcome loss': 0.8157106321832912, 'Total loss': 0.8157106321832912}
2022-11-22 23:31:55,972 INFO:     Found new best model at epoch 77
2022-11-22 23:31:55,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:55,973 INFO:     Epoch: 78
2022-11-22 23:31:56,872 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8047319420359351, 'Total loss': 0.8047319420359351} | train loss {'Reaction outcome loss': 0.8136517150923308, 'Total loss': 0.8136517150923308}
2022-11-22 23:31:56,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:56,872 INFO:     Epoch: 79
2022-11-22 23:31:57,720 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8332167498090051, 'Total loss': 0.8332167498090051} | train loss {'Reaction outcome loss': 0.807653366011164, 'Total loss': 0.807653366011164}
2022-11-22 23:31:57,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:57,720 INFO:     Epoch: 80
2022-11-22 23:31:58,609 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8103876269676469, 'Total loss': 0.8103876269676469} | train loss {'Reaction outcome loss': 0.810248237631099, 'Total loss': 0.810248237631099}
2022-11-22 23:31:58,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:58,609 INFO:     Epoch: 81
2022-11-22 23:31:59,462 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8259707113558595, 'Total loss': 0.8259707113558595} | train loss {'Reaction outcome loss': 0.8127380210137077, 'Total loss': 0.8127380210137077}
2022-11-22 23:31:59,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:31:59,463 INFO:     Epoch: 82
2022-11-22 23:32:00,298 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8462447029623118, 'Total loss': 0.8462447029623118} | train loss {'Reaction outcome loss': 0.8175044114049147, 'Total loss': 0.8175044114049147}
2022-11-22 23:32:00,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:00,298 INFO:     Epoch: 83
2022-11-22 23:32:01,184 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8249088085510514, 'Total loss': 0.8249088085510514} | train loss {'Reaction outcome loss': 0.8147148415144638, 'Total loss': 0.8147148415144638}
2022-11-22 23:32:01,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:01,185 INFO:     Epoch: 84
2022-11-22 23:32:02,093 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8213900537653402, 'Total loss': 0.8213900537653402} | train loss {'Reaction outcome loss': 0.8104113074932021, 'Total loss': 0.8104113074932021}
2022-11-22 23:32:02,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:02,093 INFO:     Epoch: 85
2022-11-22 23:32:02,972 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8116662143306299, 'Total loss': 0.8116662143306299} | train loss {'Reaction outcome loss': 0.8062667625877056, 'Total loss': 0.8062667625877056}
2022-11-22 23:32:02,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:02,972 INFO:     Epoch: 86
2022-11-22 23:32:03,869 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.817289218983867, 'Total loss': 0.817289218983867} | train loss {'Reaction outcome loss': 0.821181807561442, 'Total loss': 0.821181807561442}
2022-11-22 23:32:03,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:03,869 INFO:     Epoch: 87
2022-11-22 23:32:04,747 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.81098503687165, 'Total loss': 0.81098503687165} | train loss {'Reaction outcome loss': 0.815218695563826, 'Total loss': 0.815218695563826}
2022-11-22 23:32:04,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:04,747 INFO:     Epoch: 88
2022-11-22 23:32:05,682 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8378457880832932, 'Total loss': 0.8378457880832932} | train loss {'Reaction outcome loss': 0.8148179891621053, 'Total loss': 0.8148179891621053}
2022-11-22 23:32:05,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:05,683 INFO:     Epoch: 89
2022-11-22 23:32:06,576 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8190548501231454, 'Total loss': 0.8190548501231454} | train loss {'Reaction outcome loss': 0.8105722532460564, 'Total loss': 0.8105722532460564}
2022-11-22 23:32:06,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:06,577 INFO:     Epoch: 90
2022-11-22 23:32:07,506 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8341294892809608, 'Total loss': 0.8341294892809608} | train loss {'Reaction outcome loss': 0.8256873429304192, 'Total loss': 0.8256873429304192}
2022-11-22 23:32:07,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:07,506 INFO:     Epoch: 91
2022-11-22 23:32:08,391 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.812257594005628, 'Total loss': 0.812257594005628} | train loss {'Reaction outcome loss': 0.8049047417365588, 'Total loss': 0.8049047417365588}
2022-11-22 23:32:08,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:08,391 INFO:     Epoch: 92
2022-11-22 23:32:09,296 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8509056473320181, 'Total loss': 0.8509056473320181} | train loss {'Reaction outcome loss': 0.809305071468778, 'Total loss': 0.809305071468778}
2022-11-22 23:32:09,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:09,297 INFO:     Epoch: 93
2022-11-22 23:32:10,210 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.819601300087842, 'Total loss': 0.819601300087842} | train loss {'Reaction outcome loss': 0.811995873687721, 'Total loss': 0.811995873687721}
2022-11-22 23:32:10,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:10,211 INFO:     Epoch: 94
2022-11-22 23:32:11,140 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8341464136134494, 'Total loss': 0.8341464136134494} | train loss {'Reaction outcome loss': 0.8166802164755369, 'Total loss': 0.8166802164755369}
2022-11-22 23:32:11,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:11,140 INFO:     Epoch: 95
2022-11-22 23:32:12,051 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8317750597541983, 'Total loss': 0.8317750597541983} | train loss {'Reaction outcome loss': 0.8176261961369621, 'Total loss': 0.8176261961369621}
2022-11-22 23:32:12,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:12,051 INFO:     Epoch: 96
2022-11-22 23:32:12,969 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8527762781489979, 'Total loss': 0.8527762781489979} | train loss {'Reaction outcome loss': 0.8158012734733613, 'Total loss': 0.8158012734733613}
2022-11-22 23:32:12,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:12,969 INFO:     Epoch: 97
2022-11-22 23:32:13,861 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8336985470219092, 'Total loss': 0.8336985470219092} | train loss {'Reaction outcome loss': 0.8184258616887606, 'Total loss': 0.8184258616887606}
2022-11-22 23:32:13,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:13,861 INFO:     Epoch: 98
2022-11-22 23:32:14,743 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8629123446616259, 'Total loss': 0.8629123446616259} | train loss {'Reaction outcome loss': 0.8193557988776852, 'Total loss': 0.8193557988776852}
2022-11-22 23:32:14,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:14,743 INFO:     Epoch: 99
2022-11-22 23:32:15,618 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8255679336461154, 'Total loss': 0.8255679336461154} | train loss {'Reaction outcome loss': 0.8158346649847532, 'Total loss': 0.8158346649847532}
2022-11-22 23:32:15,619 INFO:     Best model found after epoch 78 of 100.
2022-11-22 23:32:15,619 INFO:   Done with stage: TRAINING
2022-11-22 23:32:15,619 INFO:   Starting stage: EVALUATION
2022-11-22 23:32:15,764 INFO:   Done with stage: EVALUATION
2022-11-22 23:32:15,764 INFO:   Leaving out SEQ value Fold_6
2022-11-22 23:32:15,778 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 23:32:15,778 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:32:16,462 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:32:16,462 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:32:16,534 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:32:16,535 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:32:16,535 INFO:     No hyperparam tuning for this model
2022-11-22 23:32:16,535 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:32:16,535 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:32:16,536 INFO:     None feature selector for col prot
2022-11-22 23:32:16,536 INFO:     None feature selector for col prot
2022-11-22 23:32:16,536 INFO:     None feature selector for col prot
2022-11-22 23:32:16,536 INFO:     None feature selector for col chem
2022-11-22 23:32:16,537 INFO:     None feature selector for col chem
2022-11-22 23:32:16,537 INFO:     None feature selector for col chem
2022-11-22 23:32:16,537 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:32:16,537 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:32:16,538 INFO:     Number of params in model 168571
2022-11-22 23:32:16,542 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:32:16,542 INFO:   Starting stage: TRAINING
2022-11-22 23:32:16,602 INFO:     Val loss before train {'Reaction outcome loss': 1.003685449334708, 'Total loss': 1.003685449334708}
2022-11-22 23:32:16,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:16,602 INFO:     Epoch: 0
2022-11-22 23:32:17,513 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9210673489353873, 'Total loss': 0.9210673489353873} | train loss {'Reaction outcome loss': 0.880026044263955, 'Total loss': 0.880026044263955}
2022-11-22 23:32:17,513 INFO:     Found new best model at epoch 0
2022-11-22 23:32:17,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:17,514 INFO:     Epoch: 1
2022-11-22 23:32:18,354 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8696012442762201, 'Total loss': 0.8696012442762201} | train loss {'Reaction outcome loss': 0.8489245097002676, 'Total loss': 0.8489245097002676}
2022-11-22 23:32:18,355 INFO:     Found new best model at epoch 1
2022-11-22 23:32:18,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:18,356 INFO:     Epoch: 2
2022-11-22 23:32:19,252 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8566366539082744, 'Total loss': 0.8566366539082744} | train loss {'Reaction outcome loss': 0.856821313620575, 'Total loss': 0.856821313620575}
2022-11-22 23:32:19,252 INFO:     Found new best model at epoch 2
2022-11-22 23:32:19,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:19,253 INFO:     Epoch: 3
2022-11-22 23:32:20,106 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8420240052721717, 'Total loss': 0.8420240052721717} | train loss {'Reaction outcome loss': 0.8429208663442442, 'Total loss': 0.8429208663442442}
2022-11-22 23:32:20,106 INFO:     Found new best model at epoch 3
2022-11-22 23:32:20,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:20,107 INFO:     Epoch: 4
2022-11-22 23:32:21,026 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8232313238761642, 'Total loss': 0.8232313238761642} | train loss {'Reaction outcome loss': 0.8443764916831448, 'Total loss': 0.8443764916831448}
2022-11-22 23:32:21,026 INFO:     Found new best model at epoch 4
2022-11-22 23:32:21,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:21,027 INFO:     Epoch: 5
2022-11-22 23:32:21,991 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8391905318606984, 'Total loss': 0.8391905318606984} | train loss {'Reaction outcome loss': 0.8370325568943254, 'Total loss': 0.8370325568943254}
2022-11-22 23:32:21,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:21,991 INFO:     Epoch: 6
2022-11-22 23:32:22,912 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8252929184924472, 'Total loss': 0.8252929184924472} | train loss {'Reaction outcome loss': 0.8336043748403749, 'Total loss': 0.8336043748403749}
2022-11-22 23:32:22,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:22,912 INFO:     Epoch: 7
2022-11-22 23:32:23,778 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8362584215673533, 'Total loss': 0.8362584215673533} | train loss {'Reaction outcome loss': 0.8319540296591097, 'Total loss': 0.8319540296591097}
2022-11-22 23:32:23,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:23,778 INFO:     Epoch: 8
2022-11-22 23:32:24,633 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.830043838782744, 'Total loss': 0.830043838782744} | train loss {'Reaction outcome loss': 0.8292694573681201, 'Total loss': 0.8292694573681201}
2022-11-22 23:32:24,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:24,635 INFO:     Epoch: 9
2022-11-22 23:32:25,491 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8263310925527052, 'Total loss': 0.8263310925527052} | train loss {'Reaction outcome loss': 0.831600412486061, 'Total loss': 0.831600412486061}
2022-11-22 23:32:25,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:25,491 INFO:     Epoch: 10
2022-11-22 23:32:26,405 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8163651871410283, 'Total loss': 0.8163651871410283} | train loss {'Reaction outcome loss': 0.8290516289491807, 'Total loss': 0.8290516289491807}
2022-11-22 23:32:26,405 INFO:     Found new best model at epoch 10
2022-11-22 23:32:26,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:26,406 INFO:     Epoch: 11
2022-11-22 23:32:27,277 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.838455549695275, 'Total loss': 0.838455549695275} | train loss {'Reaction outcome loss': 0.8308648480282675, 'Total loss': 0.8308648480282675}
2022-11-22 23:32:27,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:27,277 INFO:     Epoch: 12
2022-11-22 23:32:28,173 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8283624418757178, 'Total loss': 0.8283624418757178} | train loss {'Reaction outcome loss': 0.8282042158947837, 'Total loss': 0.8282042158947837}
2022-11-22 23:32:28,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:28,174 INFO:     Epoch: 13
2022-11-22 23:32:29,030 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8206577334891666, 'Total loss': 0.8206577334891666} | train loss {'Reaction outcome loss': 0.8259357352170252, 'Total loss': 0.8259357352170252}
2022-11-22 23:32:29,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:29,030 INFO:     Epoch: 14
2022-11-22 23:32:29,873 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8258715481920675, 'Total loss': 0.8258715481920675} | train loss {'Reaction outcome loss': 0.8238759359284755, 'Total loss': 0.8238759359284755}
2022-11-22 23:32:29,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:29,873 INFO:     Epoch: 15
2022-11-22 23:32:30,773 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8321556218645789, 'Total loss': 0.8321556218645789} | train loss {'Reaction outcome loss': 0.8283015894553354, 'Total loss': 0.8283015894553354}
2022-11-22 23:32:30,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:30,773 INFO:     Epoch: 16
2022-11-22 23:32:31,670 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8562827164476569, 'Total loss': 0.8562827164476569} | train loss {'Reaction outcome loss': 0.8261770557972693, 'Total loss': 0.8261770557972693}
2022-11-22 23:32:31,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:31,670 INFO:     Epoch: 17
2022-11-22 23:32:32,557 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8115879419175062, 'Total loss': 0.8115879419175062} | train loss {'Reaction outcome loss': 0.8259273969358013, 'Total loss': 0.8259273969358013}
2022-11-22 23:32:32,557 INFO:     Found new best model at epoch 17
2022-11-22 23:32:32,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:32,558 INFO:     Epoch: 18
2022-11-22 23:32:33,447 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8161886788227342, 'Total loss': 0.8161886788227342} | train loss {'Reaction outcome loss': 0.8250548475452008, 'Total loss': 0.8250548475452008}
2022-11-22 23:32:33,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:33,447 INFO:     Epoch: 19
2022-11-22 23:32:34,339 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8231678726998243, 'Total loss': 0.8231678726998243} | train loss {'Reaction outcome loss': 0.8218303628025516, 'Total loss': 0.8218303628025516}
2022-11-22 23:32:34,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:34,339 INFO:     Epoch: 20
2022-11-22 23:32:35,213 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8233645206147974, 'Total loss': 0.8233645206147974} | train loss {'Reaction outcome loss': 0.8231825887435867, 'Total loss': 0.8231825887435867}
2022-11-22 23:32:35,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:35,214 INFO:     Epoch: 21
2022-11-22 23:32:36,053 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8250903548164801, 'Total loss': 0.8250903548164801} | train loss {'Reaction outcome loss': 0.8222028876264249, 'Total loss': 0.8222028876264249}
2022-11-22 23:32:36,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:36,053 INFO:     Epoch: 22
2022-11-22 23:32:36,926 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8118234100666913, 'Total loss': 0.8118234100666913} | train loss {'Reaction outcome loss': 0.8202460301258871, 'Total loss': 0.8202460301258871}
2022-11-22 23:32:36,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:36,927 INFO:     Epoch: 23
2022-11-22 23:32:37,874 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8441557504914023, 'Total loss': 0.8441557504914023} | train loss {'Reaction outcome loss': 0.8182514871080075, 'Total loss': 0.8182514871080075}
2022-11-22 23:32:37,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:37,874 INFO:     Epoch: 24
2022-11-22 23:32:38,721 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8076612515883013, 'Total loss': 0.8076612515883013} | train loss {'Reaction outcome loss': 0.8236746701502031, 'Total loss': 0.8236746701502031}
2022-11-22 23:32:38,721 INFO:     Found new best model at epoch 24
2022-11-22 23:32:38,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:38,722 INFO:     Epoch: 25
2022-11-22 23:32:39,594 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8234165432778272, 'Total loss': 0.8234165432778272} | train loss {'Reaction outcome loss': 0.8267408145531532, 'Total loss': 0.8267408145531532}
2022-11-22 23:32:39,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:39,594 INFO:     Epoch: 26
2022-11-22 23:32:40,519 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8263881457122889, 'Total loss': 0.8263881457122889} | train loss {'Reaction outcome loss': 0.8232176878279255, 'Total loss': 0.8232176878279255}
2022-11-22 23:32:40,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:40,519 INFO:     Epoch: 27
2022-11-22 23:32:41,398 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.829897100275213, 'Total loss': 0.829897100275213} | train loss {'Reaction outcome loss': 0.8240988944326678, 'Total loss': 0.8240988944326678}
2022-11-22 23:32:41,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:41,398 INFO:     Epoch: 28
2022-11-22 23:32:42,297 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8216713335026394, 'Total loss': 0.8216713335026394} | train loss {'Reaction outcome loss': 0.8191080947797145, 'Total loss': 0.8191080947797145}
2022-11-22 23:32:42,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:42,297 INFO:     Epoch: 29
2022-11-22 23:32:43,165 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8173062706535513, 'Total loss': 0.8173062706535513} | train loss {'Reaction outcome loss': 0.8221878768695939, 'Total loss': 0.8221878768695939}
2022-11-22 23:32:43,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:43,165 INFO:     Epoch: 30
2022-11-22 23:32:44,047 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8144482509656386, 'Total loss': 0.8144482509656386} | train loss {'Reaction outcome loss': 0.819689746886011, 'Total loss': 0.819689746886011}
2022-11-22 23:32:44,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:44,048 INFO:     Epoch: 31
2022-11-22 23:32:44,879 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8155643113634803, 'Total loss': 0.8155643113634803} | train loss {'Reaction outcome loss': 0.8253252807884447, 'Total loss': 0.8253252807884447}
2022-11-22 23:32:44,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:44,879 INFO:     Epoch: 32
2022-11-22 23:32:45,723 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.811963867734779, 'Total loss': 0.811963867734779} | train loss {'Reaction outcome loss': 0.8207329518852695, 'Total loss': 0.8207329518852695}
2022-11-22 23:32:45,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:45,724 INFO:     Epoch: 33
2022-11-22 23:32:46,570 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8240017200058157, 'Total loss': 0.8240017200058157} | train loss {'Reaction outcome loss': 0.8242307824473227, 'Total loss': 0.8242307824473227}
2022-11-22 23:32:46,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:46,571 INFO:     Epoch: 34
2022-11-22 23:32:47,407 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8158787935972214, 'Total loss': 0.8158787935972214} | train loss {'Reaction outcome loss': 0.8222561364452685, 'Total loss': 0.8222561364452685}
2022-11-22 23:32:47,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:47,407 INFO:     Epoch: 35
2022-11-22 23:32:48,249 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8195426382801749, 'Total loss': 0.8195426382801749} | train loss {'Reaction outcome loss': 0.8197106410178446, 'Total loss': 0.8197106410178446}
2022-11-22 23:32:48,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:48,249 INFO:     Epoch: 36
2022-11-22 23:32:49,054 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.82023770023476, 'Total loss': 0.82023770023476} | train loss {'Reaction outcome loss': 0.8228408356587733, 'Total loss': 0.8228408356587733}
2022-11-22 23:32:49,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:49,055 INFO:     Epoch: 37
2022-11-22 23:32:49,911 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8205303515900265, 'Total loss': 0.8205303515900265} | train loss {'Reaction outcome loss': 0.8203401421346972, 'Total loss': 0.8203401421346972}
2022-11-22 23:32:49,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:49,912 INFO:     Epoch: 38
2022-11-22 23:32:50,756 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8277862336147915, 'Total loss': 0.8277862336147915} | train loss {'Reaction outcome loss': 0.8182151703344237, 'Total loss': 0.8182151703344237}
2022-11-22 23:32:50,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:50,756 INFO:     Epoch: 39
2022-11-22 23:32:51,560 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8194962367415428, 'Total loss': 0.8194962367415428} | train loss {'Reaction outcome loss': 0.8255412853773563, 'Total loss': 0.8255412853773563}
2022-11-22 23:32:51,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:51,561 INFO:     Epoch: 40
2022-11-22 23:32:52,404 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8254261660304937, 'Total loss': 0.8254261660304937} | train loss {'Reaction outcome loss': 0.819248890684497, 'Total loss': 0.819248890684497}
2022-11-22 23:32:52,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:52,405 INFO:     Epoch: 41
2022-11-22 23:32:53,268 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8125580379908736, 'Total loss': 0.8125580379908736} | train loss {'Reaction outcome loss': 0.8157987674517978, 'Total loss': 0.8157987674517978}
2022-11-22 23:32:53,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:53,269 INFO:     Epoch: 42
2022-11-22 23:32:54,084 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8124434053897858, 'Total loss': 0.8124434053897858} | train loss {'Reaction outcome loss': 0.8194484077394009, 'Total loss': 0.8194484077394009}
2022-11-22 23:32:54,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:54,084 INFO:     Epoch: 43
2022-11-22 23:32:54,920 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8255577642809261, 'Total loss': 0.8255577642809261} | train loss {'Reaction outcome loss': 0.8225852705297931, 'Total loss': 0.8225852705297931}
2022-11-22 23:32:54,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:54,920 INFO:     Epoch: 44
2022-11-22 23:32:55,741 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8132574476978995, 'Total loss': 0.8132574476978995} | train loss {'Reaction outcome loss': 0.8204370459481594, 'Total loss': 0.8204370459481594}
2022-11-22 23:32:55,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:55,742 INFO:     Epoch: 45
2022-11-22 23:32:56,542 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8113050887530501, 'Total loss': 0.8113050887530501} | train loss {'Reaction outcome loss': 0.8206596637685453, 'Total loss': 0.8206596637685453}
2022-11-22 23:32:56,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:56,543 INFO:     Epoch: 46
2022-11-22 23:32:57,390 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8435290902853012, 'Total loss': 0.8435290902853012} | train loss {'Reaction outcome loss': 0.8191463958111501, 'Total loss': 0.8191463958111501}
2022-11-22 23:32:57,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:57,390 INFO:     Epoch: 47
2022-11-22 23:32:58,198 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8045245964418758, 'Total loss': 0.8045245964418758} | train loss {'Reaction outcome loss': 0.8223520570224331, 'Total loss': 0.8223520570224331}
2022-11-22 23:32:58,198 INFO:     Found new best model at epoch 47
2022-11-22 23:32:58,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:58,199 INFO:     Epoch: 48
2022-11-22 23:32:59,033 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8297983028671958, 'Total loss': 0.8297983028671958} | train loss {'Reaction outcome loss': 0.8183217680742664, 'Total loss': 0.8183217680742664}
2022-11-22 23:32:59,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:59,034 INFO:     Epoch: 49
2022-11-22 23:32:59,880 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8355810479684309, 'Total loss': 0.8355810479684309} | train loss {'Reaction outcome loss': 0.8208122859078069, 'Total loss': 0.8208122859078069}
2022-11-22 23:32:59,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:32:59,880 INFO:     Epoch: 50
2022-11-22 23:33:00,682 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8114079338583079, 'Total loss': 0.8114079338583079} | train loss {'Reaction outcome loss': 0.8171722363800772, 'Total loss': 0.8171722363800772}
2022-11-22 23:33:00,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:00,683 INFO:     Epoch: 51
2022-11-22 23:33:01,546 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8142333328723907, 'Total loss': 0.8142333328723907} | train loss {'Reaction outcome loss': 0.8155265312281347, 'Total loss': 0.8155265312281347}
2022-11-22 23:33:01,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:01,546 INFO:     Epoch: 52
2022-11-22 23:33:02,361 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8059993264350024, 'Total loss': 0.8059993264350024} | train loss {'Reaction outcome loss': 0.8186033299613383, 'Total loss': 0.8186033299613383}
2022-11-22 23:33:02,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:02,362 INFO:     Epoch: 53
2022-11-22 23:33:03,208 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8106317140839316, 'Total loss': 0.8106317140839316} | train loss {'Reaction outcome loss': 0.8205859024197825, 'Total loss': 0.8205859024197825}
2022-11-22 23:33:03,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:03,209 INFO:     Epoch: 54
2022-11-22 23:33:04,044 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8253617977554147, 'Total loss': 0.8253617977554147} | train loss {'Reaction outcome loss': 0.8216038480881722, 'Total loss': 0.8216038480881722}
2022-11-22 23:33:04,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:04,044 INFO:     Epoch: 55
2022-11-22 23:33:04,870 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8082145032557574, 'Total loss': 0.8082145032557574} | train loss {'Reaction outcome loss': 0.8177817979406926, 'Total loss': 0.8177817979406926}
2022-11-22 23:33:04,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:04,870 INFO:     Epoch: 56
2022-11-22 23:33:05,702 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.825318383899602, 'Total loss': 0.825318383899602} | train loss {'Reaction outcome loss': 0.8166816944797193, 'Total loss': 0.8166816944797193}
2022-11-22 23:33:05,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:05,703 INFO:     Epoch: 57
2022-11-22 23:33:06,514 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8273677764968439, 'Total loss': 0.8273677764968439} | train loss {'Reaction outcome loss': 0.8233901154129736, 'Total loss': 0.8233901154129736}
2022-11-22 23:33:06,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:06,515 INFO:     Epoch: 58
2022-11-22 23:33:07,302 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8135656070980158, 'Total loss': 0.8135656070980158} | train loss {'Reaction outcome loss': 0.8211119767398604, 'Total loss': 0.8211119767398604}
2022-11-22 23:33:07,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:07,302 INFO:     Epoch: 59
2022-11-22 23:33:08,091 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8268352028998461, 'Total loss': 0.8268352028998461} | train loss {'Reaction outcome loss': 0.8166466207513886, 'Total loss': 0.8166466207513886}
2022-11-22 23:33:08,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:08,091 INFO:     Epoch: 60
2022-11-22 23:33:08,915 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8152704841711305, 'Total loss': 0.8152704841711305} | train loss {'Reaction outcome loss': 0.8193907750950705, 'Total loss': 0.8193907750950705}
2022-11-22 23:33:08,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:08,916 INFO:     Epoch: 61
2022-11-22 23:33:09,756 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8171080100265417, 'Total loss': 0.8171080100265417} | train loss {'Reaction outcome loss': 0.8187336713796661, 'Total loss': 0.8187336713796661}
2022-11-22 23:33:09,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:09,757 INFO:     Epoch: 62
2022-11-22 23:33:10,612 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8138635050166737, 'Total loss': 0.8138635050166737} | train loss {'Reaction outcome loss': 0.8186056194526534, 'Total loss': 0.8186056194526534}
2022-11-22 23:33:10,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:10,613 INFO:     Epoch: 63
2022-11-22 23:33:11,418 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8147992288524454, 'Total loss': 0.8147992288524454} | train loss {'Reaction outcome loss': 0.8193579087814977, 'Total loss': 0.8193579087814977}
2022-11-22 23:33:11,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:11,418 INFO:     Epoch: 64
2022-11-22 23:33:12,245 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8153556781736288, 'Total loss': 0.8153556781736288} | train loss {'Reaction outcome loss': 0.8189356933918691, 'Total loss': 0.8189356933918691}
2022-11-22 23:33:12,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:12,246 INFO:     Epoch: 65
2022-11-22 23:33:13,055 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8171145536682822, 'Total loss': 0.8171145536682822} | train loss {'Reaction outcome loss': 0.8205970824966508, 'Total loss': 0.8205970824966508}
2022-11-22 23:33:13,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:13,055 INFO:     Epoch: 66
2022-11-22 23:33:13,880 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8102192465554584, 'Total loss': 0.8102192465554584} | train loss {'Reaction outcome loss': 0.8258898688420173, 'Total loss': 0.8258898688420173}
2022-11-22 23:33:13,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:13,881 INFO:     Epoch: 67
2022-11-22 23:33:14,702 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.832212813875892, 'Total loss': 0.832212813875892} | train loss {'Reaction outcome loss': 0.8212983990388532, 'Total loss': 0.8212983990388532}
2022-11-22 23:33:14,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:14,703 INFO:     Epoch: 68
2022-11-22 23:33:15,487 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8182195844975385, 'Total loss': 0.8182195844975385} | train loss {'Reaction outcome loss': 0.8212493569139512, 'Total loss': 0.8212493569139512}
2022-11-22 23:33:15,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:15,487 INFO:     Epoch: 69
2022-11-22 23:33:16,270 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8194401067766276, 'Total loss': 0.8194401067766276} | train loss {'Reaction outcome loss': 0.8182847406114301, 'Total loss': 0.8182847406114301}
2022-11-22 23:33:16,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:16,270 INFO:     Epoch: 70
2022-11-22 23:33:17,077 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8087484430183064, 'Total loss': 0.8087484430183064} | train loss {'Reaction outcome loss': 0.8212478877075257, 'Total loss': 0.8212478877075257}
2022-11-22 23:33:17,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:17,077 INFO:     Epoch: 71
2022-11-22 23:33:17,908 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8310664675452493, 'Total loss': 0.8310664675452493} | train loss {'Reaction outcome loss': 0.8186132035428478, 'Total loss': 0.8186132035428478}
2022-11-22 23:33:17,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:17,909 INFO:     Epoch: 72
2022-11-22 23:33:18,695 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8130684738809412, 'Total loss': 0.8130684738809412} | train loss {'Reaction outcome loss': 0.8256375514451535, 'Total loss': 0.8256375514451535}
2022-11-22 23:33:18,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:18,695 INFO:     Epoch: 73
2022-11-22 23:33:19,483 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.816002145409584, 'Total loss': 0.816002145409584} | train loss {'Reaction outcome loss': 0.8178669979735729, 'Total loss': 0.8178669979735729}
2022-11-22 23:33:19,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:19,483 INFO:     Epoch: 74
2022-11-22 23:33:20,381 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8203204030340369, 'Total loss': 0.8203204030340369} | train loss {'Reaction outcome loss': 0.8166140209763281, 'Total loss': 0.8166140209763281}
2022-11-22 23:33:20,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:20,381 INFO:     Epoch: 75
2022-11-22 23:33:21,195 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.81476018442349, 'Total loss': 0.81476018442349} | train loss {'Reaction outcome loss': 0.8225203680415307, 'Total loss': 0.8225203680415307}
2022-11-22 23:33:21,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:21,196 INFO:     Epoch: 76
2022-11-22 23:33:22,010 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8282022096894004, 'Total loss': 0.8282022096894004} | train loss {'Reaction outcome loss': 0.8183778635556659, 'Total loss': 0.8183778635556659}
2022-11-22 23:33:22,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:22,010 INFO:     Epoch: 77
2022-11-22 23:33:22,838 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8196064762093804, 'Total loss': 0.8196064762093804} | train loss {'Reaction outcome loss': 0.8236585966041011, 'Total loss': 0.8236585966041011}
2022-11-22 23:33:22,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:22,838 INFO:     Epoch: 78
2022-11-22 23:33:23,635 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8260811384428631, 'Total loss': 0.8260811384428631} | train loss {'Reaction outcome loss': 0.822252172375879, 'Total loss': 0.822252172375879}
2022-11-22 23:33:23,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:23,635 INFO:     Epoch: 79
2022-11-22 23:33:24,475 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8194247240369971, 'Total loss': 0.8194247240369971} | train loss {'Reaction outcome loss': 0.8186826592972202, 'Total loss': 0.8186826592972202}
2022-11-22 23:33:24,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:24,475 INFO:     Epoch: 80
2022-11-22 23:33:25,269 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8134620345451615, 'Total loss': 0.8134620345451615} | train loss {'Reaction outcome loss': 0.8159938717801725, 'Total loss': 0.8159938717801725}
2022-11-22 23:33:25,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:25,270 INFO:     Epoch: 81
2022-11-22 23:33:26,107 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8255240253426812, 'Total loss': 0.8255240253426812} | train loss {'Reaction outcome loss': 0.8179921671267478, 'Total loss': 0.8179921671267478}
2022-11-22 23:33:26,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:26,108 INFO:     Epoch: 82
2022-11-22 23:33:26,893 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8260473161935806, 'Total loss': 0.8260473161935806} | train loss {'Reaction outcome loss': 0.8220985737298766, 'Total loss': 0.8220985737298766}
2022-11-22 23:33:26,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:26,893 INFO:     Epoch: 83
2022-11-22 23:33:27,710 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8159031597050753, 'Total loss': 0.8159031597050753} | train loss {'Reaction outcome loss': 0.8243262748564443, 'Total loss': 0.8243262748564443}
2022-11-22 23:33:27,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:27,711 INFO:     Epoch: 84
2022-11-22 23:33:28,534 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8140503723512996, 'Total loss': 0.8140503723512996} | train loss {'Reaction outcome loss': 0.8195542839746321, 'Total loss': 0.8195542839746321}
2022-11-22 23:33:28,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:28,534 INFO:     Epoch: 85
2022-11-22 23:33:29,365 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.824632307345217, 'Total loss': 0.824632307345217} | train loss {'Reaction outcome loss': 0.8154772224445497, 'Total loss': 0.8154772224445497}
2022-11-22 23:33:29,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:29,365 INFO:     Epoch: 86
2022-11-22 23:33:30,146 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8119800368493254, 'Total loss': 0.8119800368493254} | train loss {'Reaction outcome loss': 0.8190572380779251, 'Total loss': 0.8190572380779251}
2022-11-22 23:33:30,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:30,146 INFO:     Epoch: 87
2022-11-22 23:33:31,010 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8149171491915529, 'Total loss': 0.8149171491915529} | train loss {'Reaction outcome loss': 0.8208122023892018, 'Total loss': 0.8208122023892018}
2022-11-22 23:33:31,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:31,011 INFO:     Epoch: 88
2022-11-22 23:33:31,833 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8135792653669011, 'Total loss': 0.8135792653669011} | train loss {'Reaction outcome loss': 0.8208922586373745, 'Total loss': 0.8208922586373745}
2022-11-22 23:33:31,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:31,833 INFO:     Epoch: 89
2022-11-22 23:33:32,658 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8147889524698257, 'Total loss': 0.8147889524698257} | train loss {'Reaction outcome loss': 0.8217932173321324, 'Total loss': 0.8217932173321324}
2022-11-22 23:33:32,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:32,658 INFO:     Epoch: 90
2022-11-22 23:33:33,463 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8266023045236414, 'Total loss': 0.8266023045236414} | train loss {'Reaction outcome loss': 0.8158878247824407, 'Total loss': 0.8158878247824407}
2022-11-22 23:33:33,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:33,463 INFO:     Epoch: 91
2022-11-22 23:33:34,256 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8127892356027256, 'Total loss': 0.8127892356027256} | train loss {'Reaction outcome loss': 0.8191008541372514, 'Total loss': 0.8191008541372514}
2022-11-22 23:33:34,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:34,256 INFO:     Epoch: 92
2022-11-22 23:33:35,053 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8193839646198533, 'Total loss': 0.8193839646198533} | train loss {'Reaction outcome loss': 0.8230984925983413, 'Total loss': 0.8230984925983413}
2022-11-22 23:33:35,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:35,054 INFO:     Epoch: 93
2022-11-22 23:33:35,855 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8125290423631668, 'Total loss': 0.8125290423631668} | train loss {'Reaction outcome loss': 0.8220952653115795, 'Total loss': 0.8220952653115795}
2022-11-22 23:33:35,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:35,856 INFO:     Epoch: 94
2022-11-22 23:33:36,626 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8283042101697489, 'Total loss': 0.8283042101697489} | train loss {'Reaction outcome loss': 0.8229703662856933, 'Total loss': 0.8229703662856933}
2022-11-22 23:33:36,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:36,627 INFO:     Epoch: 95
2022-11-22 23:33:37,383 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8229305290363051, 'Total loss': 0.8229305290363051} | train loss {'Reaction outcome loss': 0.8182839060262326, 'Total loss': 0.8182839060262326}
2022-11-22 23:33:37,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:37,383 INFO:     Epoch: 96
2022-11-22 23:33:38,172 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8189224695617502, 'Total loss': 0.8189224695617502} | train loss {'Reaction outcome loss': 0.8203315573834604, 'Total loss': 0.8203315573834604}
2022-11-22 23:33:38,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:38,173 INFO:     Epoch: 97
2022-11-22 23:33:38,968 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8176391327922995, 'Total loss': 0.8176391327922995} | train loss {'Reaction outcome loss': 0.8213919994811858, 'Total loss': 0.8213919994811858}
2022-11-22 23:33:38,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:38,968 INFO:     Epoch: 98
2022-11-22 23:33:39,766 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8085434396158565, 'Total loss': 0.8085434396158565} | train loss {'Reaction outcome loss': 0.8208149433616669, 'Total loss': 0.8208149433616669}
2022-11-22 23:33:39,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:39,767 INFO:     Epoch: 99
2022-11-22 23:33:40,540 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8238594992594286, 'Total loss': 0.8238594992594286} | train loss {'Reaction outcome loss': 0.8163325359984752, 'Total loss': 0.8163325359984752}
2022-11-22 23:33:40,540 INFO:     Best model found after epoch 48 of 100.
2022-11-22 23:33:40,540 INFO:   Done with stage: TRAINING
2022-11-22 23:33:40,540 INFO:   Starting stage: EVALUATION
2022-11-22 23:33:40,664 INFO:   Done with stage: EVALUATION
2022-11-22 23:33:40,664 INFO:   Leaving out SEQ value Fold_7
2022-11-22 23:33:40,677 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:33:40,678 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:33:41,347 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:33:41,347 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:33:41,418 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:33:41,418 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:33:41,418 INFO:     No hyperparam tuning for this model
2022-11-22 23:33:41,418 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:33:41,418 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:33:41,419 INFO:     None feature selector for col prot
2022-11-22 23:33:41,419 INFO:     None feature selector for col prot
2022-11-22 23:33:41,420 INFO:     None feature selector for col prot
2022-11-22 23:33:41,420 INFO:     None feature selector for col chem
2022-11-22 23:33:41,420 INFO:     None feature selector for col chem
2022-11-22 23:33:41,420 INFO:     None feature selector for col chem
2022-11-22 23:33:41,420 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:33:41,421 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:33:41,422 INFO:     Number of params in model 168571
2022-11-22 23:33:41,425 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:33:41,425 INFO:   Starting stage: TRAINING
2022-11-22 23:33:41,484 INFO:     Val loss before train {'Reaction outcome loss': 1.030682771043344, 'Total loss': 1.030682771043344}
2022-11-22 23:33:41,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:41,484 INFO:     Epoch: 0
2022-11-22 23:33:42,283 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8538252819668163, 'Total loss': 0.8538252819668163} | train loss {'Reaction outcome loss': 0.8749021931215819, 'Total loss': 0.8749021931215819}
2022-11-22 23:33:42,283 INFO:     Found new best model at epoch 0
2022-11-22 23:33:42,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:42,284 INFO:     Epoch: 1
2022-11-22 23:33:43,084 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8313079767606475, 'Total loss': 0.8313079767606475} | train loss {'Reaction outcome loss': 0.8435978916613197, 'Total loss': 0.8435978916613197}
2022-11-22 23:33:43,084 INFO:     Found new best model at epoch 1
2022-11-22 23:33:43,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:43,085 INFO:     Epoch: 2
2022-11-22 23:33:43,866 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8470126173712991, 'Total loss': 0.8470126173712991} | train loss {'Reaction outcome loss': 0.8407072216151696, 'Total loss': 0.8407072216151696}
2022-11-22 23:33:43,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:43,866 INFO:     Epoch: 3
2022-11-22 23:33:44,673 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8318026072599671, 'Total loss': 0.8318026072599671} | train loss {'Reaction outcome loss': 0.8393401870360742, 'Total loss': 0.8393401870360742}
2022-11-22 23:33:44,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:44,673 INFO:     Epoch: 4
2022-11-22 23:33:45,467 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8324824517423456, 'Total loss': 0.8324824517423456} | train loss {'Reaction outcome loss': 0.835632552471962, 'Total loss': 0.835632552471962}
2022-11-22 23:33:45,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:45,467 INFO:     Epoch: 5
2022-11-22 23:33:46,237 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8293221030722965, 'Total loss': 0.8293221030722965} | train loss {'Reaction outcome loss': 0.8325783394367589, 'Total loss': 0.8325783394367589}
2022-11-22 23:33:46,237 INFO:     Found new best model at epoch 5
2022-11-22 23:33:46,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:46,238 INFO:     Epoch: 6
2022-11-22 23:33:47,047 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8441326211799275, 'Total loss': 0.8441326211799275} | train loss {'Reaction outcome loss': 0.8334254185680435, 'Total loss': 0.8334254185680435}
2022-11-22 23:33:47,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:47,048 INFO:     Epoch: 7
2022-11-22 23:33:47,843 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8146478167989037, 'Total loss': 0.8146478167989037} | train loss {'Reaction outcome loss': 0.8260733602787198, 'Total loss': 0.8260733602787198}
2022-11-22 23:33:47,843 INFO:     Found new best model at epoch 7
2022-11-22 23:33:47,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:47,844 INFO:     Epoch: 8
2022-11-22 23:33:48,628 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8095152811570601, 'Total loss': 0.8095152811570601} | train loss {'Reaction outcome loss': 0.8233940583853586, 'Total loss': 0.8233940583853586}
2022-11-22 23:33:48,628 INFO:     Found new best model at epoch 8
2022-11-22 23:33:48,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:48,629 INFO:     Epoch: 9
2022-11-22 23:33:49,399 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8209912343458696, 'Total loss': 0.8209912343458696} | train loss {'Reaction outcome loss': 0.8324451926748763, 'Total loss': 0.8324451926748763}
2022-11-22 23:33:49,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:49,399 INFO:     Epoch: 10
2022-11-22 23:33:50,215 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8377838866277174, 'Total loss': 0.8377838866277174} | train loss {'Reaction outcome loss': 0.8277995583982121, 'Total loss': 0.8277995583982121}
2022-11-22 23:33:50,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:50,215 INFO:     Epoch: 11
2022-11-22 23:33:50,988 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8265505697239529, 'Total loss': 0.8265505697239529} | train loss {'Reaction outcome loss': 0.8196738206966203, 'Total loss': 0.8196738206966203}
2022-11-22 23:33:50,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:50,989 INFO:     Epoch: 12
2022-11-22 23:33:51,785 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8569608628749847, 'Total loss': 0.8569608628749847} | train loss {'Reaction outcome loss': 0.8404429574244419, 'Total loss': 0.8404429574244419}
2022-11-22 23:33:51,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:51,786 INFO:     Epoch: 13
2022-11-22 23:33:52,632 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8144223960963163, 'Total loss': 0.8144223960963163} | train loss {'Reaction outcome loss': 0.8218604022192086, 'Total loss': 0.8218604022192086}
2022-11-22 23:33:52,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:52,632 INFO:     Epoch: 14
2022-11-22 23:33:53,428 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.815594534305009, 'Total loss': 0.815594534305009} | train loss {'Reaction outcome loss': 0.8265297117262234, 'Total loss': 0.8265297117262234}
2022-11-22 23:33:53,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:53,428 INFO:     Epoch: 15
2022-11-22 23:33:54,218 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8213960250670259, 'Total loss': 0.8213960250670259} | train loss {'Reaction outcome loss': 0.821355243805449, 'Total loss': 0.821355243805449}
2022-11-22 23:33:54,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:54,218 INFO:     Epoch: 16
2022-11-22 23:33:55,011 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8176261714913629, 'Total loss': 0.8176261714913629} | train loss {'Reaction outcome loss': 0.8180199522479825, 'Total loss': 0.8180199522479825}
2022-11-22 23:33:55,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:55,012 INFO:     Epoch: 17
2022-11-22 23:33:55,879 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8026207245209, 'Total loss': 0.8026207245209} | train loss {'Reaction outcome loss': 0.8152312224331172, 'Total loss': 0.8152312224331172}
2022-11-22 23:33:55,879 INFO:     Found new best model at epoch 17
2022-11-22 23:33:55,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:55,880 INFO:     Epoch: 18
2022-11-22 23:33:56,701 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8322815766388719, 'Total loss': 0.8322815766388719} | train loss {'Reaction outcome loss': 0.8222292466202246, 'Total loss': 0.8222292466202246}
2022-11-22 23:33:56,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:56,701 INFO:     Epoch: 19
2022-11-22 23:33:57,528 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8282101506536658, 'Total loss': 0.8282101506536658} | train loss {'Reaction outcome loss': 0.8223981209672414, 'Total loss': 0.8223981209672414}
2022-11-22 23:33:57,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:57,529 INFO:     Epoch: 20
2022-11-22 23:33:58,344 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8354468122124672, 'Total loss': 0.8354468122124672} | train loss {'Reaction outcome loss': 0.8179770052915643, 'Total loss': 0.8179770052915643}
2022-11-22 23:33:58,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:58,345 INFO:     Epoch: 21
2022-11-22 23:33:59,166 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8032744398171251, 'Total loss': 0.8032744398171251} | train loss {'Reaction outcome loss': 0.8203133455051584, 'Total loss': 0.8203133455051584}
2022-11-22 23:33:59,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:59,166 INFO:     Epoch: 22
2022-11-22 23:33:59,986 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8104925914244219, 'Total loss': 0.8104925914244219} | train loss {'Reaction outcome loss': 0.8236099950939055, 'Total loss': 0.8236099950939055}
2022-11-22 23:33:59,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:33:59,986 INFO:     Epoch: 23
2022-11-22 23:34:00,793 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8210990456017581, 'Total loss': 0.8210990456017581} | train loss {'Reaction outcome loss': 0.8188275428194749, 'Total loss': 0.8188275428194749}
2022-11-22 23:34:00,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:00,793 INFO:     Epoch: 24
2022-11-22 23:34:01,605 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8294615908102556, 'Total loss': 0.8294615908102556} | train loss {'Reaction outcome loss': 0.8188953499803658, 'Total loss': 0.8188953499803658}
2022-11-22 23:34:01,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:01,605 INFO:     Epoch: 25
2022-11-22 23:34:02,400 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8210372382944281, 'Total loss': 0.8210372382944281} | train loss {'Reaction outcome loss': 0.8259981876684104, 'Total loss': 0.8259981876684104}
2022-11-22 23:34:02,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:02,401 INFO:     Epoch: 26
2022-11-22 23:34:03,199 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8334856473586776, 'Total loss': 0.8334856473586776} | train loss {'Reaction outcome loss': 0.8221518678462457, 'Total loss': 0.8221518678462457}
2022-11-22 23:34:03,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:03,199 INFO:     Epoch: 27
2022-11-22 23:34:03,986 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8124729611656882, 'Total loss': 0.8124729611656882} | train loss {'Reaction outcome loss': 0.8138092951886808, 'Total loss': 0.8138092951886808}
2022-11-22 23:34:03,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:03,986 INFO:     Epoch: 28
2022-11-22 23:34:04,735 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8130938464945013, 'Total loss': 0.8130938464945013} | train loss {'Reaction outcome loss': 0.8173704163627586, 'Total loss': 0.8173704163627586}
2022-11-22 23:34:04,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:04,735 INFO:     Epoch: 29
2022-11-22 23:34:05,589 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8216035555709492, 'Total loss': 0.8216035555709492} | train loss {'Reaction outcome loss': 0.8211864160622663, 'Total loss': 0.8211864160622663}
2022-11-22 23:34:05,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:05,590 INFO:     Epoch: 30
2022-11-22 23:34:06,410 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8136373873461377, 'Total loss': 0.8136373873461377} | train loss {'Reaction outcome loss': 0.8162759806704425, 'Total loss': 0.8162759806704425}
2022-11-22 23:34:06,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:06,411 INFO:     Epoch: 31
2022-11-22 23:34:07,201 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8110513287511739, 'Total loss': 0.8110513287511739} | train loss {'Reaction outcome loss': 0.8173777981084368, 'Total loss': 0.8173777981084368}
2022-11-22 23:34:07,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:07,201 INFO:     Epoch: 32
2022-11-22 23:34:07,995 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8364419882947748, 'Total loss': 0.8364419882947748} | train loss {'Reaction outcome loss': 0.8130875207513932, 'Total loss': 0.8130875207513932}
2022-11-22 23:34:07,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:07,996 INFO:     Epoch: 33
2022-11-22 23:34:08,804 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.819197500293905, 'Total loss': 0.819197500293905} | train loss {'Reaction outcome loss': 0.811113468156411, 'Total loss': 0.811113468156411}
2022-11-22 23:34:08,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:08,805 INFO:     Epoch: 34
2022-11-22 23:34:09,629 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.806559373031963, 'Total loss': 0.806559373031963} | train loss {'Reaction outcome loss': 0.8109759609950217, 'Total loss': 0.8109759609950217}
2022-11-22 23:34:09,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:09,629 INFO:     Epoch: 35
2022-11-22 23:34:10,410 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8052139688621868, 'Total loss': 0.8052139688621868} | train loss {'Reaction outcome loss': 0.8149396531012377, 'Total loss': 0.8149396531012377}
2022-11-22 23:34:10,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:10,411 INFO:     Epoch: 36
2022-11-22 23:34:11,239 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8122855682264675, 'Total loss': 0.8122855682264675} | train loss {'Reaction outcome loss': 0.8149114479178842, 'Total loss': 0.8149114479178842}
2022-11-22 23:34:11,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:11,239 INFO:     Epoch: 37
2022-11-22 23:34:12,077 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8011534139513969, 'Total loss': 0.8011534139513969} | train loss {'Reaction outcome loss': 0.8180825541376585, 'Total loss': 0.8180825541376585}
2022-11-22 23:34:12,077 INFO:     Found new best model at epoch 37
2022-11-22 23:34:12,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:12,078 INFO:     Epoch: 38
2022-11-22 23:34:12,857 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.804345384917476, 'Total loss': 0.804345384917476} | train loss {'Reaction outcome loss': 0.8226629237414371, 'Total loss': 0.8226629237414371}
2022-11-22 23:34:12,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:12,858 INFO:     Epoch: 39
2022-11-22 23:34:13,675 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8087151619521055, 'Total loss': 0.8087151619521055} | train loss {'Reaction outcome loss': 0.8161241969598932, 'Total loss': 0.8161241969598932}
2022-11-22 23:34:13,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:13,675 INFO:     Epoch: 40
2022-11-22 23:34:14,464 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8081717321818526, 'Total loss': 0.8081717321818526} | train loss {'Reaction outcome loss': 0.8206482418635597, 'Total loss': 0.8206482418635597}
2022-11-22 23:34:14,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:14,464 INFO:     Epoch: 41
2022-11-22 23:34:15,288 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7916388315233317, 'Total loss': 0.7916388315233317} | train loss {'Reaction outcome loss': 0.8093257264690361, 'Total loss': 0.8093257264690361}
2022-11-22 23:34:15,288 INFO:     Found new best model at epoch 41
2022-11-22 23:34:15,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:15,289 INFO:     Epoch: 42
2022-11-22 23:34:16,132 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7940078709613193, 'Total loss': 0.7940078709613193} | train loss {'Reaction outcome loss': 0.8096634144121818, 'Total loss': 0.8096634144121818}
2022-11-22 23:34:16,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:16,132 INFO:     Epoch: 43
2022-11-22 23:34:16,980 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8017656186764891, 'Total loss': 0.8017656186764891} | train loss {'Reaction outcome loss': 0.8160769945455466, 'Total loss': 0.8160769945455466}
2022-11-22 23:34:16,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:16,980 INFO:     Epoch: 44
2022-11-22 23:34:17,767 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8049239008264109, 'Total loss': 0.8049239008264109} | train loss {'Reaction outcome loss': 0.8164106902443928, 'Total loss': 0.8164106902443928}
2022-11-22 23:34:17,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:17,767 INFO:     Epoch: 45
2022-11-22 23:34:18,602 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8165743784470991, 'Total loss': 0.8165743784470991} | train loss {'Reaction outcome loss': 0.8139293675842555, 'Total loss': 0.8139293675842555}
2022-11-22 23:34:18,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:18,602 INFO:     Epoch: 46
2022-11-22 23:34:19,452 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8468371494249864, 'Total loss': 0.8468371494249864} | train loss {'Reaction outcome loss': 0.8171958534823738, 'Total loss': 0.8171958534823738}
2022-11-22 23:34:19,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:19,453 INFO:     Epoch: 47
2022-11-22 23:34:20,266 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.814519616690549, 'Total loss': 0.814519616690549} | train loss {'Reaction outcome loss': 0.8142167977717242, 'Total loss': 0.8142167977717242}
2022-11-22 23:34:20,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:20,266 INFO:     Epoch: 48
2022-11-22 23:34:21,103 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8144060942259702, 'Total loss': 0.8144060942259702} | train loss {'Reaction outcome loss': 0.8140065462483086, 'Total loss': 0.8140065462483086}
2022-11-22 23:34:21,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:21,103 INFO:     Epoch: 49
2022-11-22 23:34:21,917 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8066274428909476, 'Total loss': 0.8066274428909476} | train loss {'Reaction outcome loss': 0.8150983039546109, 'Total loss': 0.8150983039546109}
2022-11-22 23:34:21,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:21,917 INFO:     Epoch: 50
2022-11-22 23:34:22,713 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.809927449984984, 'Total loss': 0.809927449984984} | train loss {'Reaction outcome loss': 0.8176660747663212, 'Total loss': 0.8176660747663212}
2022-11-22 23:34:22,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:22,713 INFO:     Epoch: 51
2022-11-22 23:34:23,533 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.833842086521062, 'Total loss': 0.833842086521062} | train loss {'Reaction outcome loss': 0.8088596974789855, 'Total loss': 0.8088596974789855}
2022-11-22 23:34:23,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:23,534 INFO:     Epoch: 52
2022-11-22 23:34:24,318 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8118638897484, 'Total loss': 0.8118638897484} | train loss {'Reaction outcome loss': 0.8228849918253509, 'Total loss': 0.8228849918253509}
2022-11-22 23:34:24,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:24,318 INFO:     Epoch: 53
2022-11-22 23:34:25,079 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8227980543266643, 'Total loss': 0.8227980543266643} | train loss {'Reaction outcome loss': 0.8127063935554704, 'Total loss': 0.8127063935554704}
2022-11-22 23:34:25,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:25,079 INFO:     Epoch: 54
2022-11-22 23:34:25,869 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8044878393411636, 'Total loss': 0.8044878393411636} | train loss {'Reaction outcome loss': 0.8128915043464797, 'Total loss': 0.8128915043464797}
2022-11-22 23:34:25,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:25,870 INFO:     Epoch: 55
2022-11-22 23:34:26,739 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8080568794499744, 'Total loss': 0.8080568794499744} | train loss {'Reaction outcome loss': 0.8123895972363862, 'Total loss': 0.8123895972363862}
2022-11-22 23:34:26,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:26,739 INFO:     Epoch: 56
2022-11-22 23:34:27,553 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8087171261960809, 'Total loss': 0.8087171261960809} | train loss {'Reaction outcome loss': 0.8229332639862169, 'Total loss': 0.8229332639862169}
2022-11-22 23:34:27,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:27,553 INFO:     Epoch: 57
2022-11-22 23:34:28,388 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8456190363927321, 'Total loss': 0.8456190363927321} | train loss {'Reaction outcome loss': 0.8124965772877338, 'Total loss': 0.8124965772877338}
2022-11-22 23:34:28,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:28,388 INFO:     Epoch: 58
2022-11-22 23:34:29,226 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8322205787355249, 'Total loss': 0.8322205787355249} | train loss {'Reaction outcome loss': 0.8183463063799901, 'Total loss': 0.8183463063799901}
2022-11-22 23:34:29,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:29,227 INFO:     Epoch: 59
2022-11-22 23:34:30,042 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8087301687760786, 'Total loss': 0.8087301687760786} | train loss {'Reaction outcome loss': 0.8131580567854618, 'Total loss': 0.8131580567854618}
2022-11-22 23:34:30,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:30,043 INFO:     Epoch: 60
2022-11-22 23:34:30,870 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8153719414364208, 'Total loss': 0.8153719414364208} | train loss {'Reaction outcome loss': 0.8096314430055831, 'Total loss': 0.8096314430055831}
2022-11-22 23:34:30,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:30,870 INFO:     Epoch: 61
2022-11-22 23:34:31,703 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8174926056103273, 'Total loss': 0.8174926056103273} | train loss {'Reaction outcome loss': 0.8170509849965331, 'Total loss': 0.8170509849965331}
2022-11-22 23:34:31,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:31,704 INFO:     Epoch: 62
2022-11-22 23:34:32,534 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8176171678033742, 'Total loss': 0.8176171678033742} | train loss {'Reaction outcome loss': 0.817604744120648, 'Total loss': 0.817604744120648}
2022-11-22 23:34:32,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:32,534 INFO:     Epoch: 63
2022-11-22 23:34:33,305 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8234899071129885, 'Total loss': 0.8234899071129885} | train loss {'Reaction outcome loss': 0.8126652821114189, 'Total loss': 0.8126652821114189}
2022-11-22 23:34:33,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:33,305 INFO:     Epoch: 64
2022-11-22 23:34:34,102 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8154464350505308, 'Total loss': 0.8154464350505308} | train loss {'Reaction outcome loss': 0.8163142946326298, 'Total loss': 0.8163142946326298}
2022-11-22 23:34:34,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:34,103 INFO:     Epoch: 65
2022-11-22 23:34:34,859 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8096762787212025, 'Total loss': 0.8096762787212025} | train loss {'Reaction outcome loss': 0.8137771940907004, 'Total loss': 0.8137771940907004}
2022-11-22 23:34:34,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:34,859 INFO:     Epoch: 66
2022-11-22 23:34:35,650 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.808561356907541, 'Total loss': 0.808561356907541} | train loss {'Reaction outcome loss': 0.8113445886957501, 'Total loss': 0.8113445886957501}
2022-11-22 23:34:35,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:35,650 INFO:     Epoch: 67
2022-11-22 23:34:36,449 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8113610182296146, 'Total loss': 0.8113610182296146} | train loss {'Reaction outcome loss': 0.8149246489742266, 'Total loss': 0.8149246489742266}
2022-11-22 23:34:36,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:36,449 INFO:     Epoch: 68
2022-11-22 23:34:37,204 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8196869627995924, 'Total loss': 0.8196869627995924} | train loss {'Reaction outcome loss': 0.8110711435798691, 'Total loss': 0.8110711435798691}
2022-11-22 23:34:37,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:37,205 INFO:     Epoch: 69
2022-11-22 23:34:38,007 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8215980651703748, 'Total loss': 0.8215980651703748} | train loss {'Reaction outcome loss': 0.8112570870335889, 'Total loss': 0.8112570870335889}
2022-11-22 23:34:38,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:38,008 INFO:     Epoch: 70
2022-11-22 23:34:38,782 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8196101114153862, 'Total loss': 0.8196101114153862} | train loss {'Reaction outcome loss': 0.8118995560355756, 'Total loss': 0.8118995560355756}
2022-11-22 23:34:38,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:38,782 INFO:     Epoch: 71
2022-11-22 23:34:39,556 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8320002772591331, 'Total loss': 0.8320002772591331} | train loss {'Reaction outcome loss': 0.8161885960382006, 'Total loss': 0.8161885960382006}
2022-11-22 23:34:39,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:39,557 INFO:     Epoch: 72
2022-11-22 23:34:40,344 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8179859776388515, 'Total loss': 0.8179859776388515} | train loss {'Reaction outcome loss': 0.8176130951657469, 'Total loss': 0.8176130951657469}
2022-11-22 23:34:40,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:40,345 INFO:     Epoch: 73
2022-11-22 23:34:41,119 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8310790983113375, 'Total loss': 0.8310790983113375} | train loss {'Reaction outcome loss': 0.8161808890611054, 'Total loss': 0.8161808890611054}
2022-11-22 23:34:41,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:41,119 INFO:     Epoch: 74
2022-11-22 23:34:41,909 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7997263067147948, 'Total loss': 0.7997263067147948} | train loss {'Reaction outcome loss': 0.8220015046326256, 'Total loss': 0.8220015046326256}
2022-11-22 23:34:41,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:41,909 INFO:     Epoch: 75
2022-11-22 23:34:42,697 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8093367903070017, 'Total loss': 0.8093367903070017} | train loss {'Reaction outcome loss': 0.8210228348550527, 'Total loss': 0.8210228348550527}
2022-11-22 23:34:42,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:42,698 INFO:     Epoch: 76
2022-11-22 23:34:43,496 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8206071067940105, 'Total loss': 0.8206071067940105} | train loss {'Reaction outcome loss': 0.8154119732167556, 'Total loss': 0.8154119732167556}
2022-11-22 23:34:43,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:43,497 INFO:     Epoch: 77
2022-11-22 23:34:44,281 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8184202895923094, 'Total loss': 0.8184202895923094} | train loss {'Reaction outcome loss': 0.8127524140573706, 'Total loss': 0.8127524140573706}
2022-11-22 23:34:44,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:44,281 INFO:     Epoch: 78
2022-11-22 23:34:45,072 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8137822137637571, 'Total loss': 0.8137822137637571} | train loss {'Reaction outcome loss': 0.810715980375344, 'Total loss': 0.810715980375344}
2022-11-22 23:34:45,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:45,073 INFO:     Epoch: 79
2022-11-22 23:34:45,882 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8206456899642944, 'Total loss': 0.8206456899642944} | train loss {'Reaction outcome loss': 0.8159630638867738, 'Total loss': 0.8159630638867738}
2022-11-22 23:34:45,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:45,882 INFO:     Epoch: 80
2022-11-22 23:34:46,624 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.810069281946529, 'Total loss': 0.810069281946529} | train loss {'Reaction outcome loss': 0.8198922375737414, 'Total loss': 0.8198922375737414}
2022-11-22 23:34:46,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:46,624 INFO:     Epoch: 81
2022-11-22 23:34:47,437 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8150197226892818, 'Total loss': 0.8150197226892818} | train loss {'Reaction outcome loss': 0.8159569989331821, 'Total loss': 0.8159569989331821}
2022-11-22 23:34:47,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:47,437 INFO:     Epoch: 82
2022-11-22 23:34:48,223 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8227928565307097, 'Total loss': 0.8227928565307097} | train loss {'Reaction outcome loss': 0.8126742030203584, 'Total loss': 0.8126742030203584}
2022-11-22 23:34:48,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:48,223 INFO:     Epoch: 83
2022-11-22 23:34:48,995 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8184851421551271, 'Total loss': 0.8184851421551271} | train loss {'Reaction outcome loss': 0.8137766374991491, 'Total loss': 0.8137766374991491}
2022-11-22 23:34:48,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:48,995 INFO:     Epoch: 84
2022-11-22 23:34:49,816 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8191982473839413, 'Total loss': 0.8191982473839413} | train loss {'Reaction outcome loss': 0.8119966382922431, 'Total loss': 0.8119966382922431}
2022-11-22 23:34:49,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:49,816 INFO:     Epoch: 85
2022-11-22 23:34:50,665 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8098250783302567, 'Total loss': 0.8098250783302567} | train loss {'Reaction outcome loss': 0.8213703640800739, 'Total loss': 0.8213703640800739}
2022-11-22 23:34:50,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:50,666 INFO:     Epoch: 86
2022-11-22 23:34:51,441 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8108969086950476, 'Total loss': 0.8108969086950476} | train loss {'Reaction outcome loss': 0.8213321642595747, 'Total loss': 0.8213321642595747}
2022-11-22 23:34:51,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:51,441 INFO:     Epoch: 87
2022-11-22 23:34:52,250 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8107412708076563, 'Total loss': 0.8107412708076563} | train loss {'Reaction outcome loss': 0.8195698841622001, 'Total loss': 0.8195698841622001}
2022-11-22 23:34:52,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:52,250 INFO:     Epoch: 88
2022-11-22 23:34:53,059 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.850230872631073, 'Total loss': 0.850230872631073} | train loss {'Reaction outcome loss': 0.817873686069419, 'Total loss': 0.817873686069419}
2022-11-22 23:34:53,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:53,059 INFO:     Epoch: 89
2022-11-22 23:34:53,817 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8199172074144537, 'Total loss': 0.8199172074144537} | train loss {'Reaction outcome loss': 0.8165818777402886, 'Total loss': 0.8165818777402886}
2022-11-22 23:34:53,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:53,817 INFO:     Epoch: 90
2022-11-22 23:34:54,611 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8239276266910813, 'Total loss': 0.8239276266910813} | train loss {'Reaction outcome loss': 0.8114375908847763, 'Total loss': 0.8114375908847763}
2022-11-22 23:34:54,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:54,612 INFO:     Epoch: 91
2022-11-22 23:34:55,400 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8046247498555616, 'Total loss': 0.8046247498555616} | train loss {'Reaction outcome loss': 0.8130952621761122, 'Total loss': 0.8130952621761122}
2022-11-22 23:34:55,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:55,400 INFO:     Epoch: 92
2022-11-22 23:34:56,205 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8132379481738264, 'Total loss': 0.8132379481738264} | train loss {'Reaction outcome loss': 0.8258596417392313, 'Total loss': 0.8258596417392313}
2022-11-22 23:34:56,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:56,206 INFO:     Epoch: 93
2022-11-22 23:34:57,011 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8251927745613185, 'Total loss': 0.8251927745613185} | train loss {'Reaction outcome loss': 0.8178929084467019, 'Total loss': 0.8178929084467019}
2022-11-22 23:34:57,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:57,011 INFO:     Epoch: 94
2022-11-22 23:34:57,832 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8209458142518997, 'Total loss': 0.8209458142518997} | train loss {'Reaction outcome loss': 0.8141103185381484, 'Total loss': 0.8141103185381484}
2022-11-22 23:34:57,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:57,832 INFO:     Epoch: 95
2022-11-22 23:34:58,647 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8289071186022325, 'Total loss': 0.8289071186022325} | train loss {'Reaction outcome loss': 0.8206136412466103, 'Total loss': 0.8206136412466103}
2022-11-22 23:34:58,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:58,647 INFO:     Epoch: 96
2022-11-22 23:34:59,463 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8077577278017998, 'Total loss': 0.8077577278017998} | train loss {'Reaction outcome loss': 0.8092732517282489, 'Total loss': 0.8092732517282489}
2022-11-22 23:34:59,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:34:59,463 INFO:     Epoch: 97
2022-11-22 23:35:00,309 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8103465180505406, 'Total loss': 0.8103465180505406} | train loss {'Reaction outcome loss': 0.8128248496576842, 'Total loss': 0.8128248496576842}
2022-11-22 23:35:00,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:00,309 INFO:     Epoch: 98
2022-11-22 23:35:01,110 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8101245564493266, 'Total loss': 0.8101245564493266} | train loss {'Reaction outcome loss': 0.8164136061060284, 'Total loss': 0.8164136061060284}
2022-11-22 23:35:01,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:01,111 INFO:     Epoch: 99
2022-11-22 23:35:01,918 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8192443590272557, 'Total loss': 0.8192443590272557} | train loss {'Reaction outcome loss': 0.82239955579221, 'Total loss': 0.82239955579221}
2022-11-22 23:35:01,918 INFO:     Best model found after epoch 42 of 100.
2022-11-22 23:35:01,918 INFO:   Done with stage: TRAINING
2022-11-22 23:35:01,918 INFO:   Starting stage: EVALUATION
2022-11-22 23:35:02,045 INFO:   Done with stage: EVALUATION
2022-11-22 23:35:02,045 INFO:   Leaving out SEQ value Fold_8
2022-11-22 23:35:02,058 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:35:02,058 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:35:02,736 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:35:02,736 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:35:02,805 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:35:02,805 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:35:02,805 INFO:     No hyperparam tuning for this model
2022-11-22 23:35:02,805 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:35:02,805 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:35:02,806 INFO:     None feature selector for col prot
2022-11-22 23:35:02,806 INFO:     None feature selector for col prot
2022-11-22 23:35:02,806 INFO:     None feature selector for col prot
2022-11-22 23:35:02,807 INFO:     None feature selector for col chem
2022-11-22 23:35:02,807 INFO:     None feature selector for col chem
2022-11-22 23:35:02,807 INFO:     None feature selector for col chem
2022-11-22 23:35:02,807 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:35:02,807 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:35:02,809 INFO:     Number of params in model 168571
2022-11-22 23:35:02,812 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:35:02,812 INFO:   Starting stage: TRAINING
2022-11-22 23:35:02,870 INFO:     Val loss before train {'Reaction outcome loss': 0.988264112309976, 'Total loss': 0.988264112309976}
2022-11-22 23:35:02,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:02,870 INFO:     Epoch: 0
2022-11-22 23:35:03,647 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8349656977436759, 'Total loss': 0.8349656977436759} | train loss {'Reaction outcome loss': 0.8986948116829521, 'Total loss': 0.8986948116829521}
2022-11-22 23:35:03,647 INFO:     Found new best model at epoch 0
2022-11-22 23:35:03,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:03,648 INFO:     Epoch: 1
2022-11-22 23:35:04,452 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8088875914161856, 'Total loss': 0.8088875914161856} | train loss {'Reaction outcome loss': 0.8591238691015282, 'Total loss': 0.8591238691015282}
2022-11-22 23:35:04,453 INFO:     Found new best model at epoch 1
2022-11-22 23:35:04,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:04,454 INFO:     Epoch: 2
2022-11-22 23:35:05,261 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8268211246891455, 'Total loss': 0.8268211246891455} | train loss {'Reaction outcome loss': 0.8526965584832165, 'Total loss': 0.8526965584832165}
2022-11-22 23:35:05,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:05,261 INFO:     Epoch: 3
2022-11-22 23:35:06,082 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8052892833948135, 'Total loss': 0.8052892833948135} | train loss {'Reaction outcome loss': 0.853817195303527, 'Total loss': 0.853817195303527}
2022-11-22 23:35:06,082 INFO:     Found new best model at epoch 3
2022-11-22 23:35:06,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:06,083 INFO:     Epoch: 4
2022-11-22 23:35:06,882 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8193215903910723, 'Total loss': 0.8193215903910723} | train loss {'Reaction outcome loss': 0.8535772365355782, 'Total loss': 0.8535772365355782}
2022-11-22 23:35:06,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:06,882 INFO:     Epoch: 5
2022-11-22 23:35:07,688 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8001754155213182, 'Total loss': 0.8001754155213182} | train loss {'Reaction outcome loss': 0.8475635969928401, 'Total loss': 0.8475635969928401}
2022-11-22 23:35:07,688 INFO:     Found new best model at epoch 5
2022-11-22 23:35:07,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:07,689 INFO:     Epoch: 6
2022-11-22 23:35:08,511 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8047817694869909, 'Total loss': 0.8047817694869909} | train loss {'Reaction outcome loss': 0.8400671758391114, 'Total loss': 0.8400671758391114}
2022-11-22 23:35:08,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:08,512 INFO:     Epoch: 7
2022-11-22 23:35:09,309 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8159502704035152, 'Total loss': 0.8159502704035152} | train loss {'Reaction outcome loss': 0.8393825164690674, 'Total loss': 0.8393825164690674}
2022-11-22 23:35:09,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:09,309 INFO:     Epoch: 8
2022-11-22 23:35:10,145 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8030754781582139, 'Total loss': 0.8030754781582139} | train loss {'Reaction outcome loss': 0.8437773750016564, 'Total loss': 0.8437773750016564}
2022-11-22 23:35:10,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:10,145 INFO:     Epoch: 9
2022-11-22 23:35:10,985 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7994552383368666, 'Total loss': 0.7994552383368666} | train loss {'Reaction outcome loss': 0.8379087570888794, 'Total loss': 0.8379087570888794}
2022-11-22 23:35:10,986 INFO:     Found new best model at epoch 9
2022-11-22 23:35:10,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:10,986 INFO:     Epoch: 10
2022-11-22 23:35:11,824 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8049923466010527, 'Total loss': 0.8049923466010527} | train loss {'Reaction outcome loss': 0.8354869718976349, 'Total loss': 0.8354869718976349}
2022-11-22 23:35:11,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:11,824 INFO:     Epoch: 11
2022-11-22 23:35:12,638 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8026322248307142, 'Total loss': 0.8026322248307142} | train loss {'Reaction outcome loss': 0.8352679418407472, 'Total loss': 0.8352679418407472}
2022-11-22 23:35:12,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:12,639 INFO:     Epoch: 12
2022-11-22 23:35:13,445 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.79921505600214, 'Total loss': 0.79921505600214} | train loss {'Reaction outcome loss': 0.8353939885311281, 'Total loss': 0.8353939885311281}
2022-11-22 23:35:13,446 INFO:     Found new best model at epoch 12
2022-11-22 23:35:13,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:13,447 INFO:     Epoch: 13
2022-11-22 23:35:14,257 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8142095519737764, 'Total loss': 0.8142095519737764} | train loss {'Reaction outcome loss': 0.8396416979762706, 'Total loss': 0.8396416979762706}
2022-11-22 23:35:14,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:14,258 INFO:     Epoch: 14
2022-11-22 23:35:15,034 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7964171374386008, 'Total loss': 0.7964171374386008} | train loss {'Reaction outcome loss': 0.8383362674520083, 'Total loss': 0.8383362674520083}
2022-11-22 23:35:15,035 INFO:     Found new best model at epoch 14
2022-11-22 23:35:15,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:15,035 INFO:     Epoch: 15
2022-11-22 23:35:15,830 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.824859463355758, 'Total loss': 0.824859463355758} | train loss {'Reaction outcome loss': 0.8345834856573869, 'Total loss': 0.8345834856573869}
2022-11-22 23:35:15,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:15,830 INFO:     Epoch: 16
2022-11-22 23:35:16,600 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7982372099703009, 'Total loss': 0.7982372099703009} | train loss {'Reaction outcome loss': 0.8359589592406624, 'Total loss': 0.8359589592406624}
2022-11-22 23:35:16,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:16,601 INFO:     Epoch: 17
2022-11-22 23:35:17,403 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7936270616271279, 'Total loss': 0.7936270616271279} | train loss {'Reaction outcome loss': 0.8352805672869509, 'Total loss': 0.8352805672869509}
2022-11-22 23:35:17,404 INFO:     Found new best model at epoch 17
2022-11-22 23:35:17,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:17,404 INFO:     Epoch: 18
2022-11-22 23:35:18,178 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7942296876148744, 'Total loss': 0.7942296876148744} | train loss {'Reaction outcome loss': 0.8332906788901279, 'Total loss': 0.8332906788901279}
2022-11-22 23:35:18,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:18,178 INFO:     Epoch: 19
2022-11-22 23:35:18,967 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7891304371031848, 'Total loss': 0.7891304371031848} | train loss {'Reaction outcome loss': 0.8296000405482435, 'Total loss': 0.8296000405482435}
2022-11-22 23:35:18,967 INFO:     Found new best model at epoch 19
2022-11-22 23:35:18,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:18,968 INFO:     Epoch: 20
2022-11-22 23:35:19,772 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7877267077565193, 'Total loss': 0.7877267077565193} | train loss {'Reaction outcome loss': 0.8373716936902962, 'Total loss': 0.8373716936902962}
2022-11-22 23:35:19,772 INFO:     Found new best model at epoch 20
2022-11-22 23:35:19,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:19,773 INFO:     Epoch: 21
2022-11-22 23:35:20,573 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7853021018884399, 'Total loss': 0.7853021018884399} | train loss {'Reaction outcome loss': 0.8359971395146991, 'Total loss': 0.8359971395146991}
2022-11-22 23:35:20,573 INFO:     Found new best model at epoch 21
2022-11-22 23:35:20,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:20,574 INFO:     Epoch: 22
2022-11-22 23:35:21,412 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.797569255259904, 'Total loss': 0.797569255259904} | train loss {'Reaction outcome loss': 0.835610286909559, 'Total loss': 0.835610286909559}
2022-11-22 23:35:21,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:21,412 INFO:     Epoch: 23
2022-11-22 23:35:22,220 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8009145022793249, 'Total loss': 0.8009145022793249} | train loss {'Reaction outcome loss': 0.8358012770834239, 'Total loss': 0.8358012770834239}
2022-11-22 23:35:22,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:22,220 INFO:     Epoch: 24
2022-11-22 23:35:23,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8041634288701144, 'Total loss': 0.8041634288701144} | train loss {'Reaction outcome loss': 0.8287809808184261, 'Total loss': 0.8287809808184261}
2022-11-22 23:35:23,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:23,029 INFO:     Epoch: 25
2022-11-22 23:35:23,868 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7999244650656526, 'Total loss': 0.7999244650656526} | train loss {'Reaction outcome loss': 0.8337952156781185, 'Total loss': 0.8337952156781185}
2022-11-22 23:35:23,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:23,869 INFO:     Epoch: 26
2022-11-22 23:35:24,645 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7961005473678763, 'Total loss': 0.7961005473678763} | train loss {'Reaction outcome loss': 0.8353519997133417, 'Total loss': 0.8353519997133417}
2022-11-22 23:35:24,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:24,645 INFO:     Epoch: 27
2022-11-22 23:35:25,427 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7968059547922828, 'Total loss': 0.7968059547922828} | train loss {'Reaction outcome loss': 0.8348384851868819, 'Total loss': 0.8348384851868819}
2022-11-22 23:35:25,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:25,428 INFO:     Epoch: 28
2022-11-22 23:35:26,237 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8088267364285209, 'Total loss': 0.8088267364285209} | train loss {'Reaction outcome loss': 0.8340298602214227, 'Total loss': 0.8340298602214227}
2022-11-22 23:35:26,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:26,238 INFO:     Epoch: 29
2022-11-22 23:35:27,093 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7883963537487116, 'Total loss': 0.7883963537487116} | train loss {'Reaction outcome loss': 0.8374890376199112, 'Total loss': 0.8374890376199112}
2022-11-22 23:35:27,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:27,093 INFO:     Epoch: 30
2022-11-22 23:35:27,933 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7902792272242632, 'Total loss': 0.7902792272242632} | train loss {'Reaction outcome loss': 0.8314484915270014, 'Total loss': 0.8314484915270014}
2022-11-22 23:35:27,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:27,934 INFO:     Epoch: 31
2022-11-22 23:35:28,741 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7918084514412013, 'Total loss': 0.7918084514412013} | train loss {'Reaction outcome loss': 0.8259516738445652, 'Total loss': 0.8259516738445652}
2022-11-22 23:35:28,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:28,742 INFO:     Epoch: 32
2022-11-22 23:35:29,531 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.791146458549933, 'Total loss': 0.791146458549933} | train loss {'Reaction outcome loss': 0.8314695404126093, 'Total loss': 0.8314695404126093}
2022-11-22 23:35:29,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:29,531 INFO:     Epoch: 33
2022-11-22 23:35:30,312 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.793762131170793, 'Total loss': 0.793762131170793} | train loss {'Reaction outcome loss': 0.8249172072420236, 'Total loss': 0.8249172072420236}
2022-11-22 23:35:30,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:30,313 INFO:     Epoch: 34
2022-11-22 23:35:31,121 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8217336454174735, 'Total loss': 0.8217336454174735} | train loss {'Reaction outcome loss': 0.8304919289191243, 'Total loss': 0.8304919289191243}
2022-11-22 23:35:31,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:31,121 INFO:     Epoch: 35
2022-11-22 23:35:31,943 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7957824644717303, 'Total loss': 0.7957824644717303} | train loss {'Reaction outcome loss': 0.832722039116539, 'Total loss': 0.832722039116539}
2022-11-22 23:35:31,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:31,944 INFO:     Epoch: 36
2022-11-22 23:35:32,730 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7864428176121279, 'Total loss': 0.7864428176121279} | train loss {'Reaction outcome loss': 0.8339221109504159, 'Total loss': 0.8339221109504159}
2022-11-22 23:35:32,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:32,730 INFO:     Epoch: 37
2022-11-22 23:35:33,507 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.800110703164881, 'Total loss': 0.800110703164881} | train loss {'Reaction outcome loss': 0.8283658448742469, 'Total loss': 0.8283658448742469}
2022-11-22 23:35:33,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:33,507 INFO:     Epoch: 38
2022-11-22 23:35:34,319 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7972632443363016, 'Total loss': 0.7972632443363016} | train loss {'Reaction outcome loss': 0.8292993801204782, 'Total loss': 0.8292993801204782}
2022-11-22 23:35:34,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:34,319 INFO:     Epoch: 39
2022-11-22 23:35:35,139 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8223221600055695, 'Total loss': 0.8223221600055695} | train loss {'Reaction outcome loss': 0.8302768409734795, 'Total loss': 0.8302768409734795}
2022-11-22 23:35:35,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:35,139 INFO:     Epoch: 40
2022-11-22 23:35:35,938 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7980917875062336, 'Total loss': 0.7980917875062336} | train loss {'Reaction outcome loss': 0.829326109726902, 'Total loss': 0.829326109726902}
2022-11-22 23:35:35,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:35,939 INFO:     Epoch: 41
2022-11-22 23:35:36,750 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8083908463066275, 'Total loss': 0.8083908463066275} | train loss {'Reaction outcome loss': 0.829189286540877, 'Total loss': 0.829189286540877}
2022-11-22 23:35:36,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:36,750 INFO:     Epoch: 42
2022-11-22 23:35:37,551 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8369601694020358, 'Total loss': 0.8369601694020358} | train loss {'Reaction outcome loss': 0.8334018724408709, 'Total loss': 0.8334018724408709}
2022-11-22 23:35:37,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:37,552 INFO:     Epoch: 43
2022-11-22 23:35:38,345 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7860940146175298, 'Total loss': 0.7860940146175298} | train loss {'Reaction outcome loss': 0.8330167919276696, 'Total loss': 0.8330167919276696}
2022-11-22 23:35:38,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:38,346 INFO:     Epoch: 44
2022-11-22 23:35:39,160 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8012754212726246, 'Total loss': 0.8012754212726246} | train loss {'Reaction outcome loss': 0.8276549122533817, 'Total loss': 0.8276549122533817}
2022-11-22 23:35:39,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:39,160 INFO:     Epoch: 45
2022-11-22 23:35:39,946 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7884067168289964, 'Total loss': 0.7884067168289964} | train loss {'Reaction outcome loss': 0.8268562768876311, 'Total loss': 0.8268562768876311}
2022-11-22 23:35:39,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:39,947 INFO:     Epoch: 46
2022-11-22 23:35:40,765 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7898093428124081, 'Total loss': 0.7898093428124081} | train loss {'Reaction outcome loss': 0.8279428525492247, 'Total loss': 0.8279428525492247}
2022-11-22 23:35:40,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:40,765 INFO:     Epoch: 47
2022-11-22 23:35:41,566 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7900895395062186, 'Total loss': 0.7900895395062186} | train loss {'Reaction outcome loss': 0.8277524974544038, 'Total loss': 0.8277524974544038}
2022-11-22 23:35:41,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:41,566 INFO:     Epoch: 48
2022-11-22 23:35:42,348 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7799092050303112, 'Total loss': 0.7799092050303112} | train loss {'Reaction outcome loss': 0.8247019410857305, 'Total loss': 0.8247019410857305}
2022-11-22 23:35:42,348 INFO:     Found new best model at epoch 48
2022-11-22 23:35:42,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:42,349 INFO:     Epoch: 49
2022-11-22 23:35:43,156 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8120293684981086, 'Total loss': 0.8120293684981086} | train loss {'Reaction outcome loss': 0.830310763738416, 'Total loss': 0.830310763738416}
2022-11-22 23:35:43,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:43,156 INFO:     Epoch: 50
2022-11-22 23:35:43,936 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7870060828599063, 'Total loss': 0.7870060828599063} | train loss {'Reaction outcome loss': 0.8306337125629548, 'Total loss': 0.8306337125629548}
2022-11-22 23:35:43,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:43,936 INFO:     Epoch: 51
2022-11-22 23:35:44,710 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7845561341805891, 'Total loss': 0.7845561341805891} | train loss {'Reaction outcome loss': 0.8251212439556354, 'Total loss': 0.8251212439556354}
2022-11-22 23:35:44,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:44,711 INFO:     Epoch: 52
2022-11-22 23:35:45,515 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7972205064513467, 'Total loss': 0.7972205064513467} | train loss {'Reaction outcome loss': 0.8244861888016767, 'Total loss': 0.8244861888016767}
2022-11-22 23:35:45,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:45,515 INFO:     Epoch: 53
2022-11-22 23:35:46,310 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7931280813433907, 'Total loss': 0.7931280813433907} | train loss {'Reaction outcome loss': 0.8269167881504245, 'Total loss': 0.8269167881504245}
2022-11-22 23:35:46,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:46,311 INFO:     Epoch: 54
2022-11-22 23:35:47,086 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7885053239085458, 'Total loss': 0.7885053239085458} | train loss {'Reaction outcome loss': 0.8244557279324242, 'Total loss': 0.8244557279324242}
2022-11-22 23:35:47,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:47,086 INFO:     Epoch: 55
2022-11-22 23:35:47,856 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8025722720406272, 'Total loss': 0.8025722720406272} | train loss {'Reaction outcome loss': 0.8565919177252271, 'Total loss': 0.8565919177252271}
2022-11-22 23:35:47,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:47,856 INFO:     Epoch: 56
2022-11-22 23:35:48,634 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.834970583292571, 'Total loss': 0.834970583292571} | train loss {'Reaction outcome loss': 0.8235349032107876, 'Total loss': 0.8235349032107876}
2022-11-22 23:35:48,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:48,635 INFO:     Epoch: 57
2022-11-22 23:35:49,411 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7830425108020956, 'Total loss': 0.7830425108020956} | train loss {'Reaction outcome loss': 0.823430410582527, 'Total loss': 0.823430410582527}
2022-11-22 23:35:49,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:49,411 INFO:     Epoch: 58
2022-11-22 23:35:50,171 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.788279575380412, 'Total loss': 0.788279575380412} | train loss {'Reaction outcome loss': 0.8307958134272804, 'Total loss': 0.8307958134272804}
2022-11-22 23:35:50,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:50,171 INFO:     Epoch: 59
2022-11-22 23:35:50,929 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7911064455455, 'Total loss': 0.7911064455455} | train loss {'Reaction outcome loss': 0.825768230294409, 'Total loss': 0.825768230294409}
2022-11-22 23:35:50,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:50,929 INFO:     Epoch: 60
2022-11-22 23:35:51,687 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8104951618747278, 'Total loss': 0.8104951618747278} | train loss {'Reaction outcome loss': 0.8274981620823324, 'Total loss': 0.8274981620823324}
2022-11-22 23:35:51,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:51,688 INFO:     Epoch: 61
2022-11-22 23:35:52,453 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.798321620984511, 'Total loss': 0.798321620984511} | train loss {'Reaction outcome loss': 0.8258885106577082, 'Total loss': 0.8258885106577082}
2022-11-22 23:35:52,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:52,454 INFO:     Epoch: 62
2022-11-22 23:35:53,221 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7937700843269174, 'Total loss': 0.7937700843269174} | train loss {'Reaction outcome loss': 0.8333763506731041, 'Total loss': 0.8333763506731041}
2022-11-22 23:35:53,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:53,221 INFO:     Epoch: 63
2022-11-22 23:35:53,989 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8007149059664119, 'Total loss': 0.8007149059664119} | train loss {'Reaction outcome loss': 0.8271973554482345, 'Total loss': 0.8271973554482345}
2022-11-22 23:35:53,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:53,989 INFO:     Epoch: 64
2022-11-22 23:35:54,798 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7837237654761835, 'Total loss': 0.7837237654761835} | train loss {'Reaction outcome loss': 0.8297648470894046, 'Total loss': 0.8297648470894046}
2022-11-22 23:35:54,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:54,798 INFO:     Epoch: 65
2022-11-22 23:35:55,607 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7949475659565493, 'Total loss': 0.7949475659565493} | train loss {'Reaction outcome loss': 0.8247346695859422, 'Total loss': 0.8247346695859422}
2022-11-22 23:35:55,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:55,608 INFO:     Epoch: 66
2022-11-22 23:35:56,443 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8362386335026134, 'Total loss': 0.8362386335026134} | train loss {'Reaction outcome loss': 0.8253285683359695, 'Total loss': 0.8253285683359695}
2022-11-22 23:35:56,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:56,445 INFO:     Epoch: 67
2022-11-22 23:35:57,229 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7849446711215106, 'Total loss': 0.7849446711215106} | train loss {'Reaction outcome loss': 0.8228024790885478, 'Total loss': 0.8228024790885478}
2022-11-22 23:35:57,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:57,230 INFO:     Epoch: 68
2022-11-22 23:35:58,025 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7975388006730513, 'Total loss': 0.7975388006730513} | train loss {'Reaction outcome loss': 0.8253172767548426, 'Total loss': 0.8253172767548426}
2022-11-22 23:35:58,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:58,025 INFO:     Epoch: 69
2022-11-22 23:35:58,814 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7816633866591887, 'Total loss': 0.7816633866591887} | train loss {'Reaction outcome loss': 0.8256450950616767, 'Total loss': 0.8256450950616767}
2022-11-22 23:35:58,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:58,814 INFO:     Epoch: 70
2022-11-22 23:35:59,574 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8217728056690909, 'Total loss': 0.8217728056690909} | train loss {'Reaction outcome loss': 0.8300234222943, 'Total loss': 0.8300234222943}
2022-11-22 23:35:59,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:35:59,575 INFO:     Epoch: 71
2022-11-22 23:36:00,369 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7940077524293553, 'Total loss': 0.7940077524293553} | train loss {'Reaction outcome loss': 0.8342937676288821, 'Total loss': 0.8342937676288821}
2022-11-22 23:36:00,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:00,369 INFO:     Epoch: 72
2022-11-22 23:36:01,167 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7914778353138403, 'Total loss': 0.7914778353138403} | train loss {'Reaction outcome loss': 0.833636601444198, 'Total loss': 0.833636601444198}
2022-11-22 23:36:01,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:01,167 INFO:     Epoch: 73
2022-11-22 23:36:01,952 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7772640938108618, 'Total loss': 0.7772640938108618} | train loss {'Reaction outcome loss': 0.8286711332286417, 'Total loss': 0.8286711332286417}
2022-11-22 23:36:01,952 INFO:     Found new best model at epoch 73
2022-11-22 23:36:01,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:01,953 INFO:     Epoch: 74
2022-11-22 23:36:02,735 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8114566748792474, 'Total loss': 0.8114566748792474} | train loss {'Reaction outcome loss': 0.83169796073485, 'Total loss': 0.83169796073485}
2022-11-22 23:36:02,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:02,736 INFO:     Epoch: 75
2022-11-22 23:36:03,531 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.780181338841265, 'Total loss': 0.780181338841265} | train loss {'Reaction outcome loss': 0.828031940257501, 'Total loss': 0.828031940257501}
2022-11-22 23:36:03,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:03,531 INFO:     Epoch: 76
2022-11-22 23:36:04,371 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7988479218699716, 'Total loss': 0.7988479218699716} | train loss {'Reaction outcome loss': 0.8376305751231036, 'Total loss': 0.8376305751231036}
2022-11-22 23:36:04,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:04,372 INFO:     Epoch: 77
2022-11-22 23:36:05,248 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8095286109230735, 'Total loss': 0.8095286109230735} | train loss {'Reaction outcome loss': 0.8256649225346955, 'Total loss': 0.8256649225346955}
2022-11-22 23:36:05,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:05,248 INFO:     Epoch: 78
2022-11-22 23:36:06,064 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.795396282591603, 'Total loss': 0.795396282591603} | train loss {'Reaction outcome loss': 0.8188598623521898, 'Total loss': 0.8188598623521898}
2022-11-22 23:36:06,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:06,064 INFO:     Epoch: 79
2022-11-22 23:36:06,860 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7959517457268455, 'Total loss': 0.7959517457268455} | train loss {'Reaction outcome loss': 0.825822830682824, 'Total loss': 0.825822830682824}
2022-11-22 23:36:06,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:06,861 INFO:     Epoch: 80
2022-11-22 23:36:07,632 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7789316570216959, 'Total loss': 0.7789316570216959} | train loss {'Reaction outcome loss': 0.8232695952600796, 'Total loss': 0.8232695952600796}
2022-11-22 23:36:07,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:07,632 INFO:     Epoch: 81
2022-11-22 23:36:08,412 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7895798303864219, 'Total loss': 0.7895798303864219} | train loss {'Reaction outcome loss': 0.8319152273871155, 'Total loss': 0.8319152273871155}
2022-11-22 23:36:08,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:08,412 INFO:     Epoch: 82
2022-11-22 23:36:09,187 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.788215041837909, 'Total loss': 0.788215041837909} | train loss {'Reaction outcome loss': 0.8328654860798647, 'Total loss': 0.8328654860798647}
2022-11-22 23:36:09,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:09,187 INFO:     Epoch: 83
2022-11-22 23:36:09,967 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7889273877848278, 'Total loss': 0.7889273877848278} | train loss {'Reaction outcome loss': 0.822237475801576, 'Total loss': 0.822237475801576}
2022-11-22 23:36:09,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:09,967 INFO:     Epoch: 84
2022-11-22 23:36:10,777 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7859734025868502, 'Total loss': 0.7859734025868502} | train loss {'Reaction outcome loss': 0.8293967177028115, 'Total loss': 0.8293967177028115}
2022-11-22 23:36:10,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:10,777 INFO:     Epoch: 85
2022-11-22 23:36:11,625 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8127906078642065, 'Total loss': 0.8127906078642065} | train loss {'Reaction outcome loss': 0.8375490084592148, 'Total loss': 0.8375490084592148}
2022-11-22 23:36:11,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:11,626 INFO:     Epoch: 86
2022-11-22 23:36:12,397 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8118980804627592, 'Total loss': 0.8118980804627592} | train loss {'Reaction outcome loss': 0.8510898630387387, 'Total loss': 0.8510898630387387}
2022-11-22 23:36:12,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:12,397 INFO:     Epoch: 87
2022-11-22 23:36:13,203 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7790533290667967, 'Total loss': 0.7790533290667967} | train loss {'Reaction outcome loss': 0.8204164810267537, 'Total loss': 0.8204164810267537}
2022-11-22 23:36:13,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:13,204 INFO:     Epoch: 88
2022-11-22 23:36:14,014 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7888981727036563, 'Total loss': 0.7888981727036563} | train loss {'Reaction outcome loss': 0.8231547933358413, 'Total loss': 0.8231547933358413}
2022-11-22 23:36:14,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:14,015 INFO:     Epoch: 89
2022-11-22 23:36:14,809 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8186338550665162, 'Total loss': 0.8186338550665162} | train loss {'Reaction outcome loss': 0.8331974899237938, 'Total loss': 0.8331974899237938}
2022-11-22 23:36:14,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:14,810 INFO:     Epoch: 90
2022-11-22 23:36:15,595 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8057791868394072, 'Total loss': 0.8057791868394072} | train loss {'Reaction outcome loss': 0.8271267474421605, 'Total loss': 0.8271267474421605}
2022-11-22 23:36:15,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:15,595 INFO:     Epoch: 91
2022-11-22 23:36:16,448 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7932015339081938, 'Total loss': 0.7932015339081938} | train loss {'Reaction outcome loss': 0.8290485248633241, 'Total loss': 0.8290485248633241}
2022-11-22 23:36:16,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:16,448 INFO:     Epoch: 92
2022-11-22 23:36:17,246 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7962269315665419, 'Total loss': 0.7962269315665419} | train loss {'Reaction outcome loss': 0.8284109071922688, 'Total loss': 0.8284109071922688}
2022-11-22 23:36:17,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:17,246 INFO:     Epoch: 93
2022-11-22 23:36:18,039 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8016686757857149, 'Total loss': 0.8016686757857149} | train loss {'Reaction outcome loss': 0.8195092912144989, 'Total loss': 0.8195092912144989}
2022-11-22 23:36:18,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:18,039 INFO:     Epoch: 94
2022-11-22 23:36:18,837 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7771675234491174, 'Total loss': 0.7771675234491174} | train loss {'Reaction outcome loss': 0.8333158397722823, 'Total loss': 0.8333158397722823}
2022-11-22 23:36:18,837 INFO:     Found new best model at epoch 94
2022-11-22 23:36:18,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:18,838 INFO:     Epoch: 95
2022-11-22 23:36:19,652 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7988703738559376, 'Total loss': 0.7988703738559376} | train loss {'Reaction outcome loss': 0.8363188705463641, 'Total loss': 0.8363188705463641}
2022-11-22 23:36:19,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:19,652 INFO:     Epoch: 96
2022-11-22 23:36:20,457 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7922544716434046, 'Total loss': 0.7922544716434046} | train loss {'Reaction outcome loss': 0.8368231872556663, 'Total loss': 0.8368231872556663}
2022-11-22 23:36:20,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:20,457 INFO:     Epoch: 97
2022-11-22 23:36:21,254 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7975178557363424, 'Total loss': 0.7975178557363424} | train loss {'Reaction outcome loss': 0.830520406305066, 'Total loss': 0.830520406305066}
2022-11-22 23:36:21,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:21,254 INFO:     Epoch: 98
2022-11-22 23:36:22,026 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8015583740039305, 'Total loss': 0.8015583740039305} | train loss {'Reaction outcome loss': 0.825498560179583, 'Total loss': 0.825498560179583}
2022-11-22 23:36:22,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:22,027 INFO:     Epoch: 99
2022-11-22 23:36:22,840 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7901115241375837, 'Total loss': 0.7901115241375837} | train loss {'Reaction outcome loss': 0.8270473483844325, 'Total loss': 0.8270473483844325}
2022-11-22 23:36:22,840 INFO:     Best model found after epoch 95 of 100.
2022-11-22 23:36:22,841 INFO:   Done with stage: TRAINING
2022-11-22 23:36:22,841 INFO:   Starting stage: EVALUATION
2022-11-22 23:36:22,965 INFO:   Done with stage: EVALUATION
2022-11-22 23:36:22,965 INFO:   Leaving out SEQ value Fold_9
2022-11-22 23:36:22,978 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:36:22,978 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:36:23,656 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:36:23,656 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:36:23,726 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:36:23,726 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:36:23,726 INFO:     No hyperparam tuning for this model
2022-11-22 23:36:23,726 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:36:23,726 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:36:23,727 INFO:     None feature selector for col prot
2022-11-22 23:36:23,727 INFO:     None feature selector for col prot
2022-11-22 23:36:23,727 INFO:     None feature selector for col prot
2022-11-22 23:36:23,728 INFO:     None feature selector for col chem
2022-11-22 23:36:23,728 INFO:     None feature selector for col chem
2022-11-22 23:36:23,728 INFO:     None feature selector for col chem
2022-11-22 23:36:23,728 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:36:23,728 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:36:23,730 INFO:     Number of params in model 168571
2022-11-22 23:36:23,733 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:36:23,733 INFO:   Starting stage: TRAINING
2022-11-22 23:36:23,791 INFO:     Val loss before train {'Reaction outcome loss': 1.0304471904581243, 'Total loss': 1.0304471904581243}
2022-11-22 23:36:23,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:23,791 INFO:     Epoch: 0
2022-11-22 23:36:24,597 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8757126222957264, 'Total loss': 0.8757126222957264} | train loss {'Reaction outcome loss': 0.8651639618854291, 'Total loss': 0.8651639618854291}
2022-11-22 23:36:24,597 INFO:     Found new best model at epoch 0
2022-11-22 23:36:24,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:24,598 INFO:     Epoch: 1
2022-11-22 23:36:25,422 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8564376316287301, 'Total loss': 0.8564376316287301} | train loss {'Reaction outcome loss': 0.8415338751154873, 'Total loss': 0.8415338751154873}
2022-11-22 23:36:25,422 INFO:     Found new best model at epoch 1
2022-11-22 23:36:25,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:25,423 INFO:     Epoch: 2
2022-11-22 23:36:26,232 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8466444753787734, 'Total loss': 0.8466444753787734} | train loss {'Reaction outcome loss': 0.8307580806103795, 'Total loss': 0.8307580806103795}
2022-11-22 23:36:26,232 INFO:     Found new best model at epoch 2
2022-11-22 23:36:26,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:26,233 INFO:     Epoch: 3
2022-11-22 23:36:27,035 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8493253927339207, 'Total loss': 0.8493253927339207} | train loss {'Reaction outcome loss': 0.8342482930252909, 'Total loss': 0.8342482930252909}
2022-11-22 23:36:27,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:27,036 INFO:     Epoch: 4
2022-11-22 23:36:27,838 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8495058065110986, 'Total loss': 0.8495058065110986} | train loss {'Reaction outcome loss': 0.8249001314162243, 'Total loss': 0.8249001314162243}
2022-11-22 23:36:27,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:27,839 INFO:     Epoch: 5
2022-11-22 23:36:28,645 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8672010742805221, 'Total loss': 0.8672010742805221} | train loss {'Reaction outcome loss': 0.8218720613220926, 'Total loss': 0.8218720613220926}
2022-11-22 23:36:28,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:28,646 INFO:     Epoch: 6
2022-11-22 23:36:29,416 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8463856300169771, 'Total loss': 0.8463856300169771} | train loss {'Reaction outcome loss': 0.8164960414412533, 'Total loss': 0.8164960414412533}
2022-11-22 23:36:29,416 INFO:     Found new best model at epoch 6
2022-11-22 23:36:29,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:29,416 INFO:     Epoch: 7
2022-11-22 23:36:30,216 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8557860431346026, 'Total loss': 0.8557860431346026} | train loss {'Reaction outcome loss': 0.8192757769876163, 'Total loss': 0.8192757769876163}
2022-11-22 23:36:30,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:30,216 INFO:     Epoch: 8
2022-11-22 23:36:31,029 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.850704931400039, 'Total loss': 0.850704931400039} | train loss {'Reaction outcome loss': 0.8117642239158452, 'Total loss': 0.8117642239158452}
2022-11-22 23:36:31,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:31,029 INFO:     Epoch: 9
2022-11-22 23:36:31,845 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8422836038199338, 'Total loss': 0.8422836038199338} | train loss {'Reaction outcome loss': 0.8105035985891635, 'Total loss': 0.8105035985891635}
2022-11-22 23:36:31,845 INFO:     Found new best model at epoch 9
2022-11-22 23:36:31,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:31,846 INFO:     Epoch: 10
2022-11-22 23:36:32,666 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8513659265908328, 'Total loss': 0.8513659265908328} | train loss {'Reaction outcome loss': 0.8108797039580249, 'Total loss': 0.8108797039580249}
2022-11-22 23:36:32,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:32,666 INFO:     Epoch: 11
2022-11-22 23:36:33,464 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8489598855376244, 'Total loss': 0.8489598855376244} | train loss {'Reaction outcome loss': 0.8271710370716295, 'Total loss': 0.8271710370716295}
2022-11-22 23:36:33,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:33,464 INFO:     Epoch: 12
2022-11-22 23:36:34,293 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8517593321475115, 'Total loss': 0.8517593321475115} | train loss {'Reaction outcome loss': 0.8217146764641349, 'Total loss': 0.8217146764641349}
2022-11-22 23:36:34,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:34,294 INFO:     Epoch: 13
2022-11-22 23:36:35,118 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8416470871730284, 'Total loss': 0.8416470871730284} | train loss {'Reaction outcome loss': 0.8124360831280951, 'Total loss': 0.8124360831280951}
2022-11-22 23:36:35,118 INFO:     Found new best model at epoch 13
2022-11-22 23:36:35,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:35,119 INFO:     Epoch: 14
2022-11-22 23:36:35,913 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8374695754186674, 'Total loss': 0.8374695754186674} | train loss {'Reaction outcome loss': 0.8102234196113912, 'Total loss': 0.8102234196113912}
2022-11-22 23:36:35,913 INFO:     Found new best model at epoch 14
2022-11-22 23:36:35,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:35,914 INFO:     Epoch: 15
2022-11-22 23:36:36,715 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8435248055241324, 'Total loss': 0.8435248055241324} | train loss {'Reaction outcome loss': 0.8109809840739015, 'Total loss': 0.8109809840739015}
2022-11-22 23:36:36,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:36,716 INFO:     Epoch: 16
2022-11-22 23:36:37,507 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8497893823818727, 'Total loss': 0.8497893823818727} | train loss {'Reaction outcome loss': 0.8160486296120926, 'Total loss': 0.8160486296120926}
2022-11-22 23:36:37,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:37,507 INFO:     Epoch: 17
2022-11-22 23:36:38,337 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8499334082007408, 'Total loss': 0.8499334082007408} | train loss {'Reaction outcome loss': 0.8092016924911665, 'Total loss': 0.8092016924911665}
2022-11-22 23:36:38,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:38,337 INFO:     Epoch: 18
2022-11-22 23:36:39,138 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8359714191068303, 'Total loss': 0.8359714191068303} | train loss {'Reaction outcome loss': 0.8083697413867302, 'Total loss': 0.8083697413867302}
2022-11-22 23:36:39,138 INFO:     Found new best model at epoch 18
2022-11-22 23:36:39,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:39,139 INFO:     Epoch: 19
2022-11-22 23:36:39,980 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8343147669326175, 'Total loss': 0.8343147669326175} | train loss {'Reaction outcome loss': 0.8169280797363776, 'Total loss': 0.8169280797363776}
2022-11-22 23:36:39,980 INFO:     Found new best model at epoch 19
2022-11-22 23:36:39,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:39,981 INFO:     Epoch: 20
2022-11-22 23:36:40,785 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8363679593259638, 'Total loss': 0.8363679593259638} | train loss {'Reaction outcome loss': 0.8104109314952784, 'Total loss': 0.8104109314952784}
2022-11-22 23:36:40,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:40,786 INFO:     Epoch: 21
2022-11-22 23:36:41,591 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8669961182908579, 'Total loss': 0.8669961182908579} | train loss {'Reaction outcome loss': 0.8052326747280384, 'Total loss': 0.8052326747280384}
2022-11-22 23:36:41,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:41,592 INFO:     Epoch: 22
2022-11-22 23:36:42,383 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8420787467197939, 'Total loss': 0.8420787467197939} | train loss {'Reaction outcome loss': 0.8112698484528885, 'Total loss': 0.8112698484528885}
2022-11-22 23:36:42,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:42,383 INFO:     Epoch: 23
2022-11-22 23:36:43,137 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8315286406061866, 'Total loss': 0.8315286406061866} | train loss {'Reaction outcome loss': 0.8121381639710322, 'Total loss': 0.8121381639710322}
2022-11-22 23:36:43,138 INFO:     Found new best model at epoch 23
2022-11-22 23:36:43,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:43,138 INFO:     Epoch: 24
2022-11-22 23:36:43,904 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8493555445562709, 'Total loss': 0.8493555445562709} | train loss {'Reaction outcome loss': 0.8115485234540484, 'Total loss': 0.8115485234540484}
2022-11-22 23:36:43,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:43,904 INFO:     Epoch: 25
2022-11-22 23:36:44,683 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8310880227522417, 'Total loss': 0.8310880227522417} | train loss {'Reaction outcome loss': 0.8071884569610178, 'Total loss': 0.8071884569610178}
2022-11-22 23:36:44,683 INFO:     Found new best model at epoch 25
2022-11-22 23:36:44,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:44,684 INFO:     Epoch: 26
2022-11-22 23:36:45,482 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8336002521894195, 'Total loss': 0.8336002521894195} | train loss {'Reaction outcome loss': 0.8039511209316099, 'Total loss': 0.8039511209316099}
2022-11-22 23:36:45,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:45,482 INFO:     Epoch: 27
2022-11-22 23:36:46,332 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8265617896210063, 'Total loss': 0.8265617896210063} | train loss {'Reaction outcome loss': 0.8072023600460547, 'Total loss': 0.8072023600460547}
2022-11-22 23:36:46,333 INFO:     Found new best model at epoch 27
2022-11-22 23:36:46,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:46,334 INFO:     Epoch: 28
2022-11-22 23:36:47,178 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8388044238090515, 'Total loss': 0.8388044238090515} | train loss {'Reaction outcome loss': 0.8048403400641221, 'Total loss': 0.8048403400641221}
2022-11-22 23:36:47,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:47,179 INFO:     Epoch: 29
2022-11-22 23:36:48,033 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8293501849878918, 'Total loss': 0.8293501849878918} | train loss {'Reaction outcome loss': 0.8078087618959094, 'Total loss': 0.8078087618959094}
2022-11-22 23:36:48,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:48,033 INFO:     Epoch: 30
2022-11-22 23:36:48,803 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8494975919073279, 'Total loss': 0.8494975919073279} | train loss {'Reaction outcome loss': 0.8142690417254984, 'Total loss': 0.8142690417254984}
2022-11-22 23:36:48,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:48,803 INFO:     Epoch: 31
2022-11-22 23:36:49,607 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.848988262089816, 'Total loss': 0.848988262089816} | train loss {'Reaction outcome loss': 0.807342189284954, 'Total loss': 0.807342189284954}
2022-11-22 23:36:49,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:49,607 INFO:     Epoch: 32
2022-11-22 23:36:50,413 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8433952690525488, 'Total loss': 0.8433952690525488} | train loss {'Reaction outcome loss': 0.8035309040534352, 'Total loss': 0.8035309040534352}
2022-11-22 23:36:50,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:50,413 INFO:     Epoch: 33
2022-11-22 23:36:51,215 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8709307746453718, 'Total loss': 0.8709307746453718} | train loss {'Reaction outcome loss': 0.808845965003195, 'Total loss': 0.808845965003195}
2022-11-22 23:36:51,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:51,215 INFO:     Epoch: 34
2022-11-22 23:36:52,014 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8340191725980152, 'Total loss': 0.8340191725980152} | train loss {'Reaction outcome loss': 0.8128789276005286, 'Total loss': 0.8128789276005286}
2022-11-22 23:36:52,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:52,015 INFO:     Epoch: 35
2022-11-22 23:36:52,824 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8143792135471647, 'Total loss': 0.8143792135471647} | train loss {'Reaction outcome loss': 0.8044158640178108, 'Total loss': 0.8044158640178108}
2022-11-22 23:36:52,824 INFO:     Found new best model at epoch 35
2022-11-22 23:36:52,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:52,825 INFO:     Epoch: 36
2022-11-22 23:36:53,664 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8267300460826267, 'Total loss': 0.8267300460826267} | train loss {'Reaction outcome loss': 0.8054531373475727, 'Total loss': 0.8054531373475727}
2022-11-22 23:36:53,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:53,664 INFO:     Epoch: 37
2022-11-22 23:36:54,454 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8342517641457644, 'Total loss': 0.8342517641457644} | train loss {'Reaction outcome loss': 0.8052003007789372, 'Total loss': 0.8052003007789372}
2022-11-22 23:36:54,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:54,454 INFO:     Epoch: 38
2022-11-22 23:36:55,343 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8434901102022692, 'Total loss': 0.8434901102022692} | train loss {'Reaction outcome loss': 0.8018619332477631, 'Total loss': 0.8018619332477631}
2022-11-22 23:36:55,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:55,343 INFO:     Epoch: 39
2022-11-22 23:36:56,241 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8426550884138454, 'Total loss': 0.8426550884138454} | train loss {'Reaction outcome loss': 0.8101561796448009, 'Total loss': 0.8101561796448009}
2022-11-22 23:36:56,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:56,242 INFO:     Epoch: 40
2022-11-22 23:36:57,111 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8310752273960547, 'Total loss': 0.8310752273960547} | train loss {'Reaction outcome loss': 0.8076677759166672, 'Total loss': 0.8076677759166672}
2022-11-22 23:36:57,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:57,112 INFO:     Epoch: 41
2022-11-22 23:36:57,922 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8339598294008862, 'Total loss': 0.8339598294008862} | train loss {'Reaction outcome loss': 0.8042064604730259, 'Total loss': 0.8042064604730259}
2022-11-22 23:36:57,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:57,922 INFO:     Epoch: 42
2022-11-22 23:36:58,772 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.850701166824861, 'Total loss': 0.850701166824861} | train loss {'Reaction outcome loss': 0.8065109547333196, 'Total loss': 0.8065109547333196}
2022-11-22 23:36:58,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:58,774 INFO:     Epoch: 43
2022-11-22 23:36:59,656 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8300587731328878, 'Total loss': 0.8300587731328878} | train loss {'Reaction outcome loss': 0.803198245945971, 'Total loss': 0.803198245945971}
2022-11-22 23:36:59,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:36:59,656 INFO:     Epoch: 44
2022-11-22 23:37:00,526 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8344638395038518, 'Total loss': 0.8344638395038518} | train loss {'Reaction outcome loss': 0.806618786171863, 'Total loss': 0.806618786171863}
2022-11-22 23:37:00,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:00,526 INFO:     Epoch: 45
2022-11-22 23:37:01,437 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8253129124641418, 'Total loss': 0.8253129124641418} | train loss {'Reaction outcome loss': 0.8029917821831066, 'Total loss': 0.8029917821831066}
2022-11-22 23:37:01,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:01,437 INFO:     Epoch: 46
2022-11-22 23:37:02,327 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8204806785691868, 'Total loss': 0.8204806785691868} | train loss {'Reaction outcome loss': 0.7982017220816149, 'Total loss': 0.7982017220816149}
2022-11-22 23:37:02,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:02,327 INFO:     Epoch: 47
2022-11-22 23:37:03,189 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8423097011717883, 'Total loss': 0.8423097011717883} | train loss {'Reaction outcome loss': 0.8032433230143327, 'Total loss': 0.8032433230143327}
2022-11-22 23:37:03,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:03,190 INFO:     Epoch: 48
2022-11-22 23:37:04,038 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8391221836209297, 'Total loss': 0.8391221836209297} | train loss {'Reaction outcome loss': 0.8044183606259253, 'Total loss': 0.8044183606259253}
2022-11-22 23:37:04,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:04,038 INFO:     Epoch: 49
2022-11-22 23:37:04,936 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8765469234098088, 'Total loss': 0.8765469234098088} | train loss {'Reaction outcome loss': 0.8072829460084197, 'Total loss': 0.8072829460084197}
2022-11-22 23:37:04,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:04,937 INFO:     Epoch: 50
2022-11-22 23:37:05,828 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8361037820577621, 'Total loss': 0.8361037820577621} | train loss {'Reaction outcome loss': 0.80902092261353, 'Total loss': 0.80902092261353}
2022-11-22 23:37:05,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:05,828 INFO:     Epoch: 51
2022-11-22 23:37:06,721 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8469093326817859, 'Total loss': 0.8469093326817859} | train loss {'Reaction outcome loss': 0.8060492540178029, 'Total loss': 0.8060492540178029}
2022-11-22 23:37:06,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:06,721 INFO:     Epoch: 52
2022-11-22 23:37:07,634 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8313071463595737, 'Total loss': 0.8313071463595737} | train loss {'Reaction outcome loss': 0.8029983315149299, 'Total loss': 0.8029983315149299}
2022-11-22 23:37:07,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:07,634 INFO:     Epoch: 53
2022-11-22 23:37:08,550 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8856527114456351, 'Total loss': 0.8856527114456351} | train loss {'Reaction outcome loss': 0.8044655995089033, 'Total loss': 0.8044655995089033}
2022-11-22 23:37:08,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:08,551 INFO:     Epoch: 54
2022-11-22 23:37:09,433 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8340729339556261, 'Total loss': 0.8340729339556261} | train loss {'Reaction outcome loss': 0.8110574751730389, 'Total loss': 0.8110574751730389}
2022-11-22 23:37:09,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:09,433 INFO:     Epoch: 55
2022-11-22 23:37:10,371 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8211947462775491, 'Total loss': 0.8211947462775491} | train loss {'Reaction outcome loss': 0.7991933233372355, 'Total loss': 0.7991933233372355}
2022-11-22 23:37:10,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:10,372 INFO:     Epoch: 56
2022-11-22 23:37:11,238 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8350361477244984, 'Total loss': 0.8350361477244984} | train loss {'Reaction outcome loss': 0.799140013663875, 'Total loss': 0.799140013663875}
2022-11-22 23:37:11,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:11,238 INFO:     Epoch: 57
2022-11-22 23:37:12,074 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8302462832494215, 'Total loss': 0.8302462832494215} | train loss {'Reaction outcome loss': 0.8045690486788267, 'Total loss': 0.8045690486788267}
2022-11-22 23:37:12,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:12,074 INFO:     Epoch: 58
2022-11-22 23:37:12,984 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8460318960926749, 'Total loss': 0.8460318960926749} | train loss {'Reaction outcome loss': 0.8038238986783665, 'Total loss': 0.8038238986783665}
2022-11-22 23:37:12,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:12,984 INFO:     Epoch: 59
2022-11-22 23:37:13,875 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.818324974314733, 'Total loss': 0.818324974314733} | train loss {'Reaction outcome loss': 0.804598468155996, 'Total loss': 0.804598468155996}
2022-11-22 23:37:13,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:13,875 INFO:     Epoch: 60
2022-11-22 23:37:14,801 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8222551169720563, 'Total loss': 0.8222551169720563} | train loss {'Reaction outcome loss': 0.7974402422485082, 'Total loss': 0.7974402422485082}
2022-11-22 23:37:14,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:14,801 INFO:     Epoch: 61
2022-11-22 23:37:15,699 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8434408821842887, 'Total loss': 0.8434408821842887} | train loss {'Reaction outcome loss': 0.8070051989815978, 'Total loss': 0.8070051989815978}
2022-11-22 23:37:15,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:15,700 INFO:     Epoch: 62
2022-11-22 23:37:16,588 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8327230817892335, 'Total loss': 0.8327230817892335} | train loss {'Reaction outcome loss': 0.8026342189263719, 'Total loss': 0.8026342189263719}
2022-11-22 23:37:16,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:16,588 INFO:     Epoch: 63
2022-11-22 23:37:17,478 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8319533284414898, 'Total loss': 0.8319533284414898} | train loss {'Reaction outcome loss': 0.7978042508004165, 'Total loss': 0.7978042508004165}
2022-11-22 23:37:17,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:17,479 INFO:     Epoch: 64
2022-11-22 23:37:18,357 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8360966315323656, 'Total loss': 0.8360966315323656} | train loss {'Reaction outcome loss': 0.794414804049349, 'Total loss': 0.794414804049349}
2022-11-22 23:37:18,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:18,357 INFO:     Epoch: 65
2022-11-22 23:37:19,255 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8703584169799631, 'Total loss': 0.8703584169799631} | train loss {'Reaction outcome loss': 0.8031798164069894, 'Total loss': 0.8031798164069894}
2022-11-22 23:37:19,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:19,255 INFO:     Epoch: 66
2022-11-22 23:37:20,118 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8355397995222699, 'Total loss': 0.8355397995222699} | train loss {'Reaction outcome loss': 0.7993822114670325, 'Total loss': 0.7993822114670325}
2022-11-22 23:37:20,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:20,119 INFO:     Epoch: 67
2022-11-22 23:37:20,981 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8191604831001975, 'Total loss': 0.8191604831001975} | train loss {'Reaction outcome loss': 0.8035706722060678, 'Total loss': 0.8035706722060678}
2022-11-22 23:37:20,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:20,982 INFO:     Epoch: 68
2022-11-22 23:37:21,850 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8243294703689489, 'Total loss': 0.8243294703689489} | train loss {'Reaction outcome loss': 0.79667185777836, 'Total loss': 0.79667185777836}
2022-11-22 23:37:21,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:21,850 INFO:     Epoch: 69
2022-11-22 23:37:22,748 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8231104578484189, 'Total loss': 0.8231104578484189} | train loss {'Reaction outcome loss': 0.8032336868496559, 'Total loss': 0.8032336868496559}
2022-11-22 23:37:22,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:22,748 INFO:     Epoch: 70
2022-11-22 23:37:23,667 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8196935003454034, 'Total loss': 0.8196935003454034} | train loss {'Reaction outcome loss': 0.788389183852354, 'Total loss': 0.788389183852354}
2022-11-22 23:37:23,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:23,667 INFO:     Epoch: 71
2022-11-22 23:37:24,617 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8136600655588236, 'Total loss': 0.8136600655588236} | train loss {'Reaction outcome loss': 0.7964413172079001, 'Total loss': 0.7964413172079001}
2022-11-22 23:37:24,617 INFO:     Found new best model at epoch 71
2022-11-22 23:37:24,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:24,618 INFO:     Epoch: 72
2022-11-22 23:37:25,468 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8070652999661185, 'Total loss': 0.8070652999661185} | train loss {'Reaction outcome loss': 0.7999849261995028, 'Total loss': 0.7999849261995028}
2022-11-22 23:37:25,468 INFO:     Found new best model at epoch 72
2022-11-22 23:37:25,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:25,469 INFO:     Epoch: 73
2022-11-22 23:37:26,344 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8264724917032502, 'Total loss': 0.8264724917032502} | train loss {'Reaction outcome loss': 0.7938305419466274, 'Total loss': 0.7938305419466274}
2022-11-22 23:37:26,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:26,345 INFO:     Epoch: 74
2022-11-22 23:37:27,239 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8363434401425448, 'Total loss': 0.8363434401425448} | train loss {'Reaction outcome loss': 0.7955850988988452, 'Total loss': 0.7955850988988452}
2022-11-22 23:37:27,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:27,239 INFO:     Epoch: 75
2022-11-22 23:37:28,099 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.810701610012488, 'Total loss': 0.810701610012488} | train loss {'Reaction outcome loss': 0.8008734077094537, 'Total loss': 0.8008734077094537}
2022-11-22 23:37:28,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:28,099 INFO:     Epoch: 76
2022-11-22 23:37:28,945 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8040096773342653, 'Total loss': 0.8040096773342653} | train loss {'Reaction outcome loss': 0.7968201434564012, 'Total loss': 0.7968201434564012}
2022-11-22 23:37:28,945 INFO:     Found new best model at epoch 76
2022-11-22 23:37:28,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:28,946 INFO:     Epoch: 77
2022-11-22 23:37:29,818 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8099184970964085, 'Total loss': 0.8099184970964085} | train loss {'Reaction outcome loss': 0.7991848784661003, 'Total loss': 0.7991848784661003}
2022-11-22 23:37:29,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:29,820 INFO:     Epoch: 78
2022-11-22 23:37:30,718 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8180656223134561, 'Total loss': 0.8180656223134561} | train loss {'Reaction outcome loss': 0.7900425857498579, 'Total loss': 0.7900425857498579}
2022-11-22 23:37:30,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:30,718 INFO:     Epoch: 79
2022-11-22 23:37:31,590 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8028005456382578, 'Total loss': 0.8028005456382578} | train loss {'Reaction outcome loss': 0.792129420075822, 'Total loss': 0.792129420075822}
2022-11-22 23:37:31,590 INFO:     Found new best model at epoch 79
2022-11-22 23:37:31,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:31,591 INFO:     Epoch: 80
2022-11-22 23:37:32,465 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8177344541658055, 'Total loss': 0.8177344541658055} | train loss {'Reaction outcome loss': 0.7875118451079859, 'Total loss': 0.7875118451079859}
2022-11-22 23:37:32,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:32,465 INFO:     Epoch: 81
2022-11-22 23:37:33,338 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8759991513057188, 'Total loss': 0.8759991513057188} | train loss {'Reaction outcome loss': 0.7900995160886634, 'Total loss': 0.7900995160886634}
2022-11-22 23:37:33,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:33,339 INFO:     Epoch: 82
2022-11-22 23:37:34,185 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8123726953159679, 'Total loss': 0.8123726953159679} | train loss {'Reaction outcome loss': 0.7868810096672672, 'Total loss': 0.7868810096672672}
2022-11-22 23:37:34,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:34,185 INFO:     Epoch: 83
2022-11-22 23:37:35,060 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8132824416865002, 'Total loss': 0.8132824416865002} | train loss {'Reaction outcome loss': 0.7834838085208344, 'Total loss': 0.7834838085208344}
2022-11-22 23:37:35,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:35,061 INFO:     Epoch: 84
2022-11-22 23:37:35,972 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8166576698422432, 'Total loss': 0.8166576698422432} | train loss {'Reaction outcome loss': 0.7904061000598105, 'Total loss': 0.7904061000598105}
2022-11-22 23:37:35,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:35,973 INFO:     Epoch: 85
2022-11-22 23:37:36,819 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8585179922255602, 'Total loss': 0.8585179922255602} | train loss {'Reaction outcome loss': 0.7970664771462259, 'Total loss': 0.7970664771462259}
2022-11-22 23:37:36,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:36,819 INFO:     Epoch: 86
2022-11-22 23:37:37,659 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8050944209098816, 'Total loss': 0.8050944209098816} | train loss {'Reaction outcome loss': 0.7808028295153548, 'Total loss': 0.7808028295153548}
2022-11-22 23:37:37,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:37,659 INFO:     Epoch: 87
2022-11-22 23:37:38,521 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.835204994136637, 'Total loss': 0.835204994136637} | train loss {'Reaction outcome loss': 0.7904644182577789, 'Total loss': 0.7904644182577789}
2022-11-22 23:37:38,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:38,521 INFO:     Epoch: 88
2022-11-22 23:37:39,440 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8235675238750197, 'Total loss': 0.8235675238750197} | train loss {'Reaction outcome loss': 0.7841067084899316, 'Total loss': 0.7841067084899316}
2022-11-22 23:37:39,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:39,440 INFO:     Epoch: 89
2022-11-22 23:37:40,317 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8160868693481792, 'Total loss': 0.8160868693481792} | train loss {'Reaction outcome loss': 0.7919997482405983, 'Total loss': 0.7919997482405983}
2022-11-22 23:37:40,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:40,317 INFO:     Epoch: 90
2022-11-22 23:37:41,197 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8138716532425447, 'Total loss': 0.8138716532425447} | train loss {'Reaction outcome loss': 0.7835138897573658, 'Total loss': 0.7835138897573658}
2022-11-22 23:37:41,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:41,197 INFO:     Epoch: 91
2022-11-22 23:37:42,024 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8084576035087759, 'Total loss': 0.8084576035087759} | train loss {'Reaction outcome loss': 0.7842899799527909, 'Total loss': 0.7842899799527909}
2022-11-22 23:37:42,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:42,024 INFO:     Epoch: 92
2022-11-22 23:37:42,943 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8195444135503336, 'Total loss': 0.8195444135503336} | train loss {'Reaction outcome loss': 0.789219453749869, 'Total loss': 0.789219453749869}
2022-11-22 23:37:42,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:42,943 INFO:     Epoch: 93
2022-11-22 23:37:43,808 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7935099026018922, 'Total loss': 0.7935099026018922} | train loss {'Reaction outcome loss': 0.7861669281957603, 'Total loss': 0.7861669281957603}
2022-11-22 23:37:43,808 INFO:     Found new best model at epoch 93
2022-11-22 23:37:43,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:43,809 INFO:     Epoch: 94
2022-11-22 23:37:44,688 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7918126556006345, 'Total loss': 0.7918126556006345} | train loss {'Reaction outcome loss': 0.7790871529202712, 'Total loss': 0.7790871529202712}
2022-11-22 23:37:44,688 INFO:     Found new best model at epoch 94
2022-11-22 23:37:44,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:44,689 INFO:     Epoch: 95
2022-11-22 23:37:45,604 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8415456719019196, 'Total loss': 0.8415456719019196} | train loss {'Reaction outcome loss': 0.7845164848725322, 'Total loss': 0.7845164848725322}
2022-11-22 23:37:45,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:45,604 INFO:     Epoch: 96
2022-11-22 23:37:46,521 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8098572377454151, 'Total loss': 0.8098572377454151} | train loss {'Reaction outcome loss': 0.7917707888220968, 'Total loss': 0.7917707888220968}
2022-11-22 23:37:46,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:46,521 INFO:     Epoch: 97
2022-11-22 23:37:47,395 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8083895729346708, 'Total loss': 0.8083895729346708} | train loss {'Reaction outcome loss': 0.7827105470273176, 'Total loss': 0.7827105470273176}
2022-11-22 23:37:47,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:47,396 INFO:     Epoch: 98
2022-11-22 23:37:48,259 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8243659992109645, 'Total loss': 0.8243659992109645} | train loss {'Reaction outcome loss': 0.7904347533639143, 'Total loss': 0.7904347533639143}
2022-11-22 23:37:48,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:48,260 INFO:     Epoch: 99
2022-11-22 23:37:49,138 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8009406538172201, 'Total loss': 0.8009406538172201} | train loss {'Reaction outcome loss': 0.7779805142930162, 'Total loss': 0.7779805142930162}
2022-11-22 23:37:49,139 INFO:     Best model found after epoch 95 of 100.
2022-11-22 23:37:49,139 INFO:   Done with stage: TRAINING
2022-11-22 23:37:49,139 INFO:   Starting stage: EVALUATION
2022-11-22 23:37:49,264 INFO:   Done with stage: EVALUATION
2022-11-22 23:37:49,273 INFO:   Leaving out SEQ value Fold_0
2022-11-22 23:37:49,287 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-22 23:37:49,287 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:37:49,957 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:37:49,958 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:37:50,028 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:37:50,028 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:37:50,029 INFO:     No hyperparam tuning for this model
2022-11-22 23:37:50,029 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:37:50,029 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:37:50,030 INFO:     None feature selector for col prot
2022-11-22 23:37:50,030 INFO:     None feature selector for col prot
2022-11-22 23:37:50,030 INFO:     None feature selector for col prot
2022-11-22 23:37:50,030 INFO:     None feature selector for col chem
2022-11-22 23:37:50,030 INFO:     None feature selector for col chem
2022-11-22 23:37:50,031 INFO:     None feature selector for col chem
2022-11-22 23:37:50,031 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:37:50,031 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:37:50,032 INFO:     Number of params in model 168571
2022-11-22 23:37:50,035 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:37:50,035 INFO:   Starting stage: TRAINING
2022-11-22 23:37:50,093 INFO:     Val loss before train {'Reaction outcome loss': 0.9506628762843997, 'Total loss': 0.9506628762843997}
2022-11-22 23:37:50,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:50,094 INFO:     Epoch: 0
2022-11-22 23:37:50,915 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7714383387288382, 'Total loss': 0.7714383387288382} | train loss {'Reaction outcome loss': 0.8761539221300509, 'Total loss': 0.8761539221300509}
2022-11-22 23:37:50,915 INFO:     Found new best model at epoch 0
2022-11-22 23:37:50,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:50,916 INFO:     Epoch: 1
2022-11-22 23:37:51,747 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8062218593996625, 'Total loss': 0.8062218593996625} | train loss {'Reaction outcome loss': 0.8518859231422958, 'Total loss': 0.8518859231422958}
2022-11-22 23:37:51,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:51,747 INFO:     Epoch: 2
2022-11-22 23:37:52,629 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7831403224967247, 'Total loss': 0.7831403224967247} | train loss {'Reaction outcome loss': 0.8437084464869872, 'Total loss': 0.8437084464869872}
2022-11-22 23:37:52,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:52,630 INFO:     Epoch: 3
2022-11-22 23:37:53,472 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7623387630595717, 'Total loss': 0.7623387630595717} | train loss {'Reaction outcome loss': 0.8395989049118733, 'Total loss': 0.8395989049118733}
2022-11-22 23:37:53,472 INFO:     Found new best model at epoch 3
2022-11-22 23:37:53,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:53,473 INFO:     Epoch: 4
2022-11-22 23:37:54,281 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.768474607966667, 'Total loss': 0.768474607966667} | train loss {'Reaction outcome loss': 0.8329257117622674, 'Total loss': 0.8329257117622674}
2022-11-22 23:37:54,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:54,282 INFO:     Epoch: 5
2022-11-22 23:37:55,133 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7616208479848019, 'Total loss': 0.7616208479848019} | train loss {'Reaction outcome loss': 0.8283919967986919, 'Total loss': 0.8283919967986919}
2022-11-22 23:37:55,133 INFO:     Found new best model at epoch 5
2022-11-22 23:37:55,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:55,134 INFO:     Epoch: 6
2022-11-22 23:37:55,969 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7560071279836256, 'Total loss': 0.7560071279836256} | train loss {'Reaction outcome loss': 0.8284630635638296, 'Total loss': 0.8284630635638296}
2022-11-22 23:37:55,969 INFO:     Found new best model at epoch 6
2022-11-22 23:37:55,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:55,970 INFO:     Epoch: 7
2022-11-22 23:37:56,883 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7756648458713709, 'Total loss': 0.7756648458713709} | train loss {'Reaction outcome loss': 0.8260532557473752, 'Total loss': 0.8260532557473752}
2022-11-22 23:37:56,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:56,883 INFO:     Epoch: 8
2022-11-22 23:37:57,698 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.772777256577514, 'Total loss': 0.772777256577514} | train loss {'Reaction outcome loss': 0.8188684581483833, 'Total loss': 0.8188684581483833}
2022-11-22 23:37:57,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:57,698 INFO:     Epoch: 9
2022-11-22 23:37:58,518 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7775546714316967, 'Total loss': 0.7775546714316967} | train loss {'Reaction outcome loss': 0.8229632754139449, 'Total loss': 0.8229632754139449}
2022-11-22 23:37:58,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:58,518 INFO:     Epoch: 10
2022-11-22 23:37:59,343 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.766078115895737, 'Total loss': 0.766078115895737} | train loss {'Reaction outcome loss': 0.8201302529117207, 'Total loss': 0.8201302529117207}
2022-11-22 23:37:59,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:37:59,344 INFO:     Epoch: 11
2022-11-22 23:38:00,181 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7695994987044223, 'Total loss': 0.7695994987044223} | train loss {'Reaction outcome loss': 0.8210904538140866, 'Total loss': 0.8210904538140866}
2022-11-22 23:38:00,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:00,183 INFO:     Epoch: 12
2022-11-22 23:38:01,004 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.777171864066013, 'Total loss': 0.777171864066013} | train loss {'Reaction outcome loss': 0.8235272779876803, 'Total loss': 0.8235272779876803}
2022-11-22 23:38:01,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:01,004 INFO:     Epoch: 13
2022-11-22 23:38:01,845 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7794249861739403, 'Total loss': 0.7794249861739403} | train loss {'Reaction outcome loss': 0.8199126511934853, 'Total loss': 0.8199126511934853}
2022-11-22 23:38:01,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:01,846 INFO:     Epoch: 14
2022-11-22 23:38:02,664 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7510597026625345, 'Total loss': 0.7510597026625345} | train loss {'Reaction outcome loss': 0.8175386575514397, 'Total loss': 0.8175386575514397}
2022-11-22 23:38:02,665 INFO:     Found new best model at epoch 14
2022-11-22 23:38:02,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:02,666 INFO:     Epoch: 15
2022-11-22 23:38:03,530 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7669926881790161, 'Total loss': 0.7669926881790161} | train loss {'Reaction outcome loss': 0.8245564802193347, 'Total loss': 0.8245564802193347}
2022-11-22 23:38:03,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:03,531 INFO:     Epoch: 16
2022-11-22 23:38:04,354 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8196816583012425, 'Total loss': 0.8196816583012425} | train loss {'Reaction outcome loss': 0.8184215787629532, 'Total loss': 0.8184215787629532}
2022-11-22 23:38:04,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:04,355 INFO:     Epoch: 17
2022-11-22 23:38:05,183 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7474177978759589, 'Total loss': 0.7474177978759589} | train loss {'Reaction outcome loss': 0.8225519636285649, 'Total loss': 0.8225519636285649}
2022-11-22 23:38:05,183 INFO:     Found new best model at epoch 17
2022-11-22 23:38:05,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:05,184 INFO:     Epoch: 18
2022-11-22 23:38:05,995 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7551458907681842, 'Total loss': 0.7551458907681842} | train loss {'Reaction outcome loss': 0.8183228558718912, 'Total loss': 0.8183228558718912}
2022-11-22 23:38:05,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:05,995 INFO:     Epoch: 19
2022-11-22 23:38:06,782 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7671235460181569, 'Total loss': 0.7671235460181569} | train loss {'Reaction outcome loss': 0.8170450849788179, 'Total loss': 0.8170450849788179}
2022-11-22 23:38:06,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:06,783 INFO:     Epoch: 20
2022-11-22 23:38:07,630 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7542274670545445, 'Total loss': 0.7542274670545445} | train loss {'Reaction outcome loss': 0.8186448325590833, 'Total loss': 0.8186448325590833}
2022-11-22 23:38:07,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:07,631 INFO:     Epoch: 21
2022-11-22 23:38:08,426 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7872274531874546, 'Total loss': 0.7872274531874546} | train loss {'Reaction outcome loss': 0.8185339915899583, 'Total loss': 0.8185339915899583}
2022-11-22 23:38:08,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:08,427 INFO:     Epoch: 22
2022-11-22 23:38:09,208 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.794631608696871, 'Total loss': 0.794631608696871} | train loss {'Reaction outcome loss': 0.8166316822477819, 'Total loss': 0.8166316822477819}
2022-11-22 23:38:09,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:09,209 INFO:     Epoch: 23
2022-11-22 23:38:10,040 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.764757924994757, 'Total loss': 0.764757924994757} | train loss {'Reaction outcome loss': 0.821899027858742, 'Total loss': 0.821899027858742}
2022-11-22 23:38:10,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:10,040 INFO:     Epoch: 24
2022-11-22 23:38:10,840 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7534468225961508, 'Total loss': 0.7534468225961508} | train loss {'Reaction outcome loss': 0.8218906014053909, 'Total loss': 0.8218906014053909}
2022-11-22 23:38:10,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:10,841 INFO:     Epoch: 25
2022-11-22 23:38:11,623 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7665674062662347, 'Total loss': 0.7665674062662347} | train loss {'Reaction outcome loss': 0.8220679782055043, 'Total loss': 0.8220679782055043}
2022-11-22 23:38:11,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:11,624 INFO:     Epoch: 26
2022-11-22 23:38:12,448 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7705566876156386, 'Total loss': 0.7705566876156386} | train loss {'Reaction outcome loss': 0.8161006438634033, 'Total loss': 0.8161006438634033}
2022-11-22 23:38:12,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:12,448 INFO:     Epoch: 27
2022-11-22 23:38:13,272 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.766079518684121, 'Total loss': 0.766079518684121} | train loss {'Reaction outcome loss': 0.8190741682494128, 'Total loss': 0.8190741682494128}
2022-11-22 23:38:13,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:13,272 INFO:     Epoch: 28
2022-11-22 23:38:14,023 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7526309379311495, 'Total loss': 0.7526309379311495} | train loss {'Reaction outcome loss': 0.8222590894610794, 'Total loss': 0.8222590894610794}
2022-11-22 23:38:14,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:14,023 INFO:     Epoch: 29
2022-11-22 23:38:14,823 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7620237961758015, 'Total loss': 0.7620237961758015} | train loss {'Reaction outcome loss': 0.8160978002558029, 'Total loss': 0.8160978002558029}
2022-11-22 23:38:14,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:14,823 INFO:     Epoch: 30
2022-11-22 23:38:15,643 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7724846747032431, 'Total loss': 0.7724846747032431} | train loss {'Reaction outcome loss': 0.8190986977683173, 'Total loss': 0.8190986977683173}
2022-11-22 23:38:15,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:15,644 INFO:     Epoch: 31
2022-11-22 23:38:16,451 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7659069971982823, 'Total loss': 0.7659069971982823} | train loss {'Reaction outcome loss': 0.8199711438314414, 'Total loss': 0.8199711438314414}
2022-11-22 23:38:16,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:16,451 INFO:     Epoch: 32
2022-11-22 23:38:17,215 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7527467712413433, 'Total loss': 0.7527467712413433} | train loss {'Reaction outcome loss': 0.812618772802039, 'Total loss': 0.812618772802039}
2022-11-22 23:38:17,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:17,215 INFO:     Epoch: 33
2022-11-22 23:38:18,036 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7756640966548476, 'Total loss': 0.7756640966548476} | train loss {'Reaction outcome loss': 0.8153218765562944, 'Total loss': 0.8153218765562944}
2022-11-22 23:38:18,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:18,036 INFO:     Epoch: 34
2022-11-22 23:38:18,840 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7623048986113349, 'Total loss': 0.7623048986113349} | train loss {'Reaction outcome loss': 0.8228171606367998, 'Total loss': 0.8228171606367998}
2022-11-22 23:38:18,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:18,841 INFO:     Epoch: 35
2022-11-22 23:38:19,644 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7698914367099141, 'Total loss': 0.7698914367099141} | train loss {'Reaction outcome loss': 0.8199193061869822, 'Total loss': 0.8199193061869822}
2022-11-22 23:38:19,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:19,644 INFO:     Epoch: 36
2022-11-22 23:38:20,467 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7579813052055447, 'Total loss': 0.7579813052055447} | train loss {'Reaction outcome loss': 0.8161351110464261, 'Total loss': 0.8161351110464261}
2022-11-22 23:38:20,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:20,468 INFO:     Epoch: 37
2022-11-22 23:38:21,272 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7621102568715118, 'Total loss': 0.7621102568715118} | train loss {'Reaction outcome loss': 0.8205552993978492, 'Total loss': 0.8205552993978492}
2022-11-22 23:38:21,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:21,272 INFO:     Epoch: 38
2022-11-22 23:38:22,048 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7635329254837924, 'Total loss': 0.7635329254837924} | train loss {'Reaction outcome loss': 0.821013138495355, 'Total loss': 0.821013138495355}
2022-11-22 23:38:22,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:22,049 INFO:     Epoch: 39
2022-11-22 23:38:22,822 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7505955190159553, 'Total loss': 0.7505955190159553} | train loss {'Reaction outcome loss': 0.8162756678744109, 'Total loss': 0.8162756678744109}
2022-11-22 23:38:22,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:22,822 INFO:     Epoch: 40
2022-11-22 23:38:23,603 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7499664113965145, 'Total loss': 0.7499664113965145} | train loss {'Reaction outcome loss': 0.8144106906627921, 'Total loss': 0.8144106906627921}
2022-11-22 23:38:23,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:23,603 INFO:     Epoch: 41
2022-11-22 23:38:24,438 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7785738595696383, 'Total loss': 0.7785738595696383} | train loss {'Reaction outcome loss': 0.8195189890056971, 'Total loss': 0.8195189890056971}
2022-11-22 23:38:24,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:24,438 INFO:     Epoch: 42
2022-11-22 23:38:25,257 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7481232015199439, 'Total loss': 0.7481232015199439} | train loss {'Reaction outcome loss': 0.8165051739647555, 'Total loss': 0.8165051739647555}
2022-11-22 23:38:25,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:25,257 INFO:     Epoch: 43
2022-11-22 23:38:26,036 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7686398694681567, 'Total loss': 0.7686398694681567} | train loss {'Reaction outcome loss': 0.8166531681278606, 'Total loss': 0.8166531681278606}
2022-11-22 23:38:26,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:26,036 INFO:     Epoch: 44
2022-11-22 23:38:26,856 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7574437510135562, 'Total loss': 0.7574437510135562} | train loss {'Reaction outcome loss': 0.8203983873496821, 'Total loss': 0.8203983873496821}
2022-11-22 23:38:26,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:26,856 INFO:     Epoch: 45
2022-11-22 23:38:27,688 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7466456439605978, 'Total loss': 0.7466456439605978} | train loss {'Reaction outcome loss': 0.8176790125085494, 'Total loss': 0.8176790125085494}
2022-11-22 23:38:27,688 INFO:     Found new best model at epoch 45
2022-11-22 23:38:27,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:27,689 INFO:     Epoch: 46
2022-11-22 23:38:28,452 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7574169303095618, 'Total loss': 0.7574169303095618} | train loss {'Reaction outcome loss': 0.8167661488546756, 'Total loss': 0.8167661488546756}
2022-11-22 23:38:28,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:28,452 INFO:     Epoch: 47
2022-11-22 23:38:29,260 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7624228894710541, 'Total loss': 0.7624228894710541} | train loss {'Reaction outcome loss': 0.8153745925720827, 'Total loss': 0.8153745925720827}
2022-11-22 23:38:29,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:29,260 INFO:     Epoch: 48
2022-11-22 23:38:30,093 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7490118437035139, 'Total loss': 0.7490118437035139} | train loss {'Reaction outcome loss': 0.8199263950924814, 'Total loss': 0.8199263950924814}
2022-11-22 23:38:30,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:30,093 INFO:     Epoch: 49
2022-11-22 23:38:30,908 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7579003253648448, 'Total loss': 0.7579003253648448} | train loss {'Reaction outcome loss': 0.8162908381150092, 'Total loss': 0.8162908381150092}
2022-11-22 23:38:30,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:30,908 INFO:     Epoch: 50
2022-11-22 23:38:31,717 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7602776288986206, 'Total loss': 0.7602776288986206} | train loss {'Reaction outcome loss': 0.819131045061865, 'Total loss': 0.819131045061865}
2022-11-22 23:38:31,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:31,718 INFO:     Epoch: 51
2022-11-22 23:38:32,576 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7603630347307339, 'Total loss': 0.7603630347307339} | train loss {'Reaction outcome loss': 0.8212736928413925, 'Total loss': 0.8212736928413925}
2022-11-22 23:38:32,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:32,577 INFO:     Epoch: 52
2022-11-22 23:38:33,360 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7602507534415223, 'Total loss': 0.7602507534415223} | train loss {'Reaction outcome loss': 0.8134034047892065, 'Total loss': 0.8134034047892065}
2022-11-22 23:38:33,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:33,360 INFO:     Epoch: 53
2022-11-22 23:38:34,138 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7752336374548978, 'Total loss': 0.7752336374548978} | train loss {'Reaction outcome loss': 0.8153119750719502, 'Total loss': 0.8153119750719502}
2022-11-22 23:38:34,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:34,138 INFO:     Epoch: 54
2022-11-22 23:38:34,915 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7603581298229306, 'Total loss': 0.7603581298229306} | train loss {'Reaction outcome loss': 0.8169577768064821, 'Total loss': 0.8169577768064821}
2022-11-22 23:38:34,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:34,915 INFO:     Epoch: 55
2022-11-22 23:38:35,710 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7597277157528456, 'Total loss': 0.7597277157528456} | train loss {'Reaction outcome loss': 0.8156112107475109, 'Total loss': 0.8156112107475109}
2022-11-22 23:38:35,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:35,710 INFO:     Epoch: 56
2022-11-22 23:38:36,520 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7604510153448859, 'Total loss': 0.7604510153448859} | train loss {'Reaction outcome loss': 0.8172354430818753, 'Total loss': 0.8172354430818753}
2022-11-22 23:38:36,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:36,520 INFO:     Epoch: 57
2022-11-22 23:38:37,292 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.756464246400567, 'Total loss': 0.756464246400567} | train loss {'Reaction outcome loss': 0.8134750012507654, 'Total loss': 0.8134750012507654}
2022-11-22 23:38:37,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:37,292 INFO:     Epoch: 58
2022-11-22 23:38:38,063 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7620882066183312, 'Total loss': 0.7620882066183312} | train loss {'Reaction outcome loss': 0.8174529382230814, 'Total loss': 0.8174529382230814}
2022-11-22 23:38:38,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:38,064 INFO:     Epoch: 59
2022-11-22 23:38:38,867 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7555581525314686, 'Total loss': 0.7555581525314686} | train loss {'Reaction outcome loss': 0.820075727539298, 'Total loss': 0.820075727539298}
2022-11-22 23:38:38,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:38,867 INFO:     Epoch: 60
2022-11-22 23:38:39,650 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7548625621684762, 'Total loss': 0.7548625621684762} | train loss {'Reaction outcome loss': 0.8166824413670434, 'Total loss': 0.8166824413670434}
2022-11-22 23:38:39,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:39,650 INFO:     Epoch: 61
2022-11-22 23:38:40,482 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7621987864028575, 'Total loss': 0.7621987864028575} | train loss {'Reaction outcome loss': 0.8156949622640884, 'Total loss': 0.8156949622640884}
2022-11-22 23:38:40,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:40,482 INFO:     Epoch: 62
2022-11-22 23:38:41,331 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7662110474220541, 'Total loss': 0.7662110474220541} | train loss {'Reaction outcome loss': 0.8135430137071099, 'Total loss': 0.8135430137071099}
2022-11-22 23:38:41,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:41,332 INFO:     Epoch: 63
2022-11-22 23:38:42,122 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7621529795402704, 'Total loss': 0.7621529795402704} | train loss {'Reaction outcome loss': 0.8176565798221792, 'Total loss': 0.8176565798221792}
2022-11-22 23:38:42,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:42,122 INFO:     Epoch: 64
2022-11-22 23:38:42,898 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7552869881308356, 'Total loss': 0.7552869881308356} | train loss {'Reaction outcome loss': 0.8133759324442703, 'Total loss': 0.8133759324442703}
2022-11-22 23:38:42,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:42,898 INFO:     Epoch: 65
2022-11-22 23:38:43,727 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7588465879129809, 'Total loss': 0.7588465879129809} | train loss {'Reaction outcome loss': 0.8163885585810422, 'Total loss': 0.8163885585810422}
2022-11-22 23:38:43,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:43,727 INFO:     Epoch: 66
2022-11-22 23:38:44,507 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7816288589045058, 'Total loss': 0.7816288589045058} | train loss {'Reaction outcome loss': 0.816050394449705, 'Total loss': 0.816050394449705}
2022-11-22 23:38:44,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:44,507 INFO:     Epoch: 67
2022-11-22 23:38:45,310 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7553574193355649, 'Total loss': 0.7553574193355649} | train loss {'Reaction outcome loss': 0.8154117875874288, 'Total loss': 0.8154117875874288}
2022-11-22 23:38:45,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:45,311 INFO:     Epoch: 68
2022-11-22 23:38:46,118 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7582622260548347, 'Total loss': 0.7582622260548347} | train loss {'Reaction outcome loss': 0.8168011528474314, 'Total loss': 0.8168011528474314}
2022-11-22 23:38:46,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:46,118 INFO:     Epoch: 69
2022-11-22 23:38:46,932 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7450033273807791, 'Total loss': 0.7450033273807791} | train loss {'Reaction outcome loss': 0.8177143220057703, 'Total loss': 0.8177143220057703}
2022-11-22 23:38:46,932 INFO:     Found new best model at epoch 69
2022-11-22 23:38:46,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:46,933 INFO:     Epoch: 70
2022-11-22 23:38:47,757 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7588529995707578, 'Total loss': 0.7588529995707578} | train loss {'Reaction outcome loss': 0.8196421128241613, 'Total loss': 0.8196421128241613}
2022-11-22 23:38:47,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:47,758 INFO:     Epoch: 71
2022-11-22 23:38:48,512 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7670131325721741, 'Total loss': 0.7670131325721741} | train loss {'Reaction outcome loss': 0.8231404063142376, 'Total loss': 0.8231404063142376}
2022-11-22 23:38:48,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:48,512 INFO:     Epoch: 72
2022-11-22 23:38:49,306 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.76946391546449, 'Total loss': 0.76946391546449} | train loss {'Reaction outcome loss': 0.8204955777513637, 'Total loss': 0.8204955777513637}
2022-11-22 23:38:49,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:49,306 INFO:     Epoch: 73
2022-11-22 23:38:50,096 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.755698308002117, 'Total loss': 0.755698308002117} | train loss {'Reaction outcome loss': 0.8153064560007166, 'Total loss': 0.8153064560007166}
2022-11-22 23:38:50,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:50,097 INFO:     Epoch: 74
2022-11-22 23:38:50,871 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7432333390380061, 'Total loss': 0.7432333390380061} | train loss {'Reaction outcome loss': 0.815664636622731, 'Total loss': 0.815664636622731}
2022-11-22 23:38:50,872 INFO:     Found new best model at epoch 74
2022-11-22 23:38:50,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:50,872 INFO:     Epoch: 75
2022-11-22 23:38:51,691 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7444916762584863, 'Total loss': 0.7444916762584863} | train loss {'Reaction outcome loss': 0.8147336834497413, 'Total loss': 0.8147336834497413}
2022-11-22 23:38:51,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:51,691 INFO:     Epoch: 76
2022-11-22 23:38:52,481 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7820730791535488, 'Total loss': 0.7820730791535488} | train loss {'Reaction outcome loss': 0.8106986601902134, 'Total loss': 0.8106986601902134}
2022-11-22 23:38:52,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:52,481 INFO:     Epoch: 77
2022-11-22 23:38:53,288 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7717479481253513, 'Total loss': 0.7717479481253513} | train loss {'Reaction outcome loss': 0.8199340025338616, 'Total loss': 0.8199340025338616}
2022-11-22 23:38:53,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:53,289 INFO:     Epoch: 78
2022-11-22 23:38:54,062 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7713044119435687, 'Total loss': 0.7713044119435687} | train loss {'Reaction outcome loss': 0.8195484421012823, 'Total loss': 0.8195484421012823}
2022-11-22 23:38:54,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:54,063 INFO:     Epoch: 79
2022-11-22 23:38:54,807 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7580942463043124, 'Total loss': 0.7580942463043124} | train loss {'Reaction outcome loss': 0.815093924724516, 'Total loss': 0.815093924724516}
2022-11-22 23:38:54,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:54,808 INFO:     Epoch: 80
2022-11-22 23:38:55,610 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.77561306745507, 'Total loss': 0.77561306745507} | train loss {'Reaction outcome loss': 0.8168337993906358, 'Total loss': 0.8168337993906358}
2022-11-22 23:38:55,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:55,611 INFO:     Epoch: 81
2022-11-22 23:38:56,410 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7631712084592774, 'Total loss': 0.7631712084592774} | train loss {'Reaction outcome loss': 0.8190117919273338, 'Total loss': 0.8190117919273338}
2022-11-22 23:38:56,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:56,411 INFO:     Epoch: 82
2022-11-22 23:38:57,194 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7642630893130635, 'Total loss': 0.7642630893130635} | train loss {'Reaction outcome loss': 0.822311779231201, 'Total loss': 0.822311779231201}
2022-11-22 23:38:57,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:57,195 INFO:     Epoch: 83
2022-11-22 23:38:57,993 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7742654286151709, 'Total loss': 0.7742654286151709} | train loss {'Reaction outcome loss': 0.81522567588606, 'Total loss': 0.81522567588606}
2022-11-22 23:38:57,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:57,993 INFO:     Epoch: 84
2022-11-22 23:38:58,792 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.753733460986337, 'Total loss': 0.753733460986337} | train loss {'Reaction outcome loss': 0.813565245933003, 'Total loss': 0.813565245933003}
2022-11-22 23:38:58,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:58,792 INFO:     Epoch: 85
2022-11-22 23:38:59,546 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7544264599334362, 'Total loss': 0.7544264599334362} | train loss {'Reaction outcome loss': 0.8124367472075631, 'Total loss': 0.8124367472075631}
2022-11-22 23:38:59,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:38:59,547 INFO:     Epoch: 86
2022-11-22 23:39:00,364 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7690836565439091, 'Total loss': 0.7690836565439091} | train loss {'Reaction outcome loss': 0.818833620827875, 'Total loss': 0.818833620827875}
2022-11-22 23:39:00,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:00,365 INFO:     Epoch: 87
2022-11-22 23:39:01,158 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7457894225453221, 'Total loss': 0.7457894225453221} | train loss {'Reaction outcome loss': 0.8173693667468711, 'Total loss': 0.8173693667468711}
2022-11-22 23:39:01,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:01,158 INFO:     Epoch: 88
2022-11-22 23:39:01,924 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7565066370853158, 'Total loss': 0.7565066370853158} | train loss {'Reaction outcome loss': 0.8179469685005062, 'Total loss': 0.8179469685005062}
2022-11-22 23:39:01,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:01,925 INFO:     Epoch: 89
2022-11-22 23:39:02,725 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7724454430646674, 'Total loss': 0.7724454430646674} | train loss {'Reaction outcome loss': 0.8181136152381269, 'Total loss': 0.8181136152381269}
2022-11-22 23:39:02,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:02,726 INFO:     Epoch: 90
2022-11-22 23:39:03,579 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7558859087700067, 'Total loss': 0.7558859087700067} | train loss {'Reaction outcome loss': 0.8165117299851076, 'Total loss': 0.8165117299851076}
2022-11-22 23:39:03,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:03,580 INFO:     Epoch: 91
2022-11-22 23:39:04,375 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7737022596736287, 'Total loss': 0.7737022596736287} | train loss {'Reaction outcome loss': 0.8170151150030364, 'Total loss': 0.8170151150030364}
2022-11-22 23:39:04,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:04,375 INFO:     Epoch: 92
2022-11-22 23:39:05,226 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7550628621910893, 'Total loss': 0.7550628621910893} | train loss {'Reaction outcome loss': 0.8176924255159166, 'Total loss': 0.8176924255159166}
2022-11-22 23:39:05,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:05,226 INFO:     Epoch: 93
2022-11-22 23:39:06,025 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.768409900887068, 'Total loss': 0.768409900887068} | train loss {'Reaction outcome loss': 0.8160695443428102, 'Total loss': 0.8160695443428102}
2022-11-22 23:39:06,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:06,026 INFO:     Epoch: 94
2022-11-22 23:39:06,827 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7549232944499614, 'Total loss': 0.7549232944499614} | train loss {'Reaction outcome loss': 0.8167732822796936, 'Total loss': 0.8167732822796936}
2022-11-22 23:39:06,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:06,827 INFO:     Epoch: 95
2022-11-22 23:39:07,622 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7556491196155548, 'Total loss': 0.7556491196155548} | train loss {'Reaction outcome loss': 0.814291802453406, 'Total loss': 0.814291802453406}
2022-11-22 23:39:07,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:07,622 INFO:     Epoch: 96
2022-11-22 23:39:08,457 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7677458850450294, 'Total loss': 0.7677458850450294} | train loss {'Reaction outcome loss': 0.816382535691124, 'Total loss': 0.816382535691124}
2022-11-22 23:39:08,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:08,457 INFO:     Epoch: 97
2022-11-22 23:39:09,213 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7559778343799503, 'Total loss': 0.7559778343799503} | train loss {'Reaction outcome loss': 0.8148594573446752, 'Total loss': 0.8148594573446752}
2022-11-22 23:39:09,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:09,214 INFO:     Epoch: 98
2022-11-22 23:39:10,017 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7667424560979356, 'Total loss': 0.7667424560979356} | train loss {'Reaction outcome loss': 0.8129278466779999, 'Total loss': 0.8129278466779999}
2022-11-22 23:39:10,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:10,018 INFO:     Epoch: 99
2022-11-22 23:39:10,838 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7546515166759491, 'Total loss': 0.7546515166759491} | train loss {'Reaction outcome loss': 0.8147563794512808, 'Total loss': 0.8147563794512808}
2022-11-22 23:39:10,838 INFO:     Best model found after epoch 75 of 100.
2022-11-22 23:39:10,839 INFO:   Done with stage: TRAINING
2022-11-22 23:39:10,839 INFO:   Starting stage: EVALUATION
2022-11-22 23:39:10,981 INFO:   Done with stage: EVALUATION
2022-11-22 23:39:10,981 INFO:   Leaving out SEQ value Fold_1
2022-11-22 23:39:10,994 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:39:10,994 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:39:11,657 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:39:11,657 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:39:11,726 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:39:11,726 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:39:11,726 INFO:     No hyperparam tuning for this model
2022-11-22 23:39:11,726 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:39:11,726 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:39:11,727 INFO:     None feature selector for col prot
2022-11-22 23:39:11,727 INFO:     None feature selector for col prot
2022-11-22 23:39:11,727 INFO:     None feature selector for col prot
2022-11-22 23:39:11,728 INFO:     None feature selector for col chem
2022-11-22 23:39:11,728 INFO:     None feature selector for col chem
2022-11-22 23:39:11,728 INFO:     None feature selector for col chem
2022-11-22 23:39:11,728 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:39:11,728 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:39:11,729 INFO:     Number of params in model 168571
2022-11-22 23:39:11,732 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:39:11,732 INFO:   Starting stage: TRAINING
2022-11-22 23:39:11,791 INFO:     Val loss before train {'Reaction outcome loss': 1.0277712914076718, 'Total loss': 1.0277712914076718}
2022-11-22 23:39:11,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:11,791 INFO:     Epoch: 0
2022-11-22 23:39:12,580 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.841337925331159, 'Total loss': 0.841337925331159} | train loss {'Reaction outcome loss': 0.8830854933754153, 'Total loss': 0.8830854933754153}
2022-11-22 23:39:12,580 INFO:     Found new best model at epoch 0
2022-11-22 23:39:12,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:12,581 INFO:     Epoch: 1
2022-11-22 23:39:13,363 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8447707573121245, 'Total loss': 0.8447707573121245} | train loss {'Reaction outcome loss': 0.8555267844122914, 'Total loss': 0.8555267844122914}
2022-11-22 23:39:13,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:13,363 INFO:     Epoch: 2
2022-11-22 23:39:14,182 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8039204789833589, 'Total loss': 0.8039204789833589} | train loss {'Reaction outcome loss': 0.8444695162628344, 'Total loss': 0.8444695162628344}
2022-11-22 23:39:14,182 INFO:     Found new best model at epoch 2
2022-11-22 23:39:14,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:14,183 INFO:     Epoch: 3
2022-11-22 23:39:15,016 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8354734250090339, 'Total loss': 0.8354734250090339} | train loss {'Reaction outcome loss': 0.8341619530428759, 'Total loss': 0.8341619530428759}
2022-11-22 23:39:15,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:15,017 INFO:     Epoch: 4
2022-11-22 23:39:15,844 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8160171996463429, 'Total loss': 0.8160171996463429} | train loss {'Reaction outcome loss': 0.8436343883454558, 'Total loss': 0.8436343883454558}
2022-11-22 23:39:15,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:15,844 INFO:     Epoch: 5
2022-11-22 23:39:16,695 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8005729453130201, 'Total loss': 0.8005729453130201} | train loss {'Reaction outcome loss': 0.8297401245095228, 'Total loss': 0.8297401245095228}
2022-11-22 23:39:16,696 INFO:     Found new best model at epoch 5
2022-11-22 23:39:16,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:16,696 INFO:     Epoch: 6
2022-11-22 23:39:17,463 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8387694839726795, 'Total loss': 0.8387694839726795} | train loss {'Reaction outcome loss': 0.8278484419289871, 'Total loss': 0.8278484419289871}
2022-11-22 23:39:17,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:17,464 INFO:     Epoch: 7
2022-11-22 23:39:18,298 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8074258850379423, 'Total loss': 0.8074258850379423} | train loss {'Reaction outcome loss': 0.8267255864645305, 'Total loss': 0.8267255864645305}
2022-11-22 23:39:18,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:18,298 INFO:     Epoch: 8
2022-11-22 23:39:19,084 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8194513138044964, 'Total loss': 0.8194513138044964} | train loss {'Reaction outcome loss': 0.8272674367857366, 'Total loss': 0.8272674367857366}
2022-11-22 23:39:19,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:19,084 INFO:     Epoch: 9
2022-11-22 23:39:19,882 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8171578984368931, 'Total loss': 0.8171578984368931} | train loss {'Reaction outcome loss': 0.8284822555206083, 'Total loss': 0.8284822555206083}
2022-11-22 23:39:19,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:19,882 INFO:     Epoch: 10
2022-11-22 23:39:20,695 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8384837081486528, 'Total loss': 0.8384837081486528} | train loss {'Reaction outcome loss': 0.8205669052325762, 'Total loss': 0.8205669052325762}
2022-11-22 23:39:20,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:20,696 INFO:     Epoch: 11
2022-11-22 23:39:21,512 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.804747072133151, 'Total loss': 0.804747072133151} | train loss {'Reaction outcome loss': 0.8373700254841855, 'Total loss': 0.8373700254841855}
2022-11-22 23:39:21,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:21,512 INFO:     Epoch: 12
2022-11-22 23:39:22,334 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8294845873659308, 'Total loss': 0.8294845873659308} | train loss {'Reaction outcome loss': 0.8358031675400521, 'Total loss': 0.8358031675400521}
2022-11-22 23:39:22,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:22,335 INFO:     Epoch: 13
2022-11-22 23:39:23,152 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7987400300123475, 'Total loss': 0.7987400300123475} | train loss {'Reaction outcome loss': 0.83269784433639, 'Total loss': 0.83269784433639}
2022-11-22 23:39:23,152 INFO:     Found new best model at epoch 13
2022-11-22 23:39:23,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:23,153 INFO:     Epoch: 14
2022-11-22 23:39:23,965 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8237778259949251, 'Total loss': 0.8237778259949251} | train loss {'Reaction outcome loss': 0.8265850820280762, 'Total loss': 0.8265850820280762}
2022-11-22 23:39:23,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:23,965 INFO:     Epoch: 15
2022-11-22 23:39:24,781 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7973860251632604, 'Total loss': 0.7973860251632604} | train loss {'Reaction outcome loss': 0.8321445725466076, 'Total loss': 0.8321445725466076}
2022-11-22 23:39:24,781 INFO:     Found new best model at epoch 15
2022-11-22 23:39:24,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:24,782 INFO:     Epoch: 16
2022-11-22 23:39:25,575 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7993560602719133, 'Total loss': 0.7993560602719133} | train loss {'Reaction outcome loss': 0.8213284247317295, 'Total loss': 0.8213284247317295}
2022-11-22 23:39:25,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:25,576 INFO:     Epoch: 17
2022-11-22 23:39:26,384 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.835342405194586, 'Total loss': 0.835342405194586} | train loss {'Reaction outcome loss': 0.8215609365086324, 'Total loss': 0.8215609365086324}
2022-11-22 23:39:26,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:26,384 INFO:     Epoch: 18
2022-11-22 23:39:27,214 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7936094782569192, 'Total loss': 0.7936094782569192} | train loss {'Reaction outcome loss': 0.8237617035143772, 'Total loss': 0.8237617035143772}
2022-11-22 23:39:27,215 INFO:     Found new best model at epoch 18
2022-11-22 23:39:27,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:27,215 INFO:     Epoch: 19
2022-11-22 23:39:28,038 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7932639758695256, 'Total loss': 0.7932639758695256} | train loss {'Reaction outcome loss': 0.8245150456544359, 'Total loss': 0.8245150456544359}
2022-11-22 23:39:28,038 INFO:     Found new best model at epoch 19
2022-11-22 23:39:28,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:28,039 INFO:     Epoch: 20
2022-11-22 23:39:28,846 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7902015488256108, 'Total loss': 0.7902015488256108} | train loss {'Reaction outcome loss': 0.8241605825028439, 'Total loss': 0.8241605825028439}
2022-11-22 23:39:28,846 INFO:     Found new best model at epoch 20
2022-11-22 23:39:28,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:28,847 INFO:     Epoch: 21
2022-11-22 23:39:29,669 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.816941648721695, 'Total loss': 0.816941648721695} | train loss {'Reaction outcome loss': 0.8195630661871752, 'Total loss': 0.8195630661871752}
2022-11-22 23:39:29,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:29,670 INFO:     Epoch: 22
2022-11-22 23:39:30,485 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8110147701068358, 'Total loss': 0.8110147701068358} | train loss {'Reaction outcome loss': 0.8195175451305714, 'Total loss': 0.8195175451305714}
2022-11-22 23:39:30,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:30,485 INFO:     Epoch: 23
2022-11-22 23:39:31,308 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8027611672878265, 'Total loss': 0.8027611672878265} | train loss {'Reaction outcome loss': 0.8276246635296084, 'Total loss': 0.8276246635296084}
2022-11-22 23:39:31,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:31,309 INFO:     Epoch: 24
2022-11-22 23:39:32,147 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7961882312189449, 'Total loss': 0.7961882312189449} | train loss {'Reaction outcome loss': 0.8161195511760017, 'Total loss': 0.8161195511760017}
2022-11-22 23:39:32,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:32,148 INFO:     Epoch: 25
2022-11-22 23:39:32,927 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7977863333441995, 'Total loss': 0.7977863333441995} | train loss {'Reaction outcome loss': 0.8207693365421372, 'Total loss': 0.8207693365421372}
2022-11-22 23:39:32,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:32,927 INFO:     Epoch: 26
2022-11-22 23:39:33,759 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7966193746436726, 'Total loss': 0.7966193746436726} | train loss {'Reaction outcome loss': 0.8251062109161486, 'Total loss': 0.8251062109161486}
2022-11-22 23:39:33,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:33,760 INFO:     Epoch: 27
2022-11-22 23:39:34,598 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8116921945051714, 'Total loss': 0.8116921945051714} | train loss {'Reaction outcome loss': 0.8206284702548131, 'Total loss': 0.8206284702548131}
2022-11-22 23:39:34,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:34,599 INFO:     Epoch: 28
2022-11-22 23:39:35,461 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7987890677018599, 'Total loss': 0.7987890677018599} | train loss {'Reaction outcome loss': 0.8258357086644964, 'Total loss': 0.8258357086644964}
2022-11-22 23:39:35,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:35,461 INFO:     Epoch: 29
2022-11-22 23:39:36,284 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7988546036861159, 'Total loss': 0.7988546036861159} | train loss {'Reaction outcome loss': 0.8217933109173408, 'Total loss': 0.8217933109173408}
2022-11-22 23:39:36,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:36,284 INFO:     Epoch: 30
2022-11-22 23:39:37,078 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8084865700114857, 'Total loss': 0.8084865700114857} | train loss {'Reaction outcome loss': 0.8292867386871986, 'Total loss': 0.8292867386871986}
2022-11-22 23:39:37,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:37,078 INFO:     Epoch: 31
2022-11-22 23:39:37,935 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.816897031258453, 'Total loss': 0.816897031258453} | train loss {'Reaction outcome loss': 0.828995617536398, 'Total loss': 0.828995617536398}
2022-11-22 23:39:37,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:37,936 INFO:     Epoch: 32
2022-11-22 23:39:38,714 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8057114075530659, 'Total loss': 0.8057114075530659} | train loss {'Reaction outcome loss': 0.8174316492308731, 'Total loss': 0.8174316492308731}
2022-11-22 23:39:38,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:38,714 INFO:     Epoch: 33
2022-11-22 23:39:39,548 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.796237750486894, 'Total loss': 0.796237750486894} | train loss {'Reaction outcome loss': 0.8212412138458206, 'Total loss': 0.8212412138458206}
2022-11-22 23:39:39,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:39,549 INFO:     Epoch: 34
2022-11-22 23:39:40,368 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8232841776175932, 'Total loss': 0.8232841776175932} | train loss {'Reaction outcome loss': 0.8294876324020417, 'Total loss': 0.8294876324020417}
2022-11-22 23:39:40,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:40,369 INFO:     Epoch: 35
2022-11-22 23:39:41,194 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7982474179430441, 'Total loss': 0.7982474179430441} | train loss {'Reaction outcome loss': 0.8282821706914709, 'Total loss': 0.8282821706914709}
2022-11-22 23:39:41,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:41,195 INFO:     Epoch: 36
2022-11-22 23:39:42,038 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7918484312566844, 'Total loss': 0.7918484312566844} | train loss {'Reaction outcome loss': 0.819969748919792, 'Total loss': 0.819969748919792}
2022-11-22 23:39:42,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:42,039 INFO:     Epoch: 37
2022-11-22 23:39:42,838 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8136109906164083, 'Total loss': 0.8136109906164083} | train loss {'Reaction outcome loss': 0.8181366837217741, 'Total loss': 0.8181366837217741}
2022-11-22 23:39:42,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:42,839 INFO:     Epoch: 38
2022-11-22 23:39:43,603 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8043963116678324, 'Total loss': 0.8043963116678324} | train loss {'Reaction outcome loss': 0.8222544751910545, 'Total loss': 0.8222544751910545}
2022-11-22 23:39:43,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:43,603 INFO:     Epoch: 39
2022-11-22 23:39:44,397 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8024172688072378, 'Total loss': 0.8024172688072378} | train loss {'Reaction outcome loss': 0.8255415722305476, 'Total loss': 0.8255415722305476}
2022-11-22 23:39:44,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:44,397 INFO:     Epoch: 40
2022-11-22 23:39:45,222 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7894495102492246, 'Total loss': 0.7894495102492246} | train loss {'Reaction outcome loss': 0.8249575381095593, 'Total loss': 0.8249575381095593}
2022-11-22 23:39:45,222 INFO:     Found new best model at epoch 40
2022-11-22 23:39:45,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:45,223 INFO:     Epoch: 41
2022-11-22 23:39:46,019 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.796214378692887, 'Total loss': 0.796214378692887} | train loss {'Reaction outcome loss': 0.8254703680272044, 'Total loss': 0.8254703680272044}
2022-11-22 23:39:46,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:46,020 INFO:     Epoch: 42
2022-11-22 23:39:46,827 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8624691699038852, 'Total loss': 0.8624691699038852} | train loss {'Reaction outcome loss': 0.8239385722137174, 'Total loss': 0.8239385722137174}
2022-11-22 23:39:46,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:46,827 INFO:     Epoch: 43
2022-11-22 23:39:47,642 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8026863302696835, 'Total loss': 0.8026863302696835} | train loss {'Reaction outcome loss': 0.8214254372033031, 'Total loss': 0.8214254372033031}
2022-11-22 23:39:47,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:47,642 INFO:     Epoch: 44
2022-11-22 23:39:48,469 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8141130737283013, 'Total loss': 0.8141130737283013} | train loss {'Reaction outcome loss': 0.8244263358444337, 'Total loss': 0.8244263358444337}
2022-11-22 23:39:48,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:48,470 INFO:     Epoch: 45
2022-11-22 23:39:49,300 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8271747529506683, 'Total loss': 0.8271747529506683} | train loss {'Reaction outcome loss': 0.8247388876401461, 'Total loss': 0.8247388876401461}
2022-11-22 23:39:49,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:49,301 INFO:     Epoch: 46
2022-11-22 23:39:50,085 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7955996929244562, 'Total loss': 0.7955996929244562} | train loss {'Reaction outcome loss': 0.8288167209519066, 'Total loss': 0.8288167209519066}
2022-11-22 23:39:50,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:50,085 INFO:     Epoch: 47
2022-11-22 23:39:50,925 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8134834346446124, 'Total loss': 0.8134834346446124} | train loss {'Reaction outcome loss': 0.822262525075843, 'Total loss': 0.822262525075843}
2022-11-22 23:39:50,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:50,925 INFO:     Epoch: 48
2022-11-22 23:39:51,728 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.814118963750926, 'Total loss': 0.814118963750926} | train loss {'Reaction outcome loss': 0.8214653772622468, 'Total loss': 0.8214653772622468}
2022-11-22 23:39:51,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:51,729 INFO:     Epoch: 49
2022-11-22 23:39:52,543 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8046504787423394, 'Total loss': 0.8046504787423394} | train loss {'Reaction outcome loss': 0.8233341469697142, 'Total loss': 0.8233341469697142}
2022-11-22 23:39:52,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:52,543 INFO:     Epoch: 50
2022-11-22 23:39:53,352 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7982869561422955, 'Total loss': 0.7982869561422955} | train loss {'Reaction outcome loss': 0.829877806940542, 'Total loss': 0.829877806940542}
2022-11-22 23:39:53,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:53,353 INFO:     Epoch: 51
2022-11-22 23:39:54,197 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.840105224062096, 'Total loss': 0.840105224062096} | train loss {'Reaction outcome loss': 0.8170698409681378, 'Total loss': 0.8170698409681378}
2022-11-22 23:39:54,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:54,197 INFO:     Epoch: 52
2022-11-22 23:39:55,019 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7910340665416284, 'Total loss': 0.7910340665416284} | train loss {'Reaction outcome loss': 0.8209957432167733, 'Total loss': 0.8209957432167733}
2022-11-22 23:39:55,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:55,019 INFO:     Epoch: 53
2022-11-22 23:39:55,854 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8063013648444955, 'Total loss': 0.8063013648444955} | train loss {'Reaction outcome loss': 0.828111126355314, 'Total loss': 0.828111126355314}
2022-11-22 23:39:55,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:55,854 INFO:     Epoch: 54
2022-11-22 23:39:56,658 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8020829781889915, 'Total loss': 0.8020829781889915} | train loss {'Reaction outcome loss': 0.8202077323789538, 'Total loss': 0.8202077323789538}
2022-11-22 23:39:56,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:56,658 INFO:     Epoch: 55
2022-11-22 23:39:57,443 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8065583888779987, 'Total loss': 0.8065583888779987} | train loss {'Reaction outcome loss': 0.8181996158501397, 'Total loss': 0.8181996158501397}
2022-11-22 23:39:57,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:57,444 INFO:     Epoch: 56
2022-11-22 23:39:58,232 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7901433354074304, 'Total loss': 0.7901433354074304} | train loss {'Reaction outcome loss': 0.818347033098159, 'Total loss': 0.818347033098159}
2022-11-22 23:39:58,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:58,232 INFO:     Epoch: 57
2022-11-22 23:39:59,030 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.80850096588785, 'Total loss': 0.80850096588785} | train loss {'Reaction outcome loss': 0.8168872075404233, 'Total loss': 0.8168872075404233}
2022-11-22 23:39:59,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:59,031 INFO:     Epoch: 58
2022-11-22 23:39:59,859 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8035172047940168, 'Total loss': 0.8035172047940168} | train loss {'Reaction outcome loss': 0.821044511157974, 'Total loss': 0.821044511157974}
2022-11-22 23:39:59,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:39:59,859 INFO:     Epoch: 59
2022-11-22 23:40:00,691 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7924112962050871, 'Total loss': 0.7924112962050871} | train loss {'Reaction outcome loss': 0.8195576529934822, 'Total loss': 0.8195576529934822}
2022-11-22 23:40:00,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:00,691 INFO:     Epoch: 60
2022-11-22 23:40:01,528 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7862592861056328, 'Total loss': 0.7862592861056328} | train loss {'Reaction outcome loss': 0.8227530088019275, 'Total loss': 0.8227530088019275}
2022-11-22 23:40:01,528 INFO:     Found new best model at epoch 60
2022-11-22 23:40:01,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:01,529 INFO:     Epoch: 61
2022-11-22 23:40:02,348 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8067053976384077, 'Total loss': 0.8067053976384077} | train loss {'Reaction outcome loss': 0.8204347125069815, 'Total loss': 0.8204347125069815}
2022-11-22 23:40:02,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:02,349 INFO:     Epoch: 62
2022-11-22 23:40:03,172 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7949595647779378, 'Total loss': 0.7949595647779378} | train loss {'Reaction outcome loss': 0.8253723468616424, 'Total loss': 0.8253723468616424}
2022-11-22 23:40:03,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:03,172 INFO:     Epoch: 63
2022-11-22 23:40:04,000 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7869896224953912, 'Total loss': 0.7869896224953912} | train loss {'Reaction outcome loss': 0.8241639068493476, 'Total loss': 0.8241639068493476}
2022-11-22 23:40:04,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:04,000 INFO:     Epoch: 64
2022-11-22 23:40:04,756 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7988982573151588, 'Total loss': 0.7988982573151588} | train loss {'Reaction outcome loss': 0.8233008299037995, 'Total loss': 0.8233008299037995}
2022-11-22 23:40:04,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:04,757 INFO:     Epoch: 65
2022-11-22 23:40:05,547 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7755987976085056, 'Total loss': 0.7755987976085056} | train loss {'Reaction outcome loss': 0.8222026770655443, 'Total loss': 0.8222026770655443}
2022-11-22 23:40:05,549 INFO:     Found new best model at epoch 65
2022-11-22 23:40:05,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:05,550 INFO:     Epoch: 66
2022-11-22 23:40:06,349 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7974244274876334, 'Total loss': 0.7974244274876334} | train loss {'Reaction outcome loss': 0.8253776437116538, 'Total loss': 0.8253776437116538}
2022-11-22 23:40:06,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:06,350 INFO:     Epoch: 67
2022-11-22 23:40:07,179 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7990888783877547, 'Total loss': 0.7990888783877547} | train loss {'Reaction outcome loss': 0.8232155153263918, 'Total loss': 0.8232155153263918}
2022-11-22 23:40:07,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:07,179 INFO:     Epoch: 68
2022-11-22 23:40:07,984 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8042223182591525, 'Total loss': 0.8042223182591525} | train loss {'Reaction outcome loss': 0.8247778848839192, 'Total loss': 0.8247778848839192}
2022-11-22 23:40:07,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:07,984 INFO:     Epoch: 69
2022-11-22 23:40:08,807 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.810726526108655, 'Total loss': 0.810726526108655} | train loss {'Reaction outcome loss': 0.8211875557899475, 'Total loss': 0.8211875557899475}
2022-11-22 23:40:08,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:08,807 INFO:     Epoch: 70
2022-11-22 23:40:09,600 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8098259222778407, 'Total loss': 0.8098259222778407} | train loss {'Reaction outcome loss': 0.8258230053944143, 'Total loss': 0.8258230053944143}
2022-11-22 23:40:09,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:09,601 INFO:     Epoch: 71
2022-11-22 23:40:10,380 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8282283470034599, 'Total loss': 0.8282283470034599} | train loss {'Reaction outcome loss': 0.822612990191591, 'Total loss': 0.822612990191591}
2022-11-22 23:40:10,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:10,380 INFO:     Epoch: 72
2022-11-22 23:40:11,180 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7966265671632506, 'Total loss': 0.7966265671632506} | train loss {'Reaction outcome loss': 0.823282332434828, 'Total loss': 0.823282332434828}
2022-11-22 23:40:11,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:11,180 INFO:     Epoch: 73
2022-11-22 23:40:11,991 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8035655428062786, 'Total loss': 0.8035655428062786} | train loss {'Reaction outcome loss': 0.8208727310543601, 'Total loss': 0.8208727310543601}
2022-11-22 23:40:11,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:11,992 INFO:     Epoch: 74
2022-11-22 23:40:12,781 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8131612966006453, 'Total loss': 0.8131612966006453} | train loss {'Reaction outcome loss': 0.8312008529298218, 'Total loss': 0.8312008529298218}
2022-11-22 23:40:12,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:12,781 INFO:     Epoch: 75
2022-11-22 23:40:13,607 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8018362068317153, 'Total loss': 0.8018362068317153} | train loss {'Reaction outcome loss': 0.8334482978230063, 'Total loss': 0.8334482978230063}
2022-11-22 23:40:13,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:13,607 INFO:     Epoch: 76
2022-11-22 23:40:14,407 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7973630319942128, 'Total loss': 0.7973630319942128} | train loss {'Reaction outcome loss': 0.8257867917116837, 'Total loss': 0.8257867917116837}
2022-11-22 23:40:14,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:14,407 INFO:     Epoch: 77
2022-11-22 23:40:15,231 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8268440149047158, 'Total loss': 0.8268440149047158} | train loss {'Reaction outcome loss': 0.8279457525444417, 'Total loss': 0.8279457525444417}
2022-11-22 23:40:15,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:15,231 INFO:     Epoch: 78
2022-11-22 23:40:16,082 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.824484490535476, 'Total loss': 0.824484490535476} | train loss {'Reaction outcome loss': 0.819364840202486, 'Total loss': 0.819364840202486}
2022-11-22 23:40:16,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:16,083 INFO:     Epoch: 79
2022-11-22 23:40:16,867 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8062132400545207, 'Total loss': 0.8062132400545207} | train loss {'Reaction outcome loss': 0.8274481921543476, 'Total loss': 0.8274481921543476}
2022-11-22 23:40:16,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:16,867 INFO:     Epoch: 80
2022-11-22 23:40:17,755 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7956079271706668, 'Total loss': 0.7956079271706668} | train loss {'Reaction outcome loss': 0.8219825240523226, 'Total loss': 0.8219825240523226}
2022-11-22 23:40:17,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:17,755 INFO:     Epoch: 81
2022-11-22 23:40:18,556 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8065881844271313, 'Total loss': 0.8065881844271313} | train loss {'Reaction outcome loss': 0.8316518045388736, 'Total loss': 0.8316518045388736}
2022-11-22 23:40:18,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:18,557 INFO:     Epoch: 82
2022-11-22 23:40:19,381 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8167942179874941, 'Total loss': 0.8167942179874941} | train loss {'Reaction outcome loss': 0.8243339109999931, 'Total loss': 0.8243339109999931}
2022-11-22 23:40:19,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:19,381 INFO:     Epoch: 83
2022-11-22 23:40:20,214 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7908917557109486, 'Total loss': 0.7908917557109486} | train loss {'Reaction outcome loss': 0.8151787502864595, 'Total loss': 0.8151787502864595}
2022-11-22 23:40:20,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:20,214 INFO:     Epoch: 84
2022-11-22 23:40:21,000 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7949136739427393, 'Total loss': 0.7949136739427393} | train loss {'Reaction outcome loss': 0.817536120532978, 'Total loss': 0.817536120532978}
2022-11-22 23:40:21,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:21,001 INFO:     Epoch: 85
2022-11-22 23:40:21,809 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8014913973483172, 'Total loss': 0.8014913973483172} | train loss {'Reaction outcome loss': 0.819793034179008, 'Total loss': 0.819793034179008}
2022-11-22 23:40:21,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:21,809 INFO:     Epoch: 86
2022-11-22 23:40:22,601 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7986056696284901, 'Total loss': 0.7986056696284901} | train loss {'Reaction outcome loss': 0.8268410413854035, 'Total loss': 0.8268410413854035}
2022-11-22 23:40:22,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:22,601 INFO:     Epoch: 87
2022-11-22 23:40:23,432 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8506645106456496, 'Total loss': 0.8506645106456496} | train loss {'Reaction outcome loss': 0.823771443745868, 'Total loss': 0.823771443745868}
2022-11-22 23:40:23,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:23,432 INFO:     Epoch: 88
2022-11-22 23:40:24,210 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8283095982941714, 'Total loss': 0.8283095982941714} | train loss {'Reaction outcome loss': 0.8222050986550598, 'Total loss': 0.8222050986550598}
2022-11-22 23:40:24,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:24,211 INFO:     Epoch: 89
2022-11-22 23:40:24,998 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7988073392347856, 'Total loss': 0.7988073392347856} | train loss {'Reaction outcome loss': 0.8175657368623294, 'Total loss': 0.8175657368623294}
2022-11-22 23:40:24,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:24,998 INFO:     Epoch: 90
2022-11-22 23:40:25,793 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7991315363482996, 'Total loss': 0.7991315363482996} | train loss {'Reaction outcome loss': 0.8137267307351957, 'Total loss': 0.8137267307351957}
2022-11-22 23:40:25,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:25,793 INFO:     Epoch: 91
2022-11-22 23:40:26,578 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7904262563044374, 'Total loss': 0.7904262563044374} | train loss {'Reaction outcome loss': 0.821107698958895, 'Total loss': 0.821107698958895}
2022-11-22 23:40:26,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:26,578 INFO:     Epoch: 92
2022-11-22 23:40:27,409 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8080546192147515, 'Total loss': 0.8080546192147515} | train loss {'Reaction outcome loss': 0.8215027332064594, 'Total loss': 0.8215027332064594}
2022-11-22 23:40:27,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:27,409 INFO:     Epoch: 93
2022-11-22 23:40:28,191 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8222201795063235, 'Total loss': 0.8222201795063235} | train loss {'Reaction outcome loss': 0.8189999520597671, 'Total loss': 0.8189999520597671}
2022-11-22 23:40:28,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:28,191 INFO:     Epoch: 94
2022-11-22 23:40:29,051 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8358455903150819, 'Total loss': 0.8358455903150819} | train loss {'Reaction outcome loss': 0.8180612213457161, 'Total loss': 0.8180612213457161}
2022-11-22 23:40:29,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:29,051 INFO:     Epoch: 95
2022-11-22 23:40:29,888 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8009516176852313, 'Total loss': 0.8009516176852313} | train loss {'Reaction outcome loss': 0.8233090627048663, 'Total loss': 0.8233090627048663}
2022-11-22 23:40:29,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:29,888 INFO:     Epoch: 96
2022-11-22 23:40:30,706 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8118324767459523, 'Total loss': 0.8118324767459523} | train loss {'Reaction outcome loss': 0.8182041861026393, 'Total loss': 0.8182041861026393}
2022-11-22 23:40:30,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:30,706 INFO:     Epoch: 97
2022-11-22 23:40:31,466 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8102900277484547, 'Total loss': 0.8102900277484547} | train loss {'Reaction outcome loss': 0.8214210392492503, 'Total loss': 0.8214210392492503}
2022-11-22 23:40:31,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:31,466 INFO:     Epoch: 98
2022-11-22 23:40:32,310 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8238047605211084, 'Total loss': 0.8238047605211084} | train loss {'Reaction outcome loss': 0.8224358153246675, 'Total loss': 0.8224358153246675}
2022-11-22 23:40:32,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:32,310 INFO:     Epoch: 99
2022-11-22 23:40:33,126 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7892182239077308, 'Total loss': 0.7892182239077308} | train loss {'Reaction outcome loss': 0.814270060072061, 'Total loss': 0.814270060072061}
2022-11-22 23:40:33,126 INFO:     Best model found after epoch 66 of 100.
2022-11-22 23:40:33,126 INFO:   Done with stage: TRAINING
2022-11-22 23:40:33,126 INFO:   Starting stage: EVALUATION
2022-11-22 23:40:33,251 INFO:   Done with stage: EVALUATION
2022-11-22 23:40:33,251 INFO:   Leaving out SEQ value Fold_2
2022-11-22 23:40:33,264 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 23:40:33,265 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:40:33,927 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:40:33,927 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:40:33,995 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:40:33,995 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:40:33,995 INFO:     No hyperparam tuning for this model
2022-11-22 23:40:33,995 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:40:33,995 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:40:33,996 INFO:     None feature selector for col prot
2022-11-22 23:40:33,996 INFO:     None feature selector for col prot
2022-11-22 23:40:33,996 INFO:     None feature selector for col prot
2022-11-22 23:40:33,997 INFO:     None feature selector for col chem
2022-11-22 23:40:33,997 INFO:     None feature selector for col chem
2022-11-22 23:40:33,997 INFO:     None feature selector for col chem
2022-11-22 23:40:33,997 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:40:33,997 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:40:33,999 INFO:     Number of params in model 168571
2022-11-22 23:40:34,002 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:40:34,002 INFO:   Starting stage: TRAINING
2022-11-22 23:40:34,060 INFO:     Val loss before train {'Reaction outcome loss': 1.0212294608354568, 'Total loss': 1.0212294608354568}
2022-11-22 23:40:34,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:34,060 INFO:     Epoch: 0
2022-11-22 23:40:34,885 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8796689401973378, 'Total loss': 0.8796689401973378} | train loss {'Reaction outcome loss': 0.9014867684062646, 'Total loss': 0.9014867684062646}
2022-11-22 23:40:34,885 INFO:     Found new best model at epoch 0
2022-11-22 23:40:34,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:34,886 INFO:     Epoch: 1
2022-11-22 23:40:35,687 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8900863128629598, 'Total loss': 0.8900863128629598} | train loss {'Reaction outcome loss': 0.8706031087709933, 'Total loss': 0.8706031087709933}
2022-11-22 23:40:35,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:35,687 INFO:     Epoch: 2
2022-11-22 23:40:36,517 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9002322723919695, 'Total loss': 0.9002322723919695} | train loss {'Reaction outcome loss': 0.8580400708986788, 'Total loss': 0.8580400708986788}
2022-11-22 23:40:36,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:36,518 INFO:     Epoch: 3
2022-11-22 23:40:37,376 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8772771548141133, 'Total loss': 0.8772771548141133} | train loss {'Reaction outcome loss': 0.8569291283889693, 'Total loss': 0.8569291283889693}
2022-11-22 23:40:37,377 INFO:     Found new best model at epoch 3
2022-11-22 23:40:37,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:37,378 INFO:     Epoch: 4
2022-11-22 23:40:38,150 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9130281968550249, 'Total loss': 0.9130281968550249} | train loss {'Reaction outcome loss': 0.8546948077727338, 'Total loss': 0.8546948077727338}
2022-11-22 23:40:38,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:38,150 INFO:     Epoch: 5
2022-11-22 23:40:38,952 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8721263246102766, 'Total loss': 0.8721263246102766} | train loss {'Reaction outcome loss': 0.848224694144969, 'Total loss': 0.848224694144969}
2022-11-22 23:40:38,952 INFO:     Found new best model at epoch 5
2022-11-22 23:40:38,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:38,953 INFO:     Epoch: 6
2022-11-22 23:40:39,723 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8660646778616038, 'Total loss': 0.8660646778616038} | train loss {'Reaction outcome loss': 0.8451177028977142, 'Total loss': 0.8451177028977142}
2022-11-22 23:40:39,723 INFO:     Found new best model at epoch 6
2022-11-22 23:40:39,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:39,724 INFO:     Epoch: 7
2022-11-22 23:40:40,535 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8499727343971079, 'Total loss': 0.8499727343971079} | train loss {'Reaction outcome loss': 0.8399289312411328, 'Total loss': 0.8399289312411328}
2022-11-22 23:40:40,535 INFO:     Found new best model at epoch 7
2022-11-22 23:40:40,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:40,536 INFO:     Epoch: 8
2022-11-22 23:40:41,298 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8462153984741732, 'Total loss': 0.8462153984741732} | train loss {'Reaction outcome loss': 0.845748829963256, 'Total loss': 0.845748829963256}
2022-11-22 23:40:41,298 INFO:     Found new best model at epoch 8
2022-11-22 23:40:41,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:41,299 INFO:     Epoch: 9
2022-11-22 23:40:42,097 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8524124988100745, 'Total loss': 0.8524124988100745} | train loss {'Reaction outcome loss': 0.837391574893679, 'Total loss': 0.837391574893679}
2022-11-22 23:40:42,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:42,097 INFO:     Epoch: 10
2022-11-22 23:40:42,926 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8621972528370944, 'Total loss': 0.8621972528370944} | train loss {'Reaction outcome loss': 0.8401972967751172, 'Total loss': 0.8401972967751172}
2022-11-22 23:40:42,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:42,927 INFO:     Epoch: 11
2022-11-22 23:40:43,725 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.84331164509058, 'Total loss': 0.84331164509058} | train loss {'Reaction outcome loss': 0.8388793489154505, 'Total loss': 0.8388793489154505}
2022-11-22 23:40:43,725 INFO:     Found new best model at epoch 11
2022-11-22 23:40:43,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:43,726 INFO:     Epoch: 12
2022-11-22 23:40:44,558 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8581132550131191, 'Total loss': 0.8581132550131191} | train loss {'Reaction outcome loss': 0.843134347273379, 'Total loss': 0.843134347273379}
2022-11-22 23:40:44,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:44,558 INFO:     Epoch: 13
2022-11-22 23:40:45,364 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8494470905173909, 'Total loss': 0.8494470905173909} | train loss {'Reaction outcome loss': 0.8364344545773097, 'Total loss': 0.8364344545773097}
2022-11-22 23:40:45,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:45,364 INFO:     Epoch: 14
2022-11-22 23:40:46,148 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8602841733531519, 'Total loss': 0.8602841733531519} | train loss {'Reaction outcome loss': 0.8362226157772298, 'Total loss': 0.8362226157772298}
2022-11-22 23:40:46,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:46,148 INFO:     Epoch: 15
2022-11-22 23:40:46,976 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8526890074664896, 'Total loss': 0.8526890074664896} | train loss {'Reaction outcome loss': 0.8341808694965985, 'Total loss': 0.8341808694965985}
2022-11-22 23:40:46,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:46,976 INFO:     Epoch: 16
2022-11-22 23:40:47,818 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8429163558916613, 'Total loss': 0.8429163558916613} | train loss {'Reaction outcome loss': 0.8399806447175084, 'Total loss': 0.8399806447175084}
2022-11-22 23:40:47,819 INFO:     Found new best model at epoch 16
2022-11-22 23:40:47,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:47,819 INFO:     Epoch: 17
2022-11-22 23:40:48,605 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8839512250640176, 'Total loss': 0.8839512250640176} | train loss {'Reaction outcome loss': 0.8312809395546816, 'Total loss': 0.8312809395546816}
2022-11-22 23:40:48,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:48,605 INFO:     Epoch: 18
2022-11-22 23:40:49,451 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8774858631870963, 'Total loss': 0.8774858631870963} | train loss {'Reaction outcome loss': 0.8312243678131882, 'Total loss': 0.8312243678131882}
2022-11-22 23:40:49,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:49,452 INFO:     Epoch: 19
2022-11-22 23:40:50,315 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8684943982146003, 'Total loss': 0.8684943982146003} | train loss {'Reaction outcome loss': 0.8336057262761253, 'Total loss': 0.8336057262761253}
2022-11-22 23:40:50,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:50,315 INFO:     Epoch: 20
2022-11-22 23:40:51,122 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8442522273822264, 'Total loss': 0.8442522273822264} | train loss {'Reaction outcome loss': 0.8365770617309882, 'Total loss': 0.8365770617309882}
2022-11-22 23:40:51,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:51,122 INFO:     Epoch: 21
2022-11-22 23:40:51,929 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8475161756981503, 'Total loss': 0.8475161756981503} | train loss {'Reaction outcome loss': 0.8359936650918455, 'Total loss': 0.8359936650918455}
2022-11-22 23:40:51,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:51,930 INFO:     Epoch: 22
2022-11-22 23:40:52,736 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.9037210223349658, 'Total loss': 0.9037210223349658} | train loss {'Reaction outcome loss': 0.8324057105852634, 'Total loss': 0.8324057105852634}
2022-11-22 23:40:52,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:52,737 INFO:     Epoch: 23
2022-11-22 23:40:53,499 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.853496905754913, 'Total loss': 0.853496905754913} | train loss {'Reaction outcome loss': 0.8313154719313797, 'Total loss': 0.8313154719313797}
2022-11-22 23:40:53,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:53,500 INFO:     Epoch: 24
2022-11-22 23:40:54,321 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8542267260226336, 'Total loss': 0.8542267260226336} | train loss {'Reaction outcome loss': 0.8332610751901354, 'Total loss': 0.8332610751901354}
2022-11-22 23:40:54,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:54,321 INFO:     Epoch: 25
2022-11-22 23:40:55,106 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8425447487018325, 'Total loss': 0.8425447487018325} | train loss {'Reaction outcome loss': 0.8368272847058822, 'Total loss': 0.8368272847058822}
2022-11-22 23:40:55,107 INFO:     Found new best model at epoch 25
2022-11-22 23:40:55,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:55,107 INFO:     Epoch: 26
2022-11-22 23:40:55,919 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8320339714938944, 'Total loss': 0.8320339714938944} | train loss {'Reaction outcome loss': 0.8347646272912317, 'Total loss': 0.8347646272912317}
2022-11-22 23:40:55,919 INFO:     Found new best model at epoch 26
2022-11-22 23:40:55,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:55,920 INFO:     Epoch: 27
2022-11-22 23:40:56,721 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8722137734293938, 'Total loss': 0.8722137734293938} | train loss {'Reaction outcome loss': 0.8300743663797573, 'Total loss': 0.8300743663797573}
2022-11-22 23:40:56,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:56,722 INFO:     Epoch: 28
2022-11-22 23:40:57,523 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.837649180130525, 'Total loss': 0.837649180130525} | train loss {'Reaction outcome loss': 0.8364958827592889, 'Total loss': 0.8364958827592889}
2022-11-22 23:40:57,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:57,523 INFO:     Epoch: 29
2022-11-22 23:40:58,316 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8461297337304462, 'Total loss': 0.8461297337304462} | train loss {'Reaction outcome loss': 0.82946623308318, 'Total loss': 0.82946623308318}
2022-11-22 23:40:58,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:58,317 INFO:     Epoch: 30
2022-11-22 23:40:59,152 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8530414212833751, 'Total loss': 0.8530414212833751} | train loss {'Reaction outcome loss': 0.8322811300657234, 'Total loss': 0.8322811300657234}
2022-11-22 23:40:59,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:59,152 INFO:     Epoch: 31
2022-11-22 23:40:59,970 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8426538617773489, 'Total loss': 0.8426538617773489} | train loss {'Reaction outcome loss': 0.8312987199851445, 'Total loss': 0.8312987199851445}
2022-11-22 23:40:59,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:40:59,970 INFO:     Epoch: 32
2022-11-22 23:41:00,816 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8499551794745706, 'Total loss': 0.8499551794745706} | train loss {'Reaction outcome loss': 0.8356374727219952, 'Total loss': 0.8356374727219952}
2022-11-22 23:41:00,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:00,816 INFO:     Epoch: 33
2022-11-22 23:41:01,622 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8567414270205931, 'Total loss': 0.8567414270205931} | train loss {'Reaction outcome loss': 0.8298103136675699, 'Total loss': 0.8298103136675699}
2022-11-22 23:41:01,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:01,622 INFO:     Epoch: 34
2022-11-22 23:41:02,426 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.836881488900293, 'Total loss': 0.836881488900293} | train loss {'Reaction outcome loss': 0.8306283587095689, 'Total loss': 0.8306283587095689}
2022-11-22 23:41:02,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:02,426 INFO:     Epoch: 35
2022-11-22 23:41:03,232 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.874467828057029, 'Total loss': 0.874467828057029} | train loss {'Reaction outcome loss': 0.8338721550240809, 'Total loss': 0.8338721550240809}
2022-11-22 23:41:03,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:03,232 INFO:     Epoch: 36
2022-11-22 23:41:04,092 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8451094214211811, 'Total loss': 0.8451094214211811} | train loss {'Reaction outcome loss': 0.8344853428553561, 'Total loss': 0.8344853428553561}
2022-11-22 23:41:04,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:04,092 INFO:     Epoch: 37
2022-11-22 23:41:04,939 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8299590169706128, 'Total loss': 0.8299590169706128} | train loss {'Reaction outcome loss': 0.8333911157384211, 'Total loss': 0.8333911157384211}
2022-11-22 23:41:04,940 INFO:     Found new best model at epoch 37
2022-11-22 23:41:04,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:04,941 INFO:     Epoch: 38
2022-11-22 23:41:05,847 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.863220835273916, 'Total loss': 0.863220835273916} | train loss {'Reaction outcome loss': 0.8355006784808879, 'Total loss': 0.8355006784808879}
2022-11-22 23:41:05,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:05,848 INFO:     Epoch: 39
2022-11-22 23:41:06,679 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8393092812462286, 'Total loss': 0.8393092812462286} | train loss {'Reaction outcome loss': 0.8294160255364009, 'Total loss': 0.8294160255364009}
2022-11-22 23:41:06,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:06,679 INFO:     Epoch: 40
2022-11-22 23:41:07,479 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8456524637612429, 'Total loss': 0.8456524637612429} | train loss {'Reaction outcome loss': 0.8297510404976047, 'Total loss': 0.8297510404976047}
2022-11-22 23:41:07,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:07,480 INFO:     Epoch: 41
2022-11-22 23:41:08,273 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8714229417118159, 'Total loss': 0.8714229417118159} | train loss {'Reaction outcome loss': 0.8287881393821872, 'Total loss': 0.8287881393821872}
2022-11-22 23:41:08,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:08,274 INFO:     Epoch: 42
2022-11-22 23:41:09,090 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8491288978945125, 'Total loss': 0.8491288978945125} | train loss {'Reaction outcome loss': 0.8338891660680576, 'Total loss': 0.8338891660680576}
2022-11-22 23:41:09,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:09,090 INFO:     Epoch: 43
2022-11-22 23:41:09,963 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8351083167574622, 'Total loss': 0.8351083167574622} | train loss {'Reaction outcome loss': 0.8299526046733467, 'Total loss': 0.8299526046733467}
2022-11-22 23:41:09,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:09,963 INFO:     Epoch: 44
2022-11-22 23:41:10,795 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8497097173875029, 'Total loss': 0.8497097173875029} | train loss {'Reaction outcome loss': 0.8329605005225357, 'Total loss': 0.8329605005225357}
2022-11-22 23:41:10,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:10,795 INFO:     Epoch: 45
2022-11-22 23:41:11,589 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8524282879450105, 'Total loss': 0.8524282879450105} | train loss {'Reaction outcome loss': 0.8305133638333301, 'Total loss': 0.8305133638333301}
2022-11-22 23:41:11,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:11,589 INFO:     Epoch: 46
2022-11-22 23:41:12,426 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8654853782870553, 'Total loss': 0.8654853782870553} | train loss {'Reaction outcome loss': 0.8300918120510724, 'Total loss': 0.8300918120510724}
2022-11-22 23:41:12,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:12,426 INFO:     Epoch: 47
2022-11-22 23:41:13,205 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8545491410927339, 'Total loss': 0.8545491410927339} | train loss {'Reaction outcome loss': 0.8268755575832055, 'Total loss': 0.8268755575832055}
2022-11-22 23:41:13,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:13,205 INFO:     Epoch: 48
2022-11-22 23:41:13,986 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8630073571747, 'Total loss': 0.8630073571747} | train loss {'Reaction outcome loss': 0.829602313893182, 'Total loss': 0.829602313893182}
2022-11-22 23:41:13,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:13,987 INFO:     Epoch: 49
2022-11-22 23:41:14,874 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8401491520079699, 'Total loss': 0.8401491520079699} | train loss {'Reaction outcome loss': 0.8340213044565551, 'Total loss': 0.8340213044565551}
2022-11-22 23:41:14,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:14,874 INFO:     Epoch: 50
2022-11-22 23:41:15,681 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8580265248363669, 'Total loss': 0.8580265248363669} | train loss {'Reaction outcome loss': 0.8321419893478861, 'Total loss': 0.8321419893478861}
2022-11-22 23:41:15,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:15,681 INFO:     Epoch: 51
2022-11-22 23:41:16,472 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8652011203494939, 'Total loss': 0.8652011203494939} | train loss {'Reaction outcome loss': 0.8307045921987417, 'Total loss': 0.8307045921987417}
2022-11-22 23:41:16,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:16,473 INFO:     Epoch: 52
2022-11-22 23:41:17,287 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8596933633089066, 'Total loss': 0.8596933633089066} | train loss {'Reaction outcome loss': 0.8333655948541603, 'Total loss': 0.8333655948541603}
2022-11-22 23:41:17,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:17,287 INFO:     Epoch: 53
2022-11-22 23:41:18,098 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8806405521251939, 'Total loss': 0.8806405521251939} | train loss {'Reaction outcome loss': 0.8303668217999595, 'Total loss': 0.8303668217999595}
2022-11-22 23:41:18,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:18,099 INFO:     Epoch: 54
2022-11-22 23:41:18,942 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.858809999444268, 'Total loss': 0.858809999444268} | train loss {'Reaction outcome loss': 0.8313543525277352, 'Total loss': 0.8313543525277352}
2022-11-22 23:41:18,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:18,942 INFO:     Epoch: 55
2022-11-22 23:41:19,783 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8402760049158876, 'Total loss': 0.8402760049158876} | train loss {'Reaction outcome loss': 0.8299270868301392, 'Total loss': 0.8299270868301392}
2022-11-22 23:41:19,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:19,783 INFO:     Epoch: 56
2022-11-22 23:41:20,634 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8498840643600984, 'Total loss': 0.8498840643600984} | train loss {'Reaction outcome loss': 0.8294934362781291, 'Total loss': 0.8294934362781291}
2022-11-22 23:41:20,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:20,635 INFO:     Epoch: 57
2022-11-22 23:41:21,429 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.858258606358008, 'Total loss': 0.858258606358008} | train loss {'Reaction outcome loss': 0.8297373737607684, 'Total loss': 0.8297373737607684}
2022-11-22 23:41:21,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:21,430 INFO:     Epoch: 58
2022-11-22 23:41:22,240 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8389084555886008, 'Total loss': 0.8389084555886008} | train loss {'Reaction outcome loss': 0.8316579238492615, 'Total loss': 0.8316579238492615}
2022-11-22 23:41:22,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:22,240 INFO:     Epoch: 59
2022-11-22 23:41:23,075 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8531469763679937, 'Total loss': 0.8531469763679937} | train loss {'Reaction outcome loss': 0.8323575103161286, 'Total loss': 0.8323575103161286}
2022-11-22 23:41:23,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:23,075 INFO:     Epoch: 60
2022-11-22 23:41:23,884 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8588754744692282, 'Total loss': 0.8588754744692282} | train loss {'Reaction outcome loss': 0.8326470865278828, 'Total loss': 0.8326470865278828}
2022-11-22 23:41:23,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:23,885 INFO:     Epoch: 61
2022-11-22 23:41:24,677 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.838827925988219, 'Total loss': 0.838827925988219} | train loss {'Reaction outcome loss': 0.8334449643991432, 'Total loss': 0.8334449643991432}
2022-11-22 23:41:24,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:24,677 INFO:     Epoch: 62
2022-11-22 23:41:25,490 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8583220893686468, 'Total loss': 0.8583220893686468} | train loss {'Reaction outcome loss': 0.8323590975634906, 'Total loss': 0.8323590975634906}
2022-11-22 23:41:25,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:25,490 INFO:     Epoch: 63
2022-11-22 23:41:26,296 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.84418854794719, 'Total loss': 0.84418854794719} | train loss {'Reaction outcome loss': 0.829317497963808, 'Total loss': 0.829317497963808}
2022-11-22 23:41:26,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:26,297 INFO:     Epoch: 64
2022-11-22 23:41:27,105 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8196193796836517, 'Total loss': 0.8196193796836517} | train loss {'Reaction outcome loss': 0.8315860767753757, 'Total loss': 0.8315860767753757}
2022-11-22 23:41:27,106 INFO:     Found new best model at epoch 64
2022-11-22 23:41:27,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:27,107 INFO:     Epoch: 65
2022-11-22 23:41:27,924 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8521986386992715, 'Total loss': 0.8521986386992715} | train loss {'Reaction outcome loss': 0.8284274177891867, 'Total loss': 0.8284274177891867}
2022-11-22 23:41:27,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:27,924 INFO:     Epoch: 66
2022-11-22 23:41:28,707 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8382836465131153, 'Total loss': 0.8382836465131153} | train loss {'Reaction outcome loss': 0.834863801148473, 'Total loss': 0.834863801148473}
2022-11-22 23:41:28,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:28,707 INFO:     Epoch: 67
2022-11-22 23:41:29,475 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8460125225511465, 'Total loss': 0.8460125225511465} | train loss {'Reaction outcome loss': 0.8327164112305154, 'Total loss': 0.8327164112305154}
2022-11-22 23:41:29,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:29,475 INFO:     Epoch: 68
2022-11-22 23:41:30,317 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.845119522376494, 'Total loss': 0.845119522376494} | train loss {'Reaction outcome loss': 0.827058573280062, 'Total loss': 0.827058573280062}
2022-11-22 23:41:30,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:30,317 INFO:     Epoch: 69
2022-11-22 23:41:31,119 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8422005847096443, 'Total loss': 0.8422005847096443} | train loss {'Reaction outcome loss': 0.8241825232700426, 'Total loss': 0.8241825232700426}
2022-11-22 23:41:31,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:31,120 INFO:     Epoch: 70
2022-11-22 23:41:31,907 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8513454083691944, 'Total loss': 0.8513454083691944} | train loss {'Reaction outcome loss': 0.8310400962829589, 'Total loss': 0.8310400962829589}
2022-11-22 23:41:31,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:31,907 INFO:     Epoch: 71
2022-11-22 23:41:32,683 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8529083146290346, 'Total loss': 0.8529083146290346} | train loss {'Reaction outcome loss': 0.8301850193617295, 'Total loss': 0.8301850193617295}
2022-11-22 23:41:32,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:32,684 INFO:     Epoch: 72
2022-11-22 23:41:33,466 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8581926944580945, 'Total loss': 0.8581926944580945} | train loss {'Reaction outcome loss': 0.8338086681706565, 'Total loss': 0.8338086681706565}
2022-11-22 23:41:33,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:33,467 INFO:     Epoch: 73
2022-11-22 23:41:34,284 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8492633253335953, 'Total loss': 0.8492633253335953} | train loss {'Reaction outcome loss': 0.8321396204890037, 'Total loss': 0.8321396204890037}
2022-11-22 23:41:34,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:34,284 INFO:     Epoch: 74
2022-11-22 23:41:35,120 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8443568582561883, 'Total loss': 0.8443568582561883} | train loss {'Reaction outcome loss': 0.8325694244735095, 'Total loss': 0.8325694244735095}
2022-11-22 23:41:35,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:35,120 INFO:     Epoch: 75
2022-11-22 23:41:35,943 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8408634005622431, 'Total loss': 0.8408634005622431} | train loss {'Reaction outcome loss': 0.8303451786235887, 'Total loss': 0.8303451786235887}
2022-11-22 23:41:35,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:35,944 INFO:     Epoch: 76
2022-11-22 23:41:36,772 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8671634874560616, 'Total loss': 0.8671634874560616} | train loss {'Reaction outcome loss': 0.8291253216412603, 'Total loss': 0.8291253216412603}
2022-11-22 23:41:36,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:36,772 INFO:     Epoch: 77
2022-11-22 23:41:37,549 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8386661552570083, 'Total loss': 0.8386661552570083} | train loss {'Reaction outcome loss': 0.8275532790592739, 'Total loss': 0.8275532790592739}
2022-11-22 23:41:37,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:37,550 INFO:     Epoch: 78
2022-11-22 23:41:38,338 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8631897561929442, 'Total loss': 0.8631897561929442} | train loss {'Reaction outcome loss': 0.8285431327868481, 'Total loss': 0.8285431327868481}
2022-11-22 23:41:38,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:38,339 INFO:     Epoch: 79
2022-11-22 23:41:39,130 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8464774584228342, 'Total loss': 0.8464774584228342} | train loss {'Reaction outcome loss': 0.8370679112113252, 'Total loss': 0.8370679112113252}
2022-11-22 23:41:39,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:39,130 INFO:     Epoch: 80
2022-11-22 23:41:39,973 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8360695330934091, 'Total loss': 0.8360695330934091} | train loss {'Reaction outcome loss': 0.8318790991695559, 'Total loss': 0.8318790991695559}
2022-11-22 23:41:39,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:39,974 INFO:     Epoch: 81
2022-11-22 23:41:40,816 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8583734929561615, 'Total loss': 0.8583734929561615} | train loss {'Reaction outcome loss': 0.8268994288785118, 'Total loss': 0.8268994288785118}
2022-11-22 23:41:40,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:40,816 INFO:     Epoch: 82
2022-11-22 23:41:41,621 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8405279455367815, 'Total loss': 0.8405279455367815} | train loss {'Reaction outcome loss': 0.8299760237032053, 'Total loss': 0.8299760237032053}
2022-11-22 23:41:41,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:41,621 INFO:     Epoch: 83
2022-11-22 23:41:42,432 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8553937140174888, 'Total loss': 0.8553937140174888} | train loss {'Reaction outcome loss': 0.832274184299975, 'Total loss': 0.832274184299975}
2022-11-22 23:41:42,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:42,433 INFO:     Epoch: 84
2022-11-22 23:41:43,246 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.853116397830573, 'Total loss': 0.853116397830573} | train loss {'Reaction outcome loss': 0.8304815793523983, 'Total loss': 0.8304815793523983}
2022-11-22 23:41:43,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:43,246 INFO:     Epoch: 85
2022-11-22 23:41:44,104 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8615968200293455, 'Total loss': 0.8615968200293455} | train loss {'Reaction outcome loss': 0.8339940017583419, 'Total loss': 0.8339940017583419}
2022-11-22 23:41:44,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:44,104 INFO:     Epoch: 86
2022-11-22 23:41:44,919 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8472773202440955, 'Total loss': 0.8472773202440955} | train loss {'Reaction outcome loss': 0.8335049777614827, 'Total loss': 0.8335049777614827}
2022-11-22 23:41:44,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:44,920 INFO:     Epoch: 87
2022-11-22 23:41:45,753 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.848450745371255, 'Total loss': 0.848450745371255} | train loss {'Reaction outcome loss': 0.8276304651279839, 'Total loss': 0.8276304651279839}
2022-11-22 23:41:45,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:45,753 INFO:     Epoch: 88
2022-11-22 23:41:46,574 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8653096583756533, 'Total loss': 0.8653096583756533} | train loss {'Reaction outcome loss': 0.8299312671836542, 'Total loss': 0.8299312671836542}
2022-11-22 23:41:46,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:46,574 INFO:     Epoch: 89
2022-11-22 23:41:47,387 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8532021560452201, 'Total loss': 0.8532021560452201} | train loss {'Reaction outcome loss': 0.8324045749343172, 'Total loss': 0.8324045749343172}
2022-11-22 23:41:47,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:47,387 INFO:     Epoch: 90
2022-11-22 23:41:48,187 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8562735021114349, 'Total loss': 0.8562735021114349} | train loss {'Reaction outcome loss': 0.8276897138478805, 'Total loss': 0.8276897138478805}
2022-11-22 23:41:48,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:48,187 INFO:     Epoch: 91
2022-11-22 23:41:49,008 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.875574225729162, 'Total loss': 0.875574225729162} | train loss {'Reaction outcome loss': 0.8308930144018056, 'Total loss': 0.8308930144018056}
2022-11-22 23:41:49,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:49,008 INFO:     Epoch: 92
2022-11-22 23:41:49,798 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.86512676152316, 'Total loss': 0.86512676152316} | train loss {'Reaction outcome loss': 0.8301342504365103, 'Total loss': 0.8301342504365103}
2022-11-22 23:41:49,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:49,798 INFO:     Epoch: 93
2022-11-22 23:41:50,612 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.837760020386089, 'Total loss': 0.837760020386089} | train loss {'Reaction outcome loss': 0.8347182929515838, 'Total loss': 0.8347182929515838}
2022-11-22 23:41:50,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:50,613 INFO:     Epoch: 94
2022-11-22 23:41:51,427 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8682873431931842, 'Total loss': 0.8682873431931842} | train loss {'Reaction outcome loss': 0.8322357937997701, 'Total loss': 0.8322357937997701}
2022-11-22 23:41:51,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:51,427 INFO:     Epoch: 95
2022-11-22 23:41:52,231 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8429038213057951, 'Total loss': 0.8429038213057951} | train loss {'Reaction outcome loss': 0.834284642582037, 'Total loss': 0.834284642582037}
2022-11-22 23:41:52,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:52,231 INFO:     Epoch: 96
2022-11-22 23:41:53,111 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8652118681506678, 'Total loss': 0.8652118681506678} | train loss {'Reaction outcome loss': 0.8287852243501312, 'Total loss': 0.8287852243501312}
2022-11-22 23:41:53,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:53,111 INFO:     Epoch: 97
2022-11-22 23:41:53,974 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8666954534974965, 'Total loss': 0.8666954534974965} | train loss {'Reaction outcome loss': 0.828793245189044, 'Total loss': 0.828793245189044}
2022-11-22 23:41:53,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:53,974 INFO:     Epoch: 98
2022-11-22 23:41:54,806 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8474639349363067, 'Total loss': 0.8474639349363067} | train loss {'Reaction outcome loss': 0.8286973683201537, 'Total loss': 0.8286973683201537}
2022-11-22 23:41:54,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:54,806 INFO:     Epoch: 99
2022-11-22 23:41:55,712 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8572925410487435, 'Total loss': 0.8572925410487435} | train loss {'Reaction outcome loss': 0.8268010448436348, 'Total loss': 0.8268010448436348}
2022-11-22 23:41:55,712 INFO:     Best model found after epoch 65 of 100.
2022-11-22 23:41:55,712 INFO:   Done with stage: TRAINING
2022-11-22 23:41:55,712 INFO:   Starting stage: EVALUATION
2022-11-22 23:41:55,844 INFO:   Done with stage: EVALUATION
2022-11-22 23:41:55,844 INFO:   Leaving out SEQ value Fold_3
2022-11-22 23:41:55,858 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 23:41:55,858 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:41:56,525 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:41:56,526 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:41:56,598 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:41:56,598 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:41:56,598 INFO:     No hyperparam tuning for this model
2022-11-22 23:41:56,598 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:41:56,598 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:41:56,599 INFO:     None feature selector for col prot
2022-11-22 23:41:56,599 INFO:     None feature selector for col prot
2022-11-22 23:41:56,600 INFO:     None feature selector for col prot
2022-11-22 23:41:56,600 INFO:     None feature selector for col chem
2022-11-22 23:41:56,600 INFO:     None feature selector for col chem
2022-11-22 23:41:56,600 INFO:     None feature selector for col chem
2022-11-22 23:41:56,600 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:41:56,600 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:41:56,602 INFO:     Number of params in model 168571
2022-11-22 23:41:56,605 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:41:56,605 INFO:   Starting stage: TRAINING
2022-11-22 23:41:56,664 INFO:     Val loss before train {'Reaction outcome loss': 1.0024903596833694, 'Total loss': 1.0024903596833694}
2022-11-22 23:41:56,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:56,664 INFO:     Epoch: 0
2022-11-22 23:41:57,532 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8532010594079661, 'Total loss': 0.8532010594079661} | train loss {'Reaction outcome loss': 0.8710889411998577, 'Total loss': 0.8710889411998577}
2022-11-22 23:41:57,533 INFO:     Found new best model at epoch 0
2022-11-22 23:41:57,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:57,534 INFO:     Epoch: 1
2022-11-22 23:41:58,401 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8504223324531732, 'Total loss': 0.8504223324531732} | train loss {'Reaction outcome loss': 0.8338518507900785, 'Total loss': 0.8338518507900785}
2022-11-22 23:41:58,401 INFO:     Found new best model at epoch 1
2022-11-22 23:41:58,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:58,402 INFO:     Epoch: 2
2022-11-22 23:41:59,286 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8698507935501808, 'Total loss': 0.8698507935501808} | train loss {'Reaction outcome loss': 0.8289044485961805, 'Total loss': 0.8289044485961805}
2022-11-22 23:41:59,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:41:59,286 INFO:     Epoch: 3
2022-11-22 23:42:00,179 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8944794826729353, 'Total loss': 0.8944794826729353} | train loss {'Reaction outcome loss': 0.823970827655714, 'Total loss': 0.823970827655714}
2022-11-22 23:42:00,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:00,179 INFO:     Epoch: 4
2022-11-22 23:42:01,063 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8459334761597389, 'Total loss': 0.8459334761597389} | train loss {'Reaction outcome loss': 0.816828834717391, 'Total loss': 0.816828834717391}
2022-11-22 23:42:01,063 INFO:     Found new best model at epoch 4
2022-11-22 23:42:01,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:01,064 INFO:     Epoch: 5
2022-11-22 23:42:01,988 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8499498533648114, 'Total loss': 0.8499498533648114} | train loss {'Reaction outcome loss': 0.8161632772840437, 'Total loss': 0.8161632772840437}
2022-11-22 23:42:01,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:01,988 INFO:     Epoch: 6
2022-11-22 23:42:02,847 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8615015301593515, 'Total loss': 0.8615015301593515} | train loss {'Reaction outcome loss': 0.8136385453284763, 'Total loss': 0.8136385453284763}
2022-11-22 23:42:02,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:02,848 INFO:     Epoch: 7
2022-11-22 23:42:03,693 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8583378403685814, 'Total loss': 0.8583378403685814} | train loss {'Reaction outcome loss': 0.8093850777530279, 'Total loss': 0.8093850777530279}
2022-11-22 23:42:03,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:03,693 INFO:     Epoch: 8
2022-11-22 23:42:04,498 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8412621783655744, 'Total loss': 0.8412621783655744} | train loss {'Reaction outcome loss': 0.8145506440616045, 'Total loss': 0.8145506440616045}
2022-11-22 23:42:04,498 INFO:     Found new best model at epoch 8
2022-11-22 23:42:04,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:04,499 INFO:     Epoch: 9
2022-11-22 23:42:05,427 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8453697070132854, 'Total loss': 0.8453697070132854} | train loss {'Reaction outcome loss': 0.8099282956758483, 'Total loss': 0.8099282956758483}
2022-11-22 23:42:05,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:05,427 INFO:     Epoch: 10
2022-11-22 23:42:06,352 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8493966564189556, 'Total loss': 0.8493966564189556} | train loss {'Reaction outcome loss': 0.8097033751059751, 'Total loss': 0.8097033751059751}
2022-11-22 23:42:06,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:06,353 INFO:     Epoch: 11
2022-11-22 23:42:07,275 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.84978841349136, 'Total loss': 0.84978841349136} | train loss {'Reaction outcome loss': 0.8107579004813413, 'Total loss': 0.8107579004813413}
2022-11-22 23:42:07,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:07,275 INFO:     Epoch: 12
2022-11-22 23:42:08,155 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8690197509388591, 'Total loss': 0.8690197509388591} | train loss {'Reaction outcome loss': 0.8121276401349755, 'Total loss': 0.8121276401349755}
2022-11-22 23:42:08,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:08,155 INFO:     Epoch: 13
2022-11-22 23:42:09,137 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8390336015889811, 'Total loss': 0.8390336015889811} | train loss {'Reaction outcome loss': 0.8101540602377204, 'Total loss': 0.8101540602377204}
2022-11-22 23:42:09,138 INFO:     Found new best model at epoch 13
2022-11-22 23:42:09,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:09,139 INFO:     Epoch: 14
2022-11-22 23:42:10,040 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8462529702242031, 'Total loss': 0.8462529702242031} | train loss {'Reaction outcome loss': 0.81152194726174, 'Total loss': 0.81152194726174}
2022-11-22 23:42:10,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:10,040 INFO:     Epoch: 15
2022-11-22 23:42:10,912 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8545442875041518, 'Total loss': 0.8545442875041518} | train loss {'Reaction outcome loss': 0.8107944609688931, 'Total loss': 0.8107944609688931}
2022-11-22 23:42:10,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:10,912 INFO:     Epoch: 16
2022-11-22 23:42:11,853 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8509155442548353, 'Total loss': 0.8509155442548353} | train loss {'Reaction outcome loss': 0.8036284072965872, 'Total loss': 0.8036284072965872}
2022-11-22 23:42:11,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:11,853 INFO:     Epoch: 17
2022-11-22 23:42:12,764 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8495914520219315, 'Total loss': 0.8495914520219315} | train loss {'Reaction outcome loss': 0.8030443364968065, 'Total loss': 0.8030443364968065}
2022-11-22 23:42:12,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:12,764 INFO:     Epoch: 18
2022-11-22 23:42:13,671 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8681843176830647, 'Total loss': 0.8681843176830647} | train loss {'Reaction outcome loss': 0.8086624773310833, 'Total loss': 0.8086624773310833}
2022-11-22 23:42:13,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:13,671 INFO:     Epoch: 19
2022-11-22 23:42:14,620 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8542646807293559, 'Total loss': 0.8542646807293559} | train loss {'Reaction outcome loss': 0.8044709400808225, 'Total loss': 0.8044709400808225}
2022-11-22 23:42:14,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:14,620 INFO:     Epoch: 20
2022-11-22 23:42:15,518 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8429688201394192, 'Total loss': 0.8429688201394192} | train loss {'Reaction outcome loss': 0.807838077427911, 'Total loss': 0.807838077427911}
2022-11-22 23:42:15,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:15,519 INFO:     Epoch: 21
2022-11-22 23:42:16,445 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8576766155486883, 'Total loss': 0.8576766155486883} | train loss {'Reaction outcome loss': 0.805230005964881, 'Total loss': 0.805230005964881}
2022-11-22 23:42:16,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:16,446 INFO:     Epoch: 22
2022-11-22 23:42:17,299 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8439978208652762, 'Total loss': 0.8439978208652762} | train loss {'Reaction outcome loss': 0.805972976518459, 'Total loss': 0.805972976518459}
2022-11-22 23:42:17,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:17,300 INFO:     Epoch: 23
2022-11-22 23:42:18,157 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8368575857129208, 'Total loss': 0.8368575857129208} | train loss {'Reaction outcome loss': 0.8068732399432386, 'Total loss': 0.8068732399432386}
2022-11-22 23:42:18,157 INFO:     Found new best model at epoch 23
2022-11-22 23:42:18,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:18,158 INFO:     Epoch: 24
2022-11-22 23:42:19,019 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8416308968566185, 'Total loss': 0.8416308968566185} | train loss {'Reaction outcome loss': 0.8087704555421579, 'Total loss': 0.8087704555421579}
2022-11-22 23:42:19,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:19,019 INFO:     Epoch: 25
2022-11-22 23:42:19,841 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8416338077811307, 'Total loss': 0.8416338077811307} | train loss {'Reaction outcome loss': 0.8090053211714401, 'Total loss': 0.8090053211714401}
2022-11-22 23:42:19,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:19,842 INFO:     Epoch: 26
2022-11-22 23:42:20,673 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8655222390973291, 'Total loss': 0.8655222390973291} | train loss {'Reaction outcome loss': 0.8082515675513471, 'Total loss': 0.8082515675513471}
2022-11-22 23:42:20,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:20,673 INFO:     Epoch: 27
2022-11-22 23:42:21,571 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8365276338056077, 'Total loss': 0.8365276338056077} | train loss {'Reaction outcome loss': 0.8122134636171529, 'Total loss': 0.8122134636171529}
2022-11-22 23:42:21,571 INFO:     Found new best model at epoch 27
2022-11-22 23:42:21,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:21,572 INFO:     Epoch: 28
2022-11-22 23:42:22,522 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8389610474885896, 'Total loss': 0.8389610474885896} | train loss {'Reaction outcome loss': 0.8053448306488209, 'Total loss': 0.8053448306488209}
2022-11-22 23:42:22,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:22,523 INFO:     Epoch: 29
2022-11-22 23:42:23,370 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8343351587306621, 'Total loss': 0.8343351587306621} | train loss {'Reaction outcome loss': 0.8070376156294932, 'Total loss': 0.8070376156294932}
2022-11-22 23:42:23,370 INFO:     Found new best model at epoch 29
2022-11-22 23:42:23,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:23,371 INFO:     Epoch: 30
2022-11-22 23:42:24,208 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8434088417263919, 'Total loss': 0.8434088417263919} | train loss {'Reaction outcome loss': 0.8084542781847422, 'Total loss': 0.8084542781847422}
2022-11-22 23:42:24,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:24,209 INFO:     Epoch: 31
2022-11-22 23:42:25,062 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8552428678024647, 'Total loss': 0.8552428678024647} | train loss {'Reaction outcome loss': 0.8112908411221426, 'Total loss': 0.8112908411221426}
2022-11-22 23:42:25,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:25,062 INFO:     Epoch: 32
2022-11-22 23:42:25,957 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8589696315831916, 'Total loss': 0.8589696315831916} | train loss {'Reaction outcome loss': 0.8048538662126807, 'Total loss': 0.8048538662126807}
2022-11-22 23:42:25,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:25,958 INFO:     Epoch: 33
2022-11-22 23:42:26,844 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8705232947371727, 'Total loss': 0.8705232947371727} | train loss {'Reaction outcome loss': 0.8096580695910532, 'Total loss': 0.8096580695910532}
2022-11-22 23:42:26,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:26,844 INFO:     Epoch: 34
2022-11-22 23:42:27,707 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.854405096797056, 'Total loss': 0.854405096797056} | train loss {'Reaction outcome loss': 0.805909591131523, 'Total loss': 0.805909591131523}
2022-11-22 23:42:27,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:27,707 INFO:     Epoch: 35
2022-11-22 23:42:28,571 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8346346935560537, 'Total loss': 0.8346346935560537} | train loss {'Reaction outcome loss': 0.8072929859894221, 'Total loss': 0.8072929859894221}
2022-11-22 23:42:28,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:28,571 INFO:     Epoch: 36
2022-11-22 23:42:29,393 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8319566769655361, 'Total loss': 0.8319566769655361} | train loss {'Reaction outcome loss': 0.8038518232156019, 'Total loss': 0.8038518232156019}
2022-11-22 23:42:29,394 INFO:     Found new best model at epoch 36
2022-11-22 23:42:29,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:29,394 INFO:     Epoch: 37
2022-11-22 23:42:30,275 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8451329816219418, 'Total loss': 0.8451329816219418} | train loss {'Reaction outcome loss': 0.8062251179677541, 'Total loss': 0.8062251179677541}
2022-11-22 23:42:30,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:30,276 INFO:     Epoch: 38
2022-11-22 23:42:31,089 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8415440016014631, 'Total loss': 0.8415440016014631} | train loss {'Reaction outcome loss': 0.8092209238742218, 'Total loss': 0.8092209238742218}
2022-11-22 23:42:31,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:31,090 INFO:     Epoch: 39
2022-11-22 23:42:31,949 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8444386485011078, 'Total loss': 0.8444386485011078} | train loss {'Reaction outcome loss': 0.8016326735254193, 'Total loss': 0.8016326735254193}
2022-11-22 23:42:31,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:31,950 INFO:     Epoch: 40
2022-11-22 23:42:32,828 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8401856505593588, 'Total loss': 0.8401856505593588} | train loss {'Reaction outcome loss': 0.8060679292825402, 'Total loss': 0.8060679292825402}
2022-11-22 23:42:32,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:32,829 INFO:     Epoch: 41
2022-11-22 23:42:33,661 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8379715584045233, 'Total loss': 0.8379715584045233} | train loss {'Reaction outcome loss': 0.8048163577914238, 'Total loss': 0.8048163577914238}
2022-11-22 23:42:33,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:33,661 INFO:     Epoch: 42
2022-11-22 23:42:34,543 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8367680768633998, 'Total loss': 0.8367680768633998} | train loss {'Reaction outcome loss': 0.8041121351425765, 'Total loss': 0.8041121351425765}
2022-11-22 23:42:34,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:34,544 INFO:     Epoch: 43
2022-11-22 23:42:35,327 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8476228159527446, 'Total loss': 0.8476228159527446} | train loss {'Reaction outcome loss': 0.7988027113138653, 'Total loss': 0.7988027113138653}
2022-11-22 23:42:35,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:35,327 INFO:     Epoch: 44
2022-11-22 23:42:36,240 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8426700927490411, 'Total loss': 0.8426700927490411} | train loss {'Reaction outcome loss': 0.8023053869360783, 'Total loss': 0.8023053869360783}
2022-11-22 23:42:36,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:36,242 INFO:     Epoch: 45
2022-11-22 23:42:37,111 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8425044361935106, 'Total loss': 0.8425044361935106} | train loss {'Reaction outcome loss': 0.8022682280814062, 'Total loss': 0.8022682280814062}
2022-11-22 23:42:37,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:37,111 INFO:     Epoch: 46
2022-11-22 23:42:37,977 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8380075408968815, 'Total loss': 0.8380075408968815} | train loss {'Reaction outcome loss': 0.8036228745687203, 'Total loss': 0.8036228745687203}
2022-11-22 23:42:37,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:37,977 INFO:     Epoch: 47
2022-11-22 23:42:38,886 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8468362841495248, 'Total loss': 0.8468362841495248} | train loss {'Reaction outcome loss': 0.8034499308369198, 'Total loss': 0.8034499308369198}
2022-11-22 23:42:38,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:38,886 INFO:     Epoch: 48
2022-11-22 23:42:39,793 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8443119331847789, 'Total loss': 0.8443119331847789} | train loss {'Reaction outcome loss': 0.8045602586181437, 'Total loss': 0.8045602586181437}
2022-11-22 23:42:39,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:39,793 INFO:     Epoch: 49
2022-11-22 23:42:40,669 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8400649262029071, 'Total loss': 0.8400649262029071} | train loss {'Reaction outcome loss': 0.8033087889923424, 'Total loss': 0.8033087889923424}
2022-11-22 23:42:40,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:40,669 INFO:     Epoch: 50
2022-11-22 23:42:41,592 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8422545097595038, 'Total loss': 0.8422545097595038} | train loss {'Reaction outcome loss': 0.7976725215061766, 'Total loss': 0.7976725215061766}
2022-11-22 23:42:41,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:41,593 INFO:     Epoch: 51
2022-11-22 23:42:42,446 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8449691755827083, 'Total loss': 0.8449691755827083} | train loss {'Reaction outcome loss': 0.8048842458939943, 'Total loss': 0.8048842458939943}
2022-11-22 23:42:42,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:42,447 INFO:     Epoch: 52
2022-11-22 23:42:43,285 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8338532718115075, 'Total loss': 0.8338532718115075} | train loss {'Reaction outcome loss': 0.803817016301585, 'Total loss': 0.803817016301585}
2022-11-22 23:42:43,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:43,285 INFO:     Epoch: 53
2022-11-22 23:42:44,172 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8438096989032834, 'Total loss': 0.8438096989032834} | train loss {'Reaction outcome loss': 0.8023837038972339, 'Total loss': 0.8023837038972339}
2022-11-22 23:42:44,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:44,172 INFO:     Epoch: 54
2022-11-22 23:42:45,043 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8707183516302774, 'Total loss': 0.8707183516302774} | train loss {'Reaction outcome loss': 0.8005769824395415, 'Total loss': 0.8005769824395415}
2022-11-22 23:42:45,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:45,043 INFO:     Epoch: 55
2022-11-22 23:42:45,906 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8444425352784091, 'Total loss': 0.8444425352784091} | train loss {'Reaction outcome loss': 0.8021989224142716, 'Total loss': 0.8021989224142716}
2022-11-22 23:42:45,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:45,906 INFO:     Epoch: 56
2022-11-22 23:42:46,754 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8454618606456491, 'Total loss': 0.8454618606456491} | train loss {'Reaction outcome loss': 0.7998300418257713, 'Total loss': 0.7998300418257713}
2022-11-22 23:42:46,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:46,754 INFO:     Epoch: 57
2022-11-22 23:42:47,579 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8366618502971738, 'Total loss': 0.8366618502971738} | train loss {'Reaction outcome loss': 0.8030592068785527, 'Total loss': 0.8030592068785527}
2022-11-22 23:42:47,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:47,580 INFO:     Epoch: 58
2022-11-22 23:42:48,409 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8375701405281244, 'Total loss': 0.8375701405281244} | train loss {'Reaction outcome loss': 0.7990850879520667, 'Total loss': 0.7990850879520667}
2022-11-22 23:42:48,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:48,409 INFO:     Epoch: 59
2022-11-22 23:42:49,283 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8310533637224242, 'Total loss': 0.8310533637224242} | train loss {'Reaction outcome loss': 0.8042842072785877, 'Total loss': 0.8042842072785877}
2022-11-22 23:42:49,283 INFO:     Found new best model at epoch 59
2022-11-22 23:42:49,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:49,284 INFO:     Epoch: 60
2022-11-22 23:42:50,151 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8447758375212203, 'Total loss': 0.8447758375212203} | train loss {'Reaction outcome loss': 0.7992980542485831, 'Total loss': 0.7992980542485831}
2022-11-22 23:42:50,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:50,151 INFO:     Epoch: 61
2022-11-22 23:42:51,004 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8373090964417125, 'Total loss': 0.8373090964417125} | train loss {'Reaction outcome loss': 0.8017332064079457, 'Total loss': 0.8017332064079457}
2022-11-22 23:42:51,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:51,004 INFO:     Epoch: 62
2022-11-22 23:42:51,839 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.843562058238096, 'Total loss': 0.843562058238096} | train loss {'Reaction outcome loss': 0.8013883302690553, 'Total loss': 0.8013883302690553}
2022-11-22 23:42:51,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:51,840 INFO:     Epoch: 63
2022-11-22 23:42:52,664 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8579524492108545, 'Total loss': 0.8579524492108545} | train loss {'Reaction outcome loss': 0.7970779132647593, 'Total loss': 0.7970779132647593}
2022-11-22 23:42:52,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:52,666 INFO:     Epoch: 64
2022-11-22 23:42:53,501 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8516301699849063, 'Total loss': 0.8516301699849063} | train loss {'Reaction outcome loss': 0.806010579110169, 'Total loss': 0.806010579110169}
2022-11-22 23:42:53,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:53,502 INFO:     Epoch: 65
2022-11-22 23:42:54,356 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8415107893389325, 'Total loss': 0.8415107893389325} | train loss {'Reaction outcome loss': 0.8067227893921195, 'Total loss': 0.8067227893921195}
2022-11-22 23:42:54,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:54,357 INFO:     Epoch: 66
2022-11-22 23:42:55,219 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8494250483291094, 'Total loss': 0.8494250483291094} | train loss {'Reaction outcome loss': 0.8025177939504874, 'Total loss': 0.8025177939504874}
2022-11-22 23:42:55,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:55,221 INFO:     Epoch: 67
2022-11-22 23:42:56,091 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8476495534874672, 'Total loss': 0.8476495534874672} | train loss {'Reaction outcome loss': 0.8038470732872603, 'Total loss': 0.8038470732872603}
2022-11-22 23:42:56,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:56,091 INFO:     Epoch: 68
2022-11-22 23:42:56,952 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.845892270637113, 'Total loss': 0.845892270637113} | train loss {'Reaction outcome loss': 0.8055225747530578, 'Total loss': 0.8055225747530578}
2022-11-22 23:42:56,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:56,952 INFO:     Epoch: 69
2022-11-22 23:42:57,827 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8376578245052072, 'Total loss': 0.8376578245052072} | train loss {'Reaction outcome loss': 0.8016250321611029, 'Total loss': 0.8016250321611029}
2022-11-22 23:42:57,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:57,828 INFO:     Epoch: 70
2022-11-22 23:42:58,700 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8374861950098083, 'Total loss': 0.8374861950098083} | train loss {'Reaction outcome loss': 0.8006623516805836, 'Total loss': 0.8006623516805836}
2022-11-22 23:42:58,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:58,702 INFO:     Epoch: 71
2022-11-22 23:42:59,501 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.83454996693966, 'Total loss': 0.83454996693966} | train loss {'Reaction outcome loss': 0.7999890616438428, 'Total loss': 0.7999890616438428}
2022-11-22 23:42:59,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:42:59,501 INFO:     Epoch: 72
2022-11-22 23:43:00,392 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8312656089316967, 'Total loss': 0.8312656089316967} | train loss {'Reaction outcome loss': 0.7984107699794848, 'Total loss': 0.7984107699794848}
2022-11-22 23:43:00,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:00,392 INFO:     Epoch: 73
2022-11-22 23:43:01,227 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8424337561740431, 'Total loss': 0.8424337561740431} | train loss {'Reaction outcome loss': 0.8001414705983928, 'Total loss': 0.8001414705983928}
2022-11-22 23:43:01,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:01,228 INFO:     Epoch: 74
2022-11-22 23:43:02,051 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8368504816709563, 'Total loss': 0.8368504816709563} | train loss {'Reaction outcome loss': 0.8007909087616889, 'Total loss': 0.8007909087616889}
2022-11-22 23:43:02,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:02,051 INFO:     Epoch: 75
2022-11-22 23:43:02,916 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8481394142605537, 'Total loss': 0.8481394142605537} | train loss {'Reaction outcome loss': 0.7992687952078756, 'Total loss': 0.7992687952078756}
2022-11-22 23:43:02,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:02,916 INFO:     Epoch: 76
2022-11-22 23:43:03,689 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8470252572103988, 'Total loss': 0.8470252572103988} | train loss {'Reaction outcome loss': 0.8067564678485276, 'Total loss': 0.8067564678485276}
2022-11-22 23:43:03,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:03,691 INFO:     Epoch: 77
2022-11-22 23:43:04,524 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8333189674588137, 'Total loss': 0.8333189674588137} | train loss {'Reaction outcome loss': 0.7997989165978353, 'Total loss': 0.7997989165978353}
2022-11-22 23:43:04,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:04,525 INFO:     Epoch: 78
2022-11-22 23:43:05,324 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.842097052308016, 'Total loss': 0.842097052308016} | train loss {'Reaction outcome loss': 0.8008342610030877, 'Total loss': 0.8008342610030877}
2022-11-22 23:43:05,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:05,325 INFO:     Epoch: 79
2022-11-22 23:43:06,132 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8442228062208309, 'Total loss': 0.8442228062208309} | train loss {'Reaction outcome loss': 0.8029276412285742, 'Total loss': 0.8029276412285742}
2022-11-22 23:43:06,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:06,132 INFO:     Epoch: 80
2022-11-22 23:43:06,977 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8815111136713694, 'Total loss': 0.8815111136713694} | train loss {'Reaction outcome loss': 0.8009581093172558, 'Total loss': 0.8009581093172558}
2022-11-22 23:43:06,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:06,977 INFO:     Epoch: 81
2022-11-22 23:43:07,749 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8460821107376454, 'Total loss': 0.8460821107376454} | train loss {'Reaction outcome loss': 0.8027351855254564, 'Total loss': 0.8027351855254564}
2022-11-22 23:43:07,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:07,749 INFO:     Epoch: 82
2022-11-22 23:43:08,554 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.842549976914428, 'Total loss': 0.842549976914428} | train loss {'Reaction outcome loss': 0.8035681154884275, 'Total loss': 0.8035681154884275}
2022-11-22 23:43:08,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:08,555 INFO:     Epoch: 83
2022-11-22 23:43:09,373 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8508267139279565, 'Total loss': 0.8508267139279565} | train loss {'Reaction outcome loss': 0.8012186583192622, 'Total loss': 0.8012186583192622}
2022-11-22 23:43:09,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:09,373 INFO:     Epoch: 84
2022-11-22 23:43:10,138 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8294349340505378, 'Total loss': 0.8294349340505378} | train loss {'Reaction outcome loss': 0.7995663309683565, 'Total loss': 0.7995663309683565}
2022-11-22 23:43:10,138 INFO:     Found new best model at epoch 84
2022-11-22 23:43:10,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:10,139 INFO:     Epoch: 85
2022-11-22 23:43:10,940 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8550756476646246, 'Total loss': 0.8550756476646246} | train loss {'Reaction outcome loss': 0.7982115408436197, 'Total loss': 0.7982115408436197}
2022-11-22 23:43:10,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:10,940 INFO:     Epoch: 86
2022-11-22 23:43:11,731 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8373125840065091, 'Total loss': 0.8373125840065091} | train loss {'Reaction outcome loss': 0.7974775660721982, 'Total loss': 0.7974775660721982}
2022-11-22 23:43:11,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:11,731 INFO:     Epoch: 87
2022-11-22 23:43:12,571 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8330167164636213, 'Total loss': 0.8330167164636213} | train loss {'Reaction outcome loss': 0.8011370412394648, 'Total loss': 0.8011370412394648}
2022-11-22 23:43:12,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:12,571 INFO:     Epoch: 88
2022-11-22 23:43:13,398 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8431049110584481, 'Total loss': 0.8431049110584481} | train loss {'Reaction outcome loss': 0.8003385781508977, 'Total loss': 0.8003385781508977}
2022-11-22 23:43:13,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:13,398 INFO:     Epoch: 89
2022-11-22 23:43:14,195 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8516118859135827, 'Total loss': 0.8516118859135827} | train loss {'Reaction outcome loss': 0.8051300863506364, 'Total loss': 0.8051300863506364}
2022-11-22 23:43:14,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:14,195 INFO:     Epoch: 90
2022-11-22 23:43:15,014 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8269562083621358, 'Total loss': 0.8269562083621358} | train loss {'Reaction outcome loss': 0.802928908437979, 'Total loss': 0.802928908437979}
2022-11-22 23:43:15,016 INFO:     Found new best model at epoch 90
2022-11-22 23:43:15,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:15,016 INFO:     Epoch: 91
2022-11-22 23:43:15,854 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.837523411872775, 'Total loss': 0.837523411872775} | train loss {'Reaction outcome loss': 0.7995866197543066, 'Total loss': 0.7995866197543066}
2022-11-22 23:43:15,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:15,854 INFO:     Epoch: 92
2022-11-22 23:43:16,739 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.836146071899769, 'Total loss': 0.836146071899769} | train loss {'Reaction outcome loss': 0.7992414909063793, 'Total loss': 0.7992414909063793}
2022-11-22 23:43:16,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:16,739 INFO:     Epoch: 93
2022-11-22 23:43:17,553 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8412449775740157, 'Total loss': 0.8412449775740157} | train loss {'Reaction outcome loss': 0.8037228458484665, 'Total loss': 0.8037228458484665}
2022-11-22 23:43:17,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:17,553 INFO:     Epoch: 94
2022-11-22 23:43:18,335 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8561856836773628, 'Total loss': 0.8561856836773628} | train loss {'Reaction outcome loss': 0.8008478900692502, 'Total loss': 0.8008478900692502}
2022-11-22 23:43:18,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:18,335 INFO:     Epoch: 95
2022-11-22 23:43:19,154 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8399630036464957, 'Total loss': 0.8399630036464957} | train loss {'Reaction outcome loss': 0.7992075791613, 'Total loss': 0.7992075791613}
2022-11-22 23:43:19,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:19,154 INFO:     Epoch: 96
2022-11-22 23:43:19,970 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8366977815018144, 'Total loss': 0.8366977815018144} | train loss {'Reaction outcome loss': 0.7946179885356153, 'Total loss': 0.7946179885356153}
2022-11-22 23:43:19,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:19,970 INFO:     Epoch: 97
2022-11-22 23:43:20,771 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8382120874038962, 'Total loss': 0.8382120874038962} | train loss {'Reaction outcome loss': 0.7983691093863033, 'Total loss': 0.7983691093863033}
2022-11-22 23:43:20,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:20,773 INFO:     Epoch: 98
2022-11-22 23:43:21,593 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8258482931658279, 'Total loss': 0.8258482931658279} | train loss {'Reaction outcome loss': 0.8002668406631126, 'Total loss': 0.8002668406631126}
2022-11-22 23:43:21,593 INFO:     Found new best model at epoch 98
2022-11-22 23:43:21,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:21,594 INFO:     Epoch: 99
2022-11-22 23:43:22,384 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8278196038201798, 'Total loss': 0.8278196038201798} | train loss {'Reaction outcome loss': 0.797445936281173, 'Total loss': 0.797445936281173}
2022-11-22 23:43:22,384 INFO:     Best model found after epoch 99 of 100.
2022-11-22 23:43:22,384 INFO:   Done with stage: TRAINING
2022-11-22 23:43:22,384 INFO:   Starting stage: EVALUATION
2022-11-22 23:43:22,519 INFO:   Done with stage: EVALUATION
2022-11-22 23:43:22,519 INFO:   Leaving out SEQ value Fold_4
2022-11-22 23:43:22,533 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 23:43:22,533 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:43:23,204 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:43:23,204 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:43:23,274 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:43:23,274 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:43:23,274 INFO:     No hyperparam tuning for this model
2022-11-22 23:43:23,274 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:43:23,274 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:43:23,275 INFO:     None feature selector for col prot
2022-11-22 23:43:23,275 INFO:     None feature selector for col prot
2022-11-22 23:43:23,275 INFO:     None feature selector for col prot
2022-11-22 23:43:23,276 INFO:     None feature selector for col chem
2022-11-22 23:43:23,276 INFO:     None feature selector for col chem
2022-11-22 23:43:23,276 INFO:     None feature selector for col chem
2022-11-22 23:43:23,276 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:43:23,276 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:43:23,278 INFO:     Number of params in model 168571
2022-11-22 23:43:23,281 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:43:23,281 INFO:   Starting stage: TRAINING
2022-11-22 23:43:23,339 INFO:     Val loss before train {'Reaction outcome loss': 1.0002566548911007, 'Total loss': 1.0002566548911007}
2022-11-22 23:43:23,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:23,339 INFO:     Epoch: 0
2022-11-22 23:43:24,162 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8845469491048292, 'Total loss': 0.8845469491048292} | train loss {'Reaction outcome loss': 0.877152132866334, 'Total loss': 0.877152132866334}
2022-11-22 23:43:24,162 INFO:     Found new best model at epoch 0
2022-11-22 23:43:24,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:24,163 INFO:     Epoch: 1
2022-11-22 23:43:24,997 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8595886528491974, 'Total loss': 0.8595886528491974} | train loss {'Reaction outcome loss': 0.8524218105539983, 'Total loss': 0.8524218105539983}
2022-11-22 23:43:24,997 INFO:     Found new best model at epoch 1
2022-11-22 23:43:24,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:24,998 INFO:     Epoch: 2
2022-11-22 23:43:25,798 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8375795761292631, 'Total loss': 0.8375795761292631} | train loss {'Reaction outcome loss': 0.8469417159654656, 'Total loss': 0.8469417159654656}
2022-11-22 23:43:25,799 INFO:     Found new best model at epoch 2
2022-11-22 23:43:25,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:25,800 INFO:     Epoch: 3
2022-11-22 23:43:26,602 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8642006916078654, 'Total loss': 0.8642006916078654} | train loss {'Reaction outcome loss': 0.838526377994187, 'Total loss': 0.838526377994187}
2022-11-22 23:43:26,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:26,602 INFO:     Epoch: 4
2022-11-22 23:43:27,408 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8371064994822849, 'Total loss': 0.8371064994822849} | train loss {'Reaction outcome loss': 0.8316978674762103, 'Total loss': 0.8316978674762103}
2022-11-22 23:43:27,408 INFO:     Found new best model at epoch 4
2022-11-22 23:43:27,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:27,409 INFO:     Epoch: 5
2022-11-22 23:43:28,199 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8553980047052557, 'Total loss': 0.8553980047052557} | train loss {'Reaction outcome loss': 0.8381033466786755, 'Total loss': 0.8381033466786755}
2022-11-22 23:43:28,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:28,200 INFO:     Epoch: 6
2022-11-22 23:43:29,034 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8480019433931871, 'Total loss': 0.8480019433931871} | train loss {'Reaction outcome loss': 0.8367327810550222, 'Total loss': 0.8367327810550222}
2022-11-22 23:43:29,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:29,034 INFO:     Epoch: 7
2022-11-22 23:43:29,809 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8312905315648426, 'Total loss': 0.8312905315648426} | train loss {'Reaction outcome loss': 0.8293781269569787, 'Total loss': 0.8293781269569787}
2022-11-22 23:43:29,809 INFO:     Found new best model at epoch 7
2022-11-22 23:43:29,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:29,810 INFO:     Epoch: 8
2022-11-22 23:43:30,644 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8645840300755068, 'Total loss': 0.8645840300755068} | train loss {'Reaction outcome loss': 0.829504906158058, 'Total loss': 0.829504906158058}
2022-11-22 23:43:30,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:30,645 INFO:     Epoch: 9
2022-11-22 23:43:31,454 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8125474043190479, 'Total loss': 0.8125474043190479} | train loss {'Reaction outcome loss': 0.8250293020082979, 'Total loss': 0.8250293020082979}
2022-11-22 23:43:31,455 INFO:     Found new best model at epoch 9
2022-11-22 23:43:31,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:31,456 INFO:     Epoch: 10
2022-11-22 23:43:32,248 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8236816335808147, 'Total loss': 0.8236816335808147} | train loss {'Reaction outcome loss': 0.8301530802736476, 'Total loss': 0.8301530802736476}
2022-11-22 23:43:32,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:32,249 INFO:     Epoch: 11
2022-11-22 23:43:33,011 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8213623524220153, 'Total loss': 0.8213623524220153} | train loss {'Reaction outcome loss': 0.825296227056153, 'Total loss': 0.825296227056153}
2022-11-22 23:43:33,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:33,012 INFO:     Epoch: 12
2022-11-22 23:43:33,838 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8231360993602059, 'Total loss': 0.8231360993602059} | train loss {'Reaction outcome loss': 0.8282283099330201, 'Total loss': 0.8282283099330201}
2022-11-22 23:43:33,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:33,839 INFO:     Epoch: 13
2022-11-22 23:43:34,608 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8382214517755942, 'Total loss': 0.8382214517755942} | train loss {'Reaction outcome loss': 0.821650788492086, 'Total loss': 0.821650788492086}
2022-11-22 23:43:34,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:34,608 INFO:     Epoch: 14
2022-11-22 23:43:35,418 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8300016861070286, 'Total loss': 0.8300016861070286} | train loss {'Reaction outcome loss': 0.8185509973642777, 'Total loss': 0.8185509973642777}
2022-11-22 23:43:35,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:35,418 INFO:     Epoch: 15
2022-11-22 23:43:36,239 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8375745801763101, 'Total loss': 0.8375745801763101} | train loss {'Reaction outcome loss': 0.8214152105000554, 'Total loss': 0.8214152105000554}
2022-11-22 23:43:36,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:36,240 INFO:     Epoch: 16
2022-11-22 23:43:37,062 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8380990556695245, 'Total loss': 0.8380990556695245} | train loss {'Reaction outcome loss': 0.8245445809802231, 'Total loss': 0.8245445809802231}
2022-11-22 23:43:37,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:37,062 INFO:     Epoch: 17
2022-11-22 23:43:37,875 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8168041828003797, 'Total loss': 0.8168041828003797} | train loss {'Reaction outcome loss': 0.823148306778499, 'Total loss': 0.823148306778499}
2022-11-22 23:43:37,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:37,877 INFO:     Epoch: 18
2022-11-22 23:43:38,696 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8292804732918739, 'Total loss': 0.8292804732918739} | train loss {'Reaction outcome loss': 0.8212694878480873, 'Total loss': 0.8212694878480873}
2022-11-22 23:43:38,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:38,696 INFO:     Epoch: 19
2022-11-22 23:43:39,552 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8133256536993113, 'Total loss': 0.8133256536993113} | train loss {'Reaction outcome loss': 0.8206235175838276, 'Total loss': 0.8206235175838276}
2022-11-22 23:43:39,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:39,552 INFO:     Epoch: 20
2022-11-22 23:43:40,387 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8363108065995303, 'Total loss': 0.8363108065995303} | train loss {'Reaction outcome loss': 0.8147033664644981, 'Total loss': 0.8147033664644981}
2022-11-22 23:43:40,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:40,387 INFO:     Epoch: 21
2022-11-22 23:43:41,206 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8492143099958246, 'Total loss': 0.8492143099958246} | train loss {'Reaction outcome loss': 0.8220947148848553, 'Total loss': 0.8220947148848553}
2022-11-22 23:43:41,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:41,206 INFO:     Epoch: 22
2022-11-22 23:43:42,034 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8599485389210961, 'Total loss': 0.8599485389210961} | train loss {'Reaction outcome loss': 0.8159107126751725, 'Total loss': 0.8159107126751725}
2022-11-22 23:43:42,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:42,034 INFO:     Epoch: 23
2022-11-22 23:43:42,794 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8647488016973842, 'Total loss': 0.8647488016973842} | train loss {'Reaction outcome loss': 0.8144452385756434, 'Total loss': 0.8144452385756434}
2022-11-22 23:43:42,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:42,795 INFO:     Epoch: 24
2022-11-22 23:43:43,591 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.827344223856926, 'Total loss': 0.827344223856926} | train loss {'Reaction outcome loss': 0.8175134690440431, 'Total loss': 0.8175134690440431}
2022-11-22 23:43:43,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:43,591 INFO:     Epoch: 25
2022-11-22 23:43:44,363 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8548229526389729, 'Total loss': 0.8548229526389729} | train loss {'Reaction outcome loss': 0.8176371134057336, 'Total loss': 0.8176371134057336}
2022-11-22 23:43:44,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:44,363 INFO:     Epoch: 26
2022-11-22 23:43:45,140 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8253700672225519, 'Total loss': 0.8253700672225519} | train loss {'Reaction outcome loss': 0.8172698458846734, 'Total loss': 0.8172698458846734}
2022-11-22 23:43:45,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:45,141 INFO:     Epoch: 27
2022-11-22 23:43:45,979 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8089390302246268, 'Total loss': 0.8089390302246268} | train loss {'Reaction outcome loss': 0.8157634188934249, 'Total loss': 0.8157634188934249}
2022-11-22 23:43:45,979 INFO:     Found new best model at epoch 27
2022-11-22 23:43:45,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:45,980 INFO:     Epoch: 28
2022-11-22 23:43:46,775 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8282636431130496, 'Total loss': 0.8282636431130496} | train loss {'Reaction outcome loss': 0.8148132708607888, 'Total loss': 0.8148132708607888}
2022-11-22 23:43:46,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:46,776 INFO:     Epoch: 29
2022-11-22 23:43:47,519 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.841922250660983, 'Total loss': 0.841922250660983} | train loss {'Reaction outcome loss': 0.8148956510485436, 'Total loss': 0.8148956510485436}
2022-11-22 23:43:47,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:47,519 INFO:     Epoch: 30
2022-11-22 23:43:48,329 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8095229667696086, 'Total loss': 0.8095229667696086} | train loss {'Reaction outcome loss': 0.8173388035929933, 'Total loss': 0.8173388035929933}
2022-11-22 23:43:48,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:48,330 INFO:     Epoch: 31
2022-11-22 23:43:49,108 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8237671967257153, 'Total loss': 0.8237671967257153} | train loss {'Reaction outcome loss': 0.812858250554727, 'Total loss': 0.812858250554727}
2022-11-22 23:43:49,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:49,109 INFO:     Epoch: 32
2022-11-22 23:43:49,886 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8281563926826824, 'Total loss': 0.8281563926826824} | train loss {'Reaction outcome loss': 0.8182292593985188, 'Total loss': 0.8182292593985188}
2022-11-22 23:43:49,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:49,886 INFO:     Epoch: 33
2022-11-22 23:43:50,662 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8069713024253194, 'Total loss': 0.8069713024253194} | train loss {'Reaction outcome loss': 0.8165527768281041, 'Total loss': 0.8165527768281041}
2022-11-22 23:43:50,662 INFO:     Found new best model at epoch 33
2022-11-22 23:43:50,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:50,663 INFO:     Epoch: 34
2022-11-22 23:43:51,465 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8405358147892085, 'Total loss': 0.8405358147892085} | train loss {'Reaction outcome loss': 0.8124354960967083, 'Total loss': 0.8124354960967083}
2022-11-22 23:43:51,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:51,465 INFO:     Epoch: 35
2022-11-22 23:43:52,300 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8267688277092847, 'Total loss': 0.8267688277092847} | train loss {'Reaction outcome loss': 0.8162785460754317, 'Total loss': 0.8162785460754317}
2022-11-22 23:43:52,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:52,300 INFO:     Epoch: 36
2022-11-22 23:43:53,147 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8408087051727555, 'Total loss': 0.8408087051727555} | train loss {'Reaction outcome loss': 0.814836165004847, 'Total loss': 0.814836165004847}
2022-11-22 23:43:53,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:53,148 INFO:     Epoch: 37
2022-11-22 23:43:54,007 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8334924497387626, 'Total loss': 0.8334924497387626} | train loss {'Reaction outcome loss': 0.8146501434092619, 'Total loss': 0.8146501434092619}
2022-11-22 23:43:54,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:54,007 INFO:     Epoch: 38
2022-11-22 23:43:54,784 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8337885168465701, 'Total loss': 0.8337885168465701} | train loss {'Reaction outcome loss': 0.8131221060850182, 'Total loss': 0.8131221060850182}
2022-11-22 23:43:54,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:54,785 INFO:     Epoch: 39
2022-11-22 23:43:55,583 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.832060465758497, 'Total loss': 0.832060465758497} | train loss {'Reaction outcome loss': 0.8089792448647168, 'Total loss': 0.8089792448647168}
2022-11-22 23:43:55,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:55,583 INFO:     Epoch: 40
2022-11-22 23:43:56,377 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8083736998113719, 'Total loss': 0.8083736998113719} | train loss {'Reaction outcome loss': 0.8130134752818516, 'Total loss': 0.8130134752818516}
2022-11-22 23:43:56,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:56,377 INFO:     Epoch: 41
2022-11-22 23:43:57,200 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8264912228015336, 'Total loss': 0.8264912228015336} | train loss {'Reaction outcome loss': 0.8144045519585512, 'Total loss': 0.8144045519585512}
2022-11-22 23:43:57,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:57,200 INFO:     Epoch: 42
2022-11-22 23:43:58,005 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8266189260916277, 'Total loss': 0.8266189260916277} | train loss {'Reaction outcome loss': 0.8098623590809958, 'Total loss': 0.8098623590809958}
2022-11-22 23:43:58,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:58,005 INFO:     Epoch: 43
2022-11-22 23:43:58,797 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8345630196007815, 'Total loss': 0.8345630196007815} | train loss {'Reaction outcome loss': 0.8162337085422204, 'Total loss': 0.8162337085422204}
2022-11-22 23:43:58,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:58,797 INFO:     Epoch: 44
2022-11-22 23:43:59,597 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8260068961165168, 'Total loss': 0.8260068961165168} | train loss {'Reaction outcome loss': 0.8101079619660669, 'Total loss': 0.8101079619660669}
2022-11-22 23:43:59,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:43:59,598 INFO:     Epoch: 45
2022-11-22 23:44:00,419 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8302575756203044, 'Total loss': 0.8302575756203044} | train loss {'Reaction outcome loss': 0.8154154522078377, 'Total loss': 0.8154154522078377}
2022-11-22 23:44:00,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:00,420 INFO:     Epoch: 46
2022-11-22 23:44:01,279 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8340191543102264, 'Total loss': 0.8340191543102264} | train loss {'Reaction outcome loss': 0.8138086314104042, 'Total loss': 0.8138086314104042}
2022-11-22 23:44:01,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:01,280 INFO:     Epoch: 47
2022-11-22 23:44:02,060 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8202260461720553, 'Total loss': 0.8202260461720553} | train loss {'Reaction outcome loss': 0.8154789988483702, 'Total loss': 0.8154789988483702}
2022-11-22 23:44:02,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:02,060 INFO:     Epoch: 48
2022-11-22 23:44:02,792 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8254518546164036, 'Total loss': 0.8254518546164036} | train loss {'Reaction outcome loss': 0.8130054335204923, 'Total loss': 0.8130054335204923}
2022-11-22 23:44:02,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:02,792 INFO:     Epoch: 49
2022-11-22 23:44:03,619 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8354914445768703, 'Total loss': 0.8354914445768703} | train loss {'Reaction outcome loss': 0.8153540893476836, 'Total loss': 0.8153540893476836}
2022-11-22 23:44:03,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:03,620 INFO:     Epoch: 50
2022-11-22 23:44:04,386 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8179417320273139, 'Total loss': 0.8179417320273139} | train loss {'Reaction outcome loss': 0.8168009299404767, 'Total loss': 0.8168009299404767}
2022-11-22 23:44:04,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:04,386 INFO:     Epoch: 51
2022-11-22 23:44:05,178 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8400642854923551, 'Total loss': 0.8400642854923551} | train loss {'Reaction outcome loss': 0.8092983092580522, 'Total loss': 0.8092983092580522}
2022-11-22 23:44:05,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:05,178 INFO:     Epoch: 52
2022-11-22 23:44:05,976 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8346396935257044, 'Total loss': 0.8346396935257044} | train loss {'Reaction outcome loss': 0.8092410104615347, 'Total loss': 0.8092410104615347}
2022-11-22 23:44:05,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:05,976 INFO:     Epoch: 53
2022-11-22 23:44:06,788 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8508407602255995, 'Total loss': 0.8508407602255995} | train loss {'Reaction outcome loss': 0.8125527321075906, 'Total loss': 0.8125527321075906}
2022-11-22 23:44:06,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:06,789 INFO:     Epoch: 54
2022-11-22 23:44:07,579 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8196031877940352, 'Total loss': 0.8196031877940352} | train loss {'Reaction outcome loss': 0.8143440609075585, 'Total loss': 0.8143440609075585}
2022-11-22 23:44:07,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:07,580 INFO:     Epoch: 55
2022-11-22 23:44:08,345 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8248965807936408, 'Total loss': 0.8248965807936408} | train loss {'Reaction outcome loss': 0.8112688655755957, 'Total loss': 0.8112688655755957}
2022-11-22 23:44:08,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:08,346 INFO:     Epoch: 56
2022-11-22 23:44:09,144 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8385299471291628, 'Total loss': 0.8385299471291628} | train loss {'Reaction outcome loss': 0.8122648824234397, 'Total loss': 0.8122648824234397}
2022-11-22 23:44:09,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:09,144 INFO:     Epoch: 57
2022-11-22 23:44:09,977 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8347052945332094, 'Total loss': 0.8347052945332094} | train loss {'Reaction outcome loss': 0.8185303334070712, 'Total loss': 0.8185303334070712}
2022-11-22 23:44:09,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:09,977 INFO:     Epoch: 58
2022-11-22 23:44:10,772 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8333780257539316, 'Total loss': 0.8333780257539316} | train loss {'Reaction outcome loss': 0.8118593571137409, 'Total loss': 0.8118593571137409}
2022-11-22 23:44:10,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:10,773 INFO:     Epoch: 59
2022-11-22 23:44:11,576 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8492773947390643, 'Total loss': 0.8492773947390643} | train loss {'Reaction outcome loss': 0.812355313617356, 'Total loss': 0.812355313617356}
2022-11-22 23:44:11,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:11,576 INFO:     Epoch: 60
2022-11-22 23:44:12,405 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8207867734811523, 'Total loss': 0.8207867734811523} | train loss {'Reaction outcome loss': 0.8134413883394125, 'Total loss': 0.8134413883394125}
2022-11-22 23:44:12,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:12,405 INFO:     Epoch: 61
2022-11-22 23:44:13,209 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8256354189731858, 'Total loss': 0.8256354189731858} | train loss {'Reaction outcome loss': 0.8120279133319854, 'Total loss': 0.8120279133319854}
2022-11-22 23:44:13,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:13,209 INFO:     Epoch: 62
2022-11-22 23:44:14,040 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.815657152370973, 'Total loss': 0.815657152370973} | train loss {'Reaction outcome loss': 0.8100333144470137, 'Total loss': 0.8100333144470137}
2022-11-22 23:44:14,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:14,040 INFO:     Epoch: 63
2022-11-22 23:44:14,865 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8348690880970522, 'Total loss': 0.8348690880970522} | train loss {'Reaction outcome loss': 0.817608071103388, 'Total loss': 0.817608071103388}
2022-11-22 23:44:14,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:14,865 INFO:     Epoch: 64
2022-11-22 23:44:15,659 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8258682773871855, 'Total loss': 0.8258682773871855} | train loss {'Reaction outcome loss': 0.8127545922386403, 'Total loss': 0.8127545922386403}
2022-11-22 23:44:15,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:15,659 INFO:     Epoch: 65
2022-11-22 23:44:16,430 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8117671392180703, 'Total loss': 0.8117671392180703} | train loss {'Reaction outcome loss': 0.8126106560230255, 'Total loss': 0.8126106560230255}
2022-11-22 23:44:16,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:16,430 INFO:     Epoch: 66
2022-11-22 23:44:17,223 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8157772435383364, 'Total loss': 0.8157772435383364} | train loss {'Reaction outcome loss': 0.816295791402155, 'Total loss': 0.816295791402155}
2022-11-22 23:44:17,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:17,223 INFO:     Epoch: 67
2022-11-22 23:44:17,994 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.847824789583683, 'Total loss': 0.847824789583683} | train loss {'Reaction outcome loss': 0.8118682903902871, 'Total loss': 0.8118682903902871}
2022-11-22 23:44:17,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:17,994 INFO:     Epoch: 68
2022-11-22 23:44:18,832 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8371304273605347, 'Total loss': 0.8371304273605347} | train loss {'Reaction outcome loss': 0.8125945062053447, 'Total loss': 0.8125945062053447}
2022-11-22 23:44:18,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:18,833 INFO:     Epoch: 69
2022-11-22 23:44:19,681 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8216025328094309, 'Total loss': 0.8216025328094309} | train loss {'Reaction outcome loss': 0.8142690556389945, 'Total loss': 0.8142690556389945}
2022-11-22 23:44:19,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:19,682 INFO:     Epoch: 70
2022-11-22 23:44:20,471 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8290989798578349, 'Total loss': 0.8290989798578349} | train loss {'Reaction outcome loss': 0.8100270447682362, 'Total loss': 0.8100270447682362}
2022-11-22 23:44:20,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:20,472 INFO:     Epoch: 71
2022-11-22 23:44:21,238 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8342903269962831, 'Total loss': 0.8342903269962831} | train loss {'Reaction outcome loss': 0.814555107939, 'Total loss': 0.814555107939}
2022-11-22 23:44:21,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:21,239 INFO:     Epoch: 72
2022-11-22 23:44:22,043 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.833698343146931, 'Total loss': 0.833698343146931} | train loss {'Reaction outcome loss': 0.8182359926554621, 'Total loss': 0.8182359926554621}
2022-11-22 23:44:22,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:22,043 INFO:     Epoch: 73
2022-11-22 23:44:22,817 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8261678164655512, 'Total loss': 0.8261678164655512} | train loss {'Reaction outcome loss': 0.8136538155224858, 'Total loss': 0.8136538155224858}
2022-11-22 23:44:22,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:22,817 INFO:     Epoch: 74
2022-11-22 23:44:23,646 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8260801556435499, 'Total loss': 0.8260801556435499} | train loss {'Reaction outcome loss': 0.813223489693233, 'Total loss': 0.813223489693233}
2022-11-22 23:44:23,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:23,646 INFO:     Epoch: 75
2022-11-22 23:44:24,440 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8531646884300492, 'Total loss': 0.8531646884300492} | train loss {'Reaction outcome loss': 0.8129560384215141, 'Total loss': 0.8129560384215141}
2022-11-22 23:44:24,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:24,441 INFO:     Epoch: 76
2022-11-22 23:44:25,219 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8243762071837079, 'Total loss': 0.8243762071837079} | train loss {'Reaction outcome loss': 0.8127596450095274, 'Total loss': 0.8127596450095274}
2022-11-22 23:44:25,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:25,219 INFO:     Epoch: 77
2022-11-22 23:44:25,997 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8326259749856862, 'Total loss': 0.8326259749856862} | train loss {'Reaction outcome loss': 0.8139332570591752, 'Total loss': 0.8139332570591752}
2022-11-22 23:44:25,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:25,998 INFO:     Epoch: 78
2022-11-22 23:44:26,813 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8155606734481725, 'Total loss': 0.8155606734481725} | train loss {'Reaction outcome loss': 0.8138318487576076, 'Total loss': 0.8138318487576076}
2022-11-22 23:44:26,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:26,814 INFO:     Epoch: 79
2022-11-22 23:44:27,632 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8331722129474987, 'Total loss': 0.8331722129474987} | train loss {'Reaction outcome loss': 0.8122451602196207, 'Total loss': 0.8122451602196207}
2022-11-22 23:44:27,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:27,633 INFO:     Epoch: 80
2022-11-22 23:44:28,403 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8362888402559541, 'Total loss': 0.8362888402559541} | train loss {'Reaction outcome loss': 0.8171471266113982, 'Total loss': 0.8171471266113982}
2022-11-22 23:44:28,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:28,403 INFO:     Epoch: 81
2022-11-22 23:44:29,220 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8078374591740695, 'Total loss': 0.8078374591740695} | train loss {'Reaction outcome loss': 0.8159923304100426, 'Total loss': 0.8159923304100426}
2022-11-22 23:44:29,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:29,221 INFO:     Epoch: 82
2022-11-22 23:44:30,018 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8362254100767049, 'Total loss': 0.8362254100767049} | train loss {'Reaction outcome loss': 0.8119125367427359, 'Total loss': 0.8119125367427359}
2022-11-22 23:44:30,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:30,018 INFO:     Epoch: 83
2022-11-22 23:44:30,809 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.834929193962704, 'Total loss': 0.834929193962704} | train loss {'Reaction outcome loss': 0.8184811399907482, 'Total loss': 0.8184811399907482}
2022-11-22 23:44:30,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:30,809 INFO:     Epoch: 84
2022-11-22 23:44:31,604 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8516205210577358, 'Total loss': 0.8516205210577358} | train loss {'Reaction outcome loss': 0.8143503455483183, 'Total loss': 0.8143503455483183}
2022-11-22 23:44:31,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:31,606 INFO:     Epoch: 85
2022-11-22 23:44:32,430 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8159528523683548, 'Total loss': 0.8159528523683548} | train loss {'Reaction outcome loss': 0.8163912072473642, 'Total loss': 0.8163912072473642}
2022-11-22 23:44:32,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:32,431 INFO:     Epoch: 86
2022-11-22 23:44:33,250 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8275841271335428, 'Total loss': 0.8275841271335428} | train loss {'Reaction outcome loss': 0.813764326791374, 'Total loss': 0.813764326791374}
2022-11-22 23:44:33,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:33,250 INFO:     Epoch: 87
2022-11-22 23:44:34,096 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8330995020541277, 'Total loss': 0.8330995020541277} | train loss {'Reaction outcome loss': 0.8142776452765172, 'Total loss': 0.8142776452765172}
2022-11-22 23:44:34,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:34,096 INFO:     Epoch: 88
2022-11-22 23:44:34,939 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8296572484753348, 'Total loss': 0.8296572484753348} | train loss {'Reaction outcome loss': 0.8148375962461744, 'Total loss': 0.8148375962461744}
2022-11-22 23:44:34,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:34,939 INFO:     Epoch: 89
2022-11-22 23:44:35,718 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8115490139885382, 'Total loss': 0.8115490139885382} | train loss {'Reaction outcome loss': 0.8116139499508604, 'Total loss': 0.8116139499508604}
2022-11-22 23:44:35,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:35,718 INFO:     Epoch: 90
2022-11-22 23:44:36,541 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8198352347720753, 'Total loss': 0.8198352347720753} | train loss {'Reaction outcome loss': 0.8173126937175283, 'Total loss': 0.8173126937175283}
2022-11-22 23:44:36,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:36,541 INFO:     Epoch: 91
2022-11-22 23:44:37,343 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8931203145872463, 'Total loss': 0.8931203145872463} | train loss {'Reaction outcome loss': 0.8069073295106693, 'Total loss': 0.8069073295106693}
2022-11-22 23:44:37,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:37,344 INFO:     Epoch: 92
2022-11-22 23:44:38,206 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8177886456251144, 'Total loss': 0.8177886456251144} | train loss {'Reaction outcome loss': 0.8107401072978974, 'Total loss': 0.8107401072978974}
2022-11-22 23:44:38,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:38,207 INFO:     Epoch: 93
2022-11-22 23:44:39,070 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8451464961875569, 'Total loss': 0.8451464961875569} | train loss {'Reaction outcome loss': 0.8154603703897827, 'Total loss': 0.8154603703897827}
2022-11-22 23:44:39,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:39,070 INFO:     Epoch: 94
2022-11-22 23:44:39,938 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8538476235487245, 'Total loss': 0.8538476235487245} | train loss {'Reaction outcome loss': 0.8142583552671938, 'Total loss': 0.8142583552671938}
2022-11-22 23:44:39,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:39,938 INFO:     Epoch: 95
2022-11-22 23:44:40,712 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8217335339974273, 'Total loss': 0.8217335339974273} | train loss {'Reaction outcome loss': 0.812596805971496, 'Total loss': 0.812596805971496}
2022-11-22 23:44:40,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:40,712 INFO:     Epoch: 96
2022-11-22 23:44:41,504 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8291894813830202, 'Total loss': 0.8291894813830202} | train loss {'Reaction outcome loss': 0.8111500640304721, 'Total loss': 0.8111500640304721}
2022-11-22 23:44:41,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:41,504 INFO:     Epoch: 97
2022-11-22 23:44:42,292 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8353764333508231, 'Total loss': 0.8353764333508231} | train loss {'Reaction outcome loss': 0.8115588557963469, 'Total loss': 0.8115588557963469}
2022-11-22 23:44:42,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:42,292 INFO:     Epoch: 98
2022-11-22 23:44:43,100 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8191651810299266, 'Total loss': 0.8191651810299266} | train loss {'Reaction outcome loss': 0.8202707227395505, 'Total loss': 0.8202707227395505}
2022-11-22 23:44:43,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:43,101 INFO:     Epoch: 99
2022-11-22 23:44:43,935 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8395305086265911, 'Total loss': 0.8395305086265911} | train loss {'Reaction outcome loss': 0.811002857222849, 'Total loss': 0.811002857222849}
2022-11-22 23:44:43,935 INFO:     Best model found after epoch 34 of 100.
2022-11-22 23:44:43,935 INFO:   Done with stage: TRAINING
2022-11-22 23:44:43,935 INFO:   Starting stage: EVALUATION
2022-11-22 23:44:44,068 INFO:   Done with stage: EVALUATION
2022-11-22 23:44:44,069 INFO:   Leaving out SEQ value Fold_5
2022-11-22 23:44:44,082 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:44:44,082 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:44:44,747 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:44:44,748 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:44:44,818 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:44:44,818 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:44:44,818 INFO:     No hyperparam tuning for this model
2022-11-22 23:44:44,818 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:44:44,818 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:44:44,819 INFO:     None feature selector for col prot
2022-11-22 23:44:44,819 INFO:     None feature selector for col prot
2022-11-22 23:44:44,819 INFO:     None feature selector for col prot
2022-11-22 23:44:44,820 INFO:     None feature selector for col chem
2022-11-22 23:44:44,820 INFO:     None feature selector for col chem
2022-11-22 23:44:44,820 INFO:     None feature selector for col chem
2022-11-22 23:44:44,820 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:44:44,820 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:44:44,821 INFO:     Number of params in model 168571
2022-11-22 23:44:44,825 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:44:44,825 INFO:   Starting stage: TRAINING
2022-11-22 23:44:44,882 INFO:     Val loss before train {'Reaction outcome loss': 1.062399146231738, 'Total loss': 1.062399146231738}
2022-11-22 23:44:44,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:44,883 INFO:     Epoch: 0
2022-11-22 23:44:45,668 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8969654806635596, 'Total loss': 0.8969654806635596} | train loss {'Reaction outcome loss': 0.8805996880598879, 'Total loss': 0.8805996880598879}
2022-11-22 23:44:45,668 INFO:     Found new best model at epoch 0
2022-11-22 23:44:45,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:45,669 INFO:     Epoch: 1
2022-11-22 23:44:46,480 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8928657580505718, 'Total loss': 0.8928657580505718} | train loss {'Reaction outcome loss': 0.837671650445413, 'Total loss': 0.837671650445413}
2022-11-22 23:44:46,480 INFO:     Found new best model at epoch 1
2022-11-22 23:44:46,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:46,481 INFO:     Epoch: 2
2022-11-22 23:44:47,290 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8821227110245011, 'Total loss': 0.8821227110245011} | train loss {'Reaction outcome loss': 0.8331637331831311, 'Total loss': 0.8331637331831311}
2022-11-22 23:44:47,290 INFO:     Found new best model at epoch 2
2022-11-22 23:44:47,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:47,291 INFO:     Epoch: 3
2022-11-22 23:44:48,120 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.9303538054227829, 'Total loss': 0.9303538054227829} | train loss {'Reaction outcome loss': 0.8250124688573212, 'Total loss': 0.8250124688573212}
2022-11-22 23:44:48,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:48,120 INFO:     Epoch: 4
2022-11-22 23:44:48,917 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8605974899096922, 'Total loss': 0.8605974899096922} | train loss {'Reaction outcome loss': 0.8312083308995977, 'Total loss': 0.8312083308995977}
2022-11-22 23:44:48,917 INFO:     Found new best model at epoch 4
2022-11-22 23:44:48,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:48,918 INFO:     Epoch: 5
2022-11-22 23:44:49,780 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.9017023728652434, 'Total loss': 0.9017023728652434} | train loss {'Reaction outcome loss': 0.8248757764636746, 'Total loss': 0.8248757764636746}
2022-11-22 23:44:49,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:49,780 INFO:     Epoch: 6
2022-11-22 23:44:50,616 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8560764450918544, 'Total loss': 0.8560764450918544} | train loss {'Reaction outcome loss': 0.8235147113983448, 'Total loss': 0.8235147113983448}
2022-11-22 23:44:50,617 INFO:     Found new best model at epoch 6
2022-11-22 23:44:50,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:50,618 INFO:     Epoch: 7
2022-11-22 23:44:51,423 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8609411232173443, 'Total loss': 0.8609411232173443} | train loss {'Reaction outcome loss': 0.8257933330198048, 'Total loss': 0.8257933330198048}
2022-11-22 23:44:51,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:51,424 INFO:     Epoch: 8
2022-11-22 23:44:52,231 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8493550900708545, 'Total loss': 0.8493550900708545} | train loss {'Reaction outcome loss': 0.8252635444948065, 'Total loss': 0.8252635444948065}
2022-11-22 23:44:52,231 INFO:     Found new best model at epoch 8
2022-11-22 23:44:52,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:52,232 INFO:     Epoch: 9
2022-11-22 23:44:53,049 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8751376162875782, 'Total loss': 0.8751376162875782} | train loss {'Reaction outcome loss': 0.8111557482104552, 'Total loss': 0.8111557482104552}
2022-11-22 23:44:53,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:53,049 INFO:     Epoch: 10
2022-11-22 23:44:53,896 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.858169668100097, 'Total loss': 0.858169668100097} | train loss {'Reaction outcome loss': 0.8185727685569268, 'Total loss': 0.8185727685569268}
2022-11-22 23:44:53,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:53,896 INFO:     Epoch: 11
2022-11-22 23:44:54,675 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8519537381150506, 'Total loss': 0.8519537381150506} | train loss {'Reaction outcome loss': 0.8165862072213941, 'Total loss': 0.8165862072213941}
2022-11-22 23:44:54,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:54,676 INFO:     Epoch: 12
2022-11-22 23:44:55,518 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8684574284336783, 'Total loss': 0.8684574284336783} | train loss {'Reaction outcome loss': 0.816349041486076, 'Total loss': 0.816349041486076}
2022-11-22 23:44:55,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:55,518 INFO:     Epoch: 13
2022-11-22 23:44:56,336 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8610519387505271, 'Total loss': 0.8610519387505271} | train loss {'Reaction outcome loss': 0.8251212458861502, 'Total loss': 0.8251212458861502}
2022-11-22 23:44:56,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:56,337 INFO:     Epoch: 14
2022-11-22 23:44:57,154 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8482274413108826, 'Total loss': 0.8482274413108826} | train loss {'Reaction outcome loss': 0.8132949001212352, 'Total loss': 0.8132949001212352}
2022-11-22 23:44:57,154 INFO:     Found new best model at epoch 14
2022-11-22 23:44:57,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:57,155 INFO:     Epoch: 15
2022-11-22 23:44:57,965 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8584163967858661, 'Total loss': 0.8584163967858661} | train loss {'Reaction outcome loss': 0.82050116511009, 'Total loss': 0.82050116511009}
2022-11-22 23:44:57,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:57,965 INFO:     Epoch: 16
2022-11-22 23:44:58,742 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8478010323914614, 'Total loss': 0.8478010323914614} | train loss {'Reaction outcome loss': 0.8169559818289058, 'Total loss': 0.8169559818289058}
2022-11-22 23:44:58,742 INFO:     Found new best model at epoch 16
2022-11-22 23:44:58,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:58,743 INFO:     Epoch: 17
2022-11-22 23:44:59,520 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8504907834258947, 'Total loss': 0.8504907834258947} | train loss {'Reaction outcome loss': 0.8118409378084577, 'Total loss': 0.8118409378084577}
2022-11-22 23:44:59,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:44:59,520 INFO:     Epoch: 18
2022-11-22 23:45:00,300 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8497340150854804, 'Total loss': 0.8497340150854804} | train loss {'Reaction outcome loss': 0.8139213972728745, 'Total loss': 0.8139213972728745}
2022-11-22 23:45:00,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:00,300 INFO:     Epoch: 19
2022-11-22 23:45:01,095 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8682285357605327, 'Total loss': 0.8682285357605327} | train loss {'Reaction outcome loss': 0.8196179530157252, 'Total loss': 0.8196179530157252}
2022-11-22 23:45:01,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:01,096 INFO:     Epoch: 20
2022-11-22 23:45:01,895 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8705223609100688, 'Total loss': 0.8705223609100688} | train loss {'Reaction outcome loss': 0.8194940966150539, 'Total loss': 0.8194940966150539}
2022-11-22 23:45:01,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:01,895 INFO:     Epoch: 21
2022-11-22 23:45:02,731 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8571384928443215, 'Total loss': 0.8571384928443215} | train loss {'Reaction outcome loss': 0.8095054902392722, 'Total loss': 0.8095054902392722}
2022-11-22 23:45:02,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:02,732 INFO:     Epoch: 22
2022-11-22 23:45:03,528 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8510686213319952, 'Total loss': 0.8510686213319952} | train loss {'Reaction outcome loss': 0.8102639383873959, 'Total loss': 0.8102639383873959}
2022-11-22 23:45:03,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:03,528 INFO:     Epoch: 23
2022-11-22 23:45:04,309 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8635014661333777, 'Total loss': 0.8635014661333777} | train loss {'Reaction outcome loss': 0.814767721331554, 'Total loss': 0.814767721331554}
2022-11-22 23:45:04,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:04,310 INFO:     Epoch: 24
2022-11-22 23:45:05,153 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8582155474207618, 'Total loss': 0.8582155474207618} | train loss {'Reaction outcome loss': 0.8210742587924968, 'Total loss': 0.8210742587924968}
2022-11-22 23:45:05,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:05,153 INFO:     Epoch: 25
2022-11-22 23:45:05,965 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8624613318930973, 'Total loss': 0.8624613318930973} | train loss {'Reaction outcome loss': 0.8094442667748764, 'Total loss': 0.8094442667748764}
2022-11-22 23:45:05,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:05,966 INFO:     Epoch: 26
2022-11-22 23:45:06,793 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8443179591135546, 'Total loss': 0.8443179591135546} | train loss {'Reaction outcome loss': 0.8184412343781969, 'Total loss': 0.8184412343781969}
2022-11-22 23:45:06,793 INFO:     Found new best model at epoch 26
2022-11-22 23:45:06,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:06,794 INFO:     Epoch: 27
2022-11-22 23:45:07,621 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8437368863008239, 'Total loss': 0.8437368863008239} | train loss {'Reaction outcome loss': 0.8132375350546258, 'Total loss': 0.8132375350546258}
2022-11-22 23:45:07,621 INFO:     Found new best model at epoch 27
2022-11-22 23:45:07,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:07,622 INFO:     Epoch: 28
2022-11-22 23:45:08,393 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8606069033796137, 'Total loss': 0.8606069033796137} | train loss {'Reaction outcome loss': 0.8115465893195226, 'Total loss': 0.8115465893195226}
2022-11-22 23:45:08,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:08,393 INFO:     Epoch: 29
2022-11-22 23:45:09,201 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8563649911772121, 'Total loss': 0.8563649911772121} | train loss {'Reaction outcome loss': 0.8113034478565941, 'Total loss': 0.8113034478565941}
2022-11-22 23:45:09,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:09,203 INFO:     Epoch: 30
2022-11-22 23:45:10,045 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8569475757804784, 'Total loss': 0.8569475757804784} | train loss {'Reaction outcome loss': 0.8111738047377783, 'Total loss': 0.8111738047377783}
2022-11-22 23:45:10,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:10,045 INFO:     Epoch: 31
2022-11-22 23:45:10,815 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8568990880792792, 'Total loss': 0.8568990880792792} | train loss {'Reaction outcome loss': 0.8181214951551877, 'Total loss': 0.8181214951551877}
2022-11-22 23:45:10,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:10,816 INFO:     Epoch: 32
2022-11-22 23:45:11,618 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8559606109153141, 'Total loss': 0.8559606109153141} | train loss {'Reaction outcome loss': 0.8110824395649829, 'Total loss': 0.8110824395649829}
2022-11-22 23:45:11,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:11,618 INFO:     Epoch: 33
2022-11-22 23:45:12,472 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8698137585412372, 'Total loss': 0.8698137585412372} | train loss {'Reaction outcome loss': 0.806947260582254, 'Total loss': 0.806947260582254}
2022-11-22 23:45:12,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:12,472 INFO:     Epoch: 34
2022-11-22 23:45:13,258 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8566267998381094, 'Total loss': 0.8566267998381094} | train loss {'Reaction outcome loss': 0.8124372576653716, 'Total loss': 0.8124372576653716}
2022-11-22 23:45:13,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:13,258 INFO:     Epoch: 35
2022-11-22 23:45:14,040 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8622198348695581, 'Total loss': 0.8622198348695581} | train loss {'Reaction outcome loss': 0.8111115970350953, 'Total loss': 0.8111115970350953}
2022-11-22 23:45:14,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:14,040 INFO:     Epoch: 36
2022-11-22 23:45:14,858 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8665377572178841, 'Total loss': 0.8665377572178841} | train loss {'Reaction outcome loss': 0.8058703742649874, 'Total loss': 0.8058703742649874}
2022-11-22 23:45:14,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:14,858 INFO:     Epoch: 37
2022-11-22 23:45:15,669 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8541812314228578, 'Total loss': 0.8541812314228578} | train loss {'Reaction outcome loss': 0.811481433841381, 'Total loss': 0.811481433841381}
2022-11-22 23:45:15,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:15,669 INFO:     Epoch: 38
2022-11-22 23:45:16,483 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8918689875440164, 'Total loss': 0.8918689875440164} | train loss {'Reaction outcome loss': 0.8107047753054121, 'Total loss': 0.8107047753054121}
2022-11-22 23:45:16,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:16,483 INFO:     Epoch: 39
2022-11-22 23:45:17,304 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8632473803379319, 'Total loss': 0.8632473803379319} | train loss {'Reaction outcome loss': 0.8108976686049086, 'Total loss': 0.8108976686049086}
2022-11-22 23:45:17,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:17,304 INFO:     Epoch: 40
2022-11-22 23:45:18,106 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8445951064879244, 'Total loss': 0.8445951064879244} | train loss {'Reaction outcome loss': 0.8126404134609438, 'Total loss': 0.8126404134609438}
2022-11-22 23:45:18,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:18,107 INFO:     Epoch: 41
2022-11-22 23:45:18,918 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8417013152079149, 'Total loss': 0.8417013152079149} | train loss {'Reaction outcome loss': 0.8115868265570899, 'Total loss': 0.8115868265570899}
2022-11-22 23:45:18,918 INFO:     Found new best model at epoch 41
2022-11-22 23:45:18,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:18,919 INFO:     Epoch: 42
2022-11-22 23:45:19,697 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8396517471833662, 'Total loss': 0.8396517471833662} | train loss {'Reaction outcome loss': 0.8099329809428226, 'Total loss': 0.8099329809428226}
2022-11-22 23:45:19,698 INFO:     Found new best model at epoch 42
2022-11-22 23:45:19,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:19,698 INFO:     Epoch: 43
2022-11-22 23:45:20,513 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8508470329371366, 'Total loss': 0.8508470329371366} | train loss {'Reaction outcome loss': 0.8082940289939222, 'Total loss': 0.8082940289939222}
2022-11-22 23:45:20,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:20,514 INFO:     Epoch: 44
2022-11-22 23:45:21,328 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8481117696924643, 'Total loss': 0.8481117696924643} | train loss {'Reaction outcome loss': 0.8165469953888341, 'Total loss': 0.8165469953888341}
2022-11-22 23:45:21,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:21,329 INFO:     Epoch: 45
2022-11-22 23:45:22,124 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8658789470791817, 'Total loss': 0.8658789470791817} | train loss {'Reaction outcome loss': 0.8062741314833947, 'Total loss': 0.8062741314833947}
2022-11-22 23:45:22,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:22,125 INFO:     Epoch: 46
2022-11-22 23:45:22,973 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.860824160955169, 'Total loss': 0.860824160955169} | train loss {'Reaction outcome loss': 0.8055712453387527, 'Total loss': 0.8055712453387527}
2022-11-22 23:45:22,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:22,974 INFO:     Epoch: 47
2022-11-22 23:45:23,812 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8732065084305677, 'Total loss': 0.8732065084305677} | train loss {'Reaction outcome loss': 0.8115405149546712, 'Total loss': 0.8115405149546712}
2022-11-22 23:45:23,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:23,812 INFO:     Epoch: 48
2022-11-22 23:45:24,659 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8533338376066901, 'Total loss': 0.8533338376066901} | train loss {'Reaction outcome loss': 0.8127317897945281, 'Total loss': 0.8127317897945281}
2022-11-22 23:45:24,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:24,659 INFO:     Epoch: 49
2022-11-22 23:45:25,490 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8668387877670202, 'Total loss': 0.8668387877670202} | train loss {'Reaction outcome loss': 0.8093806590266556, 'Total loss': 0.8093806590266556}
2022-11-22 23:45:25,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:25,490 INFO:     Epoch: 50
2022-11-22 23:45:26,293 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8468361232768405, 'Total loss': 0.8468361232768405} | train loss {'Reaction outcome loss': 0.8100294899120022, 'Total loss': 0.8100294899120022}
2022-11-22 23:45:26,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:26,293 INFO:     Epoch: 51
2022-11-22 23:45:27,080 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8724511191248894, 'Total loss': 0.8724511191248894} | train loss {'Reaction outcome loss': 0.8079129667417241, 'Total loss': 0.8079129667417241}
2022-11-22 23:45:27,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:27,080 INFO:     Epoch: 52
2022-11-22 23:45:27,906 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8673104359345003, 'Total loss': 0.8673104359345003} | train loss {'Reaction outcome loss': 0.8119211770322642, 'Total loss': 0.8119211770322642}
2022-11-22 23:45:27,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:27,906 INFO:     Epoch: 53
2022-11-22 23:45:28,713 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8615487664937973, 'Total loss': 0.8615487664937973} | train loss {'Reaction outcome loss': 0.813180755145154, 'Total loss': 0.813180755145154}
2022-11-22 23:45:28,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:28,713 INFO:     Epoch: 54
2022-11-22 23:45:29,519 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8728323043747381, 'Total loss': 0.8728323043747381} | train loss {'Reaction outcome loss': 0.8104641957562945, 'Total loss': 0.8104641957562945}
2022-11-22 23:45:29,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:29,519 INFO:     Epoch: 55
2022-11-22 23:45:30,300 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8686125352978706, 'Total loss': 0.8686125352978706} | train loss {'Reaction outcome loss': 0.8153296564272058, 'Total loss': 0.8153296564272058}
2022-11-22 23:45:30,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:30,301 INFO:     Epoch: 56
2022-11-22 23:45:31,096 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8788514773954045, 'Total loss': 0.8788514773954045} | train loss {'Reaction outcome loss': 0.8087904723549662, 'Total loss': 0.8087904723549662}
2022-11-22 23:45:31,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:31,097 INFO:     Epoch: 57
2022-11-22 23:45:31,882 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8414349196986719, 'Total loss': 0.8414349196986719} | train loss {'Reaction outcome loss': 0.8108689035722602, 'Total loss': 0.8108689035722602}
2022-11-22 23:45:31,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:31,882 INFO:     Epoch: 58
2022-11-22 23:45:32,660 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8605035597627814, 'Total loss': 0.8605035597627814} | train loss {'Reaction outcome loss': 0.8092707401586448, 'Total loss': 0.8092707401586448}
2022-11-22 23:45:32,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:32,660 INFO:     Epoch: 59
2022-11-22 23:45:33,450 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8550321602008559, 'Total loss': 0.8550321602008559} | train loss {'Reaction outcome loss': 0.8152787528539959, 'Total loss': 0.8152787528539959}
2022-11-22 23:45:33,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:33,451 INFO:     Epoch: 60
2022-11-22 23:45:34,289 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8711874999783256, 'Total loss': 0.8711874999783256} | train loss {'Reaction outcome loss': 0.804739665405953, 'Total loss': 0.804739665405953}
2022-11-22 23:45:34,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:34,289 INFO:     Epoch: 61
2022-11-22 23:45:35,075 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8500470959327437, 'Total loss': 0.8500470959327437} | train loss {'Reaction outcome loss': 0.8072463745469989, 'Total loss': 0.8072463745469989}
2022-11-22 23:45:35,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:35,075 INFO:     Epoch: 62
2022-11-22 23:45:35,851 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.924485832452774, 'Total loss': 0.924485832452774} | train loss {'Reaction outcome loss': 0.8086685728930268, 'Total loss': 0.8086685728930268}
2022-11-22 23:45:35,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:35,851 INFO:     Epoch: 63
2022-11-22 23:45:36,649 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8834781484170393, 'Total loss': 0.8834781484170393} | train loss {'Reaction outcome loss': 0.8156106671099721, 'Total loss': 0.8156106671099721}
2022-11-22 23:45:36,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:36,650 INFO:     Epoch: 64
2022-11-22 23:45:37,431 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8533038490197875, 'Total loss': 0.8533038490197875} | train loss {'Reaction outcome loss': 0.8164798012870526, 'Total loss': 0.8164798012870526}
2022-11-22 23:45:37,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:37,431 INFO:     Epoch: 65
2022-11-22 23:45:38,219 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8620375835082748, 'Total loss': 0.8620375835082748} | train loss {'Reaction outcome loss': 0.8102184328955677, 'Total loss': 0.8102184328955677}
2022-11-22 23:45:38,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:38,219 INFO:     Epoch: 66
2022-11-22 23:45:39,084 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8589382340962236, 'Total loss': 0.8589382340962236} | train loss {'Reaction outcome loss': 0.8084725082252431, 'Total loss': 0.8084725082252431}
2022-11-22 23:45:39,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:39,084 INFO:     Epoch: 67
2022-11-22 23:45:39,887 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8572800992564722, 'Total loss': 0.8572800992564722} | train loss {'Reaction outcome loss': 0.8068282332738884, 'Total loss': 0.8068282332738884}
2022-11-22 23:45:39,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:39,888 INFO:     Epoch: 68
2022-11-22 23:45:40,674 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8629575703631748, 'Total loss': 0.8629575703631748} | train loss {'Reaction outcome loss': 0.8197206486815866, 'Total loss': 0.8197206486815866}
2022-11-22 23:45:40,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:40,674 INFO:     Epoch: 69
2022-11-22 23:45:41,498 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8550059443170374, 'Total loss': 0.8550059443170374} | train loss {'Reaction outcome loss': 0.8224388589019235, 'Total loss': 0.8224388589019235}
2022-11-22 23:45:41,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:41,498 INFO:     Epoch: 70
2022-11-22 23:45:42,309 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8436983525753021, 'Total loss': 0.8436983525753021} | train loss {'Reaction outcome loss': 0.8170067583501097, 'Total loss': 0.8170067583501097}
2022-11-22 23:45:42,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:42,309 INFO:     Epoch: 71
2022-11-22 23:45:43,135 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8492515141313727, 'Total loss': 0.8492515141313727} | train loss {'Reaction outcome loss': 0.8097572121542957, 'Total loss': 0.8097572121542957}
2022-11-22 23:45:43,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:43,136 INFO:     Epoch: 72
2022-11-22 23:45:43,990 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8671709549697962, 'Total loss': 0.8671709549697962} | train loss {'Reaction outcome loss': 0.8074828845407316, 'Total loss': 0.8074828845407316}
2022-11-22 23:45:43,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:43,991 INFO:     Epoch: 73
2022-11-22 23:45:44,779 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8584760711951689, 'Total loss': 0.8584760711951689} | train loss {'Reaction outcome loss': 0.8120636575617771, 'Total loss': 0.8120636575617771}
2022-11-22 23:45:44,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:44,779 INFO:     Epoch: 74
2022-11-22 23:45:45,566 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.85459365086122, 'Total loss': 0.85459365086122} | train loss {'Reaction outcome loss': 0.8123147459889231, 'Total loss': 0.8123147459889231}
2022-11-22 23:45:45,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:45,566 INFO:     Epoch: 75
2022-11-22 23:45:46,376 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8355660909278826, 'Total loss': 0.8355660909278826} | train loss {'Reaction outcome loss': 0.8148953191604209, 'Total loss': 0.8148953191604209}
2022-11-22 23:45:46,376 INFO:     Found new best model at epoch 75
2022-11-22 23:45:46,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:46,377 INFO:     Epoch: 76
2022-11-22 23:45:47,183 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.87480267746882, 'Total loss': 0.87480267746882} | train loss {'Reaction outcome loss': 0.8125886706567487, 'Total loss': 0.8125886706567487}
2022-11-22 23:45:47,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:47,184 INFO:     Epoch: 77
2022-11-22 23:45:48,018 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.859324415976351, 'Total loss': 0.859324415976351} | train loss {'Reaction outcome loss': 0.8057618223824482, 'Total loss': 0.8057618223824482}
2022-11-22 23:45:48,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:48,019 INFO:     Epoch: 78
2022-11-22 23:45:48,838 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.839832799678499, 'Total loss': 0.839832799678499} | train loss {'Reaction outcome loss': 0.803682541678309, 'Total loss': 0.803682541678309}
2022-11-22 23:45:48,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:48,838 INFO:     Epoch: 79
2022-11-22 23:45:49,640 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8488735908811743, 'Total loss': 0.8488735908811743} | train loss {'Reaction outcome loss': 0.8036668433351555, 'Total loss': 0.8036668433351555}
2022-11-22 23:45:49,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:49,641 INFO:     Epoch: 80
2022-11-22 23:45:50,487 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8644941422072324, 'Total loss': 0.8644941422072324} | train loss {'Reaction outcome loss': 0.8085098602028511, 'Total loss': 0.8085098602028511}
2022-11-22 23:45:50,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:50,487 INFO:     Epoch: 81
2022-11-22 23:45:51,316 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8578636781735853, 'Total loss': 0.8578636781735853} | train loss {'Reaction outcome loss': 0.8224073035514307, 'Total loss': 0.8224073035514307}
2022-11-22 23:45:51,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:51,316 INFO:     Epoch: 82
2022-11-22 23:45:52,158 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8656911043958231, 'Total loss': 0.8656911043958231} | train loss {'Reaction outcome loss': 0.8225601666610733, 'Total loss': 0.8225601666610733}
2022-11-22 23:45:52,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:52,159 INFO:     Epoch: 83
2022-11-22 23:45:52,951 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8495734760707075, 'Total loss': 0.8495734760707075} | train loss {'Reaction outcome loss': 0.8126175209336918, 'Total loss': 0.8126175209336918}
2022-11-22 23:45:52,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:52,951 INFO:     Epoch: 84
2022-11-22 23:45:53,753 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8570688793605025, 'Total loss': 0.8570688793605025} | train loss {'Reaction outcome loss': 0.8082804158631607, 'Total loss': 0.8082804158631607}
2022-11-22 23:45:53,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:53,753 INFO:     Epoch: 85
2022-11-22 23:45:54,546 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8837056657807394, 'Total loss': 0.8837056657807394} | train loss {'Reaction outcome loss': 0.8077240173633282, 'Total loss': 0.8077240173633282}
2022-11-22 23:45:54,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:54,546 INFO:     Epoch: 86
2022-11-22 23:45:55,396 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8490284505215558, 'Total loss': 0.8490284505215558} | train loss {'Reaction outcome loss': 0.8068361786695627, 'Total loss': 0.8068361786695627}
2022-11-22 23:45:55,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:55,396 INFO:     Epoch: 87
2022-11-22 23:45:56,216 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8466158197684721, 'Total loss': 0.8466158197684721} | train loss {'Reaction outcome loss': 0.8063957268892512, 'Total loss': 0.8063957268892512}
2022-11-22 23:45:56,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:56,216 INFO:     Epoch: 88
2022-11-22 23:45:57,008 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8417200540954416, 'Total loss': 0.8417200540954416} | train loss {'Reaction outcome loss': 0.8100188654443996, 'Total loss': 0.8100188654443996}
2022-11-22 23:45:57,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:57,008 INFO:     Epoch: 89
2022-11-22 23:45:57,831 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8513483838601545, 'Total loss': 0.8513483838601545} | train loss {'Reaction outcome loss': 0.8110515957901835, 'Total loss': 0.8110515957901835}
2022-11-22 23:45:57,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:57,831 INFO:     Epoch: 90
2022-11-22 23:45:58,661 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8629545251076872, 'Total loss': 0.8629545251076872} | train loss {'Reaction outcome loss': 0.8080722529154557, 'Total loss': 0.8080722529154557}
2022-11-22 23:45:58,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:58,661 INFO:     Epoch: 91
2022-11-22 23:45:59,539 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.851874053478241, 'Total loss': 0.851874053478241} | train loss {'Reaction outcome loss': 0.8075016117711299, 'Total loss': 0.8075016117711299}
2022-11-22 23:45:59,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:45:59,540 INFO:     Epoch: 92
2022-11-22 23:46:00,447 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8705815984444185, 'Total loss': 0.8705815984444185} | train loss {'Reaction outcome loss': 0.8081144641044169, 'Total loss': 0.8081144641044169}
2022-11-22 23:46:00,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:00,448 INFO:     Epoch: 93
2022-11-22 23:46:01,357 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8544246012514288, 'Total loss': 0.8544246012514288} | train loss {'Reaction outcome loss': 0.8123081205827505, 'Total loss': 0.8123081205827505}
2022-11-22 23:46:01,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:01,357 INFO:     Epoch: 94
2022-11-22 23:46:02,271 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8438968942923979, 'Total loss': 0.8438968942923979} | train loss {'Reaction outcome loss': 0.8047655755691683, 'Total loss': 0.8047655755691683}
2022-11-22 23:46:02,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:02,271 INFO:     Epoch: 95
2022-11-22 23:46:03,119 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.844116976315325, 'Total loss': 0.844116976315325} | train loss {'Reaction outcome loss': 0.8077281629628981, 'Total loss': 0.8077281629628981}
2022-11-22 23:46:03,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:03,119 INFO:     Epoch: 96
2022-11-22 23:46:03,940 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8483690849759362, 'Total loss': 0.8483690849759362} | train loss {'Reaction outcome loss': 0.8045857555953114, 'Total loss': 0.8045857555953114}
2022-11-22 23:46:03,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:03,941 INFO:     Epoch: 97
2022-11-22 23:46:04,731 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.871407762169838, 'Total loss': 0.871407762169838} | train loss {'Reaction outcome loss': 0.81453133293009, 'Total loss': 0.81453133293009}
2022-11-22 23:46:04,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:04,731 INFO:     Epoch: 98
2022-11-22 23:46:05,533 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8631021095947786, 'Total loss': 0.8631021095947786} | train loss {'Reaction outcome loss': 0.8141379061980769, 'Total loss': 0.8141379061980769}
2022-11-22 23:46:05,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:05,534 INFO:     Epoch: 99
2022-11-22 23:46:06,362 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8555525107817217, 'Total loss': 0.8555525107817217} | train loss {'Reaction outcome loss': 0.8062250092927261, 'Total loss': 0.8062250092927261}
2022-11-22 23:46:06,363 INFO:     Best model found after epoch 76 of 100.
2022-11-22 23:46:06,363 INFO:   Done with stage: TRAINING
2022-11-22 23:46:06,363 INFO:   Starting stage: EVALUATION
2022-11-22 23:46:06,488 INFO:   Done with stage: EVALUATION
2022-11-22 23:46:06,488 INFO:   Leaving out SEQ value Fold_6
2022-11-22 23:46:06,502 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 23:46:06,502 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:46:07,174 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:46:07,174 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:46:07,244 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:46:07,244 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:46:07,245 INFO:     No hyperparam tuning for this model
2022-11-22 23:46:07,245 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:46:07,245 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:46:07,246 INFO:     None feature selector for col prot
2022-11-22 23:46:07,246 INFO:     None feature selector for col prot
2022-11-22 23:46:07,246 INFO:     None feature selector for col prot
2022-11-22 23:46:07,246 INFO:     None feature selector for col chem
2022-11-22 23:46:07,247 INFO:     None feature selector for col chem
2022-11-22 23:46:07,247 INFO:     None feature selector for col chem
2022-11-22 23:46:07,247 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:46:07,247 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:46:07,248 INFO:     Number of params in model 168571
2022-11-22 23:46:07,252 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:46:07,252 INFO:   Starting stage: TRAINING
2022-11-22 23:46:07,310 INFO:     Val loss before train {'Reaction outcome loss': 0.959590882062912, 'Total loss': 0.959590882062912}
2022-11-22 23:46:07,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:07,311 INFO:     Epoch: 0
2022-11-22 23:46:08,113 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8181162618777968, 'Total loss': 0.8181162618777968} | train loss {'Reaction outcome loss': 0.8785238698605569, 'Total loss': 0.8785238698605569}
2022-11-22 23:46:08,113 INFO:     Found new best model at epoch 0
2022-11-22 23:46:08,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:08,114 INFO:     Epoch: 1
2022-11-22 23:46:08,969 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8048436248844321, 'Total loss': 0.8048436248844321} | train loss {'Reaction outcome loss': 0.8543723396235897, 'Total loss': 0.8543723396235897}
2022-11-22 23:46:08,970 INFO:     Found new best model at epoch 1
2022-11-22 23:46:08,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:08,971 INFO:     Epoch: 2
2022-11-22 23:46:09,792 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8070597838271748, 'Total loss': 0.8070597838271748} | train loss {'Reaction outcome loss': 0.844006656158355, 'Total loss': 0.844006656158355}
2022-11-22 23:46:09,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:09,793 INFO:     Epoch: 3
2022-11-22 23:46:10,641 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8045649352398786, 'Total loss': 0.8045649352398786} | train loss {'Reaction outcome loss': 0.8453980576126806, 'Total loss': 0.8453980576126806}
2022-11-22 23:46:10,641 INFO:     Found new best model at epoch 3
2022-11-22 23:46:10,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:10,642 INFO:     Epoch: 4
2022-11-22 23:46:11,473 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7854892780834978, 'Total loss': 0.7854892780834978} | train loss {'Reaction outcome loss': 0.8369869541737341, 'Total loss': 0.8369869541737341}
2022-11-22 23:46:11,473 INFO:     Found new best model at epoch 4
2022-11-22 23:46:11,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:11,474 INFO:     Epoch: 5
2022-11-22 23:46:12,276 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7889698371291161, 'Total loss': 0.7889698371291161} | train loss {'Reaction outcome loss': 0.8327130565960561, 'Total loss': 0.8327130565960561}
2022-11-22 23:46:12,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:12,277 INFO:     Epoch: 6
2022-11-22 23:46:13,084 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8287661929022182, 'Total loss': 0.8287661929022182} | train loss {'Reaction outcome loss': 0.8281149572182086, 'Total loss': 0.8281149572182086}
2022-11-22 23:46:13,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:13,085 INFO:     Epoch: 7
2022-11-22 23:46:13,977 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7950769398700107, 'Total loss': 0.7950769398700107} | train loss {'Reaction outcome loss': 0.8264273995112988, 'Total loss': 0.8264273995112988}
2022-11-22 23:46:13,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:13,977 INFO:     Epoch: 8
2022-11-22 23:46:14,819 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7973343282938004, 'Total loss': 0.7973343282938004} | train loss {'Reaction outcome loss': 0.8262259694597414, 'Total loss': 0.8262259694597414}
2022-11-22 23:46:14,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:14,820 INFO:     Epoch: 9
2022-11-22 23:46:15,654 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7780141207304868, 'Total loss': 0.7780141207304868} | train loss {'Reaction outcome loss': 0.8286252001360539, 'Total loss': 0.8286252001360539}
2022-11-22 23:46:15,654 INFO:     Found new best model at epoch 9
2022-11-22 23:46:15,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:15,655 INFO:     Epoch: 10
2022-11-22 23:46:16,468 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7893902246247638, 'Total loss': 0.7893902246247638} | train loss {'Reaction outcome loss': 0.8229722951448732, 'Total loss': 0.8229722951448732}
2022-11-22 23:46:16,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:16,468 INFO:     Epoch: 11
2022-11-22 23:46:17,285 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7930648055943575, 'Total loss': 0.7930648055943575} | train loss {'Reaction outcome loss': 0.8171007376044027, 'Total loss': 0.8171007376044027}
2022-11-22 23:46:17,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:17,285 INFO:     Epoch: 12
2022-11-22 23:46:18,113 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8146427714011886, 'Total loss': 0.8146427714011886} | train loss {'Reaction outcome loss': 0.8226767636595234, 'Total loss': 0.8226767636595234}
2022-11-22 23:46:18,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:18,113 INFO:     Epoch: 13
2022-11-22 23:46:18,929 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7927215647968379, 'Total loss': 0.7927215647968379} | train loss {'Reaction outcome loss': 0.8226916125464824, 'Total loss': 0.8226916125464824}
2022-11-22 23:46:18,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:18,930 INFO:     Epoch: 14
2022-11-22 23:46:19,769 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7887654907324098, 'Total loss': 0.7887654907324098} | train loss {'Reaction outcome loss': 0.8177255395679704, 'Total loss': 0.8177255395679704}
2022-11-22 23:46:19,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:19,769 INFO:     Epoch: 15
2022-11-22 23:46:20,612 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7821525044061921, 'Total loss': 0.7821525044061921} | train loss {'Reaction outcome loss': 0.8171691888522717, 'Total loss': 0.8171691888522717}
2022-11-22 23:46:20,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:20,612 INFO:     Epoch: 16
2022-11-22 23:46:21,492 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.783687636256218, 'Total loss': 0.783687636256218} | train loss {'Reaction outcome loss': 0.8239383548498154, 'Total loss': 0.8239383548498154}
2022-11-22 23:46:21,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:21,492 INFO:     Epoch: 17
2022-11-22 23:46:22,327 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7959486842155457, 'Total loss': 0.7959486842155457} | train loss {'Reaction outcome loss': 0.8243906235983295, 'Total loss': 0.8243906235983295}
2022-11-22 23:46:22,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:22,327 INFO:     Epoch: 18
2022-11-22 23:46:23,167 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.791096293790774, 'Total loss': 0.791096293790774} | train loss {'Reaction outcome loss': 0.8202973091073574, 'Total loss': 0.8202973091073574}
2022-11-22 23:46:23,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:23,167 INFO:     Epoch: 19
2022-11-22 23:46:24,000 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7746198028326035, 'Total loss': 0.7746198028326035} | train loss {'Reaction outcome loss': 0.8156428197699208, 'Total loss': 0.8156428197699208}
2022-11-22 23:46:24,000 INFO:     Found new best model at epoch 19
2022-11-22 23:46:24,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:24,001 INFO:     Epoch: 20
2022-11-22 23:46:24,828 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7970811623063955, 'Total loss': 0.7970811623063955} | train loss {'Reaction outcome loss': 0.8195288228171487, 'Total loss': 0.8195288228171487}
2022-11-22 23:46:24,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:24,829 INFO:     Epoch: 21
2022-11-22 23:46:25,689 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7805594774809751, 'Total loss': 0.7805594774809751} | train loss {'Reaction outcome loss': 0.81677449807044, 'Total loss': 0.81677449807044}
2022-11-22 23:46:25,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:25,689 INFO:     Epoch: 22
2022-11-22 23:46:26,510 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7715954008427534, 'Total loss': 0.7715954008427534} | train loss {'Reaction outcome loss': 0.8173682153705628, 'Total loss': 0.8173682153705628}
2022-11-22 23:46:26,511 INFO:     Found new best model at epoch 22
2022-11-22 23:46:26,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:26,511 INFO:     Epoch: 23
2022-11-22 23:46:27,336 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7901497252962806, 'Total loss': 0.7901497252962806} | train loss {'Reaction outcome loss': 0.8183260489135019, 'Total loss': 0.8183260489135019}
2022-11-22 23:46:27,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:27,337 INFO:     Epoch: 24
2022-11-22 23:46:28,171 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7914970943873579, 'Total loss': 0.7914970943873579} | train loss {'Reaction outcome loss': 0.820066876108608, 'Total loss': 0.820066876108608}
2022-11-22 23:46:28,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:28,171 INFO:     Epoch: 25
2022-11-22 23:46:28,990 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7908500703898343, 'Total loss': 0.7908500703898343} | train loss {'Reaction outcome loss': 0.8145123083264597, 'Total loss': 0.8145123083264597}
2022-11-22 23:46:28,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:28,990 INFO:     Epoch: 26
2022-11-22 23:46:29,786 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7774099497632547, 'Total loss': 0.7774099497632547} | train loss {'Reaction outcome loss': 0.8177875012399689, 'Total loss': 0.8177875012399689}
2022-11-22 23:46:29,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:29,786 INFO:     Epoch: 27
2022-11-22 23:46:30,612 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7803937945176255, 'Total loss': 0.7803937945176255} | train loss {'Reaction outcome loss': 0.8197567536225242, 'Total loss': 0.8197567536225242}
2022-11-22 23:46:30,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:30,612 INFO:     Epoch: 28
2022-11-22 23:46:31,470 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7796168252825737, 'Total loss': 0.7796168252825737} | train loss {'Reaction outcome loss': 0.8170072941049453, 'Total loss': 0.8170072941049453}
2022-11-22 23:46:31,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:31,471 INFO:     Epoch: 29
2022-11-22 23:46:32,299 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7824051143093542, 'Total loss': 0.7824051143093542} | train loss {'Reaction outcome loss': 0.8219598117134264, 'Total loss': 0.8219598117134264}
2022-11-22 23:46:32,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:32,299 INFO:     Epoch: 30
2022-11-22 23:46:33,114 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.774518602273681, 'Total loss': 0.774518602273681} | train loss {'Reaction outcome loss': 0.8156408232546621, 'Total loss': 0.8156408232546621}
2022-11-22 23:46:33,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:33,114 INFO:     Epoch: 31
2022-11-22 23:46:33,915 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7802056053822691, 'Total loss': 0.7802056053822691} | train loss {'Reaction outcome loss': 0.8138900714055184, 'Total loss': 0.8138900714055184}
2022-11-22 23:46:33,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:33,916 INFO:     Epoch: 32
2022-11-22 23:46:34,691 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7851881804791364, 'Total loss': 0.7851881804791364} | train loss {'Reaction outcome loss': 0.8140739328678577, 'Total loss': 0.8140739328678577}
2022-11-22 23:46:34,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:34,691 INFO:     Epoch: 33
2022-11-22 23:46:35,526 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7772356928749518, 'Total loss': 0.7772356928749518} | train loss {'Reaction outcome loss': 0.8163599981175315, 'Total loss': 0.8163599981175315}
2022-11-22 23:46:35,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:35,526 INFO:     Epoch: 34
2022-11-22 23:46:36,357 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7805040038444779, 'Total loss': 0.7805040038444779} | train loss {'Reaction outcome loss': 0.8158993551567677, 'Total loss': 0.8158993551567677}
2022-11-22 23:46:36,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:36,358 INFO:     Epoch: 35
2022-11-22 23:46:37,197 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7865029153498736, 'Total loss': 0.7865029153498736} | train loss {'Reaction outcome loss': 0.8171817492092809, 'Total loss': 0.8171817492092809}
2022-11-22 23:46:37,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:37,197 INFO:     Epoch: 36
2022-11-22 23:46:38,031 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7769833315502513, 'Total loss': 0.7769833315502513} | train loss {'Reaction outcome loss': 0.8154237301599595, 'Total loss': 0.8154237301599595}
2022-11-22 23:46:38,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:38,031 INFO:     Epoch: 37
2022-11-22 23:46:38,840 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7947838861833919, 'Total loss': 0.7947838861833919} | train loss {'Reaction outcome loss': 0.8236270651461617, 'Total loss': 0.8236270651461617}
2022-11-22 23:46:38,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:38,840 INFO:     Epoch: 38
2022-11-22 23:46:39,643 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7680393159389496, 'Total loss': 0.7680393159389496} | train loss {'Reaction outcome loss': 0.8122514326485896, 'Total loss': 0.8122514326485896}
2022-11-22 23:46:39,643 INFO:     Found new best model at epoch 38
2022-11-22 23:46:39,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:39,644 INFO:     Epoch: 39
2022-11-22 23:46:40,494 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.773984586650675, 'Total loss': 0.773984586650675} | train loss {'Reaction outcome loss': 0.8144049437776688, 'Total loss': 0.8144049437776688}
2022-11-22 23:46:40,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:40,494 INFO:     Epoch: 40
2022-11-22 23:46:41,341 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7846899750557813, 'Total loss': 0.7846899750557813} | train loss {'Reaction outcome loss': 0.8170741895033468, 'Total loss': 0.8170741895033468}
2022-11-22 23:46:41,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:41,341 INFO:     Epoch: 41
2022-11-22 23:46:42,194 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7813464552164078, 'Total loss': 0.7813464552164078} | train loss {'Reaction outcome loss': 0.8184494240389716, 'Total loss': 0.8184494240389716}
2022-11-22 23:46:42,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:42,195 INFO:     Epoch: 42
2022-11-22 23:46:43,009 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7901081375100396, 'Total loss': 0.7901081375100396} | train loss {'Reaction outcome loss': 0.8168586056318975, 'Total loss': 0.8168586056318975}
2022-11-22 23:46:43,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:43,010 INFO:     Epoch: 43
2022-11-22 23:46:43,862 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7925154715776443, 'Total loss': 0.7925154715776443} | train loss {'Reaction outcome loss': 0.8154470852065471, 'Total loss': 0.8154470852065471}
2022-11-22 23:46:43,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:43,862 INFO:     Epoch: 44
2022-11-22 23:46:44,719 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7959246147762645, 'Total loss': 0.7959246147762645} | train loss {'Reaction outcome loss': 0.8191556390975753, 'Total loss': 0.8191556390975753}
2022-11-22 23:46:44,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:44,720 INFO:     Epoch: 45
2022-11-22 23:46:45,566 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7851692986759272, 'Total loss': 0.7851692986759272} | train loss {'Reaction outcome loss': 0.8155674743315866, 'Total loss': 0.8155674743315866}
2022-11-22 23:46:45,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:45,566 INFO:     Epoch: 46
2022-11-22 23:46:46,391 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8143776492639021, 'Total loss': 0.8143776492639021} | train loss {'Reaction outcome loss': 0.8133127328849608, 'Total loss': 0.8133127328849608}
2022-11-22 23:46:46,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:46,392 INFO:     Epoch: 47
2022-11-22 23:46:47,259 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7797507711432197, 'Total loss': 0.7797507711432197} | train loss {'Reaction outcome loss': 0.8164639374421488, 'Total loss': 0.8164639374421488}
2022-11-22 23:46:47,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:47,259 INFO:     Epoch: 48
2022-11-22 23:46:48,072 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7761518975550478, 'Total loss': 0.7761518975550478} | train loss {'Reaction outcome loss': 0.8157239705324173, 'Total loss': 0.8157239705324173}
2022-11-22 23:46:48,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:48,072 INFO:     Epoch: 49
2022-11-22 23:46:48,915 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7873392403125763, 'Total loss': 0.7873392403125763} | train loss {'Reaction outcome loss': 0.815491437671646, 'Total loss': 0.815491437671646}
2022-11-22 23:46:48,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:48,915 INFO:     Epoch: 50
2022-11-22 23:46:49,777 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.773863709108396, 'Total loss': 0.773863709108396} | train loss {'Reaction outcome loss': 0.8118781813931081, 'Total loss': 0.8118781813931081}
2022-11-22 23:46:49,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:49,777 INFO:     Epoch: 51
2022-11-22 23:46:50,553 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7693640007214113, 'Total loss': 0.7693640007214113} | train loss {'Reaction outcome loss': 0.8210767268413498, 'Total loss': 0.8210767268413498}
2022-11-22 23:46:50,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:50,553 INFO:     Epoch: 52
2022-11-22 23:46:51,347 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7681810395284132, 'Total loss': 0.7681810395284132} | train loss {'Reaction outcome loss': 0.8143158680008303, 'Total loss': 0.8143158680008303}
2022-11-22 23:46:51,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:51,347 INFO:     Epoch: 53
2022-11-22 23:46:52,127 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7824647385965694, 'Total loss': 0.7824647385965694} | train loss {'Reaction outcome loss': 0.8153505002058321, 'Total loss': 0.8153505002058321}
2022-11-22 23:46:52,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:52,127 INFO:     Epoch: 54
2022-11-22 23:46:52,929 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7751005244525996, 'Total loss': 0.7751005244525996} | train loss {'Reaction outcome loss': 0.8154609014670695, 'Total loss': 0.8154609014670695}
2022-11-22 23:46:52,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:52,930 INFO:     Epoch: 55
2022-11-22 23:46:53,865 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7723873095078901, 'Total loss': 0.7723873095078901} | train loss {'Reaction outcome loss': 0.8143913707425517, 'Total loss': 0.8143913707425517}
2022-11-22 23:46:53,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:53,866 INFO:     Epoch: 56
2022-11-22 23:46:54,746 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7882301170717586, 'Total loss': 0.7882301170717586} | train loss {'Reaction outcome loss': 0.8177534834511818, 'Total loss': 0.8177534834511818}
2022-11-22 23:46:54,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:54,747 INFO:     Epoch: 57
2022-11-22 23:46:55,646 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7797275368462909, 'Total loss': 0.7797275368462909} | train loss {'Reaction outcome loss': 0.815195363856131, 'Total loss': 0.815195363856131}
2022-11-22 23:46:55,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:55,647 INFO:     Epoch: 58
2022-11-22 23:46:56,527 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.779854340986772, 'Total loss': 0.779854340986772} | train loss {'Reaction outcome loss': 0.8120854474123447, 'Total loss': 0.8120854474123447}
2022-11-22 23:46:56,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:56,527 INFO:     Epoch: 59
2022-11-22 23:46:57,423 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7761366441845894, 'Total loss': 0.7761366441845894} | train loss {'Reaction outcome loss': 0.8115281659749246, 'Total loss': 0.8115281659749246}
2022-11-22 23:46:57,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:57,423 INFO:     Epoch: 60
2022-11-22 23:46:58,287 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7793819308280945, 'Total loss': 0.7793819308280945} | train loss {'Reaction outcome loss': 0.8133827184717501, 'Total loss': 0.8133827184717501}
2022-11-22 23:46:58,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:58,287 INFO:     Epoch: 61
2022-11-22 23:46:59,195 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7678405906666409, 'Total loss': 0.7678405906666409} | train loss {'Reaction outcome loss': 0.8134314714660568, 'Total loss': 0.8134314714660568}
2022-11-22 23:46:59,195 INFO:     Found new best model at epoch 61
2022-11-22 23:46:59,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:46:59,196 INFO:     Epoch: 62
2022-11-22 23:47:00,112 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7777243249795653, 'Total loss': 0.7777243249795653} | train loss {'Reaction outcome loss': 0.8187400708275456, 'Total loss': 0.8187400708275456}
2022-11-22 23:47:00,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:00,112 INFO:     Epoch: 63
2022-11-22 23:47:01,089 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7685081823305651, 'Total loss': 0.7685081823305651} | train loss {'Reaction outcome loss': 0.8187387922117787, 'Total loss': 0.8187387922117787}
2022-11-22 23:47:01,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:01,089 INFO:     Epoch: 64
2022-11-22 23:47:02,015 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7669031829996542, 'Total loss': 0.7669031829996542} | train loss {'Reaction outcome loss': 0.8107557545506185, 'Total loss': 0.8107557545506185}
2022-11-22 23:47:02,015 INFO:     Found new best model at epoch 64
2022-11-22 23:47:02,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:02,016 INFO:     Epoch: 65
2022-11-22 23:47:02,898 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7936802669004961, 'Total loss': 0.7936802669004961} | train loss {'Reaction outcome loss': 0.8186290917858001, 'Total loss': 0.8186290917858001}
2022-11-22 23:47:02,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:02,899 INFO:     Epoch: 66
2022-11-22 23:47:03,815 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8156499842351134, 'Total loss': 0.8156499842351134} | train loss {'Reaction outcome loss': 0.8105443502145429, 'Total loss': 0.8105443502145429}
2022-11-22 23:47:03,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:03,815 INFO:     Epoch: 67
2022-11-22 23:47:04,741 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7920002856037833, 'Total loss': 0.7920002856037833} | train loss {'Reaction outcome loss': 0.8182203867022069, 'Total loss': 0.8182203867022069}
2022-11-22 23:47:04,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:04,741 INFO:     Epoch: 68
2022-11-22 23:47:05,668 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8037681335752661, 'Total loss': 0.8037681335752661} | train loss {'Reaction outcome loss': 0.8183325961712868, 'Total loss': 0.8183325961712868}
2022-11-22 23:47:05,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:05,669 INFO:     Epoch: 69
2022-11-22 23:47:06,578 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7922512611204927, 'Total loss': 0.7922512611204927} | train loss {'Reaction outcome loss': 0.8129458474295754, 'Total loss': 0.8129458474295754}
2022-11-22 23:47:06,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:06,579 INFO:     Epoch: 70
2022-11-22 23:47:07,526 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7820659943602302, 'Total loss': 0.7820659943602302} | train loss {'Reaction outcome loss': 0.813309945166111, 'Total loss': 0.813309945166111}
2022-11-22 23:47:07,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:07,528 INFO:     Epoch: 71
2022-11-22 23:47:08,490 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.762906472791325, 'Total loss': 0.762906472791325} | train loss {'Reaction outcome loss': 0.8158645205680402, 'Total loss': 0.8158645205680402}
2022-11-22 23:47:08,490 INFO:     Found new best model at epoch 71
2022-11-22 23:47:08,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:08,491 INFO:     Epoch: 72
2022-11-22 23:47:09,406 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7848760797218843, 'Total loss': 0.7848760797218843} | train loss {'Reaction outcome loss': 0.8163069997343325, 'Total loss': 0.8163069997343325}
2022-11-22 23:47:09,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:09,407 INFO:     Epoch: 73
2022-11-22 23:47:10,342 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7726250764998522, 'Total loss': 0.7726250764998522} | train loss {'Reaction outcome loss': 0.8227337449789047, 'Total loss': 0.8227337449789047}
2022-11-22 23:47:10,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:10,342 INFO:     Epoch: 74
2022-11-22 23:47:11,280 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7815519313920628, 'Total loss': 0.7815519313920628} | train loss {'Reaction outcome loss': 0.8145522102713585, 'Total loss': 0.8145522102713585}
2022-11-22 23:47:11,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:11,280 INFO:     Epoch: 75
2022-11-22 23:47:12,233 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7711697444319725, 'Total loss': 0.7711697444319725} | train loss {'Reaction outcome loss': 0.819256953895092, 'Total loss': 0.819256953895092}
2022-11-22 23:47:12,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:12,234 INFO:     Epoch: 76
2022-11-22 23:47:13,142 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7715934962034225, 'Total loss': 0.7715934962034225} | train loss {'Reaction outcome loss': 0.8127519610908723, 'Total loss': 0.8127519610908723}
2022-11-22 23:47:13,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:13,143 INFO:     Epoch: 77
2022-11-22 23:47:14,034 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8064867021007971, 'Total loss': 0.8064867021007971} | train loss {'Reaction outcome loss': 0.8151554465293884, 'Total loss': 0.8151554465293884}
2022-11-22 23:47:14,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:14,035 INFO:     Epoch: 78
2022-11-22 23:47:14,928 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7977799529379065, 'Total loss': 0.7977799529379065} | train loss {'Reaction outcome loss': 0.817120960162532, 'Total loss': 0.817120960162532}
2022-11-22 23:47:14,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:14,928 INFO:     Epoch: 79
2022-11-22 23:47:15,810 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7923843610015783, 'Total loss': 0.7923843610015783} | train loss {'Reaction outcome loss': 0.8125266473620169, 'Total loss': 0.8125266473620169}
2022-11-22 23:47:15,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:15,810 INFO:     Epoch: 80
2022-11-22 23:47:16,729 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7591810500757261, 'Total loss': 0.7591810500757261} | train loss {'Reaction outcome loss': 0.8140302109381845, 'Total loss': 0.8140302109381845}
2022-11-22 23:47:16,729 INFO:     Found new best model at epoch 80
2022-11-22 23:47:16,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:16,730 INFO:     Epoch: 81
2022-11-22 23:47:17,633 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.77739528702064, 'Total loss': 0.77739528702064} | train loss {'Reaction outcome loss': 0.815709070212418, 'Total loss': 0.815709070212418}
2022-11-22 23:47:17,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:17,633 INFO:     Epoch: 82
2022-11-22 23:47:18,536 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7694736678491939, 'Total loss': 0.7694736678491939} | train loss {'Reaction outcome loss': 0.8146983780447514, 'Total loss': 0.8146983780447514}
2022-11-22 23:47:18,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:18,536 INFO:     Epoch: 83
2022-11-22 23:47:19,442 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7758252864534204, 'Total loss': 0.7758252864534204} | train loss {'Reaction outcome loss': 0.8173045263655724, 'Total loss': 0.8173045263655724}
2022-11-22 23:47:19,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:19,442 INFO:     Epoch: 84
2022-11-22 23:47:20,364 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7820200683041052, 'Total loss': 0.7820200683041052} | train loss {'Reaction outcome loss': 0.8160323363638693, 'Total loss': 0.8160323363638693}
2022-11-22 23:47:20,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:20,364 INFO:     Epoch: 85
2022-11-22 23:47:21,236 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7668865302746947, 'Total loss': 0.7668865302746947} | train loss {'Reaction outcome loss': 0.8164024852937267, 'Total loss': 0.8164024852937267}
2022-11-22 23:47:21,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:21,236 INFO:     Epoch: 86
2022-11-22 23:47:22,186 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7788958447900686, 'Total loss': 0.7788958447900686} | train loss {'Reaction outcome loss': 0.8176035619070453, 'Total loss': 0.8176035619070453}
2022-11-22 23:47:22,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:22,187 INFO:     Epoch: 87
2022-11-22 23:47:23,106 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7777685692364519, 'Total loss': 0.7777685692364519} | train loss {'Reaction outcome loss': 0.8170221093441209, 'Total loss': 0.8170221093441209}
2022-11-22 23:47:23,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:23,106 INFO:     Epoch: 88
2022-11-22 23:47:24,016 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7848294749855995, 'Total loss': 0.7848294749855995} | train loss {'Reaction outcome loss': 0.8169435554694745, 'Total loss': 0.8169435554694745}
2022-11-22 23:47:24,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:24,017 INFO:     Epoch: 89
2022-11-22 23:47:24,916 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7799356992949139, 'Total loss': 0.7799356992949139} | train loss {'Reaction outcome loss': 0.8140629124977896, 'Total loss': 0.8140629124977896}
2022-11-22 23:47:24,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:24,916 INFO:     Epoch: 90
2022-11-22 23:47:25,872 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7888844494115222, 'Total loss': 0.7888844494115222} | train loss {'Reaction outcome loss': 0.8165535865531813, 'Total loss': 0.8165535865531813}
2022-11-22 23:47:25,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:25,872 INFO:     Epoch: 91
2022-11-22 23:47:26,782 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7929315052249215, 'Total loss': 0.7929315052249215} | train loss {'Reaction outcome loss': 0.8125511359783911, 'Total loss': 0.8125511359783911}
2022-11-22 23:47:26,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:26,783 INFO:     Epoch: 92
2022-11-22 23:47:27,694 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7865244231440804, 'Total loss': 0.7865244231440804} | train loss {'Reaction outcome loss': 0.8150758557021618, 'Total loss': 0.8150758557021618}
2022-11-22 23:47:27,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:27,694 INFO:     Epoch: 93
2022-11-22 23:47:28,523 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7781016806309874, 'Total loss': 0.7781016806309874} | train loss {'Reaction outcome loss': 0.8135789956056303, 'Total loss': 0.8135789956056303}
2022-11-22 23:47:28,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:28,524 INFO:     Epoch: 94
2022-11-22 23:47:29,430 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7888508682901209, 'Total loss': 0.7888508682901209} | train loss {'Reaction outcome loss': 0.8160672761019199, 'Total loss': 0.8160672761019199}
2022-11-22 23:47:29,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:29,430 INFO:     Epoch: 95
2022-11-22 23:47:30,361 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7732785459269177, 'Total loss': 0.7732785459269177} | train loss {'Reaction outcome loss': 0.816330339158735, 'Total loss': 0.816330339158735}
2022-11-22 23:47:30,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:30,362 INFO:     Epoch: 96
2022-11-22 23:47:31,260 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7894087162884799, 'Total loss': 0.7894087162884799} | train loss {'Reaction outcome loss': 0.8174318035523738, 'Total loss': 0.8174318035523738}
2022-11-22 23:47:31,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:31,261 INFO:     Epoch: 97
2022-11-22 23:47:32,134 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7779506106268276, 'Total loss': 0.7779506106268276} | train loss {'Reaction outcome loss': 0.8158768151075609, 'Total loss': 0.8158768151075609}
2022-11-22 23:47:32,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:32,134 INFO:     Epoch: 98
2022-11-22 23:47:33,044 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7829555584625765, 'Total loss': 0.7829555584625765} | train loss {'Reaction outcome loss': 0.8149014355674866, 'Total loss': 0.8149014355674866}
2022-11-22 23:47:33,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:33,044 INFO:     Epoch: 99
2022-11-22 23:47:33,945 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7862446789037097, 'Total loss': 0.7862446789037097} | train loss {'Reaction outcome loss': 0.8192250098912947, 'Total loss': 0.8192250098912947}
2022-11-22 23:47:33,945 INFO:     Best model found after epoch 81 of 100.
2022-11-22 23:47:33,945 INFO:   Done with stage: TRAINING
2022-11-22 23:47:33,945 INFO:   Starting stage: EVALUATION
2022-11-22 23:47:34,066 INFO:   Done with stage: EVALUATION
2022-11-22 23:47:34,066 INFO:   Leaving out SEQ value Fold_7
2022-11-22 23:47:34,079 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 23:47:34,079 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:47:34,764 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:47:34,764 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:47:34,839 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:47:34,839 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:47:34,839 INFO:     No hyperparam tuning for this model
2022-11-22 23:47:34,839 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:47:34,839 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:47:34,840 INFO:     None feature selector for col prot
2022-11-22 23:47:34,841 INFO:     None feature selector for col prot
2022-11-22 23:47:34,841 INFO:     None feature selector for col prot
2022-11-22 23:47:34,842 INFO:     None feature selector for col chem
2022-11-22 23:47:34,842 INFO:     None feature selector for col chem
2022-11-22 23:47:34,842 INFO:     None feature selector for col chem
2022-11-22 23:47:34,842 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:47:34,842 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:47:34,844 INFO:     Number of params in model 168571
2022-11-22 23:47:34,848 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:47:34,848 INFO:   Starting stage: TRAINING
2022-11-22 23:47:34,909 INFO:     Val loss before train {'Reaction outcome loss': 0.9920924590392546, 'Total loss': 0.9920924590392546}
2022-11-22 23:47:34,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:34,910 INFO:     Epoch: 0
2022-11-22 23:47:35,791 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8238532875071872, 'Total loss': 0.8238532875071872} | train loss {'Reaction outcome loss': 0.8700691812461422, 'Total loss': 0.8700691812461422}
2022-11-22 23:47:35,792 INFO:     Found new best model at epoch 0
2022-11-22 23:47:35,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:35,792 INFO:     Epoch: 1
2022-11-22 23:47:36,664 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8152437765489925, 'Total loss': 0.8152437765489925} | train loss {'Reaction outcome loss': 0.8337884342237827, 'Total loss': 0.8337884342237827}
2022-11-22 23:47:36,664 INFO:     Found new best model at epoch 1
2022-11-22 23:47:36,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:36,665 INFO:     Epoch: 2
2022-11-22 23:47:37,560 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8285403766415336, 'Total loss': 0.8285403766415336} | train loss {'Reaction outcome loss': 0.8231132950994277, 'Total loss': 0.8231132950994277}
2022-11-22 23:47:37,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:37,561 INFO:     Epoch: 3
2022-11-22 23:47:38,434 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.826265890489925, 'Total loss': 0.826265890489925} | train loss {'Reaction outcome loss': 0.8203976423509659, 'Total loss': 0.8203976423509659}
2022-11-22 23:47:38,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:38,434 INFO:     Epoch: 4
2022-11-22 23:47:39,334 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8277799405834891, 'Total loss': 0.8277799405834891} | train loss {'Reaction outcome loss': 0.8188657951691458, 'Total loss': 0.8188657951691458}
2022-11-22 23:47:39,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:39,335 INFO:     Epoch: 5
2022-11-22 23:47:40,207 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8090073175050996, 'Total loss': 0.8090073175050996} | train loss {'Reaction outcome loss': 0.8108276486877473, 'Total loss': 0.8108276486877473}
2022-11-22 23:47:40,207 INFO:     Found new best model at epoch 5
2022-11-22 23:47:40,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:40,208 INFO:     Epoch: 6
2022-11-22 23:47:41,100 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8009463782337579, 'Total loss': 0.8009463782337579} | train loss {'Reaction outcome loss': 0.8094747419799527, 'Total loss': 0.8094747419799527}
2022-11-22 23:47:41,100 INFO:     Found new best model at epoch 6
2022-11-22 23:47:41,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:41,101 INFO:     Epoch: 7
2022-11-22 23:47:41,995 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8093759153376926, 'Total loss': 0.8093759153376926} | train loss {'Reaction outcome loss': 0.8155487530654476, 'Total loss': 0.8155487530654476}
2022-11-22 23:47:41,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:41,996 INFO:     Epoch: 8
2022-11-22 23:47:42,899 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8182712007652629, 'Total loss': 0.8182712007652629} | train loss {'Reaction outcome loss': 0.8109477609395981, 'Total loss': 0.8109477609395981}
2022-11-22 23:47:42,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:42,899 INFO:     Epoch: 9
2022-11-22 23:47:43,853 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7963729649782181, 'Total loss': 0.7963729649782181} | train loss {'Reaction outcome loss': 0.8076642043888569, 'Total loss': 0.8076642043888569}
2022-11-22 23:47:43,854 INFO:     Found new best model at epoch 9
2022-11-22 23:47:43,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:43,856 INFO:     Epoch: 10
2022-11-22 23:47:44,758 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7917281484062021, 'Total loss': 0.7917281484062021} | train loss {'Reaction outcome loss': 0.8061247291343827, 'Total loss': 0.8061247291343827}
2022-11-22 23:47:44,758 INFO:     Found new best model at epoch 10
2022-11-22 23:47:44,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:44,759 INFO:     Epoch: 11
2022-11-22 23:47:45,607 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8036547641862523, 'Total loss': 0.8036547641862523} | train loss {'Reaction outcome loss': 0.8175583604362703, 'Total loss': 0.8175583604362703}
2022-11-22 23:47:45,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:45,607 INFO:     Epoch: 12
2022-11-22 23:47:46,537 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8072855174541473, 'Total loss': 0.8072855174541473} | train loss {'Reaction outcome loss': 0.8083423742603871, 'Total loss': 0.8083423742603871}
2022-11-22 23:47:46,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:46,538 INFO:     Epoch: 13
2022-11-22 23:47:47,446 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8088867515325546, 'Total loss': 0.8088867515325546} | train loss {'Reaction outcome loss': 0.8042024182936838, 'Total loss': 0.8042024182936838}
2022-11-22 23:47:47,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:47,446 INFO:     Epoch: 14
2022-11-22 23:47:48,353 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8028678433461622, 'Total loss': 0.8028678433461622} | train loss {'Reaction outcome loss': 0.8122708531877687, 'Total loss': 0.8122708531877687}
2022-11-22 23:47:48,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:48,353 INFO:     Epoch: 15
2022-11-22 23:47:49,277 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8103064691478555, 'Total loss': 0.8103064691478555} | train loss {'Reaction outcome loss': 0.8101333549186107, 'Total loss': 0.8101333549186107}
2022-11-22 23:47:49,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:49,277 INFO:     Epoch: 16
2022-11-22 23:47:50,185 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8068747574632819, 'Total loss': 0.8068747574632819} | train loss {'Reaction outcome loss': 0.8090293755935084, 'Total loss': 0.8090293755935084}
2022-11-22 23:47:50,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:50,185 INFO:     Epoch: 17
2022-11-22 23:47:51,060 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8033081462437456, 'Total loss': 0.8033081462437456} | train loss {'Reaction outcome loss': 0.8085929935257281, 'Total loss': 0.8085929935257281}
2022-11-22 23:47:51,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:51,060 INFO:     Epoch: 18
2022-11-22 23:47:51,912 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8078465062108907, 'Total loss': 0.8078465062108907} | train loss {'Reaction outcome loss': 0.8075919159718098, 'Total loss': 0.8075919159718098}
2022-11-22 23:47:51,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:51,912 INFO:     Epoch: 19
2022-11-22 23:47:52,794 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8142531554807316, 'Total loss': 0.8142531554807316} | train loss {'Reaction outcome loss': 0.806874172521695, 'Total loss': 0.806874172521695}
2022-11-22 23:47:52,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:52,795 INFO:     Epoch: 20
2022-11-22 23:47:53,690 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8005438006737016, 'Total loss': 0.8005438006737016} | train loss {'Reaction outcome loss': 0.8075883125345553, 'Total loss': 0.8075883125345553}
2022-11-22 23:47:53,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:53,690 INFO:     Epoch: 21
2022-11-22 23:47:54,514 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8069298727945848, 'Total loss': 0.8069298727945848} | train loss {'Reaction outcome loss': 0.8097141716749438, 'Total loss': 0.8097141716749438}
2022-11-22 23:47:54,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:54,514 INFO:     Epoch: 22
2022-11-22 23:47:55,382 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7922845398160544, 'Total loss': 0.7922845398160544} | train loss {'Reaction outcome loss': 0.8042441006870039, 'Total loss': 0.8042441006870039}
2022-11-22 23:47:55,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:55,382 INFO:     Epoch: 23
2022-11-22 23:47:56,236 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8119775917042386, 'Total loss': 0.8119775917042386} | train loss {'Reaction outcome loss': 0.8058735084149146, 'Total loss': 0.8058735084149146}
2022-11-22 23:47:56,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:56,238 INFO:     Epoch: 24
2022-11-22 23:47:57,084 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7942920042709871, 'Total loss': 0.7942920042709871} | train loss {'Reaction outcome loss': 0.804522309211954, 'Total loss': 0.804522309211954}
2022-11-22 23:47:57,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:57,084 INFO:     Epoch: 25
2022-11-22 23:47:57,945 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7945195880125869, 'Total loss': 0.7945195880125869} | train loss {'Reaction outcome loss': 0.8061562800599683, 'Total loss': 0.8061562800599683}
2022-11-22 23:47:57,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:57,945 INFO:     Epoch: 26
2022-11-22 23:47:58,852 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7993272881616246, 'Total loss': 0.7993272881616246} | train loss {'Reaction outcome loss': 0.8063936809137944, 'Total loss': 0.8063936809137944}
2022-11-22 23:47:58,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:58,852 INFO:     Epoch: 27
2022-11-22 23:47:59,786 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8194258456880396, 'Total loss': 0.8194258456880396} | train loss {'Reaction outcome loss': 0.8032259860586736, 'Total loss': 0.8032259860586736}
2022-11-22 23:47:59,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:47:59,787 INFO:     Epoch: 28
2022-11-22 23:48:00,672 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8330789299851115, 'Total loss': 0.8330789299851115} | train loss {'Reaction outcome loss': 0.8028106922584195, 'Total loss': 0.8028106922584195}
2022-11-22 23:48:00,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:00,673 INFO:     Epoch: 29
2022-11-22 23:48:01,580 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8019076409665021, 'Total loss': 0.8019076409665021} | train loss {'Reaction outcome loss': 0.8121602488381248, 'Total loss': 0.8121602488381248}
2022-11-22 23:48:01,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:01,581 INFO:     Epoch: 30
2022-11-22 23:48:02,406 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8231994557109746, 'Total loss': 0.8231994557109746} | train loss {'Reaction outcome loss': 0.8052570875133237, 'Total loss': 0.8052570875133237}
2022-11-22 23:48:02,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:02,406 INFO:     Epoch: 31
2022-11-22 23:48:03,249 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8034025261347945, 'Total loss': 0.8034025261347945} | train loss {'Reaction outcome loss': 0.8088885567361309, 'Total loss': 0.8088885567361309}
2022-11-22 23:48:03,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:03,249 INFO:     Epoch: 32
2022-11-22 23:48:04,103 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8393396870656447, 'Total loss': 0.8393396870656447} | train loss {'Reaction outcome loss': 0.8036491123418654, 'Total loss': 0.8036491123418654}
2022-11-22 23:48:04,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:04,103 INFO:     Epoch: 33
2022-11-22 23:48:04,962 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7931429228999398, 'Total loss': 0.7931429228999398} | train loss {'Reaction outcome loss': 0.8065513026329779, 'Total loss': 0.8065513026329779}
2022-11-22 23:48:04,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:04,962 INFO:     Epoch: 34
2022-11-22 23:48:05,816 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8104494627226483, 'Total loss': 0.8104494627226483} | train loss {'Reaction outcome loss': 0.8019807475709146, 'Total loss': 0.8019807475709146}
2022-11-22 23:48:05,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:05,816 INFO:     Epoch: 35
2022-11-22 23:48:06,651 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7908227931369435, 'Total loss': 0.7908227931369435} | train loss {'Reaction outcome loss': 0.8023842865180585, 'Total loss': 0.8023842865180585}
2022-11-22 23:48:06,651 INFO:     Found new best model at epoch 35
2022-11-22 23:48:06,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:06,652 INFO:     Epoch: 36
2022-11-22 23:48:07,492 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7996011715043675, 'Total loss': 0.7996011715043675} | train loss {'Reaction outcome loss': 0.8039555800778251, 'Total loss': 0.8039555800778251}
2022-11-22 23:48:07,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:07,492 INFO:     Epoch: 37
2022-11-22 23:48:08,331 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8061205026778308, 'Total loss': 0.8061205026778308} | train loss {'Reaction outcome loss': 0.805610757080778, 'Total loss': 0.805610757080778}
2022-11-22 23:48:08,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:08,331 INFO:     Epoch: 38
2022-11-22 23:48:09,142 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8022741702469912, 'Total loss': 0.8022741702469912} | train loss {'Reaction outcome loss': 0.7998304781654189, 'Total loss': 0.7998304781654189}
2022-11-22 23:48:09,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:09,144 INFO:     Epoch: 39
2022-11-22 23:48:09,944 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7991487329656427, 'Total loss': 0.7991487329656427} | train loss {'Reaction outcome loss': 0.8067056635214437, 'Total loss': 0.8067056635214437}
2022-11-22 23:48:09,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:09,944 INFO:     Epoch: 40
2022-11-22 23:48:10,744 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7939048185944557, 'Total loss': 0.7939048185944557} | train loss {'Reaction outcome loss': 0.8030311985602302, 'Total loss': 0.8030311985602302}
2022-11-22 23:48:10,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:10,745 INFO:     Epoch: 41
2022-11-22 23:48:11,567 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8183134442025964, 'Total loss': 0.8183134442025964} | train loss {'Reaction outcome loss': 0.7981701686737999, 'Total loss': 0.7981701686737999}
2022-11-22 23:48:11,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:11,567 INFO:     Epoch: 42
2022-11-22 23:48:12,390 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.791130239313299, 'Total loss': 0.791130239313299} | train loss {'Reaction outcome loss': 0.806159874724765, 'Total loss': 0.806159874724765}
2022-11-22 23:48:12,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:12,390 INFO:     Epoch: 43
2022-11-22 23:48:13,209 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7961515364321795, 'Total loss': 0.7961515364321795} | train loss {'Reaction outcome loss': 0.803989103244197, 'Total loss': 0.803989103244197}
2022-11-22 23:48:13,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:13,209 INFO:     Epoch: 44
2022-11-22 23:48:14,023 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8005909940058534, 'Total loss': 0.8005909940058534} | train loss {'Reaction outcome loss': 0.7999129080243649, 'Total loss': 0.7999129080243649}
2022-11-22 23:48:14,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:14,023 INFO:     Epoch: 45
2022-11-22 23:48:14,835 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7971762581305071, 'Total loss': 0.7971762581305071} | train loss {'Reaction outcome loss': 0.7989815479565051, 'Total loss': 0.7989815479565051}
2022-11-22 23:48:14,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:14,836 INFO:     Epoch: 46
2022-11-22 23:48:15,694 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8026964640752836, 'Total loss': 0.8026964640752836} | train loss {'Reaction outcome loss': 0.8052966765338375, 'Total loss': 0.8052966765338375}
2022-11-22 23:48:15,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:15,695 INFO:     Epoch: 47
2022-11-22 23:48:16,534 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7935448763045397, 'Total loss': 0.7935448763045397} | train loss {'Reaction outcome loss': 0.8025942313815316, 'Total loss': 0.8025942313815316}
2022-11-22 23:48:16,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:16,534 INFO:     Epoch: 48
2022-11-22 23:48:17,356 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8207595700567419, 'Total loss': 0.8207595700567419} | train loss {'Reaction outcome loss': 0.806217712139891, 'Total loss': 0.806217712139891}
2022-11-22 23:48:17,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:17,356 INFO:     Epoch: 49
2022-11-22 23:48:18,173 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7963197217746214, 'Total loss': 0.7963197217746214} | train loss {'Reaction outcome loss': 0.804829957264085, 'Total loss': 0.804829957264085}
2022-11-22 23:48:18,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:18,174 INFO:     Epoch: 50
2022-11-22 23:48:18,972 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7996592467481439, 'Total loss': 0.7996592467481439} | train loss {'Reaction outcome loss': 0.7997667775639603, 'Total loss': 0.7997667775639603}
2022-11-22 23:48:18,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:18,972 INFO:     Epoch: 51
2022-11-22 23:48:19,798 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7993061305447058, 'Total loss': 0.7993061305447058} | train loss {'Reaction outcome loss': 0.8056131373009374, 'Total loss': 0.8056131373009374}
2022-11-22 23:48:19,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:19,799 INFO:     Epoch: 52
2022-11-22 23:48:20,621 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8197312937541441, 'Total loss': 0.8197312937541441} | train loss {'Reaction outcome loss': 0.8043452601038641, 'Total loss': 0.8043452601038641}
2022-11-22 23:48:20,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:20,621 INFO:     Epoch: 53
2022-11-22 23:48:21,489 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8158832490444183, 'Total loss': 0.8158832490444183} | train loss {'Reaction outcome loss': 0.8082548067454369, 'Total loss': 0.8082548067454369}
2022-11-22 23:48:21,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:21,490 INFO:     Epoch: 54
2022-11-22 23:48:22,312 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8096715577624061, 'Total loss': 0.8096715577624061} | train loss {'Reaction outcome loss': 0.8054997703481105, 'Total loss': 0.8054997703481105}
2022-11-22 23:48:22,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:22,312 INFO:     Epoch: 55
2022-11-22 23:48:23,132 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8003253638744354, 'Total loss': 0.8003253638744354} | train loss {'Reaction outcome loss': 0.8011315845914425, 'Total loss': 0.8011315845914425}
2022-11-22 23:48:23,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:23,132 INFO:     Epoch: 56
2022-11-22 23:48:23,931 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7984449402852491, 'Total loss': 0.7984449402852491} | train loss {'Reaction outcome loss': 0.8034280625081831, 'Total loss': 0.8034280625081831}
2022-11-22 23:48:23,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:23,931 INFO:     Epoch: 57
2022-11-22 23:48:24,717 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.803317478434606, 'Total loss': 0.803317478434606} | train loss {'Reaction outcome loss': 0.8076735861118762, 'Total loss': 0.8076735861118762}
2022-11-22 23:48:24,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:24,718 INFO:     Epoch: 58
2022-11-22 23:48:25,561 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8145455345511436, 'Total loss': 0.8145455345511436} | train loss {'Reaction outcome loss': 0.7998487759501703, 'Total loss': 0.7998487759501703}
2022-11-22 23:48:25,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:25,562 INFO:     Epoch: 59
2022-11-22 23:48:26,399 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8091625889593904, 'Total loss': 0.8091625889593904} | train loss {'Reaction outcome loss': 0.8061024594691492, 'Total loss': 0.8061024594691492}
2022-11-22 23:48:26,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:26,399 INFO:     Epoch: 60
2022-11-22 23:48:27,225 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.801185941831632, 'Total loss': 0.801185941831632} | train loss {'Reaction outcome loss': 0.8069839846462973, 'Total loss': 0.8069839846462973}
2022-11-22 23:48:27,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:27,226 INFO:     Epoch: 61
2022-11-22 23:48:28,028 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7936358221552589, 'Total loss': 0.7936358221552589} | train loss {'Reaction outcome loss': 0.803968912651462, 'Total loss': 0.803968912651462}
2022-11-22 23:48:28,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:28,029 INFO:     Epoch: 62
2022-11-22 23:48:28,842 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7963049601424824, 'Total loss': 0.7963049601424824} | train loss {'Reaction outcome loss': 0.8033711749219126, 'Total loss': 0.8033711749219126}
2022-11-22 23:48:28,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:28,842 INFO:     Epoch: 63
2022-11-22 23:48:29,677 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8054380186579444, 'Total loss': 0.8054380186579444} | train loss {'Reaction outcome loss': 0.8047979207288835, 'Total loss': 0.8047979207288835}
2022-11-22 23:48:29,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:29,677 INFO:     Epoch: 64
2022-11-22 23:48:30,463 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.808498206463727, 'Total loss': 0.808498206463727} | train loss {'Reaction outcome loss': 0.8050471662032989, 'Total loss': 0.8050471662032989}
2022-11-22 23:48:30,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:30,464 INFO:     Epoch: 65
2022-11-22 23:48:31,279 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8050878061489626, 'Total loss': 0.8050878061489626} | train loss {'Reaction outcome loss': 0.8019747079139755, 'Total loss': 0.8019747079139755}
2022-11-22 23:48:31,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:31,279 INFO:     Epoch: 66
2022-11-22 23:48:32,101 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7923112965442918, 'Total loss': 0.7923112965442918} | train loss {'Reaction outcome loss': 0.8054336369518311, 'Total loss': 0.8054336369518311}
2022-11-22 23:48:32,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:32,102 INFO:     Epoch: 67
2022-11-22 23:48:32,914 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8117916136980057, 'Total loss': 0.8117916136980057} | train loss {'Reaction outcome loss': 0.8041356023280851, 'Total loss': 0.8041356023280851}
2022-11-22 23:48:32,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:32,914 INFO:     Epoch: 68
2022-11-22 23:48:33,747 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7917339239608158, 'Total loss': 0.7917339239608158} | train loss {'Reaction outcome loss': 0.8017835583417646, 'Total loss': 0.8017835583417646}
2022-11-22 23:48:33,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:33,747 INFO:     Epoch: 69
2022-11-22 23:48:34,528 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8028643977912989, 'Total loss': 0.8028643977912989} | train loss {'Reaction outcome loss': 0.8048134044774117, 'Total loss': 0.8048134044774117}
2022-11-22 23:48:34,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:34,528 INFO:     Epoch: 70
2022-11-22 23:48:35,322 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7981056401675398, 'Total loss': 0.7981056401675398} | train loss {'Reaction outcome loss': 0.8075937804195189, 'Total loss': 0.8075937804195189}
2022-11-22 23:48:35,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:35,322 INFO:     Epoch: 71
2022-11-22 23:48:36,137 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7976060279391028, 'Total loss': 0.7976060279391028} | train loss {'Reaction outcome loss': 0.8028495660231959, 'Total loss': 0.8028495660231959}
2022-11-22 23:48:36,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:36,137 INFO:     Epoch: 72
2022-11-22 23:48:36,934 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7992974926124919, 'Total loss': 0.7992974926124919} | train loss {'Reaction outcome loss': 0.8045233270574, 'Total loss': 0.8045233270574}
2022-11-22 23:48:36,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:36,934 INFO:     Epoch: 73
2022-11-22 23:48:37,723 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8111623715270649, 'Total loss': 0.8111623715270649} | train loss {'Reaction outcome loss': 0.8080718816528397, 'Total loss': 0.8080718816528397}
2022-11-22 23:48:37,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:37,724 INFO:     Epoch: 74
2022-11-22 23:48:38,519 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8171971596100114, 'Total loss': 0.8171971596100114} | train loss {'Reaction outcome loss': 0.8070458346797574, 'Total loss': 0.8070458346797574}
2022-11-22 23:48:38,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:38,519 INFO:     Epoch: 75
2022-11-22 23:48:39,295 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8001035147092559, 'Total loss': 0.8001035147092559} | train loss {'Reaction outcome loss': 0.8037149498779927, 'Total loss': 0.8037149498779927}
2022-11-22 23:48:39,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:39,296 INFO:     Epoch: 76
2022-11-22 23:48:40,093 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7891106680035591, 'Total loss': 0.7891106680035591} | train loss {'Reaction outcome loss': 0.80451057935434, 'Total loss': 0.80451057935434}
2022-11-22 23:48:40,095 INFO:     Found new best model at epoch 76
2022-11-22 23:48:40,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:40,095 INFO:     Epoch: 77
2022-11-22 23:48:40,874 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8063027709722519, 'Total loss': 0.8063027709722519} | train loss {'Reaction outcome loss': 0.8024534051937442, 'Total loss': 0.8024534051937442}
2022-11-22 23:48:40,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:40,874 INFO:     Epoch: 78
2022-11-22 23:48:41,662 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8006989590146325, 'Total loss': 0.8006989590146325} | train loss {'Reaction outcome loss': 0.8071419709031621, 'Total loss': 0.8071419709031621}
2022-11-22 23:48:41,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:41,662 INFO:     Epoch: 79
2022-11-22 23:48:42,442 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8010507476600733, 'Total loss': 0.8010507476600733} | train loss {'Reaction outcome loss': 0.8040227929670964, 'Total loss': 0.8040227929670964}
2022-11-22 23:48:42,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:42,443 INFO:     Epoch: 80
2022-11-22 23:48:43,230 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8073162504217841, 'Total loss': 0.8073162504217841} | train loss {'Reaction outcome loss': 0.8062988726362106, 'Total loss': 0.8062988726362106}
2022-11-22 23:48:43,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:43,230 INFO:     Epoch: 81
2022-11-22 23:48:44,018 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.803491401401433, 'Total loss': 0.803491401401433} | train loss {'Reaction outcome loss': 0.8016737043376891, 'Total loss': 0.8016737043376891}
2022-11-22 23:48:44,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:44,019 INFO:     Epoch: 82
2022-11-22 23:48:44,789 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.818318675187501, 'Total loss': 0.818318675187501} | train loss {'Reaction outcome loss': 0.8023048380930577, 'Total loss': 0.8023048380930577}
2022-11-22 23:48:44,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:44,789 INFO:     Epoch: 83
2022-11-22 23:48:45,586 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8020656210455027, 'Total loss': 0.8020656210455027} | train loss {'Reaction outcome loss': 0.8030637113317367, 'Total loss': 0.8030637113317367}
2022-11-22 23:48:45,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:45,586 INFO:     Epoch: 84
2022-11-22 23:48:46,399 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8004897182637994, 'Total loss': 0.8004897182637994} | train loss {'Reaction outcome loss': 0.8033082166746739, 'Total loss': 0.8033082166746739}
2022-11-22 23:48:46,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:46,400 INFO:     Epoch: 85
2022-11-22 23:48:47,204 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8194622519341382, 'Total loss': 0.8194622519341382} | train loss {'Reaction outcome loss': 0.8027615878851183, 'Total loss': 0.8027615878851183}
2022-11-22 23:48:47,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:47,205 INFO:     Epoch: 86
2022-11-22 23:48:48,016 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7921243106777017, 'Total loss': 0.7921243106777017} | train loss {'Reaction outcome loss': 0.7976413157678419, 'Total loss': 0.7976413157678419}
2022-11-22 23:48:48,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:48,016 INFO:     Epoch: 87
2022-11-22 23:48:48,815 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7944045947356657, 'Total loss': 0.7944045947356657} | train loss {'Reaction outcome loss': 0.8076853725698686, 'Total loss': 0.8076853725698686}
2022-11-22 23:48:48,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:48,815 INFO:     Epoch: 88
2022-11-22 23:48:49,593 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7946660687977617, 'Total loss': 0.7946660687977617} | train loss {'Reaction outcome loss': 0.7999606250274566, 'Total loss': 0.7999606250274566}
2022-11-22 23:48:49,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:49,593 INFO:     Epoch: 89
2022-11-22 23:48:50,361 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8018642047589476, 'Total loss': 0.8018642047589476} | train loss {'Reaction outcome loss': 0.804147188101084, 'Total loss': 0.804147188101084}
2022-11-22 23:48:50,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:50,361 INFO:     Epoch: 90
2022-11-22 23:48:51,149 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7962829287756573, 'Total loss': 0.7962829287756573} | train loss {'Reaction outcome loss': 0.8064123185411576, 'Total loss': 0.8064123185411576}
2022-11-22 23:48:51,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:51,149 INFO:     Epoch: 91
2022-11-22 23:48:51,961 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8124564120715315, 'Total loss': 0.8124564120715315} | train loss {'Reaction outcome loss': 0.8043941416807713, 'Total loss': 0.8043941416807713}
2022-11-22 23:48:51,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:51,962 INFO:     Epoch: 92
2022-11-22 23:48:52,751 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7854480770501223, 'Total loss': 0.7854480770501223} | train loss {'Reaction outcome loss': 0.8035978428538768, 'Total loss': 0.8035978428538768}
2022-11-22 23:48:52,751 INFO:     Found new best model at epoch 92
2022-11-22 23:48:52,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:52,752 INFO:     Epoch: 93
2022-11-22 23:48:53,530 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7833662121133371, 'Total loss': 0.7833662121133371} | train loss {'Reaction outcome loss': 0.8021764368299515, 'Total loss': 0.8021764368299515}
2022-11-22 23:48:53,530 INFO:     Found new best model at epoch 93
2022-11-22 23:48:53,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:53,531 INFO:     Epoch: 94
2022-11-22 23:48:54,322 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.811846027997407, 'Total loss': 0.811846027997407} | train loss {'Reaction outcome loss': 0.802907251302273, 'Total loss': 0.802907251302273}
2022-11-22 23:48:54,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:54,323 INFO:     Epoch: 95
2022-11-22 23:48:55,108 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7932513776150617, 'Total loss': 0.7932513776150617} | train loss {'Reaction outcome loss': 0.8054021187126637, 'Total loss': 0.8054021187126637}
2022-11-22 23:48:55,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:55,109 INFO:     Epoch: 96
2022-11-22 23:48:55,902 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8207004727287726, 'Total loss': 0.8207004727287726} | train loss {'Reaction outcome loss': 0.8021035426326336, 'Total loss': 0.8021035426326336}
2022-11-22 23:48:55,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:55,902 INFO:     Epoch: 97
2022-11-22 23:48:56,696 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8002051182768561, 'Total loss': 0.8002051182768561} | train loss {'Reaction outcome loss': 0.7997296963247561, 'Total loss': 0.7997296963247561}
2022-11-22 23:48:56,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:56,697 INFO:     Epoch: 98
2022-11-22 23:48:57,533 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7865257066759196, 'Total loss': 0.7865257066759196} | train loss {'Reaction outcome loss': 0.8048575411160146, 'Total loss': 0.8048575411160146}
2022-11-22 23:48:57,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:57,533 INFO:     Epoch: 99
2022-11-22 23:48:58,319 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8014702878215096, 'Total loss': 0.8014702878215096} | train loss {'Reaction outcome loss': 0.7986311121813713, 'Total loss': 0.7986311121813713}
2022-11-22 23:48:58,320 INFO:     Best model found after epoch 94 of 100.
2022-11-22 23:48:58,320 INFO:   Done with stage: TRAINING
2022-11-22 23:48:58,320 INFO:   Starting stage: EVALUATION
2022-11-22 23:48:58,439 INFO:   Done with stage: EVALUATION
2022-11-22 23:48:58,440 INFO:   Leaving out SEQ value Fold_8
2022-11-22 23:48:58,453 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:48:58,453 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:48:59,134 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:48:59,134 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:48:59,204 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:48:59,204 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:48:59,204 INFO:     No hyperparam tuning for this model
2022-11-22 23:48:59,204 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:48:59,204 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:48:59,205 INFO:     None feature selector for col prot
2022-11-22 23:48:59,205 INFO:     None feature selector for col prot
2022-11-22 23:48:59,205 INFO:     None feature selector for col prot
2022-11-22 23:48:59,206 INFO:     None feature selector for col chem
2022-11-22 23:48:59,206 INFO:     None feature selector for col chem
2022-11-22 23:48:59,206 INFO:     None feature selector for col chem
2022-11-22 23:48:59,206 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:48:59,206 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:48:59,208 INFO:     Number of params in model 168571
2022-11-22 23:48:59,211 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:48:59,211 INFO:   Starting stage: TRAINING
2022-11-22 23:48:59,270 INFO:     Val loss before train {'Reaction outcome loss': 1.0358479808677326, 'Total loss': 1.0358479808677326}
2022-11-22 23:48:59,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:48:59,270 INFO:     Epoch: 0
2022-11-22 23:49:00,087 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8538295315070585, 'Total loss': 0.8538295315070585} | train loss {'Reaction outcome loss': 0.8912819351261927, 'Total loss': 0.8912819351261927}
2022-11-22 23:49:00,087 INFO:     Found new best model at epoch 0
2022-11-22 23:49:00,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:00,088 INFO:     Epoch: 1
2022-11-22 23:49:00,911 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.83468673852357, 'Total loss': 0.83468673852357} | train loss {'Reaction outcome loss': 0.8401248085233364, 'Total loss': 0.8401248085233364}
2022-11-22 23:49:00,911 INFO:     Found new best model at epoch 1
2022-11-22 23:49:00,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:00,912 INFO:     Epoch: 2
2022-11-22 23:49:01,711 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.834138656204397, 'Total loss': 0.834138656204397} | train loss {'Reaction outcome loss': 0.8364127910571543, 'Total loss': 0.8364127910571543}
2022-11-22 23:49:01,711 INFO:     Found new best model at epoch 2
2022-11-22 23:49:01,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:01,712 INFO:     Epoch: 3
2022-11-22 23:49:02,514 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8348409777337854, 'Total loss': 0.8348409777337854} | train loss {'Reaction outcome loss': 0.8270662870966954, 'Total loss': 0.8270662870966954}
2022-11-22 23:49:02,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:02,514 INFO:     Epoch: 4
2022-11-22 23:49:03,340 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8164994283155962, 'Total loss': 0.8164994283155962} | train loss {'Reaction outcome loss': 0.8267065102030874, 'Total loss': 0.8267065102030874}
2022-11-22 23:49:03,340 INFO:     Found new best model at epoch 4
2022-11-22 23:49:03,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:03,341 INFO:     Epoch: 5
2022-11-22 23:49:04,135 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8157427243211053, 'Total loss': 0.8157427243211053} | train loss {'Reaction outcome loss': 0.8189214544619626, 'Total loss': 0.8189214544619626}
2022-11-22 23:49:04,136 INFO:     Found new best model at epoch 5
2022-11-22 23:49:04,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:04,136 INFO:     Epoch: 6
2022-11-22 23:49:04,955 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8315545103766702, 'Total loss': 0.8315545103766702} | train loss {'Reaction outcome loss': 0.8222836835181665, 'Total loss': 0.8222836835181665}
2022-11-22 23:49:04,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:04,955 INFO:     Epoch: 7
2022-11-22 23:49:05,783 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8085544576699083, 'Total loss': 0.8085544576699083} | train loss {'Reaction outcome loss': 0.8176073320662445, 'Total loss': 0.8176073320662445}
2022-11-22 23:49:05,784 INFO:     Found new best model at epoch 7
2022-11-22 23:49:05,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:05,785 INFO:     Epoch: 8
2022-11-22 23:49:06,621 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8173095218159936, 'Total loss': 0.8173095218159936} | train loss {'Reaction outcome loss': 0.8091340497105952, 'Total loss': 0.8091340497105952}
2022-11-22 23:49:06,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:06,621 INFO:     Epoch: 9
2022-11-22 23:49:07,410 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8217107877135277, 'Total loss': 0.8217107877135277} | train loss {'Reaction outcome loss': 0.8192662135792165, 'Total loss': 0.8192662135792165}
2022-11-22 23:49:07,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:07,410 INFO:     Epoch: 10
2022-11-22 23:49:08,213 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.816070138730786, 'Total loss': 0.816070138730786} | train loss {'Reaction outcome loss': 0.8177434751831809, 'Total loss': 0.8177434751831809}
2022-11-22 23:49:08,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:08,213 INFO:     Epoch: 11
2022-11-22 23:49:09,027 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7971032241528685, 'Total loss': 0.7971032241528685} | train loss {'Reaction outcome loss': 0.8197922455637079, 'Total loss': 0.8197922455637079}
2022-11-22 23:49:09,027 INFO:     Found new best model at epoch 11
2022-11-22 23:49:09,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:09,028 INFO:     Epoch: 12
2022-11-22 23:49:09,827 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8254162005402825, 'Total loss': 0.8254162005402825} | train loss {'Reaction outcome loss': 0.8207066158051433, 'Total loss': 0.8207066158051433}
2022-11-22 23:49:09,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:09,827 INFO:     Epoch: 13
2022-11-22 23:49:10,649 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8036144016818567, 'Total loss': 0.8036144016818567} | train loss {'Reaction outcome loss': 0.8205816073697588, 'Total loss': 0.8205816073697588}
2022-11-22 23:49:10,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:10,649 INFO:     Epoch: 14
2022-11-22 23:49:11,437 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8442426906390623, 'Total loss': 0.8442426906390623} | train loss {'Reaction outcome loss': 0.8165329395518129, 'Total loss': 0.8165329395518129}
2022-11-22 23:49:11,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:11,439 INFO:     Epoch: 15
2022-11-22 23:49:12,225 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8110112927176736, 'Total loss': 0.8110112927176736} | train loss {'Reaction outcome loss': 0.8203428949904346, 'Total loss': 0.8203428949904346}
2022-11-22 23:49:12,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:12,225 INFO:     Epoch: 16
2022-11-22 23:49:13,037 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8314228044314818, 'Total loss': 0.8314228044314818} | train loss {'Reaction outcome loss': 0.8152165221057923, 'Total loss': 0.8152165221057923}
2022-11-22 23:49:13,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:13,037 INFO:     Epoch: 17
2022-11-22 23:49:13,869 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8007194088263945, 'Total loss': 0.8007194088263945} | train loss {'Reaction outcome loss': 0.8212860238696882, 'Total loss': 0.8212860238696882}
2022-11-22 23:49:13,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:13,870 INFO:     Epoch: 18
2022-11-22 23:49:14,702 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8317507017742504, 'Total loss': 0.8317507017742504} | train loss {'Reaction outcome loss': 0.8281855577158059, 'Total loss': 0.8281855577158059}
2022-11-22 23:49:14,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:14,702 INFO:     Epoch: 19
2022-11-22 23:49:15,514 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7986646463925188, 'Total loss': 0.7986646463925188} | train loss {'Reaction outcome loss': 0.8164743776112674, 'Total loss': 0.8164743776112674}
2022-11-22 23:49:15,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:15,515 INFO:     Epoch: 20
2022-11-22 23:49:16,314 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8307837694883347, 'Total loss': 0.8307837694883347} | train loss {'Reaction outcome loss': 0.814035013137076, 'Total loss': 0.814035013137076}
2022-11-22 23:49:16,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:16,314 INFO:     Epoch: 21
2022-11-22 23:49:17,143 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8155619603666392, 'Total loss': 0.8155619603666392} | train loss {'Reaction outcome loss': 0.8148538428038238, 'Total loss': 0.8148538428038238}
2022-11-22 23:49:17,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:17,143 INFO:     Epoch: 22
2022-11-22 23:49:17,924 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7988116991790858, 'Total loss': 0.7988116991790858} | train loss {'Reaction outcome loss': 0.8116109724710827, 'Total loss': 0.8116109724710827}
2022-11-22 23:49:17,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:17,925 INFO:     Epoch: 23
2022-11-22 23:49:18,730 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7957995276559483, 'Total loss': 0.7957995276559483} | train loss {'Reaction outcome loss': 0.8094741953046698, 'Total loss': 0.8094741953046698}
2022-11-22 23:49:18,730 INFO:     Found new best model at epoch 23
2022-11-22 23:49:18,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:18,731 INFO:     Epoch: 24
2022-11-22 23:49:19,530 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8231508217074655, 'Total loss': 0.8231508217074655} | train loss {'Reaction outcome loss': 0.8107625310599562, 'Total loss': 0.8107625310599562}
2022-11-22 23:49:19,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:19,530 INFO:     Epoch: 25
2022-11-22 23:49:20,344 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8033349974588915, 'Total loss': 0.8033349974588915} | train loss {'Reaction outcome loss': 0.817420706575216, 'Total loss': 0.817420706575216}
2022-11-22 23:49:20,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:20,344 INFO:     Epoch: 26
2022-11-22 23:49:21,176 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.816597503694621, 'Total loss': 0.816597503694621} | train loss {'Reaction outcome loss': 0.8094395886548618, 'Total loss': 0.8094395886548618}
2022-11-22 23:49:21,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:21,176 INFO:     Epoch: 27
2022-11-22 23:49:21,965 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8107503137805245, 'Total loss': 0.8107503137805245} | train loss {'Reaction outcome loss': 0.8089778659797391, 'Total loss': 0.8089778659797391}
2022-11-22 23:49:21,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:21,965 INFO:     Epoch: 28
2022-11-22 23:49:22,752 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8019033501094038, 'Total loss': 0.8019033501094038} | train loss {'Reaction outcome loss': 0.8114296908562, 'Total loss': 0.8114296908562}
2022-11-22 23:49:22,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:22,752 INFO:     Epoch: 29
2022-11-22 23:49:23,600 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8227227756922896, 'Total loss': 0.8227227756922896} | train loss {'Reaction outcome loss': 0.8187952486850955, 'Total loss': 0.8187952486850955}
2022-11-22 23:49:23,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:23,600 INFO:     Epoch: 30
2022-11-22 23:49:24,440 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8187650814652443, 'Total loss': 0.8187650814652443} | train loss {'Reaction outcome loss': 0.8113053882351289, 'Total loss': 0.8113053882351289}
2022-11-22 23:49:24,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:24,440 INFO:     Epoch: 31
2022-11-22 23:49:25,222 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8298661106012084, 'Total loss': 0.8298661106012084} | train loss {'Reaction outcome loss': 0.8078655003294771, 'Total loss': 0.8078655003294771}
2022-11-22 23:49:25,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:25,223 INFO:     Epoch: 32
2022-11-22 23:49:26,025 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8465822691267187, 'Total loss': 0.8465822691267187} | train loss {'Reaction outcome loss': 0.8130339894458832, 'Total loss': 0.8130339894458832}
2022-11-22 23:49:26,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:26,026 INFO:     Epoch: 33
2022-11-22 23:49:26,885 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8147444508292458, 'Total loss': 0.8147444508292458} | train loss {'Reaction outcome loss': 0.8119201263194142, 'Total loss': 0.8119201263194142}
2022-11-22 23:49:26,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:26,885 INFO:     Epoch: 34
2022-11-22 23:49:27,696 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8079876147887923, 'Total loss': 0.8079876147887923} | train loss {'Reaction outcome loss': 0.8062245781243089, 'Total loss': 0.8062245781243089}
2022-11-22 23:49:27,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:27,696 INFO:     Epoch: 35
2022-11-22 23:49:28,491 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8409510376778516, 'Total loss': 0.8409510376778516} | train loss {'Reaction outcome loss': 0.82018465986136, 'Total loss': 0.82018465986136}
2022-11-22 23:49:28,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:28,492 INFO:     Epoch: 36
2022-11-22 23:49:29,335 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7918236059221354, 'Total loss': 0.7918236059221354} | train loss {'Reaction outcome loss': 0.8106033374906069, 'Total loss': 0.8106033374906069}
2022-11-22 23:49:29,335 INFO:     Found new best model at epoch 36
2022-11-22 23:49:29,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:29,336 INFO:     Epoch: 37
2022-11-22 23:49:30,178 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8036841628226367, 'Total loss': 0.8036841628226367} | train loss {'Reaction outcome loss': 0.8055846219362035, 'Total loss': 0.8055846219362035}
2022-11-22 23:49:30,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:30,179 INFO:     Epoch: 38
2022-11-22 23:49:30,993 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7938597825440493, 'Total loss': 0.7938597825440493} | train loss {'Reaction outcome loss': 0.8120213989847103, 'Total loss': 0.8120213989847103}
2022-11-22 23:49:30,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:30,993 INFO:     Epoch: 39
2022-11-22 23:49:31,815 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7941713522781025, 'Total loss': 0.7941713522781025} | train loss {'Reaction outcome loss': 0.807730944110797, 'Total loss': 0.807730944110797}
2022-11-22 23:49:31,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:31,816 INFO:     Epoch: 40
2022-11-22 23:49:32,659 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8018331067128615, 'Total loss': 0.8018331067128615} | train loss {'Reaction outcome loss': 0.8123453696247055, 'Total loss': 0.8123453696247055}
2022-11-22 23:49:32,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:32,660 INFO:     Epoch: 41
2022-11-22 23:49:33,474 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8021895330060612, 'Total loss': 0.8021895330060612} | train loss {'Reaction outcome loss': 0.8151540709169287, 'Total loss': 0.8151540709169287}
2022-11-22 23:49:33,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:33,475 INFO:     Epoch: 42
2022-11-22 23:49:34,306 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8152588443322615, 'Total loss': 0.8152588443322615} | train loss {'Reaction outcome loss': 0.8064484868334373, 'Total loss': 0.8064484868334373}
2022-11-22 23:49:34,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:34,307 INFO:     Epoch: 43
2022-11-22 23:49:35,145 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.805006971413439, 'Total loss': 0.805006971413439} | train loss {'Reaction outcome loss': 0.8074346117162512, 'Total loss': 0.8074346117162512}
2022-11-22 23:49:35,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:35,145 INFO:     Epoch: 44
2022-11-22 23:49:35,954 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8068030429157343, 'Total loss': 0.8068030429157343} | train loss {'Reaction outcome loss': 0.8048100744181799, 'Total loss': 0.8048100744181799}
2022-11-22 23:49:35,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:35,954 INFO:     Epoch: 45
2022-11-22 23:49:36,758 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8104842129078779, 'Total loss': 0.8104842129078779} | train loss {'Reaction outcome loss': 0.810088309078564, 'Total loss': 0.810088309078564}
2022-11-22 23:49:36,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:36,758 INFO:     Epoch: 46
2022-11-22 23:49:37,546 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7964737767522986, 'Total loss': 0.7964737767522986} | train loss {'Reaction outcome loss': 0.8152523104719788, 'Total loss': 0.8152523104719788}
2022-11-22 23:49:37,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:37,546 INFO:     Epoch: 47
2022-11-22 23:49:38,326 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8169299919496883, 'Total loss': 0.8169299919496883} | train loss {'Reaction outcome loss': 0.8199012663200317, 'Total loss': 0.8199012663200317}
2022-11-22 23:49:38,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:38,326 INFO:     Epoch: 48
2022-11-22 23:49:39,143 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8458868495442651, 'Total loss': 0.8458868495442651} | train loss {'Reaction outcome loss': 0.8094953376995889, 'Total loss': 0.8094953376995889}
2022-11-22 23:49:39,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:39,143 INFO:     Epoch: 49
2022-11-22 23:49:39,953 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8310018953951922, 'Total loss': 0.8310018953951922} | train loss {'Reaction outcome loss': 0.8090484413782112, 'Total loss': 0.8090484413782112}
2022-11-22 23:49:39,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:39,953 INFO:     Epoch: 50
2022-11-22 23:49:40,803 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7974228648976847, 'Total loss': 0.7974228648976847} | train loss {'Reaction outcome loss': 0.809156719610276, 'Total loss': 0.809156719610276}
2022-11-22 23:49:40,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:40,803 INFO:     Epoch: 51
2022-11-22 23:49:41,641 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8193490484898741, 'Total loss': 0.8193490484898741} | train loss {'Reaction outcome loss': 0.8101786369012918, 'Total loss': 0.8101786369012918}
2022-11-22 23:49:41,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:41,642 INFO:     Epoch: 52
2022-11-22 23:49:42,455 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8188932957974348, 'Total loss': 0.8188932957974348} | train loss {'Reaction outcome loss': 0.8103847712399024, 'Total loss': 0.8103847712399024}
2022-11-22 23:49:42,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:42,457 INFO:     Epoch: 53
2022-11-22 23:49:43,309 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8075985116037455, 'Total loss': 0.8075985116037455} | train loss {'Reaction outcome loss': 0.8060017290868258, 'Total loss': 0.8060017290868258}
2022-11-22 23:49:43,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:43,309 INFO:     Epoch: 54
2022-11-22 23:49:44,112 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8388482508334246, 'Total loss': 0.8388482508334246} | train loss {'Reaction outcome loss': 0.8073046384794027, 'Total loss': 0.8073046384794027}
2022-11-22 23:49:44,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:44,113 INFO:     Epoch: 55
2022-11-22 23:49:44,904 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7881570322947069, 'Total loss': 0.7881570322947069} | train loss {'Reaction outcome loss': 0.8042786247605979, 'Total loss': 0.8042786247605979}
2022-11-22 23:49:44,904 INFO:     Found new best model at epoch 55
2022-11-22 23:49:44,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:44,905 INFO:     Epoch: 56
2022-11-22 23:49:45,716 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8140970996835015, 'Total loss': 0.8140970996835015} | train loss {'Reaction outcome loss': 0.8079152003473599, 'Total loss': 0.8079152003473599}
2022-11-22 23:49:45,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:45,716 INFO:     Epoch: 57
2022-11-22 23:49:46,516 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8115762980146841, 'Total loss': 0.8115762980146841} | train loss {'Reaction outcome loss': 0.8117255097941348, 'Total loss': 0.8117255097941348}
2022-11-22 23:49:46,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:46,517 INFO:     Epoch: 58
2022-11-22 23:49:47,334 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7986172031272541, 'Total loss': 0.7986172031272541} | train loss {'Reaction outcome loss': 0.8125722625477594, 'Total loss': 0.8125722625477594}
2022-11-22 23:49:47,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:47,335 INFO:     Epoch: 59
2022-11-22 23:49:48,128 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8088786107572642, 'Total loss': 0.8088786107572642} | train loss {'Reaction outcome loss': 0.8089902306857862, 'Total loss': 0.8089902306857862}
2022-11-22 23:49:48,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:48,129 INFO:     Epoch: 60
2022-11-22 23:49:48,909 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8141767301342704, 'Total loss': 0.8141767301342704} | train loss {'Reaction outcome loss': 0.8131724844577342, 'Total loss': 0.8131724844577342}
2022-11-22 23:49:48,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:48,910 INFO:     Epoch: 61
2022-11-22 23:49:49,759 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.795561322434382, 'Total loss': 0.795561322434382} | train loss {'Reaction outcome loss': 0.8105293652306684, 'Total loss': 0.8105293652306684}
2022-11-22 23:49:49,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:49,759 INFO:     Epoch: 62
2022-11-22 23:49:50,581 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8116540211168203, 'Total loss': 0.8116540211168203} | train loss {'Reaction outcome loss': 0.809365569459282, 'Total loss': 0.809365569459282}
2022-11-22 23:49:50,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:50,581 INFO:     Epoch: 63
2022-11-22 23:49:51,431 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.817093359475786, 'Total loss': 0.817093359475786} | train loss {'Reaction outcome loss': 0.8134200720169283, 'Total loss': 0.8134200720169283}
2022-11-22 23:49:51,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:51,431 INFO:     Epoch: 64
2022-11-22 23:49:52,219 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8037338304248723, 'Total loss': 0.8037338304248723} | train loss {'Reaction outcome loss': 0.8069496247691181, 'Total loss': 0.8069496247691181}
2022-11-22 23:49:52,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:52,219 INFO:     Epoch: 65
2022-11-22 23:49:53,076 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8127796677025881, 'Total loss': 0.8127796677025881} | train loss {'Reaction outcome loss': 0.8105535019747159, 'Total loss': 0.8105535019747159}
2022-11-22 23:49:53,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:53,077 INFO:     Epoch: 66
2022-11-22 23:49:53,878 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8055049661885608, 'Total loss': 0.8055049661885608} | train loss {'Reaction outcome loss': 0.8154194224701237, 'Total loss': 0.8154194224701237}
2022-11-22 23:49:53,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:53,878 INFO:     Epoch: 67
2022-11-22 23:49:54,669 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7978662475943565, 'Total loss': 0.7978662475943565} | train loss {'Reaction outcome loss': 0.8051524169230269, 'Total loss': 0.8051524169230269}
2022-11-22 23:49:54,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:54,669 INFO:     Epoch: 68
2022-11-22 23:49:55,458 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8050198175690391, 'Total loss': 0.8050198175690391} | train loss {'Reaction outcome loss': 0.8108339608922178, 'Total loss': 0.8108339608922178}
2022-11-22 23:49:55,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:55,458 INFO:     Epoch: 69
2022-11-22 23:49:56,278 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7957731078971516, 'Total loss': 0.7957731078971516} | train loss {'Reaction outcome loss': 0.811133093558825, 'Total loss': 0.811133093558825}
2022-11-22 23:49:56,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:56,278 INFO:     Epoch: 70
2022-11-22 23:49:57,081 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8062656562436711, 'Total loss': 0.8062656562436711} | train loss {'Reaction outcome loss': 0.8072735253374587, 'Total loss': 0.8072735253374587}
2022-11-22 23:49:57,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:57,082 INFO:     Epoch: 71
2022-11-22 23:49:57,894 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8078632192178206, 'Total loss': 0.8078632192178206} | train loss {'Reaction outcome loss': 0.8058458563045934, 'Total loss': 0.8058458563045934}
2022-11-22 23:49:57,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:57,894 INFO:     Epoch: 72
2022-11-22 23:49:58,699 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7930576970631426, 'Total loss': 0.7930576970631426} | train loss {'Reaction outcome loss': 0.8102417362001744, 'Total loss': 0.8102417362001744}
2022-11-22 23:49:58,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:58,700 INFO:     Epoch: 73
2022-11-22 23:49:59,485 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8061702481724999, 'Total loss': 0.8061702481724999} | train loss {'Reaction outcome loss': 0.8063027499175748, 'Total loss': 0.8063027499175748}
2022-11-22 23:49:59,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:49:59,485 INFO:     Epoch: 74
2022-11-22 23:50:00,306 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.795213596387343, 'Total loss': 0.795213596387343} | train loss {'Reaction outcome loss': 0.8080200755041138, 'Total loss': 0.8080200755041138}
2022-11-22 23:50:00,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:00,306 INFO:     Epoch: 75
2022-11-22 23:50:01,110 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.807081246917898, 'Total loss': 0.807081246917898} | train loss {'Reaction outcome loss': 0.8109832531527469, 'Total loss': 0.8109832531527469}
2022-11-22 23:50:01,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:01,111 INFO:     Epoch: 76
2022-11-22 23:50:01,921 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7963981133970347, 'Total loss': 0.7963981133970347} | train loss {'Reaction outcome loss': 0.8104188298648186, 'Total loss': 0.8104188298648186}
2022-11-22 23:50:01,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:01,921 INFO:     Epoch: 77
2022-11-22 23:50:02,742 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8077592246911742, 'Total loss': 0.8077592246911742} | train loss {'Reaction outcome loss': 0.8125922635257968, 'Total loss': 0.8125922635257968}
2022-11-22 23:50:02,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:02,743 INFO:     Epoch: 78
2022-11-22 23:50:03,567 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8089724135669795, 'Total loss': 0.8089724135669795} | train loss {'Reaction outcome loss': 0.8093040951109125, 'Total loss': 0.8093040951109125}
2022-11-22 23:50:03,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:03,567 INFO:     Epoch: 79
2022-11-22 23:50:04,354 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7880605655637655, 'Total loss': 0.7880605655637655} | train loss {'Reaction outcome loss': 0.8025753535481117, 'Total loss': 0.8025753535481117}
2022-11-22 23:50:04,354 INFO:     Found new best model at epoch 79
2022-11-22 23:50:04,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:04,355 INFO:     Epoch: 80
2022-11-22 23:50:05,178 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7951419732787393, 'Total loss': 0.7951419732787393} | train loss {'Reaction outcome loss': 0.8072686322063569, 'Total loss': 0.8072686322063569}
2022-11-22 23:50:05,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:05,178 INFO:     Epoch: 81
2022-11-22 23:50:05,972 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8054474659941413, 'Total loss': 0.8054474659941413} | train loss {'Reaction outcome loss': 0.8080406437518626, 'Total loss': 0.8080406437518626}
2022-11-22 23:50:05,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:05,973 INFO:     Epoch: 82
2022-11-22 23:50:06,746 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7980608852072195, 'Total loss': 0.7980608852072195} | train loss {'Reaction outcome loss': 0.8114925864254415, 'Total loss': 0.8114925864254415}
2022-11-22 23:50:06,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:06,746 INFO:     Epoch: 83
2022-11-22 23:50:07,510 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7984876998446204, 'Total loss': 0.7984876998446204} | train loss {'Reaction outcome loss': 0.8052391505193132, 'Total loss': 0.8052391505193132}
2022-11-22 23:50:07,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:07,510 INFO:     Epoch: 84
2022-11-22 23:50:08,289 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8052263368259777, 'Total loss': 0.8052263368259777} | train loss {'Reaction outcome loss': 0.8047653611613671, 'Total loss': 0.8047653611613671}
2022-11-22 23:50:08,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:08,289 INFO:     Epoch: 85
2022-11-22 23:50:09,065 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8309483663602308, 'Total loss': 0.8309483663602308} | train loss {'Reaction outcome loss': 0.8163255623236358, 'Total loss': 0.8163255623236358}
2022-11-22 23:50:09,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:09,065 INFO:     Epoch: 86
2022-11-22 23:50:09,874 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7951712838628076, 'Total loss': 0.7951712838628076} | train loss {'Reaction outcome loss': 0.8090342108295997, 'Total loss': 0.8090342108295997}
2022-11-22 23:50:09,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:09,874 INFO:     Epoch: 87
2022-11-22 23:50:10,645 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8079715222120285, 'Total loss': 0.8079715222120285} | train loss {'Reaction outcome loss': 0.8065975786220689, 'Total loss': 0.8065975786220689}
2022-11-22 23:50:10,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:10,645 INFO:     Epoch: 88
2022-11-22 23:50:11,421 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7964835505593907, 'Total loss': 0.7964835505593907} | train loss {'Reaction outcome loss': 0.8094734386635213, 'Total loss': 0.8094734386635213}
2022-11-22 23:50:11,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:11,421 INFO:     Epoch: 89
2022-11-22 23:50:12,228 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7945978052236817, 'Total loss': 0.7945978052236817} | train loss {'Reaction outcome loss': 0.8065384901637732, 'Total loss': 0.8065384901637732}
2022-11-22 23:50:12,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:12,229 INFO:     Epoch: 90
2022-11-22 23:50:13,018 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7973993793129921, 'Total loss': 0.7973993793129921} | train loss {'Reaction outcome loss': 0.8098945371535143, 'Total loss': 0.8098945371535143}
2022-11-22 23:50:13,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:13,019 INFO:     Epoch: 91
2022-11-22 23:50:13,804 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7924430817365646, 'Total loss': 0.7924430817365646} | train loss {'Reaction outcome loss': 0.8052359215372246, 'Total loss': 0.8052359215372246}
2022-11-22 23:50:13,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:13,804 INFO:     Epoch: 92
2022-11-22 23:50:14,623 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8345679640769958, 'Total loss': 0.8345679640769958} | train loss {'Reaction outcome loss': 0.8053144314873074, 'Total loss': 0.8053144314873074}
2022-11-22 23:50:14,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:14,623 INFO:     Epoch: 93
2022-11-22 23:50:15,429 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8119594705375758, 'Total loss': 0.8119594705375758} | train loss {'Reaction outcome loss': 0.8136135741525333, 'Total loss': 0.8136135741525333}
2022-11-22 23:50:15,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:15,429 INFO:     Epoch: 94
2022-11-22 23:50:16,209 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7921804887327281, 'Total loss': 0.7921804887327281} | train loss {'Reaction outcome loss': 0.8147073344663087, 'Total loss': 0.8147073344663087}
2022-11-22 23:50:16,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:16,209 INFO:     Epoch: 95
2022-11-22 23:50:17,020 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8177698945457285, 'Total loss': 0.8177698945457285} | train loss {'Reaction outcome loss': 0.8100821690762091, 'Total loss': 0.8100821690762091}
2022-11-22 23:50:17,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:17,021 INFO:     Epoch: 96
2022-11-22 23:50:17,812 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7938038815151561, 'Total loss': 0.7938038815151561} | train loss {'Reaction outcome loss': 0.8104481266638045, 'Total loss': 0.8104481266638045}
2022-11-22 23:50:17,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:17,812 INFO:     Epoch: 97
2022-11-22 23:50:18,614 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7992435598915274, 'Total loss': 0.7992435598915274} | train loss {'Reaction outcome loss': 0.8006711919841013, 'Total loss': 0.8006711919841013}
2022-11-22 23:50:18,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:18,615 INFO:     Epoch: 98
2022-11-22 23:50:19,378 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7982194396582517, 'Total loss': 0.7982194396582517} | train loss {'Reaction outcome loss': 0.8068463231629206, 'Total loss': 0.8068463231629206}
2022-11-22 23:50:19,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:19,379 INFO:     Epoch: 99
2022-11-22 23:50:20,273 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8001757142218676, 'Total loss': 0.8001757142218676} | train loss {'Reaction outcome loss': 0.8118698934794437, 'Total loss': 0.8118698934794437}
2022-11-22 23:50:20,273 INFO:     Best model found after epoch 80 of 100.
2022-11-22 23:50:20,273 INFO:   Done with stage: TRAINING
2022-11-22 23:50:20,273 INFO:   Starting stage: EVALUATION
2022-11-22 23:50:20,398 INFO:   Done with stage: EVALUATION
2022-11-22 23:50:20,398 INFO:   Leaving out SEQ value Fold_9
2022-11-22 23:50:20,411 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 23:50:20,412 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:50:21,095 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:50:21,096 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:50:21,165 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:50:21,165 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:50:21,165 INFO:     No hyperparam tuning for this model
2022-11-22 23:50:21,165 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:50:21,165 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:50:21,166 INFO:     None feature selector for col prot
2022-11-22 23:50:21,166 INFO:     None feature selector for col prot
2022-11-22 23:50:21,167 INFO:     None feature selector for col prot
2022-11-22 23:50:21,167 INFO:     None feature selector for col chem
2022-11-22 23:50:21,167 INFO:     None feature selector for col chem
2022-11-22 23:50:21,167 INFO:     None feature selector for col chem
2022-11-22 23:50:21,168 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:50:21,168 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:50:21,169 INFO:     Number of params in model 168571
2022-11-22 23:50:21,172 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:50:21,173 INFO:   Starting stage: TRAINING
2022-11-22 23:50:21,231 INFO:     Val loss before train {'Reaction outcome loss': 1.0452627702192827, 'Total loss': 1.0452627702192827}
2022-11-22 23:50:21,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:21,231 INFO:     Epoch: 0
2022-11-22 23:50:22,009 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8275696316903288, 'Total loss': 0.8275696316903288} | train loss {'Reaction outcome loss': 0.8875430543576518, 'Total loss': 0.8875430543576518}
2022-11-22 23:50:22,009 INFO:     Found new best model at epoch 0
2022-11-22 23:50:22,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:22,010 INFO:     Epoch: 1
2022-11-22 23:50:22,833 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8481528731909665, 'Total loss': 0.8481528731909665} | train loss {'Reaction outcome loss': 0.8554296284433334, 'Total loss': 0.8554296284433334}
2022-11-22 23:50:22,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:22,833 INFO:     Epoch: 2
2022-11-22 23:50:23,603 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.851531371474266, 'Total loss': 0.851531371474266} | train loss {'Reaction outcome loss': 0.8582192759119696, 'Total loss': 0.8582192759119696}
2022-11-22 23:50:23,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:23,603 INFO:     Epoch: 3
2022-11-22 23:50:24,444 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8260724381967024, 'Total loss': 0.8260724381967024} | train loss {'Reaction outcome loss': 0.8527765332931473, 'Total loss': 0.8527765332931473}
2022-11-22 23:50:24,444 INFO:     Found new best model at epoch 3
2022-11-22 23:50:24,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:24,445 INFO:     Epoch: 4
2022-11-22 23:50:25,234 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8192892995747653, 'Total loss': 0.8192892995747653} | train loss {'Reaction outcome loss': 0.8491140405737585, 'Total loss': 0.8491140405737585}
2022-11-22 23:50:25,234 INFO:     Found new best model at epoch 4
2022-11-22 23:50:25,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:25,235 INFO:     Epoch: 5
2022-11-22 23:50:26,070 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.840380192480304, 'Total loss': 0.840380192480304} | train loss {'Reaction outcome loss': 0.8370279789932312, 'Total loss': 0.8370279789932312}
2022-11-22 23:50:26,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:26,070 INFO:     Epoch: 6
2022-11-22 23:50:26,898 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8137262890284712, 'Total loss': 0.8137262890284712} | train loss {'Reaction outcome loss': 0.8449838579662384, 'Total loss': 0.8449838579662384}
2022-11-22 23:50:26,898 INFO:     Found new best model at epoch 6
2022-11-22 23:50:26,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:26,899 INFO:     Epoch: 7
2022-11-22 23:50:27,729 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8361720226027749, 'Total loss': 0.8361720226027749} | train loss {'Reaction outcome loss': 0.8385688357295529, 'Total loss': 0.8385688357295529}
2022-11-22 23:50:27,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:27,729 INFO:     Epoch: 8
2022-11-22 23:50:28,562 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8431611812927506, 'Total loss': 0.8431611812927506} | train loss {'Reaction outcome loss': 0.8358114640558919, 'Total loss': 0.8358114640558919}
2022-11-22 23:50:28,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:28,562 INFO:     Epoch: 9
2022-11-22 23:50:29,384 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8170043297789313, 'Total loss': 0.8170043297789313} | train loss {'Reaction outcome loss': 0.8376842145958254, 'Total loss': 0.8376842145958254}
2022-11-22 23:50:29,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:29,384 INFO:     Epoch: 10
2022-11-22 23:50:30,215 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8069887811487372, 'Total loss': 0.8069887811487372} | train loss {'Reaction outcome loss': 0.8326431155925796, 'Total loss': 0.8326431155925796}
2022-11-22 23:50:30,215 INFO:     Found new best model at epoch 10
2022-11-22 23:50:30,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:30,216 INFO:     Epoch: 11
2022-11-22 23:50:31,020 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8147596920078451, 'Total loss': 0.8147596920078451} | train loss {'Reaction outcome loss': 0.8304262591465827, 'Total loss': 0.8304262591465827}
2022-11-22 23:50:31,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:31,020 INFO:     Epoch: 12
2022-11-22 23:50:31,799 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8214798962528055, 'Total loss': 0.8214798962528055} | train loss {'Reaction outcome loss': 0.8286276551023606, 'Total loss': 0.8286276551023606}
2022-11-22 23:50:31,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:31,800 INFO:     Epoch: 13
2022-11-22 23:50:32,631 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.812321322208101, 'Total loss': 0.812321322208101} | train loss {'Reaction outcome loss': 0.83063910264642, 'Total loss': 0.83063910264642}
2022-11-22 23:50:32,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:32,632 INFO:     Epoch: 14
2022-11-22 23:50:33,431 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8083719672127203, 'Total loss': 0.8083719672127203} | train loss {'Reaction outcome loss': 0.8291367980982026, 'Total loss': 0.8291367980982026}
2022-11-22 23:50:33,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:33,431 INFO:     Epoch: 15
2022-11-22 23:50:34,254 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.809913922439922, 'Total loss': 0.809913922439922} | train loss {'Reaction outcome loss': 0.8268630051564786, 'Total loss': 0.8268630051564786}
2022-11-22 23:50:34,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:34,254 INFO:     Epoch: 16
2022-11-22 23:50:35,044 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8203118457035585, 'Total loss': 0.8203118457035585} | train loss {'Reaction outcome loss': 0.8275420347288731, 'Total loss': 0.8275420347288731}
2022-11-22 23:50:35,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:35,045 INFO:     Epoch: 17
2022-11-22 23:50:35,824 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8227500238201835, 'Total loss': 0.8227500238201835} | train loss {'Reaction outcome loss': 0.8280560886186938, 'Total loss': 0.8280560886186938}
2022-11-22 23:50:35,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:35,824 INFO:     Epoch: 18
2022-11-22 23:50:36,612 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8266799808903174, 'Total loss': 0.8266799808903174} | train loss {'Reaction outcome loss': 0.8289046398093624, 'Total loss': 0.8289046398093624}
2022-11-22 23:50:36,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:36,613 INFO:     Epoch: 19
2022-11-22 23:50:37,450 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8137265586040237, 'Total loss': 0.8137265586040237} | train loss {'Reaction outcome loss': 0.824744692372699, 'Total loss': 0.824744692372699}
2022-11-22 23:50:37,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:37,451 INFO:     Epoch: 20
2022-11-22 23:50:38,310 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8111948005177758, 'Total loss': 0.8111948005177758} | train loss {'Reaction outcome loss': 0.826672466772218, 'Total loss': 0.826672466772218}
2022-11-22 23:50:38,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:38,311 INFO:     Epoch: 21
2022-11-22 23:50:39,125 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7967694300142202, 'Total loss': 0.7967694300142202} | train loss {'Reaction outcome loss': 0.8260117105899318, 'Total loss': 0.8260117105899318}
2022-11-22 23:50:39,125 INFO:     Found new best model at epoch 21
2022-11-22 23:50:39,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:39,126 INFO:     Epoch: 22
2022-11-22 23:50:39,975 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8081293979829008, 'Total loss': 0.8081293979829008} | train loss {'Reaction outcome loss': 0.8268651325375803, 'Total loss': 0.8268651325375803}
2022-11-22 23:50:39,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:39,975 INFO:     Epoch: 23
2022-11-22 23:50:40,773 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8090180592103438, 'Total loss': 0.8090180592103438} | train loss {'Reaction outcome loss': 0.8269627760014227, 'Total loss': 0.8269627760014227}
2022-11-22 23:50:40,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:40,774 INFO:     Epoch: 24
2022-11-22 23:50:41,563 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8015675118023698, 'Total loss': 0.8015675118023698} | train loss {'Reaction outcome loss': 0.8288018048530624, 'Total loss': 0.8288018048530624}
2022-11-22 23:50:41,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:41,563 INFO:     Epoch: 25
2022-11-22 23:50:42,345 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8151940337636254, 'Total loss': 0.8151940337636254} | train loss {'Reaction outcome loss': 0.8260197530110036, 'Total loss': 0.8260197530110036}
2022-11-22 23:50:42,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:42,345 INFO:     Epoch: 26
2022-11-22 23:50:43,131 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8027230934663252, 'Total loss': 0.8027230934663252} | train loss {'Reaction outcome loss': 0.8235329252577597, 'Total loss': 0.8235329252577597}
2022-11-22 23:50:43,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:43,131 INFO:     Epoch: 27
2022-11-22 23:50:43,954 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8085322346199643, 'Total loss': 0.8085322346199643} | train loss {'Reaction outcome loss': 0.8267164777123159, 'Total loss': 0.8267164777123159}
2022-11-22 23:50:43,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:43,955 INFO:     Epoch: 28
2022-11-22 23:50:44,788 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8045468438755382, 'Total loss': 0.8045468438755382} | train loss {'Reaction outcome loss': 0.8263163071486258, 'Total loss': 0.8263163071486258}
2022-11-22 23:50:44,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:44,789 INFO:     Epoch: 29
2022-11-22 23:50:45,599 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8160452883351933, 'Total loss': 0.8160452883351933} | train loss {'Reaction outcome loss': 0.8242672306876029, 'Total loss': 0.8242672306876029}
2022-11-22 23:50:45,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:45,600 INFO:     Epoch: 30
2022-11-22 23:50:46,464 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8149204945022409, 'Total loss': 0.8149204945022409} | train loss {'Reaction outcome loss': 0.8244091089694731, 'Total loss': 0.8244091089694731}
2022-11-22 23:50:46,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:46,464 INFO:     Epoch: 31
2022-11-22 23:50:47,296 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8005074479363181, 'Total loss': 0.8005074479363181} | train loss {'Reaction outcome loss': 0.8244555325758073, 'Total loss': 0.8244555325758073}
2022-11-22 23:50:47,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:47,296 INFO:     Epoch: 32
2022-11-22 23:50:48,108 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8234821537678892, 'Total loss': 0.8234821537678892} | train loss {'Reaction outcome loss': 0.8241086186420533, 'Total loss': 0.8241086186420533}
2022-11-22 23:50:48,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:48,108 INFO:     Epoch: 33
2022-11-22 23:50:48,941 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7994519343430345, 'Total loss': 0.7994519343430345} | train loss {'Reaction outcome loss': 0.8244113614482265, 'Total loss': 0.8244113614482265}
2022-11-22 23:50:48,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:48,942 INFO:     Epoch: 34
2022-11-22 23:50:49,768 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8123163899237459, 'Total loss': 0.8123163899237459} | train loss {'Reaction outcome loss': 0.8232935695878921, 'Total loss': 0.8232935695878921}
2022-11-22 23:50:49,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:49,768 INFO:     Epoch: 35
2022-11-22 23:50:50,565 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7933132540095936, 'Total loss': 0.7933132540095936} | train loss {'Reaction outcome loss': 0.8273720880669932, 'Total loss': 0.8273720880669932}
2022-11-22 23:50:50,565 INFO:     Found new best model at epoch 35
2022-11-22 23:50:50,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:50,566 INFO:     Epoch: 36
2022-11-22 23:50:51,376 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7988915456966921, 'Total loss': 0.7988915456966921} | train loss {'Reaction outcome loss': 0.8260385276329133, 'Total loss': 0.8260385276329133}
2022-11-22 23:50:51,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:51,377 INFO:     Epoch: 37
2022-11-22 23:50:52,169 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8257099376483397, 'Total loss': 0.8257099376483397} | train loss {'Reaction outcome loss': 0.8240874438516556, 'Total loss': 0.8240874438516556}
2022-11-22 23:50:52,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:52,170 INFO:     Epoch: 38
2022-11-22 23:50:53,018 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8045279681682587, 'Total loss': 0.8045279681682587} | train loss {'Reaction outcome loss': 0.8240314260605843, 'Total loss': 0.8240314260605843}
2022-11-22 23:50:53,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:53,018 INFO:     Epoch: 39
2022-11-22 23:50:53,815 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7984770644794811, 'Total loss': 0.7984770644794811} | train loss {'Reaction outcome loss': 0.824345150061192, 'Total loss': 0.824345150061192}
2022-11-22 23:50:53,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:53,815 INFO:     Epoch: 40
2022-11-22 23:50:54,675 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8087228428233754, 'Total loss': 0.8087228428233754} | train loss {'Reaction outcome loss': 0.8239564942496438, 'Total loss': 0.8239564942496438}
2022-11-22 23:50:54,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:54,676 INFO:     Epoch: 41
2022-11-22 23:50:55,503 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8046204799955542, 'Total loss': 0.8046204799955542} | train loss {'Reaction outcome loss': 0.8283975042643086, 'Total loss': 0.8283975042643086}
2022-11-22 23:50:55,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:55,503 INFO:     Epoch: 42
2022-11-22 23:50:56,317 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8000456325032494, 'Total loss': 0.8000456325032494} | train loss {'Reaction outcome loss': 0.825740001855358, 'Total loss': 0.825740001855358}
2022-11-22 23:50:56,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:56,318 INFO:     Epoch: 43
2022-11-22 23:50:57,148 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.82871474461122, 'Total loss': 0.82871474461122} | train loss {'Reaction outcome loss': 0.8207615823034318, 'Total loss': 0.8207615823034318}
2022-11-22 23:50:57,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:57,149 INFO:     Epoch: 44
2022-11-22 23:50:57,953 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8240052989938043, 'Total loss': 0.8240052989938043} | train loss {'Reaction outcome loss': 0.8321747023972773, 'Total loss': 0.8321747023972773}
2022-11-22 23:50:57,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:57,953 INFO:     Epoch: 45
2022-11-22 23:50:58,728 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8016006194732406, 'Total loss': 0.8016006194732406} | train loss {'Reaction outcome loss': 0.8234841347702088, 'Total loss': 0.8234841347702088}
2022-11-22 23:50:58,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:58,729 INFO:     Epoch: 46
2022-11-22 23:50:59,552 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8114383877678351, 'Total loss': 0.8114383877678351} | train loss {'Reaction outcome loss': 0.8237170877475892, 'Total loss': 0.8237170877475892}
2022-11-22 23:50:59,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:50:59,552 INFO:     Epoch: 47
2022-11-22 23:51:00,400 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.803842846642841, 'Total loss': 0.803842846642841} | train loss {'Reaction outcome loss': 0.8272815430837293, 'Total loss': 0.8272815430837293}
2022-11-22 23:51:00,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:00,400 INFO:     Epoch: 48
2022-11-22 23:51:01,316 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8026998137885873, 'Total loss': 0.8026998137885873} | train loss {'Reaction outcome loss': 0.8285417741825504, 'Total loss': 0.8285417741825504}
2022-11-22 23:51:01,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:01,316 INFO:     Epoch: 49
2022-11-22 23:51:02,228 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8066105158491568, 'Total loss': 0.8066105158491568} | train loss {'Reaction outcome loss': 0.8218014005932116, 'Total loss': 0.8218014005932116}
2022-11-22 23:51:02,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:02,228 INFO:     Epoch: 50
2022-11-22 23:51:03,128 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7936369207772341, 'Total loss': 0.7936369207772341} | train loss {'Reaction outcome loss': 0.8264395633051472, 'Total loss': 0.8264395633051472}
2022-11-22 23:51:03,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:03,129 INFO:     Epoch: 51
2022-11-22 23:51:03,965 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8026465760035948, 'Total loss': 0.8026465760035948} | train loss {'Reaction outcome loss': 0.8258521309302699, 'Total loss': 0.8258521309302699}
2022-11-22 23:51:03,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:03,966 INFO:     Epoch: 52
2022-11-22 23:51:04,804 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8007603788917715, 'Total loss': 0.8007603788917715} | train loss {'Reaction outcome loss': 0.8260458063694739, 'Total loss': 0.8260458063694739}
2022-11-22 23:51:04,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:04,804 INFO:     Epoch: 53
2022-11-22 23:51:05,611 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7990336512977426, 'Total loss': 0.7990336512977426} | train loss {'Reaction outcome loss': 0.8277689299035457, 'Total loss': 0.8277689299035457}
2022-11-22 23:51:05,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:05,611 INFO:     Epoch: 54
2022-11-22 23:51:06,471 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7992951030080969, 'Total loss': 0.7992951030080969} | train loss {'Reaction outcome loss': 0.825230207534567, 'Total loss': 0.825230207534567}
2022-11-22 23:51:06,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:06,471 INFO:     Epoch: 55
2022-11-22 23:51:07,311 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8004211586984721, 'Total loss': 0.8004211586984721} | train loss {'Reaction outcome loss': 0.8241377325067597, 'Total loss': 0.8241377325067597}
2022-11-22 23:51:07,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:07,312 INFO:     Epoch: 56
2022-11-22 23:51:08,109 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7983696616508744, 'Total loss': 0.7983696616508744} | train loss {'Reaction outcome loss': 0.8227580151250286, 'Total loss': 0.8227580151250286}
2022-11-22 23:51:08,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:08,109 INFO:     Epoch: 57
2022-11-22 23:51:08,927 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8027918189764023, 'Total loss': 0.8027918189764023} | train loss {'Reaction outcome loss': 0.8258947700021728, 'Total loss': 0.8258947700021728}
2022-11-22 23:51:08,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:08,927 INFO:     Epoch: 58
2022-11-22 23:51:09,767 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7918210645968263, 'Total loss': 0.7918210645968263} | train loss {'Reaction outcome loss': 0.821832329154976, 'Total loss': 0.821832329154976}
2022-11-22 23:51:09,767 INFO:     Found new best model at epoch 58
2022-11-22 23:51:09,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:09,769 INFO:     Epoch: 59
2022-11-22 23:51:10,570 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8313590477813374, 'Total loss': 0.8313590477813374} | train loss {'Reaction outcome loss': 0.8220006151785774, 'Total loss': 0.8220006151785774}
2022-11-22 23:51:10,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:10,570 INFO:     Epoch: 60
2022-11-22 23:51:11,386 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7804908826947212, 'Total loss': 0.7804908826947212} | train loss {'Reaction outcome loss': 0.8207132512282941, 'Total loss': 0.8207132512282941}
2022-11-22 23:51:11,387 INFO:     Found new best model at epoch 60
2022-11-22 23:51:11,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:11,388 INFO:     Epoch: 61
2022-11-22 23:51:12,248 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8153375691988252, 'Total loss': 0.8153375691988252} | train loss {'Reaction outcome loss': 0.8239879281290116, 'Total loss': 0.8239879281290116}
2022-11-22 23:51:12,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:12,248 INFO:     Epoch: 62
2022-11-22 23:51:13,092 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8040644892237403, 'Total loss': 0.8040644892237403} | train loss {'Reaction outcome loss': 0.8232533317660132, 'Total loss': 0.8232533317660132}
2022-11-22 23:51:13,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:13,092 INFO:     Epoch: 63
2022-11-22 23:51:13,887 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7930657843297179, 'Total loss': 0.7930657843297179} | train loss {'Reaction outcome loss': 0.8202729540005806, 'Total loss': 0.8202729540005806}
2022-11-22 23:51:13,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:13,887 INFO:     Epoch: 64
2022-11-22 23:51:14,693 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8005667633631013, 'Total loss': 0.8005667633631013} | train loss {'Reaction outcome loss': 0.8260762192789586, 'Total loss': 0.8260762192789586}
2022-11-22 23:51:14,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:14,693 INFO:     Epoch: 65
2022-11-22 23:51:15,521 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8199792585589669, 'Total loss': 0.8199792585589669} | train loss {'Reaction outcome loss': 0.8232445420036393, 'Total loss': 0.8232445420036393}
2022-11-22 23:51:15,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:15,522 INFO:     Epoch: 66
2022-11-22 23:51:16,326 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.803374626419761, 'Total loss': 0.803374626419761} | train loss {'Reaction outcome loss': 0.8229367847163831, 'Total loss': 0.8229367847163831}
2022-11-22 23:51:16,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:16,326 INFO:     Epoch: 67
2022-11-22 23:51:17,146 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8091244507919658, 'Total loss': 0.8091244507919658} | train loss {'Reaction outcome loss': 0.8260311341333774, 'Total loss': 0.8260311341333774}
2022-11-22 23:51:17,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:17,146 INFO:     Epoch: 68
2022-11-22 23:51:18,009 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7933896563269875, 'Total loss': 0.7933896563269875} | train loss {'Reaction outcome loss': 0.8286067027478449, 'Total loss': 0.8286067027478449}
2022-11-22 23:51:18,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:18,009 INFO:     Epoch: 69
2022-11-22 23:51:18,857 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7973040376197208, 'Total loss': 0.7973040376197208} | train loss {'Reaction outcome loss': 0.8238520362684804, 'Total loss': 0.8238520362684804}
2022-11-22 23:51:18,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:18,857 INFO:     Epoch: 70
2022-11-22 23:51:19,671 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.814291276037693, 'Total loss': 0.814291276037693} | train loss {'Reaction outcome loss': 0.8202833112689757, 'Total loss': 0.8202833112689757}
2022-11-22 23:51:19,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:19,671 INFO:     Epoch: 71
2022-11-22 23:51:20,486 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8167177777398716, 'Total loss': 0.8167177777398716} | train loss {'Reaction outcome loss': 0.824764670984399, 'Total loss': 0.824764670984399}
2022-11-22 23:51:20,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:20,487 INFO:     Epoch: 72
2022-11-22 23:51:21,265 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8207925117828629, 'Total loss': 0.8207925117828629} | train loss {'Reaction outcome loss': 0.8290313872839173, 'Total loss': 0.8290313872839173}
2022-11-22 23:51:21,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:21,265 INFO:     Epoch: 73
2022-11-22 23:51:22,085 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7929320667277683, 'Total loss': 0.7929320667277683} | train loss {'Reaction outcome loss': 0.8290774233398899, 'Total loss': 0.8290774233398899}
2022-11-22 23:51:22,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:22,087 INFO:     Epoch: 74
2022-11-22 23:51:22,900 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8086883581497453, 'Total loss': 0.8086883581497453} | train loss {'Reaction outcome loss': 0.8284501835944191, 'Total loss': 0.8284501835944191}
2022-11-22 23:51:22,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:22,900 INFO:     Epoch: 75
2022-11-22 23:51:23,714 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8265731084075841, 'Total loss': 0.8265731084075841} | train loss {'Reaction outcome loss': 0.8280864436059229, 'Total loss': 0.8280864436059229}
2022-11-22 23:51:23,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:23,714 INFO:     Epoch: 76
2022-11-22 23:51:24,552 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8188717283985831, 'Total loss': 0.8188717283985831} | train loss {'Reaction outcome loss': 0.8273874457565046, 'Total loss': 0.8273874457565046}
2022-11-22 23:51:24,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:24,553 INFO:     Epoch: 77
2022-11-22 23:51:25,364 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8062906339764595, 'Total loss': 0.8062906339764595} | train loss {'Reaction outcome loss': 0.8230586615541289, 'Total loss': 0.8230586615541289}
2022-11-22 23:51:25,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:25,364 INFO:     Epoch: 78
2022-11-22 23:51:26,195 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7959360683506186, 'Total loss': 0.7959360683506186} | train loss {'Reaction outcome loss': 0.8280114321218383, 'Total loss': 0.8280114321218383}
2022-11-22 23:51:26,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:26,196 INFO:     Epoch: 79
2022-11-22 23:51:27,009 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.813911147415638, 'Total loss': 0.813911147415638} | train loss {'Reaction outcome loss': 0.8284854518790399, 'Total loss': 0.8284854518790399}
2022-11-22 23:51:27,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:27,009 INFO:     Epoch: 80
2022-11-22 23:51:27,847 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7984991757707163, 'Total loss': 0.7984991757707163} | train loss {'Reaction outcome loss': 0.82210771210732, 'Total loss': 0.82210771210732}
2022-11-22 23:51:27,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:27,847 INFO:     Epoch: 81
2022-11-22 23:51:28,666 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8053585175763477, 'Total loss': 0.8053585175763477} | train loss {'Reaction outcome loss': 0.8263952526594361, 'Total loss': 0.8263952526594361}
2022-11-22 23:51:28,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:28,667 INFO:     Epoch: 82
2022-11-22 23:51:29,498 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7996854158965024, 'Total loss': 0.7996854158965024} | train loss {'Reaction outcome loss': 0.8209521190053032, 'Total loss': 0.8209521190053032}
2022-11-22 23:51:29,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:29,499 INFO:     Epoch: 83
2022-11-22 23:51:30,329 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7981759438460524, 'Total loss': 0.7981759438460524} | train loss {'Reaction outcome loss': 0.824543132296493, 'Total loss': 0.824543132296493}
2022-11-22 23:51:30,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:30,330 INFO:     Epoch: 84
2022-11-22 23:51:31,137 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8050705716013908, 'Total loss': 0.8050705716013908} | train loss {'Reaction outcome loss': 0.8212403450762072, 'Total loss': 0.8212403450762072}
2022-11-22 23:51:31,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:31,138 INFO:     Epoch: 85
2022-11-22 23:51:31,935 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8232100328261202, 'Total loss': 0.8232100328261202} | train loss {'Reaction outcome loss': 0.8225205135681937, 'Total loss': 0.8225205135681937}
2022-11-22 23:51:31,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:31,935 INFO:     Epoch: 86
2022-11-22 23:51:32,795 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8095934628085657, 'Total loss': 0.8095934628085657} | train loss {'Reaction outcome loss': 0.824499553730411, 'Total loss': 0.824499553730411}
2022-11-22 23:51:32,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:32,795 INFO:     Epoch: 87
2022-11-22 23:51:33,624 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8097426512024619, 'Total loss': 0.8097426512024619} | train loss {'Reaction outcome loss': 0.8239680177742436, 'Total loss': 0.8239680177742436}
2022-11-22 23:51:33,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:33,624 INFO:     Epoch: 88
2022-11-22 23:51:34,437 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8116266558116133, 'Total loss': 0.8116266558116133} | train loss {'Reaction outcome loss': 0.8254780387205463, 'Total loss': 0.8254780387205463}
2022-11-22 23:51:34,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:34,438 INFO:     Epoch: 89
2022-11-22 23:51:35,271 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7969144664027474, 'Total loss': 0.7969144664027474} | train loss {'Reaction outcome loss': 0.8234122695942079, 'Total loss': 0.8234122695942079}
2022-11-22 23:51:35,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:35,272 INFO:     Epoch: 90
2022-11-22 23:51:36,119 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.804159056733955, 'Total loss': 0.804159056733955} | train loss {'Reaction outcome loss': 0.8237034476572468, 'Total loss': 0.8237034476572468}
2022-11-22 23:51:36,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:36,119 INFO:     Epoch: 91
2022-11-22 23:51:36,950 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7941682982173833, 'Total loss': 0.7941682982173833} | train loss {'Reaction outcome loss': 0.8240709080090446, 'Total loss': 0.8240709080090446}
2022-11-22 23:51:36,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:36,951 INFO:     Epoch: 92
2022-11-22 23:51:37,753 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8294587656855583, 'Total loss': 0.8294587656855583} | train loss {'Reaction outcome loss': 0.8229572489376991, 'Total loss': 0.8229572489376991}
2022-11-22 23:51:37,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:37,754 INFO:     Epoch: 93
2022-11-22 23:51:38,592 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7992083789272741, 'Total loss': 0.7992083789272741} | train loss {'Reaction outcome loss': 0.8269673514991037, 'Total loss': 0.8269673514991037}
2022-11-22 23:51:38,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:38,592 INFO:     Epoch: 94
2022-11-22 23:51:39,391 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8066913431340997, 'Total loss': 0.8066913431340997} | train loss {'Reaction outcome loss': 0.8217506933837168, 'Total loss': 0.8217506933837168}
2022-11-22 23:51:39,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:39,392 INFO:     Epoch: 95
2022-11-22 23:51:40,189 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7933261814442548, 'Total loss': 0.7933261814442548} | train loss {'Reaction outcome loss': 0.8249513895040558, 'Total loss': 0.8249513895040558}
2022-11-22 23:51:40,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:40,189 INFO:     Epoch: 96
2022-11-22 23:51:41,027 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8018914413723078, 'Total loss': 0.8018914413723078} | train loss {'Reaction outcome loss': 0.8198249720397496, 'Total loss': 0.8198249720397496}
2022-11-22 23:51:41,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:41,027 INFO:     Epoch: 97
2022-11-22 23:51:41,815 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8009629771113396, 'Total loss': 0.8009629771113396} | train loss {'Reaction outcome loss': 0.8183077446395352, 'Total loss': 0.8183077446395352}
2022-11-22 23:51:41,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:41,815 INFO:     Epoch: 98
2022-11-22 23:51:42,658 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8511369946328077, 'Total loss': 0.8511369946328077} | train loss {'Reaction outcome loss': 0.8188716472396927, 'Total loss': 0.8188716472396927}
2022-11-22 23:51:42,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:42,658 INFO:     Epoch: 99
2022-11-22 23:51:43,481 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8034305064515634, 'Total loss': 0.8034305064515634} | train loss {'Reaction outcome loss': 0.8241048218502153, 'Total loss': 0.8241048218502153}
2022-11-22 23:51:43,481 INFO:     Best model found after epoch 61 of 100.
2022-11-22 23:51:43,481 INFO:   Done with stage: TRAINING
2022-11-22 23:51:43,481 INFO:   Starting stage: EVALUATION
2022-11-22 23:51:43,603 INFO:   Done with stage: EVALUATION
2022-11-22 23:51:43,612 INFO:   Leaving out SEQ value Fold_0
2022-11-22 23:51:43,625 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-22 23:51:43,625 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:51:44,292 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:51:44,292 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:51:44,361 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:51:44,361 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:51:44,361 INFO:     No hyperparam tuning for this model
2022-11-22 23:51:44,361 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:51:44,361 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:51:44,362 INFO:     None feature selector for col prot
2022-11-22 23:51:44,362 INFO:     None feature selector for col prot
2022-11-22 23:51:44,363 INFO:     None feature selector for col prot
2022-11-22 23:51:44,363 INFO:     None feature selector for col chem
2022-11-22 23:51:44,363 INFO:     None feature selector for col chem
2022-11-22 23:51:44,363 INFO:     None feature selector for col chem
2022-11-22 23:51:44,364 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:51:44,364 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:51:44,365 INFO:     Number of params in model 168571
2022-11-22 23:51:44,368 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:51:44,369 INFO:   Starting stage: TRAINING
2022-11-22 23:51:44,427 INFO:     Val loss before train {'Reaction outcome loss': 0.9724904176863757, 'Total loss': 0.9724904176863757}
2022-11-22 23:51:44,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:44,427 INFO:     Epoch: 0
2022-11-22 23:51:45,255 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.875833969224583, 'Total loss': 0.875833969224583} | train loss {'Reaction outcome loss': 0.8709054960280048, 'Total loss': 0.8709054960280048}
2022-11-22 23:51:45,255 INFO:     Found new best model at epoch 0
2022-11-22 23:51:45,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:45,256 INFO:     Epoch: 1
2022-11-22 23:51:46,069 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8227509056979959, 'Total loss': 0.8227509056979959} | train loss {'Reaction outcome loss': 0.8342605936283968, 'Total loss': 0.8342605936283968}
2022-11-22 23:51:46,069 INFO:     Found new best model at epoch 1
2022-11-22 23:51:46,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:46,070 INFO:     Epoch: 2
2022-11-22 23:51:46,866 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8262928107922728, 'Total loss': 0.8262928107922728} | train loss {'Reaction outcome loss': 0.8350839751107352, 'Total loss': 0.8350839751107352}
2022-11-22 23:51:46,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:46,868 INFO:     Epoch: 3
2022-11-22 23:51:47,677 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8573259724812075, 'Total loss': 0.8573259724812075} | train loss {'Reaction outcome loss': 0.8296658393071622, 'Total loss': 0.8296658393071622}
2022-11-22 23:51:47,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:47,677 INFO:     Epoch: 4
2022-11-22 23:51:48,470 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.833256405862895, 'Total loss': 0.833256405862895} | train loss {'Reaction outcome loss': 0.8259017025937839, 'Total loss': 0.8259017025937839}
2022-11-22 23:51:48,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:48,470 INFO:     Epoch: 5
2022-11-22 23:51:49,285 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8329998742450367, 'Total loss': 0.8329998742450367} | train loss {'Reaction outcome loss': 0.8248713243980796, 'Total loss': 0.8248713243980796}
2022-11-22 23:51:49,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:49,285 INFO:     Epoch: 6
2022-11-22 23:51:50,060 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8300795602527532, 'Total loss': 0.8300795602527532} | train loss {'Reaction outcome loss': 0.8251852366389061, 'Total loss': 0.8251852366389061}
2022-11-22 23:51:50,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:50,060 INFO:     Epoch: 7
2022-11-22 23:51:50,854 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8246732448989694, 'Total loss': 0.8246732448989694} | train loss {'Reaction outcome loss': 0.820415755558987, 'Total loss': 0.820415755558987}
2022-11-22 23:51:50,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:50,854 INFO:     Epoch: 8
2022-11-22 23:51:51,635 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.833417999473485, 'Total loss': 0.833417999473485} | train loss {'Reaction outcome loss': 0.8167957445796655, 'Total loss': 0.8167957445796655}
2022-11-22 23:51:51,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:51,636 INFO:     Epoch: 9
2022-11-22 23:51:52,452 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8464986749670722, 'Total loss': 0.8464986749670722} | train loss {'Reaction outcome loss': 0.8144619748300436, 'Total loss': 0.8144619748300436}
2022-11-22 23:51:52,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:52,452 INFO:     Epoch: 10
2022-11-22 23:51:53,267 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7944635728543455, 'Total loss': 0.7944635728543455} | train loss {'Reaction outcome loss': 0.8209866237883665, 'Total loss': 0.8209866237883665}
2022-11-22 23:51:53,268 INFO:     Found new best model at epoch 10
2022-11-22 23:51:53,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:53,269 INFO:     Epoch: 11
2022-11-22 23:51:54,096 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.803518726744435, 'Total loss': 0.803518726744435} | train loss {'Reaction outcome loss': 0.8156112374091635, 'Total loss': 0.8156112374091635}
2022-11-22 23:51:54,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:54,096 INFO:     Epoch: 12
2022-11-22 23:51:55,032 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8141479593786326, 'Total loss': 0.8141479593786326} | train loss {'Reaction outcome loss': 0.816206263887639, 'Total loss': 0.816206263887639}
2022-11-22 23:51:55,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:55,032 INFO:     Epoch: 13
2022-11-22 23:51:55,884 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8227547894824635, 'Total loss': 0.8227547894824635} | train loss {'Reaction outcome loss': 0.8202512944839438, 'Total loss': 0.8202512944839438}
2022-11-22 23:51:55,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:55,884 INFO:     Epoch: 14
2022-11-22 23:51:56,748 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.804522271183404, 'Total loss': 0.804522271183404} | train loss {'Reaction outcome loss': 0.8106608064807191, 'Total loss': 0.8106608064807191}
2022-11-22 23:51:56,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:56,749 INFO:     Epoch: 15
2022-11-22 23:51:57,654 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.809869725595821, 'Total loss': 0.809869725595821} | train loss {'Reaction outcome loss': 0.8193770734631285, 'Total loss': 0.8193770734631285}
2022-11-22 23:51:57,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:57,655 INFO:     Epoch: 16
2022-11-22 23:51:58,499 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.813539752906019, 'Total loss': 0.813539752906019} | train loss {'Reaction outcome loss': 0.8110107727196751, 'Total loss': 0.8110107727196751}
2022-11-22 23:51:58,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:58,499 INFO:     Epoch: 17
2022-11-22 23:51:59,429 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8156306479464878, 'Total loss': 0.8156306479464878} | train loss {'Reaction outcome loss': 0.8144828547020347, 'Total loss': 0.8144828547020347}
2022-11-22 23:51:59,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:51:59,430 INFO:     Epoch: 18
2022-11-22 23:52:00,378 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7964393838562749, 'Total loss': 0.7964393838562749} | train loss {'Reaction outcome loss': 0.8105058404864097, 'Total loss': 0.8105058404864097}
2022-11-22 23:52:00,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:00,378 INFO:     Epoch: 19
2022-11-22 23:52:01,288 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.82517164403742, 'Total loss': 0.82517164403742} | train loss {'Reaction outcome loss': 0.8089609571865627, 'Total loss': 0.8089609571865627}
2022-11-22 23:52:01,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:01,288 INFO:     Epoch: 20
2022-11-22 23:52:02,195 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8191560235890475, 'Total loss': 0.8191560235890475} | train loss {'Reaction outcome loss': 0.8126761318469534, 'Total loss': 0.8126761318469534}
2022-11-22 23:52:02,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:02,195 INFO:     Epoch: 21
2022-11-22 23:52:03,101 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8289478753100742, 'Total loss': 0.8289478753100742} | train loss {'Reaction outcome loss': 0.8108710655144282, 'Total loss': 0.8108710655144282}
2022-11-22 23:52:03,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:03,101 INFO:     Epoch: 22
2022-11-22 23:52:04,001 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8249129537831653, 'Total loss': 0.8249129537831653} | train loss {'Reaction outcome loss': 0.809832522577169, 'Total loss': 0.809832522577169}
2022-11-22 23:52:04,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:04,001 INFO:     Epoch: 23
2022-11-22 23:52:04,952 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7925446047024294, 'Total loss': 0.7925446047024294} | train loss {'Reaction outcome loss': 0.8067421664997023, 'Total loss': 0.8067421664997023}
2022-11-22 23:52:04,952 INFO:     Found new best model at epoch 23
2022-11-22 23:52:04,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:04,953 INFO:     Epoch: 24
2022-11-22 23:52:05,839 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7948755427179012, 'Total loss': 0.7948755427179012} | train loss {'Reaction outcome loss': 0.8118012934314961, 'Total loss': 0.8118012934314961}
2022-11-22 23:52:05,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:05,841 INFO:     Epoch: 25
2022-11-22 23:52:06,709 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8166552700779655, 'Total loss': 0.8166552700779655} | train loss {'Reaction outcome loss': 0.8067796289920807, 'Total loss': 0.8067796289920807}
2022-11-22 23:52:06,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:06,709 INFO:     Epoch: 26
2022-11-22 23:52:07,596 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.829044518145648, 'Total loss': 0.829044518145648} | train loss {'Reaction outcome loss': 0.8106211067462454, 'Total loss': 0.8106211067462454}
2022-11-22 23:52:07,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:07,596 INFO:     Epoch: 27
2022-11-22 23:52:08,525 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8249176625501026, 'Total loss': 0.8249176625501026} | train loss {'Reaction outcome loss': 0.8089697034991518, 'Total loss': 0.8089697034991518}
2022-11-22 23:52:08,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:08,525 INFO:     Epoch: 28
2022-11-22 23:52:09,431 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8104668828574094, 'Total loss': 0.8104668828574094} | train loss {'Reaction outcome loss': 0.8070525079357381, 'Total loss': 0.8070525079357381}
2022-11-22 23:52:09,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:09,431 INFO:     Epoch: 29
2022-11-22 23:52:10,369 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8042155196043578, 'Total loss': 0.8042155196043578} | train loss {'Reaction outcome loss': 0.8048351480644577, 'Total loss': 0.8048351480644577}
2022-11-22 23:52:10,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:10,369 INFO:     Epoch: 30
2022-11-22 23:52:11,339 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8196084655143998, 'Total loss': 0.8196084655143998} | train loss {'Reaction outcome loss': 0.8087422473090036, 'Total loss': 0.8087422473090036}
2022-11-22 23:52:11,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:11,339 INFO:     Epoch: 31
2022-11-22 23:52:12,230 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8713257678530433, 'Total loss': 0.8713257678530433} | train loss {'Reaction outcome loss': 0.8083206719889933, 'Total loss': 0.8083206719889933}
2022-11-22 23:52:12,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:12,230 INFO:     Epoch: 32
2022-11-22 23:52:13,177 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8232446285811338, 'Total loss': 0.8232446285811338} | train loss {'Reaction outcome loss': 0.8107154735497066, 'Total loss': 0.8107154735497066}
2022-11-22 23:52:13,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:13,177 INFO:     Epoch: 33
2022-11-22 23:52:14,044 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7839634249156172, 'Total loss': 0.7839634249156172} | train loss {'Reaction outcome loss': 0.8067938646491692, 'Total loss': 0.8067938646491692}
2022-11-22 23:52:14,044 INFO:     Found new best model at epoch 33
2022-11-22 23:52:14,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:14,045 INFO:     Epoch: 34
2022-11-22 23:52:14,967 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.818502588705583, 'Total loss': 0.818502588705583} | train loss {'Reaction outcome loss': 0.8103515262506447, 'Total loss': 0.8103515262506447}
2022-11-22 23:52:14,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:14,967 INFO:     Epoch: 35
2022-11-22 23:52:15,876 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8191407404162667, 'Total loss': 0.8191407404162667} | train loss {'Reaction outcome loss': 0.8068914187197782, 'Total loss': 0.8068914187197782}
2022-11-22 23:52:15,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:15,876 INFO:     Epoch: 36
2022-11-22 23:52:16,744 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8111149912530725, 'Total loss': 0.8111149912530725} | train loss {'Reaction outcome loss': 0.8085692580865353, 'Total loss': 0.8085692580865353}
2022-11-22 23:52:16,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:16,744 INFO:     Epoch: 37
2022-11-22 23:52:17,651 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7948626320470463, 'Total loss': 0.7948626320470463} | train loss {'Reaction outcome loss': 0.8082483375559048, 'Total loss': 0.8082483375559048}
2022-11-22 23:52:17,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:17,652 INFO:     Epoch: 38
2022-11-22 23:52:18,514 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8066025376319885, 'Total loss': 0.8066025376319885} | train loss {'Reaction outcome loss': 0.8045731978757041, 'Total loss': 0.8045731978757041}
2022-11-22 23:52:18,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:18,516 INFO:     Epoch: 39
2022-11-22 23:52:19,493 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8164878717877648, 'Total loss': 0.8164878717877648} | train loss {'Reaction outcome loss': 0.8053386573888818, 'Total loss': 0.8053386573888818}
2022-11-22 23:52:19,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:19,493 INFO:     Epoch: 40
2022-11-22 23:52:20,388 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8034748448566957, 'Total loss': 0.8034748448566957} | train loss {'Reaction outcome loss': 0.8065687368110734, 'Total loss': 0.8065687368110734}
2022-11-22 23:52:20,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:20,388 INFO:     Epoch: 41
2022-11-22 23:52:21,271 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8245426551862196, 'Total loss': 0.8245426551862196} | train loss {'Reaction outcome loss': 0.8055466772342215, 'Total loss': 0.8055466772342215}
2022-11-22 23:52:21,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:21,271 INFO:     Epoch: 42
2022-11-22 23:52:22,145 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8017215816812082, 'Total loss': 0.8017215816812082} | train loss {'Reaction outcome loss': 0.8059010375519188, 'Total loss': 0.8059010375519188}
2022-11-22 23:52:22,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:22,145 INFO:     Epoch: 43
2022-11-22 23:52:23,127 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8112006465142424, 'Total loss': 0.8112006465142424} | train loss {'Reaction outcome loss': 0.8041704106087587, 'Total loss': 0.8041704106087587}
2022-11-22 23:52:23,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:23,127 INFO:     Epoch: 44
2022-11-22 23:52:24,002 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7963592796163126, 'Total loss': 0.7963592796163126} | train loss {'Reaction outcome loss': 0.807510497010484, 'Total loss': 0.807510497010484}
2022-11-22 23:52:24,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:24,002 INFO:     Epoch: 45
2022-11-22 23:52:24,877 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8106008199128237, 'Total loss': 0.8106008199128237} | train loss {'Reaction outcome loss': 0.8036699147856965, 'Total loss': 0.8036699147856965}
2022-11-22 23:52:24,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:24,878 INFO:     Epoch: 46
2022-11-22 23:52:25,765 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8347734090956774, 'Total loss': 0.8347734090956774} | train loss {'Reaction outcome loss': 0.7995264842802164, 'Total loss': 0.7995264842802164}
2022-11-22 23:52:25,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:25,765 INFO:     Epoch: 47
2022-11-22 23:52:26,620 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7932240800424055, 'Total loss': 0.7932240800424055} | train loss {'Reaction outcome loss': 0.8019952739988054, 'Total loss': 0.8019952739988054}
2022-11-22 23:52:26,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:26,620 INFO:     Epoch: 48
2022-11-22 23:52:27,458 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7864525257186457, 'Total loss': 0.7864525257186457} | train loss {'Reaction outcome loss': 0.8041081440692045, 'Total loss': 0.8041081440692045}
2022-11-22 23:52:27,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:27,459 INFO:     Epoch: 49
2022-11-22 23:52:28,350 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8201507553458214, 'Total loss': 0.8201507553458214} | train loss {'Reaction outcome loss': 0.8056901939061223, 'Total loss': 0.8056901939061223}
2022-11-22 23:52:28,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:28,350 INFO:     Epoch: 50
2022-11-22 23:52:29,233 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8094283362681215, 'Total loss': 0.8094283362681215} | train loss {'Reaction outcome loss': 0.8017595437716465, 'Total loss': 0.8017595437716465}
2022-11-22 23:52:29,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:29,233 INFO:     Epoch: 51
2022-11-22 23:52:30,104 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8149759722026911, 'Total loss': 0.8149759722026911} | train loss {'Reaction outcome loss': 0.8029932597462012, 'Total loss': 0.8029932597462012}
2022-11-22 23:52:30,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:30,104 INFO:     Epoch: 52
2022-11-22 23:52:30,963 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8269427303563465, 'Total loss': 0.8269427303563465} | train loss {'Reaction outcome loss': 0.8061988030161177, 'Total loss': 0.8061988030161177}
2022-11-22 23:52:30,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:30,963 INFO:     Epoch: 53
2022-11-22 23:52:31,846 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.802379195663062, 'Total loss': 0.802379195663062} | train loss {'Reaction outcome loss': 0.8080253349275005, 'Total loss': 0.8080253349275005}
2022-11-22 23:52:31,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:31,846 INFO:     Epoch: 54
2022-11-22 23:52:32,771 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8054116429253058, 'Total loss': 0.8054116429253058} | train loss {'Reaction outcome loss': 0.8053254621369498, 'Total loss': 0.8053254621369498}
2022-11-22 23:52:32,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:32,771 INFO:     Epoch: 55
2022-11-22 23:52:33,658 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7975467545065013, 'Total loss': 0.7975467545065013} | train loss {'Reaction outcome loss': 0.8045644307014893, 'Total loss': 0.8045644307014893}
2022-11-22 23:52:33,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:33,658 INFO:     Epoch: 56
2022-11-22 23:52:34,534 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8125190694223751, 'Total loss': 0.8125190694223751} | train loss {'Reaction outcome loss': 0.8008255631339793, 'Total loss': 0.8008255631339793}
2022-11-22 23:52:34,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:34,535 INFO:     Epoch: 57
2022-11-22 23:52:35,369 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7933688664978201, 'Total loss': 0.7933688664978201} | train loss {'Reaction outcome loss': 0.8022637136128484, 'Total loss': 0.8022637136128484}
2022-11-22 23:52:35,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:35,370 INFO:     Epoch: 58
2022-11-22 23:52:36,216 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8027730916034092, 'Total loss': 0.8027730916034092} | train loss {'Reaction outcome loss': 0.8006889503829333, 'Total loss': 0.8006889503829333}
2022-11-22 23:52:36,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:36,216 INFO:     Epoch: 59
2022-11-22 23:52:37,107 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7868835147131573, 'Total loss': 0.7868835147131573} | train loss {'Reaction outcome loss': 0.7996803749580772, 'Total loss': 0.7996803749580772}
2022-11-22 23:52:37,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:37,108 INFO:     Epoch: 60
2022-11-22 23:52:37,979 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8181814375248823, 'Total loss': 0.8181814375248823} | train loss {'Reaction outcome loss': 0.8029395274969996, 'Total loss': 0.8029395274969996}
2022-11-22 23:52:37,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:37,979 INFO:     Epoch: 61
2022-11-22 23:52:38,826 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8177387402816252, 'Total loss': 0.8177387402816252} | train loss {'Reaction outcome loss': 0.8035274782959296, 'Total loss': 0.8035274782959296}
2022-11-22 23:52:38,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:38,827 INFO:     Epoch: 62
2022-11-22 23:52:39,686 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8219317231665958, 'Total loss': 0.8219317231665958} | train loss {'Reaction outcome loss': 0.8004315915156384, 'Total loss': 0.8004315915156384}
2022-11-22 23:52:39,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:39,686 INFO:     Epoch: 63
2022-11-22 23:52:40,521 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7931666895747185, 'Total loss': 0.7931666895747185} | train loss {'Reaction outcome loss': 0.8034800626793687, 'Total loss': 0.8034800626793687}
2022-11-22 23:52:40,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:40,521 INFO:     Epoch: 64
2022-11-22 23:52:41,412 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8122676583853635, 'Total loss': 0.8122676583853635} | train loss {'Reaction outcome loss': 0.8001665198073096, 'Total loss': 0.8001665198073096}
2022-11-22 23:52:41,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:41,413 INFO:     Epoch: 65
2022-11-22 23:52:42,271 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8011027750643817, 'Total loss': 0.8011027750643817} | train loss {'Reaction outcome loss': 0.7949650954227059, 'Total loss': 0.7949650954227059}
2022-11-22 23:52:42,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:42,272 INFO:     Epoch: 66
2022-11-22 23:52:43,118 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7910702154040337, 'Total loss': 0.7910702154040337} | train loss {'Reaction outcome loss': 0.7984815040413215, 'Total loss': 0.7984815040413215}
2022-11-22 23:52:43,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:43,118 INFO:     Epoch: 67
2022-11-22 23:52:43,993 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7899003804407336, 'Total loss': 0.7899003804407336} | train loss {'Reaction outcome loss': 0.7987874702531464, 'Total loss': 0.7987874702531464}
2022-11-22 23:52:43,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:43,994 INFO:     Epoch: 68
2022-11-22 23:52:44,890 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7842984355308793, 'Total loss': 0.7842984355308793} | train loss {'Reaction outcome loss': 0.7984628207829534, 'Total loss': 0.7984628207829534}
2022-11-22 23:52:44,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:44,890 INFO:     Epoch: 69
2022-11-22 23:52:45,765 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8239254667000337, 'Total loss': 0.8239254667000337} | train loss {'Reaction outcome loss': 0.7979492433217107, 'Total loss': 0.7979492433217107}
2022-11-22 23:52:45,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:45,766 INFO:     Epoch: 70
2022-11-22 23:52:46,647 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7916926104914058, 'Total loss': 0.7916926104914058} | train loss {'Reaction outcome loss': 0.7966125142817595, 'Total loss': 0.7966125142817595}
2022-11-22 23:52:46,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:46,647 INFO:     Epoch: 71
2022-11-22 23:52:47,563 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8061773214827884, 'Total loss': 0.8061773214827884} | train loss {'Reaction outcome loss': 0.7985143204124606, 'Total loss': 0.7985143204124606}
2022-11-22 23:52:47,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:47,563 INFO:     Epoch: 72
2022-11-22 23:52:48,409 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8021700246767565, 'Total loss': 0.8021700246767565} | train loss {'Reaction outcome loss': 0.7948374727550818, 'Total loss': 0.7948374727550818}
2022-11-22 23:52:48,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:48,410 INFO:     Epoch: 73
2022-11-22 23:52:49,261 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8057818114757538, 'Total loss': 0.8057818114757538} | train loss {'Reaction outcome loss': 0.7948132675521228, 'Total loss': 0.7948132675521228}
2022-11-22 23:52:49,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:49,261 INFO:     Epoch: 74
2022-11-22 23:52:50,130 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8052380504933271, 'Total loss': 0.8052380504933271} | train loss {'Reaction outcome loss': 0.7992805041828934, 'Total loss': 0.7992805041828934}
2022-11-22 23:52:50,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:50,131 INFO:     Epoch: 75
2022-11-22 23:52:51,002 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8008041673085906, 'Total loss': 0.8008041673085906} | train loss {'Reaction outcome loss': 0.8020688263129215, 'Total loss': 0.8020688263129215}
2022-11-22 23:52:51,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:51,002 INFO:     Epoch: 76
2022-11-22 23:52:51,864 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.802729267288338, 'Total loss': 0.802729267288338} | train loss {'Reaction outcome loss': 0.8015717472348894, 'Total loss': 0.8015717472348894}
2022-11-22 23:52:51,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:51,864 INFO:     Epoch: 77
2022-11-22 23:52:52,680 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7942031574520197, 'Total loss': 0.7942031574520197} | train loss {'Reaction outcome loss': 0.7997599672298042, 'Total loss': 0.7997599672298042}
2022-11-22 23:52:52,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:52,681 INFO:     Epoch: 78
2022-11-22 23:52:53,576 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7777453552592885, 'Total loss': 0.7777453552592885} | train loss {'Reaction outcome loss': 0.7966090819057153, 'Total loss': 0.7966090819057153}
2022-11-22 23:52:53,576 INFO:     Found new best model at epoch 78
2022-11-22 23:52:53,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:53,577 INFO:     Epoch: 79
2022-11-22 23:52:54,447 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8234863037412817, 'Total loss': 0.8234863037412817} | train loss {'Reaction outcome loss': 0.7934723303026082, 'Total loss': 0.7934723303026082}
2022-11-22 23:52:54,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:54,447 INFO:     Epoch: 80
2022-11-22 23:52:55,283 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8053464029322971, 'Total loss': 0.8053464029322971} | train loss {'Reaction outcome loss': 0.8006775134680223, 'Total loss': 0.8006775134680223}
2022-11-22 23:52:55,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:55,283 INFO:     Epoch: 81
2022-11-22 23:52:56,192 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7936657497828657, 'Total loss': 0.7936657497828657} | train loss {'Reaction outcome loss': 0.7971781167448784, 'Total loss': 0.7971781167448784}
2022-11-22 23:52:56,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:56,193 INFO:     Epoch: 82
2022-11-22 23:52:57,062 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7936303066936407, 'Total loss': 0.7936303066936407} | train loss {'Reaction outcome loss': 0.7949894998754774, 'Total loss': 0.7949894998754774}
2022-11-22 23:52:57,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:57,062 INFO:     Epoch: 83
2022-11-22 23:52:57,895 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8143570125102997, 'Total loss': 0.8143570125102997} | train loss {'Reaction outcome loss': 0.7956253005533802, 'Total loss': 0.7956253005533802}
2022-11-22 23:52:57,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:57,896 INFO:     Epoch: 84
2022-11-22 23:52:58,724 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7972581928426569, 'Total loss': 0.7972581928426569} | train loss {'Reaction outcome loss': 0.803424473441377, 'Total loss': 0.803424473441377}
2022-11-22 23:52:58,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:58,724 INFO:     Epoch: 85
2022-11-22 23:52:59,582 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7919570627537641, 'Total loss': 0.7919570627537641} | train loss {'Reaction outcome loss': 0.7997534157062064, 'Total loss': 0.7997534157062064}
2022-11-22 23:52:59,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:52:59,583 INFO:     Epoch: 86
2022-11-22 23:53:00,404 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.794030211865902, 'Total loss': 0.794030211865902} | train loss {'Reaction outcome loss': 0.7926263837181792, 'Total loss': 0.7926263837181792}
2022-11-22 23:53:00,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:00,404 INFO:     Epoch: 87
2022-11-22 23:53:01,233 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7818786430765282, 'Total loss': 0.7818786430765282} | train loss {'Reaction outcome loss': 0.7920412075762846, 'Total loss': 0.7920412075762846}
2022-11-22 23:53:01,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:01,233 INFO:     Epoch: 88
2022-11-22 23:53:02,052 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.783606574616649, 'Total loss': 0.783606574616649} | train loss {'Reaction outcome loss': 0.7919428731713977, 'Total loss': 0.7919428731713977}
2022-11-22 23:53:02,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:02,052 INFO:     Epoch: 89
2022-11-22 23:53:02,911 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7885382981462912, 'Total loss': 0.7885382981462912} | train loss {'Reaction outcome loss': 0.7937640351908547, 'Total loss': 0.7937640351908547}
2022-11-22 23:53:02,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:02,911 INFO:     Epoch: 90
2022-11-22 23:53:03,786 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8197613764892925, 'Total loss': 0.8197613764892925} | train loss {'Reaction outcome loss': 0.7930502092351719, 'Total loss': 0.7930502092351719}
2022-11-22 23:53:03,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:03,786 INFO:     Epoch: 91
2022-11-22 23:53:04,594 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8284359032457526, 'Total loss': 0.8284359032457526} | train loss {'Reaction outcome loss': 0.7927182765639558, 'Total loss': 0.7927182765639558}
2022-11-22 23:53:04,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:04,594 INFO:     Epoch: 92
2022-11-22 23:53:05,427 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.789657055654309, 'Total loss': 0.789657055654309} | train loss {'Reaction outcome loss': 0.7967350843001385, 'Total loss': 0.7967350843001385}
2022-11-22 23:53:05,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:05,427 INFO:     Epoch: 93
2022-11-22 23:53:06,290 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7951889085498723, 'Total loss': 0.7951889085498723} | train loss {'Reaction outcome loss': 0.7972473903578154, 'Total loss': 0.7972473903578154}
2022-11-22 23:53:06,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:06,290 INFO:     Epoch: 94
2022-11-22 23:53:07,144 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7860601883042942, 'Total loss': 0.7860601883042942} | train loss {'Reaction outcome loss': 0.7953450982667962, 'Total loss': 0.7953450982667962}
2022-11-22 23:53:07,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:07,144 INFO:     Epoch: 95
2022-11-22 23:53:07,972 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7897966531190005, 'Total loss': 0.7897966531190005} | train loss {'Reaction outcome loss': 0.7891726712791287, 'Total loss': 0.7891726712791287}
2022-11-22 23:53:07,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:07,972 INFO:     Epoch: 96
2022-11-22 23:53:08,777 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7935548201203346, 'Total loss': 0.7935548201203346} | train loss {'Reaction outcome loss': 0.7913319360236732, 'Total loss': 0.7913319360236732}
2022-11-22 23:53:08,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:08,778 INFO:     Epoch: 97
2022-11-22 23:53:09,555 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7887565398758108, 'Total loss': 0.7887565398758108} | train loss {'Reaction outcome loss': 0.7924885451793671, 'Total loss': 0.7924885451793671}
2022-11-22 23:53:09,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:09,555 INFO:     Epoch: 98
2022-11-22 23:53:10,384 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7719886025244539, 'Total loss': 0.7719886025244539} | train loss {'Reaction outcome loss': 0.794506152187075, 'Total loss': 0.794506152187075}
2022-11-22 23:53:10,384 INFO:     Found new best model at epoch 98
2022-11-22 23:53:10,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:10,385 INFO:     Epoch: 99
2022-11-22 23:53:11,259 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7949174249714072, 'Total loss': 0.7949174249714072} | train loss {'Reaction outcome loss': 0.7840870138333769, 'Total loss': 0.7840870138333769}
2022-11-22 23:53:11,259 INFO:     Best model found after epoch 99 of 100.
2022-11-22 23:53:11,259 INFO:   Done with stage: TRAINING
2022-11-22 23:53:11,259 INFO:   Starting stage: EVALUATION
2022-11-22 23:53:11,390 INFO:   Done with stage: EVALUATION
2022-11-22 23:53:11,390 INFO:   Leaving out SEQ value Fold_1
2022-11-22 23:53:11,403 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-22 23:53:11,403 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:53:12,075 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:53:12,075 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:53:12,144 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:53:12,144 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:53:12,144 INFO:     No hyperparam tuning for this model
2022-11-22 23:53:12,144 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:53:12,144 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:53:12,145 INFO:     None feature selector for col prot
2022-11-22 23:53:12,145 INFO:     None feature selector for col prot
2022-11-22 23:53:12,145 INFO:     None feature selector for col prot
2022-11-22 23:53:12,146 INFO:     None feature selector for col chem
2022-11-22 23:53:12,146 INFO:     None feature selector for col chem
2022-11-22 23:53:12,146 INFO:     None feature selector for col chem
2022-11-22 23:53:12,146 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:53:12,146 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:53:12,148 INFO:     Number of params in model 168571
2022-11-22 23:53:12,151 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:53:12,151 INFO:   Starting stage: TRAINING
2022-11-22 23:53:12,208 INFO:     Val loss before train {'Reaction outcome loss': 1.0041794291762418, 'Total loss': 1.0041794291762418}
2022-11-22 23:53:12,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:12,208 INFO:     Epoch: 0
2022-11-22 23:53:12,994 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8443040154701056, 'Total loss': 0.8443040154701056} | train loss {'Reaction outcome loss': 0.8755067325668571, 'Total loss': 0.8755067325668571}
2022-11-22 23:53:12,994 INFO:     Found new best model at epoch 0
2022-11-22 23:53:12,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:12,995 INFO:     Epoch: 1
2022-11-22 23:53:13,770 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8247887000095012, 'Total loss': 0.8247887000095012} | train loss {'Reaction outcome loss': 0.8492752291538097, 'Total loss': 0.8492752291538097}
2022-11-22 23:53:13,770 INFO:     Found new best model at epoch 1
2022-11-22 23:53:13,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:13,771 INFO:     Epoch: 2
2022-11-22 23:53:14,586 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8316522878269816, 'Total loss': 0.8316522878269816} | train loss {'Reaction outcome loss': 0.8462826515176168, 'Total loss': 0.8462826515176168}
2022-11-22 23:53:14,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:14,586 INFO:     Epoch: 3
2022-11-22 23:53:15,364 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8331338596898455, 'Total loss': 0.8331338596898455} | train loss {'Reaction outcome loss': 0.8381505552142736, 'Total loss': 0.8381505552142736}
2022-11-22 23:53:15,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:15,365 INFO:     Epoch: 4
2022-11-22 23:53:16,125 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8123199898143147, 'Total loss': 0.8123199898143147} | train loss {'Reaction outcome loss': 0.8293130152510026, 'Total loss': 0.8293130152510026}
2022-11-22 23:53:16,125 INFO:     Found new best model at epoch 4
2022-11-22 23:53:16,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:16,126 INFO:     Epoch: 5
2022-11-22 23:53:16,879 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8481989655383798, 'Total loss': 0.8481989655383798} | train loss {'Reaction outcome loss': 0.8265155290134649, 'Total loss': 0.8265155290134649}
2022-11-22 23:53:16,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:16,879 INFO:     Epoch: 6
2022-11-22 23:53:17,666 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8249927745308987, 'Total loss': 0.8249927745308987} | train loss {'Reaction outcome loss': 0.8272571236263087, 'Total loss': 0.8272571236263087}
2022-11-22 23:53:17,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:17,666 INFO:     Epoch: 7
2022-11-22 23:53:18,481 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8035937596199124, 'Total loss': 0.8035937596199124} | train loss {'Reaction outcome loss': 0.8265196994989498, 'Total loss': 0.8265196994989498}
2022-11-22 23:53:18,482 INFO:     Found new best model at epoch 7
2022-11-22 23:53:18,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:18,482 INFO:     Epoch: 8
2022-11-22 23:53:19,338 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8154693557772525, 'Total loss': 0.8154693557772525} | train loss {'Reaction outcome loss': 0.8260689843829276, 'Total loss': 0.8260689843829276}
2022-11-22 23:53:19,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:19,338 INFO:     Epoch: 9
2022-11-22 23:53:20,212 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8234940067280171, 'Total loss': 0.8234940067280171} | train loss {'Reaction outcome loss': 0.8199178302974858, 'Total loss': 0.8199178302974858}
2022-11-22 23:53:20,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:20,212 INFO:     Epoch: 10
2022-11-22 23:53:21,034 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8205129441826843, 'Total loss': 0.8205129441826843} | train loss {'Reaction outcome loss': 0.8165077385588438, 'Total loss': 0.8165077385588438}
2022-11-22 23:53:21,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:21,036 INFO:     Epoch: 11
2022-11-22 23:53:21,840 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8242073461066844, 'Total loss': 0.8242073461066844} | train loss {'Reaction outcome loss': 0.8195146658293013, 'Total loss': 0.8195146658293013}
2022-11-22 23:53:21,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:21,840 INFO:     Epoch: 12
2022-11-22 23:53:22,648 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8102753751499708, 'Total loss': 0.8102753751499708} | train loss {'Reaction outcome loss': 0.815323076375718, 'Total loss': 0.815323076375718}
2022-11-22 23:53:22,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:22,649 INFO:     Epoch: 13
2022-11-22 23:53:23,457 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8014390427012776, 'Total loss': 0.8014390427012776} | train loss {'Reaction outcome loss': 0.8202933736544087, 'Total loss': 0.8202933736544087}
2022-11-22 23:53:23,457 INFO:     Found new best model at epoch 13
2022-11-22 23:53:23,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:23,458 INFO:     Epoch: 14
2022-11-22 23:53:24,273 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8078658726326254, 'Total loss': 0.8078658726326254} | train loss {'Reaction outcome loss': 0.817964154751703, 'Total loss': 0.817964154751703}
2022-11-22 23:53:24,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:24,273 INFO:     Epoch: 15
2022-11-22 23:53:25,057 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8179604133894277, 'Total loss': 0.8179604133894277} | train loss {'Reaction outcome loss': 0.8159825945342029, 'Total loss': 0.8159825945342029}
2022-11-22 23:53:25,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:25,057 INFO:     Epoch: 16
2022-11-22 23:53:25,856 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8010217609793641, 'Total loss': 0.8010217609793641} | train loss {'Reaction outcome loss': 0.8082416128719785, 'Total loss': 0.8082416128719785}
2022-11-22 23:53:25,856 INFO:     Found new best model at epoch 16
2022-11-22 23:53:25,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:25,857 INFO:     Epoch: 17
2022-11-22 23:53:26,643 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.821922627299331, 'Total loss': 0.821922627299331} | train loss {'Reaction outcome loss': 0.8133571723115788, 'Total loss': 0.8133571723115788}
2022-11-22 23:53:26,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:26,643 INFO:     Epoch: 18
2022-11-22 23:53:27,417 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8063734839128893, 'Total loss': 0.8063734839128893} | train loss {'Reaction outcome loss': 0.8113950905485899, 'Total loss': 0.8113950905485899}
2022-11-22 23:53:27,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:27,418 INFO:     Epoch: 19
2022-11-22 23:53:28,192 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7922631003135858, 'Total loss': 0.7922631003135858} | train loss {'Reaction outcome loss': 0.8154860324084513, 'Total loss': 0.8154860324084513}
2022-11-22 23:53:28,192 INFO:     Found new best model at epoch 19
2022-11-22 23:53:28,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:28,193 INFO:     Epoch: 20
2022-11-22 23:53:28,980 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7964320411515791, 'Total loss': 0.7964320411515791} | train loss {'Reaction outcome loss': 0.8116239693184448, 'Total loss': 0.8116239693184448}
2022-11-22 23:53:28,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:28,981 INFO:     Epoch: 21
2022-11-22 23:53:29,760 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8266641622365907, 'Total loss': 0.8266641622365907} | train loss {'Reaction outcome loss': 0.8093145922623544, 'Total loss': 0.8093145922623544}
2022-11-22 23:53:29,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:29,760 INFO:     Epoch: 22
2022-11-22 23:53:30,525 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.796731315379919, 'Total loss': 0.796731315379919} | train loss {'Reaction outcome loss': 0.8108982992025069, 'Total loss': 0.8108982992025069}
2022-11-22 23:53:30,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:30,525 INFO:     Epoch: 23
2022-11-22 23:53:31,355 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8186695437098659, 'Total loss': 0.8186695437098659} | train loss {'Reaction outcome loss': 0.811450014879674, 'Total loss': 0.811450014879674}
2022-11-22 23:53:31,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:31,356 INFO:     Epoch: 24
2022-11-22 23:53:32,185 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7991457969643349, 'Total loss': 0.7991457969643349} | train loss {'Reaction outcome loss': 0.8173668640876504, 'Total loss': 0.8173668640876504}
2022-11-22 23:53:32,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:32,185 INFO:     Epoch: 25
2022-11-22 23:53:32,987 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8098999587602393, 'Total loss': 0.8098999587602393} | train loss {'Reaction outcome loss': 0.8138855156093958, 'Total loss': 0.8138855156093958}
2022-11-22 23:53:32,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:32,987 INFO:     Epoch: 26
2022-11-22 23:53:33,797 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7992812921834547, 'Total loss': 0.7992812921834547} | train loss {'Reaction outcome loss': 0.8095794542090883, 'Total loss': 0.8095794542090883}
2022-11-22 23:53:33,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:33,798 INFO:     Epoch: 27
2022-11-22 23:53:34,610 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8177985195503679, 'Total loss': 0.8177985195503679} | train loss {'Reaction outcome loss': 0.8086522346661414, 'Total loss': 0.8086522346661414}
2022-11-22 23:53:34,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:34,610 INFO:     Epoch: 28
2022-11-22 23:53:35,468 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7989670343177263, 'Total loss': 0.7989670343177263} | train loss {'Reaction outcome loss': 0.8124140413945594, 'Total loss': 0.8124140413945594}
2022-11-22 23:53:35,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:35,469 INFO:     Epoch: 29
2022-11-22 23:53:36,262 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7974405926327373, 'Total loss': 0.7974405926327373} | train loss {'Reaction outcome loss': 0.8084729007242147, 'Total loss': 0.8084729007242147}
2022-11-22 23:53:36,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:36,262 INFO:     Epoch: 30
2022-11-22 23:53:37,038 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8225065580634183, 'Total loss': 0.8225065580634183} | train loss {'Reaction outcome loss': 0.808482831029735, 'Total loss': 0.808482831029735}
2022-11-22 23:53:37,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:37,038 INFO:     Epoch: 31
2022-11-22 23:53:37,859 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7893457523612089, 'Total loss': 0.7893457523612089} | train loss {'Reaction outcome loss': 0.8088184725109933, 'Total loss': 0.8088184725109933}
2022-11-22 23:53:37,859 INFO:     Found new best model at epoch 31
2022-11-22 23:53:37,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:37,860 INFO:     Epoch: 32
2022-11-22 23:53:38,625 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8023381406484649, 'Total loss': 0.8023381406484649} | train loss {'Reaction outcome loss': 0.8118445450141106, 'Total loss': 0.8118445450141106}
2022-11-22 23:53:38,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:38,626 INFO:     Epoch: 33
2022-11-22 23:53:39,411 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7845327472963999, 'Total loss': 0.7845327472963999} | train loss {'Reaction outcome loss': 0.8071489808736024, 'Total loss': 0.8071489808736024}
2022-11-22 23:53:39,411 INFO:     Found new best model at epoch 33
2022-11-22 23:53:39,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:39,412 INFO:     Epoch: 34
2022-11-22 23:53:40,230 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7839308401872945, 'Total loss': 0.7839308401872945} | train loss {'Reaction outcome loss': 0.8081856138176389, 'Total loss': 0.8081856138176389}
2022-11-22 23:53:40,231 INFO:     Found new best model at epoch 34
2022-11-22 23:53:40,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:40,232 INFO:     Epoch: 35
2022-11-22 23:53:41,036 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7915202296057413, 'Total loss': 0.7915202296057413} | train loss {'Reaction outcome loss': 0.8043794532616934, 'Total loss': 0.8043794532616934}
2022-11-22 23:53:41,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:41,036 INFO:     Epoch: 36
2022-11-22 23:53:41,821 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.797020843555761, 'Total loss': 0.797020843555761} | train loss {'Reaction outcome loss': 0.8076234306572887, 'Total loss': 0.8076234306572887}
2022-11-22 23:53:41,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:41,821 INFO:     Epoch: 37
2022-11-22 23:53:42,625 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8727005234984464, 'Total loss': 0.8727005234984464} | train loss {'Reaction outcome loss': 0.8109073269759677, 'Total loss': 0.8109073269759677}
2022-11-22 23:53:42,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:42,625 INFO:     Epoch: 38
2022-11-22 23:53:43,430 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7958927535733511, 'Total loss': 0.7958927535733511} | train loss {'Reaction outcome loss': 0.8137453789573638, 'Total loss': 0.8137453789573638}
2022-11-22 23:53:43,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:43,430 INFO:     Epoch: 39
2022-11-22 23:53:44,261 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7931147896966269, 'Total loss': 0.7931147896966269} | train loss {'Reaction outcome loss': 0.8087550895940129, 'Total loss': 0.8087550895940129}
2022-11-22 23:53:44,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:44,262 INFO:     Epoch: 40
2022-11-22 23:53:45,088 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7843609590863072, 'Total loss': 0.7843609590863072} | train loss {'Reaction outcome loss': 0.8133728376631875, 'Total loss': 0.8133728376631875}
2022-11-22 23:53:45,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:45,088 INFO:     Epoch: 41
2022-11-22 23:53:45,922 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7824143067348835, 'Total loss': 0.7824143067348835} | train loss {'Reaction outcome loss': 0.810465094115999, 'Total loss': 0.810465094115999}
2022-11-22 23:53:45,923 INFO:     Found new best model at epoch 41
2022-11-22 23:53:45,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:45,923 INFO:     Epoch: 42
2022-11-22 23:53:46,755 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7956535497377085, 'Total loss': 0.7956535497377085} | train loss {'Reaction outcome loss': 0.8036392389992137, 'Total loss': 0.8036392389992137}
2022-11-22 23:53:46,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:46,755 INFO:     Epoch: 43
2022-11-22 23:53:47,552 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8142198934111484, 'Total loss': 0.8142198934111484} | train loss {'Reaction outcome loss': 0.8029039207799935, 'Total loss': 0.8029039207799935}
2022-11-22 23:53:47,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:47,552 INFO:     Epoch: 44
2022-11-22 23:53:48,380 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8099914068399474, 'Total loss': 0.8099914068399474} | train loss {'Reaction outcome loss': 0.8052280914391019, 'Total loss': 0.8052280914391019}
2022-11-22 23:53:48,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:48,380 INFO:     Epoch: 45
2022-11-22 23:53:49,199 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.800208908873935, 'Total loss': 0.800208908873935} | train loss {'Reaction outcome loss': 0.8134321429356626, 'Total loss': 0.8134321429356626}
2022-11-22 23:53:49,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:49,200 INFO:     Epoch: 46
2022-11-22 23:53:50,029 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7924790957639384, 'Total loss': 0.7924790957639384} | train loss {'Reaction outcome loss': 0.813829500243497, 'Total loss': 0.813829500243497}
2022-11-22 23:53:50,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:50,030 INFO:     Epoch: 47
2022-11-22 23:53:50,800 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7967690659123797, 'Total loss': 0.7967690659123797} | train loss {'Reaction outcome loss': 0.8035037355658449, 'Total loss': 0.8035037355658449}
2022-11-22 23:53:50,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:50,801 INFO:     Epoch: 48
2022-11-22 23:53:51,620 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7974885279356048, 'Total loss': 0.7974885279356048} | train loss {'Reaction outcome loss': 0.809408340557122, 'Total loss': 0.809408340557122}
2022-11-22 23:53:51,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:51,621 INFO:     Epoch: 49
2022-11-22 23:53:52,448 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7892216215300005, 'Total loss': 0.7892216215300005} | train loss {'Reaction outcome loss': 0.8104176571585023, 'Total loss': 0.8104176571585023}
2022-11-22 23:53:52,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:52,449 INFO:     Epoch: 50
2022-11-22 23:53:53,229 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8239518286183823, 'Total loss': 0.8239518286183823} | train loss {'Reaction outcome loss': 0.8021232930966365, 'Total loss': 0.8021232930966365}
2022-11-22 23:53:53,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:53,229 INFO:     Epoch: 51
2022-11-22 23:53:54,065 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7977583020232445, 'Total loss': 0.7977583020232445} | train loss {'Reaction outcome loss': 0.8154377115606771, 'Total loss': 0.8154377115606771}
2022-11-22 23:53:54,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:54,065 INFO:     Epoch: 52
2022-11-22 23:53:54,880 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8025504815023999, 'Total loss': 0.8025504815023999} | train loss {'Reaction outcome loss': 0.8069442450509641, 'Total loss': 0.8069442450509641}
2022-11-22 23:53:54,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:54,880 INFO:     Epoch: 53
2022-11-22 23:53:55,695 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.796347803154657, 'Total loss': 0.796347803154657} | train loss {'Reaction outcome loss': 0.8097428939470048, 'Total loss': 0.8097428939470048}
2022-11-22 23:53:55,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:55,696 INFO:     Epoch: 54
2022-11-22 23:53:56,458 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.783518138319947, 'Total loss': 0.783518138319947} | train loss {'Reaction outcome loss': 0.8080454270044962, 'Total loss': 0.8080454270044962}
2022-11-22 23:53:56,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:56,459 INFO:     Epoch: 55
2022-11-22 23:53:57,226 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8147776293200116, 'Total loss': 0.8147776293200116} | train loss {'Reaction outcome loss': 0.8076279440534458, 'Total loss': 0.8076279440534458}
2022-11-22 23:53:57,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:57,226 INFO:     Epoch: 56
2022-11-22 23:53:57,995 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.808120590309764, 'Total loss': 0.808120590309764} | train loss {'Reaction outcome loss': 0.8080095759144535, 'Total loss': 0.8080095759144535}
2022-11-22 23:53:57,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:57,996 INFO:     Epoch: 57
2022-11-22 23:53:58,772 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8018626196439876, 'Total loss': 0.8018626196439876} | train loss {'Reaction outcome loss': 0.8021935043634211, 'Total loss': 0.8021935043634211}
2022-11-22 23:53:58,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:58,772 INFO:     Epoch: 58
2022-11-22 23:53:59,566 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.799506967843965, 'Total loss': 0.799506967843965} | train loss {'Reaction outcome loss': 0.8020983667040067, 'Total loss': 0.8020983667040067}
2022-11-22 23:53:59,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:53:59,566 INFO:     Epoch: 59
2022-11-22 23:54:00,395 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7972491612268049, 'Total loss': 0.7972491612268049} | train loss {'Reaction outcome loss': 0.8081504571339722, 'Total loss': 0.8081504571339722}
2022-11-22 23:54:00,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:00,396 INFO:     Epoch: 60
2022-11-22 23:54:01,208 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.806205710699392, 'Total loss': 0.806205710699392} | train loss {'Reaction outcome loss': 0.8058859353938711, 'Total loss': 0.8058859353938711}
2022-11-22 23:54:01,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:01,208 INFO:     Epoch: 61
2022-11-22 23:54:02,000 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7938172276629958, 'Total loss': 0.7938172276629958} | train loss {'Reaction outcome loss': 0.8094573092068174, 'Total loss': 0.8094573092068174}
2022-11-22 23:54:02,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:02,000 INFO:     Epoch: 62
2022-11-22 23:54:02,790 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7937700041504794, 'Total loss': 0.7937700041504794} | train loss {'Reaction outcome loss': 0.8117733699549373, 'Total loss': 0.8117733699549373}
2022-11-22 23:54:02,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:02,790 INFO:     Epoch: 63
2022-11-22 23:54:03,600 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7931499647539716, 'Total loss': 0.7931499647539716} | train loss {'Reaction outcome loss': 0.8008525064943258, 'Total loss': 0.8008525064943258}
2022-11-22 23:54:03,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:03,601 INFO:     Epoch: 64
2022-11-22 23:54:04,409 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8023455558821212, 'Total loss': 0.8023455558821212} | train loss {'Reaction outcome loss': 0.8058183530475868, 'Total loss': 0.8058183530475868}
2022-11-22 23:54:04,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:04,409 INFO:     Epoch: 65
2022-11-22 23:54:05,216 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7853303821974023, 'Total loss': 0.7853303821974023} | train loss {'Reaction outcome loss': 0.805339756448573, 'Total loss': 0.805339756448573}
2022-11-22 23:54:05,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:05,217 INFO:     Epoch: 66
2022-11-22 23:54:06,027 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7988403176152429, 'Total loss': 0.7988403176152429} | train loss {'Reaction outcome loss': 0.8019043197357115, 'Total loss': 0.8019043197357115}
2022-11-22 23:54:06,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:06,028 INFO:     Epoch: 67
2022-11-22 23:54:06,789 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.814428344022396, 'Total loss': 0.814428344022396} | train loss {'Reaction outcome loss': 0.8050657134242509, 'Total loss': 0.8050657134242509}
2022-11-22 23:54:06,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:06,789 INFO:     Epoch: 68
2022-11-22 23:54:07,569 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8007573623989903, 'Total loss': 0.8007573623989903} | train loss {'Reaction outcome loss': 0.8064617356400431, 'Total loss': 0.8064617356400431}
2022-11-22 23:54:07,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:07,570 INFO:     Epoch: 69
2022-11-22 23:54:08,352 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.794876217842102, 'Total loss': 0.794876217842102} | train loss {'Reaction outcome loss': 0.804193749471947, 'Total loss': 0.804193749471947}
2022-11-22 23:54:08,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:08,353 INFO:     Epoch: 70
2022-11-22 23:54:09,117 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7843655264654825, 'Total loss': 0.7843655264654825} | train loss {'Reaction outcome loss': 0.8039827285480107, 'Total loss': 0.8039827285480107}
2022-11-22 23:54:09,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:09,117 INFO:     Epoch: 71
2022-11-22 23:54:09,934 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7876905313757963, 'Total loss': 0.7876905313757963} | train loss {'Reaction outcome loss': 0.8041232148560967, 'Total loss': 0.8041232148560967}
2022-11-22 23:54:09,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:09,934 INFO:     Epoch: 72
2022-11-22 23:54:10,749 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8046728795350984, 'Total loss': 0.8046728795350984} | train loss {'Reaction outcome loss': 0.8044295543996395, 'Total loss': 0.8044295543996395}
2022-11-22 23:54:10,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:10,750 INFO:     Epoch: 73
2022-11-22 23:54:11,543 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8119603069715722, 'Total loss': 0.8119603069715722} | train loss {'Reaction outcome loss': 0.8012003517199936, 'Total loss': 0.8012003517199936}
2022-11-22 23:54:11,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:11,543 INFO:     Epoch: 74
2022-11-22 23:54:12,319 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8060654568117719, 'Total loss': 0.8060654568117719} | train loss {'Reaction outcome loss': 0.8074098192615273, 'Total loss': 0.8074098192615273}
2022-11-22 23:54:12,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:12,320 INFO:     Epoch: 75
2022-11-22 23:54:13,099 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7791062829106353, 'Total loss': 0.7791062829106353} | train loss {'Reaction outcome loss': 0.7992233207196365, 'Total loss': 0.7992233207196365}
2022-11-22 23:54:13,099 INFO:     Found new best model at epoch 75
2022-11-22 23:54:13,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:13,100 INFO:     Epoch: 76
2022-11-22 23:54:13,895 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7949882413065711, 'Total loss': 0.7949882413065711} | train loss {'Reaction outcome loss': 0.8029469713997939, 'Total loss': 0.8029469713997939}
2022-11-22 23:54:13,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:13,895 INFO:     Epoch: 77
2022-11-22 23:54:14,732 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8050188442995382, 'Total loss': 0.8050188442995382} | train loss {'Reaction outcome loss': 0.804852996834021, 'Total loss': 0.804852996834021}
2022-11-22 23:54:14,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:14,732 INFO:     Epoch: 78
2022-11-22 23:54:15,527 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7956406183021013, 'Total loss': 0.7956406183021013} | train loss {'Reaction outcome loss': 0.8082319942030887, 'Total loss': 0.8082319942030887}
2022-11-22 23:54:15,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:15,528 INFO:     Epoch: 79
2022-11-22 23:54:16,281 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7928181734195975, 'Total loss': 0.7928181734195975} | train loss {'Reaction outcome loss': 0.8013364863984379, 'Total loss': 0.8013364863984379}
2022-11-22 23:54:16,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:16,281 INFO:     Epoch: 80
2022-11-22 23:54:17,118 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.790181381064792, 'Total loss': 0.790181381064792} | train loss {'Reaction outcome loss': 0.8002253200536893, 'Total loss': 0.8002253200536893}
2022-11-22 23:54:17,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:17,118 INFO:     Epoch: 81
2022-11-22 23:54:17,934 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8277247783749603, 'Total loss': 0.8277247783749603} | train loss {'Reaction outcome loss': 0.8072002293396389, 'Total loss': 0.8072002293396389}
2022-11-22 23:54:17,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:17,934 INFO:     Epoch: 82
2022-11-22 23:54:18,769 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.810054024291593, 'Total loss': 0.810054024291593} | train loss {'Reaction outcome loss': 0.8071045912342307, 'Total loss': 0.8071045912342307}
2022-11-22 23:54:18,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:18,769 INFO:     Epoch: 83
2022-11-22 23:54:19,580 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.802791225355725, 'Total loss': 0.802791225355725} | train loss {'Reaction outcome loss': 0.8094935592555215, 'Total loss': 0.8094935592555215}
2022-11-22 23:54:19,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:19,580 INFO:     Epoch: 84
2022-11-22 23:54:20,414 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8000754471435103, 'Total loss': 0.8000754471435103} | train loss {'Reaction outcome loss': 0.8050659633713004, 'Total loss': 0.8050659633713004}
2022-11-22 23:54:20,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:20,414 INFO:     Epoch: 85
2022-11-22 23:54:21,251 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7974169891934062, 'Total loss': 0.7974169891934062} | train loss {'Reaction outcome loss': 0.8079485281259434, 'Total loss': 0.8079485281259434}
2022-11-22 23:54:21,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:21,252 INFO:     Epoch: 86
2022-11-22 23:54:22,060 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7873870092769002, 'Total loss': 0.7873870092769002} | train loss {'Reaction outcome loss': 0.7997287699469814, 'Total loss': 0.7997287699469814}
2022-11-22 23:54:22,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:22,061 INFO:     Epoch: 87
2022-11-22 23:54:22,870 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7974000545435174, 'Total loss': 0.7974000545435174} | train loss {'Reaction outcome loss': 0.8017446280997477, 'Total loss': 0.8017446280997477}
2022-11-22 23:54:22,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:22,870 INFO:     Epoch: 88
2022-11-22 23:54:23,651 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8180635294248891, 'Total loss': 0.8180635294248891} | train loss {'Reaction outcome loss': 0.8028383378874618, 'Total loss': 0.8028383378874618}
2022-11-22 23:54:23,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:23,652 INFO:     Epoch: 89
2022-11-22 23:54:24,433 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7936797169751899, 'Total loss': 0.7936797169751899} | train loss {'Reaction outcome loss': 0.8152151317508133, 'Total loss': 0.8152151317508133}
2022-11-22 23:54:24,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:24,433 INFO:     Epoch: 90
2022-11-22 23:54:25,232 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8020110677841098, 'Total loss': 0.8020110677841098} | train loss {'Reaction outcome loss': 0.8033803514982938, 'Total loss': 0.8033803514982938}
2022-11-22 23:54:25,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:25,232 INFO:     Epoch: 91
2022-11-22 23:54:26,046 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8138705686081288, 'Total loss': 0.8138705686081288} | train loss {'Reaction outcome loss': 0.8049371995553067, 'Total loss': 0.8049371995553067}
2022-11-22 23:54:26,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:26,046 INFO:     Epoch: 92
2022-11-22 23:54:26,812 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7902472234049509, 'Total loss': 0.7902472234049509} | train loss {'Reaction outcome loss': 0.8017682761812406, 'Total loss': 0.8017682761812406}
2022-11-22 23:54:26,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:26,812 INFO:     Epoch: 93
2022-11-22 23:54:27,568 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7901383125504782, 'Total loss': 0.7901383125504782} | train loss {'Reaction outcome loss': 0.8047887768765045, 'Total loss': 0.8047887768765045}
2022-11-22 23:54:27,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:27,569 INFO:     Epoch: 94
2022-11-22 23:54:28,348 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8033477553101473, 'Total loss': 0.8033477553101473} | train loss {'Reaction outcome loss': 0.8004383671676181, 'Total loss': 0.8004383671676181}
2022-11-22 23:54:28,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:28,349 INFO:     Epoch: 95
2022-11-22 23:54:29,153 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7996379095454549, 'Total loss': 0.7996379095454549} | train loss {'Reaction outcome loss': 0.7987547814846039, 'Total loss': 0.7987547814846039}
2022-11-22 23:54:29,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:29,154 INFO:     Epoch: 96
2022-11-22 23:54:29,982 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8336794903112013, 'Total loss': 0.8336794903112013} | train loss {'Reaction outcome loss': 0.805104059324343, 'Total loss': 0.805104059324343}
2022-11-22 23:54:29,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:29,982 INFO:     Epoch: 97
2022-11-22 23:54:30,750 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7949866617834845, 'Total loss': 0.7949866617834845} | train loss {'Reaction outcome loss': 0.8009315444608774, 'Total loss': 0.8009315444608774}
2022-11-22 23:54:30,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:30,750 INFO:     Epoch: 98
2022-11-22 23:54:31,549 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8066083885902582, 'Total loss': 0.8066083885902582} | train loss {'Reaction outcome loss': 0.797704663173652, 'Total loss': 0.797704663173652}
2022-11-22 23:54:31,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:31,549 INFO:     Epoch: 99
2022-11-22 23:54:32,362 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.803014432275018, 'Total loss': 0.803014432275018} | train loss {'Reaction outcome loss': 0.8033112423655427, 'Total loss': 0.8033112423655427}
2022-11-22 23:54:32,362 INFO:     Best model found after epoch 76 of 100.
2022-11-22 23:54:32,362 INFO:   Done with stage: TRAINING
2022-11-22 23:54:32,362 INFO:   Starting stage: EVALUATION
2022-11-22 23:54:32,505 INFO:   Done with stage: EVALUATION
2022-11-22 23:54:32,505 INFO:   Leaving out SEQ value Fold_2
2022-11-22 23:54:32,518 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:54:32,519 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:54:33,179 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:54:33,180 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:54:33,248 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:54:33,248 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:54:33,249 INFO:     No hyperparam tuning for this model
2022-11-22 23:54:33,249 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:54:33,249 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:54:33,249 INFO:     None feature selector for col prot
2022-11-22 23:54:33,250 INFO:     None feature selector for col prot
2022-11-22 23:54:33,250 INFO:     None feature selector for col prot
2022-11-22 23:54:33,250 INFO:     None feature selector for col chem
2022-11-22 23:54:33,250 INFO:     None feature selector for col chem
2022-11-22 23:54:33,250 INFO:     None feature selector for col chem
2022-11-22 23:54:33,250 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:54:33,251 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:54:33,252 INFO:     Number of params in model 168571
2022-11-22 23:54:33,255 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:54:33,255 INFO:   Starting stage: TRAINING
2022-11-22 23:54:33,313 INFO:     Val loss before train {'Reaction outcome loss': 0.942311320792545, 'Total loss': 0.942311320792545}
2022-11-22 23:54:33,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:33,313 INFO:     Epoch: 0
2022-11-22 23:54:34,107 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.807634485038844, 'Total loss': 0.807634485038844} | train loss {'Reaction outcome loss': 0.8769423180987478, 'Total loss': 0.8769423180987478}
2022-11-22 23:54:34,107 INFO:     Found new best model at epoch 0
2022-11-22 23:54:34,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:34,108 INFO:     Epoch: 1
2022-11-22 23:54:34,913 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8192140730944547, 'Total loss': 0.8192140730944547} | train loss {'Reaction outcome loss': 0.8553022317558165, 'Total loss': 0.8553022317558165}
2022-11-22 23:54:34,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:34,913 INFO:     Epoch: 2
2022-11-22 23:54:35,750 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8016229475086386, 'Total loss': 0.8016229475086386} | train loss {'Reaction outcome loss': 0.8546532996994282, 'Total loss': 0.8546532996994282}
2022-11-22 23:54:35,750 INFO:     Found new best model at epoch 2
2022-11-22 23:54:35,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:35,751 INFO:     Epoch: 3
2022-11-22 23:54:36,524 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8168445669791915, 'Total loss': 0.8168445669791915} | train loss {'Reaction outcome loss': 0.8451372850158436, 'Total loss': 0.8451372850158436}
2022-11-22 23:54:36,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:36,524 INFO:     Epoch: 4
2022-11-22 23:54:37,345 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8537465530362996, 'Total loss': 0.8537465530362996} | train loss {'Reaction outcome loss': 0.8368374625077615, 'Total loss': 0.8368374625077615}
2022-11-22 23:54:37,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:37,345 INFO:     Epoch: 5
2022-11-22 23:54:38,178 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7842462198300795, 'Total loss': 0.7842462198300795} | train loss {'Reaction outcome loss': 0.8367691499742902, 'Total loss': 0.8367691499742902}
2022-11-22 23:54:38,179 INFO:     Found new best model at epoch 5
2022-11-22 23:54:38,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:38,179 INFO:     Epoch: 6
2022-11-22 23:54:38,977 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8066870739514177, 'Total loss': 0.8066870739514177} | train loss {'Reaction outcome loss': 0.8347185074770258, 'Total loss': 0.8347185074770258}
2022-11-22 23:54:38,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:38,978 INFO:     Epoch: 7
2022-11-22 23:54:39,805 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7894249653274362, 'Total loss': 0.7894249653274362} | train loss {'Reaction outcome loss': 0.8292403861819974, 'Total loss': 0.8292403861819974}
2022-11-22 23:54:39,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:39,805 INFO:     Epoch: 8
2022-11-22 23:54:40,643 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7901454611935399, 'Total loss': 0.7901454611935399} | train loss {'Reaction outcome loss': 0.8305373974898567, 'Total loss': 0.8305373974898567}
2022-11-22 23:54:40,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:40,644 INFO:     Epoch: 9
2022-11-22 23:54:41,481 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7989052046429027, 'Total loss': 0.7989052046429027} | train loss {'Reaction outcome loss': 0.8319353660349904, 'Total loss': 0.8319353660349904}
2022-11-22 23:54:41,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:41,482 INFO:     Epoch: 10
2022-11-22 23:54:42,343 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7975112843242559, 'Total loss': 0.7975112843242559} | train loss {'Reaction outcome loss': 0.8291307004839785, 'Total loss': 0.8291307004839785}
2022-11-22 23:54:42,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:42,344 INFO:     Epoch: 11
2022-11-22 23:54:43,134 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7844006547873671, 'Total loss': 0.7844006547873671} | train loss {'Reaction outcome loss': 0.8276162377977179, 'Total loss': 0.8276162377977179}
2022-11-22 23:54:43,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:43,135 INFO:     Epoch: 12
2022-11-22 23:54:43,958 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7896276461807165, 'Total loss': 0.7896276461807165} | train loss {'Reaction outcome loss': 0.8239765460433265, 'Total loss': 0.8239765460433265}
2022-11-22 23:54:43,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:43,958 INFO:     Epoch: 13
2022-11-22 23:54:44,783 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7794364602728323, 'Total loss': 0.7794364602728323} | train loss {'Reaction outcome loss': 0.8208127714361739, 'Total loss': 0.8208127714361739}
2022-11-22 23:54:44,783 INFO:     Found new best model at epoch 13
2022-11-22 23:54:44,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:44,784 INFO:     Epoch: 14
2022-11-22 23:54:45,627 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8004001785408367, 'Total loss': 0.8004001785408367} | train loss {'Reaction outcome loss': 0.8281382251123668, 'Total loss': 0.8281382251123668}
2022-11-22 23:54:45,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:45,627 INFO:     Epoch: 15
2022-11-22 23:54:46,457 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7800286398692564, 'Total loss': 0.7800286398692564} | train loss {'Reaction outcome loss': 0.8253483307747705, 'Total loss': 0.8253483307747705}
2022-11-22 23:54:46,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:46,457 INFO:     Epoch: 16
2022-11-22 23:54:47,234 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7995154302228581, 'Total loss': 0.7995154302228581} | train loss {'Reaction outcome loss': 0.8249709643574379, 'Total loss': 0.8249709643574379}
2022-11-22 23:54:47,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:47,234 INFO:     Epoch: 17
2022-11-22 23:54:48,036 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7921938943591985, 'Total loss': 0.7921938943591985} | train loss {'Reaction outcome loss': 0.8200190125055883, 'Total loss': 0.8200190125055883}
2022-11-22 23:54:48,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:48,037 INFO:     Epoch: 18
2022-11-22 23:54:48,837 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8007796481251717, 'Total loss': 0.8007796481251717} | train loss {'Reaction outcome loss': 0.8249134616813196, 'Total loss': 0.8249134616813196}
2022-11-22 23:54:48,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:48,837 INFO:     Epoch: 19
2022-11-22 23:54:49,671 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7860839712348852, 'Total loss': 0.7860839712348852} | train loss {'Reaction outcome loss': 0.8236944652520694, 'Total loss': 0.8236944652520694}
2022-11-22 23:54:49,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:49,671 INFO:     Epoch: 20
2022-11-22 23:54:50,510 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7743505496870388, 'Total loss': 0.7743505496870388} | train loss {'Reaction outcome loss': 0.828650127055674, 'Total loss': 0.828650127055674}
2022-11-22 23:54:50,510 INFO:     Found new best model at epoch 20
2022-11-22 23:54:50,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:50,511 INFO:     Epoch: 21
2022-11-22 23:54:51,354 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7928763113238595, 'Total loss': 0.7928763113238595} | train loss {'Reaction outcome loss': 0.8316858268459799, 'Total loss': 0.8316858268459799}
2022-11-22 23:54:51,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:51,354 INFO:     Epoch: 22
2022-11-22 23:54:52,148 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7771087729118087, 'Total loss': 0.7771087729118087} | train loss {'Reaction outcome loss': 0.8361345588678291, 'Total loss': 0.8361345588678291}
2022-11-22 23:54:52,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:52,149 INFO:     Epoch: 23
2022-11-22 23:54:52,932 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7746346816420555, 'Total loss': 0.7746346816420555} | train loss {'Reaction outcome loss': 0.835237723009789, 'Total loss': 0.835237723009789}
2022-11-22 23:54:52,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:52,932 INFO:     Epoch: 24
2022-11-22 23:54:53,735 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8165588582103903, 'Total loss': 0.8165588582103903} | train loss {'Reaction outcome loss': 0.8302607226226977, 'Total loss': 0.8302607226226977}
2022-11-22 23:54:53,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:53,736 INFO:     Epoch: 25
2022-11-22 23:54:54,499 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7927061116153543, 'Total loss': 0.7927061116153543} | train loss {'Reaction outcome loss': 0.8279556598257922, 'Total loss': 0.8279556598257922}
2022-11-22 23:54:54,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:54,499 INFO:     Epoch: 26
2022-11-22 23:54:55,295 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7827150110494007, 'Total loss': 0.7827150110494007} | train loss {'Reaction outcome loss': 0.8413719406977356, 'Total loss': 0.8413719406977356}
2022-11-22 23:54:55,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:55,295 INFO:     Epoch: 27
2022-11-22 23:54:56,095 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7938226495276798, 'Total loss': 0.7938226495276798} | train loss {'Reaction outcome loss': 0.8170538081859167, 'Total loss': 0.8170538081859167}
2022-11-22 23:54:56,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:56,095 INFO:     Epoch: 28
2022-11-22 23:54:56,885 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.780053177679127, 'Total loss': 0.780053177679127} | train loss {'Reaction outcome loss': 0.819061684584328, 'Total loss': 0.819061684584328}
2022-11-22 23:54:56,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:56,886 INFO:     Epoch: 29
2022-11-22 23:54:57,662 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7997555211186409, 'Total loss': 0.7997555211186409} | train loss {'Reaction outcome loss': 0.8238428290556317, 'Total loss': 0.8238428290556317}
2022-11-22 23:54:57,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:57,662 INFO:     Epoch: 30
2022-11-22 23:54:58,438 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7696980529210784, 'Total loss': 0.7696980529210784} | train loss {'Reaction outcome loss': 0.8263405712268613, 'Total loss': 0.8263405712268613}
2022-11-22 23:54:58,438 INFO:     Found new best model at epoch 30
2022-11-22 23:54:58,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:58,439 INFO:     Epoch: 31
2022-11-22 23:54:59,223 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7802400067448616, 'Total loss': 0.7802400067448616} | train loss {'Reaction outcome loss': 0.818346217184173, 'Total loss': 0.818346217184173}
2022-11-22 23:54:59,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:54:59,223 INFO:     Epoch: 32
2022-11-22 23:55:00,012 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7827530970627611, 'Total loss': 0.7827530970627611} | train loss {'Reaction outcome loss': 0.8202106181667884, 'Total loss': 0.8202106181667884}
2022-11-22 23:55:00,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:00,013 INFO:     Epoch: 33
2022-11-22 23:55:00,795 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7747820995070718, 'Total loss': 0.7747820995070718} | train loss {'Reaction outcome loss': 0.82106569961377, 'Total loss': 0.82106569961377}
2022-11-22 23:55:00,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:00,795 INFO:     Epoch: 34
2022-11-22 23:55:01,603 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.783059682358395, 'Total loss': 0.783059682358395} | train loss {'Reaction outcome loss': 0.819860677849426, 'Total loss': 0.819860677849426}
2022-11-22 23:55:01,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:01,603 INFO:     Epoch: 35
2022-11-22 23:55:02,389 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7900001338937066, 'Total loss': 0.7900001338937066} | train loss {'Reaction outcome loss': 0.8171059083842073, 'Total loss': 0.8171059083842073}
2022-11-22 23:55:02,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:02,390 INFO:     Epoch: 36
2022-11-22 23:55:03,194 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7869346331466328, 'Total loss': 0.7869346331466328} | train loss {'Reaction outcome loss': 0.8184608578802604, 'Total loss': 0.8184608578802604}
2022-11-22 23:55:03,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:03,195 INFO:     Epoch: 37
2022-11-22 23:55:04,032 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7773325023326006, 'Total loss': 0.7773325023326006} | train loss {'Reaction outcome loss': 0.8175234097218224, 'Total loss': 0.8175234097218224}
2022-11-22 23:55:04,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:04,033 INFO:     Epoch: 38
2022-11-22 23:55:04,848 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7935947694561698, 'Total loss': 0.7935947694561698} | train loss {'Reaction outcome loss': 0.8178966227873616, 'Total loss': 0.8178966227873616}
2022-11-22 23:55:04,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:04,848 INFO:     Epoch: 39
2022-11-22 23:55:05,716 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7760428908196363, 'Total loss': 0.7760428908196363} | train loss {'Reaction outcome loss': 0.8217395442700096, 'Total loss': 0.8217395442700096}
2022-11-22 23:55:05,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:05,716 INFO:     Epoch: 40
2022-11-22 23:55:06,559 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8096176379106261, 'Total loss': 0.8096176379106261} | train loss {'Reaction outcome loss': 0.8276883197216852, 'Total loss': 0.8276883197216852}
2022-11-22 23:55:06,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:06,559 INFO:     Epoch: 41
2022-11-22 23:55:07,375 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7859962569041685, 'Total loss': 0.7859962569041685} | train loss {'Reaction outcome loss': 0.8189968755129378, 'Total loss': 0.8189968755129378}
2022-11-22 23:55:07,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:07,375 INFO:     Epoch: 42
2022-11-22 23:55:08,169 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.76989561048421, 'Total loss': 0.76989561048421} | train loss {'Reaction outcome loss': 0.8177803004318885, 'Total loss': 0.8177803004318885}
2022-11-22 23:55:08,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:08,169 INFO:     Epoch: 43
2022-11-22 23:55:08,981 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.772126014937054, 'Total loss': 0.772126014937054} | train loss {'Reaction outcome loss': 0.8253191773466736, 'Total loss': 0.8253191773466736}
2022-11-22 23:55:08,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:08,981 INFO:     Epoch: 44
2022-11-22 23:55:09,817 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.786926574327729, 'Total loss': 0.786926574327729} | train loss {'Reaction outcome loss': 0.8265254930687337, 'Total loss': 0.8265254930687337}
2022-11-22 23:55:09,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:09,818 INFO:     Epoch: 45
2022-11-22 23:55:10,647 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7974014973098581, 'Total loss': 0.7974014973098581} | train loss {'Reaction outcome loss': 0.8222885981262454, 'Total loss': 0.8222885981262454}
2022-11-22 23:55:10,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:10,647 INFO:     Epoch: 46
2022-11-22 23:55:11,464 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7839091420173645, 'Total loss': 0.7839091420173645} | train loss {'Reaction outcome loss': 0.8210731368315848, 'Total loss': 0.8210731368315848}
2022-11-22 23:55:11,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:11,464 INFO:     Epoch: 47
2022-11-22 23:55:12,234 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7902803461660038, 'Total loss': 0.7902803461660038} | train loss {'Reaction outcome loss': 0.8151355511716262, 'Total loss': 0.8151355511716262}
2022-11-22 23:55:12,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:12,235 INFO:     Epoch: 48
2022-11-22 23:55:13,086 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.787077050994743, 'Total loss': 0.787077050994743} | train loss {'Reaction outcome loss': 0.8233192068362526, 'Total loss': 0.8233192068362526}
2022-11-22 23:55:13,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:13,086 INFO:     Epoch: 49
2022-11-22 23:55:13,884 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7832236025821079, 'Total loss': 0.7832236025821079} | train loss {'Reaction outcome loss': 0.817020813583845, 'Total loss': 0.817020813583845}
2022-11-22 23:55:13,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:13,884 INFO:     Epoch: 50
2022-11-22 23:55:14,676 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7889323315837167, 'Total loss': 0.7889323315837167} | train loss {'Reaction outcome loss': 0.8168218033275141, 'Total loss': 0.8168218033275141}
2022-11-22 23:55:14,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:14,677 INFO:     Epoch: 51
2022-11-22 23:55:15,454 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7745037227869034, 'Total loss': 0.7745037227869034} | train loss {'Reaction outcome loss': 0.8210623181059293, 'Total loss': 0.8210623181059293}
2022-11-22 23:55:15,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:15,454 INFO:     Epoch: 52
2022-11-22 23:55:16,266 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7864334833892909, 'Total loss': 0.7864334833892909} | train loss {'Reaction outcome loss': 0.8228995155708992, 'Total loss': 0.8228995155708992}
2022-11-22 23:55:16,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:16,266 INFO:     Epoch: 53
2022-11-22 23:55:17,034 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7987724867734042, 'Total loss': 0.7987724867734042} | train loss {'Reaction outcome loss': 0.8160213721305253, 'Total loss': 0.8160213721305253}
2022-11-22 23:55:17,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:17,034 INFO:     Epoch: 54
2022-11-22 23:55:17,831 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8252960226752541, 'Total loss': 0.8252960226752541} | train loss {'Reaction outcome loss': 0.8243827819824219, 'Total loss': 0.8243827819824219}
2022-11-22 23:55:17,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:17,832 INFO:     Epoch: 55
2022-11-22 23:55:18,650 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7850383852015842, 'Total loss': 0.7850383852015842} | train loss {'Reaction outcome loss': 0.8180297655373933, 'Total loss': 0.8180297655373933}
2022-11-22 23:55:18,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:18,651 INFO:     Epoch: 56
2022-11-22 23:55:19,461 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7858140238306739, 'Total loss': 0.7858140238306739} | train loss {'Reaction outcome loss': 0.8293858452847129, 'Total loss': 0.8293858452847129}
2022-11-22 23:55:19,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:19,462 INFO:     Epoch: 57
2022-11-22 23:55:20,293 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.778918361121958, 'Total loss': 0.778918361121958} | train loss {'Reaction outcome loss': 0.8195069094418514, 'Total loss': 0.8195069094418514}
2022-11-22 23:55:20,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:20,294 INFO:     Epoch: 58
2022-11-22 23:55:21,111 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7835152108560909, 'Total loss': 0.7835152108560909} | train loss {'Reaction outcome loss': 0.8262617924676733, 'Total loss': 0.8262617924676733}
2022-11-22 23:55:21,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:21,111 INFO:     Epoch: 59
2022-11-22 23:55:21,902 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7855685942552306, 'Total loss': 0.7855685942552306} | train loss {'Reaction outcome loss': 0.8245075838527216, 'Total loss': 0.8245075838527216}
2022-11-22 23:55:21,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:21,902 INFO:     Epoch: 60
2022-11-22 23:55:22,733 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7973011542450298, 'Total loss': 0.7973011542450298} | train loss {'Reaction outcome loss': 0.8142328948868431, 'Total loss': 0.8142328948868431}
2022-11-22 23:55:22,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:22,733 INFO:     Epoch: 61
2022-11-22 23:55:23,567 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7781377969817682, 'Total loss': 0.7781377969817682} | train loss {'Reaction outcome loss': 0.8225659766660528, 'Total loss': 0.8225659766660528}
2022-11-22 23:55:23,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:23,567 INFO:     Epoch: 62
2022-11-22 23:55:24,384 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7834708954800259, 'Total loss': 0.7834708954800259} | train loss {'Reaction outcome loss': 0.8207991310218086, 'Total loss': 0.8207991310218086}
2022-11-22 23:55:24,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:24,386 INFO:     Epoch: 63
2022-11-22 23:55:25,262 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.807156965136528, 'Total loss': 0.807156965136528} | train loss {'Reaction outcome loss': 0.8191870985183156, 'Total loss': 0.8191870985183156}
2022-11-22 23:55:25,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:25,262 INFO:     Epoch: 64
2022-11-22 23:55:26,073 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7800168875943531, 'Total loss': 0.7800168875943531} | train loss {'Reaction outcome loss': 0.814422869941725, 'Total loss': 0.814422869941725}
2022-11-22 23:55:26,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:26,074 INFO:     Epoch: 65
2022-11-22 23:55:26,924 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7913774902170355, 'Total loss': 0.7913774902170355} | train loss {'Reaction outcome loss': 0.82047313536227, 'Total loss': 0.82047313536227}
2022-11-22 23:55:26,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:26,924 INFO:     Epoch: 66
2022-11-22 23:55:27,717 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7784388735890388, 'Total loss': 0.7784388735890388} | train loss {'Reaction outcome loss': 0.8226695461311804, 'Total loss': 0.8226695461311804}
2022-11-22 23:55:27,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:27,717 INFO:     Epoch: 67
2022-11-22 23:55:28,559 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7710706239396875, 'Total loss': 0.7710706239396875} | train loss {'Reaction outcome loss': 0.8226120856850736, 'Total loss': 0.8226120856850736}
2022-11-22 23:55:28,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:28,559 INFO:     Epoch: 68
2022-11-22 23:55:29,382 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7760257477110083, 'Total loss': 0.7760257477110083} | train loss {'Reaction outcome loss': 0.8230956480329336, 'Total loss': 0.8230956480329336}
2022-11-22 23:55:29,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:29,383 INFO:     Epoch: 69
2022-11-22 23:55:30,239 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.78246759487824, 'Total loss': 0.78246759487824} | train loss {'Reaction outcome loss': 0.8181682037197144, 'Total loss': 0.8181682037197144}
2022-11-22 23:55:30,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:30,239 INFO:     Epoch: 70
2022-11-22 23:55:31,053 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7799282040108334, 'Total loss': 0.7799282040108334} | train loss {'Reaction outcome loss': 0.8149211197970849, 'Total loss': 0.8149211197970849}
2022-11-22 23:55:31,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:31,054 INFO:     Epoch: 71
2022-11-22 23:55:31,862 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7841137159954418, 'Total loss': 0.7841137159954418} | train loss {'Reaction outcome loss': 0.8238583703031425, 'Total loss': 0.8238583703031425}
2022-11-22 23:55:31,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:31,863 INFO:     Epoch: 72
2022-11-22 23:55:32,710 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7882111343470487, 'Total loss': 0.7882111343470487} | train loss {'Reaction outcome loss': 0.8220884855459576, 'Total loss': 0.8220884855459576}
2022-11-22 23:55:32,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:32,710 INFO:     Epoch: 73
2022-11-22 23:55:33,536 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7929237302054059, 'Total loss': 0.7929237302054059} | train loss {'Reaction outcome loss': 0.8175606943425621, 'Total loss': 0.8175606943425621}
2022-11-22 23:55:33,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:33,536 INFO:     Epoch: 74
2022-11-22 23:55:34,325 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7696513872254979, 'Total loss': 0.7696513872254979} | train loss {'Reaction outcome loss': 0.8224647127182377, 'Total loss': 0.8224647127182377}
2022-11-22 23:55:34,326 INFO:     Found new best model at epoch 74
2022-11-22 23:55:34,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:34,326 INFO:     Epoch: 75
2022-11-22 23:55:35,168 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7865776406093077, 'Total loss': 0.7865776406093077} | train loss {'Reaction outcome loss': 0.825810617884161, 'Total loss': 0.825810617884161}
2022-11-22 23:55:35,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:35,168 INFO:     Epoch: 76
2022-11-22 23:55:35,979 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7768736650997942, 'Total loss': 0.7768736650997942} | train loss {'Reaction outcome loss': 0.8181890891148493, 'Total loss': 0.8181890891148493}
2022-11-22 23:55:35,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:35,979 INFO:     Epoch: 77
2022-11-22 23:55:36,796 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7884223461151123, 'Total loss': 0.7884223461151123} | train loss {'Reaction outcome loss': 0.8207191815260451, 'Total loss': 0.8207191815260451}
2022-11-22 23:55:36,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:36,796 INFO:     Epoch: 78
2022-11-22 23:55:37,631 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.781319528140805, 'Total loss': 0.781319528140805} | train loss {'Reaction outcome loss': 0.8183840267390374, 'Total loss': 0.8183840267390374}
2022-11-22 23:55:37,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:37,631 INFO:     Epoch: 79
2022-11-22 23:55:38,446 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7980156534097411, 'Total loss': 0.7980156534097411} | train loss {'Reaction outcome loss': 0.8144250071422774, 'Total loss': 0.8144250071422774}
2022-11-22 23:55:38,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:38,446 INFO:     Epoch: 80
2022-11-22 23:55:39,260 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7800651687112722, 'Total loss': 0.7800651687112722} | train loss {'Reaction outcome loss': 0.8235373206225484, 'Total loss': 0.8235373206225484}
2022-11-22 23:55:39,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:39,260 INFO:     Epoch: 81
2022-11-22 23:55:40,087 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7958120371807705, 'Total loss': 0.7958120371807705} | train loss {'Reaction outcome loss': 0.8138807676581719, 'Total loss': 0.8138807676581719}
2022-11-22 23:55:40,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:40,087 INFO:     Epoch: 82
2022-11-22 23:55:40,868 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7728040570562537, 'Total loss': 0.7728040570562537} | train loss {'Reaction outcome loss': 0.8149603622765677, 'Total loss': 0.8149603622765677}
2022-11-22 23:55:40,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:40,868 INFO:     Epoch: 83
2022-11-22 23:55:41,667 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7683575302362442, 'Total loss': 0.7683575302362442} | train loss {'Reaction outcome loss': 0.8163583141106826, 'Total loss': 0.8163583141106826}
2022-11-22 23:55:41,667 INFO:     Found new best model at epoch 83
2022-11-22 23:55:41,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:41,668 INFO:     Epoch: 84
2022-11-22 23:55:42,487 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7794888080521063, 'Total loss': 0.7794888080521063} | train loss {'Reaction outcome loss': 0.8104815788355916, 'Total loss': 0.8104815788355916}
2022-11-22 23:55:42,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:42,487 INFO:     Epoch: 85
2022-11-22 23:55:43,316 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8095687817443501, 'Total loss': 0.8095687817443501} | train loss {'Reaction outcome loss': 0.8197598189477496, 'Total loss': 0.8197598189477496}
2022-11-22 23:55:43,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:43,317 INFO:     Epoch: 86
2022-11-22 23:55:44,130 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7913003685799512, 'Total loss': 0.7913003685799512} | train loss {'Reaction outcome loss': 0.8241442789432973, 'Total loss': 0.8241442789432973}
2022-11-22 23:55:44,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:44,130 INFO:     Epoch: 87
2022-11-22 23:55:44,954 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7828579040413554, 'Total loss': 0.7828579040413554} | train loss {'Reaction outcome loss': 0.8197041605768899, 'Total loss': 0.8197041605768899}
2022-11-22 23:55:44,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:44,954 INFO:     Epoch: 88
2022-11-22 23:55:45,757 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7995543947274034, 'Total loss': 0.7995543947274034} | train loss {'Reaction outcome loss': 0.8209636219539623, 'Total loss': 0.8209636219539623}
2022-11-22 23:55:45,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:45,757 INFO:     Epoch: 89
2022-11-22 23:55:46,541 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7865392741831866, 'Total loss': 0.7865392741831866} | train loss {'Reaction outcome loss': 0.8209219894669799, 'Total loss': 0.8209219894669799}
2022-11-22 23:55:46,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:46,542 INFO:     Epoch: 90
2022-11-22 23:55:47,362 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7881313792683862, 'Total loss': 0.7881313792683862} | train loss {'Reaction outcome loss': 0.8246779415288917, 'Total loss': 0.8246779415288917}
2022-11-22 23:55:47,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:47,362 INFO:     Epoch: 91
2022-11-22 23:55:48,182 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7800749296491797, 'Total loss': 0.7800749296491797} | train loss {'Reaction outcome loss': 0.8189629024339591, 'Total loss': 0.8189629024339591}
2022-11-22 23:55:48,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:48,182 INFO:     Epoch: 92
2022-11-22 23:55:48,996 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7998470264402303, 'Total loss': 0.7998470264402303} | train loss {'Reaction outcome loss': 0.8152381840505099, 'Total loss': 0.8152381840505099}
2022-11-22 23:55:48,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:48,997 INFO:     Epoch: 93
2022-11-22 23:55:49,793 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7816221077333797, 'Total loss': 0.7816221077333797} | train loss {'Reaction outcome loss': 0.8166584578693395, 'Total loss': 0.8166584578693395}
2022-11-22 23:55:49,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:49,794 INFO:     Epoch: 94
2022-11-22 23:55:50,577 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7781055596741763, 'Total loss': 0.7781055596741763} | train loss {'Reaction outcome loss': 0.8234868488813701, 'Total loss': 0.8234868488813701}
2022-11-22 23:55:50,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:50,577 INFO:     Epoch: 95
2022-11-22 23:55:51,390 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7779891206459566, 'Total loss': 0.7779891206459566} | train loss {'Reaction outcome loss': 0.8146805535202567, 'Total loss': 0.8146805535202567}
2022-11-22 23:55:51,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:51,390 INFO:     Epoch: 96
2022-11-22 23:55:52,239 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7955797301097349, 'Total loss': 0.7955797301097349} | train loss {'Reaction outcome loss': 0.8276644409426793, 'Total loss': 0.8276644409426793}
2022-11-22 23:55:52,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:52,240 INFO:     Epoch: 97
2022-11-22 23:55:53,050 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8043772117658095, 'Total loss': 0.8043772117658095} | train loss {'Reaction outcome loss': 0.8202408925000473, 'Total loss': 0.8202408925000473}
2022-11-22 23:55:53,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:53,051 INFO:     Epoch: 98
2022-11-22 23:55:53,887 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7877064828168262, 'Total loss': 0.7877064828168262} | train loss {'Reaction outcome loss': 0.8191162410535311, 'Total loss': 0.8191162410535311}
2022-11-22 23:55:53,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:53,887 INFO:     Epoch: 99
2022-11-22 23:55:54,703 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7773404910483144, 'Total loss': 0.7773404910483144} | train loss {'Reaction outcome loss': 0.8192279858567454, 'Total loss': 0.8192279858567454}
2022-11-22 23:55:54,703 INFO:     Best model found after epoch 84 of 100.
2022-11-22 23:55:54,703 INFO:   Done with stage: TRAINING
2022-11-22 23:55:54,703 INFO:   Starting stage: EVALUATION
2022-11-22 23:55:54,827 INFO:   Done with stage: EVALUATION
2022-11-22 23:55:54,827 INFO:   Leaving out SEQ value Fold_3
2022-11-22 23:55:54,840 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-22 23:55:54,841 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:55:55,502 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:55:55,502 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:55:55,571 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:55:55,571 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:55:55,571 INFO:     No hyperparam tuning for this model
2022-11-22 23:55:55,571 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:55:55,571 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:55:55,572 INFO:     None feature selector for col prot
2022-11-22 23:55:55,572 INFO:     None feature selector for col prot
2022-11-22 23:55:55,572 INFO:     None feature selector for col prot
2022-11-22 23:55:55,573 INFO:     None feature selector for col chem
2022-11-22 23:55:55,573 INFO:     None feature selector for col chem
2022-11-22 23:55:55,573 INFO:     None feature selector for col chem
2022-11-22 23:55:55,573 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:55:55,573 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:55:55,575 INFO:     Number of params in model 168571
2022-11-22 23:55:55,578 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:55:55,578 INFO:   Starting stage: TRAINING
2022-11-22 23:55:55,635 INFO:     Val loss before train {'Reaction outcome loss': 0.995098894418672, 'Total loss': 0.995098894418672}
2022-11-22 23:55:55,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:55,636 INFO:     Epoch: 0
2022-11-22 23:55:56,468 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8576934296031331, 'Total loss': 0.8576934296031331} | train loss {'Reaction outcome loss': 0.8783753335964485, 'Total loss': 0.8783753335964485}
2022-11-22 23:55:56,469 INFO:     Found new best model at epoch 0
2022-11-22 23:55:56,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:56,470 INFO:     Epoch: 1
2022-11-22 23:55:57,309 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8904854045357815, 'Total loss': 0.8904854045357815} | train loss {'Reaction outcome loss': 0.8442527001998463, 'Total loss': 0.8442527001998463}
2022-11-22 23:55:57,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:57,309 INFO:     Epoch: 2
2022-11-22 23:55:58,104 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8265869735285293, 'Total loss': 0.8265869735285293} | train loss {'Reaction outcome loss': 0.8436997301998685, 'Total loss': 0.8436997301998685}
2022-11-22 23:55:58,104 INFO:     Found new best model at epoch 2
2022-11-22 23:55:58,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:58,105 INFO:     Epoch: 3
2022-11-22 23:55:58,933 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8381385221037754, 'Total loss': 0.8381385221037754} | train loss {'Reaction outcome loss': 0.8248273501874971, 'Total loss': 0.8248273501874971}
2022-11-22 23:55:58,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:58,934 INFO:     Epoch: 4
2022-11-22 23:55:59,738 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8373480660970821, 'Total loss': 0.8373480660970821} | train loss {'Reaction outcome loss': 0.8249452584346787, 'Total loss': 0.8249452584346787}
2022-11-22 23:55:59,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:55:59,738 INFO:     Epoch: 5
2022-11-22 23:56:00,538 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8271745096805484, 'Total loss': 0.8271745096805484} | train loss {'Reaction outcome loss': 0.8166738161053814, 'Total loss': 0.8166738161053814}
2022-11-22 23:56:00,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:00,538 INFO:     Epoch: 6
2022-11-22 23:56:01,303 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8326878700145456, 'Total loss': 0.8326878700145456} | train loss {'Reaction outcome loss': 0.8148036568624074, 'Total loss': 0.8148036568624074}
2022-11-22 23:56:01,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:01,303 INFO:     Epoch: 7
2022-11-22 23:56:02,113 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8429350021273591, 'Total loss': 0.8429350021273591} | train loss {'Reaction outcome loss': 0.8162202566373543, 'Total loss': 0.8162202566373543}
2022-11-22 23:56:02,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:02,113 INFO:     Epoch: 8
2022-11-22 23:56:02,900 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8467358239861422, 'Total loss': 0.8467358239861422} | train loss {'Reaction outcome loss': 0.8148480545057625, 'Total loss': 0.8148480545057625}
2022-11-22 23:56:02,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:02,901 INFO:     Epoch: 9
2022-11-22 23:56:03,714 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8158403711263523, 'Total loss': 0.8158403711263523} | train loss {'Reaction outcome loss': 0.8135476135572449, 'Total loss': 0.8135476135572449}
2022-11-22 23:56:03,714 INFO:     Found new best model at epoch 9
2022-11-22 23:56:03,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:03,715 INFO:     Epoch: 10
2022-11-22 23:56:04,547 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8265875598718954, 'Total loss': 0.8265875598718954} | train loss {'Reaction outcome loss': 0.8118034290974258, 'Total loss': 0.8118034290974258}
2022-11-22 23:56:04,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:04,547 INFO:     Epoch: 11
2022-11-22 23:56:05,407 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8235393145749735, 'Total loss': 0.8235393145749735} | train loss {'Reaction outcome loss': 0.8146967223433198, 'Total loss': 0.8146967223433198}
2022-11-22 23:56:05,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:05,408 INFO:     Epoch: 12
2022-11-22 23:56:06,241 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8179036267968112, 'Total loss': 0.8179036267968112} | train loss {'Reaction outcome loss': 0.8136021838080688, 'Total loss': 0.8136021838080688}
2022-11-22 23:56:06,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:06,242 INFO:     Epoch: 13
2022-11-22 23:56:07,062 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8300058107043422, 'Total loss': 0.8300058107043422} | train loss {'Reaction outcome loss': 0.8115161320225137, 'Total loss': 0.8115161320225137}
2022-11-22 23:56:07,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:07,062 INFO:     Epoch: 14
2022-11-22 23:56:07,906 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8267924841060195, 'Total loss': 0.8267924841060195} | train loss {'Reaction outcome loss': 0.8116161975337833, 'Total loss': 0.8116161975337833}
2022-11-22 23:56:07,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:07,906 INFO:     Epoch: 15
2022-11-22 23:56:08,687 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8459970216418422, 'Total loss': 0.8459970216418422} | train loss {'Reaction outcome loss': 0.8129593118048105, 'Total loss': 0.8129593118048105}
2022-11-22 23:56:08,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:08,688 INFO:     Epoch: 16
2022-11-22 23:56:09,466 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.814546664093816, 'Total loss': 0.814546664093816} | train loss {'Reaction outcome loss': 0.8118588961050158, 'Total loss': 0.8118588961050158}
2022-11-22 23:56:09,467 INFO:     Found new best model at epoch 16
2022-11-22 23:56:09,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:09,467 INFO:     Epoch: 17
2022-11-22 23:56:10,279 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8180735125098118, 'Total loss': 0.8180735125098118} | train loss {'Reaction outcome loss': 0.8110975183424403, 'Total loss': 0.8110975183424403}
2022-11-22 23:56:10,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:10,279 INFO:     Epoch: 18
2022-11-22 23:56:11,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8248625078866648, 'Total loss': 0.8248625078866648} | train loss {'Reaction outcome loss': 0.812051642014355, 'Total loss': 0.812051642014355}
2022-11-22 23:56:11,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:11,066 INFO:     Epoch: 19
2022-11-22 23:56:11,905 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.841747242350911, 'Total loss': 0.841747242350911} | train loss {'Reaction outcome loss': 0.8118670735447133, 'Total loss': 0.8118670735447133}
2022-11-22 23:56:11,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:11,905 INFO:     Epoch: 20
2022-11-22 23:56:12,700 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8152022590470869, 'Total loss': 0.8152022590470869} | train loss {'Reaction outcome loss': 0.8103963968450906, 'Total loss': 0.8103963968450906}
2022-11-22 23:56:12,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:12,700 INFO:     Epoch: 21
2022-11-22 23:56:13,454 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8123798980269321, 'Total loss': 0.8123798980269321} | train loss {'Reaction outcome loss': 0.811345748236922, 'Total loss': 0.811345748236922}
2022-11-22 23:56:13,454 INFO:     Found new best model at epoch 21
2022-11-22 23:56:13,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:13,455 INFO:     Epoch: 22
2022-11-22 23:56:14,242 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8375325972257659, 'Total loss': 0.8375325972257659} | train loss {'Reaction outcome loss': 0.8149033242561778, 'Total loss': 0.8149033242561778}
2022-11-22 23:56:14,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:14,242 INFO:     Epoch: 23
2022-11-22 23:56:15,028 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8127868619076041, 'Total loss': 0.8127868619076041} | train loss {'Reaction outcome loss': 0.8095139068413953, 'Total loss': 0.8095139068413953}
2022-11-22 23:56:15,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:15,029 INFO:     Epoch: 24
2022-11-22 23:56:15,820 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8198663814123287, 'Total loss': 0.8198663814123287} | train loss {'Reaction outcome loss': 0.8136961090027309, 'Total loss': 0.8136961090027309}
2022-11-22 23:56:15,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:15,820 INFO:     Epoch: 25
2022-11-22 23:56:16,623 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.811168082231699, 'Total loss': 0.811168082231699} | train loss {'Reaction outcome loss': 0.8086336439505952, 'Total loss': 0.8086336439505952}
2022-11-22 23:56:16,623 INFO:     Found new best model at epoch 25
2022-11-22 23:56:16,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:16,624 INFO:     Epoch: 26
2022-11-22 23:56:17,475 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8196664785229882, 'Total loss': 0.8196664785229882} | train loss {'Reaction outcome loss': 0.8098008249138222, 'Total loss': 0.8098008249138222}
2022-11-22 23:56:17,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:17,475 INFO:     Epoch: 27
2022-11-22 23:56:18,240 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8239796133928521, 'Total loss': 0.8239796133928521} | train loss {'Reaction outcome loss': 0.8154364754674864, 'Total loss': 0.8154364754674864}
2022-11-22 23:56:18,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:18,241 INFO:     Epoch: 28
2022-11-22 23:56:19,080 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8273749885170959, 'Total loss': 0.8273749885170959} | train loss {'Reaction outcome loss': 0.8120570540672443, 'Total loss': 0.8120570540672443}
2022-11-22 23:56:19,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:19,081 INFO:     Epoch: 29
2022-11-22 23:56:19,872 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8108579571857009, 'Total loss': 0.8108579571857009} | train loss {'Reaction outcome loss': 0.8138943889834842, 'Total loss': 0.8138943889834842}
2022-11-22 23:56:19,872 INFO:     Found new best model at epoch 29
2022-11-22 23:56:19,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:19,873 INFO:     Epoch: 30
2022-11-22 23:56:20,719 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8272269368171692, 'Total loss': 0.8272269368171692} | train loss {'Reaction outcome loss': 0.8097642487922653, 'Total loss': 0.8097642487922653}
2022-11-22 23:56:20,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:20,719 INFO:     Epoch: 31
2022-11-22 23:56:21,584 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8275957003582356, 'Total loss': 0.8275957003582356} | train loss {'Reaction outcome loss': 0.8086792406488638, 'Total loss': 0.8086792406488638}
2022-11-22 23:56:21,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:21,584 INFO:     Epoch: 32
2022-11-22 23:56:22,406 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8214376901471337, 'Total loss': 0.8214376901471337} | train loss {'Reaction outcome loss': 0.8101988756021515, 'Total loss': 0.8101988756021515}
2022-11-22 23:56:22,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:22,406 INFO:     Epoch: 33
2022-11-22 23:56:23,195 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8321588878021684, 'Total loss': 0.8321588878021684} | train loss {'Reaction outcome loss': 0.8090661722617071, 'Total loss': 0.8090661722617071}
2022-11-22 23:56:23,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:23,195 INFO:     Epoch: 34
2022-11-22 23:56:24,008 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8207272928814555, 'Total loss': 0.8207272928814555} | train loss {'Reaction outcome loss': 0.8104123090867137, 'Total loss': 0.8104123090867137}
2022-11-22 23:56:24,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:24,009 INFO:     Epoch: 35
2022-11-22 23:56:24,810 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8365429431893104, 'Total loss': 0.8365429431893104} | train loss {'Reaction outcome loss': 0.8090775401377287, 'Total loss': 0.8090775401377287}
2022-11-22 23:56:24,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:24,811 INFO:     Epoch: 36
2022-11-22 23:56:25,636 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8500443551429483, 'Total loss': 0.8500443551429483} | train loss {'Reaction outcome loss': 0.8101104199886322, 'Total loss': 0.8101104199886322}
2022-11-22 23:56:25,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:25,636 INFO:     Epoch: 37
2022-11-22 23:56:26,422 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8210261422534322, 'Total loss': 0.8210261422534322} | train loss {'Reaction outcome loss': 0.8101883254578857, 'Total loss': 0.8101883254578857}
2022-11-22 23:56:26,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:26,422 INFO:     Epoch: 38
2022-11-22 23:56:27,219 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8288999199867249, 'Total loss': 0.8288999199867249} | train loss {'Reaction outcome loss': 0.8121480861159621, 'Total loss': 0.8121480861159621}
2022-11-22 23:56:27,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:27,221 INFO:     Epoch: 39
2022-11-22 23:56:28,045 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.814500957034355, 'Total loss': 0.814500957034355} | train loss {'Reaction outcome loss': 0.811899721256045, 'Total loss': 0.811899721256045}
2022-11-22 23:56:28,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:28,045 INFO:     Epoch: 40
2022-11-22 23:56:28,847 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8518127799034119, 'Total loss': 0.8518127799034119} | train loss {'Reaction outcome loss': 0.8084053308015964, 'Total loss': 0.8084053308015964}
2022-11-22 23:56:28,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:28,847 INFO:     Epoch: 41
2022-11-22 23:56:29,635 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8190097774184028, 'Total loss': 0.8190097774184028} | train loss {'Reaction outcome loss': 0.8155148809806245, 'Total loss': 0.8155148809806245}
2022-11-22 23:56:29,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:29,636 INFO:     Epoch: 42
2022-11-22 23:56:30,410 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.829279559296231, 'Total loss': 0.829279559296231} | train loss {'Reaction outcome loss': 0.8119563826772033, 'Total loss': 0.8119563826772033}
2022-11-22 23:56:30,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:30,410 INFO:     Epoch: 43
2022-11-22 23:56:31,223 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8232484903446463, 'Total loss': 0.8232484903446463} | train loss {'Reaction outcome loss': 0.8065909710331042, 'Total loss': 0.8065909710331042}
2022-11-22 23:56:31,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:31,223 INFO:     Epoch: 44
2022-11-22 23:56:32,014 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8216461962045625, 'Total loss': 0.8216461962045625} | train loss {'Reaction outcome loss': 0.8116461502724006, 'Total loss': 0.8116461502724006}
2022-11-22 23:56:32,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:32,014 INFO:     Epoch: 45
2022-11-22 23:56:32,783 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8242638935876447, 'Total loss': 0.8242638935876447} | train loss {'Reaction outcome loss': 0.8149949911920751, 'Total loss': 0.8149949911920751}
2022-11-22 23:56:32,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:32,783 INFO:     Epoch: 46
2022-11-22 23:56:33,595 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8276904260003289, 'Total loss': 0.8276904260003289} | train loss {'Reaction outcome loss': 0.8109374085410697, 'Total loss': 0.8109374085410697}
2022-11-22 23:56:33,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:33,596 INFO:     Epoch: 47
2022-11-22 23:56:34,405 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8194506653519564, 'Total loss': 0.8194506653519564} | train loss {'Reaction outcome loss': 0.8154470623760927, 'Total loss': 0.8154470623760927}
2022-11-22 23:56:34,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:34,405 INFO:     Epoch: 48
2022-11-22 23:56:35,176 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8165196998174801, 'Total loss': 0.8165196998174801} | train loss {'Reaction outcome loss': 0.8119885502535789, 'Total loss': 0.8119885502535789}
2022-11-22 23:56:35,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:35,176 INFO:     Epoch: 49
2022-11-22 23:56:35,957 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8185422656147979, 'Total loss': 0.8185422656147979} | train loss {'Reaction outcome loss': 0.8087101809558321, 'Total loss': 0.8087101809558321}
2022-11-22 23:56:35,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:35,957 INFO:     Epoch: 50
2022-11-22 23:56:36,776 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8138912957768107, 'Total loss': 0.8138912957768107} | train loss {'Reaction outcome loss': 0.8103078038233226, 'Total loss': 0.8103078038233226}
2022-11-22 23:56:36,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:36,777 INFO:     Epoch: 51
2022-11-22 23:56:37,587 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8385040621424831, 'Total loss': 0.8385040621424831} | train loss {'Reaction outcome loss': 0.8096978457980468, 'Total loss': 0.8096978457980468}
2022-11-22 23:56:37,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:37,587 INFO:     Epoch: 52
2022-11-22 23:56:38,426 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8248227571332177, 'Total loss': 0.8248227571332177} | train loss {'Reaction outcome loss': 0.8122065502112029, 'Total loss': 0.8122065502112029}
2022-11-22 23:56:38,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:38,426 INFO:     Epoch: 53
2022-11-22 23:56:39,215 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8197461241899535, 'Total loss': 0.8197461241899535} | train loss {'Reaction outcome loss': 0.8097627811500283, 'Total loss': 0.8097627811500283}
2022-11-22 23:56:39,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:39,215 INFO:     Epoch: 54
2022-11-22 23:56:40,023 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8197294293447982, 'Total loss': 0.8197294293447982} | train loss {'Reaction outcome loss': 0.8083248863943288, 'Total loss': 0.8083248863943288}
2022-11-22 23:56:40,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:40,023 INFO:     Epoch: 55
2022-11-22 23:56:40,821 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8287426108537719, 'Total loss': 0.8287426108537719} | train loss {'Reaction outcome loss': 0.8091985226654616, 'Total loss': 0.8091985226654616}
2022-11-22 23:56:40,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:40,821 INFO:     Epoch: 56
2022-11-22 23:56:41,613 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8304559429024541, 'Total loss': 0.8304559429024541} | train loss {'Reaction outcome loss': 0.8095192399914147, 'Total loss': 0.8095192399914147}
2022-11-22 23:56:41,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:41,613 INFO:     Epoch: 57
2022-11-22 23:56:42,392 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8399265685746836, 'Total loss': 0.8399265685746836} | train loss {'Reaction outcome loss': 0.8135845372911359, 'Total loss': 0.8135845372911359}
2022-11-22 23:56:42,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:42,392 INFO:     Epoch: 58
2022-11-22 23:56:43,209 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8346564360829287, 'Total loss': 0.8346564360829287} | train loss {'Reaction outcome loss': 0.8096776168610229, 'Total loss': 0.8096776168610229}
2022-11-22 23:56:43,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:43,209 INFO:     Epoch: 59
2022-11-22 23:56:43,987 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8236185755840567, 'Total loss': 0.8236185755840567} | train loss {'Reaction outcome loss': 0.8120857202371613, 'Total loss': 0.8120857202371613}
2022-11-22 23:56:43,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:43,987 INFO:     Epoch: 60
2022-11-22 23:56:44,807 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8285625632419142, 'Total loss': 0.8285625632419142} | train loss {'Reaction outcome loss': 0.8103834615379083, 'Total loss': 0.8103834615379083}
2022-11-22 23:56:44,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:44,807 INFO:     Epoch: 61
2022-11-22 23:56:45,650 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8372945660768554, 'Total loss': 0.8372945660768554} | train loss {'Reaction outcome loss': 0.8130339932490568, 'Total loss': 0.8130339932490568}
2022-11-22 23:56:45,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:45,651 INFO:     Epoch: 62
2022-11-22 23:56:46,434 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8243104163990465, 'Total loss': 0.8243104163990465} | train loss {'Reaction outcome loss': 0.8133888134702307, 'Total loss': 0.8133888134702307}
2022-11-22 23:56:46,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:46,435 INFO:     Epoch: 63
2022-11-22 23:56:47,276 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8176328221032786, 'Total loss': 0.8176328221032786} | train loss {'Reaction outcome loss': 0.814200226889282, 'Total loss': 0.814200226889282}
2022-11-22 23:56:47,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:47,276 INFO:     Epoch: 64
2022-11-22 23:56:48,109 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.821356488521709, 'Total loss': 0.821356488521709} | train loss {'Reaction outcome loss': 0.8100262853454371, 'Total loss': 0.8100262853454371}
2022-11-22 23:56:48,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:48,109 INFO:     Epoch: 65
2022-11-22 23:56:48,898 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8234406612640204, 'Total loss': 0.8234406612640204} | train loss {'Reaction outcome loss': 0.8112517695446484, 'Total loss': 0.8112517695446484}
2022-11-22 23:56:48,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:48,899 INFO:     Epoch: 66
2022-11-22 23:56:49,725 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.825099028127138, 'Total loss': 0.825099028127138} | train loss {'Reaction outcome loss': 0.8113014628408385, 'Total loss': 0.8113014628408385}
2022-11-22 23:56:49,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:49,726 INFO:     Epoch: 67
2022-11-22 23:56:50,500 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8244801260704218, 'Total loss': 0.8244801260704218} | train loss {'Reaction outcome loss': 0.8127177163469986, 'Total loss': 0.8127177163469986}
2022-11-22 23:56:50,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:50,501 INFO:     Epoch: 68
2022-11-22 23:56:51,318 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8103792681250461, 'Total loss': 0.8103792681250461} | train loss {'Reaction outcome loss': 0.8126386142656451, 'Total loss': 0.8126386142656451}
2022-11-22 23:56:51,318 INFO:     Found new best model at epoch 68
2022-11-22 23:56:51,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:51,319 INFO:     Epoch: 69
2022-11-22 23:56:52,104 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8353710902291674, 'Total loss': 0.8353710902291674} | train loss {'Reaction outcome loss': 0.81151894846412, 'Total loss': 0.81151894846412}
2022-11-22 23:56:52,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:52,104 INFO:     Epoch: 70
2022-11-22 23:56:52,889 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8231049193892368, 'Total loss': 0.8231049193892368} | train loss {'Reaction outcome loss': 0.8134478411225022, 'Total loss': 0.8134478411225022}
2022-11-22 23:56:52,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:52,890 INFO:     Epoch: 71
2022-11-22 23:56:53,685 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.827739113985106, 'Total loss': 0.827739113985106} | train loss {'Reaction outcome loss': 0.8116357741785831, 'Total loss': 0.8116357741785831}
2022-11-22 23:56:53,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:53,685 INFO:     Epoch: 72
2022-11-22 23:56:54,445 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8156605030215064, 'Total loss': 0.8156605030215064} | train loss {'Reaction outcome loss': 0.8098382716540431, 'Total loss': 0.8098382716540431}
2022-11-22 23:56:54,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:54,445 INFO:     Epoch: 73
2022-11-22 23:56:55,300 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8213245695413545, 'Total loss': 0.8213245695413545} | train loss {'Reaction outcome loss': 0.8080853010054494, 'Total loss': 0.8080853010054494}
2022-11-22 23:56:55,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:55,300 INFO:     Epoch: 74
2022-11-22 23:56:56,183 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8177477502545645, 'Total loss': 0.8177477502545645} | train loss {'Reaction outcome loss': 0.8136828594276162, 'Total loss': 0.8136828594276162}
2022-11-22 23:56:56,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:56,183 INFO:     Epoch: 75
2022-11-22 23:56:57,046 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8127569202766862, 'Total loss': 0.8127569202766862} | train loss {'Reaction outcome loss': 0.8117707786989994, 'Total loss': 0.8117707786989994}
2022-11-22 23:56:57,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:57,047 INFO:     Epoch: 76
2022-11-22 23:56:57,876 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.811550825141197, 'Total loss': 0.811550825141197} | train loss {'Reaction outcome loss': 0.8082586668553899, 'Total loss': 0.8082586668553899}
2022-11-22 23:56:57,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:57,877 INFO:     Epoch: 77
2022-11-22 23:56:58,778 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8289442963378374, 'Total loss': 0.8289442963378374} | train loss {'Reaction outcome loss': 0.8039169249231698, 'Total loss': 0.8039169249231698}
2022-11-22 23:56:58,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:58,779 INFO:     Epoch: 78
2022-11-22 23:56:59,591 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8488228404244711, 'Total loss': 0.8488228404244711} | train loss {'Reaction outcome loss': 0.8124284900602747, 'Total loss': 0.8124284900602747}
2022-11-22 23:56:59,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:56:59,592 INFO:     Epoch: 79
2022-11-22 23:57:00,438 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8266294182733048, 'Total loss': 0.8266294182733048} | train loss {'Reaction outcome loss': 0.8079493071456425, 'Total loss': 0.8079493071456425}
2022-11-22 23:57:00,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:00,438 INFO:     Epoch: 80
2022-11-22 23:57:01,345 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8213943284611369, 'Total loss': 0.8213943284611369} | train loss {'Reaction outcome loss': 0.8098415182750733, 'Total loss': 0.8098415182750733}
2022-11-22 23:57:01,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:01,345 INFO:     Epoch: 81
2022-11-22 23:57:02,265 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8191171745921291, 'Total loss': 0.8191171745921291} | train loss {'Reaction outcome loss': 0.8123752422264365, 'Total loss': 0.8123752422264365}
2022-11-22 23:57:02,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:02,266 INFO:     Epoch: 82
2022-11-22 23:57:03,155 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8329883661381033, 'Total loss': 0.8329883661381033} | train loss {'Reaction outcome loss': 0.8113924914696178, 'Total loss': 0.8113924914696178}
2022-11-22 23:57:03,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:03,156 INFO:     Epoch: 83
2022-11-22 23:57:04,016 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8203641647516295, 'Total loss': 0.8203641647516295} | train loss {'Reaction outcome loss': 0.8111504188082257, 'Total loss': 0.8111504188082257}
2022-11-22 23:57:04,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:04,017 INFO:     Epoch: 84
2022-11-22 23:57:04,915 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8379029465276141, 'Total loss': 0.8379029465276141} | train loss {'Reaction outcome loss': 0.8094741858419825, 'Total loss': 0.8094741858419825}
2022-11-22 23:57:04,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:04,915 INFO:     Epoch: 85
2022-11-22 23:57:05,808 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8215687434340633, 'Total loss': 0.8215687434340633} | train loss {'Reaction outcome loss': 0.811095048413902, 'Total loss': 0.811095048413902}
2022-11-22 23:57:05,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:05,808 INFO:     Epoch: 86
2022-11-22 23:57:06,724 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8351580126340999, 'Total loss': 0.8351580126340999} | train loss {'Reaction outcome loss': 0.8127796923527952, 'Total loss': 0.8127796923527952}
2022-11-22 23:57:06,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:06,724 INFO:     Epoch: 87
2022-11-22 23:57:07,675 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8250684654989908, 'Total loss': 0.8250684654989908} | train loss {'Reaction outcome loss': 0.8117477617791442, 'Total loss': 0.8117477617791442}
2022-11-22 23:57:07,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:07,675 INFO:     Epoch: 88
2022-11-22 23:57:08,536 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8300803282926249, 'Total loss': 0.8300803282926249} | train loss {'Reaction outcome loss': 0.8133961414215994, 'Total loss': 0.8133961414215994}
2022-11-22 23:57:08,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:08,537 INFO:     Epoch: 89
2022-11-22 23:57:09,448 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8287017026612925, 'Total loss': 0.8287017026612925} | train loss {'Reaction outcome loss': 0.810695436890008, 'Total loss': 0.810695436890008}
2022-11-22 23:57:09,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:09,448 INFO:     Epoch: 90
2022-11-22 23:57:10,354 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8207590857217478, 'Total loss': 0.8207590857217478} | train loss {'Reaction outcome loss': 0.8093248049988121, 'Total loss': 0.8093248049988121}
2022-11-22 23:57:10,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:10,355 INFO:     Epoch: 91
2022-11-22 23:57:11,252 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8365150967309641, 'Total loss': 0.8365150967309641} | train loss {'Reaction outcome loss': 0.8115251539427726, 'Total loss': 0.8115251539427726}
2022-11-22 23:57:11,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:11,253 INFO:     Epoch: 92
2022-11-22 23:57:12,161 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8140912797561911, 'Total loss': 0.8140912797561911} | train loss {'Reaction outcome loss': 0.8152635027883482, 'Total loss': 0.8152635027883482}
2022-11-22 23:57:12,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:12,161 INFO:     Epoch: 93
2022-11-22 23:57:13,097 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8133795434652373, 'Total loss': 0.8133795434652373} | train loss {'Reaction outcome loss': 0.8088239629249103, 'Total loss': 0.8088239629249103}
2022-11-22 23:57:13,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:13,097 INFO:     Epoch: 94
2022-11-22 23:57:13,958 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8251816748186599, 'Total loss': 0.8251816748186599} | train loss {'Reaction outcome loss': 0.8069948031276953, 'Total loss': 0.8069948031276953}
2022-11-22 23:57:13,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:13,958 INFO:     Epoch: 95
2022-11-22 23:57:14,823 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8356302366700283, 'Total loss': 0.8356302366700283} | train loss {'Reaction outcome loss': 0.8126530209403546, 'Total loss': 0.8126530209403546}
2022-11-22 23:57:14,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:14,823 INFO:     Epoch: 96
2022-11-22 23:57:15,736 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8251898240211398, 'Total loss': 0.8251898240211398} | train loss {'Reaction outcome loss': 0.8093435485832027, 'Total loss': 0.8093435485832027}
2022-11-22 23:57:15,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:15,736 INFO:     Epoch: 97
2022-11-22 23:57:16,594 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8234689706979796, 'Total loss': 0.8234689706979796} | train loss {'Reaction outcome loss': 0.807359736107412, 'Total loss': 0.807359736107412}
2022-11-22 23:57:16,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:16,596 INFO:     Epoch: 98
2022-11-22 23:57:17,507 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8163873213668202, 'Total loss': 0.8163873213668202} | train loss {'Reaction outcome loss': 0.8085816242411489, 'Total loss': 0.8085816242411489}
2022-11-22 23:57:17,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:17,508 INFO:     Epoch: 99
2022-11-22 23:57:18,403 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8196473592935607, 'Total loss': 0.8196473592935607} | train loss {'Reaction outcome loss': 0.8080687277385445, 'Total loss': 0.8080687277385445}
2022-11-22 23:57:18,403 INFO:     Best model found after epoch 69 of 100.
2022-11-22 23:57:18,403 INFO:   Done with stage: TRAINING
2022-11-22 23:57:18,403 INFO:   Starting stage: EVALUATION
2022-11-22 23:57:18,540 INFO:   Done with stage: EVALUATION
2022-11-22 23:57:18,541 INFO:   Leaving out SEQ value Fold_4
2022-11-22 23:57:18,554 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-22 23:57:18,554 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:57:19,238 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:57:19,239 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:57:19,311 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:57:19,311 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:57:19,311 INFO:     No hyperparam tuning for this model
2022-11-22 23:57:19,311 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:57:19,311 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:57:19,312 INFO:     None feature selector for col prot
2022-11-22 23:57:19,312 INFO:     None feature selector for col prot
2022-11-22 23:57:19,312 INFO:     None feature selector for col prot
2022-11-22 23:57:19,313 INFO:     None feature selector for col chem
2022-11-22 23:57:19,313 INFO:     None feature selector for col chem
2022-11-22 23:57:19,313 INFO:     None feature selector for col chem
2022-11-22 23:57:19,313 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:57:19,313 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:57:19,314 INFO:     Number of params in model 168571
2022-11-22 23:57:19,318 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:57:19,318 INFO:   Starting stage: TRAINING
2022-11-22 23:57:19,381 INFO:     Val loss before train {'Reaction outcome loss': 0.992047590288249, 'Total loss': 0.992047590288249}
2022-11-22 23:57:19,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:19,381 INFO:     Epoch: 0
2022-11-22 23:57:20,312 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8092875548384406, 'Total loss': 0.8092875548384406} | train loss {'Reaction outcome loss': 0.8983290304820384, 'Total loss': 0.8983290304820384}
2022-11-22 23:57:20,312 INFO:     Found new best model at epoch 0
2022-11-22 23:57:20,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:20,313 INFO:     Epoch: 1
2022-11-22 23:57:21,218 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.812965986403552, 'Total loss': 0.812965986403552} | train loss {'Reaction outcome loss': 0.8624644980074898, 'Total loss': 0.8624644980074898}
2022-11-22 23:57:21,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:21,218 INFO:     Epoch: 2
2022-11-22 23:57:22,094 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8221173868937925, 'Total loss': 0.8221173868937925} | train loss {'Reaction outcome loss': 0.855694149170191, 'Total loss': 0.855694149170191}
2022-11-22 23:57:22,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:22,095 INFO:     Epoch: 3
2022-11-22 23:57:23,010 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8170803317969496, 'Total loss': 0.8170803317969496} | train loss {'Reaction outcome loss': 0.8533165025855264, 'Total loss': 0.8533165025855264}
2022-11-22 23:57:23,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:23,010 INFO:     Epoch: 4
2022-11-22 23:57:23,931 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8295466371557929, 'Total loss': 0.8295466371557929} | train loss {'Reaction outcome loss': 0.8472184317727243, 'Total loss': 0.8472184317727243}
2022-11-22 23:57:23,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:23,931 INFO:     Epoch: 5
2022-11-22 23:57:24,808 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8061637878417969, 'Total loss': 0.8061637878417969} | train loss {'Reaction outcome loss': 0.8464945851554794, 'Total loss': 0.8464945851554794}
2022-11-22 23:57:24,808 INFO:     Found new best model at epoch 5
2022-11-22 23:57:24,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:24,809 INFO:     Epoch: 6
2022-11-22 23:57:25,695 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8072632747617635, 'Total loss': 0.8072632747617635} | train loss {'Reaction outcome loss': 0.8445698855625045, 'Total loss': 0.8445698855625045}
2022-11-22 23:57:25,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:25,695 INFO:     Epoch: 7
2022-11-22 23:57:26,595 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8122303533283147, 'Total loss': 0.8122303533283147} | train loss {'Reaction outcome loss': 0.8429448393083387, 'Total loss': 0.8429448393083387}
2022-11-22 23:57:26,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:26,596 INFO:     Epoch: 8
2022-11-22 23:57:27,457 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8068023425611582, 'Total loss': 0.8068023425611582} | train loss {'Reaction outcome loss': 0.8361688119269186, 'Total loss': 0.8361688119269186}
2022-11-22 23:57:27,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:27,458 INFO:     Epoch: 9
2022-11-22 23:57:28,317 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8062912659211592, 'Total loss': 0.8062912659211592} | train loss {'Reaction outcome loss': 0.8384062014520168, 'Total loss': 0.8384062014520168}
2022-11-22 23:57:28,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:28,317 INFO:     Epoch: 10
2022-11-22 23:57:29,190 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8056583560325883, 'Total loss': 0.8056583560325883} | train loss {'Reaction outcome loss': 0.8395423668046151, 'Total loss': 0.8395423668046151}
2022-11-22 23:57:29,191 INFO:     Found new best model at epoch 10
2022-11-22 23:57:29,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:29,193 INFO:     Epoch: 11
2022-11-22 23:57:30,053 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8113690530034628, 'Total loss': 0.8113690530034628} | train loss {'Reaction outcome loss': 0.8345917428453122, 'Total loss': 0.8345917428453122}
2022-11-22 23:57:30,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:30,053 INFO:     Epoch: 12
2022-11-22 23:57:30,969 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7893181348388846, 'Total loss': 0.7893181348388846} | train loss {'Reaction outcome loss': 0.8398957418337945, 'Total loss': 0.8398957418337945}
2022-11-22 23:57:30,969 INFO:     Found new best model at epoch 12
2022-11-22 23:57:30,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:30,970 INFO:     Epoch: 13
2022-11-22 23:57:31,837 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7906967198306863, 'Total loss': 0.7906967198306863} | train loss {'Reaction outcome loss': 0.8370063059752987, 'Total loss': 0.8370063059752987}
2022-11-22 23:57:31,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:31,837 INFO:     Epoch: 14
2022-11-22 23:57:32,751 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8020991987802766, 'Total loss': 0.8020991987802766} | train loss {'Reaction outcome loss': 0.8364016621583893, 'Total loss': 0.8364016621583893}
2022-11-22 23:57:32,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:32,751 INFO:     Epoch: 15
2022-11-22 23:57:33,653 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7827214977957986, 'Total loss': 0.7827214977957986} | train loss {'Reaction outcome loss': 0.8379423500549409, 'Total loss': 0.8379423500549409}
2022-11-22 23:57:33,653 INFO:     Found new best model at epoch 15
2022-11-22 23:57:33,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:33,654 INFO:     Epoch: 16
2022-11-22 23:57:34,518 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.807649820365689, 'Total loss': 0.807649820365689} | train loss {'Reaction outcome loss': 0.8347487372736777, 'Total loss': 0.8347487372736777}
2022-11-22 23:57:34,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:34,519 INFO:     Epoch: 17
2022-11-22 23:57:35,401 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7913513461297209, 'Total loss': 0.7913513461297209} | train loss {'Reaction outcome loss': 0.8364947054895663, 'Total loss': 0.8364947054895663}
2022-11-22 23:57:35,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:35,402 INFO:     Epoch: 18
2022-11-22 23:57:36,317 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7899454967542128, 'Total loss': 0.7899454967542128} | train loss {'Reaction outcome loss': 0.8348583485330304, 'Total loss': 0.8348583485330304}
2022-11-22 23:57:36,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:36,318 INFO:     Epoch: 19
2022-11-22 23:57:37,218 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8094627105376937, 'Total loss': 0.8094627105376937} | train loss {'Reaction outcome loss': 0.8354135227780188, 'Total loss': 0.8354135227780188}
2022-11-22 23:57:37,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:37,218 INFO:     Epoch: 20
2022-11-22 23:57:38,111 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7972243272445418, 'Total loss': 0.7972243272445418} | train loss {'Reaction outcome loss': 0.8320829352784541, 'Total loss': 0.8320829352784541}
2022-11-22 23:57:38,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:38,111 INFO:     Epoch: 21
2022-11-22 23:57:38,976 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8201919882134958, 'Total loss': 0.8201919882134958} | train loss {'Reaction outcome loss': 0.8298344577272092, 'Total loss': 0.8298344577272092}
2022-11-22 23:57:38,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:38,977 INFO:     Epoch: 22
2022-11-22 23:57:39,832 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.791637780314142, 'Total loss': 0.791637780314142} | train loss {'Reaction outcome loss': 0.8314939279469752, 'Total loss': 0.8314939279469752}
2022-11-22 23:57:39,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:39,832 INFO:     Epoch: 23
2022-11-22 23:57:40,697 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7906424850225449, 'Total loss': 0.7906424850225449} | train loss {'Reaction outcome loss': 0.8324376956950272, 'Total loss': 0.8324376956950272}
2022-11-22 23:57:40,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:40,697 INFO:     Epoch: 24
2022-11-22 23:57:41,589 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8034912564537742, 'Total loss': 0.8034912564537742} | train loss {'Reaction outcome loss': 0.8310974335237857, 'Total loss': 0.8310974335237857}
2022-11-22 23:57:41,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:41,590 INFO:     Epoch: 25
2022-11-22 23:57:42,483 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7993207092989575, 'Total loss': 0.7993207092989575} | train loss {'Reaction outcome loss': 0.8300093924326282, 'Total loss': 0.8300093924326282}
2022-11-22 23:57:42,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:42,484 INFO:     Epoch: 26
2022-11-22 23:57:43,371 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8047172765840184, 'Total loss': 0.8047172765840184} | train loss {'Reaction outcome loss': 0.8296614334948601, 'Total loss': 0.8296614334948601}
2022-11-22 23:57:43,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:43,371 INFO:     Epoch: 27
2022-11-22 23:57:44,247 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8003126044165004, 'Total loss': 0.8003126044165004} | train loss {'Reaction outcome loss': 0.828135026198241, 'Total loss': 0.828135026198241}
2022-11-22 23:57:44,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:44,248 INFO:     Epoch: 28
2022-11-22 23:57:45,081 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8204608126120134, 'Total loss': 0.8204608126120134} | train loss {'Reaction outcome loss': 0.8324921476023812, 'Total loss': 0.8324921476023812}
2022-11-22 23:57:45,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:45,082 INFO:     Epoch: 29
2022-11-22 23:57:45,956 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8058365800163962, 'Total loss': 0.8058365800163962} | train loss {'Reaction outcome loss': 0.8312710375795441, 'Total loss': 0.8312710375795441}
2022-11-22 23:57:45,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:45,956 INFO:     Epoch: 30
2022-11-22 23:57:46,816 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7951936667615717, 'Total loss': 0.7951936667615717} | train loss {'Reaction outcome loss': 0.8272527143239014, 'Total loss': 0.8272527143239014}
2022-11-22 23:57:46,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:46,816 INFO:     Epoch: 31
2022-11-22 23:57:47,748 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.805688701570034, 'Total loss': 0.805688701570034} | train loss {'Reaction outcome loss': 0.8276938924625996, 'Total loss': 0.8276938924625996}
2022-11-22 23:57:47,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:47,749 INFO:     Epoch: 32
2022-11-22 23:57:48,639 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7997329905629158, 'Total loss': 0.7997329905629158} | train loss {'Reaction outcome loss': 0.8307153624632666, 'Total loss': 0.8307153624632666}
2022-11-22 23:57:48,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:48,639 INFO:     Epoch: 33
2022-11-22 23:57:49,492 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7995011806488037, 'Total loss': 0.7995011806488037} | train loss {'Reaction outcome loss': 0.8313095002405105, 'Total loss': 0.8313095002405105}
2022-11-22 23:57:49,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:49,493 INFO:     Epoch: 34
2022-11-22 23:57:50,396 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7960256839340384, 'Total loss': 0.7960256839340384} | train loss {'Reaction outcome loss': 0.8291829414665699, 'Total loss': 0.8291829414665699}
2022-11-22 23:57:50,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:50,396 INFO:     Epoch: 35
2022-11-22 23:57:51,246 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7942205945199187, 'Total loss': 0.7942205945199187} | train loss {'Reaction outcome loss': 0.8236808482437364, 'Total loss': 0.8236808482437364}
2022-11-22 23:57:51,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:51,246 INFO:     Epoch: 36
2022-11-22 23:57:52,096 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7976338335058906, 'Total loss': 0.7976338335058906} | train loss {'Reaction outcome loss': 0.8302384970649597, 'Total loss': 0.8302384970649597}
2022-11-22 23:57:52,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:52,096 INFO:     Epoch: 37
2022-11-22 23:57:53,011 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7922722135077823, 'Total loss': 0.7922722135077823} | train loss {'Reaction outcome loss': 0.8230866550678207, 'Total loss': 0.8230866550678207}
2022-11-22 23:57:53,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:53,011 INFO:     Epoch: 38
2022-11-22 23:57:53,925 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.796517819843509, 'Total loss': 0.796517819843509} | train loss {'Reaction outcome loss': 0.831040215948897, 'Total loss': 0.831040215948897}
2022-11-22 23:57:53,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:53,925 INFO:     Epoch: 39
2022-11-22 23:57:54,819 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7992207475683906, 'Total loss': 0.7992207475683906} | train loss {'Reaction outcome loss': 0.8286480595988612, 'Total loss': 0.8286480595988612}
2022-11-22 23:57:54,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:54,819 INFO:     Epoch: 40
2022-11-22 23:57:55,665 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7963938943364404, 'Total loss': 0.7963938943364404} | train loss {'Reaction outcome loss': 0.830074711792892, 'Total loss': 0.830074711792892}
2022-11-22 23:57:55,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:55,666 INFO:     Epoch: 41
2022-11-22 23:57:56,539 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8203751295804977, 'Total loss': 0.8203751295804977} | train loss {'Reaction outcome loss': 0.8252333706665423, 'Total loss': 0.8252333706665423}
2022-11-22 23:57:56,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:56,539 INFO:     Epoch: 42
2022-11-22 23:57:57,428 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8214711573990908, 'Total loss': 0.8214711573990908} | train loss {'Reaction outcome loss': 0.8310520131020777, 'Total loss': 0.8310520131020777}
2022-11-22 23:57:57,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:57,428 INFO:     Epoch: 43
2022-11-22 23:57:58,308 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7890261343934319, 'Total loss': 0.7890261343934319} | train loss {'Reaction outcome loss': 0.8282650435163129, 'Total loss': 0.8282650435163129}
2022-11-22 23:57:58,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:58,308 INFO:     Epoch: 44
2022-11-22 23:57:59,159 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7988122674551877, 'Total loss': 0.7988122674551877} | train loss {'Reaction outcome loss': 0.8275957946335116, 'Total loss': 0.8275957946335116}
2022-11-22 23:57:59,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:57:59,159 INFO:     Epoch: 45
2022-11-22 23:58:00,083 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.807257510044358, 'Total loss': 0.807257510044358} | train loss {'Reaction outcome loss': 0.8291959533047292, 'Total loss': 0.8291959533047292}
2022-11-22 23:58:00,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:00,084 INFO:     Epoch: 46
2022-11-22 23:58:00,983 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8032214783809402, 'Total loss': 0.8032214783809402} | train loss {'Reaction outcome loss': 0.8279118930860874, 'Total loss': 0.8279118930860874}
2022-11-22 23:58:00,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:00,984 INFO:     Epoch: 47
2022-11-22 23:58:01,891 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8013766556978226, 'Total loss': 0.8013766556978226} | train loss {'Reaction outcome loss': 0.8275401387964526, 'Total loss': 0.8275401387964526}
2022-11-22 23:58:01,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:01,892 INFO:     Epoch: 48
2022-11-22 23:58:02,731 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.812872362407771, 'Total loss': 0.812872362407771} | train loss {'Reaction outcome loss': 0.8296761683398678, 'Total loss': 0.8296761683398678}
2022-11-22 23:58:02,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:02,732 INFO:     Epoch: 49
2022-11-22 23:58:03,575 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8013061420484022, 'Total loss': 0.8013061420484022} | train loss {'Reaction outcome loss': 0.8282213358869476, 'Total loss': 0.8282213358869476}
2022-11-22 23:58:03,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:03,575 INFO:     Epoch: 50
2022-11-22 23:58:04,404 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7985138527371667, 'Total loss': 0.7985138527371667} | train loss {'Reaction outcome loss': 0.8296185366569027, 'Total loss': 0.8296185366569027}
2022-11-22 23:58:04,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:04,404 INFO:     Epoch: 51
2022-11-22 23:58:05,228 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7935104234652086, 'Total loss': 0.7935104234652086} | train loss {'Reaction outcome loss': 0.8281789857052988, 'Total loss': 0.8281789857052988}
2022-11-22 23:58:05,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:05,228 INFO:     Epoch: 52
2022-11-22 23:58:06,061 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.80606959015131, 'Total loss': 0.80606959015131} | train loss {'Reaction outcome loss': 0.8270375700967927, 'Total loss': 0.8270375700967927}
2022-11-22 23:58:06,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:06,061 INFO:     Epoch: 53
2022-11-22 23:58:06,877 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7896988256411119, 'Total loss': 0.7896988256411119} | train loss {'Reaction outcome loss': 0.8292972695442938, 'Total loss': 0.8292972695442938}
2022-11-22 23:58:06,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:06,878 INFO:     Epoch: 54
2022-11-22 23:58:07,670 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.79262478988279, 'Total loss': 0.79262478988279} | train loss {'Reaction outcome loss': 0.8314657434821129, 'Total loss': 0.8314657434821129}
2022-11-22 23:58:07,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:07,671 INFO:     Epoch: 55
2022-11-22 23:58:08,492 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7964434989474036, 'Total loss': 0.7964434989474036} | train loss {'Reaction outcome loss': 0.8289714121530133, 'Total loss': 0.8289714121530133}
2022-11-22 23:58:08,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:08,492 INFO:     Epoch: 56
2022-11-22 23:58:09,264 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7850439304655249, 'Total loss': 0.7850439304655249} | train loss {'Reaction outcome loss': 0.8241245072455176, 'Total loss': 0.8241245072455176}
2022-11-22 23:58:09,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:09,265 INFO:     Epoch: 57
2022-11-22 23:58:10,050 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8005064265294508, 'Total loss': 0.8005064265294508} | train loss {'Reaction outcome loss': 0.8321642416619486, 'Total loss': 0.8321642416619486}
2022-11-22 23:58:10,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:10,051 INFO:     Epoch: 58
2022-11-22 23:58:10,836 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.788426315242594, 'Total loss': 0.788426315242594} | train loss {'Reaction outcome loss': 0.8272228686799926, 'Total loss': 0.8272228686799926}
2022-11-22 23:58:10,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:10,837 INFO:     Epoch: 59
2022-11-22 23:58:11,619 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7959119386293672, 'Total loss': 0.7959119386293672} | train loss {'Reaction outcome loss': 0.8300718326241739, 'Total loss': 0.8300718326241739}
2022-11-22 23:58:11,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:11,619 INFO:     Epoch: 60
2022-11-22 23:58:12,404 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7951456193219532, 'Total loss': 0.7951456193219532} | train loss {'Reaction outcome loss': 0.828856943595794, 'Total loss': 0.828856943595794}
2022-11-22 23:58:12,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:12,404 INFO:     Epoch: 61
2022-11-22 23:58:13,172 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.787170721725984, 'Total loss': 0.787170721725984} | train loss {'Reaction outcome loss': 0.8271879984005805, 'Total loss': 0.8271879984005805}
2022-11-22 23:58:13,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:13,172 INFO:     Epoch: 62
2022-11-22 23:58:13,933 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8073649352247064, 'Total loss': 0.8073649352247064} | train loss {'Reaction outcome loss': 0.8247773989794716, 'Total loss': 0.8247773989794716}
2022-11-22 23:58:13,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:13,934 INFO:     Epoch: 63
2022-11-22 23:58:14,720 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7936715388839896, 'Total loss': 0.7936715388839896} | train loss {'Reaction outcome loss': 0.8276213453181328, 'Total loss': 0.8276213453181328}
2022-11-22 23:58:14,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:14,720 INFO:     Epoch: 64
2022-11-22 23:58:15,477 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8116884184154597, 'Total loss': 0.8116884184154597} | train loss {'Reaction outcome loss': 0.8289477074098203, 'Total loss': 0.8289477074098203}
2022-11-22 23:58:15,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:15,478 INFO:     Epoch: 65
2022-11-22 23:58:16,298 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7892748063260858, 'Total loss': 0.7892748063260858} | train loss {'Reaction outcome loss': 0.8262277041231433, 'Total loss': 0.8262277041231433}
2022-11-22 23:58:16,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:16,298 INFO:     Epoch: 66
2022-11-22 23:58:17,071 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8026220568201758, 'Total loss': 0.8026220568201758} | train loss {'Reaction outcome loss': 0.8269051719577082, 'Total loss': 0.8269051719577082}
2022-11-22 23:58:17,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:17,071 INFO:     Epoch: 67
2022-11-22 23:58:17,855 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8011989011005922, 'Total loss': 0.8011989011005922} | train loss {'Reaction outcome loss': 0.8290698946483673, 'Total loss': 0.8290698946483673}
2022-11-22 23:58:17,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:17,855 INFO:     Epoch: 68
2022-11-22 23:58:18,665 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7934109914031896, 'Total loss': 0.7934109914031896} | train loss {'Reaction outcome loss': 0.8304800617118036, 'Total loss': 0.8304800617118036}
2022-11-22 23:58:18,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:18,665 INFO:     Epoch: 69
2022-11-22 23:58:19,429 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8190802207047289, 'Total loss': 0.8190802207047289} | train loss {'Reaction outcome loss': 0.8330137615482653, 'Total loss': 0.8330137615482653}
2022-11-22 23:58:19,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:19,429 INFO:     Epoch: 70
2022-11-22 23:58:20,212 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8176902200688015, 'Total loss': 0.8176902200688015} | train loss {'Reaction outcome loss': 0.8281264991289184, 'Total loss': 0.8281264991289184}
2022-11-22 23:58:20,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:20,213 INFO:     Epoch: 71
2022-11-22 23:58:21,073 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7869590541178529, 'Total loss': 0.7869590541178529} | train loss {'Reaction outcome loss': 0.8283578531155663, 'Total loss': 0.8283578531155663}
2022-11-22 23:58:21,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:21,073 INFO:     Epoch: 72
2022-11-22 23:58:21,870 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7903771657835353, 'Total loss': 0.7903771657835353} | train loss {'Reaction outcome loss': 0.8252739526571766, 'Total loss': 0.8252739526571766}
2022-11-22 23:58:21,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:21,871 INFO:     Epoch: 73
2022-11-22 23:58:22,695 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7868917462500659, 'Total loss': 0.7868917462500659} | train loss {'Reaction outcome loss': 0.8270498363962097, 'Total loss': 0.8270498363962097}
2022-11-22 23:58:22,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:22,696 INFO:     Epoch: 74
2022-11-22 23:58:23,499 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7921427007425915, 'Total loss': 0.7921427007425915} | train loss {'Reaction outcome loss': 0.825729685685327, 'Total loss': 0.825729685685327}
2022-11-22 23:58:23,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:23,500 INFO:     Epoch: 75
2022-11-22 23:58:24,303 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7948504869233478, 'Total loss': 0.7948504869233478} | train loss {'Reaction outcome loss': 0.8256954561558462, 'Total loss': 0.8256954561558462}
2022-11-22 23:58:24,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:24,303 INFO:     Epoch: 76
2022-11-22 23:58:25,086 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7981529960578139, 'Total loss': 0.7981529960578139} | train loss {'Reaction outcome loss': 0.8326590830279935, 'Total loss': 0.8326590830279935}
2022-11-22 23:58:25,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:25,087 INFO:     Epoch: 77
2022-11-22 23:58:25,880 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7918112657286904, 'Total loss': 0.7918112657286904} | train loss {'Reaction outcome loss': 0.8255363112736133, 'Total loss': 0.8255363112736133}
2022-11-22 23:58:25,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:25,881 INFO:     Epoch: 78
2022-11-22 23:58:26,719 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.795419464057142, 'Total loss': 0.795419464057142} | train loss {'Reaction outcome loss': 0.8282455804367219, 'Total loss': 0.8282455804367219}
2022-11-22 23:58:26,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:26,719 INFO:     Epoch: 79
2022-11-22 23:58:27,556 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7968532253395427, 'Total loss': 0.7968532253395427} | train loss {'Reaction outcome loss': 0.833626429880819, 'Total loss': 0.833626429880819}
2022-11-22 23:58:27,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:27,556 INFO:     Epoch: 80
2022-11-22 23:58:28,372 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8011116778308695, 'Total loss': 0.8011116778308695} | train loss {'Reaction outcome loss': 0.8276877398452451, 'Total loss': 0.8276877398452451}
2022-11-22 23:58:28,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:28,372 INFO:     Epoch: 81
2022-11-22 23:58:29,214 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7831506864591078, 'Total loss': 0.7831506864591078} | train loss {'Reaction outcome loss': 0.8263776215814775, 'Total loss': 0.8263776215814775}
2022-11-22 23:58:29,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:29,215 INFO:     Epoch: 82
2022-11-22 23:58:30,035 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8055170225826177, 'Total loss': 0.8055170225826177} | train loss {'Reaction outcome loss': 0.8274538386012277, 'Total loss': 0.8274538386012277}
2022-11-22 23:58:30,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:30,036 INFO:     Epoch: 83
2022-11-22 23:58:30,867 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.786657147786834, 'Total loss': 0.786657147786834} | train loss {'Reaction outcome loss': 0.8274147631900926, 'Total loss': 0.8274147631900926}
2022-11-22 23:58:30,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:30,868 INFO:     Epoch: 84
2022-11-22 23:58:31,657 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7955710020932284, 'Total loss': 0.7955710020932284} | train loss {'Reaction outcome loss': 0.8357016858794997, 'Total loss': 0.8357016858794997}
2022-11-22 23:58:31,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:31,658 INFO:     Epoch: 85
2022-11-22 23:58:32,445 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8027053299275312, 'Total loss': 0.8027053299275312} | train loss {'Reaction outcome loss': 0.8266191655589689, 'Total loss': 0.8266191655589689}
2022-11-22 23:58:32,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:32,445 INFO:     Epoch: 86
2022-11-22 23:58:33,238 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8011893880638209, 'Total loss': 0.8011893880638209} | train loss {'Reaction outcome loss': 0.8297640561696983, 'Total loss': 0.8297640561696983}
2022-11-22 23:58:33,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:33,238 INFO:     Epoch: 87
2022-11-22 23:58:34,069 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8035581501370127, 'Total loss': 0.8035581501370127} | train loss {'Reaction outcome loss': 0.8270913793915703, 'Total loss': 0.8270913793915703}
2022-11-22 23:58:34,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:34,069 INFO:     Epoch: 88
2022-11-22 23:58:34,872 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7942842177369378, 'Total loss': 0.7942842177369378} | train loss {'Reaction outcome loss': 0.8256019907853296, 'Total loss': 0.8256019907853296}
2022-11-22 23:58:34,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:34,872 INFO:     Epoch: 89
2022-11-22 23:58:35,672 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8142807124690576, 'Total loss': 0.8142807124690576} | train loss {'Reaction outcome loss': 0.827758987464251, 'Total loss': 0.827758987464251}
2022-11-22 23:58:35,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:35,672 INFO:     Epoch: 90
2022-11-22 23:58:36,494 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8055014901540496, 'Total loss': 0.8055014901540496} | train loss {'Reaction outcome loss': 0.8275035176306001, 'Total loss': 0.8275035176306001}
2022-11-22 23:58:36,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:36,495 INFO:     Epoch: 91
2022-11-22 23:58:37,274 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7998288680206646, 'Total loss': 0.7998288680206646} | train loss {'Reaction outcome loss': 0.8272239109200816, 'Total loss': 0.8272239109200816}
2022-11-22 23:58:37,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:37,275 INFO:     Epoch: 92
2022-11-22 23:58:38,122 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7965262633833018, 'Total loss': 0.7965262633833018} | train loss {'Reaction outcome loss': 0.8250979663383576, 'Total loss': 0.8250979663383576}
2022-11-22 23:58:38,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:38,123 INFO:     Epoch: 93
2022-11-22 23:58:38,928 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8047271966934204, 'Total loss': 0.8047271966934204} | train loss {'Reaction outcome loss': 0.8288612911297429, 'Total loss': 0.8288612911297429}
2022-11-22 23:58:38,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:38,929 INFO:     Epoch: 94
2022-11-22 23:58:39,753 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7998356751420281, 'Total loss': 0.7998356751420281} | train loss {'Reaction outcome loss': 0.8275623328743442, 'Total loss': 0.8275623328743442}
2022-11-22 23:58:39,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:39,753 INFO:     Epoch: 95
2022-11-22 23:58:40,564 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7798141335899179, 'Total loss': 0.7798141335899179} | train loss {'Reaction outcome loss': 0.8296972286076315, 'Total loss': 0.8296972286076315}
2022-11-22 23:58:40,564 INFO:     Found new best model at epoch 95
2022-11-22 23:58:40,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:40,565 INFO:     Epoch: 96
2022-11-22 23:58:41,419 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7874822704629465, 'Total loss': 0.7874822704629465} | train loss {'Reaction outcome loss': 0.8228583230126288, 'Total loss': 0.8228583230126288}
2022-11-22 23:58:41,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:41,419 INFO:     Epoch: 97
2022-11-22 23:58:42,247 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7989528951319781, 'Total loss': 0.7989528951319781} | train loss {'Reaction outcome loss': 0.8308712281286716, 'Total loss': 0.8308712281286716}
2022-11-22 23:58:42,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:42,247 INFO:     Epoch: 98
2022-11-22 23:58:43,040 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7895515086975965, 'Total loss': 0.7895515086975965} | train loss {'Reaction outcome loss': 0.8275491958183627, 'Total loss': 0.8275491958183627}
2022-11-22 23:58:43,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:43,040 INFO:     Epoch: 99
2022-11-22 23:58:43,858 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7966583276336844, 'Total loss': 0.7966583276336844} | train loss {'Reaction outcome loss': 0.8308920451710301, 'Total loss': 0.8308920451710301}
2022-11-22 23:58:43,858 INFO:     Best model found after epoch 96 of 100.
2022-11-22 23:58:43,858 INFO:   Done with stage: TRAINING
2022-11-22 23:58:43,858 INFO:   Starting stage: EVALUATION
2022-11-22 23:58:43,978 INFO:   Done with stage: EVALUATION
2022-11-22 23:58:43,978 INFO:   Leaving out SEQ value Fold_5
2022-11-22 23:58:43,991 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-22 23:58:43,991 INFO:   Starting stage: FEATURE SCALING
2022-11-22 23:58:44,670 INFO:   Done with stage: FEATURE SCALING
2022-11-22 23:58:44,670 INFO:   Starting stage: SCALING TARGETS
2022-11-22 23:58:44,739 INFO:   Done with stage: SCALING TARGETS
2022-11-22 23:58:44,739 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:58:44,739 INFO:     No hyperparam tuning for this model
2022-11-22 23:58:44,739 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-22 23:58:44,739 INFO:   Starting stage: FEATURE SELECTION
2022-11-22 23:58:44,740 INFO:     None feature selector for col prot
2022-11-22 23:58:44,740 INFO:     None feature selector for col prot
2022-11-22 23:58:44,741 INFO:     None feature selector for col prot
2022-11-22 23:58:44,741 INFO:     None feature selector for col chem
2022-11-22 23:58:44,741 INFO:     None feature selector for col chem
2022-11-22 23:58:44,741 INFO:     None feature selector for col chem
2022-11-22 23:58:44,741 INFO:   Done with stage: FEATURE SELECTION
2022-11-22 23:58:44,742 INFO:   Starting stage: BUILD MODEL
2022-11-22 23:58:44,743 INFO:     Number of params in model 168571
2022-11-22 23:58:44,746 INFO:   Done with stage: BUILD MODEL
2022-11-22 23:58:44,746 INFO:   Starting stage: TRAINING
2022-11-22 23:58:44,805 INFO:     Val loss before train {'Reaction outcome loss': 1.0443122373385862, 'Total loss': 1.0443122373385862}
2022-11-22 23:58:44,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:44,805 INFO:     Epoch: 0
2022-11-22 23:58:45,586 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8620065904476426, 'Total loss': 0.8620065904476426} | train loss {'Reaction outcome loss': 0.8745817047984976, 'Total loss': 0.8745817047984976}
2022-11-22 23:58:45,586 INFO:     Found new best model at epoch 0
2022-11-22 23:58:45,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:45,587 INFO:     Epoch: 1
2022-11-22 23:58:46,410 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8799582773988898, 'Total loss': 0.8799582773988898} | train loss {'Reaction outcome loss': 0.8382299781931557, 'Total loss': 0.8382299781931557}
2022-11-22 23:58:46,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:46,411 INFO:     Epoch: 2
2022-11-22 23:58:47,187 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8720934242010117, 'Total loss': 0.8720934242010117} | train loss {'Reaction outcome loss': 0.840952258843642, 'Total loss': 0.840952258843642}
2022-11-22 23:58:47,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:47,188 INFO:     Epoch: 3
2022-11-22 23:58:47,981 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.85879667035558, 'Total loss': 0.85879667035558} | train loss {'Reaction outcome loss': 0.841974070559629, 'Total loss': 0.841974070559629}
2022-11-22 23:58:47,981 INFO:     Found new best model at epoch 3
2022-11-22 23:58:47,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:47,982 INFO:     Epoch: 4
2022-11-22 23:58:48,752 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8523059019988234, 'Total loss': 0.8523059019988234} | train loss {'Reaction outcome loss': 0.8300503663688537, 'Total loss': 0.8300503663688537}
2022-11-22 23:58:48,752 INFO:     Found new best model at epoch 4
2022-11-22 23:58:48,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:48,753 INFO:     Epoch: 5
2022-11-22 23:58:49,540 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8472569395195354, 'Total loss': 0.8472569395195354} | train loss {'Reaction outcome loss': 0.8363867361053281, 'Total loss': 0.8363867361053281}
2022-11-22 23:58:49,540 INFO:     Found new best model at epoch 5
2022-11-22 23:58:49,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:49,541 INFO:     Epoch: 6
2022-11-22 23:58:50,319 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8618814714930274, 'Total loss': 0.8618814714930274} | train loss {'Reaction outcome loss': 0.8347085664870768, 'Total loss': 0.8347085664870768}
2022-11-22 23:58:50,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:50,320 INFO:     Epoch: 7
2022-11-22 23:58:51,133 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8452135412530466, 'Total loss': 0.8452135412530466} | train loss {'Reaction outcome loss': 0.8222315631776687, 'Total loss': 0.8222315631776687}
2022-11-22 23:58:51,133 INFO:     Found new best model at epoch 7
2022-11-22 23:58:51,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:51,134 INFO:     Epoch: 8
2022-11-22 23:58:51,960 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8405958271839402, 'Total loss': 0.8405958271839402} | train loss {'Reaction outcome loss': 0.8263174548805484, 'Total loss': 0.8263174548805484}
2022-11-22 23:58:51,960 INFO:     Found new best model at epoch 8
2022-11-22 23:58:51,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:51,961 INFO:     Epoch: 9
2022-11-22 23:58:52,764 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8364815495230935, 'Total loss': 0.8364815495230935} | train loss {'Reaction outcome loss': 0.827479505345889, 'Total loss': 0.827479505345889}
2022-11-22 23:58:52,765 INFO:     Found new best model at epoch 9
2022-11-22 23:58:52,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:52,765 INFO:     Epoch: 10
2022-11-22 23:58:53,544 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8644656051288951, 'Total loss': 0.8644656051288951} | train loss {'Reaction outcome loss': 0.8219538197403977, 'Total loss': 0.8219538197403977}
2022-11-22 23:58:53,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:53,544 INFO:     Epoch: 11
2022-11-22 23:58:54,332 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8397950740023092, 'Total loss': 0.8397950740023092} | train loss {'Reaction outcome loss': 0.8174089591211153, 'Total loss': 0.8174089591211153}
2022-11-22 23:58:54,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:54,332 INFO:     Epoch: 12
2022-11-22 23:58:55,110 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8459976396777413, 'Total loss': 0.8459976396777413} | train loss {'Reaction outcome loss': 0.8159500808730299, 'Total loss': 0.8159500808730299}
2022-11-22 23:58:55,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:55,110 INFO:     Epoch: 13
2022-11-22 23:58:55,911 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8703520365736701, 'Total loss': 0.8703520365736701} | train loss {'Reaction outcome loss': 0.8124037001297059, 'Total loss': 0.8124037001297059}
2022-11-22 23:58:55,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:55,911 INFO:     Epoch: 14
2022-11-22 23:58:56,718 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8327282707799565, 'Total loss': 0.8327282707799565} | train loss {'Reaction outcome loss': 0.8188762715470935, 'Total loss': 0.8188762715470935}
2022-11-22 23:58:56,718 INFO:     Found new best model at epoch 14
2022-11-22 23:58:56,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:56,719 INFO:     Epoch: 15
2022-11-22 23:58:57,591 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8364411660216071, 'Total loss': 0.8364411660216071} | train loss {'Reaction outcome loss': 0.8186357877394448, 'Total loss': 0.8186357877394448}
2022-11-22 23:58:57,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:57,592 INFO:     Epoch: 16
2022-11-22 23:58:58,351 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8597026277672161, 'Total loss': 0.8597026277672161} | train loss {'Reaction outcome loss': 0.8164240387287217, 'Total loss': 0.8164240387287217}
2022-11-22 23:58:58,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:58,352 INFO:     Epoch: 17
2022-11-22 23:58:59,175 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8372924287210811, 'Total loss': 0.8372924287210811} | train loss {'Reaction outcome loss': 0.8197331579349302, 'Total loss': 0.8197331579349302}
2022-11-22 23:58:59,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:59,175 INFO:     Epoch: 18
2022-11-22 23:58:59,986 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8177318125963211, 'Total loss': 0.8177318125963211} | train loss {'Reaction outcome loss': 0.8159922920016625, 'Total loss': 0.8159922920016625}
2022-11-22 23:58:59,986 INFO:     Found new best model at epoch 18
2022-11-22 23:58:59,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:58:59,987 INFO:     Epoch: 19
2022-11-22 23:59:00,813 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8295845213261518, 'Total loss': 0.8295845213261518} | train loss {'Reaction outcome loss': 0.8192283976898502, 'Total loss': 0.8192283976898502}
2022-11-22 23:59:00,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:00,814 INFO:     Epoch: 20
2022-11-22 23:59:01,626 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8623780980706215, 'Total loss': 0.8623780980706215} | train loss {'Reaction outcome loss': 0.8117608621052885, 'Total loss': 0.8117608621052885}
2022-11-22 23:59:01,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:01,626 INFO:     Epoch: 21
2022-11-22 23:59:02,404 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8549353615804152, 'Total loss': 0.8549353615804152} | train loss {'Reaction outcome loss': 0.8145138367950192, 'Total loss': 0.8145138367950192}
2022-11-22 23:59:02,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:02,406 INFO:     Epoch: 22
2022-11-22 23:59:03,210 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8279210843823173, 'Total loss': 0.8279210843823173} | train loss {'Reaction outcome loss': 0.8162888693302749, 'Total loss': 0.8162888693302749}
2022-11-22 23:59:03,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:03,210 INFO:     Epoch: 23
2022-11-22 23:59:04,036 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8279580677097494, 'Total loss': 0.8279580677097494} | train loss {'Reaction outcome loss': 0.8157305601637374, 'Total loss': 0.8157305601637374}
2022-11-22 23:59:04,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:04,036 INFO:     Epoch: 24
2022-11-22 23:59:04,797 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8388109559362585, 'Total loss': 0.8388109559362585} | train loss {'Reaction outcome loss': 0.8188872301144156, 'Total loss': 0.8188872301144156}
2022-11-22 23:59:04,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:04,797 INFO:     Epoch: 25
2022-11-22 23:59:05,588 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8287798186594789, 'Total loss': 0.8287798186594789} | train loss {'Reaction outcome loss': 0.8223579069863447, 'Total loss': 0.8223579069863447}
2022-11-22 23:59:05,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:05,588 INFO:     Epoch: 26
2022-11-22 23:59:06,385 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8429510850798, 'Total loss': 0.8429510850798} | train loss {'Reaction outcome loss': 0.8174748407443043, 'Total loss': 0.8174748407443043}
2022-11-22 23:59:06,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:06,385 INFO:     Epoch: 27
2022-11-22 23:59:07,209 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8410335359248248, 'Total loss': 0.8410335359248248} | train loss {'Reaction outcome loss': 0.8177242058250103, 'Total loss': 0.8177242058250103}
2022-11-22 23:59:07,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:07,209 INFO:     Epoch: 28
2022-11-22 23:59:08,037 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8304523703726855, 'Total loss': 0.8304523703726855} | train loss {'Reaction outcome loss': 0.81006538822704, 'Total loss': 0.81006538822704}
2022-11-22 23:59:08,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:08,038 INFO:     Epoch: 29
2022-11-22 23:59:08,845 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8372891545295715, 'Total loss': 0.8372891545295715} | train loss {'Reaction outcome loss': 0.8108442955412846, 'Total loss': 0.8108442955412846}
2022-11-22 23:59:08,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:08,846 INFO:     Epoch: 30
2022-11-22 23:59:09,663 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8317987078970129, 'Total loss': 0.8317987078970129} | train loss {'Reaction outcome loss': 0.822367712433039, 'Total loss': 0.822367712433039}
2022-11-22 23:59:09,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:09,663 INFO:     Epoch: 31
2022-11-22 23:59:10,499 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8376283550804312, 'Total loss': 0.8376283550804312} | train loss {'Reaction outcome loss': 0.8171999878004977, 'Total loss': 0.8171999878004977}
2022-11-22 23:59:10,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:10,500 INFO:     Epoch: 32
2022-11-22 23:59:11,380 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8385603285648606, 'Total loss': 0.8385603285648606} | train loss {'Reaction outcome loss': 0.8234339197154953, 'Total loss': 0.8234339197154953}
2022-11-22 23:59:11,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:11,381 INFO:     Epoch: 33
2022-11-22 23:59:12,223 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8336890245025809, 'Total loss': 0.8336890245025809} | train loss {'Reaction outcome loss': 0.8120034334630619, 'Total loss': 0.8120034334630619}
2022-11-22 23:59:12,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:12,223 INFO:     Epoch: 34
2022-11-22 23:59:13,050 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8369409590959549, 'Total loss': 0.8369409590959549} | train loss {'Reaction outcome loss': 0.8127990831971651, 'Total loss': 0.8127990831971651}
2022-11-22 23:59:13,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:13,050 INFO:     Epoch: 35
2022-11-22 23:59:13,857 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8422394042665308, 'Total loss': 0.8422394042665308} | train loss {'Reaction outcome loss': 0.8201233095485672, 'Total loss': 0.8201233095485672}
2022-11-22 23:59:13,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:13,857 INFO:     Epoch: 36
2022-11-22 23:59:14,680 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8260502381758257, 'Total loss': 0.8260502381758257} | train loss {'Reaction outcome loss': 0.8160043575985712, 'Total loss': 0.8160043575985712}
2022-11-22 23:59:14,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:14,680 INFO:     Epoch: 37
2022-11-22 23:59:15,527 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8472189970991828, 'Total loss': 0.8472189970991828} | train loss {'Reaction outcome loss': 0.8140225700038647, 'Total loss': 0.8140225700038647}
2022-11-22 23:59:15,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:15,527 INFO:     Epoch: 38
2022-11-22 23:59:16,324 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8397302553057671, 'Total loss': 0.8397302553057671} | train loss {'Reaction outcome loss': 0.8120819234896285, 'Total loss': 0.8120819234896285}
2022-11-22 23:59:16,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:16,324 INFO:     Epoch: 39
2022-11-22 23:59:17,144 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8248614723032172, 'Total loss': 0.8248614723032172} | train loss {'Reaction outcome loss': 0.8190420028651774, 'Total loss': 0.8190420028651774}
2022-11-22 23:59:17,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:17,144 INFO:     Epoch: 40
2022-11-22 23:59:17,976 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8257574080066248, 'Total loss': 0.8257574080066248} | train loss {'Reaction outcome loss': 0.8103792040876532, 'Total loss': 0.8103792040876532}
2022-11-22 23:59:17,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:17,976 INFO:     Epoch: 41
2022-11-22 23:59:18,801 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8336572620001707, 'Total loss': 0.8336572620001707} | train loss {'Reaction outcome loss': 0.8103154520032859, 'Total loss': 0.8103154520032859}
2022-11-22 23:59:18,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:18,802 INFO:     Epoch: 42
2022-11-22 23:59:19,626 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.823950665240938, 'Total loss': 0.823950665240938} | train loss {'Reaction outcome loss': 0.8153605611942075, 'Total loss': 0.8153605611942075}
2022-11-22 23:59:19,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:19,626 INFO:     Epoch: 43
2022-11-22 23:59:20,426 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8357452784072269, 'Total loss': 0.8357452784072269} | train loss {'Reaction outcome loss': 0.8149340216688782, 'Total loss': 0.8149340216688782}
2022-11-22 23:59:20,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:20,427 INFO:     Epoch: 44
2022-11-22 23:59:21,244 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8277586481787942, 'Total loss': 0.8277586481787942} | train loss {'Reaction outcome loss': 0.818080370846065, 'Total loss': 0.818080370846065}
2022-11-22 23:59:21,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:21,246 INFO:     Epoch: 45
2022-11-22 23:59:22,065 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8328214599327608, 'Total loss': 0.8328214599327608} | train loss {'Reaction outcome loss': 0.8139262761664294, 'Total loss': 0.8139262761664294}
2022-11-22 23:59:22,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:22,065 INFO:     Epoch: 46
2022-11-22 23:59:22,922 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8548380055210807, 'Total loss': 0.8548380055210807} | train loss {'Reaction outcome loss': 0.8137201383287608, 'Total loss': 0.8137201383287608}
2022-11-22 23:59:22,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:22,922 INFO:     Epoch: 47
2022-11-22 23:59:23,728 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.841072675856677, 'Total loss': 0.841072675856677} | train loss {'Reaction outcome loss': 0.8137440225071753, 'Total loss': 0.8137440225071753}
2022-11-22 23:59:23,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:23,728 INFO:     Epoch: 48
2022-11-22 23:59:24,530 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8247908502817154, 'Total loss': 0.8247908502817154} | train loss {'Reaction outcome loss': 0.81553708119431, 'Total loss': 0.81553708119431}
2022-11-22 23:59:24,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:24,530 INFO:     Epoch: 49
2022-11-22 23:59:25,345 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8344137506051497, 'Total loss': 0.8344137506051497} | train loss {'Reaction outcome loss': 0.805862596763773, 'Total loss': 0.805862596763773}
2022-11-22 23:59:25,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:25,346 INFO:     Epoch: 50
2022-11-22 23:59:26,179 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8399359868331389, 'Total loss': 0.8399359868331389} | train loss {'Reaction outcome loss': 0.8126897423901418, 'Total loss': 0.8126897423901418}
2022-11-22 23:59:26,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:26,179 INFO:     Epoch: 51
2022-11-22 23:59:26,938 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8316362981091846, 'Total loss': 0.8316362981091846} | train loss {'Reaction outcome loss': 0.8081077390806637, 'Total loss': 0.8081077390806637}
2022-11-22 23:59:26,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:26,938 INFO:     Epoch: 52
2022-11-22 23:59:27,797 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8247481469403614, 'Total loss': 0.8247481469403614} | train loss {'Reaction outcome loss': 0.8053716239236627, 'Total loss': 0.8053716239236627}
2022-11-22 23:59:27,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:27,798 INFO:     Epoch: 53
2022-11-22 23:59:28,598 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8474946767091751, 'Total loss': 0.8474946767091751} | train loss {'Reaction outcome loss': 0.8118574417192443, 'Total loss': 0.8118574417192443}
2022-11-22 23:59:28,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:28,598 INFO:     Epoch: 54
2022-11-22 23:59:29,431 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8440349081700499, 'Total loss': 0.8440349081700499} | train loss {'Reaction outcome loss': 0.8190269135994467, 'Total loss': 0.8190269135994467}
2022-11-22 23:59:29,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:29,431 INFO:     Epoch: 55
2022-11-22 23:59:30,251 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8247147385369648, 'Total loss': 0.8247147385369648} | train loss {'Reaction outcome loss': 0.8165542922521892, 'Total loss': 0.8165542922521892}
2022-11-22 23:59:30,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:30,252 INFO:     Epoch: 56
2022-11-22 23:59:31,082 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8272227279164575, 'Total loss': 0.8272227279164575} | train loss {'Reaction outcome loss': 0.8104753904346271, 'Total loss': 0.8104753904346271}
2022-11-22 23:59:31,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:31,083 INFO:     Epoch: 57
2022-11-22 23:59:31,889 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8397744338620793, 'Total loss': 0.8397744338620793} | train loss {'Reaction outcome loss': 0.8124422099184894, 'Total loss': 0.8124422099184894}
2022-11-22 23:59:31,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:31,889 INFO:     Epoch: 58
2022-11-22 23:59:32,713 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8324751095338301, 'Total loss': 0.8324751095338301} | train loss {'Reaction outcome loss': 0.8103746366404329, 'Total loss': 0.8103746366404329}
2022-11-22 23:59:32,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:32,713 INFO:     Epoch: 59
2022-11-22 23:59:33,516 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8394776359200478, 'Total loss': 0.8394776359200478} | train loss {'Reaction outcome loss': 0.8098589605406711, 'Total loss': 0.8098589605406711}
2022-11-22 23:59:33,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:33,517 INFO:     Epoch: 60
2022-11-22 23:59:34,309 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8246894851326942, 'Total loss': 0.8246894851326942} | train loss {'Reaction outcome loss': 0.8149249588671, 'Total loss': 0.8149249588671}
2022-11-22 23:59:34,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:34,309 INFO:     Epoch: 61
2022-11-22 23:59:35,151 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8415719683874737, 'Total loss': 0.8415719683874737} | train loss {'Reaction outcome loss': 0.8122579035488701, 'Total loss': 0.8122579035488701}
2022-11-22 23:59:35,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:35,151 INFO:     Epoch: 62
2022-11-22 23:59:35,917 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8247319561513987, 'Total loss': 0.8247319561513987} | train loss {'Reaction outcome loss': 0.8084972833287016, 'Total loss': 0.8084972833287016}
2022-11-22 23:59:35,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:35,917 INFO:     Epoch: 63
2022-11-22 23:59:36,729 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8208689168095589, 'Total loss': 0.8208689168095589} | train loss {'Reaction outcome loss': 0.8117663856098044, 'Total loss': 0.8117663856098044}
2022-11-22 23:59:36,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:36,729 INFO:     Epoch: 64
2022-11-22 23:59:37,509 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8349651342088525, 'Total loss': 0.8349651342088525} | train loss {'Reaction outcome loss': 0.8166250629946288, 'Total loss': 0.8166250629946288}
2022-11-22 23:59:37,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:37,509 INFO:     Epoch: 65
2022-11-22 23:59:38,345 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8254523466933857, 'Total loss': 0.8254523466933857} | train loss {'Reaction outcome loss': 0.8135042731095905, 'Total loss': 0.8135042731095905}
2022-11-22 23:59:38,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:38,345 INFO:     Epoch: 66
2022-11-22 23:59:39,176 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8198595345020294, 'Total loss': 0.8198595345020294} | train loss {'Reaction outcome loss': 0.8109583144004529, 'Total loss': 0.8109583144004529}
2022-11-22 23:59:39,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:39,176 INFO:     Epoch: 67
2022-11-22 23:59:39,934 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8333074152469635, 'Total loss': 0.8333074152469635} | train loss {'Reaction outcome loss': 0.8173785535430136, 'Total loss': 0.8173785535430136}
2022-11-22 23:59:39,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:39,935 INFO:     Epoch: 68
2022-11-22 23:59:40,740 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8272085819732059, 'Total loss': 0.8272085819732059} | train loss {'Reaction outcome loss': 0.8120277053431461, 'Total loss': 0.8120277053431461}
2022-11-22 23:59:40,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:40,740 INFO:     Epoch: 69
2022-11-22 23:59:41,545 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8310911242257465, 'Total loss': 0.8310911242257465} | train loss {'Reaction outcome loss': 0.8139618486769287, 'Total loss': 0.8139618486769287}
2022-11-22 23:59:41,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:41,546 INFO:     Epoch: 70
2022-11-22 23:59:42,308 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8331512673334642, 'Total loss': 0.8331512673334642} | train loss {'Reaction outcome loss': 0.8130787133205275, 'Total loss': 0.8130787133205275}
2022-11-22 23:59:42,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:42,308 INFO:     Epoch: 71
2022-11-22 23:59:43,102 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.825843867930499, 'Total loss': 0.825843867930499} | train loss {'Reaction outcome loss': 0.8086740097053621, 'Total loss': 0.8086740097053621}
2022-11-22 23:59:43,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:43,103 INFO:     Epoch: 72
2022-11-22 23:59:43,945 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8291644277897748, 'Total loss': 0.8291644277897748} | train loss {'Reaction outcome loss': 0.8058421550552372, 'Total loss': 0.8058421550552372}
2022-11-22 23:59:43,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:43,945 INFO:     Epoch: 73
2022-11-22 23:59:44,750 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8206442310051485, 'Total loss': 0.8206442310051485} | train loss {'Reaction outcome loss': 0.8105597299964804, 'Total loss': 0.8105597299964804}
2022-11-22 23:59:44,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:44,750 INFO:     Epoch: 74
2022-11-22 23:59:45,543 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8257129869677804, 'Total loss': 0.8257129869677804} | train loss {'Reaction outcome loss': 0.8091290611095032, 'Total loss': 0.8091290611095032}
2022-11-22 23:59:45,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:45,543 INFO:     Epoch: 75
2022-11-22 23:59:46,357 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8438865122469988, 'Total loss': 0.8438865122469988} | train loss {'Reaction outcome loss': 0.8079156129949006, 'Total loss': 0.8079156129949006}
2022-11-22 23:59:46,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:46,357 INFO:     Epoch: 76
2022-11-22 23:59:47,241 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8342071514238011, 'Total loss': 0.8342071514238011} | train loss {'Reaction outcome loss': 0.8098872106084939, 'Total loss': 0.8098872106084939}
2022-11-22 23:59:47,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:47,241 INFO:     Epoch: 77
2022-11-22 23:59:48,083 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.814808417450298, 'Total loss': 0.814808417450298} | train loss {'Reaction outcome loss': 0.8173949757085638, 'Total loss': 0.8173949757085638}
2022-11-22 23:59:48,083 INFO:     Found new best model at epoch 77
2022-11-22 23:59:48,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:48,084 INFO:     Epoch: 78
2022-11-22 23:59:48,878 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8369176143949683, 'Total loss': 0.8369176143949683} | train loss {'Reaction outcome loss': 0.8075357036672624, 'Total loss': 0.8075357036672624}
2022-11-22 23:59:48,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:48,878 INFO:     Epoch: 79
2022-11-22 23:59:49,718 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.851997049017386, 'Total loss': 0.851997049017386} | train loss {'Reaction outcome loss': 0.8117726902488754, 'Total loss': 0.8117726902488754}
2022-11-22 23:59:49,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:49,718 INFO:     Epoch: 80
2022-11-22 23:59:50,527 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8142890388315375, 'Total loss': 0.8142890388315375} | train loss {'Reaction outcome loss': 0.8118003610717622, 'Total loss': 0.8118003610717622}
2022-11-22 23:59:50,527 INFO:     Found new best model at epoch 80
2022-11-22 23:59:50,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:50,528 INFO:     Epoch: 81
2022-11-22 23:59:51,327 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8347918221896345, 'Total loss': 0.8347918221896345} | train loss {'Reaction outcome loss': 0.8053589147112148, 'Total loss': 0.8053589147112148}
2022-11-22 23:59:51,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:51,328 INFO:     Epoch: 82
2022-11-22 23:59:52,167 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8091927983544089, 'Total loss': 0.8091927983544089} | train loss {'Reaction outcome loss': 0.811325969966317, 'Total loss': 0.811325969966317}
2022-11-22 23:59:52,168 INFO:     Found new best model at epoch 82
2022-11-22 23:59:52,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:52,169 INFO:     Epoch: 83
2022-11-22 23:59:52,962 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8340633294799111, 'Total loss': 0.8340633294799111} | train loss {'Reaction outcome loss': 0.8085756408058198, 'Total loss': 0.8085756408058198}
2022-11-22 23:59:52,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:52,962 INFO:     Epoch: 84
2022-11-22 23:59:53,756 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8327901295640252, 'Total loss': 0.8327901295640252} | train loss {'Reaction outcome loss': 0.8108025332573454, 'Total loss': 0.8108025332573454}
2022-11-22 23:59:53,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:53,757 INFO:     Epoch: 85
2022-11-22 23:59:54,525 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8262412053617564, 'Total loss': 0.8262412053617564} | train loss {'Reaction outcome loss': 0.8095675338859017, 'Total loss': 0.8095675338859017}
2022-11-22 23:59:54,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:54,525 INFO:     Epoch: 86
2022-11-22 23:59:55,325 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8188158063725992, 'Total loss': 0.8188158063725992} | train loss {'Reaction outcome loss': 0.8059136336028334, 'Total loss': 0.8059136336028334}
2022-11-22 23:59:55,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:55,325 INFO:     Epoch: 87
2022-11-22 23:59:56,117 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8436483794992621, 'Total loss': 0.8436483794992621} | train loss {'Reaction outcome loss': 0.8121325164912683, 'Total loss': 0.8121325164912683}
2022-11-22 23:59:56,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:56,117 INFO:     Epoch: 88
2022-11-22 23:59:56,933 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8348043411970139, 'Total loss': 0.8348043411970139} | train loss {'Reaction outcome loss': 0.8122449117874809, 'Total loss': 0.8122449117874809}
2022-11-22 23:59:56,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:56,933 INFO:     Epoch: 89
2022-11-22 23:59:57,768 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8312029743736441, 'Total loss': 0.8312029743736441} | train loss {'Reaction outcome loss': 0.81229212819806, 'Total loss': 0.81229212819806}
2022-11-22 23:59:57,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:57,768 INFO:     Epoch: 90
2022-11-22 23:59:58,584 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8112011734734882, 'Total loss': 0.8112011734734882} | train loss {'Reaction outcome loss': 0.8072223748996673, 'Total loss': 0.8072223748996673}
2022-11-22 23:59:58,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:58,585 INFO:     Epoch: 91
2022-11-22 23:59:59,387 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8334497680718248, 'Total loss': 0.8334497680718248} | train loss {'Reaction outcome loss': 0.8079803937721831, 'Total loss': 0.8079803937721831}
2022-11-22 23:59:59,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-22 23:59:59,387 INFO:     Epoch: 92
2022-11-23 00:00:00,248 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8334235670891675, 'Total loss': 0.8334235670891675} | train loss {'Reaction outcome loss': 0.8049535528428642, 'Total loss': 0.8049535528428642}
2022-11-23 00:00:00,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:00,249 INFO:     Epoch: 93
2022-11-23 00:00:01,038 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8329886848276312, 'Total loss': 0.8329886848276312} | train loss {'Reaction outcome loss': 0.8092573028103061, 'Total loss': 0.8092573028103061}
2022-11-23 00:00:01,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:01,039 INFO:     Epoch: 94
2022-11-23 00:00:01,838 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.817142741246657, 'Total loss': 0.817142741246657} | train loss {'Reaction outcome loss': 0.8025092444559823, 'Total loss': 0.8025092444559823}
2022-11-23 00:00:01,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:01,839 INFO:     Epoch: 95
2022-11-23 00:00:02,664 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8135901445692236, 'Total loss': 0.8135901445692236} | train loss {'Reaction outcome loss': 0.8077665039824571, 'Total loss': 0.8077665039824571}
2022-11-23 00:00:02,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:02,664 INFO:     Epoch: 96
2022-11-23 00:00:03,518 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8139773857864466, 'Total loss': 0.8139773857864466} | train loss {'Reaction outcome loss': 0.8090104008251838, 'Total loss': 0.8090104008251838}
2022-11-23 00:00:03,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:03,519 INFO:     Epoch: 97
2022-11-23 00:00:04,325 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8304327401247892, 'Total loss': 0.8304327401247892} | train loss {'Reaction outcome loss': 0.8165124319342949, 'Total loss': 0.8165124319342949}
2022-11-23 00:00:04,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:04,327 INFO:     Epoch: 98
2022-11-23 00:00:05,156 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8210277211937037, 'Total loss': 0.8210277211937037} | train loss {'Reaction outcome loss': 0.8041318874308455, 'Total loss': 0.8041318874308455}
2022-11-23 00:00:05,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:05,156 INFO:     Epoch: 99
2022-11-23 00:00:06,007 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8284131349487738, 'Total loss': 0.8284131349487738} | train loss {'Reaction outcome loss': 0.8139407024209798, 'Total loss': 0.8139407024209798}
2022-11-23 00:00:06,008 INFO:     Best model found after epoch 83 of 100.
2022-11-23 00:00:06,008 INFO:   Done with stage: TRAINING
2022-11-23 00:00:06,008 INFO:   Starting stage: EVALUATION
2022-11-23 00:00:06,133 INFO:   Done with stage: EVALUATION
2022-11-23 00:00:06,133 INFO:   Leaving out SEQ value Fold_6
2022-11-23 00:00:06,147 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:00:06,147 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:00:06,819 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:00:06,819 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:00:06,890 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:00:06,890 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:00:06,890 INFO:     No hyperparam tuning for this model
2022-11-23 00:00:06,891 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:00:06,891 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:00:06,891 INFO:     None feature selector for col prot
2022-11-23 00:00:06,892 INFO:     None feature selector for col prot
2022-11-23 00:00:06,892 INFO:     None feature selector for col prot
2022-11-23 00:00:06,892 INFO:     None feature selector for col chem
2022-11-23 00:00:06,892 INFO:     None feature selector for col chem
2022-11-23 00:00:06,893 INFO:     None feature selector for col chem
2022-11-23 00:00:06,893 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:00:06,893 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:00:06,894 INFO:     Number of params in model 168571
2022-11-23 00:00:06,898 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:00:06,898 INFO:   Starting stage: TRAINING
2022-11-23 00:00:06,956 INFO:     Val loss before train {'Reaction outcome loss': 0.9653910073367032, 'Total loss': 0.9653910073367032}
2022-11-23 00:00:06,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:06,956 INFO:     Epoch: 0
2022-11-23 00:00:07,746 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8202958608215506, 'Total loss': 0.8202958608215506} | train loss {'Reaction outcome loss': 0.8785895678785539, 'Total loss': 0.8785895678785539}
2022-11-23 00:00:07,746 INFO:     Found new best model at epoch 0
2022-11-23 00:00:07,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:07,747 INFO:     Epoch: 1
2022-11-23 00:00:08,543 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8132251589135691, 'Total loss': 0.8132251589135691} | train loss {'Reaction outcome loss': 0.8516197899176229, 'Total loss': 0.8516197899176229}
2022-11-23 00:00:08,543 INFO:     Found new best model at epoch 1
2022-11-23 00:00:08,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:08,544 INFO:     Epoch: 2
2022-11-23 00:00:09,354 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8067979223348878, 'Total loss': 0.8067979223348878} | train loss {'Reaction outcome loss': 0.8474215245054614, 'Total loss': 0.8474215245054614}
2022-11-23 00:00:09,354 INFO:     Found new best model at epoch 2
2022-11-23 00:00:09,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:09,355 INFO:     Epoch: 3
2022-11-23 00:00:10,164 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7874511378732595, 'Total loss': 0.7874511378732595} | train loss {'Reaction outcome loss': 0.8362069914658223, 'Total loss': 0.8362069914658223}
2022-11-23 00:00:10,164 INFO:     Found new best model at epoch 3
2022-11-23 00:00:10,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:10,165 INFO:     Epoch: 4
2022-11-23 00:00:11,011 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8036191456697204, 'Total loss': 0.8036191456697204} | train loss {'Reaction outcome loss': 0.8347666719027104, 'Total loss': 0.8347666719027104}
2022-11-23 00:00:11,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:11,012 INFO:     Epoch: 5
2022-11-23 00:00:11,826 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7945821569724516, 'Total loss': 0.7945821569724516} | train loss {'Reaction outcome loss': 0.8372997396415279, 'Total loss': 0.8372997396415279}
2022-11-23 00:00:11,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:11,826 INFO:     Epoch: 6
2022-11-23 00:00:12,680 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7789994349533861, 'Total loss': 0.7789994349533861} | train loss {'Reaction outcome loss': 0.8353203774219559, 'Total loss': 0.8353203774219559}
2022-11-23 00:00:12,680 INFO:     Found new best model at epoch 6
2022-11-23 00:00:12,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:12,681 INFO:     Epoch: 7
2022-11-23 00:00:13,472 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7890025736256079, 'Total loss': 0.7890025736256079} | train loss {'Reaction outcome loss': 0.8306942254064544, 'Total loss': 0.8306942254064544}
2022-11-23 00:00:13,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:13,472 INFO:     Epoch: 8
2022-11-23 00:00:14,273 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7777845459905538, 'Total loss': 0.7777845459905538} | train loss {'Reaction outcome loss': 0.8330861084884212, 'Total loss': 0.8330861084884212}
2022-11-23 00:00:14,274 INFO:     Found new best model at epoch 8
2022-11-23 00:00:14,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:14,274 INFO:     Epoch: 9
2022-11-23 00:00:15,056 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7836574099280618, 'Total loss': 0.7836574099280618} | train loss {'Reaction outcome loss': 0.8271489756241921, 'Total loss': 0.8271489756241921}
2022-11-23 00:00:15,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:15,056 INFO:     Epoch: 10
2022-11-23 00:00:15,878 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7749706527048891, 'Total loss': 0.7749706527048891} | train loss {'Reaction outcome loss': 0.8257541804304046, 'Total loss': 0.8257541804304046}
2022-11-23 00:00:15,879 INFO:     Found new best model at epoch 10
2022-11-23 00:00:15,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:15,879 INFO:     Epoch: 11
2022-11-23 00:00:16,714 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.779353566467762, 'Total loss': 0.779353566467762} | train loss {'Reaction outcome loss': 0.8227133841043518, 'Total loss': 0.8227133841043518}
2022-11-23 00:00:16,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:16,714 INFO:     Epoch: 12
2022-11-23 00:00:17,497 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7880800667811524, 'Total loss': 0.7880800667811524} | train loss {'Reaction outcome loss': 0.8242053459248235, 'Total loss': 0.8242053459248235}
2022-11-23 00:00:17,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:17,497 INFO:     Epoch: 13
2022-11-23 00:00:18,289 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7724967937577855, 'Total loss': 0.7724967937577855} | train loss {'Reaction outcome loss': 0.8257529967494549, 'Total loss': 0.8257529967494549}
2022-11-23 00:00:18,289 INFO:     Found new best model at epoch 13
2022-11-23 00:00:18,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:18,290 INFO:     Epoch: 14
2022-11-23 00:00:19,117 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7775238169865175, 'Total loss': 0.7775238169865175} | train loss {'Reaction outcome loss': 0.8323369953901537, 'Total loss': 0.8323369953901537}
2022-11-23 00:00:19,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:19,118 INFO:     Epoch: 15
2022-11-23 00:00:19,960 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7751882218501784, 'Total loss': 0.7751882218501784} | train loss {'Reaction outcome loss': 0.8212396420778767, 'Total loss': 0.8212396420778767}
2022-11-23 00:00:19,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:19,960 INFO:     Epoch: 16
2022-11-23 00:00:20,806 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8131165836345066, 'Total loss': 0.8131165836345066} | train loss {'Reaction outcome loss': 0.8230618022141918, 'Total loss': 0.8230618022141918}
2022-11-23 00:00:20,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:20,806 INFO:     Epoch: 17
2022-11-23 00:00:21,605 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8018259053880518, 'Total loss': 0.8018259053880518} | train loss {'Reaction outcome loss': 0.8255224783093699, 'Total loss': 0.8255224783093699}
2022-11-23 00:00:21,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:21,605 INFO:     Epoch: 18
2022-11-23 00:00:22,420 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7740628516132181, 'Total loss': 0.7740628516132181} | train loss {'Reaction outcome loss': 0.8246791820612646, 'Total loss': 0.8246791820612646}
2022-11-23 00:00:22,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:22,421 INFO:     Epoch: 19
2022-11-23 00:00:23,236 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7714156041091139, 'Total loss': 0.7714156041091139} | train loss {'Reaction outcome loss': 0.8218037165220706, 'Total loss': 0.8218037165220706}
2022-11-23 00:00:23,237 INFO:     Found new best model at epoch 19
2022-11-23 00:00:23,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:23,238 INFO:     Epoch: 20
2022-11-23 00:00:24,047 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.773299821398475, 'Total loss': 0.773299821398475} | train loss {'Reaction outcome loss': 0.8184015074324223, 'Total loss': 0.8184015074324223}
2022-11-23 00:00:24,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:24,047 INFO:     Epoch: 21
2022-11-23 00:00:24,834 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.78517123921351, 'Total loss': 0.78517123921351} | train loss {'Reaction outcome loss': 0.8240935708726606, 'Total loss': 0.8240935708726606}
2022-11-23 00:00:24,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:24,834 INFO:     Epoch: 22
2022-11-23 00:00:25,646 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.798692489889535, 'Total loss': 0.798692489889535} | train loss {'Reaction outcome loss': 0.8151104020014885, 'Total loss': 0.8151104020014885}
2022-11-23 00:00:25,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:25,646 INFO:     Epoch: 23
2022-11-23 00:00:26,473 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7979903851043094, 'Total loss': 0.7979903851043094} | train loss {'Reaction outcome loss': 0.8166610969891471, 'Total loss': 0.8166610969891471}
2022-11-23 00:00:26,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:26,474 INFO:     Epoch: 24
2022-11-23 00:00:27,266 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7798685025085103, 'Total loss': 0.7798685025085103} | train loss {'Reaction outcome loss': 0.816234230394325, 'Total loss': 0.816234230394325}
2022-11-23 00:00:27,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:27,266 INFO:     Epoch: 25
2022-11-23 00:00:28,073 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8003230460665443, 'Total loss': 0.8003230460665443} | train loss {'Reaction outcome loss': 0.8172627955434784, 'Total loss': 0.8172627955434784}
2022-11-23 00:00:28,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:28,073 INFO:     Epoch: 26
2022-11-23 00:00:28,882 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7773913097652522, 'Total loss': 0.7773913097652522} | train loss {'Reaction outcome loss': 0.818927836634459, 'Total loss': 0.818927836634459}
2022-11-23 00:00:28,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:28,883 INFO:     Epoch: 27
2022-11-23 00:00:29,677 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7777035967870192, 'Total loss': 0.7777035967870192} | train loss {'Reaction outcome loss': 0.8212556689977646, 'Total loss': 0.8212556689977646}
2022-11-23 00:00:29,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:29,678 INFO:     Epoch: 28
2022-11-23 00:00:30,473 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.781263914975253, 'Total loss': 0.781263914975253} | train loss {'Reaction outcome loss': 0.8181788979038116, 'Total loss': 0.8181788979038116}
2022-11-23 00:00:30,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:30,473 INFO:     Epoch: 29
2022-11-23 00:00:31,277 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7868821289051663, 'Total loss': 0.7868821289051663} | train loss {'Reaction outcome loss': 0.819469332454666, 'Total loss': 0.819469332454666}
2022-11-23 00:00:31,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:31,277 INFO:     Epoch: 30
2022-11-23 00:00:32,074 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.773310353810137, 'Total loss': 0.773310353810137} | train loss {'Reaction outcome loss': 0.8175725019987552, 'Total loss': 0.8175725019987552}
2022-11-23 00:00:32,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:32,075 INFO:     Epoch: 31
2022-11-23 00:00:32,869 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7738284292546186, 'Total loss': 0.7738284292546186} | train loss {'Reaction outcome loss': 0.8205031074823872, 'Total loss': 0.8205031074823872}
2022-11-23 00:00:32,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:32,869 INFO:     Epoch: 32
2022-11-23 00:00:33,682 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.777130823243748, 'Total loss': 0.777130823243748} | train loss {'Reaction outcome loss': 0.8188126171308179, 'Total loss': 0.8188126171308179}
2022-11-23 00:00:33,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:33,682 INFO:     Epoch: 33
2022-11-23 00:00:34,488 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7699446556243029, 'Total loss': 0.7699446556243029} | train loss {'Reaction outcome loss': 0.8161046139655574, 'Total loss': 0.8161046139655574}
2022-11-23 00:00:34,488 INFO:     Found new best model at epoch 33
2022-11-23 00:00:34,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:34,489 INFO:     Epoch: 34
2022-11-23 00:00:35,313 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7700759280811657, 'Total loss': 0.7700759280811657} | train loss {'Reaction outcome loss': 0.8168156655325044, 'Total loss': 0.8168156655325044}
2022-11-23 00:00:35,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:35,314 INFO:     Epoch: 35
2022-11-23 00:00:36,116 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7781626649878242, 'Total loss': 0.7781626649878242} | train loss {'Reaction outcome loss': 0.8139058307053582, 'Total loss': 0.8139058307053582}
2022-11-23 00:00:36,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:36,116 INFO:     Epoch: 36
2022-11-23 00:00:36,916 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7796363945711743, 'Total loss': 0.7796363945711743} | train loss {'Reaction outcome loss': 0.8167915370675826, 'Total loss': 0.8167915370675826}
2022-11-23 00:00:36,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:36,917 INFO:     Epoch: 37
2022-11-23 00:00:37,730 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.785208794880997, 'Total loss': 0.785208794880997} | train loss {'Reaction outcome loss': 0.8192514923791732, 'Total loss': 0.8192514923791732}
2022-11-23 00:00:37,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:37,730 INFO:     Epoch: 38
2022-11-23 00:00:38,563 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7783763273195787, 'Total loss': 0.7783763273195787} | train loss {'Reaction outcome loss': 0.8159801306263093, 'Total loss': 0.8159801306263093}
2022-11-23 00:00:38,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:38,564 INFO:     Epoch: 39
2022-11-23 00:00:39,375 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7826443002982573, 'Total loss': 0.7826443002982573} | train loss {'Reaction outcome loss': 0.8181229111167693, 'Total loss': 0.8181229111167693}
2022-11-23 00:00:39,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:39,376 INFO:     Epoch: 40
2022-11-23 00:00:40,181 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8005547841841524, 'Total loss': 0.8005547841841524} | train loss {'Reaction outcome loss': 0.8154601482374053, 'Total loss': 0.8154601482374053}
2022-11-23 00:00:40,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:40,181 INFO:     Epoch: 41
2022-11-23 00:00:41,050 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7656294419006868, 'Total loss': 0.7656294419006868} | train loss {'Reaction outcome loss': 0.8198870957618759, 'Total loss': 0.8198870957618759}
2022-11-23 00:00:41,050 INFO:     Found new best model at epoch 41
2022-11-23 00:00:41,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:41,051 INFO:     Epoch: 42
2022-11-23 00:00:41,852 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7677858932451769, 'Total loss': 0.7677858932451769} | train loss {'Reaction outcome loss': 0.8141690999149315, 'Total loss': 0.8141690999149315}
2022-11-23 00:00:41,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:41,853 INFO:     Epoch: 43
2022-11-23 00:00:42,627 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7730547602881085, 'Total loss': 0.7730547602881085} | train loss {'Reaction outcome loss': 0.8247724237941927, 'Total loss': 0.8247724237941927}
2022-11-23 00:00:42,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:42,627 INFO:     Epoch: 44
2022-11-23 00:00:43,423 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7714704891497438, 'Total loss': 0.7714704891497438} | train loss {'Reaction outcome loss': 0.8232735097408295, 'Total loss': 0.8232735097408295}
2022-11-23 00:00:43,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:43,423 INFO:     Epoch: 45
2022-11-23 00:00:44,225 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7781359363685955, 'Total loss': 0.7781359363685955} | train loss {'Reaction outcome loss': 0.8146847583834202, 'Total loss': 0.8146847583834202}
2022-11-23 00:00:44,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:44,225 INFO:     Epoch: 46
2022-11-23 00:00:45,036 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7752749852158807, 'Total loss': 0.7752749852158807} | train loss {'Reaction outcome loss': 0.8213213235139847, 'Total loss': 0.8213213235139847}
2022-11-23 00:00:45,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:45,036 INFO:     Epoch: 47
2022-11-23 00:00:45,828 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7789481438019059, 'Total loss': 0.7789481438019059} | train loss {'Reaction outcome loss': 0.8168187658152273, 'Total loss': 0.8168187658152273}
2022-11-23 00:00:45,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:45,828 INFO:     Epoch: 48
2022-11-23 00:00:46,637 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7720253738490018, 'Total loss': 0.7720253738490018} | train loss {'Reaction outcome loss': 0.818770402381497, 'Total loss': 0.818770402381497}
2022-11-23 00:00:46,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:46,637 INFO:     Epoch: 49
2022-11-23 00:00:47,506 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7682517150586302, 'Total loss': 0.7682517150586302} | train loss {'Reaction outcome loss': 0.817562825737461, 'Total loss': 0.817562825737461}
2022-11-23 00:00:47,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:47,506 INFO:     Epoch: 50
2022-11-23 00:00:48,331 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7909694551066919, 'Total loss': 0.7909694551066919} | train loss {'Reaction outcome loss': 0.8205217625344953, 'Total loss': 0.8205217625344953}
2022-11-23 00:00:48,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:48,331 INFO:     Epoch: 51
2022-11-23 00:00:49,155 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7793227664448998, 'Total loss': 0.7793227664448998} | train loss {'Reaction outcome loss': 0.8169953309960903, 'Total loss': 0.8169953309960903}
2022-11-23 00:00:49,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:49,155 INFO:     Epoch: 52
2022-11-23 00:00:49,983 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7655437832528894, 'Total loss': 0.7655437832528894} | train loss {'Reaction outcome loss': 0.8177730158692406, 'Total loss': 0.8177730158692406}
2022-11-23 00:00:49,983 INFO:     Found new best model at epoch 52
2022-11-23 00:00:49,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:49,984 INFO:     Epoch: 53
2022-11-23 00:00:50,768 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7859266772866249, 'Total loss': 0.7859266772866249} | train loss {'Reaction outcome loss': 0.8156820696688467, 'Total loss': 0.8156820696688467}
2022-11-23 00:00:50,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:50,768 INFO:     Epoch: 54
2022-11-23 00:00:51,579 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7972594553774054, 'Total loss': 0.7972594553774054} | train loss {'Reaction outcome loss': 0.814736858731316, 'Total loss': 0.814736858731316}
2022-11-23 00:00:51,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:51,579 INFO:     Epoch: 55
2022-11-23 00:00:52,413 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7762113768946041, 'Total loss': 0.7762113768946041} | train loss {'Reaction outcome loss': 0.8189220577478409, 'Total loss': 0.8189220577478409}
2022-11-23 00:00:52,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:52,413 INFO:     Epoch: 56
2022-11-23 00:00:53,246 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.772778641093861, 'Total loss': 0.772778641093861} | train loss {'Reaction outcome loss': 0.8168125466233299, 'Total loss': 0.8168125466233299}
2022-11-23 00:00:53,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:53,246 INFO:     Epoch: 57
2022-11-23 00:00:54,109 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7891227101737802, 'Total loss': 0.7891227101737802} | train loss {'Reaction outcome loss': 0.8195479001489377, 'Total loss': 0.8195479001489377}
2022-11-23 00:00:54,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:54,110 INFO:     Epoch: 58
2022-11-23 00:00:54,977 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7729869505221193, 'Total loss': 0.7729869505221193} | train loss {'Reaction outcome loss': 0.812659879004763, 'Total loss': 0.812659879004763}
2022-11-23 00:00:54,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:54,978 INFO:     Epoch: 59
2022-11-23 00:00:55,779 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7716861177574504, 'Total loss': 0.7716861177574504} | train loss {'Reaction outcome loss': 0.8198694003926169, 'Total loss': 0.8198694003926169}
2022-11-23 00:00:55,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:55,780 INFO:     Epoch: 60
2022-11-23 00:00:56,619 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7927259186452086, 'Total loss': 0.7927259186452086} | train loss {'Reaction outcome loss': 0.8145876387434621, 'Total loss': 0.8145876387434621}
2022-11-23 00:00:56,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:56,619 INFO:     Epoch: 61
2022-11-23 00:00:57,428 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7788750989870592, 'Total loss': 0.7788750989870592} | train loss {'Reaction outcome loss': 0.8177858169280714, 'Total loss': 0.8177858169280714}
2022-11-23 00:00:57,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:57,429 INFO:     Epoch: 62
2022-11-23 00:00:58,209 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.773234489289197, 'Total loss': 0.773234489289197} | train loss {'Reaction outcome loss': 0.8181551234616388, 'Total loss': 0.8181551234616388}
2022-11-23 00:00:58,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:58,209 INFO:     Epoch: 63
2022-11-23 00:00:59,037 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7785759012807499, 'Total loss': 0.7785759012807499} | train loss {'Reaction outcome loss': 0.8150160679173085, 'Total loss': 0.8150160679173085}
2022-11-23 00:00:59,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:59,037 INFO:     Epoch: 64
2022-11-23 00:00:59,906 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7752861854704943, 'Total loss': 0.7752861854704943} | train loss {'Reaction outcome loss': 0.8163701388384065, 'Total loss': 0.8163701388384065}
2022-11-23 00:00:59,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:00:59,907 INFO:     Epoch: 65
2022-11-23 00:01:00,743 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7779699083078991, 'Total loss': 0.7779699083078991} | train loss {'Reaction outcome loss': 0.819289899521297, 'Total loss': 0.819289899521297}
2022-11-23 00:01:00,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:00,743 INFO:     Epoch: 66
2022-11-23 00:01:01,600 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7788315022533591, 'Total loss': 0.7788315022533591} | train loss {'Reaction outcome loss': 0.8120063877394122, 'Total loss': 0.8120063877394122}
2022-11-23 00:01:01,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:01,601 INFO:     Epoch: 67
2022-11-23 00:01:02,408 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7658942294391718, 'Total loss': 0.7658942294391718} | train loss {'Reaction outcome loss': 0.8168060350562295, 'Total loss': 0.8168060350562295}
2022-11-23 00:01:02,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:02,408 INFO:     Epoch: 68
2022-11-23 00:01:03,198 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7718265612017025, 'Total loss': 0.7718265612017025} | train loss {'Reaction outcome loss': 0.8183840731939962, 'Total loss': 0.8183840731939962}
2022-11-23 00:01:03,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:03,198 INFO:     Epoch: 69
2022-11-23 00:01:04,027 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7676709788766775, 'Total loss': 0.7676709788766775} | train loss {'Reaction outcome loss': 0.8132815489605549, 'Total loss': 0.8132815489605549}
2022-11-23 00:01:04,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:04,027 INFO:     Epoch: 70
2022-11-23 00:01:04,925 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7665313861586831, 'Total loss': 0.7665313861586831} | train loss {'Reaction outcome loss': 0.816927041738264, 'Total loss': 0.816927041738264}
2022-11-23 00:01:04,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:04,926 INFO:     Epoch: 71
2022-11-23 00:01:05,797 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.790061582218517, 'Total loss': 0.790061582218517} | train loss {'Reaction outcome loss': 0.8159314523781499, 'Total loss': 0.8159314523781499}
2022-11-23 00:01:05,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:05,798 INFO:     Epoch: 72
2022-11-23 00:01:06,692 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7688496119596742, 'Total loss': 0.7688496119596742} | train loss {'Reaction outcome loss': 0.8152419669974235, 'Total loss': 0.8152419669974235}
2022-11-23 00:01:06,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:06,692 INFO:     Epoch: 73
2022-11-23 00:01:07,535 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7722952481020581, 'Total loss': 0.7722952481020581} | train loss {'Reaction outcome loss': 0.82140631709368, 'Total loss': 0.82140631709368}
2022-11-23 00:01:07,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:07,535 INFO:     Epoch: 74
2022-11-23 00:01:08,392 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7728244763883677, 'Total loss': 0.7728244763883677} | train loss {'Reaction outcome loss': 0.8202953760422045, 'Total loss': 0.8202953760422045}
2022-11-23 00:01:08,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:08,393 INFO:     Epoch: 75
2022-11-23 00:01:09,174 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7790285084735263, 'Total loss': 0.7790285084735263} | train loss {'Reaction outcome loss': 0.8155223017017688, 'Total loss': 0.8155223017017688}
2022-11-23 00:01:09,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:09,174 INFO:     Epoch: 76
2022-11-23 00:01:09,976 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7721049243753607, 'Total loss': 0.7721049243753607} | train loss {'Reaction outcome loss': 0.8189948786410594, 'Total loss': 0.8189948786410594}
2022-11-23 00:01:09,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:09,976 INFO:     Epoch: 77
2022-11-23 00:01:10,750 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7893497740680521, 'Total loss': 0.7893497740680521} | train loss {'Reaction outcome loss': 0.8148573338985443, 'Total loss': 0.8148573338985443}
2022-11-23 00:01:10,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:10,750 INFO:     Epoch: 78
2022-11-23 00:01:11,541 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7826769236813892, 'Total loss': 0.7826769236813892} | train loss {'Reaction outcome loss': 0.8172043804680148, 'Total loss': 0.8172043804680148}
2022-11-23 00:01:11,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:11,541 INFO:     Epoch: 79
2022-11-23 00:01:12,324 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7671693123199723, 'Total loss': 0.7671693123199723} | train loss {'Reaction outcome loss': 0.8194529809538396, 'Total loss': 0.8194529809538396}
2022-11-23 00:01:12,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:12,325 INFO:     Epoch: 80
2022-11-23 00:01:13,112 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8010734881867062, 'Total loss': 0.8010734881867062} | train loss {'Reaction outcome loss': 0.817944239224157, 'Total loss': 0.817944239224157}
2022-11-23 00:01:13,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:13,112 INFO:     Epoch: 81
2022-11-23 00:01:13,866 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7839724015105854, 'Total loss': 0.7839724015105854} | train loss {'Reaction outcome loss': 0.8198534267083291, 'Total loss': 0.8198534267083291}
2022-11-23 00:01:13,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:13,867 INFO:     Epoch: 82
2022-11-23 00:01:14,643 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7916074882854115, 'Total loss': 0.7916074882854115} | train loss {'Reaction outcome loss': 0.8166537370172239, 'Total loss': 0.8166537370172239}
2022-11-23 00:01:14,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:14,643 INFO:     Epoch: 83
2022-11-23 00:01:15,424 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7741016014055773, 'Total loss': 0.7741016014055773} | train loss {'Reaction outcome loss': 0.8184298141108405, 'Total loss': 0.8184298141108405}
2022-11-23 00:01:15,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:15,425 INFO:     Epoch: 84
2022-11-23 00:01:16,213 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7840665917504918, 'Total loss': 0.7840665917504918} | train loss {'Reaction outcome loss': 0.8175057332602239, 'Total loss': 0.8175057332602239}
2022-11-23 00:01:16,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:16,214 INFO:     Epoch: 85
2022-11-23 00:01:16,985 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7837617519226941, 'Total loss': 0.7837617519226941} | train loss {'Reaction outcome loss': 0.818865027879515, 'Total loss': 0.818865027879515}
2022-11-23 00:01:16,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:16,985 INFO:     Epoch: 86
2022-11-23 00:01:17,782 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.77864795550704, 'Total loss': 0.77864795550704} | train loss {'Reaction outcome loss': 0.8207547256062108, 'Total loss': 0.8207547256062108}
2022-11-23 00:01:17,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:17,782 INFO:     Epoch: 87
2022-11-23 00:01:18,543 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7695918923074548, 'Total loss': 0.7695918923074548} | train loss {'Reaction outcome loss': 0.8155986957492367, 'Total loss': 0.8155986957492367}
2022-11-23 00:01:18,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:18,543 INFO:     Epoch: 88
2022-11-23 00:01:19,341 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.772967434742234, 'Total loss': 0.772967434742234} | train loss {'Reaction outcome loss': 0.8156903537531053, 'Total loss': 0.8156903537531053}
2022-11-23 00:01:19,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:19,341 INFO:     Epoch: 89
2022-11-23 00:01:20,155 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7924446693875573, 'Total loss': 0.7924446693875573} | train loss {'Reaction outcome loss': 0.814409660956552, 'Total loss': 0.814409660956552}
2022-11-23 00:01:20,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:20,155 INFO:     Epoch: 90
2022-11-23 00:01:20,991 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7941276133060455, 'Total loss': 0.7941276133060455} | train loss {'Reaction outcome loss': 0.8161530968162322, 'Total loss': 0.8161530968162322}
2022-11-23 00:01:20,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:20,991 INFO:     Epoch: 91
2022-11-23 00:01:21,812 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.762645813551816, 'Total loss': 0.762645813551816} | train loss {'Reaction outcome loss': 0.8131947346752689, 'Total loss': 0.8131947346752689}
2022-11-23 00:01:21,812 INFO:     Found new best model at epoch 91
2022-11-23 00:01:21,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:21,813 INFO:     Epoch: 92
2022-11-23 00:01:22,626 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7677987299182198, 'Total loss': 0.7677987299182198} | train loss {'Reaction outcome loss': 0.8186077661812305, 'Total loss': 0.8186077661812305}
2022-11-23 00:01:22,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:22,626 INFO:     Epoch: 93
2022-11-23 00:01:23,413 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8056667663834312, 'Total loss': 0.8056667663834312} | train loss {'Reaction outcome loss': 0.8192503186723878, 'Total loss': 0.8192503186723878}
2022-11-23 00:01:23,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:23,413 INFO:     Epoch: 94
2022-11-23 00:01:24,245 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7736435478383844, 'Total loss': 0.7736435478383844} | train loss {'Reaction outcome loss': 0.8168107237546675, 'Total loss': 0.8168107237546675}
2022-11-23 00:01:24,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:24,245 INFO:     Epoch: 95
2022-11-23 00:01:25,066 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7730877616188743, 'Total loss': 0.7730877616188743} | train loss {'Reaction outcome loss': 0.810931834001695, 'Total loss': 0.810931834001695}
2022-11-23 00:01:25,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:25,067 INFO:     Epoch: 96
2022-11-23 00:01:25,911 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.768403866074302, 'Total loss': 0.768403866074302} | train loss {'Reaction outcome loss': 0.8177455985137532, 'Total loss': 0.8177455985137532}
2022-11-23 00:01:25,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:25,911 INFO:     Epoch: 97
2022-11-23 00:01:26,737 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7711756798354062, 'Total loss': 0.7711756798354062} | train loss {'Reaction outcome loss': 0.8158935537982371, 'Total loss': 0.8158935537982371}
2022-11-23 00:01:26,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:26,738 INFO:     Epoch: 98
2022-11-23 00:01:27,523 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7779991409995339, 'Total loss': 0.7779991409995339} | train loss {'Reaction outcome loss': 0.8124291176997847, 'Total loss': 0.8124291176997847}
2022-11-23 00:01:27,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:27,523 INFO:     Epoch: 99
2022-11-23 00:01:28,277 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.772717294367877, 'Total loss': 0.772717294367877} | train loss {'Reaction outcome loss': 0.8202317807703249, 'Total loss': 0.8202317807703249}
2022-11-23 00:01:28,277 INFO:     Best model found after epoch 92 of 100.
2022-11-23 00:01:28,277 INFO:   Done with stage: TRAINING
2022-11-23 00:01:28,277 INFO:   Starting stage: EVALUATION
2022-11-23 00:01:28,399 INFO:   Done with stage: EVALUATION
2022-11-23 00:01:28,399 INFO:   Leaving out SEQ value Fold_7
2022-11-23 00:01:28,412 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:01:28,413 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:01:29,080 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:01:29,080 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:01:29,149 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:01:29,149 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:01:29,149 INFO:     No hyperparam tuning for this model
2022-11-23 00:01:29,149 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:01:29,149 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:01:29,150 INFO:     None feature selector for col prot
2022-11-23 00:01:29,150 INFO:     None feature selector for col prot
2022-11-23 00:01:29,151 INFO:     None feature selector for col prot
2022-11-23 00:01:29,151 INFO:     None feature selector for col chem
2022-11-23 00:01:29,151 INFO:     None feature selector for col chem
2022-11-23 00:01:29,151 INFO:     None feature selector for col chem
2022-11-23 00:01:29,151 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:01:29,152 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:01:29,153 INFO:     Number of params in model 168571
2022-11-23 00:01:29,156 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:01:29,156 INFO:   Starting stage: TRAINING
2022-11-23 00:01:29,214 INFO:     Val loss before train {'Reaction outcome loss': 1.044388715516437, 'Total loss': 1.044388715516437}
2022-11-23 00:01:29,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:29,215 INFO:     Epoch: 0
2022-11-23 00:01:30,042 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8513321720741012, 'Total loss': 0.8513321720741012} | train loss {'Reaction outcome loss': 0.8745885889140927, 'Total loss': 0.8745885889140927}
2022-11-23 00:01:30,042 INFO:     Found new best model at epoch 0
2022-11-23 00:01:30,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:30,043 INFO:     Epoch: 1
2022-11-23 00:01:30,867 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8489890085025267, 'Total loss': 0.8489890085025267} | train loss {'Reaction outcome loss': 0.8474022564839344, 'Total loss': 0.8474022564839344}
2022-11-23 00:01:30,867 INFO:     Found new best model at epoch 1
2022-11-23 00:01:30,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:30,868 INFO:     Epoch: 2
2022-11-23 00:01:31,657 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8760302330959927, 'Total loss': 0.8760302330959927} | train loss {'Reaction outcome loss': 0.8411897193412392, 'Total loss': 0.8411897193412392}
2022-11-23 00:01:31,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:31,657 INFO:     Epoch: 3
2022-11-23 00:01:32,469 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8299441716887734, 'Total loss': 0.8299441716887734} | train loss {'Reaction outcome loss': 0.8308043588180931, 'Total loss': 0.8308043588180931}
2022-11-23 00:01:32,469 INFO:     Found new best model at epoch 3
2022-11-23 00:01:32,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:32,470 INFO:     Epoch: 4
2022-11-23 00:01:33,264 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.854563145474954, 'Total loss': 0.854563145474954} | train loss {'Reaction outcome loss': 0.8311295066561017, 'Total loss': 0.8311295066561017}
2022-11-23 00:01:33,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:33,264 INFO:     Epoch: 5
2022-11-23 00:01:34,108 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8503495461561463, 'Total loss': 0.8503495461561463} | train loss {'Reaction outcome loss': 0.8265767265339287, 'Total loss': 0.8265767265339287}
2022-11-23 00:01:34,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:34,108 INFO:     Epoch: 6
2022-11-23 00:01:34,902 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8304780206897042, 'Total loss': 0.8304780206897042} | train loss {'Reaction outcome loss': 0.8217040782072106, 'Total loss': 0.8217040782072106}
2022-11-23 00:01:34,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:34,903 INFO:     Epoch: 7
2022-11-23 00:01:35,703 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8209845037622885, 'Total loss': 0.8209845037622885} | train loss {'Reaction outcome loss': 0.8119198042519239, 'Total loss': 0.8119198042519239}
2022-11-23 00:01:35,703 INFO:     Found new best model at epoch 7
2022-11-23 00:01:35,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:35,704 INFO:     Epoch: 8
2022-11-23 00:01:36,479 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8235203407027505, 'Total loss': 0.8235203407027505} | train loss {'Reaction outcome loss': 0.8151364636664488, 'Total loss': 0.8151364636664488}
2022-11-23 00:01:36,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:36,479 INFO:     Epoch: 9
2022-11-23 00:01:37,307 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8856310410933061, 'Total loss': 0.8856310410933061} | train loss {'Reaction outcome loss': 0.8173294213353371, 'Total loss': 0.8173294213353371}
2022-11-23 00:01:37,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:37,309 INFO:     Epoch: 10
2022-11-23 00:01:38,085 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8176152401349761, 'Total loss': 0.8176152401349761} | train loss {'Reaction outcome loss': 0.8151183068752289, 'Total loss': 0.8151183068752289}
2022-11-23 00:01:38,085 INFO:     Found new best model at epoch 10
2022-11-23 00:01:38,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:38,086 INFO:     Epoch: 11
2022-11-23 00:01:38,844 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8314213928851214, 'Total loss': 0.8314213928851214} | train loss {'Reaction outcome loss': 0.8151232349629305, 'Total loss': 0.8151232349629305}
2022-11-23 00:01:38,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:38,844 INFO:     Epoch: 12
2022-11-23 00:01:39,731 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.840912170030854, 'Total loss': 0.840912170030854} | train loss {'Reaction outcome loss': 0.8151151556141523, 'Total loss': 0.8151151556141523}
2022-11-23 00:01:39,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:39,731 INFO:     Epoch: 13
2022-11-23 00:01:40,543 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8481183742935007, 'Total loss': 0.8481183742935007} | train loss {'Reaction outcome loss': 0.8124835579979176, 'Total loss': 0.8124835579979176}
2022-11-23 00:01:40,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:40,544 INFO:     Epoch: 14
2022-11-23 00:01:41,347 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8502114272930406, 'Total loss': 0.8502114272930406} | train loss {'Reaction outcome loss': 0.8173721655290954, 'Total loss': 0.8173721655290954}
2022-11-23 00:01:41,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:41,347 INFO:     Epoch: 15
2022-11-23 00:01:42,118 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8186024170030247, 'Total loss': 0.8186024170030247} | train loss {'Reaction outcome loss': 0.8114398749507203, 'Total loss': 0.8114398749507203}
2022-11-23 00:01:42,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:42,119 INFO:     Epoch: 16
2022-11-23 00:01:42,904 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8119121532548558, 'Total loss': 0.8119121532548558} | train loss {'Reaction outcome loss': 0.8141095360931085, 'Total loss': 0.8141095360931085}
2022-11-23 00:01:42,905 INFO:     Found new best model at epoch 16
2022-11-23 00:01:42,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:42,905 INFO:     Epoch: 17
2022-11-23 00:01:43,697 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8412978906523098, 'Total loss': 0.8412978906523098} | train loss {'Reaction outcome loss': 0.8132275014507527, 'Total loss': 0.8132275014507527}
2022-11-23 00:01:43,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:43,699 INFO:     Epoch: 18
2022-11-23 00:01:44,440 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8453480479392138, 'Total loss': 0.8453480479392138} | train loss {'Reaction outcome loss': 0.8049324530728009, 'Total loss': 0.8049324530728009}
2022-11-23 00:01:44,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:44,440 INFO:     Epoch: 19
2022-11-23 00:01:45,231 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8261052153327249, 'Total loss': 0.8261052153327249} | train loss {'Reaction outcome loss': 0.8159306538348295, 'Total loss': 0.8159306538348295}
2022-11-23 00:01:45,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:45,231 INFO:     Epoch: 20
2022-11-23 00:01:46,024 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8188201056962664, 'Total loss': 0.8188201056962664} | train loss {'Reaction outcome loss': 0.8135220842702048, 'Total loss': 0.8135220842702048}
2022-11-23 00:01:46,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:46,024 INFO:     Epoch: 21
2022-11-23 00:01:46,798 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8221877494996245, 'Total loss': 0.8221877494996245} | train loss {'Reaction outcome loss': 0.8141484131618422, 'Total loss': 0.8141484131618422}
2022-11-23 00:01:46,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:46,798 INFO:     Epoch: 22
2022-11-23 00:01:47,579 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8295687159354036, 'Total loss': 0.8295687159354036} | train loss {'Reaction outcome loss': 0.8119659853224852, 'Total loss': 0.8119659853224852}
2022-11-23 00:01:47,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:47,579 INFO:     Epoch: 23
2022-11-23 00:01:48,382 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8250700601122596, 'Total loss': 0.8250700601122596} | train loss {'Reaction outcome loss': 0.8099150385175432, 'Total loss': 0.8099150385175432}
2022-11-23 00:01:48,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:48,382 INFO:     Epoch: 24
2022-11-23 00:01:49,164 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.82824460755695, 'Total loss': 0.82824460755695} | train loss {'Reaction outcome loss': 0.8098409198984808, 'Total loss': 0.8098409198984808}
2022-11-23 00:01:49,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:49,165 INFO:     Epoch: 25
2022-11-23 00:01:49,949 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8609095608646219, 'Total loss': 0.8609095608646219} | train loss {'Reaction outcome loss': 0.8089199724246044, 'Total loss': 0.8089199724246044}
2022-11-23 00:01:49,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:49,950 INFO:     Epoch: 26
2022-11-23 00:01:50,741 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.819917995821346, 'Total loss': 0.819917995821346} | train loss {'Reaction outcome loss': 0.8086353069665481, 'Total loss': 0.8086353069665481}
2022-11-23 00:01:50,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:50,741 INFO:     Epoch: 27
2022-11-23 00:01:51,515 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8325608995827761, 'Total loss': 0.8325608995827761} | train loss {'Reaction outcome loss': 0.8043565666188999, 'Total loss': 0.8043565666188999}
2022-11-23 00:01:51,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:51,515 INFO:     Epoch: 28
2022-11-23 00:01:52,294 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8275571492585269, 'Total loss': 0.8275571492585269} | train loss {'Reaction outcome loss': 0.8069097944668361, 'Total loss': 0.8069097944668361}
2022-11-23 00:01:52,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:52,294 INFO:     Epoch: 29
2022-11-23 00:01:53,054 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8109145035797899, 'Total loss': 0.8109145035797899} | train loss {'Reaction outcome loss': 0.8121855740644494, 'Total loss': 0.8121855740644494}
2022-11-23 00:01:53,055 INFO:     Found new best model at epoch 29
2022-11-23 00:01:53,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:53,056 INFO:     Epoch: 30
2022-11-23 00:01:53,822 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8058672648939219, 'Total loss': 0.8058672648939219} | train loss {'Reaction outcome loss': 0.8083168326591958, 'Total loss': 0.8083168326591958}
2022-11-23 00:01:53,823 INFO:     Found new best model at epoch 30
2022-11-23 00:01:53,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:53,823 INFO:     Epoch: 31
2022-11-23 00:01:54,591 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8190581602129069, 'Total loss': 0.8190581602129069} | train loss {'Reaction outcome loss': 0.8074751631337769, 'Total loss': 0.8074751631337769}
2022-11-23 00:01:54,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:54,591 INFO:     Epoch: 32
2022-11-23 00:01:55,370 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8423346362330697, 'Total loss': 0.8423346362330697} | train loss {'Reaction outcome loss': 0.8055762857806926, 'Total loss': 0.8055762857806926}
2022-11-23 00:01:55,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:55,370 INFO:     Epoch: 33
2022-11-23 00:01:56,162 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8601178892634131, 'Total loss': 0.8601178892634131} | train loss {'Reaction outcome loss': 0.8139589679484465, 'Total loss': 0.8139589679484465}
2022-11-23 00:01:56,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:56,163 INFO:     Epoch: 34
2022-11-23 00:01:56,931 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8135712438009002, 'Total loss': 0.8135712438009002} | train loss {'Reaction outcome loss': 0.8076364636421204, 'Total loss': 0.8076364636421204}
2022-11-23 00:01:56,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:56,931 INFO:     Epoch: 35
2022-11-23 00:01:57,700 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.817681300369176, 'Total loss': 0.817681300369176} | train loss {'Reaction outcome loss': 0.8060333951395385, 'Total loss': 0.8060333951395385}
2022-11-23 00:01:57,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:57,700 INFO:     Epoch: 36
2022-11-23 00:01:58,430 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.811645354736935, 'Total loss': 0.811645354736935} | train loss {'Reaction outcome loss': 0.8113302865806891, 'Total loss': 0.8113302865806891}
2022-11-23 00:01:58,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:58,430 INFO:     Epoch: 37
2022-11-23 00:01:59,202 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8356668888167902, 'Total loss': 0.8356668888167902} | train loss {'Reaction outcome loss': 0.8105885270906954, 'Total loss': 0.8105885270906954}
2022-11-23 00:01:59,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:59,202 INFO:     Epoch: 38
2022-11-23 00:01:59,985 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8140724463896318, 'Total loss': 0.8140724463896318} | train loss {'Reaction outcome loss': 0.8061636625504007, 'Total loss': 0.8061636625504007}
2022-11-23 00:01:59,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:01:59,985 INFO:     Epoch: 39
2022-11-23 00:02:00,757 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8341814875602722, 'Total loss': 0.8341814875602722} | train loss {'Reaction outcome loss': 0.805418084348951, 'Total loss': 0.805418084348951}
2022-11-23 00:02:00,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:00,758 INFO:     Epoch: 40
2022-11-23 00:02:01,536 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8249234882268038, 'Total loss': 0.8249234882268038} | train loss {'Reaction outcome loss': 0.8059319670103035, 'Total loss': 0.8059319670103035}
2022-11-23 00:02:01,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:01,536 INFO:     Epoch: 41
2022-11-23 00:02:02,328 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8220566192811186, 'Total loss': 0.8220566192811186} | train loss {'Reaction outcome loss': 0.8045130663988541, 'Total loss': 0.8045130663988541}
2022-11-23 00:02:02,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:02,329 INFO:     Epoch: 42
2022-11-23 00:02:03,125 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8117604783990167, 'Total loss': 0.8117604783990167} | train loss {'Reaction outcome loss': 0.8083780877444209, 'Total loss': 0.8083780877444209}
2022-11-23 00:02:03,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:03,125 INFO:     Epoch: 43
2022-11-23 00:02:03,914 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.81676220419732, 'Total loss': 0.81676220419732} | train loss {'Reaction outcome loss': 0.8070675528779322, 'Total loss': 0.8070675528779322}
2022-11-23 00:02:03,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:03,914 INFO:     Epoch: 44
2022-11-23 00:02:04,694 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8079256178303198, 'Total loss': 0.8079256178303198} | train loss {'Reaction outcome loss': 0.8022052631086233, 'Total loss': 0.8022052631086233}
2022-11-23 00:02:04,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:04,694 INFO:     Epoch: 45
2022-11-23 00:02:05,475 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8285941603508863, 'Total loss': 0.8285941603508863} | train loss {'Reaction outcome loss': 0.8059011955650486, 'Total loss': 0.8059011955650486}
2022-11-23 00:02:05,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:05,475 INFO:     Epoch: 46
2022-11-23 00:02:06,363 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8556578931483355, 'Total loss': 0.8556578931483355} | train loss {'Reaction outcome loss': 0.8102319828101567, 'Total loss': 0.8102319828101567}
2022-11-23 00:02:06,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:06,363 INFO:     Epoch: 47
2022-11-23 00:02:07,213 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8601884970610792, 'Total loss': 0.8601884970610792} | train loss {'Reaction outcome loss': 0.8069223330945384, 'Total loss': 0.8069223330945384}
2022-11-23 00:02:07,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:07,213 INFO:     Epoch: 48
2022-11-23 00:02:08,106 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8043161698363044, 'Total loss': 0.8043161698363044} | train loss {'Reaction outcome loss': 0.8048076161316463, 'Total loss': 0.8048076161316463}
2022-11-23 00:02:08,107 INFO:     Found new best model at epoch 48
2022-11-23 00:02:08,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:08,108 INFO:     Epoch: 49
2022-11-23 00:02:08,943 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8316116793589159, 'Total loss': 0.8316116793589159} | train loss {'Reaction outcome loss': 0.8057178924278338, 'Total loss': 0.8057178924278338}
2022-11-23 00:02:08,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:08,943 INFO:     Epoch: 50
2022-11-23 00:02:09,835 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8244791762395338, 'Total loss': 0.8244791762395338} | train loss {'Reaction outcome loss': 0.8106074720012898, 'Total loss': 0.8106074720012898}
2022-11-23 00:02:09,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:09,835 INFO:     Epoch: 51
2022-11-23 00:02:10,712 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8053831607103348, 'Total loss': 0.8053831607103348} | train loss {'Reaction outcome loss': 0.8050852340094897, 'Total loss': 0.8050852340094897}
2022-11-23 00:02:10,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:10,712 INFO:     Epoch: 52
2022-11-23 00:02:11,628 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8271934830329635, 'Total loss': 0.8271934830329635} | train loss {'Reaction outcome loss': 0.8026955527918679, 'Total loss': 0.8026955527918679}
2022-11-23 00:02:11,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:11,628 INFO:     Epoch: 53
2022-11-23 00:02:12,559 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8042211888188665, 'Total loss': 0.8042211888188665} | train loss {'Reaction outcome loss': 0.8071204094254241, 'Total loss': 0.8071204094254241}
2022-11-23 00:02:12,559 INFO:     Found new best model at epoch 53
2022-11-23 00:02:12,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:12,560 INFO:     Epoch: 54
2022-11-23 00:02:13,463 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8411834741180594, 'Total loss': 0.8411834741180594} | train loss {'Reaction outcome loss': 0.7997192936284202, 'Total loss': 0.7997192936284202}
2022-11-23 00:02:13,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:13,464 INFO:     Epoch: 55
2022-11-23 00:02:14,393 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.824337126179175, 'Total loss': 0.824337126179175} | train loss {'Reaction outcome loss': 0.8094972935258126, 'Total loss': 0.8094972935258126}
2022-11-23 00:02:14,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:14,394 INFO:     Epoch: 56
2022-11-23 00:02:15,359 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.826599817384373, 'Total loss': 0.826599817384373} | train loss {'Reaction outcome loss': 0.8035251031116564, 'Total loss': 0.8035251031116564}
2022-11-23 00:02:15,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:15,359 INFO:     Epoch: 57
2022-11-23 00:02:16,275 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8301208168268204, 'Total loss': 0.8301208168268204} | train loss {'Reaction outcome loss': 0.7998074515741699, 'Total loss': 0.7998074515741699}
2022-11-23 00:02:16,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:16,275 INFO:     Epoch: 58
2022-11-23 00:02:17,217 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8221841901540756, 'Total loss': 0.8221841901540756} | train loss {'Reaction outcome loss': 0.8108588925429753, 'Total loss': 0.8108588925429753}
2022-11-23 00:02:17,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:17,217 INFO:     Epoch: 59
2022-11-23 00:02:18,085 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8376805646853014, 'Total loss': 0.8376805646853014} | train loss {'Reaction outcome loss': 0.8054962099814902, 'Total loss': 0.8054962099814902}
2022-11-23 00:02:18,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:18,085 INFO:     Epoch: 60
2022-11-23 00:02:19,004 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8198496015234427, 'Total loss': 0.8198496015234427} | train loss {'Reaction outcome loss': 0.8093815235459074, 'Total loss': 0.8093815235459074}
2022-11-23 00:02:19,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:19,005 INFO:     Epoch: 61
2022-11-23 00:02:19,906 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8156867542050101, 'Total loss': 0.8156867542050101} | train loss {'Reaction outcome loss': 0.8023433016271008, 'Total loss': 0.8023433016271008}
2022-11-23 00:02:19,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:19,906 INFO:     Epoch: 62
2022-11-23 00:02:20,825 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.819384824145924, 'Total loss': 0.819384824145924} | train loss {'Reaction outcome loss': 0.8074345018182482, 'Total loss': 0.8074345018182482}
2022-11-23 00:02:20,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:20,826 INFO:     Epoch: 63
2022-11-23 00:02:21,736 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8328615169633519, 'Total loss': 0.8328615169633519} | train loss {'Reaction outcome loss': 0.8052032772375612, 'Total loss': 0.8052032772375612}
2022-11-23 00:02:21,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:21,736 INFO:     Epoch: 64
2022-11-23 00:02:22,618 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8249300388111309, 'Total loss': 0.8249300388111309} | train loss {'Reaction outcome loss': 0.8054100411278861, 'Total loss': 0.8054100411278861}
2022-11-23 00:02:22,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:22,618 INFO:     Epoch: 65
2022-11-23 00:02:23,515 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8058103973215277, 'Total loss': 0.8058103973215277} | train loss {'Reaction outcome loss': 0.804961823200693, 'Total loss': 0.804961823200693}
2022-11-23 00:02:23,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:23,515 INFO:     Epoch: 66
2022-11-23 00:02:24,388 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8118833418596875, 'Total loss': 0.8118833418596875} | train loss {'Reaction outcome loss': 0.8001592238338626, 'Total loss': 0.8001592238338626}
2022-11-23 00:02:24,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:24,388 INFO:     Epoch: 67
2022-11-23 00:02:25,343 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8347468308427117, 'Total loss': 0.8347468308427117} | train loss {'Reaction outcome loss': 0.8040892601013183, 'Total loss': 0.8040892601013183}
2022-11-23 00:02:25,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:25,343 INFO:     Epoch: 68
2022-11-23 00:02:26,294 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8123421926390041, 'Total loss': 0.8123421926390041} | train loss {'Reaction outcome loss': 0.8024635679867803, 'Total loss': 0.8024635679867803}
2022-11-23 00:02:26,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:26,294 INFO:     Epoch: 69
2022-11-23 00:02:27,222 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8291679390452125, 'Total loss': 0.8291679390452125} | train loss {'Reaction outcome loss': 0.8077303429039158, 'Total loss': 0.8077303429039158}
2022-11-23 00:02:27,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:27,223 INFO:     Epoch: 70
2022-11-23 00:02:28,113 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8314667560837485, 'Total loss': 0.8314667560837485} | train loss {'Reaction outcome loss': 0.8068165887375267, 'Total loss': 0.8068165887375267}
2022-11-23 00:02:28,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:28,113 INFO:     Epoch: 71
2022-11-23 00:02:28,959 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8032141029834747, 'Total loss': 0.8032141029834747} | train loss {'Reaction outcome loss': 0.804149683032717, 'Total loss': 0.804149683032717}
2022-11-23 00:02:28,959 INFO:     Found new best model at epoch 71
2022-11-23 00:02:28,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:28,960 INFO:     Epoch: 72
2022-11-23 00:02:29,816 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8352023769508709, 'Total loss': 0.8352023769508709} | train loss {'Reaction outcome loss': 0.8035475772254321, 'Total loss': 0.8035475772254321}
2022-11-23 00:02:29,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:29,816 INFO:     Epoch: 73
2022-11-23 00:02:30,764 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7977670163593509, 'Total loss': 0.7977670163593509} | train loss {'Reaction outcome loss': 0.8032603701766656, 'Total loss': 0.8032603701766656}
2022-11-23 00:02:30,764 INFO:     Found new best model at epoch 73
2022-11-23 00:02:30,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:30,765 INFO:     Epoch: 74
2022-11-23 00:02:31,668 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8185012340545654, 'Total loss': 0.8185012340545654} | train loss {'Reaction outcome loss': 0.8081449710592932, 'Total loss': 0.8081449710592932}
2022-11-23 00:02:31,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:31,668 INFO:     Epoch: 75
2022-11-23 00:02:32,530 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8278656114231456, 'Total loss': 0.8278656114231456} | train loss {'Reaction outcome loss': 0.8036993692115861, 'Total loss': 0.8036993692115861}
2022-11-23 00:02:32,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:32,531 INFO:     Epoch: 76
2022-11-23 00:02:33,384 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8312515176155351, 'Total loss': 0.8312515176155351} | train loss {'Reaction outcome loss': 0.8028182195157421, 'Total loss': 0.8028182195157421}
2022-11-23 00:02:33,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:33,385 INFO:     Epoch: 77
2022-11-23 00:02:34,263 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8019415912303057, 'Total loss': 0.8019415912303057} | train loss {'Reaction outcome loss': 0.8027719866256324, 'Total loss': 0.8027719866256324}
2022-11-23 00:02:34,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:34,264 INFO:     Epoch: 78
2022-11-23 00:02:35,191 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.834258183836937, 'Total loss': 0.834258183836937} | train loss {'Reaction outcome loss': 0.8063179821384197, 'Total loss': 0.8063179821384197}
2022-11-23 00:02:35,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:35,191 INFO:     Epoch: 79
2022-11-23 00:02:36,044 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8145607581192796, 'Total loss': 0.8145607581192796} | train loss {'Reaction outcome loss': 0.8098853584454984, 'Total loss': 0.8098853584454984}
2022-11-23 00:02:36,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:36,045 INFO:     Epoch: 80
2022-11-23 00:02:36,934 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8100880391218446, 'Total loss': 0.8100880391218446} | train loss {'Reaction outcome loss': 0.8094609949053551, 'Total loss': 0.8094609949053551}
2022-11-23 00:02:36,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:36,934 INFO:     Epoch: 81
2022-11-23 00:02:37,866 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8227990953759714, 'Total loss': 0.8227990953759714} | train loss {'Reaction outcome loss': 0.8024067225504895, 'Total loss': 0.8024067225504895}
2022-11-23 00:02:37,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:37,866 INFO:     Epoch: 82
2022-11-23 00:02:38,706 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8187742788683284, 'Total loss': 0.8187742788683284} | train loss {'Reaction outcome loss': 0.8065913114012504, 'Total loss': 0.8065913114012504}
2022-11-23 00:02:38,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:38,706 INFO:     Epoch: 83
2022-11-23 00:02:39,606 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8141336888074875, 'Total loss': 0.8141336888074875} | train loss {'Reaction outcome loss': 0.8017455869791459, 'Total loss': 0.8017455869791459}
2022-11-23 00:02:39,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:39,607 INFO:     Epoch: 84
2022-11-23 00:02:40,469 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8128609352491118, 'Total loss': 0.8128609352491118} | train loss {'Reaction outcome loss': 0.8054601736214696, 'Total loss': 0.8054601736214696}
2022-11-23 00:02:40,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:40,470 INFO:     Epoch: 85
2022-11-23 00:02:41,301 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8061228459700942, 'Total loss': 0.8061228459700942} | train loss {'Reaction outcome loss': 0.8031972211234424, 'Total loss': 0.8031972211234424}
2022-11-23 00:02:41,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:41,302 INFO:     Epoch: 86
2022-11-23 00:02:42,151 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8242805058305914, 'Total loss': 0.8242805058305914} | train loss {'Reaction outcome loss': 0.8056477839849433, 'Total loss': 0.8056477839849433}
2022-11-23 00:02:42,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:42,152 INFO:     Epoch: 87
2022-11-23 00:02:42,978 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8105941855094649, 'Total loss': 0.8105941855094649} | train loss {'Reaction outcome loss': 0.8033711882270113, 'Total loss': 0.8033711882270113}
2022-11-23 00:02:42,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:42,978 INFO:     Epoch: 88
2022-11-23 00:02:43,801 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8019600679928606, 'Total loss': 0.8019600679928606} | train loss {'Reaction outcome loss': 0.8061484501069905, 'Total loss': 0.8061484501069905}
2022-11-23 00:02:43,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:43,801 INFO:     Epoch: 89
2022-11-23 00:02:44,641 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8363970626484264, 'Total loss': 0.8363970626484264} | train loss {'Reaction outcome loss': 0.802077229777161, 'Total loss': 0.802077229777161}
2022-11-23 00:02:44,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:44,641 INFO:     Epoch: 90
2022-11-23 00:02:45,473 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8086144998669624, 'Total loss': 0.8086144998669624} | train loss {'Reaction outcome loss': 0.8036263260306145, 'Total loss': 0.8036263260306145}
2022-11-23 00:02:45,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:45,474 INFO:     Epoch: 91
2022-11-23 00:02:46,311 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8275052336129275, 'Total loss': 0.8275052336129275} | train loss {'Reaction outcome loss': 0.8022642074799051, 'Total loss': 0.8022642074799051}
2022-11-23 00:02:46,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:46,312 INFO:     Epoch: 92
2022-11-23 00:02:47,165 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8292869403958321, 'Total loss': 0.8292869403958321} | train loss {'Reaction outcome loss': 0.8015127882665517, 'Total loss': 0.8015127882665517}
2022-11-23 00:02:47,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:47,165 INFO:     Epoch: 93
2022-11-23 00:02:48,011 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8079667477445169, 'Total loss': 0.8079667477445169} | train loss {'Reaction outcome loss': 0.8021134912967682, 'Total loss': 0.8021134912967682}
2022-11-23 00:02:48,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:48,011 INFO:     Epoch: 94
2022-11-23 00:02:48,858 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8140280646356669, 'Total loss': 0.8140280646356669} | train loss {'Reaction outcome loss': 0.8033323343919248, 'Total loss': 0.8033323343919248}
2022-11-23 00:02:48,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:48,859 INFO:     Epoch: 95
2022-11-23 00:02:49,684 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8439673185348511, 'Total loss': 0.8439673185348511} | train loss {'Reaction outcome loss': 0.805442841563906, 'Total loss': 0.805442841563906}
2022-11-23 00:02:49,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:49,684 INFO:     Epoch: 96
2022-11-23 00:02:50,579 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8069475476037372, 'Total loss': 0.8069475476037372} | train loss {'Reaction outcome loss': 0.8009516904548722, 'Total loss': 0.8009516904548722}
2022-11-23 00:02:50,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:50,580 INFO:     Epoch: 97
2022-11-23 00:02:51,431 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8269658251242205, 'Total loss': 0.8269658251242205} | train loss {'Reaction outcome loss': 0.803349226226612, 'Total loss': 0.803349226226612}
2022-11-23 00:02:51,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:51,431 INFO:     Epoch: 98
2022-11-23 00:02:52,334 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8023987209255045, 'Total loss': 0.8023987209255045} | train loss {'Reaction outcome loss': 0.801338524964391, 'Total loss': 0.801338524964391}
2022-11-23 00:02:52,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:52,334 INFO:     Epoch: 99
2022-11-23 00:02:53,119 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8051896034316584, 'Total loss': 0.8051896034316584} | train loss {'Reaction outcome loss': 0.8002312624941067, 'Total loss': 0.8002312624941067}
2022-11-23 00:02:53,119 INFO:     Best model found after epoch 74 of 100.
2022-11-23 00:02:53,119 INFO:   Done with stage: TRAINING
2022-11-23 00:02:53,119 INFO:   Starting stage: EVALUATION
2022-11-23 00:02:53,251 INFO:   Done with stage: EVALUATION
2022-11-23 00:02:53,251 INFO:   Leaving out SEQ value Fold_8
2022-11-23 00:02:53,264 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:02:53,265 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:02:53,949 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:02:53,950 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:02:54,021 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:02:54,021 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:02:54,021 INFO:     No hyperparam tuning for this model
2022-11-23 00:02:54,021 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:02:54,021 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:02:54,022 INFO:     None feature selector for col prot
2022-11-23 00:02:54,022 INFO:     None feature selector for col prot
2022-11-23 00:02:54,023 INFO:     None feature selector for col prot
2022-11-23 00:02:54,023 INFO:     None feature selector for col chem
2022-11-23 00:02:54,023 INFO:     None feature selector for col chem
2022-11-23 00:02:54,023 INFO:     None feature selector for col chem
2022-11-23 00:02:54,024 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:02:54,024 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:02:54,025 INFO:     Number of params in model 168571
2022-11-23 00:02:54,029 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:02:54,029 INFO:   Starting stage: TRAINING
2022-11-23 00:02:54,089 INFO:     Val loss before train {'Reaction outcome loss': 0.9750776372172616, 'Total loss': 0.9750776372172616}
2022-11-23 00:02:54,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:54,089 INFO:     Epoch: 0
2022-11-23 00:02:54,963 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8351643925363367, 'Total loss': 0.8351643925363367} | train loss {'Reaction outcome loss': 0.8782240643856987, 'Total loss': 0.8782240643856987}
2022-11-23 00:02:54,963 INFO:     Found new best model at epoch 0
2022-11-23 00:02:54,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:54,964 INFO:     Epoch: 1
2022-11-23 00:02:55,813 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8424231586131182, 'Total loss': 0.8424231586131182} | train loss {'Reaction outcome loss': 0.8584880751948203, 'Total loss': 0.8584880751948203}
2022-11-23 00:02:55,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:55,815 INFO:     Epoch: 2
2022-11-23 00:02:56,668 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7990394282070074, 'Total loss': 0.7990394282070074} | train loss {'Reaction outcome loss': 0.8446078634550495, 'Total loss': 0.8446078634550495}
2022-11-23 00:02:56,668 INFO:     Found new best model at epoch 2
2022-11-23 00:02:56,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:56,669 INFO:     Epoch: 3
2022-11-23 00:02:57,525 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7903069264509461, 'Total loss': 0.7903069264509461} | train loss {'Reaction outcome loss': 0.840608905159658, 'Total loss': 0.840608905159658}
2022-11-23 00:02:57,525 INFO:     Found new best model at epoch 3
2022-11-23 00:02:57,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:57,526 INFO:     Epoch: 4
2022-11-23 00:02:58,403 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8388288468122482, 'Total loss': 0.8388288468122482} | train loss {'Reaction outcome loss': 0.8421279873338438, 'Total loss': 0.8421279873338438}
2022-11-23 00:02:58,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:58,403 INFO:     Epoch: 5
2022-11-23 00:02:59,327 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7995608042586934, 'Total loss': 0.7995608042586934} | train loss {'Reaction outcome loss': 0.834096880329232, 'Total loss': 0.834096880329232}
2022-11-23 00:02:59,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:02:59,327 INFO:     Epoch: 6
2022-11-23 00:03:00,181 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7927062755281274, 'Total loss': 0.7927062755281274} | train loss {'Reaction outcome loss': 0.8254346698522568, 'Total loss': 0.8254346698522568}
2022-11-23 00:03:00,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:00,181 INFO:     Epoch: 7
2022-11-23 00:03:01,000 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8148853982036764, 'Total loss': 0.8148853982036764} | train loss {'Reaction outcome loss': 0.8283330437637144, 'Total loss': 0.8283330437637144}
2022-11-23 00:03:01,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:01,001 INFO:     Epoch: 8
2022-11-23 00:03:01,930 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7847833619876341, 'Total loss': 0.7847833619876341} | train loss {'Reaction outcome loss': 0.8203180411890629, 'Total loss': 0.8203180411890629}
2022-11-23 00:03:01,931 INFO:     Found new best model at epoch 8
2022-11-23 00:03:01,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:01,932 INFO:     Epoch: 9
2022-11-23 00:03:02,793 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7788764814084227, 'Total loss': 0.7788764814084227} | train loss {'Reaction outcome loss': 0.8260821034350703, 'Total loss': 0.8260821034350703}
2022-11-23 00:03:02,793 INFO:     Found new best model at epoch 9
2022-11-23 00:03:02,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:02,794 INFO:     Epoch: 10
2022-11-23 00:03:03,631 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7786544811996546, 'Total loss': 0.7786544811996546} | train loss {'Reaction outcome loss': 0.8247564406164231, 'Total loss': 0.8247564406164231}
2022-11-23 00:03:03,631 INFO:     Found new best model at epoch 10
2022-11-23 00:03:03,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:03,632 INFO:     Epoch: 11
2022-11-23 00:03:04,518 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7969666800715707, 'Total loss': 0.7969666800715707} | train loss {'Reaction outcome loss': 0.8222565492314677, 'Total loss': 0.8222565492314677}
2022-11-23 00:03:04,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:04,518 INFO:     Epoch: 12
2022-11-23 00:03:05,397 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7885588827458295, 'Total loss': 0.7885588827458295} | train loss {'Reaction outcome loss': 0.8200194376610941, 'Total loss': 0.8200194376610941}
2022-11-23 00:03:05,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:05,397 INFO:     Epoch: 13
2022-11-23 00:03:06,246 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8281755406748165, 'Total loss': 0.8281755406748165} | train loss {'Reaction outcome loss': 0.8226281045785835, 'Total loss': 0.8226281045785835}
2022-11-23 00:03:06,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:06,246 INFO:     Epoch: 14
2022-11-23 00:03:07,082 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7907364720647986, 'Total loss': 0.7907364720647986} | train loss {'Reaction outcome loss': 0.8228633519141905, 'Total loss': 0.8228633519141905}
2022-11-23 00:03:07,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:07,082 INFO:     Epoch: 15
2022-11-23 00:03:07,904 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7941642180085182, 'Total loss': 0.7941642180085182} | train loss {'Reaction outcome loss': 0.8232163386719842, 'Total loss': 0.8232163386719842}
2022-11-23 00:03:07,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:07,905 INFO:     Epoch: 16
2022-11-23 00:03:08,779 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7972316701303829, 'Total loss': 0.7972316701303829} | train loss {'Reaction outcome loss': 0.8181796531763769, 'Total loss': 0.8181796531763769}
2022-11-23 00:03:08,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:08,780 INFO:     Epoch: 17
2022-11-23 00:03:09,679 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8178863166408106, 'Total loss': 0.8178863166408106} | train loss {'Reaction outcome loss': 0.8121260574628268, 'Total loss': 0.8121260574628268}
2022-11-23 00:03:09,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:09,680 INFO:     Epoch: 18
2022-11-23 00:03:10,537 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8113121302290396, 'Total loss': 0.8113121302290396} | train loss {'Reaction outcome loss': 0.8190444435083097, 'Total loss': 0.8190444435083097}
2022-11-23 00:03:10,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:10,537 INFO:     Epoch: 19
2022-11-23 00:03:11,366 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.782904826104641, 'Total loss': 0.782904826104641} | train loss {'Reaction outcome loss': 0.8183572408893416, 'Total loss': 0.8183572408893416}
2022-11-23 00:03:11,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:11,366 INFO:     Epoch: 20
2022-11-23 00:03:12,201 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7844544086943973, 'Total loss': 0.7844544086943973} | train loss {'Reaction outcome loss': 0.8146789212140345, 'Total loss': 0.8146789212140345}
2022-11-23 00:03:12,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:12,201 INFO:     Epoch: 21
2022-11-23 00:03:13,025 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7842197431759401, 'Total loss': 0.7842197431759401} | train loss {'Reaction outcome loss': 0.8211857160973933, 'Total loss': 0.8211857160973933}
2022-11-23 00:03:13,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:13,026 INFO:     Epoch: 22
2022-11-23 00:03:13,873 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.79035972668366, 'Total loss': 0.79035972668366} | train loss {'Reaction outcome loss': 0.8185845589445483, 'Total loss': 0.8185845589445483}
2022-11-23 00:03:13,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:13,873 INFO:     Epoch: 23
2022-11-23 00:03:14,686 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7848153249783949, 'Total loss': 0.7848153249783949} | train loss {'Reaction outcome loss': 0.8172394504710552, 'Total loss': 0.8172394504710552}
2022-11-23 00:03:14,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:14,687 INFO:     Epoch: 24
2022-11-23 00:03:15,471 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7863205088810488, 'Total loss': 0.7863205088810488} | train loss {'Reaction outcome loss': 0.8229241156049313, 'Total loss': 0.8229241156049313}
2022-11-23 00:03:15,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:15,471 INFO:     Epoch: 25
2022-11-23 00:03:16,299 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7842129563743417, 'Total loss': 0.7842129563743417} | train loss {'Reaction outcome loss': 0.8192096692660162, 'Total loss': 0.8192096692660162}
2022-11-23 00:03:16,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:16,299 INFO:     Epoch: 26
2022-11-23 00:03:17,098 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8461647209796038, 'Total loss': 0.8461647209796038} | train loss {'Reaction outcome loss': 0.8200021539964983, 'Total loss': 0.8200021539964983}
2022-11-23 00:03:17,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:17,098 INFO:     Epoch: 27
2022-11-23 00:03:17,905 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7787904055281119, 'Total loss': 0.7787904055281119} | train loss {'Reaction outcome loss': 0.815974603136701, 'Total loss': 0.815974603136701}
2022-11-23 00:03:17,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:17,906 INFO:     Epoch: 28
2022-11-23 00:03:18,728 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7804334373636679, 'Total loss': 0.7804334373636679} | train loss {'Reaction outcome loss': 0.8157059564705818, 'Total loss': 0.8157059564705818}
2022-11-23 00:03:18,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:18,728 INFO:     Epoch: 29
2022-11-23 00:03:19,549 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7863798155026003, 'Total loss': 0.7863798155026003} | train loss {'Reaction outcome loss': 0.8116811328837948, 'Total loss': 0.8116811328837948}
2022-11-23 00:03:19,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:19,549 INFO:     Epoch: 30
2022-11-23 00:03:20,364 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7906414087523114, 'Total loss': 0.7906414087523114} | train loss {'Reaction outcome loss': 0.8176009268049271, 'Total loss': 0.8176009268049271}
2022-11-23 00:03:20,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:20,364 INFO:     Epoch: 31
2022-11-23 00:03:21,148 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7831778390841051, 'Total loss': 0.7831778390841051} | train loss {'Reaction outcome loss': 0.8154013021098029, 'Total loss': 0.8154013021098029}
2022-11-23 00:03:21,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:21,148 INFO:     Epoch: 32
2022-11-23 00:03:21,931 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8016886325045065, 'Total loss': 0.8016886325045065} | train loss {'Reaction outcome loss': 0.8165942281484604, 'Total loss': 0.8165942281484604}
2022-11-23 00:03:21,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:21,931 INFO:     Epoch: 33
2022-11-23 00:03:22,696 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7964535843242299, 'Total loss': 0.7964535843242299} | train loss {'Reaction outcome loss': 0.8118161747772847, 'Total loss': 0.8118161747772847}
2022-11-23 00:03:22,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:22,697 INFO:     Epoch: 34
2022-11-23 00:03:23,486 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7839976853945039, 'Total loss': 0.7839976853945039} | train loss {'Reaction outcome loss': 0.8132426936419741, 'Total loss': 0.8132426936419741}
2022-11-23 00:03:23,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:23,486 INFO:     Epoch: 35
2022-11-23 00:03:24,265 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7897305840795691, 'Total loss': 0.7897305840795691} | train loss {'Reaction outcome loss': 0.8153905185960955, 'Total loss': 0.8153905185960955}
2022-11-23 00:03:24,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:24,265 INFO:     Epoch: 36
2022-11-23 00:03:25,040 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8119321777061983, 'Total loss': 0.8119321777061983} | train loss {'Reaction outcome loss': 0.8216035593180887, 'Total loss': 0.8216035593180887}
2022-11-23 00:03:25,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:25,041 INFO:     Epoch: 37
2022-11-23 00:03:25,833 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7716035057197917, 'Total loss': 0.7716035057197917} | train loss {'Reaction outcome loss': 0.8136244723873753, 'Total loss': 0.8136244723873753}
2022-11-23 00:03:25,833 INFO:     Found new best model at epoch 37
2022-11-23 00:03:25,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:25,834 INFO:     Epoch: 38
2022-11-23 00:03:26,600 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.787575248290192, 'Total loss': 0.787575248290192} | train loss {'Reaction outcome loss': 0.813686657817133, 'Total loss': 0.813686657817133}
2022-11-23 00:03:26,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:26,601 INFO:     Epoch: 39
2022-11-23 00:03:27,382 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8112251866947521, 'Total loss': 0.8112251866947521} | train loss {'Reaction outcome loss': 0.8135444143366429, 'Total loss': 0.8135444143366429}
2022-11-23 00:03:27,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:27,382 INFO:     Epoch: 40
2022-11-23 00:03:28,147 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7945685278285634, 'Total loss': 0.7945685278285634} | train loss {'Reaction outcome loss': 0.81744639683635, 'Total loss': 0.81744639683635}
2022-11-23 00:03:28,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:28,147 INFO:     Epoch: 41
2022-11-23 00:03:28,929 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7965825762261044, 'Total loss': 0.7965825762261044} | train loss {'Reaction outcome loss': 0.8115910858877243, 'Total loss': 0.8115910858877243}
2022-11-23 00:03:28,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:28,929 INFO:     Epoch: 42
2022-11-23 00:03:29,730 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7904927364804528, 'Total loss': 0.7904927364804528} | train loss {'Reaction outcome loss': 0.8060703391750013, 'Total loss': 0.8060703391750013}
2022-11-23 00:03:29,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:29,730 INFO:     Epoch: 43
2022-11-23 00:03:30,527 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7903044318610971, 'Total loss': 0.7903044318610971} | train loss {'Reaction outcome loss': 0.8136286643003264, 'Total loss': 0.8136286643003264}
2022-11-23 00:03:30,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:30,527 INFO:     Epoch: 44
2022-11-23 00:03:31,376 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7829766842451963, 'Total loss': 0.7829766842451963} | train loss {'Reaction outcome loss': 0.8120021540070733, 'Total loss': 0.8120021540070733}
2022-11-23 00:03:31,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:31,376 INFO:     Epoch: 45
2022-11-23 00:03:32,179 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7782823815941811, 'Total loss': 0.7782823815941811} | train loss {'Reaction outcome loss': 0.811020148978118, 'Total loss': 0.811020148978118}
2022-11-23 00:03:32,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:32,179 INFO:     Epoch: 46
2022-11-23 00:03:32,966 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7871889113025232, 'Total loss': 0.7871889113025232} | train loss {'Reaction outcome loss': 0.8117142228349563, 'Total loss': 0.8117142228349563}
2022-11-23 00:03:32,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:32,967 INFO:     Epoch: 47
2022-11-23 00:03:33,756 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7933297807520087, 'Total loss': 0.7933297807520087} | train loss {'Reaction outcome loss': 0.8103065961791623, 'Total loss': 0.8103065961791623}
2022-11-23 00:03:33,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:33,756 INFO:     Epoch: 48
2022-11-23 00:03:34,576 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8000578650019385, 'Total loss': 0.8000578650019385} | train loss {'Reaction outcome loss': 0.8103926861959119, 'Total loss': 0.8103926861959119}
2022-11-23 00:03:34,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:34,576 INFO:     Epoch: 49
2022-11-23 00:03:35,371 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7839280529455706, 'Total loss': 0.7839280529455706} | train loss {'Reaction outcome loss': 0.8036208790877173, 'Total loss': 0.8036208790877173}
2022-11-23 00:03:35,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:35,371 INFO:     Epoch: 50
2022-11-23 00:03:36,167 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7822803245349363, 'Total loss': 0.7822803245349363} | train loss {'Reaction outcome loss': 0.8130080493227128, 'Total loss': 0.8130080493227128}
2022-11-23 00:03:36,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:36,167 INFO:     Epoch: 51
2022-11-23 00:03:36,933 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7809069055047902, 'Total loss': 0.7809069055047902} | train loss {'Reaction outcome loss': 0.8084000498056412, 'Total loss': 0.8084000498056412}
2022-11-23 00:03:36,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:36,933 INFO:     Epoch: 52
2022-11-23 00:03:37,727 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8036056479269807, 'Total loss': 0.8036056479269807} | train loss {'Reaction outcome loss': 0.8121345527470112, 'Total loss': 0.8121345527470112}
2022-11-23 00:03:37,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:37,727 INFO:     Epoch: 53
2022-11-23 00:03:38,513 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7842169647867029, 'Total loss': 0.7842169647867029} | train loss {'Reaction outcome loss': 0.8123616963144271, 'Total loss': 0.8123616963144271}
2022-11-23 00:03:38,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:38,513 INFO:     Epoch: 54
2022-11-23 00:03:39,316 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7826073278080333, 'Total loss': 0.7826073278080333} | train loss {'Reaction outcome loss': 0.8135965609502408, 'Total loss': 0.8135965609502408}
2022-11-23 00:03:39,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:39,316 INFO:     Epoch: 55
2022-11-23 00:03:40,118 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7976073920726776, 'Total loss': 0.7976073920726776} | train loss {'Reaction outcome loss': 0.8083743521523091, 'Total loss': 0.8083743521523091}
2022-11-23 00:03:40,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:40,119 INFO:     Epoch: 56
2022-11-23 00:03:40,918 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7703934907913208, 'Total loss': 0.7703934907913208} | train loss {'Reaction outcome loss': 0.8120003167179323, 'Total loss': 0.8120003167179323}
2022-11-23 00:03:40,918 INFO:     Found new best model at epoch 56
2022-11-23 00:03:40,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:40,919 INFO:     Epoch: 57
2022-11-23 00:03:41,718 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.782413320785219, 'Total loss': 0.782413320785219} | train loss {'Reaction outcome loss': 0.8071763309980592, 'Total loss': 0.8071763309980592}
2022-11-23 00:03:41,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:41,719 INFO:     Epoch: 58
2022-11-23 00:03:42,526 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.790973573923111, 'Total loss': 0.790973573923111} | train loss {'Reaction outcome loss': 0.8113744775614431, 'Total loss': 0.8113744775614431}
2022-11-23 00:03:42,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:42,526 INFO:     Epoch: 59
2022-11-23 00:03:43,339 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7839748927138068, 'Total loss': 0.7839748927138068} | train loss {'Reaction outcome loss': 0.8101210915032895, 'Total loss': 0.8101210915032895}
2022-11-23 00:03:43,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:43,340 INFO:     Epoch: 60
2022-11-23 00:03:44,117 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7883033887906508, 'Total loss': 0.7883033887906508} | train loss {'Reaction outcome loss': 0.807605913329509, 'Total loss': 0.807605913329509}
2022-11-23 00:03:44,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:44,117 INFO:     Epoch: 61
2022-11-23 00:03:44,944 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7763318392363462, 'Total loss': 0.7763318392363462} | train loss {'Reaction outcome loss': 0.808565879060376, 'Total loss': 0.808565879060376}
2022-11-23 00:03:44,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:44,945 INFO:     Epoch: 62
2022-11-23 00:03:45,735 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7765068818222393, 'Total loss': 0.7765068818222393} | train loss {'Reaction outcome loss': 0.8119616450801972, 'Total loss': 0.8119616450801972}
2022-11-23 00:03:45,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:45,736 INFO:     Epoch: 63
2022-11-23 00:03:46,550 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7914902073415843, 'Total loss': 0.7914902073415843} | train loss {'Reaction outcome loss': 0.8107158103056492, 'Total loss': 0.8107158103056492}
2022-11-23 00:03:46,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:46,550 INFO:     Epoch: 64
2022-11-23 00:03:47,339 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7877441671761599, 'Total loss': 0.7877441671761599} | train loss {'Reaction outcome loss': 0.8062871491476413, 'Total loss': 0.8062871491476413}
2022-11-23 00:03:47,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:47,339 INFO:     Epoch: 65
2022-11-23 00:03:48,136 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7793942229314283, 'Total loss': 0.7793942229314283} | train loss {'Reaction outcome loss': 0.8064610825911644, 'Total loss': 0.8064610825911644}
2022-11-23 00:03:48,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:48,136 INFO:     Epoch: 66
2022-11-23 00:03:48,945 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7836915755813773, 'Total loss': 0.7836915755813773} | train loss {'Reaction outcome loss': 0.8070779099099098, 'Total loss': 0.8070779099099098}
2022-11-23 00:03:48,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:48,945 INFO:     Epoch: 67
2022-11-23 00:03:49,729 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8204873251644048, 'Total loss': 0.8204873251644048} | train loss {'Reaction outcome loss': 0.8076953539444555, 'Total loss': 0.8076953539444555}
2022-11-23 00:03:49,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:49,729 INFO:     Epoch: 68
2022-11-23 00:03:50,543 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7910485023801977, 'Total loss': 0.7910485023801977} | train loss {'Reaction outcome loss': 0.8044990148515471, 'Total loss': 0.8044990148515471}
2022-11-23 00:03:50,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:50,544 INFO:     Epoch: 69
2022-11-23 00:03:51,345 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7667961743744937, 'Total loss': 0.7667961743744937} | train loss {'Reaction outcome loss': 0.8049813254225638, 'Total loss': 0.8049813254225638}
2022-11-23 00:03:51,345 INFO:     Found new best model at epoch 69
2022-11-23 00:03:51,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:51,346 INFO:     Epoch: 70
2022-11-23 00:03:52,152 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7859071012247693, 'Total loss': 0.7859071012247693} | train loss {'Reaction outcome loss': 0.8099387310925992, 'Total loss': 0.8099387310925992}
2022-11-23 00:03:52,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:52,152 INFO:     Epoch: 71
2022-11-23 00:03:53,013 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.778168226507577, 'Total loss': 0.778168226507577} | train loss {'Reaction outcome loss': 0.8045326816218514, 'Total loss': 0.8045326816218514}
2022-11-23 00:03:53,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:53,014 INFO:     Epoch: 72
2022-11-23 00:03:53,817 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7832134406674992, 'Total loss': 0.7832134406674992} | train loss {'Reaction outcome loss': 0.8078629512700343, 'Total loss': 0.8078629512700343}
2022-11-23 00:03:53,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:53,818 INFO:     Epoch: 73
2022-11-23 00:03:54,643 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7779274000362917, 'Total loss': 0.7779274000362917} | train loss {'Reaction outcome loss': 0.8066970617059739, 'Total loss': 0.8066970617059739}
2022-11-23 00:03:54,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:54,643 INFO:     Epoch: 74
2022-11-23 00:03:55,494 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8370400971987031, 'Total loss': 0.8370400971987031} | train loss {'Reaction outcome loss': 0.8108445553769988, 'Total loss': 0.8108445553769988}
2022-11-23 00:03:55,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:55,495 INFO:     Epoch: 75
2022-11-23 00:03:56,315 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8359713317318396, 'Total loss': 0.8359713317318396} | train loss {'Reaction outcome loss': 0.80633285966131, 'Total loss': 0.80633285966131}
2022-11-23 00:03:56,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:56,315 INFO:     Epoch: 76
2022-11-23 00:03:57,126 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7791351946917447, 'Total loss': 0.7791351946917447} | train loss {'Reaction outcome loss': 0.8078527122495636, 'Total loss': 0.8078527122495636}
2022-11-23 00:03:57,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:57,126 INFO:     Epoch: 77
2022-11-23 00:03:57,925 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7850971641865644, 'Total loss': 0.7850971641865644} | train loss {'Reaction outcome loss': 0.8075380178709184, 'Total loss': 0.8075380178709184}
2022-11-23 00:03:57,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:57,926 INFO:     Epoch: 78
2022-11-23 00:03:58,765 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7898448231545362, 'Total loss': 0.7898448231545362} | train loss {'Reaction outcome loss': 0.8034068309972363, 'Total loss': 0.8034068309972363}
2022-11-23 00:03:58,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:58,766 INFO:     Epoch: 79
2022-11-23 00:03:59,559 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7769311639395627, 'Total loss': 0.7769311639395627} | train loss {'Reaction outcome loss': 0.812349111562775, 'Total loss': 0.812349111562775}
2022-11-23 00:03:59,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:03:59,560 INFO:     Epoch: 80
2022-11-23 00:04:00,384 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7809510522268035, 'Total loss': 0.7809510522268035} | train loss {'Reaction outcome loss': 0.8042079826756832, 'Total loss': 0.8042079826756832}
2022-11-23 00:04:00,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:00,384 INFO:     Epoch: 81
2022-11-23 00:04:01,227 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7920974215323274, 'Total loss': 0.7920974215323274} | train loss {'Reaction outcome loss': 0.8055260758246144, 'Total loss': 0.8055260758246144}
2022-11-23 00:04:01,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:01,227 INFO:     Epoch: 82
2022-11-23 00:04:02,050 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7860188010064039, 'Total loss': 0.7860188010064039} | train loss {'Reaction outcome loss': 0.814030316928702, 'Total loss': 0.814030316928702}
2022-11-23 00:04:02,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:02,051 INFO:     Epoch: 83
2022-11-23 00:04:02,847 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7844651646234773, 'Total loss': 0.7844651646234773} | train loss {'Reaction outcome loss': 0.8111876727592561, 'Total loss': 0.8111876727592561}
2022-11-23 00:04:02,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:02,847 INFO:     Epoch: 84
2022-11-23 00:04:03,644 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7770751768892462, 'Total loss': 0.7770751768892462} | train loss {'Reaction outcome loss': 0.8063668257166301, 'Total loss': 0.8063668257166301}
2022-11-23 00:04:03,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:03,644 INFO:     Epoch: 85
2022-11-23 00:04:04,447 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8188432915644213, 'Total loss': 0.8188432915644213} | train loss {'Reaction outcome loss': 0.8054521836100086, 'Total loss': 0.8054521836100086}
2022-11-23 00:04:04,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:04,448 INFO:     Epoch: 86
2022-11-23 00:04:05,226 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7828591709787195, 'Total loss': 0.7828591709787195} | train loss {'Reaction outcome loss': 0.8038676032616247, 'Total loss': 0.8038676032616247}
2022-11-23 00:04:05,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:05,226 INFO:     Epoch: 87
2022-11-23 00:04:06,035 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7775781459429048, 'Total loss': 0.7775781459429048} | train loss {'Reaction outcome loss': 0.8033101696881556, 'Total loss': 0.8033101696881556}
2022-11-23 00:04:06,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:06,035 INFO:     Epoch: 88
2022-11-23 00:04:06,837 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7729164138436317, 'Total loss': 0.7729164138436317} | train loss {'Reaction outcome loss': 0.8046341532420728, 'Total loss': 0.8046341532420728}
2022-11-23 00:04:06,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:06,838 INFO:     Epoch: 89
2022-11-23 00:04:07,673 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7781187275593932, 'Total loss': 0.7781187275593932} | train loss {'Reaction outcome loss': 0.8007527520098994, 'Total loss': 0.8007527520098994}
2022-11-23 00:04:07,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:07,674 INFO:     Epoch: 90
2022-11-23 00:04:08,472 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7698652852665294, 'Total loss': 0.7698652852665294} | train loss {'Reaction outcome loss': 0.8008703452444845, 'Total loss': 0.8008703452444845}
2022-11-23 00:04:08,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:08,472 INFO:     Epoch: 91
2022-11-23 00:04:09,314 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7942883954806761, 'Total loss': 0.7942883954806761} | train loss {'Reaction outcome loss': 0.8042284091634135, 'Total loss': 0.8042284091634135}
2022-11-23 00:04:09,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:09,314 INFO:     Epoch: 92
2022-11-23 00:04:10,133 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7864592346278104, 'Total loss': 0.7864592346278104} | train loss {'Reaction outcome loss': 0.7979448722495187, 'Total loss': 0.7979448722495187}
2022-11-23 00:04:10,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:10,133 INFO:     Epoch: 93
2022-11-23 00:04:10,935 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7657361111857675, 'Total loss': 0.7657361111857675} | train loss {'Reaction outcome loss': 0.8019495093293728, 'Total loss': 0.8019495093293728}
2022-11-23 00:04:10,935 INFO:     Found new best model at epoch 93
2022-11-23 00:04:10,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:10,936 INFO:     Epoch: 94
2022-11-23 00:04:11,747 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7720926356586543, 'Total loss': 0.7720926356586543} | train loss {'Reaction outcome loss': 0.8046784324030722, 'Total loss': 0.8046784324030722}
2022-11-23 00:04:11,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:11,747 INFO:     Epoch: 95
2022-11-23 00:04:12,595 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8298353959213604, 'Total loss': 0.8298353959213604} | train loss {'Reaction outcome loss': 0.8048213905384464, 'Total loss': 0.8048213905384464}
2022-11-23 00:04:12,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:12,595 INFO:     Epoch: 96
2022-11-23 00:04:13,438 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7651825906200842, 'Total loss': 0.7651825906200842} | train loss {'Reaction outcome loss': 0.7987813248990043, 'Total loss': 0.7987813248990043}
2022-11-23 00:04:13,438 INFO:     Found new best model at epoch 96
2022-11-23 00:04:13,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:13,439 INFO:     Epoch: 97
2022-11-23 00:04:14,252 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7944736677137288, 'Total loss': 0.7944736677137288} | train loss {'Reaction outcome loss': 0.7934465445578098, 'Total loss': 0.7934465445578098}
2022-11-23 00:04:14,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:14,252 INFO:     Epoch: 98
2022-11-23 00:04:15,050 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7568864680149339, 'Total loss': 0.7568864680149339} | train loss {'Reaction outcome loss': 0.7980986552373055, 'Total loss': 0.7980986552373055}
2022-11-23 00:04:15,051 INFO:     Found new best model at epoch 98
2022-11-23 00:04:15,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:15,052 INFO:     Epoch: 99
2022-11-23 00:04:15,841 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7918934557925571, 'Total loss': 0.7918934557925571} | train loss {'Reaction outcome loss': 0.7944793578597807, 'Total loss': 0.7944793578597807}
2022-11-23 00:04:15,841 INFO:     Best model found after epoch 99 of 100.
2022-11-23 00:04:15,841 INFO:   Done with stage: TRAINING
2022-11-23 00:04:15,842 INFO:   Starting stage: EVALUATION
2022-11-23 00:04:15,961 INFO:   Done with stage: EVALUATION
2022-11-23 00:04:15,961 INFO:   Leaving out SEQ value Fold_9
2022-11-23 00:04:15,974 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:04:15,974 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:04:16,657 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:04:16,658 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:04:16,727 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:04:16,727 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:04:16,728 INFO:     No hyperparam tuning for this model
2022-11-23 00:04:16,728 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:04:16,728 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:04:16,728 INFO:     None feature selector for col prot
2022-11-23 00:04:16,729 INFO:     None feature selector for col prot
2022-11-23 00:04:16,729 INFO:     None feature selector for col prot
2022-11-23 00:04:16,729 INFO:     None feature selector for col chem
2022-11-23 00:04:16,730 INFO:     None feature selector for col chem
2022-11-23 00:04:16,730 INFO:     None feature selector for col chem
2022-11-23 00:04:16,730 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:04:16,730 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:04:16,731 INFO:     Number of params in model 168571
2022-11-23 00:04:16,735 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:04:16,735 INFO:   Starting stage: TRAINING
2022-11-23 00:04:16,793 INFO:     Val loss before train {'Reaction outcome loss': 1.0338943072340705, 'Total loss': 1.0338943072340705}
2022-11-23 00:04:16,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:16,793 INFO:     Epoch: 0
2022-11-23 00:04:17,588 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8575405112721703, 'Total loss': 0.8575405112721703} | train loss {'Reaction outcome loss': 0.8776684886651483, 'Total loss': 0.8776684886651483}
2022-11-23 00:04:17,588 INFO:     Found new best model at epoch 0
2022-11-23 00:04:17,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:17,589 INFO:     Epoch: 1
2022-11-23 00:04:18,419 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8603813675316897, 'Total loss': 0.8603813675316897} | train loss {'Reaction outcome loss': 0.8498379461437102, 'Total loss': 0.8498379461437102}
2022-11-23 00:04:18,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:18,419 INFO:     Epoch: 2
2022-11-23 00:04:19,216 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8338829217986627, 'Total loss': 0.8338829217986627} | train loss {'Reaction outcome loss': 0.8474883089664011, 'Total loss': 0.8474883089664011}
2022-11-23 00:04:19,216 INFO:     Found new best model at epoch 2
2022-11-23 00:04:19,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:19,217 INFO:     Epoch: 3
2022-11-23 00:04:19,981 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8726353266022422, 'Total loss': 0.8726353266022422} | train loss {'Reaction outcome loss': 0.8406308312647739, 'Total loss': 0.8406308312647739}
2022-11-23 00:04:19,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:19,982 INFO:     Epoch: 4
2022-11-23 00:04:20,817 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8668178726326335, 'Total loss': 0.8668178726326335} | train loss {'Reaction outcome loss': 0.8406311354415137, 'Total loss': 0.8406311354415137}
2022-11-23 00:04:20,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:20,817 INFO:     Epoch: 5
2022-11-23 00:04:21,606 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8509643240408464, 'Total loss': 0.8509643240408464} | train loss {'Reaction outcome loss': 0.8439074876578713, 'Total loss': 0.8439074876578713}
2022-11-23 00:04:21,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:21,606 INFO:     Epoch: 6
2022-11-23 00:04:22,410 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.834850171750242, 'Total loss': 0.834850171750242} | train loss {'Reaction outcome loss': 0.8410729300155331, 'Total loss': 0.8410729300155331}
2022-11-23 00:04:22,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:22,410 INFO:     Epoch: 7
2022-11-23 00:04:23,206 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8371454158967192, 'Total loss': 0.8371454158967192} | train loss {'Reaction outcome loss': 0.8322058945049641, 'Total loss': 0.8322058945049641}
2022-11-23 00:04:23,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:23,206 INFO:     Epoch: 8
2022-11-23 00:04:24,019 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8280993686480955, 'Total loss': 0.8280993686480955} | train loss {'Reaction outcome loss': 0.8289251220129762, 'Total loss': 0.8289251220129762}
2022-11-23 00:04:24,019 INFO:     Found new best model at epoch 8
2022-11-23 00:04:24,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:24,020 INFO:     Epoch: 9
2022-11-23 00:04:24,805 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8378292267972772, 'Total loss': 0.8378292267972772} | train loss {'Reaction outcome loss': 0.8253460715898135, 'Total loss': 0.8253460715898135}
2022-11-23 00:04:24,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:24,806 INFO:     Epoch: 10
2022-11-23 00:04:25,580 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8519899100065231, 'Total loss': 0.8519899100065231} | train loss {'Reaction outcome loss': 0.8232390098122933, 'Total loss': 0.8232390098122933}
2022-11-23 00:04:25,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:25,580 INFO:     Epoch: 11
2022-11-23 00:04:26,373 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8313173868439414, 'Total loss': 0.8313173868439414} | train loss {'Reaction outcome loss': 0.8238955902667181, 'Total loss': 0.8238955902667181}
2022-11-23 00:04:26,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:26,373 INFO:     Epoch: 12
2022-11-23 00:04:27,207 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8625958297740329, 'Total loss': 0.8625958297740329} | train loss {'Reaction outcome loss': 0.8264544750997412, 'Total loss': 0.8264544750997412}
2022-11-23 00:04:27,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:27,207 INFO:     Epoch: 13
2022-11-23 00:04:28,046 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8214189234105024, 'Total loss': 0.8214189234105024} | train loss {'Reaction outcome loss': 0.8307018225733568, 'Total loss': 0.8307018225733568}
2022-11-23 00:04:28,047 INFO:     Found new best model at epoch 13
2022-11-23 00:04:28,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:28,047 INFO:     Epoch: 14
2022-11-23 00:04:28,846 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8534863753752275, 'Total loss': 0.8534863753752275} | train loss {'Reaction outcome loss': 0.8245040254312971, 'Total loss': 0.8245040254312971}
2022-11-23 00:04:28,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:28,847 INFO:     Epoch: 15
2022-11-23 00:04:29,678 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8388764072548259, 'Total loss': 0.8388764072548259} | train loss {'Reaction outcome loss': 0.8301775036794454, 'Total loss': 0.8301775036794454}
2022-11-23 00:04:29,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:29,678 INFO:     Epoch: 16
2022-11-23 00:04:30,497 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8241068896922198, 'Total loss': 0.8241068896922198} | train loss {'Reaction outcome loss': 0.8280285848116102, 'Total loss': 0.8280285848116102}
2022-11-23 00:04:30,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:30,497 INFO:     Epoch: 17
2022-11-23 00:04:31,337 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8363643532449548, 'Total loss': 0.8363643532449548} | train loss {'Reaction outcome loss': 0.8298747751876893, 'Total loss': 0.8298747751876893}
2022-11-23 00:04:31,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:31,337 INFO:     Epoch: 18
2022-11-23 00:04:32,152 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8384693231094967, 'Total loss': 0.8384693231094967} | train loss {'Reaction outcome loss': 0.8293243942231785, 'Total loss': 0.8293243942231785}
2022-11-23 00:04:32,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:32,152 INFO:     Epoch: 19
2022-11-23 00:04:32,968 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8291733075271953, 'Total loss': 0.8291733075271953} | train loss {'Reaction outcome loss': 0.8198438853870037, 'Total loss': 0.8198438853870037}
2022-11-23 00:04:32,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:32,968 INFO:     Epoch: 20
2022-11-23 00:04:33,781 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8444306112148545, 'Total loss': 0.8444306112148545} | train loss {'Reaction outcome loss': 0.8165958278816239, 'Total loss': 0.8165958278816239}
2022-11-23 00:04:33,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:33,781 INFO:     Epoch: 21
2022-11-23 00:04:34,611 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8158204420046373, 'Total loss': 0.8158204420046373} | train loss {'Reaction outcome loss': 0.8129326268004985, 'Total loss': 0.8129326268004985}
2022-11-23 00:04:34,612 INFO:     Found new best model at epoch 21
2022-11-23 00:04:34,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:34,613 INFO:     Epoch: 22
2022-11-23 00:04:35,410 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8311574404889887, 'Total loss': 0.8311574404889887} | train loss {'Reaction outcome loss': 0.8215692616426028, 'Total loss': 0.8215692616426028}
2022-11-23 00:04:35,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:35,411 INFO:     Epoch: 23
2022-11-23 00:04:36,236 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8226035162806511, 'Total loss': 0.8226035162806511} | train loss {'Reaction outcome loss': 0.8190319564057748, 'Total loss': 0.8190319564057748}
2022-11-23 00:04:36,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:36,237 INFO:     Epoch: 24
2022-11-23 00:04:37,040 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8676438169045881, 'Total loss': 0.8676438169045881} | train loss {'Reaction outcome loss': 0.8183051844840108, 'Total loss': 0.8183051844840108}
2022-11-23 00:04:37,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:37,040 INFO:     Epoch: 25
2022-11-23 00:04:37,825 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8337314034050162, 'Total loss': 0.8337314034050162} | train loss {'Reaction outcome loss': 0.8185245832390631, 'Total loss': 0.8185245832390631}
2022-11-23 00:04:37,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:37,826 INFO:     Epoch: 26
2022-11-23 00:04:38,641 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8197940926660191, 'Total loss': 0.8197940926660191} | train loss {'Reaction outcome loss': 0.8227407742849728, 'Total loss': 0.8227407742849728}
2022-11-23 00:04:38,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:38,642 INFO:     Epoch: 27
2022-11-23 00:04:39,499 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.851685687222264, 'Total loss': 0.851685687222264} | train loss {'Reaction outcome loss': 0.8204351282312803, 'Total loss': 0.8204351282312803}
2022-11-23 00:04:39,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:39,499 INFO:     Epoch: 28
2022-11-23 00:04:40,309 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.827635488726876, 'Total loss': 0.827635488726876} | train loss {'Reaction outcome loss': 0.8228082417959144, 'Total loss': 0.8228082417959144}
2022-11-23 00:04:40,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:40,309 INFO:     Epoch: 29
2022-11-23 00:04:41,089 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8338451744480566, 'Total loss': 0.8338451744480566} | train loss {'Reaction outcome loss': 0.8213946123716802, 'Total loss': 0.8213946123716802}
2022-11-23 00:04:41,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:41,089 INFO:     Epoch: 30
2022-11-23 00:04:41,890 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8124844120307402, 'Total loss': 0.8124844120307402} | train loss {'Reaction outcome loss': 0.8178704480832888, 'Total loss': 0.8178704480832888}
2022-11-23 00:04:41,890 INFO:     Found new best model at epoch 30
2022-11-23 00:04:41,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:41,891 INFO:     Epoch: 31
2022-11-23 00:04:42,730 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8277332125739618, 'Total loss': 0.8277332125739618} | train loss {'Reaction outcome loss': 0.8154548425906101, 'Total loss': 0.8154548425906101}
2022-11-23 00:04:42,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:42,730 INFO:     Epoch: 32
2022-11-23 00:04:43,534 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.846789694645188, 'Total loss': 0.846789694645188} | train loss {'Reaction outcome loss': 0.8137931310937472, 'Total loss': 0.8137931310937472}
2022-11-23 00:04:43,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:43,535 INFO:     Epoch: 33
2022-11-23 00:04:44,315 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8149498755281622, 'Total loss': 0.8149498755281622} | train loss {'Reaction outcome loss': 0.8212412649441344, 'Total loss': 0.8212412649441344}
2022-11-23 00:04:44,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:44,315 INFO:     Epoch: 34
2022-11-23 00:04:45,107 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8396894383159551, 'Total loss': 0.8396894383159551} | train loss {'Reaction outcome loss': 0.8134948493618714, 'Total loss': 0.8134948493618714}
2022-11-23 00:04:45,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:45,108 INFO:     Epoch: 35
2022-11-23 00:04:45,932 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8287533074617386, 'Total loss': 0.8287533074617386} | train loss {'Reaction outcome loss': 0.8197102649250494, 'Total loss': 0.8197102649250494}
2022-11-23 00:04:45,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:45,933 INFO:     Epoch: 36
2022-11-23 00:04:46,759 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8315351476723497, 'Total loss': 0.8315351476723497} | train loss {'Reaction outcome loss': 0.8133233482779761, 'Total loss': 0.8133233482779761}
2022-11-23 00:04:46,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:46,760 INFO:     Epoch: 37
2022-11-23 00:04:47,605 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8455844501202757, 'Total loss': 0.8455844501202757} | train loss {'Reaction outcome loss': 0.8183173527601759, 'Total loss': 0.8183173527601759}
2022-11-23 00:04:47,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:47,606 INFO:     Epoch: 38
2022-11-23 00:04:48,390 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8313736048611727, 'Total loss': 0.8313736048611727} | train loss {'Reaction outcome loss': 0.8122346488087766, 'Total loss': 0.8122346488087766}
2022-11-23 00:04:48,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:48,391 INFO:     Epoch: 39
2022-11-23 00:04:49,199 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8805156451734629, 'Total loss': 0.8805156451734629} | train loss {'Reaction outcome loss': 0.8126501426523031, 'Total loss': 0.8126501426523031}
2022-11-23 00:04:49,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:49,199 INFO:     Epoch: 40
2022-11-23 00:04:49,993 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8309859511527148, 'Total loss': 0.8309859511527148} | train loss {'Reaction outcome loss': 0.8199025934283067, 'Total loss': 0.8199025934283067}
2022-11-23 00:04:49,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:49,993 INFO:     Epoch: 41
2022-11-23 00:04:50,812 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8196188096295703, 'Total loss': 0.8196188096295703} | train loss {'Reaction outcome loss': 0.8124420889747529, 'Total loss': 0.8124420889747529}
2022-11-23 00:04:50,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:50,812 INFO:     Epoch: 42
2022-11-23 00:04:51,647 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8163902867924083, 'Total loss': 0.8163902867924083} | train loss {'Reaction outcome loss': 0.8149405108530995, 'Total loss': 0.8149405108530995}
2022-11-23 00:04:51,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:51,647 INFO:     Epoch: 43
2022-11-23 00:04:52,438 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8200530247254805, 'Total loss': 0.8200530247254805} | train loss {'Reaction outcome loss': 0.8133385250201592, 'Total loss': 0.8133385250201592}
2022-11-23 00:04:52,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:52,438 INFO:     Epoch: 44
2022-11-23 00:04:53,248 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8397765599868514, 'Total loss': 0.8397765599868514} | train loss {'Reaction outcome loss': 0.8173996141323676, 'Total loss': 0.8173996141323676}
2022-11-23 00:04:53,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:53,248 INFO:     Epoch: 45
2022-11-23 00:04:54,051 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8235868513584137, 'Total loss': 0.8235868513584137} | train loss {'Reaction outcome loss': 0.8207676650782828, 'Total loss': 0.8207676650782828}
2022-11-23 00:04:54,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:54,051 INFO:     Epoch: 46
2022-11-23 00:04:54,900 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8300667303529653, 'Total loss': 0.8300667303529653} | train loss {'Reaction outcome loss': 0.8201207307427518, 'Total loss': 0.8201207307427518}
2022-11-23 00:04:54,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:54,900 INFO:     Epoch: 47
2022-11-23 00:04:55,699 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8270371109247208, 'Total loss': 0.8270371109247208} | train loss {'Reaction outcome loss': 0.825125957790174, 'Total loss': 0.825125957790174}
2022-11-23 00:04:55,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:55,699 INFO:     Epoch: 48
2022-11-23 00:04:56,571 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8099940114400603, 'Total loss': 0.8099940114400603} | train loss {'Reaction outcome loss': 0.8190388677091252, 'Total loss': 0.8190388677091252}
2022-11-23 00:04:56,572 INFO:     Found new best model at epoch 48
2022-11-23 00:04:56,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:56,573 INFO:     Epoch: 49
2022-11-23 00:04:57,409 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.827610164203427, 'Total loss': 0.827610164203427} | train loss {'Reaction outcome loss': 0.8142691637099031, 'Total loss': 0.8142691637099031}
2022-11-23 00:04:57,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:57,409 INFO:     Epoch: 50
2022-11-23 00:04:58,208 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8127445009621707, 'Total loss': 0.8127445009621707} | train loss {'Reaction outcome loss': 0.8107271933181566, 'Total loss': 0.8107271933181566}
2022-11-23 00:04:58,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:58,208 INFO:     Epoch: 51
2022-11-23 00:04:59,030 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8204221447760408, 'Total loss': 0.8204221447760408} | train loss {'Reaction outcome loss': 0.8115239057704987, 'Total loss': 0.8115239057704987}
2022-11-23 00:04:59,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:59,030 INFO:     Epoch: 52
2022-11-23 00:04:59,818 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8281362693418156, 'Total loss': 0.8281362693418156} | train loss {'Reaction outcome loss': 0.8161705967928716, 'Total loss': 0.8161705967928716}
2022-11-23 00:04:59,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:04:59,819 INFO:     Epoch: 53
2022-11-23 00:05:00,671 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8216730390082706, 'Total loss': 0.8216730390082706} | train loss {'Reaction outcome loss': 0.8070059844899756, 'Total loss': 0.8070059844899756}
2022-11-23 00:05:00,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:00,671 INFO:     Epoch: 54
2022-11-23 00:05:01,488 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.818185955286026, 'Total loss': 0.818185955286026} | train loss {'Reaction outcome loss': 0.8161446956487802, 'Total loss': 0.8161446956487802}
2022-11-23 00:05:01,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:01,488 INFO:     Epoch: 55
2022-11-23 00:05:02,284 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8346683857115832, 'Total loss': 0.8346683857115832} | train loss {'Reaction outcome loss': 0.8154484902316259, 'Total loss': 0.8154484902316259}
2022-11-23 00:05:02,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:02,284 INFO:     Epoch: 56
2022-11-23 00:05:03,151 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.82189384306019, 'Total loss': 0.82189384306019} | train loss {'Reaction outcome loss': 0.8120128279061694, 'Total loss': 0.8120128279061694}
2022-11-23 00:05:03,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:03,152 INFO:     Epoch: 57
2022-11-23 00:05:03,991 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8179803815754977, 'Total loss': 0.8179803815754977} | train loss {'Reaction outcome loss': 0.8101810790628556, 'Total loss': 0.8101810790628556}
2022-11-23 00:05:03,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:03,991 INFO:     Epoch: 58
2022-11-23 00:05:04,808 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8215190558270975, 'Total loss': 0.8215190558270975} | train loss {'Reaction outcome loss': 0.8088509411464336, 'Total loss': 0.8088509411464336}
2022-11-23 00:05:04,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:04,808 INFO:     Epoch: 59
2022-11-23 00:05:05,633 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8222227441993627, 'Total loss': 0.8222227441993627} | train loss {'Reaction outcome loss': 0.8202236140305214, 'Total loss': 0.8202236140305214}
2022-11-23 00:05:05,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:05,634 INFO:     Epoch: 60
2022-11-23 00:05:06,403 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.815575554289601, 'Total loss': 0.815575554289601} | train loss {'Reaction outcome loss': 0.80714319411077, 'Total loss': 0.80714319411077}
2022-11-23 00:05:06,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:06,404 INFO:     Epoch: 61
2022-11-23 00:05:07,211 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.817286495457996, 'Total loss': 0.817286495457996} | train loss {'Reaction outcome loss': 0.816963405140981, 'Total loss': 0.816963405140981}
2022-11-23 00:05:07,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:07,211 INFO:     Epoch: 62
2022-11-23 00:05:08,068 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8175148198550398, 'Total loss': 0.8175148198550398} | train loss {'Reaction outcome loss': 0.8184150345774315, 'Total loss': 0.8184150345774315}
2022-11-23 00:05:08,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:08,068 INFO:     Epoch: 63
2022-11-23 00:05:08,895 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8225780610333789, 'Total loss': 0.8225780610333789} | train loss {'Reaction outcome loss': 0.8111214031604862, 'Total loss': 0.8111214031604862}
2022-11-23 00:05:08,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:08,895 INFO:     Epoch: 64
2022-11-23 00:05:09,761 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8120718611912294, 'Total loss': 0.8120718611912294} | train loss {'Reaction outcome loss': 0.8123169904537046, 'Total loss': 0.8123169904537046}
2022-11-23 00:05:09,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:09,761 INFO:     Epoch: 65
2022-11-23 00:05:10,624 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8612421554597941, 'Total loss': 0.8612421554597941} | train loss {'Reaction outcome loss': 0.8082741031249766, 'Total loss': 0.8082741031249766}
2022-11-23 00:05:10,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:10,624 INFO:     Epoch: 66
2022-11-23 00:05:11,420 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8171907256950032, 'Total loss': 0.8171907256950032} | train loss {'Reaction outcome loss': 0.8166291322785351, 'Total loss': 0.8166291322785351}
2022-11-23 00:05:11,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:11,420 INFO:     Epoch: 67
2022-11-23 00:05:12,230 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8305998302318833, 'Total loss': 0.8305998302318833} | train loss {'Reaction outcome loss': 0.8137293044130812, 'Total loss': 0.8137293044130812}
2022-11-23 00:05:12,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:12,230 INFO:     Epoch: 68
2022-11-23 00:05:13,049 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.814155326648192, 'Total loss': 0.814155326648192} | train loss {'Reaction outcome loss': 0.8189511474086205, 'Total loss': 0.8189511474086205}
2022-11-23 00:05:13,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:13,049 INFO:     Epoch: 69
2022-11-23 00:05:13,828 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8095623965967785, 'Total loss': 0.8095623965967785} | train loss {'Reaction outcome loss': 0.8149030174803638, 'Total loss': 0.8149030174803638}
2022-11-23 00:05:13,828 INFO:     Found new best model at epoch 69
2022-11-23 00:05:13,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:13,829 INFO:     Epoch: 70
2022-11-23 00:05:14,647 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8352051946249875, 'Total loss': 0.8352051946249875} | train loss {'Reaction outcome loss': 0.8100881408824612, 'Total loss': 0.8100881408824612}
2022-11-23 00:05:14,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:14,648 INFO:     Epoch: 71
2022-11-23 00:05:15,453 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8078906373544172, 'Total loss': 0.8078906373544172} | train loss {'Reaction outcome loss': 0.8167259246714202, 'Total loss': 0.8167259246714202}
2022-11-23 00:05:15,453 INFO:     Found new best model at epoch 71
2022-11-23 00:05:15,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:15,454 INFO:     Epoch: 72
2022-11-23 00:05:16,270 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8142004507509145, 'Total loss': 0.8142004507509145} | train loss {'Reaction outcome loss': 0.8156258031906869, 'Total loss': 0.8156258031906869}
2022-11-23 00:05:16,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:16,271 INFO:     Epoch: 73
2022-11-23 00:05:17,059 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8346711762926795, 'Total loss': 0.8346711762926795} | train loss {'Reaction outcome loss': 0.81717283885006, 'Total loss': 0.81717283885006}
2022-11-23 00:05:17,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:17,059 INFO:     Epoch: 74
2022-11-23 00:05:17,949 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8130372891371901, 'Total loss': 0.8130372891371901} | train loss {'Reaction outcome loss': 0.8158038607251789, 'Total loss': 0.8158038607251789}
2022-11-23 00:05:17,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:17,949 INFO:     Epoch: 75
2022-11-23 00:05:18,764 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.828002316030589, 'Total loss': 0.828002316030589} | train loss {'Reaction outcome loss': 0.8138444463492405, 'Total loss': 0.8138444463492405}
2022-11-23 00:05:18,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:18,765 INFO:     Epoch: 76
2022-11-23 00:05:19,564 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8139392083341425, 'Total loss': 0.8139392083341425} | train loss {'Reaction outcome loss': 0.8120433572332869, 'Total loss': 0.8120433572332869}
2022-11-23 00:05:19,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:19,564 INFO:     Epoch: 77
2022-11-23 00:05:20,322 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8309466947208751, 'Total loss': 0.8309466947208751} | train loss {'Reaction outcome loss': 0.8151811105519654, 'Total loss': 0.8151811105519654}
2022-11-23 00:05:20,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:20,322 INFO:     Epoch: 78
2022-11-23 00:05:21,129 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8237623504616998, 'Total loss': 0.8237623504616998} | train loss {'Reaction outcome loss': 0.8114921523009234, 'Total loss': 0.8114921523009234}
2022-11-23 00:05:21,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:21,129 INFO:     Epoch: 79
2022-11-23 00:05:21,924 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8671898482875391, 'Total loss': 0.8671898482875391} | train loss {'Reaction outcome loss': 0.8062712423473235, 'Total loss': 0.8062712423473235}
2022-11-23 00:05:21,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:21,924 INFO:     Epoch: 80
2022-11-23 00:05:22,687 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8258362439545718, 'Total loss': 0.8258362439545718} | train loss {'Reaction outcome loss': 0.8191309335984682, 'Total loss': 0.8191309335984682}
2022-11-23 00:05:22,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:22,687 INFO:     Epoch: 81
2022-11-23 00:05:23,512 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8031186827204444, 'Total loss': 0.8031186827204444} | train loss {'Reaction outcome loss': 0.8224543054335514, 'Total loss': 0.8224543054335514}
2022-11-23 00:05:23,512 INFO:     Found new best model at epoch 81
2022-11-23 00:05:23,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:23,513 INFO:     Epoch: 82
2022-11-23 00:05:24,342 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8100583675232801, 'Total loss': 0.8100583675232801} | train loss {'Reaction outcome loss': 0.8083817467757082, 'Total loss': 0.8083817467757082}
2022-11-23 00:05:24,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:24,342 INFO:     Epoch: 83
2022-11-23 00:05:25,146 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8213467726653273, 'Total loss': 0.8213467726653273} | train loss {'Reaction outcome loss': 0.8178295658426247, 'Total loss': 0.8178295658426247}
2022-11-23 00:05:25,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:25,147 INFO:     Epoch: 84
2022-11-23 00:05:26,008 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8098993870345029, 'Total loss': 0.8098993870345029} | train loss {'Reaction outcome loss': 0.8163474910413688, 'Total loss': 0.8163474910413688}
2022-11-23 00:05:26,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:26,009 INFO:     Epoch: 85
2022-11-23 00:05:26,849 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8216232162984934, 'Total loss': 0.8216232162984934} | train loss {'Reaction outcome loss': 0.8189133707328364, 'Total loss': 0.8189133707328364}
2022-11-23 00:05:26,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:26,849 INFO:     Epoch: 86
2022-11-23 00:05:27,620 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8134188740090891, 'Total loss': 0.8134188740090891} | train loss {'Reaction outcome loss': 0.8140339636006336, 'Total loss': 0.8140339636006336}
2022-11-23 00:05:27,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:27,620 INFO:     Epoch: 87
2022-11-23 00:05:28,445 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8054022125222466, 'Total loss': 0.8054022125222466} | train loss {'Reaction outcome loss': 0.8166388279271994, 'Total loss': 0.8166388279271994}
2022-11-23 00:05:28,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:28,445 INFO:     Epoch: 88
2022-11-23 00:05:29,298 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8177438297054984, 'Total loss': 0.8177438297054984} | train loss {'Reaction outcome loss': 0.8181518693925881, 'Total loss': 0.8181518693925881}
2022-11-23 00:05:29,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:29,299 INFO:     Epoch: 89
2022-11-23 00:05:30,094 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8326260501688177, 'Total loss': 0.8326260501688177} | train loss {'Reaction outcome loss': 0.8198123063273758, 'Total loss': 0.8198123063273758}
2022-11-23 00:05:30,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:30,094 INFO:     Epoch: 90
2022-11-23 00:05:30,933 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8117990060286089, 'Total loss': 0.8117990060286089} | train loss {'Reaction outcome loss': 0.8221225141272371, 'Total loss': 0.8221225141272371}
2022-11-23 00:05:30,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:30,934 INFO:     Epoch: 91
2022-11-23 00:05:31,726 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8593287711793726, 'Total loss': 0.8593287711793726} | train loss {'Reaction outcome loss': 0.8143937612171115, 'Total loss': 0.8143937612171115}
2022-11-23 00:05:31,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:31,727 INFO:     Epoch: 92
2022-11-23 00:05:32,537 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8087765845385465, 'Total loss': 0.8087765845385465} | train loss {'Reaction outcome loss': 0.8102361579173007, 'Total loss': 0.8102361579173007}
2022-11-23 00:05:32,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:32,537 INFO:     Epoch: 93
2022-11-23 00:05:33,329 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8218721124258909, 'Total loss': 0.8218721124258909} | train loss {'Reaction outcome loss': 0.8110682986043243, 'Total loss': 0.8110682986043243}
2022-11-23 00:05:33,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:33,330 INFO:     Epoch: 94
2022-11-23 00:05:34,176 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8248162486336448, 'Total loss': 0.8248162486336448} | train loss {'Reaction outcome loss': 0.8083286816291964, 'Total loss': 0.8083286816291964}
2022-11-23 00:05:34,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:34,177 INFO:     Epoch: 95
2022-11-23 00:05:34,959 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.818127034062689, 'Total loss': 0.818127034062689} | train loss {'Reaction outcome loss': 0.8097445646278288, 'Total loss': 0.8097445646278288}
2022-11-23 00:05:34,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:34,959 INFO:     Epoch: 96
2022-11-23 00:05:35,749 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8349523815241727, 'Total loss': 0.8349523815241727} | train loss {'Reaction outcome loss': 0.8173417872504184, 'Total loss': 0.8173417872504184}
2022-11-23 00:05:35,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:35,750 INFO:     Epoch: 97
2022-11-23 00:05:36,537 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8260840780355714, 'Total loss': 0.8260840780355714} | train loss {'Reaction outcome loss': 0.8080210553610373, 'Total loss': 0.8080210553610373}
2022-11-23 00:05:36,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:36,537 INFO:     Epoch: 98
2022-11-23 00:05:37,314 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8167740347033198, 'Total loss': 0.8167740347033198} | train loss {'Reaction outcome loss': 0.8095239162867368, 'Total loss': 0.8095239162867368}
2022-11-23 00:05:37,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:37,315 INFO:     Epoch: 99
2022-11-23 00:05:38,171 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8264495987783779, 'Total loss': 0.8264495987783779} | train loss {'Reaction outcome loss': 0.8128647926124001, 'Total loss': 0.8128647926124001}
2022-11-23 00:05:38,171 INFO:     Best model found after epoch 82 of 100.
2022-11-23 00:05:38,171 INFO:   Done with stage: TRAINING
2022-11-23 00:05:38,172 INFO:   Starting stage: EVALUATION
2022-11-23 00:05:38,306 INFO:   Done with stage: EVALUATION
2022-11-23 00:05:38,315 INFO:   Leaving out SEQ value Fold_0
2022-11-23 00:05:38,328 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:05:38,328 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:05:39,000 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:05:39,000 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:05:39,069 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:05:39,070 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:05:39,070 INFO:     No hyperparam tuning for this model
2022-11-23 00:05:39,070 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:05:39,070 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:05:39,071 INFO:     None feature selector for col prot
2022-11-23 00:05:39,071 INFO:     None feature selector for col prot
2022-11-23 00:05:39,071 INFO:     None feature selector for col prot
2022-11-23 00:05:39,071 INFO:     None feature selector for col chem
2022-11-23 00:05:39,072 INFO:     None feature selector for col chem
2022-11-23 00:05:39,072 INFO:     None feature selector for col chem
2022-11-23 00:05:39,072 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:05:39,072 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:05:39,073 INFO:     Number of params in model 168571
2022-11-23 00:05:39,077 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:05:39,077 INFO:   Starting stage: TRAINING
2022-11-23 00:05:39,135 INFO:     Val loss before train {'Reaction outcome loss': 1.078436285934665, 'Total loss': 1.078436285934665}
2022-11-23 00:05:39,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:39,135 INFO:     Epoch: 0
2022-11-23 00:05:39,933 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8964508751576598, 'Total loss': 0.8964508751576598} | train loss {'Reaction outcome loss': 0.8625465771373437, 'Total loss': 0.8625465771373437}
2022-11-23 00:05:39,934 INFO:     Found new best model at epoch 0
2022-11-23 00:05:39,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:39,934 INFO:     Epoch: 1
2022-11-23 00:05:40,744 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8847105970436876, 'Total loss': 0.8847105970436876} | train loss {'Reaction outcome loss': 0.8308988884395483, 'Total loss': 0.8308988884395483}
2022-11-23 00:05:40,745 INFO:     Found new best model at epoch 1
2022-11-23 00:05:40,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:40,745 INFO:     Epoch: 2
2022-11-23 00:05:41,563 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8838559673591093, 'Total loss': 0.8838559673591093} | train loss {'Reaction outcome loss': 0.8205463791380123, 'Total loss': 0.8205463791380123}
2022-11-23 00:05:41,563 INFO:     Found new best model at epoch 2
2022-11-23 00:05:41,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:41,564 INFO:     Epoch: 3
2022-11-23 00:05:42,383 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8647760593078353, 'Total loss': 0.8647760593078353} | train loss {'Reaction outcome loss': 0.8218527162561611, 'Total loss': 0.8218527162561611}
2022-11-23 00:05:42,383 INFO:     Found new best model at epoch 3
2022-11-23 00:05:42,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:42,384 INFO:     Epoch: 4
2022-11-23 00:05:43,180 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8910701735453173, 'Total loss': 0.8910701735453173} | train loss {'Reaction outcome loss': 0.8169476849692209, 'Total loss': 0.8169476849692209}
2022-11-23 00:05:43,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:43,180 INFO:     Epoch: 5
2022-11-23 00:05:43,952 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8740498884157701, 'Total loss': 0.8740498884157701} | train loss {'Reaction outcome loss': 0.8136598379028087, 'Total loss': 0.8136598379028087}
2022-11-23 00:05:43,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:43,952 INFO:     Epoch: 6
2022-11-23 00:05:44,734 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9178104251623154, 'Total loss': 0.9178104251623154} | train loss {'Reaction outcome loss': 0.8133280446334761, 'Total loss': 0.8133280446334761}
2022-11-23 00:05:44,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:44,734 INFO:     Epoch: 7
2022-11-23 00:05:45,563 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8860891420732845, 'Total loss': 0.8860891420732845} | train loss {'Reaction outcome loss': 0.8102186738228311, 'Total loss': 0.8102186738228311}
2022-11-23 00:05:45,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:45,563 INFO:     Epoch: 8
2022-11-23 00:05:46,365 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8835913362828168, 'Total loss': 0.8835913362828168} | train loss {'Reaction outcome loss': 0.8073153285347685, 'Total loss': 0.8073153285347685}
2022-11-23 00:05:46,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:46,365 INFO:     Epoch: 9
2022-11-23 00:05:47,130 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8775182257999073, 'Total loss': 0.8775182257999073} | train loss {'Reaction outcome loss': 0.8036379510042618, 'Total loss': 0.8036379510042618}
2022-11-23 00:05:47,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:47,130 INFO:     Epoch: 10
2022-11-23 00:05:47,943 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8904945545575835, 'Total loss': 0.8904945545575835} | train loss {'Reaction outcome loss': 0.8038423736484683, 'Total loss': 0.8038423736484683}
2022-11-23 00:05:47,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:47,944 INFO:     Epoch: 11
2022-11-23 00:05:48,755 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8567047820172526, 'Total loss': 0.8567047820172526} | train loss {'Reaction outcome loss': 0.8061696253260787, 'Total loss': 0.8061696253260787}
2022-11-23 00:05:48,755 INFO:     Found new best model at epoch 11
2022-11-23 00:05:48,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:48,756 INFO:     Epoch: 12
2022-11-23 00:05:49,523 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8672918806021864, 'Total loss': 0.8672918806021864} | train loss {'Reaction outcome loss': 0.8058017931422409, 'Total loss': 0.8058017931422409}
2022-11-23 00:05:49,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:49,524 INFO:     Epoch: 13
2022-11-23 00:05:50,342 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8744967078620737, 'Total loss': 0.8744967078620737} | train loss {'Reaction outcome loss': 0.8036485988266614, 'Total loss': 0.8036485988266614}
2022-11-23 00:05:50,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:50,343 INFO:     Epoch: 14
2022-11-23 00:05:51,096 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8821284008974378, 'Total loss': 0.8821284008974378} | train loss {'Reaction outcome loss': 0.8034419978151516, 'Total loss': 0.8034419978151516}
2022-11-23 00:05:51,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:51,097 INFO:     Epoch: 15
2022-11-23 00:05:51,891 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8562421006235209, 'Total loss': 0.8562421006235209} | train loss {'Reaction outcome loss': 0.8025163173675537, 'Total loss': 0.8025163173675537}
2022-11-23 00:05:51,891 INFO:     Found new best model at epoch 15
2022-11-23 00:05:51,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:51,892 INFO:     Epoch: 16
2022-11-23 00:05:52,683 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8534063100814819, 'Total loss': 0.8534063100814819} | train loss {'Reaction outcome loss': 0.7983223913883676, 'Total loss': 0.7983223913883676}
2022-11-23 00:05:52,684 INFO:     Found new best model at epoch 16
2022-11-23 00:05:52,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:52,684 INFO:     Epoch: 17
2022-11-23 00:05:53,525 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8652872050350363, 'Total loss': 0.8652872050350363} | train loss {'Reaction outcome loss': 0.801248992097621, 'Total loss': 0.801248992097621}
2022-11-23 00:05:53,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:53,526 INFO:     Epoch: 18
2022-11-23 00:05:54,332 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8539068590510975, 'Total loss': 0.8539068590510975} | train loss {'Reaction outcome loss': 0.7982538551700359, 'Total loss': 0.7982538551700359}
2022-11-23 00:05:54,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:54,332 INFO:     Epoch: 19
2022-11-23 00:05:55,100 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8863493678244677, 'Total loss': 0.8863493678244677} | train loss {'Reaction outcome loss': 0.8001748407373623, 'Total loss': 0.8001748407373623}
2022-11-23 00:05:55,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:55,100 INFO:     Epoch: 20
2022-11-23 00:05:55,888 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8592428544705565, 'Total loss': 0.8592428544705565} | train loss {'Reaction outcome loss': 0.8028379557084064, 'Total loss': 0.8028379557084064}
2022-11-23 00:05:55,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:55,888 INFO:     Epoch: 21
2022-11-23 00:05:56,715 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8771582645448771, 'Total loss': 0.8771582645448771} | train loss {'Reaction outcome loss': 0.7965992083354873, 'Total loss': 0.7965992083354873}
2022-11-23 00:05:56,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:56,715 INFO:     Epoch: 22
2022-11-23 00:05:57,523 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8576913530176337, 'Total loss': 0.8576913530176337} | train loss {'Reaction outcome loss': 0.7999361937143364, 'Total loss': 0.7999361937143364}
2022-11-23 00:05:57,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:57,523 INFO:     Epoch: 23
2022-11-23 00:05:58,369 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8655160949988798, 'Total loss': 0.8655160949988798} | train loss {'Reaction outcome loss': 0.7998352308662571, 'Total loss': 0.7998352308662571}
2022-11-23 00:05:58,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:58,369 INFO:     Epoch: 24
2022-11-23 00:05:59,202 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8755891262130304, 'Total loss': 0.8755891262130304} | train loss {'Reaction outcome loss': 0.8023755038271145, 'Total loss': 0.8023755038271145}
2022-11-23 00:05:59,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:05:59,203 INFO:     Epoch: 25
2022-11-23 00:06:00,073 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8634748824618079, 'Total loss': 0.8634748824618079} | train loss {'Reaction outcome loss': 0.7961580529504892, 'Total loss': 0.7961580529504892}
2022-11-23 00:06:00,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:00,073 INFO:     Epoch: 26
2022-11-23 00:06:00,932 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8646657317876816, 'Total loss': 0.8646657317876816} | train loss {'Reaction outcome loss': 0.7993366568672414, 'Total loss': 0.7993366568672414}
2022-11-23 00:06:00,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:00,933 INFO:     Epoch: 27
2022-11-23 00:06:01,842 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.920324331657453, 'Total loss': 0.920324331657453} | train loss {'Reaction outcome loss': 0.7991835350892982, 'Total loss': 0.7991835350892982}
2022-11-23 00:06:01,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:01,843 INFO:     Epoch: 28
2022-11-23 00:06:02,716 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8442075503143397, 'Total loss': 0.8442075503143397} | train loss {'Reaction outcome loss': 0.7985131841533039, 'Total loss': 0.7985131841533039}
2022-11-23 00:06:02,716 INFO:     Found new best model at epoch 28
2022-11-23 00:06:02,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:02,717 INFO:     Epoch: 29
2022-11-23 00:06:03,618 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8391906341368501, 'Total loss': 0.8391906341368501} | train loss {'Reaction outcome loss': 0.7962298231465476, 'Total loss': 0.7962298231465476}
2022-11-23 00:06:03,619 INFO:     Found new best model at epoch 29
2022-11-23 00:06:03,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:03,619 INFO:     Epoch: 30
2022-11-23 00:06:04,472 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8588946095921777, 'Total loss': 0.8588946095921777} | train loss {'Reaction outcome loss': 0.7964633782299197, 'Total loss': 0.7964633782299197}
2022-11-23 00:06:04,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:04,472 INFO:     Epoch: 31
2022-11-23 00:06:05,297 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8823280707001686, 'Total loss': 0.8823280707001686} | train loss {'Reaction outcome loss': 0.7958724097329744, 'Total loss': 0.7958724097329744}
2022-11-23 00:06:05,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:05,298 INFO:     Epoch: 32
2022-11-23 00:06:06,102 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8578521379015662, 'Total loss': 0.8578521379015662} | train loss {'Reaction outcome loss': 0.7979252191222443, 'Total loss': 0.7979252191222443}
2022-11-23 00:06:06,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:06,102 INFO:     Epoch: 33
2022-11-23 00:06:06,882 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8678963258862495, 'Total loss': 0.8678963258862495} | train loss {'Reaction outcome loss': 0.7998698944948157, 'Total loss': 0.7998698944948157}
2022-11-23 00:06:06,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:06,882 INFO:     Epoch: 34
2022-11-23 00:06:07,714 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8961808952418241, 'Total loss': 0.8961808952418241} | train loss {'Reaction outcome loss': 0.799099451303482, 'Total loss': 0.799099451303482}
2022-11-23 00:06:07,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:07,715 INFO:     Epoch: 35
2022-11-23 00:06:08,566 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.858088304373351, 'Total loss': 0.858088304373351} | train loss {'Reaction outcome loss': 0.7985700917487242, 'Total loss': 0.7985700917487242}
2022-11-23 00:06:08,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:08,567 INFO:     Epoch: 36
2022-11-23 00:06:09,368 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8535353663292798, 'Total loss': 0.8535353663292798} | train loss {'Reaction outcome loss': 0.8004035322033629, 'Total loss': 0.8004035322033629}
2022-11-23 00:06:09,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:09,369 INFO:     Epoch: 37
2022-11-23 00:06:10,200 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8697335171428594, 'Total loss': 0.8697335171428594} | train loss {'Reaction outcome loss': 0.7983702752054954, 'Total loss': 0.7983702752054954}
2022-11-23 00:06:10,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:10,200 INFO:     Epoch: 38
2022-11-23 00:06:10,998 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8850242637775161, 'Total loss': 0.8850242637775161} | train loss {'Reaction outcome loss': 0.797699544137838, 'Total loss': 0.797699544137838}
2022-11-23 00:06:10,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:10,998 INFO:     Epoch: 39
2022-11-23 00:06:11,808 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8617783798412844, 'Total loss': 0.8617783798412844} | train loss {'Reaction outcome loss': 0.7956546891708763, 'Total loss': 0.7956546891708763}
2022-11-23 00:06:11,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:11,808 INFO:     Epoch: 40
2022-11-23 00:06:12,612 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.9241000813516703, 'Total loss': 0.9241000813516703} | train loss {'Reaction outcome loss': 0.7926254257863882, 'Total loss': 0.7926254257863882}
2022-11-23 00:06:12,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:12,612 INFO:     Epoch: 41
2022-11-23 00:06:13,406 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8613864833658392, 'Total loss': 0.8613864833658392} | train loss {'Reaction outcome loss': 0.8019295118292984, 'Total loss': 0.8019295118292984}
2022-11-23 00:06:13,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:13,407 INFO:     Epoch: 42
2022-11-23 00:06:14,224 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8614049648696726, 'Total loss': 0.8614049648696726} | train loss {'Reaction outcome loss': 0.7946944020232376, 'Total loss': 0.7946944020232376}
2022-11-23 00:06:14,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:14,224 INFO:     Epoch: 43
2022-11-23 00:06:15,013 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8413461968302727, 'Total loss': 0.8413461968302727} | train loss {'Reaction outcome loss': 0.7986797898399587, 'Total loss': 0.7986797898399587}
2022-11-23 00:06:15,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:15,013 INFO:     Epoch: 44
2022-11-23 00:06:15,858 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8486205461350355, 'Total loss': 0.8486205461350355} | train loss {'Reaction outcome loss': 0.7987228475054916, 'Total loss': 0.7987228475054916}
2022-11-23 00:06:15,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:15,858 INFO:     Epoch: 45
2022-11-23 00:06:16,638 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8615212975577875, 'Total loss': 0.8615212975577875} | train loss {'Reaction outcome loss': 0.7970004365152242, 'Total loss': 0.7970004365152242}
2022-11-23 00:06:16,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:16,638 INFO:     Epoch: 46
2022-11-23 00:06:17,434 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8594839152964678, 'Total loss': 0.8594839152964678} | train loss {'Reaction outcome loss': 0.7970684384813114, 'Total loss': 0.7970684384813114}
2022-11-23 00:06:17,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:17,435 INFO:     Epoch: 47
2022-11-23 00:06:18,298 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8522406193343076, 'Total loss': 0.8522406193343076} | train loss {'Reaction outcome loss': 0.8020267956110896, 'Total loss': 0.8020267956110896}
2022-11-23 00:06:18,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:18,298 INFO:     Epoch: 48
2022-11-23 00:06:19,057 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8498951636932113, 'Total loss': 0.8498951636932113} | train loss {'Reaction outcome loss': 0.7992847428029898, 'Total loss': 0.7992847428029898}
2022-11-23 00:06:19,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:19,057 INFO:     Epoch: 49
2022-11-23 00:06:19,864 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8543735254894603, 'Total loss': 0.8543735254894603} | train loss {'Reaction outcome loss': 0.7985100041238629, 'Total loss': 0.7985100041238629}
2022-11-23 00:06:19,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:19,865 INFO:     Epoch: 50
2022-11-23 00:06:20,636 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.9111589674245227, 'Total loss': 0.9111589674245227} | train loss {'Reaction outcome loss': 0.8002672143128453, 'Total loss': 0.8002672143128453}
2022-11-23 00:06:20,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:20,637 INFO:     Epoch: 51
2022-11-23 00:06:21,409 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8513535017316992, 'Total loss': 0.8513535017316992} | train loss {'Reaction outcome loss': 0.7926201712112038, 'Total loss': 0.7926201712112038}
2022-11-23 00:06:21,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:21,409 INFO:     Epoch: 52
2022-11-23 00:06:22,166 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.90033950724385, 'Total loss': 0.90033950724385} | train loss {'Reaction outcome loss': 0.7937090703419276, 'Total loss': 0.7937090703419276}
2022-11-23 00:06:22,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:22,166 INFO:     Epoch: 53
2022-11-23 00:06:22,920 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8562162254344333, 'Total loss': 0.8562162254344333} | train loss {'Reaction outcome loss': 0.7982309392520359, 'Total loss': 0.7982309392520359}
2022-11-23 00:06:22,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:22,921 INFO:     Epoch: 54
2022-11-23 00:06:23,703 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8512571196664463, 'Total loss': 0.8512571196664463} | train loss {'Reaction outcome loss': 0.7970100668011879, 'Total loss': 0.7970100668011879}
2022-11-23 00:06:23,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:23,703 INFO:     Epoch: 55
2022-11-23 00:06:24,472 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8440835144032132, 'Total loss': 0.8440835144032132} | train loss {'Reaction outcome loss': 0.7951046318423991, 'Total loss': 0.7951046318423991}
2022-11-23 00:06:24,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:24,472 INFO:     Epoch: 56
2022-11-23 00:06:25,238 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8502169298854741, 'Total loss': 0.8502169298854741} | train loss {'Reaction outcome loss': 0.7974846065044403, 'Total loss': 0.7974846065044403}
2022-11-23 00:06:25,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:25,238 INFO:     Epoch: 57
2022-11-23 00:06:26,021 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8676936416463419, 'Total loss': 0.8676936416463419} | train loss {'Reaction outcome loss': 0.8018127969333104, 'Total loss': 0.8018127969333104}
2022-11-23 00:06:26,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:26,022 INFO:     Epoch: 58
2022-11-23 00:06:26,801 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8593464439565485, 'Total loss': 0.8593464439565485} | train loss {'Reaction outcome loss': 0.7979562703444033, 'Total loss': 0.7979562703444033}
2022-11-23 00:06:26,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:26,801 INFO:     Epoch: 59
2022-11-23 00:06:27,594 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8730536882172931, 'Total loss': 0.8730536882172931} | train loss {'Reaction outcome loss': 0.7974519067881058, 'Total loss': 0.7974519067881058}
2022-11-23 00:06:27,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:27,594 INFO:     Epoch: 60
2022-11-23 00:06:28,372 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8518289334394715, 'Total loss': 0.8518289334394715} | train loss {'Reaction outcome loss': 0.7948023704849944, 'Total loss': 0.7948023704849944}
2022-11-23 00:06:28,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:28,372 INFO:     Epoch: 61
2022-11-23 00:06:29,155 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8353659381920641, 'Total loss': 0.8353659381920641} | train loss {'Reaction outcome loss': 0.7970388716580916, 'Total loss': 0.7970388716580916}
2022-11-23 00:06:29,155 INFO:     Found new best model at epoch 61
2022-11-23 00:06:29,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:29,156 INFO:     Epoch: 62
2022-11-23 00:06:29,932 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.869872659444809, 'Total loss': 0.869872659444809} | train loss {'Reaction outcome loss': 0.7956542022374211, 'Total loss': 0.7956542022374211}
2022-11-23 00:06:29,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:29,933 INFO:     Epoch: 63
2022-11-23 00:06:30,713 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8575678576122631, 'Total loss': 0.8575678576122631} | train loss {'Reaction outcome loss': 0.7973218785256756, 'Total loss': 0.7973218785256756}
2022-11-23 00:06:30,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:30,713 INFO:     Epoch: 64
2022-11-23 00:06:31,462 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8691354515877637, 'Total loss': 0.8691354515877637} | train loss {'Reaction outcome loss': 0.7976332651109111, 'Total loss': 0.7976332651109111}
2022-11-23 00:06:31,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:31,462 INFO:     Epoch: 65
2022-11-23 00:06:32,228 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8381180424581874, 'Total loss': 0.8381180424581874} | train loss {'Reaction outcome loss': 0.7990651009034138, 'Total loss': 0.7990651009034138}
2022-11-23 00:06:32,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:32,228 INFO:     Epoch: 66
2022-11-23 00:06:33,019 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.839585465463725, 'Total loss': 0.839585465463725} | train loss {'Reaction outcome loss': 0.7928581985892081, 'Total loss': 0.7928581985892081}
2022-11-23 00:06:33,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:33,020 INFO:     Epoch: 67
2022-11-23 00:06:33,801 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8577976795760068, 'Total loss': 0.8577976795760068} | train loss {'Reaction outcome loss': 0.796711462006277, 'Total loss': 0.796711462006277}
2022-11-23 00:06:33,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:33,801 INFO:     Epoch: 68
2022-11-23 00:06:34,628 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8825148195028305, 'Total loss': 0.8825148195028305} | train loss {'Reaction outcome loss': 0.792580873625619, 'Total loss': 0.792580873625619}
2022-11-23 00:06:34,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:34,628 INFO:     Epoch: 69
2022-11-23 00:06:35,420 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8462917987595905, 'Total loss': 0.8462917987595905} | train loss {'Reaction outcome loss': 0.8001094129620766, 'Total loss': 0.8001094129620766}
2022-11-23 00:06:35,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:35,420 INFO:     Epoch: 70
2022-11-23 00:06:36,278 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8577179746194319, 'Total loss': 0.8577179746194319} | train loss {'Reaction outcome loss': 0.7980916900294167, 'Total loss': 0.7980916900294167}
2022-11-23 00:06:36,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:36,278 INFO:     Epoch: 71
2022-11-23 00:06:37,093 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8491294980049133, 'Total loss': 0.8491294980049133} | train loss {'Reaction outcome loss': 0.7943575857853403, 'Total loss': 0.7943575857853403}
2022-11-23 00:06:37,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:37,094 INFO:     Epoch: 72
2022-11-23 00:06:37,917 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8708534687757492, 'Total loss': 0.8708534687757492} | train loss {'Reaction outcome loss': 0.7981547889052605, 'Total loss': 0.7981547889052605}
2022-11-23 00:06:37,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:37,918 INFO:     Epoch: 73
2022-11-23 00:06:38,795 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8469631021673029, 'Total loss': 0.8469631021673029} | train loss {'Reaction outcome loss': 0.7976334530480054, 'Total loss': 0.7976334530480054}
2022-11-23 00:06:38,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:38,795 INFO:     Epoch: 74
2022-11-23 00:06:39,573 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.869641971859065, 'Total loss': 0.869641971859065} | train loss {'Reaction outcome loss': 0.7967231304061656, 'Total loss': 0.7967231304061656}
2022-11-23 00:06:39,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:39,574 INFO:     Epoch: 75
2022-11-23 00:06:40,373 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8615249571475115, 'Total loss': 0.8615249571475115} | train loss {'Reaction outcome loss': 0.795494471764078, 'Total loss': 0.795494471764078}
2022-11-23 00:06:40,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:40,373 INFO:     Epoch: 76
2022-11-23 00:06:41,170 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8601396049965512, 'Total loss': 0.8601396049965512} | train loss {'Reaction outcome loss': 0.7935950551714216, 'Total loss': 0.7935950551714216}
2022-11-23 00:06:41,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:41,170 INFO:     Epoch: 77
2022-11-23 00:06:41,966 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8683199394832958, 'Total loss': 0.8683199394832958} | train loss {'Reaction outcome loss': 0.795907782778448, 'Total loss': 0.795907782778448}
2022-11-23 00:06:41,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:41,966 INFO:     Epoch: 78
2022-11-23 00:06:42,735 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8434083732691678, 'Total loss': 0.8434083732691678} | train loss {'Reaction outcome loss': 0.7927772632666996, 'Total loss': 0.7927772632666996}
2022-11-23 00:06:42,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:42,735 INFO:     Epoch: 79
2022-11-23 00:06:43,501 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8739150755784728, 'Total loss': 0.8739150755784728} | train loss {'Reaction outcome loss': 0.8011459102435988, 'Total loss': 0.8011459102435988}
2022-11-23 00:06:43,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:43,501 INFO:     Epoch: 80
2022-11-23 00:06:44,349 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8650782731446353, 'Total loss': 0.8650782731446353} | train loss {'Reaction outcome loss': 0.7956534351621355, 'Total loss': 0.7956534351621355}
2022-11-23 00:06:44,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:44,349 INFO:     Epoch: 81
2022-11-23 00:06:45,175 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8777197206562216, 'Total loss': 0.8777197206562216} | train loss {'Reaction outcome loss': 0.7927574604141469, 'Total loss': 0.7927574604141469}
2022-11-23 00:06:45,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:45,175 INFO:     Epoch: 82
2022-11-23 00:06:45,942 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8518997356295586, 'Total loss': 0.8518997356295586} | train loss {'Reaction outcome loss': 0.7949368925727144, 'Total loss': 0.7949368925727144}
2022-11-23 00:06:45,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:45,942 INFO:     Epoch: 83
2022-11-23 00:06:46,740 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.85446063158187, 'Total loss': 0.85446063158187} | train loss {'Reaction outcome loss': 0.7963581626512566, 'Total loss': 0.7963581626512566}
2022-11-23 00:06:46,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:46,740 INFO:     Epoch: 84
2022-11-23 00:06:47,531 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8722225644371726, 'Total loss': 0.8722225644371726} | train loss {'Reaction outcome loss': 0.7933971873351506, 'Total loss': 0.7933971873351506}
2022-11-23 00:06:47,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:47,531 INFO:     Epoch: 85
2022-11-23 00:06:48,309 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8567729456858202, 'Total loss': 0.8567729456858202} | train loss {'Reaction outcome loss': 0.7993531637045802, 'Total loss': 0.7993531637045802}
2022-11-23 00:06:48,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:48,309 INFO:     Epoch: 86
2022-11-23 00:06:49,088 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8517467880790884, 'Total loss': 0.8517467880790884} | train loss {'Reaction outcome loss': 0.7970814298610298, 'Total loss': 0.7970814298610298}
2022-11-23 00:06:49,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:49,089 INFO:     Epoch: 87
2022-11-23 00:06:49,857 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.90583381598646, 'Total loss': 0.90583381598646} | train loss {'Reaction outcome loss': 0.7975825117558849, 'Total loss': 0.7975825117558849}
2022-11-23 00:06:49,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:49,858 INFO:     Epoch: 88
2022-11-23 00:06:50,707 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.858235464854674, 'Total loss': 0.858235464854674} | train loss {'Reaction outcome loss': 0.7952468508360337, 'Total loss': 0.7952468508360337}
2022-11-23 00:06:50,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:50,708 INFO:     Epoch: 89
2022-11-23 00:06:51,472 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.853887678547339, 'Total loss': 0.853887678547339} | train loss {'Reaction outcome loss': 0.8001112535291789, 'Total loss': 0.8001112535291789}
2022-11-23 00:06:51,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:51,472 INFO:     Epoch: 90
2022-11-23 00:06:52,245 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8465822291645136, 'Total loss': 0.8465822291645136} | train loss {'Reaction outcome loss': 0.7971182449739806, 'Total loss': 0.7971182449739806}
2022-11-23 00:06:52,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:52,246 INFO:     Epoch: 91
2022-11-23 00:06:53,100 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8704049431464889, 'Total loss': 0.8704049431464889} | train loss {'Reaction outcome loss': 0.792364357442272, 'Total loss': 0.792364357442272}
2022-11-23 00:06:53,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:53,100 INFO:     Epoch: 92
2022-11-23 00:06:53,950 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8369533622806723, 'Total loss': 0.8369533622806723} | train loss {'Reaction outcome loss': 0.7954172715848806, 'Total loss': 0.7954172715848806}
2022-11-23 00:06:53,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:53,950 INFO:     Epoch: 93
2022-11-23 00:06:54,791 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8490914512764324, 'Total loss': 0.8490914512764324} | train loss {'Reaction outcome loss': 0.7952081603663308, 'Total loss': 0.7952081603663308}
2022-11-23 00:06:54,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:54,791 INFO:     Epoch: 94
2022-11-23 00:06:55,607 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8762096220796759, 'Total loss': 0.8762096220796759} | train loss {'Reaction outcome loss': 0.7926194572935299, 'Total loss': 0.7926194572935299}
2022-11-23 00:06:55,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:55,607 INFO:     Epoch: 95
2022-11-23 00:06:56,400 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8454763584516265, 'Total loss': 0.8454763584516265} | train loss {'Reaction outcome loss': 0.7947176804347914, 'Total loss': 0.7947176804347914}
2022-11-23 00:06:56,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:56,400 INFO:     Epoch: 96
2022-11-23 00:06:57,207 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8616787791252136, 'Total loss': 0.8616787791252136} | train loss {'Reaction outcome loss': 0.7962692948628445, 'Total loss': 0.7962692948628445}
2022-11-23 00:06:57,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:57,207 INFO:     Epoch: 97
2022-11-23 00:06:58,014 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8698926642537117, 'Total loss': 0.8698926642537117} | train loss {'Reaction outcome loss': 0.7955760278872082, 'Total loss': 0.7955760278872082}
2022-11-23 00:06:58,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:58,014 INFO:     Epoch: 98
2022-11-23 00:06:58,789 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8339697420597076, 'Total loss': 0.8339697420597076} | train loss {'Reaction outcome loss': 0.7961777751543084, 'Total loss': 0.7961777751543084}
2022-11-23 00:06:58,789 INFO:     Found new best model at epoch 98
2022-11-23 00:06:58,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:06:58,790 INFO:     Epoch: 99
2022-11-23 00:06:59,625 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8555279247124087, 'Total loss': 0.8555279247124087} | train loss {'Reaction outcome loss': 0.7945203325578145, 'Total loss': 0.7945203325578145}
2022-11-23 00:06:59,625 INFO:     Best model found after epoch 99 of 100.
2022-11-23 00:06:59,625 INFO:   Done with stage: TRAINING
2022-11-23 00:06:59,625 INFO:   Starting stage: EVALUATION
2022-11-23 00:06:59,761 INFO:   Done with stage: EVALUATION
2022-11-23 00:06:59,761 INFO:   Leaving out SEQ value Fold_1
2022-11-23 00:06:59,775 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:06:59,775 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:07:00,450 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:07:00,450 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:07:00,522 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:07:00,523 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:07:00,523 INFO:     No hyperparam tuning for this model
2022-11-23 00:07:00,523 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:07:00,523 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:07:00,524 INFO:     None feature selector for col prot
2022-11-23 00:07:00,524 INFO:     None feature selector for col prot
2022-11-23 00:07:00,524 INFO:     None feature selector for col prot
2022-11-23 00:07:00,525 INFO:     None feature selector for col chem
2022-11-23 00:07:00,525 INFO:     None feature selector for col chem
2022-11-23 00:07:00,525 INFO:     None feature selector for col chem
2022-11-23 00:07:00,525 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:07:00,525 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:07:00,526 INFO:     Number of params in model 168571
2022-11-23 00:07:00,530 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:07:00,530 INFO:   Starting stage: TRAINING
2022-11-23 00:07:00,590 INFO:     Val loss before train {'Reaction outcome loss': 0.9856542734937235, 'Total loss': 0.9856542734937235}
2022-11-23 00:07:00,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:00,600 INFO:     Epoch: 0
2022-11-23 00:07:01,462 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8442009348760952, 'Total loss': 0.8442009348760952} | train loss {'Reaction outcome loss': 0.8845335198908436, 'Total loss': 0.8845335198908436}
2022-11-23 00:07:01,462 INFO:     Found new best model at epoch 0
2022-11-23 00:07:01,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:01,463 INFO:     Epoch: 1
2022-11-23 00:07:02,328 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8484154316512021, 'Total loss': 0.8484154316512021} | train loss {'Reaction outcome loss': 0.857278466711239, 'Total loss': 0.857278466711239}
2022-11-23 00:07:02,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:02,328 INFO:     Epoch: 2
2022-11-23 00:07:03,190 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8289515829899095, 'Total loss': 0.8289515829899095} | train loss {'Reaction outcome loss': 0.8413453863591563, 'Total loss': 0.8413453863591563}
2022-11-23 00:07:03,190 INFO:     Found new best model at epoch 2
2022-11-23 00:07:03,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:03,191 INFO:     Epoch: 3
2022-11-23 00:07:04,081 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8122287199578502, 'Total loss': 0.8122287199578502} | train loss {'Reaction outcome loss': 0.8441581272349066, 'Total loss': 0.8441581272349066}
2022-11-23 00:07:04,082 INFO:     Found new best model at epoch 3
2022-11-23 00:07:04,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:04,083 INFO:     Epoch: 4
2022-11-23 00:07:04,911 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8047866814515807, 'Total loss': 0.8047866814515807} | train loss {'Reaction outcome loss': 0.8400227997984205, 'Total loss': 0.8400227997984205}
2022-11-23 00:07:04,912 INFO:     Found new best model at epoch 4
2022-11-23 00:07:04,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:04,912 INFO:     Epoch: 5
2022-11-23 00:07:05,771 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8228584704073992, 'Total loss': 0.8228584704073992} | train loss {'Reaction outcome loss': 0.8341697999409267, 'Total loss': 0.8341697999409267}
2022-11-23 00:07:05,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:05,772 INFO:     Epoch: 6
2022-11-23 00:07:06,666 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8253772407770157, 'Total loss': 0.8253772407770157} | train loss {'Reaction outcome loss': 0.8356375937559166, 'Total loss': 0.8356375937559166}
2022-11-23 00:07:06,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:06,666 INFO:     Epoch: 7
2022-11-23 00:07:07,609 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8242558884349737, 'Total loss': 0.8242558884349737} | train loss {'Reaction outcome loss': 0.8302556379717223, 'Total loss': 0.8302556379717223}
2022-11-23 00:07:07,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:07,609 INFO:     Epoch: 8
2022-11-23 00:07:08,530 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8326888463713906, 'Total loss': 0.8326888463713906} | train loss {'Reaction outcome loss': 0.8284128034601406, 'Total loss': 0.8284128034601406}
2022-11-23 00:07:08,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:08,530 INFO:     Epoch: 9
2022-11-23 00:07:09,453 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8185299960049716, 'Total loss': 0.8185299960049716} | train loss {'Reaction outcome loss': 0.8433784544467926, 'Total loss': 0.8433784544467926}
2022-11-23 00:07:09,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:09,454 INFO:     Epoch: 10
2022-11-23 00:07:10,352 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8198966986753724, 'Total loss': 0.8198966986753724} | train loss {'Reaction outcome loss': 0.8292380727067286, 'Total loss': 0.8292380727067286}
2022-11-23 00:07:10,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:10,353 INFO:     Epoch: 11
2022-11-23 00:07:11,292 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8129836591807279, 'Total loss': 0.8129836591807279} | train loss {'Reaction outcome loss': 0.8307383156552607, 'Total loss': 0.8307383156552607}
2022-11-23 00:07:11,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:11,292 INFO:     Epoch: 12
2022-11-23 00:07:12,160 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8002317236228422, 'Total loss': 0.8002317236228422} | train loss {'Reaction outcome loss': 0.8294599411438922, 'Total loss': 0.8294599411438922}
2022-11-23 00:07:12,160 INFO:     Found new best model at epoch 12
2022-11-23 00:07:12,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:12,161 INFO:     Epoch: 13
2022-11-23 00:07:13,032 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8112279833717779, 'Total loss': 0.8112279833717779} | train loss {'Reaction outcome loss': 0.8267298450275343, 'Total loss': 0.8267298450275343}
2022-11-23 00:07:13,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:13,032 INFO:     Epoch: 14
2022-11-23 00:07:13,906 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.829645535485311, 'Total loss': 0.829645535485311} | train loss {'Reaction outcome loss': 0.8283481697646939, 'Total loss': 0.8283481697646939}
2022-11-23 00:07:13,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:13,906 INFO:     Epoch: 15
2022-11-23 00:07:14,820 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8100593523545698, 'Total loss': 0.8100593523545698} | train loss {'Reaction outcome loss': 0.8278436068977628, 'Total loss': 0.8278436068977628}
2022-11-23 00:07:14,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:14,820 INFO:     Epoch: 16
2022-11-23 00:07:15,768 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.804666494442658, 'Total loss': 0.804666494442658} | train loss {'Reaction outcome loss': 0.8292555879573433, 'Total loss': 0.8292555879573433}
2022-11-23 00:07:15,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:15,768 INFO:     Epoch: 17
2022-11-23 00:07:16,682 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8381959843364629, 'Total loss': 0.8381959843364629} | train loss {'Reaction outcome loss': 0.8268477048192705, 'Total loss': 0.8268477048192705}
2022-11-23 00:07:16,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:16,682 INFO:     Epoch: 18
2022-11-23 00:07:17,591 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8198055611415342, 'Total loss': 0.8198055611415342} | train loss {'Reaction outcome loss': 0.8290229412974144, 'Total loss': 0.8290229412974144}
2022-11-23 00:07:17,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:17,592 INFO:     Epoch: 19
2022-11-23 00:07:18,478 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8052410185337067, 'Total loss': 0.8052410185337067} | train loss {'Reaction outcome loss': 0.8286860577914179, 'Total loss': 0.8286860577914179}
2022-11-23 00:07:18,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:18,478 INFO:     Epoch: 20
2022-11-23 00:07:19,355 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8015712826428089, 'Total loss': 0.8015712826428089} | train loss {'Reaction outcome loss': 0.8255310801827178, 'Total loss': 0.8255310801827178}
2022-11-23 00:07:19,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:19,355 INFO:     Epoch: 21
2022-11-23 00:07:20,201 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8100278154015541, 'Total loss': 0.8100278154015541} | train loss {'Reaction outcome loss': 0.8258473087330254, 'Total loss': 0.8258473087330254}
2022-11-23 00:07:20,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:20,201 INFO:     Epoch: 22
2022-11-23 00:07:21,067 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8056815276769075, 'Total loss': 0.8056815276769075} | train loss {'Reaction outcome loss': 0.8242816108830121, 'Total loss': 0.8242816108830121}
2022-11-23 00:07:21,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:21,067 INFO:     Epoch: 23
2022-11-23 00:07:21,953 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8168597979979082, 'Total loss': 0.8168597979979082} | train loss {'Reaction outcome loss': 0.8234213304762937, 'Total loss': 0.8234213304762937}
2022-11-23 00:07:21,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:21,953 INFO:     Epoch: 24
2022-11-23 00:07:22,860 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8166544444181703, 'Total loss': 0.8166544444181703} | train loss {'Reaction outcome loss': 0.8247352670650093, 'Total loss': 0.8247352670650093}
2022-11-23 00:07:22,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:22,861 INFO:     Epoch: 25
2022-11-23 00:07:23,719 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8379480222409422, 'Total loss': 0.8379480222409422} | train loss {'Reaction outcome loss': 0.8246044611444279, 'Total loss': 0.8246044611444279}
2022-11-23 00:07:23,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:23,719 INFO:     Epoch: 26
2022-11-23 00:07:24,585 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8285094384442676, 'Total loss': 0.8285094384442676} | train loss {'Reaction outcome loss': 0.8282215210856224, 'Total loss': 0.8282215210856224}
2022-11-23 00:07:24,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:24,585 INFO:     Epoch: 27
2022-11-23 00:07:25,430 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8184024827046827, 'Total loss': 0.8184024827046827} | train loss {'Reaction outcome loss': 0.8253552253148994, 'Total loss': 0.8253552253148994}
2022-11-23 00:07:25,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:25,431 INFO:     Epoch: 28
2022-11-23 00:07:26,325 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8162633661519397, 'Total loss': 0.8162633661519397} | train loss {'Reaction outcome loss': 0.8186200149205266, 'Total loss': 0.8186200149205266}
2022-11-23 00:07:26,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:26,325 INFO:     Epoch: 29
2022-11-23 00:07:27,162 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8144124150276184, 'Total loss': 0.8144124150276184} | train loss {'Reaction outcome loss': 0.8249993270757247, 'Total loss': 0.8249993270757247}
2022-11-23 00:07:27,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:27,162 INFO:     Epoch: 30
2022-11-23 00:07:27,999 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8071565357121554, 'Total loss': 0.8071565357121554} | train loss {'Reaction outcome loss': 0.825131553533126, 'Total loss': 0.825131553533126}
2022-11-23 00:07:27,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:27,999 INFO:     Epoch: 31
2022-11-23 00:07:28,819 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7955993427471681, 'Total loss': 0.7955993427471681} | train loss {'Reaction outcome loss': 0.8237301916492229, 'Total loss': 0.8237301916492229}
2022-11-23 00:07:28,819 INFO:     Found new best model at epoch 31
2022-11-23 00:07:28,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:28,820 INFO:     Epoch: 32
2022-11-23 00:07:29,678 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8005102293735201, 'Total loss': 0.8005102293735201} | train loss {'Reaction outcome loss': 0.8205194183758326, 'Total loss': 0.8205194183758326}
2022-11-23 00:07:29,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:29,679 INFO:     Epoch: 33
2022-11-23 00:07:30,514 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.798974368382584, 'Total loss': 0.798974368382584} | train loss {'Reaction outcome loss': 0.822121460340461, 'Total loss': 0.822121460340461}
2022-11-23 00:07:30,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:30,514 INFO:     Epoch: 34
2022-11-23 00:07:31,337 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8240279013460333, 'Total loss': 0.8240279013460333} | train loss {'Reaction outcome loss': 0.821971042180548, 'Total loss': 0.821971042180548}
2022-11-23 00:07:31,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:31,337 INFO:     Epoch: 35
2022-11-23 00:07:32,179 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8020004467530684, 'Total loss': 0.8020004467530684} | train loss {'Reaction outcome loss': 0.8250720924260665, 'Total loss': 0.8250720924260665}
2022-11-23 00:07:32,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:32,179 INFO:     Epoch: 36
2022-11-23 00:07:32,975 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8068132075396451, 'Total loss': 0.8068132075396451} | train loss {'Reaction outcome loss': 0.8219521079744612, 'Total loss': 0.8219521079744612}
2022-11-23 00:07:32,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:32,975 INFO:     Epoch: 37
2022-11-23 00:07:33,812 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8320789967070926, 'Total loss': 0.8320789967070926} | train loss {'Reaction outcome loss': 0.8207391263270865, 'Total loss': 0.8207391263270865}
2022-11-23 00:07:33,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:33,812 INFO:     Epoch: 38
2022-11-23 00:07:34,631 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8136311403729699, 'Total loss': 0.8136311403729699} | train loss {'Reaction outcome loss': 0.8237631528961415, 'Total loss': 0.8237631528961415}
2022-11-23 00:07:34,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:34,632 INFO:     Epoch: 39
2022-11-23 00:07:35,453 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8258725458925421, 'Total loss': 0.8258725458925421} | train loss {'Reaction outcome loss': 0.8207402761493411, 'Total loss': 0.8207402761493411}
2022-11-23 00:07:35,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:35,454 INFO:     Epoch: 40
2022-11-23 00:07:36,279 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.804302607070316, 'Total loss': 0.804302607070316} | train loss {'Reaction outcome loss': 0.8234838766711099, 'Total loss': 0.8234838766711099}
2022-11-23 00:07:36,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:36,280 INFO:     Epoch: 41
2022-11-23 00:07:37,081 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7958474326878786, 'Total loss': 0.7958474326878786} | train loss {'Reaction outcome loss': 0.8242433402003074, 'Total loss': 0.8242433402003074}
2022-11-23 00:07:37,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:37,081 INFO:     Epoch: 42
2022-11-23 00:07:37,893 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8102545968510888, 'Total loss': 0.8102545968510888} | train loss {'Reaction outcome loss': 0.8200545345033918, 'Total loss': 0.8200545345033918}
2022-11-23 00:07:37,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:37,894 INFO:     Epoch: 43
2022-11-23 00:07:38,707 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8122474456375296, 'Total loss': 0.8122474456375296} | train loss {'Reaction outcome loss': 0.8176973837978986, 'Total loss': 0.8176973837978986}
2022-11-23 00:07:38,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:38,708 INFO:     Epoch: 44
2022-11-23 00:07:39,594 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7934051745317199, 'Total loss': 0.7934051745317199} | train loss {'Reaction outcome loss': 0.8233431132472291, 'Total loss': 0.8233431132472291}
2022-11-23 00:07:39,594 INFO:     Found new best model at epoch 44
2022-11-23 00:07:39,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:39,595 INFO:     Epoch: 45
2022-11-23 00:07:40,489 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8055766400965777, 'Total loss': 0.8055766400965777} | train loss {'Reaction outcome loss': 0.8206778397365492, 'Total loss': 0.8206778397365492}
2022-11-23 00:07:40,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:40,490 INFO:     Epoch: 46
2022-11-23 00:07:41,343 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7965932657772844, 'Total loss': 0.7965932657772844} | train loss {'Reaction outcome loss': 0.8225037636805553, 'Total loss': 0.8225037636805553}
2022-11-23 00:07:41,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:41,344 INFO:     Epoch: 47
2022-11-23 00:07:42,220 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8117493323304437, 'Total loss': 0.8117493323304437} | train loss {'Reaction outcome loss': 0.8215921797314468, 'Total loss': 0.8215921797314468}
2022-11-23 00:07:42,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:42,220 INFO:     Epoch: 48
2022-11-23 00:07:43,064 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8219356780702417, 'Total loss': 0.8219356780702417} | train loss {'Reaction outcome loss': 0.8234538343487954, 'Total loss': 0.8234538343487954}
2022-11-23 00:07:43,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:43,064 INFO:     Epoch: 49
2022-11-23 00:07:43,917 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8208878975022923, 'Total loss': 0.8208878975022923} | train loss {'Reaction outcome loss': 0.8203092853633724, 'Total loss': 0.8203092853633724}
2022-11-23 00:07:43,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:43,917 INFO:     Epoch: 50
2022-11-23 00:07:44,766 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8078595338897272, 'Total loss': 0.8078595338897272} | train loss {'Reaction outcome loss': 0.8237745742408596, 'Total loss': 0.8237745742408596}
2022-11-23 00:07:44,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:44,767 INFO:     Epoch: 51
2022-11-23 00:07:45,647 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7914393991231918, 'Total loss': 0.7914393991231918} | train loss {'Reaction outcome loss': 0.8238023512217463, 'Total loss': 0.8238023512217463}
2022-11-23 00:07:45,647 INFO:     Found new best model at epoch 51
2022-11-23 00:07:45,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:45,648 INFO:     Epoch: 52
2022-11-23 00:07:46,507 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8036918816241351, 'Total loss': 0.8036918816241351} | train loss {'Reaction outcome loss': 0.8220695180552346, 'Total loss': 0.8220695180552346}
2022-11-23 00:07:46,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:46,507 INFO:     Epoch: 53
2022-11-23 00:07:47,379 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8041966665874828, 'Total loss': 0.8041966665874828} | train loss {'Reaction outcome loss': 0.8225686193728934, 'Total loss': 0.8225686193728934}
2022-11-23 00:07:47,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:47,379 INFO:     Epoch: 54
2022-11-23 00:07:48,205 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8172903304750269, 'Total loss': 0.8172903304750269} | train loss {'Reaction outcome loss': 0.8263789460367086, 'Total loss': 0.8263789460367086}
2022-11-23 00:07:48,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:48,205 INFO:     Epoch: 55
2022-11-23 00:07:49,098 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.78874152966521, 'Total loss': 0.78874152966521} | train loss {'Reaction outcome loss': 0.8226566135883331, 'Total loss': 0.8226566135883331}
2022-11-23 00:07:49,098 INFO:     Found new best model at epoch 55
2022-11-23 00:07:49,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:49,099 INFO:     Epoch: 56
2022-11-23 00:07:49,968 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8184092031283812, 'Total loss': 0.8184092031283812} | train loss {'Reaction outcome loss': 0.8247667184897831, 'Total loss': 0.8247667184897831}
2022-11-23 00:07:49,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:49,969 INFO:     Epoch: 57
2022-11-23 00:07:50,847 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8058964203704487, 'Total loss': 0.8058964203704487} | train loss {'Reaction outcome loss': 0.8255956829810629, 'Total loss': 0.8255956829810629}
2022-11-23 00:07:50,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:50,847 INFO:     Epoch: 58
2022-11-23 00:07:51,696 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8170003911310976, 'Total loss': 0.8170003911310976} | train loss {'Reaction outcome loss': 0.8231691774056882, 'Total loss': 0.8231691774056882}
2022-11-23 00:07:51,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:51,697 INFO:     Epoch: 59
2022-11-23 00:07:52,569 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7990275357257236, 'Total loss': 0.7990275357257236} | train loss {'Reaction outcome loss': 0.8212421926916862, 'Total loss': 0.8212421926916862}
2022-11-23 00:07:52,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:52,569 INFO:     Epoch: 60
2022-11-23 00:07:53,432 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8273532790216532, 'Total loss': 0.8273532790216532} | train loss {'Reaction outcome loss': 0.8184858211449214, 'Total loss': 0.8184858211449214}
2022-11-23 00:07:53,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:53,433 INFO:     Epoch: 61
2022-11-23 00:07:54,278 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7855942360633477, 'Total loss': 0.7855942360633477} | train loss {'Reaction outcome loss': 0.8154395249425148, 'Total loss': 0.8154395249425148}
2022-11-23 00:07:54,279 INFO:     Found new best model at epoch 61
2022-11-23 00:07:54,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:54,280 INFO:     Epoch: 62
2022-11-23 00:07:55,169 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8186463144692507, 'Total loss': 0.8186463144692507} | train loss {'Reaction outcome loss': 0.8247647077453379, 'Total loss': 0.8247647077453379}
2022-11-23 00:07:55,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:55,169 INFO:     Epoch: 63
2022-11-23 00:07:56,039 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8224644186821851, 'Total loss': 0.8224644186821851} | train loss {'Reaction outcome loss': 0.8253113441321315, 'Total loss': 0.8253113441321315}
2022-11-23 00:07:56,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:56,039 INFO:     Epoch: 64
2022-11-23 00:07:56,919 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7824464585970748, 'Total loss': 0.7824464585970748} | train loss {'Reaction outcome loss': 0.8228913383824484, 'Total loss': 0.8228913383824484}
2022-11-23 00:07:56,919 INFO:     Found new best model at epoch 64
2022-11-23 00:07:56,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:56,920 INFO:     Epoch: 65
2022-11-23 00:07:57,771 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8154457943005995, 'Total loss': 0.8154457943005995} | train loss {'Reaction outcome loss': 0.8222207574211822, 'Total loss': 0.8222207574211822}
2022-11-23 00:07:57,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:57,771 INFO:     Epoch: 66
2022-11-23 00:07:58,662 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8042728873816404, 'Total loss': 0.8042728873816404} | train loss {'Reaction outcome loss': 0.8229452789438014, 'Total loss': 0.8229452789438014}
2022-11-23 00:07:58,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:58,662 INFO:     Epoch: 67
2022-11-23 00:07:59,496 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7969936823303049, 'Total loss': 0.7969936823303049} | train loss {'Reaction outcome loss': 0.8195393533122782, 'Total loss': 0.8195393533122782}
2022-11-23 00:07:59,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:07:59,496 INFO:     Epoch: 68
2022-11-23 00:08:00,360 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8150939372452822, 'Total loss': 0.8150939372452822} | train loss {'Reaction outcome loss': 0.8206113253320967, 'Total loss': 0.8206113253320967}
2022-11-23 00:08:00,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:00,360 INFO:     Epoch: 69
2022-11-23 00:08:01,199 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.811910371211442, 'Total loss': 0.811910371211442} | train loss {'Reaction outcome loss': 0.8214051834174565, 'Total loss': 0.8214051834174565}
2022-11-23 00:08:01,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:01,200 INFO:     Epoch: 70
2022-11-23 00:08:02,051 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8057250990109011, 'Total loss': 0.8057250990109011} | train loss {'Reaction outcome loss': 0.8285453304952505, 'Total loss': 0.8285453304952505}
2022-11-23 00:08:02,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:02,051 INFO:     Epoch: 71
2022-11-23 00:08:02,925 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8319376747716557, 'Total loss': 0.8319376747716557} | train loss {'Reaction outcome loss': 0.8234938263893128, 'Total loss': 0.8234938263893128}
2022-11-23 00:08:02,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:02,925 INFO:     Epoch: 72
2022-11-23 00:08:03,833 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8019005994905125, 'Total loss': 0.8019005994905125} | train loss {'Reaction outcome loss': 0.8253809358392443, 'Total loss': 0.8253809358392443}
2022-11-23 00:08:03,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:03,834 INFO:     Epoch: 73
2022-11-23 00:08:04,691 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8297658596526493, 'Total loss': 0.8297658596526493} | train loss {'Reaction outcome loss': 0.8233199176739673, 'Total loss': 0.8233199176739673}
2022-11-23 00:08:04,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:04,692 INFO:     Epoch: 74
2022-11-23 00:08:05,542 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8016005852683024, 'Total loss': 0.8016005852683024} | train loss {'Reaction outcome loss': 0.8209327617470099, 'Total loss': 0.8209327617470099}
2022-11-23 00:08:05,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:05,543 INFO:     Epoch: 75
2022-11-23 00:08:06,376 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8080451759425077, 'Total loss': 0.8080451759425077} | train loss {'Reaction outcome loss': 0.8275005228665411, 'Total loss': 0.8275005228665411}
2022-11-23 00:08:06,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:06,376 INFO:     Epoch: 76
2022-11-23 00:08:07,174 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8206412920897658, 'Total loss': 0.8206412920897658} | train loss {'Reaction outcome loss': 0.826390512987059, 'Total loss': 0.826390512987059}
2022-11-23 00:08:07,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:07,175 INFO:     Epoch: 77
2022-11-23 00:08:08,000 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8295340741222555, 'Total loss': 0.8295340741222555} | train loss {'Reaction outcome loss': 0.8225561627319881, 'Total loss': 0.8225561627319881}
2022-11-23 00:08:08,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:08,001 INFO:     Epoch: 78
2022-11-23 00:08:08,874 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7972437807104804, 'Total loss': 0.7972437807104804} | train loss {'Reaction outcome loss': 0.8217615181086014, 'Total loss': 0.8217615181086014}
2022-11-23 00:08:08,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:08,874 INFO:     Epoch: 79
2022-11-23 00:08:09,715 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8139052242040634, 'Total loss': 0.8139052242040634} | train loss {'Reaction outcome loss': 0.819843660203778, 'Total loss': 0.819843660203778}
2022-11-23 00:08:09,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:09,716 INFO:     Epoch: 80
2022-11-23 00:08:10,523 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8233148821375587, 'Total loss': 0.8233148821375587} | train loss {'Reaction outcome loss': 0.8176121920955425, 'Total loss': 0.8176121920955425}
2022-11-23 00:08:10,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:10,523 INFO:     Epoch: 81
2022-11-23 00:08:11,324 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.799965612590313, 'Total loss': 0.799965612590313} | train loss {'Reaction outcome loss': 0.8257748187804709, 'Total loss': 0.8257748187804709}
2022-11-23 00:08:11,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:11,324 INFO:     Epoch: 82
2022-11-23 00:08:12,118 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.797629555517977, 'Total loss': 0.797629555517977} | train loss {'Reaction outcome loss': 0.8227640218272501, 'Total loss': 0.8227640218272501}
2022-11-23 00:08:12,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:12,119 INFO:     Epoch: 83
2022-11-23 00:08:12,937 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8283493803306059, 'Total loss': 0.8283493803306059} | train loss {'Reaction outcome loss': 0.8206194263331744, 'Total loss': 0.8206194263331744}
2022-11-23 00:08:12,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:12,937 INFO:     Epoch: 84
2022-11-23 00:08:13,724 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7935914282094348, 'Total loss': 0.7935914282094348} | train loss {'Reaction outcome loss': 0.8166163931087572, 'Total loss': 0.8166163931087572}
2022-11-23 00:08:13,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:13,724 INFO:     Epoch: 85
2022-11-23 00:08:14,548 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8236149590123784, 'Total loss': 0.8236149590123784} | train loss {'Reaction outcome loss': 0.8266230027286374, 'Total loss': 0.8266230027286374}
2022-11-23 00:08:14,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:14,548 INFO:     Epoch: 86
2022-11-23 00:08:15,362 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8050097342241894, 'Total loss': 0.8050097342241894} | train loss {'Reaction outcome loss': 0.8175515909584201, 'Total loss': 0.8175515909584201}
2022-11-23 00:08:15,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:15,362 INFO:     Epoch: 87
2022-11-23 00:08:16,170 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8162773508917202, 'Total loss': 0.8162773508917202} | train loss {'Reaction outcome loss': 0.8242817358094818, 'Total loss': 0.8242817358094818}
2022-11-23 00:08:16,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:16,170 INFO:     Epoch: 88
2022-11-23 00:08:17,002 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8056240996176546, 'Total loss': 0.8056240996176546} | train loss {'Reaction outcome loss': 0.8212454525791869, 'Total loss': 0.8212454525791869}
2022-11-23 00:08:17,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:17,002 INFO:     Epoch: 89
2022-11-23 00:08:17,815 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7993264685977589, 'Total loss': 0.7993264685977589} | train loss {'Reaction outcome loss': 0.824739558477791, 'Total loss': 0.824739558477791}
2022-11-23 00:08:17,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:17,816 INFO:     Epoch: 90
2022-11-23 00:08:18,591 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8284216767007654, 'Total loss': 0.8284216767007654} | train loss {'Reaction outcome loss': 0.8222595644240477, 'Total loss': 0.8222595644240477}
2022-11-23 00:08:18,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:18,591 INFO:     Epoch: 91
2022-11-23 00:08:19,392 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8021015870300207, 'Total loss': 0.8021015870300207} | train loss {'Reaction outcome loss': 0.8229718556209487, 'Total loss': 0.8229718556209487}
2022-11-23 00:08:19,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:19,392 INFO:     Epoch: 92
2022-11-23 00:08:20,219 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8345788581804796, 'Total loss': 0.8345788581804796} | train loss {'Reaction outcome loss': 0.8221648811077585, 'Total loss': 0.8221648811077585}
2022-11-23 00:08:20,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:20,219 INFO:     Epoch: 93
2022-11-23 00:08:21,057 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.853313192047856, 'Total loss': 0.853313192047856} | train loss {'Reaction outcome loss': 0.8241365690620578, 'Total loss': 0.8241365690620578}
2022-11-23 00:08:21,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:21,057 INFO:     Epoch: 94
2022-11-23 00:08:21,884 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8074330037290399, 'Total loss': 0.8074330037290399} | train loss {'Reaction outcome loss': 0.8214161287765114, 'Total loss': 0.8214161287765114}
2022-11-23 00:08:21,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:21,884 INFO:     Epoch: 95
2022-11-23 00:08:22,670 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8251883929426019, 'Total loss': 0.8251883929426019} | train loss {'Reaction outcome loss': 0.8223927327564784, 'Total loss': 0.8223927327564784}
2022-11-23 00:08:22,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:22,670 INFO:     Epoch: 96
2022-11-23 00:08:23,474 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8220999721776355, 'Total loss': 0.8220999721776355} | train loss {'Reaction outcome loss': 0.8253152100407347, 'Total loss': 0.8253152100407347}
2022-11-23 00:08:23,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:23,474 INFO:     Epoch: 97
2022-11-23 00:08:24,269 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8172005475922064, 'Total loss': 0.8172005475922064} | train loss {'Reaction outcome loss': 0.8209202947665234, 'Total loss': 0.8209202947665234}
2022-11-23 00:08:24,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:24,270 INFO:     Epoch: 98
2022-11-23 00:08:25,101 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7993884865533222, 'Total loss': 0.7993884865533222} | train loss {'Reaction outcome loss': 0.8255080715734131, 'Total loss': 0.8255080715734131}
2022-11-23 00:08:25,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:25,101 INFO:     Epoch: 99
2022-11-23 00:08:25,853 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7907175435261293, 'Total loss': 0.7907175435261293} | train loss {'Reaction outcome loss': 0.8195501978300056, 'Total loss': 0.8195501978300056}
2022-11-23 00:08:25,853 INFO:     Best model found after epoch 65 of 100.
2022-11-23 00:08:25,853 INFO:   Done with stage: TRAINING
2022-11-23 00:08:25,853 INFO:   Starting stage: EVALUATION
2022-11-23 00:08:25,983 INFO:   Done with stage: EVALUATION
2022-11-23 00:08:25,984 INFO:   Leaving out SEQ value Fold_2
2022-11-23 00:08:25,997 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:08:25,997 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:08:26,666 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:08:26,666 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:08:26,735 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:08:26,735 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:08:26,736 INFO:     No hyperparam tuning for this model
2022-11-23 00:08:26,736 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:08:26,736 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:08:26,736 INFO:     None feature selector for col prot
2022-11-23 00:08:26,737 INFO:     None feature selector for col prot
2022-11-23 00:08:26,737 INFO:     None feature selector for col prot
2022-11-23 00:08:26,737 INFO:     None feature selector for col chem
2022-11-23 00:08:26,738 INFO:     None feature selector for col chem
2022-11-23 00:08:26,738 INFO:     None feature selector for col chem
2022-11-23 00:08:26,738 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:08:26,738 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:08:26,739 INFO:     Number of params in model 168571
2022-11-23 00:08:26,743 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:08:26,743 INFO:   Starting stage: TRAINING
2022-11-23 00:08:26,801 INFO:     Val loss before train {'Reaction outcome loss': 0.9774054072119973, 'Total loss': 0.9774054072119973}
2022-11-23 00:08:26,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:26,801 INFO:     Epoch: 0
2022-11-23 00:08:27,653 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8406250117854639, 'Total loss': 0.8406250117854639} | train loss {'Reaction outcome loss': 0.8901771132038673, 'Total loss': 0.8901771132038673}
2022-11-23 00:08:27,653 INFO:     Found new best model at epoch 0
2022-11-23 00:08:27,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:27,654 INFO:     Epoch: 1
2022-11-23 00:08:28,484 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8394280509515242, 'Total loss': 0.8394280509515242} | train loss {'Reaction outcome loss': 0.8609626920599687, 'Total loss': 0.8609626920599687}
2022-11-23 00:08:28,484 INFO:     Found new best model at epoch 1
2022-11-23 00:08:28,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:28,485 INFO:     Epoch: 2
2022-11-23 00:08:29,278 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8470623289996927, 'Total loss': 0.8470623289996927} | train loss {'Reaction outcome loss': 0.859612025833323, 'Total loss': 0.859612025833323}
2022-11-23 00:08:29,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:29,278 INFO:     Epoch: 3
2022-11-23 00:08:30,060 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8393050296740099, 'Total loss': 0.8393050296740099} | train loss {'Reaction outcome loss': 0.8587871867152843, 'Total loss': 0.8587871867152843}
2022-11-23 00:08:30,061 INFO:     Found new best model at epoch 3
2022-11-23 00:08:30,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:30,062 INFO:     Epoch: 4
2022-11-23 00:08:30,851 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8370485292239622, 'Total loss': 0.8370485292239622} | train loss {'Reaction outcome loss': 0.8481697490220128, 'Total loss': 0.8481697490220128}
2022-11-23 00:08:30,851 INFO:     Found new best model at epoch 4
2022-11-23 00:08:30,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:30,852 INFO:     Epoch: 5
2022-11-23 00:08:31,654 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8699966249140826, 'Total loss': 0.8699966249140826} | train loss {'Reaction outcome loss': 0.8458435169839666, 'Total loss': 0.8458435169839666}
2022-11-23 00:08:31,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:31,654 INFO:     Epoch: 6
2022-11-23 00:08:32,425 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8464206816120581, 'Total loss': 0.8464206816120581} | train loss {'Reaction outcome loss': 0.8471898120424526, 'Total loss': 0.8471898120424526}
2022-11-23 00:08:32,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:32,425 INFO:     Epoch: 7
2022-11-23 00:08:33,289 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8283415653488853, 'Total loss': 0.8283415653488853} | train loss {'Reaction outcome loss': 0.8509059743842615, 'Total loss': 0.8509059743842615}
2022-11-23 00:08:33,289 INFO:     Found new best model at epoch 7
2022-11-23 00:08:33,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:33,290 INFO:     Epoch: 8
2022-11-23 00:08:34,047 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8433848185972734, 'Total loss': 0.8433848185972734} | train loss {'Reaction outcome loss': 0.837968087630716, 'Total loss': 0.837968087630716}
2022-11-23 00:08:34,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:34,047 INFO:     Epoch: 9
2022-11-23 00:08:34,832 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8475293794816191, 'Total loss': 0.8475293794816191} | train loss {'Reaction outcome loss': 0.8366184664158686, 'Total loss': 0.8366184664158686}
2022-11-23 00:08:34,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:34,832 INFO:     Epoch: 10
2022-11-23 00:08:35,650 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8273583101955327, 'Total loss': 0.8273583101955327} | train loss {'Reaction outcome loss': 0.8350210987363267, 'Total loss': 0.8350210987363267}
2022-11-23 00:08:35,650 INFO:     Found new best model at epoch 10
2022-11-23 00:08:35,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:35,651 INFO:     Epoch: 11
2022-11-23 00:08:36,467 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8289828815243461, 'Total loss': 0.8289828815243461} | train loss {'Reaction outcome loss': 0.8272491279793414, 'Total loss': 0.8272491279793414}
2022-11-23 00:08:36,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:36,468 INFO:     Epoch: 12
2022-11-23 00:08:37,296 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8241067921573465, 'Total loss': 0.8241067921573465} | train loss {'Reaction outcome loss': 0.836591751710606, 'Total loss': 0.836591751710606}
2022-11-23 00:08:37,297 INFO:     Found new best model at epoch 12
2022-11-23 00:08:37,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:37,298 INFO:     Epoch: 13
2022-11-23 00:08:38,111 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8485598455775868, 'Total loss': 0.8485598455775868} | train loss {'Reaction outcome loss': 0.8401684097432898, 'Total loss': 0.8401684097432898}
2022-11-23 00:08:38,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:38,111 INFO:     Epoch: 14
2022-11-23 00:08:38,904 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8533189669251442, 'Total loss': 0.8533189669251442} | train loss {'Reaction outcome loss': 0.8286152996183166, 'Total loss': 0.8286152996183166}
2022-11-23 00:08:38,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:38,904 INFO:     Epoch: 15
2022-11-23 00:08:39,702 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8355010761456056, 'Total loss': 0.8355010761456056} | train loss {'Reaction outcome loss': 0.8288566355521862, 'Total loss': 0.8288566355521862}
2022-11-23 00:08:39,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:39,702 INFO:     Epoch: 16
2022-11-23 00:08:40,497 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8306223032149401, 'Total loss': 0.8306223032149401} | train loss {'Reaction outcome loss': 0.8265168514811558, 'Total loss': 0.8265168514811558}
2022-11-23 00:08:40,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:40,497 INFO:     Epoch: 17
2022-11-23 00:08:41,301 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8325066295537081, 'Total loss': 0.8325066295537081} | train loss {'Reaction outcome loss': 0.8257223715183706, 'Total loss': 0.8257223715183706}
2022-11-23 00:08:41,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:41,301 INFO:     Epoch: 18
2022-11-23 00:08:42,110 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8312077501958067, 'Total loss': 0.8312077501958067} | train loss {'Reaction outcome loss': 0.8299718357863938, 'Total loss': 0.8299718357863938}
2022-11-23 00:08:42,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:42,111 INFO:     Epoch: 19
2022-11-23 00:08:42,932 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8664262945001776, 'Total loss': 0.8664262945001776} | train loss {'Reaction outcome loss': 0.8257819464814807, 'Total loss': 0.8257819464814807}
2022-11-23 00:08:42,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:42,933 INFO:     Epoch: 20
2022-11-23 00:08:43,713 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8307872915809805, 'Total loss': 0.8307872915809805} | train loss {'Reaction outcome loss': 0.8205434604272669, 'Total loss': 0.8205434604272669}
2022-11-23 00:08:43,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:43,714 INFO:     Epoch: 21
2022-11-23 00:08:44,536 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8264878100969575, 'Total loss': 0.8264878100969575} | train loss {'Reaction outcome loss': 0.820123612186928, 'Total loss': 0.820123612186928}
2022-11-23 00:08:44,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:44,536 INFO:     Epoch: 22
2022-11-23 00:08:45,372 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8475661433555863, 'Total loss': 0.8475661433555863} | train loss {'Reaction outcome loss': 0.8274413321906255, 'Total loss': 0.8274413321906255}
2022-11-23 00:08:45,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:45,373 INFO:     Epoch: 23
2022-11-23 00:08:46,273 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8353396207094193, 'Total loss': 0.8353396207094193} | train loss {'Reaction outcome loss': 0.8261726171622875, 'Total loss': 0.8261726171622875}
2022-11-23 00:08:46,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:46,273 INFO:     Epoch: 24
2022-11-23 00:08:47,092 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8245192603631453, 'Total loss': 0.8245192603631453} | train loss {'Reaction outcome loss': 0.8184156684800681, 'Total loss': 0.8184156684800681}
2022-11-23 00:08:47,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:47,092 INFO:     Epoch: 25
2022-11-23 00:08:47,918 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8518569388172843, 'Total loss': 0.8518569388172843} | train loss {'Reaction outcome loss': 0.8187504851142404, 'Total loss': 0.8187504851142404}
2022-11-23 00:08:47,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:47,918 INFO:     Epoch: 26
2022-11-23 00:08:48,742 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8350043987685983, 'Total loss': 0.8350043987685983} | train loss {'Reaction outcome loss': 0.8242761004067626, 'Total loss': 0.8242761004067626}
2022-11-23 00:08:48,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:48,742 INFO:     Epoch: 27
2022-11-23 00:08:49,550 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8686186508698897, 'Total loss': 0.8686186508698897} | train loss {'Reaction outcome loss': 0.8213249775562209, 'Total loss': 0.8213249775562209}
2022-11-23 00:08:49,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:49,550 INFO:     Epoch: 28
2022-11-23 00:08:50,363 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8462458334185861, 'Total loss': 0.8462458334185861} | train loss {'Reaction outcome loss': 0.8186660986318279, 'Total loss': 0.8186660986318279}
2022-11-23 00:08:50,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:50,363 INFO:     Epoch: 29
2022-11-23 00:08:51,170 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8329311324791475, 'Total loss': 0.8329311324791475} | train loss {'Reaction outcome loss': 0.8247791895499597, 'Total loss': 0.8247791895499597}
2022-11-23 00:08:51,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:51,171 INFO:     Epoch: 30
2022-11-23 00:08:51,982 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8336673094467684, 'Total loss': 0.8336673094467684} | train loss {'Reaction outcome loss': 0.8171827484238968, 'Total loss': 0.8171827484238968}
2022-11-23 00:08:51,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:51,982 INFO:     Epoch: 31
2022-11-23 00:08:52,834 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8206101710146124, 'Total loss': 0.8206101710146124} | train loss {'Reaction outcome loss': 0.8189970712113356, 'Total loss': 0.8189970712113356}
2022-11-23 00:08:52,834 INFO:     Found new best model at epoch 31
2022-11-23 00:08:52,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:52,835 INFO:     Epoch: 32
2022-11-23 00:08:53,705 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8277996135028926, 'Total loss': 0.8277996135028926} | train loss {'Reaction outcome loss': 0.8189322981033248, 'Total loss': 0.8189322981033248}
2022-11-23 00:08:53,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:53,705 INFO:     Epoch: 33
2022-11-23 00:08:54,571 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8371954682198438, 'Total loss': 0.8371954682198438} | train loss {'Reaction outcome loss': 0.8253071579614631, 'Total loss': 0.8253071579614631}
2022-11-23 00:08:54,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:54,571 INFO:     Epoch: 34
2022-11-23 00:08:55,412 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8219830461523749, 'Total loss': 0.8219830461523749} | train loss {'Reaction outcome loss': 0.830544228133885, 'Total loss': 0.830544228133885}
2022-11-23 00:08:55,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:55,413 INFO:     Epoch: 35
2022-11-23 00:08:56,254 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8354605463418093, 'Total loss': 0.8354605463418093} | train loss {'Reaction outcome loss': 0.827211919342458, 'Total loss': 0.827211919342458}
2022-11-23 00:08:56,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:56,255 INFO:     Epoch: 36
2022-11-23 00:08:57,125 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8498447158119895, 'Total loss': 0.8498447158119895} | train loss {'Reaction outcome loss': 0.8235069662935821, 'Total loss': 0.8235069662935821}
2022-11-23 00:08:57,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:57,125 INFO:     Epoch: 37
2022-11-23 00:08:58,007 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8310902389613065, 'Total loss': 0.8310902389613065} | train loss {'Reaction outcome loss': 0.82199030740541, 'Total loss': 0.82199030740541}
2022-11-23 00:08:58,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:58,008 INFO:     Epoch: 38
2022-11-23 00:08:58,915 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8221933828158812, 'Total loss': 0.8221933828158812} | train loss {'Reaction outcome loss': 0.8263477175100612, 'Total loss': 0.8263477175100612}
2022-11-23 00:08:58,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:58,915 INFO:     Epoch: 39
2022-11-23 00:08:59,764 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8324553600766442, 'Total loss': 0.8324553600766442} | train loss {'Reaction outcome loss': 0.8157931281185826, 'Total loss': 0.8157931281185826}
2022-11-23 00:08:59,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:08:59,764 INFO:     Epoch: 40
2022-11-23 00:09:00,567 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8275150846351277, 'Total loss': 0.8275150846351277} | train loss {'Reaction outcome loss': 0.8213168436940382, 'Total loss': 0.8213168436940382}
2022-11-23 00:09:00,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:00,567 INFO:     Epoch: 41
2022-11-23 00:09:01,338 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.853236237032847, 'Total loss': 0.853236237032847} | train loss {'Reaction outcome loss': 0.8259484536252041, 'Total loss': 0.8259484536252041}
2022-11-23 00:09:01,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:01,338 INFO:     Epoch: 42
2022-11-23 00:09:02,209 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8311796730214899, 'Total loss': 0.8311796730214899} | train loss {'Reaction outcome loss': 0.8191220759892994, 'Total loss': 0.8191220759892994}
2022-11-23 00:09:02,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:02,210 INFO:     Epoch: 43
2022-11-23 00:09:03,022 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8126364499330521, 'Total loss': 0.8126364499330521} | train loss {'Reaction outcome loss': 0.8201891401036066, 'Total loss': 0.8201891401036066}
2022-11-23 00:09:03,022 INFO:     Found new best model at epoch 43
2022-11-23 00:09:03,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:03,023 INFO:     Epoch: 44
2022-11-23 00:09:03,865 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8237562640146776, 'Total loss': 0.8237562640146776} | train loss {'Reaction outcome loss': 0.8212086762252607, 'Total loss': 0.8212086762252607}
2022-11-23 00:09:03,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:03,865 INFO:     Epoch: 45
2022-11-23 00:09:04,766 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8338414904746142, 'Total loss': 0.8338414904746142} | train loss {'Reaction outcome loss': 0.8288197015461168, 'Total loss': 0.8288197015461168}
2022-11-23 00:09:04,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:04,766 INFO:     Epoch: 46
2022-11-23 00:09:05,612 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8198199068958109, 'Total loss': 0.8198199068958109} | train loss {'Reaction outcome loss': 0.8180161529646711, 'Total loss': 0.8180161529646711}
2022-11-23 00:09:05,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:05,612 INFO:     Epoch: 47
2022-11-23 00:09:06,448 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8254626955498349, 'Total loss': 0.8254626955498349} | train loss {'Reaction outcome loss': 0.8201328152828371, 'Total loss': 0.8201328152828371}
2022-11-23 00:09:06,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:06,448 INFO:     Epoch: 48
2022-11-23 00:09:07,273 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8215734470974315, 'Total loss': 0.8215734470974315} | train loss {'Reaction outcome loss': 0.8211258715885853, 'Total loss': 0.8211258715885853}
2022-11-23 00:09:07,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:07,274 INFO:     Epoch: 49
2022-11-23 00:09:08,154 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8179186880588531, 'Total loss': 0.8179186880588531} | train loss {'Reaction outcome loss': 0.8164374351742779, 'Total loss': 0.8164374351742779}
2022-11-23 00:09:08,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:08,154 INFO:     Epoch: 50
2022-11-23 00:09:09,036 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.824975430288098, 'Total loss': 0.824975430288098} | train loss {'Reaction outcome loss': 0.8274890875768083, 'Total loss': 0.8274890875768083}
2022-11-23 00:09:09,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:09,036 INFO:     Epoch: 51
2022-11-23 00:09:09,949 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8180183930830522, 'Total loss': 0.8180183930830522} | train loss {'Reaction outcome loss': 0.8208331055486733, 'Total loss': 0.8208331055486733}
2022-11-23 00:09:09,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:09,950 INFO:     Epoch: 52
2022-11-23 00:09:10,841 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8207934282042764, 'Total loss': 0.8207934282042764} | train loss {'Reaction outcome loss': 0.8152775581066425, 'Total loss': 0.8152775581066425}
2022-11-23 00:09:10,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:10,841 INFO:     Epoch: 53
2022-11-23 00:09:11,726 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8315992253747854, 'Total loss': 0.8315992253747854} | train loss {'Reaction outcome loss': 0.8181665093309967, 'Total loss': 0.8181665093309967}
2022-11-23 00:09:11,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:11,726 INFO:     Epoch: 54
2022-11-23 00:09:12,561 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8175563311034982, 'Total loss': 0.8175563311034982} | train loss {'Reaction outcome loss': 0.8234059942154749, 'Total loss': 0.8234059942154749}
2022-11-23 00:09:12,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:12,561 INFO:     Epoch: 55
2022-11-23 00:09:13,418 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8301092047582973, 'Total loss': 0.8301092047582973} | train loss {'Reaction outcome loss': 0.8159444280843503, 'Total loss': 0.8159444280843503}
2022-11-23 00:09:13,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:13,419 INFO:     Epoch: 56
2022-11-23 00:09:14,258 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8164013610644774, 'Total loss': 0.8164013610644774} | train loss {'Reaction outcome loss': 0.8171596570536193, 'Total loss': 0.8171596570536193}
2022-11-23 00:09:14,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:14,258 INFO:     Epoch: 57
2022-11-23 00:09:15,160 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8205035789446398, 'Total loss': 0.8205035789446398} | train loss {'Reaction outcome loss': 0.818085828894063, 'Total loss': 0.818085828894063}
2022-11-23 00:09:15,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:15,160 INFO:     Epoch: 58
2022-11-23 00:09:16,061 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8258288313042034, 'Total loss': 0.8258288313042034} | train loss {'Reaction outcome loss': 0.823815101795351, 'Total loss': 0.823815101795351}
2022-11-23 00:09:16,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:16,061 INFO:     Epoch: 59
2022-11-23 00:09:16,895 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8416803574020212, 'Total loss': 0.8416803574020212} | train loss {'Reaction outcome loss': 0.8176205522618313, 'Total loss': 0.8176205522618313}
2022-11-23 00:09:16,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:16,895 INFO:     Epoch: 60
2022-11-23 00:09:17,769 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8279827657071027, 'Total loss': 0.8279827657071027} | train loss {'Reaction outcome loss': 0.8194561609131122, 'Total loss': 0.8194561609131122}
2022-11-23 00:09:17,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:17,769 INFO:     Epoch: 61
2022-11-23 00:09:18,568 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8271182416514917, 'Total loss': 0.8271182416514917} | train loss {'Reaction outcome loss': 0.8192667094802084, 'Total loss': 0.8192667094802084}
2022-11-23 00:09:18,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:18,568 INFO:     Epoch: 62
2022-11-23 00:09:19,441 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8523056534203616, 'Total loss': 0.8523056534203616} | train loss {'Reaction outcome loss': 0.8206434289694797, 'Total loss': 0.8206434289694797}
2022-11-23 00:09:19,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:19,441 INFO:     Epoch: 63
2022-11-23 00:09:20,302 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8349914781071923, 'Total loss': 0.8349914781071923} | train loss {'Reaction outcome loss': 0.8150518062384987, 'Total loss': 0.8150518062384987}
2022-11-23 00:09:20,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:20,302 INFO:     Epoch: 64
2022-11-23 00:09:21,118 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8132451596585187, 'Total loss': 0.8132451596585187} | train loss {'Reaction outcome loss': 0.8177958594763327, 'Total loss': 0.8177958594763327}
2022-11-23 00:09:21,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:21,118 INFO:     Epoch: 65
2022-11-23 00:09:21,894 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8190224895423109, 'Total loss': 0.8190224895423109} | train loss {'Reaction outcome loss': 0.8212557391599122, 'Total loss': 0.8212557391599122}
2022-11-23 00:09:21,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:21,895 INFO:     Epoch: 66
2022-11-23 00:09:22,712 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8330910856073553, 'Total loss': 0.8330910856073553} | train loss {'Reaction outcome loss': 0.8195734016808421, 'Total loss': 0.8195734016808421}
2022-11-23 00:09:22,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:22,712 INFO:     Epoch: 67
2022-11-23 00:09:23,550 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8339052078398791, 'Total loss': 0.8339052078398791} | train loss {'Reaction outcome loss': 0.8150447469491225, 'Total loss': 0.8150447469491225}
2022-11-23 00:09:23,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:23,550 INFO:     Epoch: 68
2022-11-23 00:09:24,399 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8244495703415438, 'Total loss': 0.8244495703415438} | train loss {'Reaction outcome loss': 0.8209383164340185, 'Total loss': 0.8209383164340185}
2022-11-23 00:09:24,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:24,399 INFO:     Epoch: 69
2022-11-23 00:09:25,257 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8268480111252178, 'Total loss': 0.8268480111252178} | train loss {'Reaction outcome loss': 0.8240206362264841, 'Total loss': 0.8240206362264841}
2022-11-23 00:09:25,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:25,257 INFO:     Epoch: 70
2022-11-23 00:09:26,078 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8448570492592725, 'Total loss': 0.8448570492592725} | train loss {'Reaction outcome loss': 0.8179228485595842, 'Total loss': 0.8179228485595842}
2022-11-23 00:09:26,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:26,079 INFO:     Epoch: 71
2022-11-23 00:09:26,943 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.83030705018477, 'Total loss': 0.83030705018477} | train loss {'Reaction outcome loss': 0.8205807466316319, 'Total loss': 0.8205807466316319}
2022-11-23 00:09:26,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:26,943 INFO:     Epoch: 72
2022-11-23 00:09:27,778 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8073425475846637, 'Total loss': 0.8073425475846637} | train loss {'Reaction outcome loss': 0.8196519350233348, 'Total loss': 0.8196519350233348}
2022-11-23 00:09:27,778 INFO:     Found new best model at epoch 72
2022-11-23 00:09:27,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:27,779 INFO:     Epoch: 73
2022-11-23 00:09:28,611 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8222755830396306, 'Total loss': 0.8222755830396306} | train loss {'Reaction outcome loss': 0.8182819911584198, 'Total loss': 0.8182819911584198}
2022-11-23 00:09:28,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:28,611 INFO:     Epoch: 74
2022-11-23 00:09:29,442 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8353601856665178, 'Total loss': 0.8353601856665178} | train loss {'Reaction outcome loss': 0.8192942760552955, 'Total loss': 0.8192942760552955}
2022-11-23 00:09:29,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:29,442 INFO:     Epoch: 75
2022-11-23 00:09:30,276 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8245211453600363, 'Total loss': 0.8245211453600363} | train loss {'Reaction outcome loss': 0.8176237970801742, 'Total loss': 0.8176237970801742}
2022-11-23 00:09:30,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:30,277 INFO:     Epoch: 76
2022-11-23 00:09:31,138 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8249974210153926, 'Total loss': 0.8249974210153926} | train loss {'Reaction outcome loss': 0.8184541363706473, 'Total loss': 0.8184541363706473}
2022-11-23 00:09:31,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:31,138 INFO:     Epoch: 77
2022-11-23 00:09:31,973 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8254056931896643, 'Total loss': 0.8254056931896643} | train loss {'Reaction outcome loss': 0.8218923177313708, 'Total loss': 0.8218923177313708}
2022-11-23 00:09:31,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:31,974 INFO:     Epoch: 78
2022-11-23 00:09:32,859 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8253737092018127, 'Total loss': 0.8253737092018127} | train loss {'Reaction outcome loss': 0.817639001105961, 'Total loss': 0.817639001105961}
2022-11-23 00:09:32,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:32,859 INFO:     Epoch: 79
2022-11-23 00:09:33,699 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8376977728171782, 'Total loss': 0.8376977728171782} | train loss {'Reaction outcome loss': 0.8182948791546377, 'Total loss': 0.8182948791546377}
2022-11-23 00:09:33,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:33,700 INFO:     Epoch: 80
2022-11-23 00:09:34,548 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.854809542271224, 'Total loss': 0.854809542271224} | train loss {'Reaction outcome loss': 0.8212163397657727, 'Total loss': 0.8212163397657727}
2022-11-23 00:09:34,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:34,548 INFO:     Epoch: 81
2022-11-23 00:09:35,403 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8399601558392699, 'Total loss': 0.8399601558392699} | train loss {'Reaction outcome loss': 0.8234536623665196, 'Total loss': 0.8234536623665196}
2022-11-23 00:09:35,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:35,403 INFO:     Epoch: 82
2022-11-23 00:09:36,238 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8303433053872802, 'Total loss': 0.8303433053872802} | train loss {'Reaction outcome loss': 0.8241968321414129, 'Total loss': 0.8241968321414129}
2022-11-23 00:09:36,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:36,238 INFO:     Epoch: 83
2022-11-23 00:09:37,066 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8236159892244772, 'Total loss': 0.8236159892244772} | train loss {'Reaction outcome loss': 0.8212804247734518, 'Total loss': 0.8212804247734518}
2022-11-23 00:09:37,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:37,066 INFO:     Epoch: 84
2022-11-23 00:09:37,888 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.82688512111252, 'Total loss': 0.82688512111252} | train loss {'Reaction outcome loss': 0.8255211881056488, 'Total loss': 0.8255211881056488}
2022-11-23 00:09:37,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:37,889 INFO:     Epoch: 85
2022-11-23 00:09:38,744 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.823772482573986, 'Total loss': 0.823772482573986} | train loss {'Reaction outcome loss': 0.8250666359658183, 'Total loss': 0.8250666359658183}
2022-11-23 00:09:38,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:38,745 INFO:     Epoch: 86
2022-11-23 00:09:39,567 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8238058164715767, 'Total loss': 0.8238058164715767} | train loss {'Reaction outcome loss': 0.8216674713953304, 'Total loss': 0.8216674713953304}
2022-11-23 00:09:39,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:39,568 INFO:     Epoch: 87
2022-11-23 00:09:40,377 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8415290029211477, 'Total loss': 0.8415290029211477} | train loss {'Reaction outcome loss': 0.8256317101992093, 'Total loss': 0.8256317101992093}
2022-11-23 00:09:40,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:40,377 INFO:     Epoch: 88
2022-11-23 00:09:41,210 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8117577623237263, 'Total loss': 0.8117577623237263} | train loss {'Reaction outcome loss': 0.8238985157205991, 'Total loss': 0.8238985157205991}
2022-11-23 00:09:41,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:41,210 INFO:     Epoch: 89
2022-11-23 00:09:42,021 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8338631919839166, 'Total loss': 0.8338631919839166} | train loss {'Reaction outcome loss': 0.8206517386291674, 'Total loss': 0.8206517386291674}
2022-11-23 00:09:42,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:42,021 INFO:     Epoch: 90
2022-11-23 00:09:42,832 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.828145218166438, 'Total loss': 0.828145218166438} | train loss {'Reaction outcome loss': 0.8141923973917479, 'Total loss': 0.8141923973917479}
2022-11-23 00:09:42,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:42,832 INFO:     Epoch: 91
2022-11-23 00:09:43,615 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8215244155038487, 'Total loss': 0.8215244155038487} | train loss {'Reaction outcome loss': 0.8235976293019438, 'Total loss': 0.8235976293019438}
2022-11-23 00:09:43,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:43,615 INFO:     Epoch: 92
2022-11-23 00:09:44,417 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8451589169827375, 'Total loss': 0.8451589169827375} | train loss {'Reaction outcome loss': 0.8180282533410107, 'Total loss': 0.8180282533410107}
2022-11-23 00:09:44,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:44,418 INFO:     Epoch: 93
2022-11-23 00:09:45,220 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8336012776602398, 'Total loss': 0.8336012776602398} | train loss {'Reaction outcome loss': 0.821617492780029, 'Total loss': 0.821617492780029}
2022-11-23 00:09:45,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:45,221 INFO:     Epoch: 94
2022-11-23 00:09:46,048 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8307300508022308, 'Total loss': 0.8307300508022308} | train loss {'Reaction outcome loss': 0.81503049166579, 'Total loss': 0.81503049166579}
2022-11-23 00:09:46,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:46,048 INFO:     Epoch: 95
2022-11-23 00:09:46,888 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8254467316649177, 'Total loss': 0.8254467316649177} | train loss {'Reaction outcome loss': 0.8211519465996668, 'Total loss': 0.8211519465996668}
2022-11-23 00:09:46,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:46,888 INFO:     Epoch: 96
2022-11-23 00:09:47,694 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8278295431624759, 'Total loss': 0.8278295431624759} | train loss {'Reaction outcome loss': 0.8210342638647026, 'Total loss': 0.8210342638647026}
2022-11-23 00:09:47,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:47,694 INFO:     Epoch: 97
2022-11-23 00:09:48,549 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8084629929878495, 'Total loss': 0.8084629929878495} | train loss {'Reaction outcome loss': 0.819834942397801, 'Total loss': 0.819834942397801}
2022-11-23 00:09:48,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:48,549 INFO:     Epoch: 98
2022-11-23 00:09:49,363 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8403605039824139, 'Total loss': 0.8403605039824139} | train loss {'Reaction outcome loss': 0.8171606028248907, 'Total loss': 0.8171606028248907}
2022-11-23 00:09:49,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:49,363 INFO:     Epoch: 99
2022-11-23 00:09:50,193 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8221854946830056, 'Total loss': 0.8221854946830056} | train loss {'Reaction outcome loss': 0.8157877029044184, 'Total loss': 0.8157877029044184}
2022-11-23 00:09:50,193 INFO:     Best model found after epoch 73 of 100.
2022-11-23 00:09:50,193 INFO:   Done with stage: TRAINING
2022-11-23 00:09:50,193 INFO:   Starting stage: EVALUATION
2022-11-23 00:09:50,318 INFO:   Done with stage: EVALUATION
2022-11-23 00:09:50,318 INFO:   Leaving out SEQ value Fold_3
2022-11-23 00:09:50,331 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:09:50,331 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:09:51,004 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:09:51,004 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:09:51,075 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:09:51,075 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:09:51,075 INFO:     No hyperparam tuning for this model
2022-11-23 00:09:51,075 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:09:51,075 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:09:51,076 INFO:     None feature selector for col prot
2022-11-23 00:09:51,076 INFO:     None feature selector for col prot
2022-11-23 00:09:51,076 INFO:     None feature selector for col prot
2022-11-23 00:09:51,077 INFO:     None feature selector for col chem
2022-11-23 00:09:51,077 INFO:     None feature selector for col chem
2022-11-23 00:09:51,077 INFO:     None feature selector for col chem
2022-11-23 00:09:51,077 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:09:51,077 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:09:51,079 INFO:     Number of params in model 168571
2022-11-23 00:09:51,082 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:09:51,082 INFO:   Starting stage: TRAINING
2022-11-23 00:09:51,141 INFO:     Val loss before train {'Reaction outcome loss': 1.0072308047251268, 'Total loss': 1.0072308047251268}
2022-11-23 00:09:51,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:51,141 INFO:     Epoch: 0
2022-11-23 00:09:51,959 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8400553288784894, 'Total loss': 0.8400553288784894} | train loss {'Reaction outcome loss': 0.8686179207295788, 'Total loss': 0.8686179207295788}
2022-11-23 00:09:51,959 INFO:     Found new best model at epoch 0
2022-11-23 00:09:51,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:51,960 INFO:     Epoch: 1
2022-11-23 00:09:52,754 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8297907682982358, 'Total loss': 0.8297907682982358} | train loss {'Reaction outcome loss': 0.8360171519980139, 'Total loss': 0.8360171519980139}
2022-11-23 00:09:52,754 INFO:     Found new best model at epoch 1
2022-11-23 00:09:52,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:52,755 INFO:     Epoch: 2
2022-11-23 00:09:53,530 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8066977452148091, 'Total loss': 0.8066977452148091} | train loss {'Reaction outcome loss': 0.8368394597452514, 'Total loss': 0.8368394597452514}
2022-11-23 00:09:53,530 INFO:     Found new best model at epoch 2
2022-11-23 00:09:53,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:53,531 INFO:     Epoch: 3
2022-11-23 00:09:54,341 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8573730852116238, 'Total loss': 0.8573730852116238} | train loss {'Reaction outcome loss': 0.8227016886886285, 'Total loss': 0.8227016886886285}
2022-11-23 00:09:54,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:54,341 INFO:     Epoch: 4
2022-11-23 00:09:55,173 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8220195269042795, 'Total loss': 0.8220195269042795} | train loss {'Reaction outcome loss': 0.8209524306715751, 'Total loss': 0.8209524306715751}
2022-11-23 00:09:55,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:55,173 INFO:     Epoch: 5
2022-11-23 00:09:55,987 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8066166232932698, 'Total loss': 0.8066166232932698} | train loss {'Reaction outcome loss': 0.8173832807005669, 'Total loss': 0.8173832807005669}
2022-11-23 00:09:55,987 INFO:     Found new best model at epoch 5
2022-11-23 00:09:55,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:55,988 INFO:     Epoch: 6
2022-11-23 00:09:56,815 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8229746276682074, 'Total loss': 0.8229746276682074} | train loss {'Reaction outcome loss': 0.8153345627444131, 'Total loss': 0.8153345627444131}
2022-11-23 00:09:56,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:56,816 INFO:     Epoch: 7
2022-11-23 00:09:57,630 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8177173246036876, 'Total loss': 0.8177173246036876} | train loss {'Reaction outcome loss': 0.813030937739781, 'Total loss': 0.813030937739781}
2022-11-23 00:09:57,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:57,631 INFO:     Epoch: 8
2022-11-23 00:09:58,491 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7983832178129391, 'Total loss': 0.7983832178129391} | train loss {'Reaction outcome loss': 0.8141568189981032, 'Total loss': 0.8141568189981032}
2022-11-23 00:09:58,491 INFO:     Found new best model at epoch 8
2022-11-23 00:09:58,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:58,492 INFO:     Epoch: 9
2022-11-23 00:09:59,266 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.802133671939373, 'Total loss': 0.802133671939373} | train loss {'Reaction outcome loss': 0.8140544509401126, 'Total loss': 0.8140544509401126}
2022-11-23 00:09:59,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:09:59,266 INFO:     Epoch: 10
2022-11-23 00:10:00,105 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8026482652534138, 'Total loss': 0.8026482652534138} | train loss {'Reaction outcome loss': 0.8116264188776211, 'Total loss': 0.8116264188776211}
2022-11-23 00:10:00,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:00,105 INFO:     Epoch: 11
2022-11-23 00:10:00,925 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7987827429209243, 'Total loss': 0.7987827429209243} | train loss {'Reaction outcome loss': 0.810303705200857, 'Total loss': 0.810303705200857}
2022-11-23 00:10:00,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:00,925 INFO:     Epoch: 12
2022-11-23 00:10:01,709 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8272781907157465, 'Total loss': 0.8272781907157465} | train loss {'Reaction outcome loss': 0.811382415343304, 'Total loss': 0.811382415343304}
2022-11-23 00:10:01,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:01,709 INFO:     Epoch: 13
2022-11-23 00:10:02,495 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8222681189125235, 'Total loss': 0.8222681189125235} | train loss {'Reaction outcome loss': 0.8151151457611395, 'Total loss': 0.8151151457611395}
2022-11-23 00:10:02,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:02,495 INFO:     Epoch: 14
2022-11-23 00:10:03,287 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.804584114388986, 'Total loss': 0.804584114388986} | train loss {'Reaction outcome loss': 0.8073531042556373, 'Total loss': 0.8073531042556373}
2022-11-23 00:10:03,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:03,287 INFO:     Epoch: 15
2022-11-23 00:10:04,095 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8003477874127302, 'Total loss': 0.8003477874127302} | train loss {'Reaction outcome loss': 0.8075770569090941, 'Total loss': 0.8075770569090941}
2022-11-23 00:10:04,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:04,095 INFO:     Epoch: 16
2022-11-23 00:10:04,878 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7929341583089395, 'Total loss': 0.7929341583089395} | train loss {'Reaction outcome loss': 0.8076560727187565, 'Total loss': 0.8076560727187565}
2022-11-23 00:10:04,878 INFO:     Found new best model at epoch 16
2022-11-23 00:10:04,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:04,879 INFO:     Epoch: 17
2022-11-23 00:10:05,670 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8102006898684935, 'Total loss': 0.8102006898684935} | train loss {'Reaction outcome loss': 0.811844605937296, 'Total loss': 0.811844605937296}
2022-11-23 00:10:05,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:05,671 INFO:     Epoch: 18
2022-11-23 00:10:06,479 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.809884178367528, 'Total loss': 0.809884178367528} | train loss {'Reaction outcome loss': 0.8059827376385125, 'Total loss': 0.8059827376385125}
2022-11-23 00:10:06,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:06,479 INFO:     Epoch: 19
2022-11-23 00:10:07,324 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7860754792663184, 'Total loss': 0.7860754792663184} | train loss {'Reaction outcome loss': 0.8072290763563039, 'Total loss': 0.8072290763563039}
2022-11-23 00:10:07,324 INFO:     Found new best model at epoch 19
2022-11-23 00:10:07,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:07,325 INFO:     Epoch: 20
2022-11-23 00:10:08,152 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.809206597507, 'Total loss': 0.809206597507} | train loss {'Reaction outcome loss': 0.808107906336687, 'Total loss': 0.808107906336687}
2022-11-23 00:10:08,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:08,152 INFO:     Epoch: 21
2022-11-23 00:10:08,964 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8124302266673609, 'Total loss': 0.8124302266673609} | train loss {'Reaction outcome loss': 0.8050875112718465, 'Total loss': 0.8050875112718465}
2022-11-23 00:10:08,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:08,964 INFO:     Epoch: 22
2022-11-23 00:10:09,754 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.817353450439193, 'Total loss': 0.817353450439193} | train loss {'Reaction outcome loss': 0.8126661352965296, 'Total loss': 0.8126661352965296}
2022-11-23 00:10:09,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:09,755 INFO:     Epoch: 23
2022-11-23 00:10:10,559 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7988782735033468, 'Total loss': 0.7988782735033468} | train loss {'Reaction outcome loss': 0.8064213954672521, 'Total loss': 0.8064213954672521}
2022-11-23 00:10:10,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:10,561 INFO:     Epoch: 24
2022-11-23 00:10:11,386 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8418011834675615, 'Total loss': 0.8418011834675615} | train loss {'Reaction outcome loss': 0.8027578037612292, 'Total loss': 0.8027578037612292}
2022-11-23 00:10:11,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:11,386 INFO:     Epoch: 25
2022-11-23 00:10:12,235 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8095522292635657, 'Total loss': 0.8095522292635657} | train loss {'Reaction outcome loss': 0.8087856071335929, 'Total loss': 0.8087856071335929}
2022-11-23 00:10:12,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:12,235 INFO:     Epoch: 26
2022-11-23 00:10:13,035 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8088682876391844, 'Total loss': 0.8088682876391844} | train loss {'Reaction outcome loss': 0.805601817369461, 'Total loss': 0.805601817369461}
2022-11-23 00:10:13,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:13,035 INFO:     Epoch: 27
2022-11-23 00:10:13,802 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8247815492478284, 'Total loss': 0.8247815492478284} | train loss {'Reaction outcome loss': 0.8067802325803406, 'Total loss': 0.8067802325803406}
2022-11-23 00:10:13,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:13,802 INFO:     Epoch: 28
2022-11-23 00:10:14,562 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.812611692331054, 'Total loss': 0.812611692331054} | train loss {'Reaction outcome loss': 0.8058811437110511, 'Total loss': 0.8058811437110511}
2022-11-23 00:10:14,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:14,562 INFO:     Epoch: 29
2022-11-23 00:10:15,371 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7918219667944041, 'Total loss': 0.7918219667944041} | train loss {'Reaction outcome loss': 0.8050399623355087, 'Total loss': 0.8050399623355087}
2022-11-23 00:10:15,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:15,371 INFO:     Epoch: 30
2022-11-23 00:10:16,146 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8147554702379487, 'Total loss': 0.8147554702379487} | train loss {'Reaction outcome loss': 0.8019673054315606, 'Total loss': 0.8019673054315606}
2022-11-23 00:10:16,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:16,146 INFO:     Epoch: 31
2022-11-23 00:10:16,952 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8152512386441231, 'Total loss': 0.8152512386441231} | train loss {'Reaction outcome loss': 0.8038553239131461, 'Total loss': 0.8038553239131461}
2022-11-23 00:10:16,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:16,953 INFO:     Epoch: 32
2022-11-23 00:10:17,772 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.790500782430172, 'Total loss': 0.790500782430172} | train loss {'Reaction outcome loss': 0.804842625710429, 'Total loss': 0.804842625710429}
2022-11-23 00:10:17,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:17,772 INFO:     Epoch: 33
2022-11-23 00:10:18,617 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7874205058271234, 'Total loss': 0.7874205058271234} | train loss {'Reaction outcome loss': 0.8065519684431505, 'Total loss': 0.8065519684431505}
2022-11-23 00:10:18,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:18,617 INFO:     Epoch: 34
2022-11-23 00:10:19,399 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.804156709801067, 'Total loss': 0.804156709801067} | train loss {'Reaction outcome loss': 0.8040167465501902, 'Total loss': 0.8040167465501902}
2022-11-23 00:10:19,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:19,400 INFO:     Epoch: 35
2022-11-23 00:10:20,209 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.854570597410202, 'Total loss': 0.854570597410202} | train loss {'Reaction outcome loss': 0.804011101138835, 'Total loss': 0.804011101138835}
2022-11-23 00:10:20,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:20,210 INFO:     Epoch: 36
2022-11-23 00:10:21,003 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8163969787684354, 'Total loss': 0.8163969787684354} | train loss {'Reaction outcome loss': 0.8066618390229283, 'Total loss': 0.8066618390229283}
2022-11-23 00:10:21,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:21,003 INFO:     Epoch: 37
2022-11-23 00:10:21,790 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.806635169820352, 'Total loss': 0.806635169820352} | train loss {'Reaction outcome loss': 0.8050046746828118, 'Total loss': 0.8050046746828118}
2022-11-23 00:10:21,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:21,790 INFO:     Epoch: 38
2022-11-23 00:10:22,588 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8312523947520689, 'Total loss': 0.8312523947520689} | train loss {'Reaction outcome loss': 0.8094039323378582, 'Total loss': 0.8094039323378582}
2022-11-23 00:10:22,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:22,588 INFO:     Epoch: 39
2022-11-23 00:10:23,400 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7964813191105019, 'Total loss': 0.7964813191105019} | train loss {'Reaction outcome loss': 0.8039750461675683, 'Total loss': 0.8039750461675683}
2022-11-23 00:10:23,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:23,400 INFO:     Epoch: 40
2022-11-23 00:10:24,207 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8075276721607555, 'Total loss': 0.8075276721607555} | train loss {'Reaction outcome loss': 0.8055781801136173, 'Total loss': 0.8055781801136173}
2022-11-23 00:10:24,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:24,207 INFO:     Epoch: 41
2022-11-23 00:10:25,031 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8180543489076875, 'Total loss': 0.8180543489076875} | train loss {'Reaction outcome loss': 0.8048278255122049, 'Total loss': 0.8048278255122049}
2022-11-23 00:10:25,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:25,031 INFO:     Epoch: 42
2022-11-23 00:10:25,843 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8091780252077363, 'Total loss': 0.8091780252077363} | train loss {'Reaction outcome loss': 0.8042927986505081, 'Total loss': 0.8042927986505081}
2022-11-23 00:10:25,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:25,843 INFO:     Epoch: 43
2022-11-23 00:10:26,634 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8061626736413349, 'Total loss': 0.8061626736413349} | train loss {'Reaction outcome loss': 0.8021086893519577, 'Total loss': 0.8021086893519577}
2022-11-23 00:10:26,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:26,634 INFO:     Epoch: 44
2022-11-23 00:10:27,486 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8000118481841955, 'Total loss': 0.8000118481841955} | train loss {'Reaction outcome loss': 0.7992262294097823, 'Total loss': 0.7992262294097823}
2022-11-23 00:10:27,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:27,487 INFO:     Epoch: 45
2022-11-23 00:10:28,293 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7988135137341239, 'Total loss': 0.7988135137341239} | train loss {'Reaction outcome loss': 0.8026069877099018, 'Total loss': 0.8026069877099018}
2022-11-23 00:10:28,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:28,293 INFO:     Epoch: 46
2022-11-23 00:10:29,084 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8111833008852872, 'Total loss': 0.8111833008852872} | train loss {'Reaction outcome loss': 0.8025384732655116, 'Total loss': 0.8025384732655116}
2022-11-23 00:10:29,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:29,085 INFO:     Epoch: 47
2022-11-23 00:10:29,920 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7982545210556551, 'Total loss': 0.7982545210556551} | train loss {'Reaction outcome loss': 0.8079890586891952, 'Total loss': 0.8079890586891952}
2022-11-23 00:10:29,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:29,920 INFO:     Epoch: 48
2022-11-23 00:10:30,703 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8235453821041367, 'Total loss': 0.8235453821041367} | train loss {'Reaction outcome loss': 0.8041320203518381, 'Total loss': 0.8041320203518381}
2022-11-23 00:10:30,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:30,703 INFO:     Epoch: 49
2022-11-23 00:10:31,504 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8004078695719893, 'Total loss': 0.8004078695719893} | train loss {'Reaction outcome loss': 0.8067647249114757, 'Total loss': 0.8067647249114757}
2022-11-23 00:10:31,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:31,504 INFO:     Epoch: 50
2022-11-23 00:10:32,293 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7938842597332868, 'Total loss': 0.7938842597332868} | train loss {'Reaction outcome loss': 0.8042226989658512, 'Total loss': 0.8042226989658512}
2022-11-23 00:10:32,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:32,293 INFO:     Epoch: 51
2022-11-23 00:10:33,103 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8030019944364374, 'Total loss': 0.8030019944364374} | train loss {'Reaction outcome loss': 0.8074905441731822, 'Total loss': 0.8074905441731822}
2022-11-23 00:10:33,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:33,103 INFO:     Epoch: 52
2022-11-23 00:10:33,953 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7885819863189351, 'Total loss': 0.7885819863189351} | train loss {'Reaction outcome loss': 0.8047126911124405, 'Total loss': 0.8047126911124405}
2022-11-23 00:10:33,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:33,954 INFO:     Epoch: 53
2022-11-23 00:10:34,768 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8038307692516934, 'Total loss': 0.8038307692516934} | train loss {'Reaction outcome loss': 0.8032010401998247, 'Total loss': 0.8032010401998247}
2022-11-23 00:10:34,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:34,769 INFO:     Epoch: 54
2022-11-23 00:10:35,590 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8123796798966147, 'Total loss': 0.8123796798966147} | train loss {'Reaction outcome loss': 0.8030553454039048, 'Total loss': 0.8030553454039048}
2022-11-23 00:10:35,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:35,591 INFO:     Epoch: 55
2022-11-23 00:10:36,385 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8295312415469777, 'Total loss': 0.8295312415469777} | train loss {'Reaction outcome loss': 0.8066908348579795, 'Total loss': 0.8066908348579795}
2022-11-23 00:10:36,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:36,386 INFO:     Epoch: 56
2022-11-23 00:10:37,199 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8060042262077332, 'Total loss': 0.8060042262077332} | train loss {'Reaction outcome loss': 0.8034285974745847, 'Total loss': 0.8034285974745847}
2022-11-23 00:10:37,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:37,199 INFO:     Epoch: 57
2022-11-23 00:10:38,022 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8170687061819163, 'Total loss': 0.8170687061819163} | train loss {'Reaction outcome loss': 0.8068211031203367, 'Total loss': 0.8068211031203367}
2022-11-23 00:10:38,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:38,022 INFO:     Epoch: 58
2022-11-23 00:10:38,827 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8476117862896486, 'Total loss': 0.8476117862896486} | train loss {'Reaction outcome loss': 0.8097006656685654, 'Total loss': 0.8097006656685654}
2022-11-23 00:10:38,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:38,827 INFO:     Epoch: 59
2022-11-23 00:10:39,573 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.805349894545295, 'Total loss': 0.805349894545295} | train loss {'Reaction outcome loss': 0.8031952420059516, 'Total loss': 0.8031952420059516}
2022-11-23 00:10:39,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:39,573 INFO:     Epoch: 60
2022-11-23 00:10:40,425 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8001312586394224, 'Total loss': 0.8001312586394224} | train loss {'Reaction outcome loss': 0.8067048464502607, 'Total loss': 0.8067048464502607}
2022-11-23 00:10:40,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:40,425 INFO:     Epoch: 61
2022-11-23 00:10:41,203 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8197237009351904, 'Total loss': 0.8197237009351904} | train loss {'Reaction outcome loss': 0.8049386711753145, 'Total loss': 0.8049386711753145}
2022-11-23 00:10:41,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:41,204 INFO:     Epoch: 62
2022-11-23 00:10:42,000 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8288258144801314, 'Total loss': 0.8288258144801314} | train loss {'Reaction outcome loss': 0.8077264695751424, 'Total loss': 0.8077264695751424}
2022-11-23 00:10:42,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:42,001 INFO:     Epoch: 63
2022-11-23 00:10:42,819 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.817033635621721, 'Total loss': 0.817033635621721} | train loss {'Reaction outcome loss': 0.8028674972300627, 'Total loss': 0.8028674972300627}
2022-11-23 00:10:42,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:42,820 INFO:     Epoch: 64
2022-11-23 00:10:43,630 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8005254356698557, 'Total loss': 0.8005254356698557} | train loss {'Reaction outcome loss': 0.8067454820992995, 'Total loss': 0.8067454820992995}
2022-11-23 00:10:43,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:43,630 INFO:     Epoch: 65
2022-11-23 00:10:44,417 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8112329813567075, 'Total loss': 0.8112329813567075} | train loss {'Reaction outcome loss': 0.7994549180780138, 'Total loss': 0.7994549180780138}
2022-11-23 00:10:44,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:44,417 INFO:     Epoch: 66
2022-11-23 00:10:45,218 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.804726324298165, 'Total loss': 0.804726324298165} | train loss {'Reaction outcome loss': 0.8050499356522852, 'Total loss': 0.8050499356522852}
2022-11-23 00:10:45,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:45,219 INFO:     Epoch: 67
2022-11-23 00:10:46,054 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7958499531854283, 'Total loss': 0.7958499531854283} | train loss {'Reaction outcome loss': 0.8062428273716752, 'Total loss': 0.8062428273716752}
2022-11-23 00:10:46,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:46,054 INFO:     Epoch: 68
2022-11-23 00:10:46,866 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8154395615512674, 'Total loss': 0.8154395615512674} | train loss {'Reaction outcome loss': 0.8015816496343029, 'Total loss': 0.8015816496343029}
2022-11-23 00:10:46,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:46,866 INFO:     Epoch: 69
2022-11-23 00:10:47,668 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8008680871941827, 'Total loss': 0.8008680871941827} | train loss {'Reaction outcome loss': 0.8060625449735291, 'Total loss': 0.8060625449735291}
2022-11-23 00:10:47,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:47,669 INFO:     Epoch: 70
2022-11-23 00:10:48,466 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8507805927233263, 'Total loss': 0.8507805927233263} | train loss {'Reaction outcome loss': 0.8070138685557307, 'Total loss': 0.8070138685557307}
2022-11-23 00:10:48,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:48,466 INFO:     Epoch: 71
2022-11-23 00:10:49,265 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8060977712950923, 'Total loss': 0.8060977712950923} | train loss {'Reaction outcome loss': 0.8062720279304348, 'Total loss': 0.8062720279304348}
2022-11-23 00:10:49,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:49,266 INFO:     Epoch: 72
2022-11-23 00:10:50,065 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7952671172943983, 'Total loss': 0.7952671172943983} | train loss {'Reaction outcome loss': 0.8050976377360675, 'Total loss': 0.8050976377360675}
2022-11-23 00:10:50,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:50,065 INFO:     Epoch: 73
2022-11-23 00:10:50,872 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8024452762170271, 'Total loss': 0.8024452762170271} | train loss {'Reaction outcome loss': 0.8053679434620604, 'Total loss': 0.8053679434620604}
2022-11-23 00:10:50,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:50,872 INFO:     Epoch: 74
2022-11-23 00:10:51,682 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8152240541848269, 'Total loss': 0.8152240541848269} | train loss {'Reaction outcome loss': 0.8018742336302388, 'Total loss': 0.8018742336302388}
2022-11-23 00:10:51,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:51,682 INFO:     Epoch: 75
2022-11-23 00:10:52,483 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8111573525450446, 'Total loss': 0.8111573525450446} | train loss {'Reaction outcome loss': 0.8064858786913813, 'Total loss': 0.8064858786913813}
2022-11-23 00:10:52,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:52,484 INFO:     Epoch: 76
2022-11-23 00:10:53,256 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8269317868081006, 'Total loss': 0.8269317868081006} | train loss {'Reaction outcome loss': 0.8068342172369665, 'Total loss': 0.8068342172369665}
2022-11-23 00:10:53,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:53,256 INFO:     Epoch: 77
2022-11-23 00:10:54,093 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.803504541516304, 'Total loss': 0.803504541516304} | train loss {'Reaction outcome loss': 0.8109195369846967, 'Total loss': 0.8109195369846967}
2022-11-23 00:10:54,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:54,094 INFO:     Epoch: 78
2022-11-23 00:10:54,886 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8189832690087232, 'Total loss': 0.8189832690087232} | train loss {'Reaction outcome loss': 0.8043118273725315, 'Total loss': 0.8043118273725315}
2022-11-23 00:10:54,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:54,886 INFO:     Epoch: 79
2022-11-23 00:10:55,703 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.792221737517552, 'Total loss': 0.792221737517552} | train loss {'Reaction outcome loss': 0.8047614242349352, 'Total loss': 0.8047614242349352}
2022-11-23 00:10:55,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:55,703 INFO:     Epoch: 80
2022-11-23 00:10:56,485 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8243091079321775, 'Total loss': 0.8243091079321775} | train loss {'Reaction outcome loss': 0.8036007797231479, 'Total loss': 0.8036007797231479}
2022-11-23 00:10:56,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:56,486 INFO:     Epoch: 81
2022-11-23 00:10:57,317 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8148060725493864, 'Total loss': 0.8148060725493864} | train loss {'Reaction outcome loss': 0.8076588912886016, 'Total loss': 0.8076588912886016}
2022-11-23 00:10:57,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:57,318 INFO:     Epoch: 82
2022-11-23 00:10:58,131 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7963606254620985, 'Total loss': 0.7963606254620985} | train loss {'Reaction outcome loss': 0.8022441975924434, 'Total loss': 0.8022441975924434}
2022-11-23 00:10:58,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:58,131 INFO:     Epoch: 83
2022-11-23 00:10:58,934 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8006025932051919, 'Total loss': 0.8006025932051919} | train loss {'Reaction outcome loss': 0.8071280115112967, 'Total loss': 0.8071280115112967}
2022-11-23 00:10:58,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:58,934 INFO:     Epoch: 84
2022-11-23 00:10:59,789 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8047720268368721, 'Total loss': 0.8047720268368721} | train loss {'Reaction outcome loss': 0.8051653071325653, 'Total loss': 0.8051653071325653}
2022-11-23 00:10:59,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:10:59,790 INFO:     Epoch: 85
2022-11-23 00:11:00,570 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7908366214145314, 'Total loss': 0.7908366214145314} | train loss {'Reaction outcome loss': 0.8099641168604091, 'Total loss': 0.8099641168604091}
2022-11-23 00:11:00,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:00,570 INFO:     Epoch: 86
2022-11-23 00:11:01,409 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.828406962481412, 'Total loss': 0.828406962481412} | train loss {'Reaction outcome loss': 0.8082222561446988, 'Total loss': 0.8082222561446988}
2022-11-23 00:11:01,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:01,409 INFO:     Epoch: 87
2022-11-23 00:11:02,237 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7965098395943642, 'Total loss': 0.7965098395943642} | train loss {'Reaction outcome loss': 0.8097595590717939, 'Total loss': 0.8097595590717939}
2022-11-23 00:11:02,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:02,237 INFO:     Epoch: 88
2022-11-23 00:11:03,053 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.791600143367594, 'Total loss': 0.791600143367594} | train loss {'Reaction outcome loss': 0.8087454878554052, 'Total loss': 0.8087454878554052}
2022-11-23 00:11:03,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:03,054 INFO:     Epoch: 89
2022-11-23 00:11:03,919 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7888587726788088, 'Total loss': 0.7888587726788088} | train loss {'Reaction outcome loss': 0.8061797770918632, 'Total loss': 0.8061797770918632}
2022-11-23 00:11:03,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:03,919 INFO:     Epoch: 90
2022-11-23 00:11:04,753 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8245940161022273, 'Total loss': 0.8245940161022273} | train loss {'Reaction outcome loss': 0.8053939782843298, 'Total loss': 0.8053939782843298}
2022-11-23 00:11:04,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:04,753 INFO:     Epoch: 91
2022-11-23 00:11:05,628 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8234958066181703, 'Total loss': 0.8234958066181703} | train loss {'Reaction outcome loss': 0.8065693400344071, 'Total loss': 0.8065693400344071}
2022-11-23 00:11:05,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:05,628 INFO:     Epoch: 92
2022-11-23 00:11:06,462 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8113970512693579, 'Total loss': 0.8113970512693579} | train loss {'Reaction outcome loss': 0.8078306465732809, 'Total loss': 0.8078306465732809}
2022-11-23 00:11:06,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:06,462 INFO:     Epoch: 93
2022-11-23 00:11:07,284 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8020779036662795, 'Total loss': 0.8020779036662795} | train loss {'Reaction outcome loss': 0.8098446827761981, 'Total loss': 0.8098446827761981}
2022-11-23 00:11:07,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:07,285 INFO:     Epoch: 94
2022-11-23 00:11:08,078 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8136878250674768, 'Total loss': 0.8136878250674768} | train loss {'Reaction outcome loss': 0.8097597123408804, 'Total loss': 0.8097597123408804}
2022-11-23 00:11:08,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:08,078 INFO:     Epoch: 95
2022-11-23 00:11:08,880 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8168487128886309, 'Total loss': 0.8168487128886309} | train loss {'Reaction outcome loss': 0.803266267873803, 'Total loss': 0.803266267873803}
2022-11-23 00:11:08,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:08,881 INFO:     Epoch: 96
2022-11-23 00:11:09,662 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8082172552292998, 'Total loss': 0.8082172552292998} | train loss {'Reaction outcome loss': 0.8037100888028437, 'Total loss': 0.8037100888028437}
2022-11-23 00:11:09,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:09,663 INFO:     Epoch: 97
2022-11-23 00:11:10,478 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8158192268826745, 'Total loss': 0.8158192268826745} | train loss {'Reaction outcome loss': 0.8064902295871657, 'Total loss': 0.8064902295871657}
2022-11-23 00:11:10,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:10,478 INFO:     Epoch: 98
2022-11-23 00:11:11,275 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8275812593373385, 'Total loss': 0.8275812593373385} | train loss {'Reaction outcome loss': 0.8094005298857786, 'Total loss': 0.8094005298857786}
2022-11-23 00:11:11,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:11,276 INFO:     Epoch: 99
2022-11-23 00:11:12,062 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8016897345131094, 'Total loss': 0.8016897345131094} | train loss {'Reaction outcome loss': 0.8033755709930342, 'Total loss': 0.8033755709930342}
2022-11-23 00:11:12,064 INFO:     Best model found after epoch 20 of 100.
2022-11-23 00:11:12,064 INFO:   Done with stage: TRAINING
2022-11-23 00:11:12,064 INFO:   Starting stage: EVALUATION
2022-11-23 00:11:12,195 INFO:   Done with stage: EVALUATION
2022-11-23 00:11:12,195 INFO:   Leaving out SEQ value Fold_4
2022-11-23 00:11:12,209 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:11:12,209 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:11:12,881 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:11:12,881 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:11:12,950 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:11:12,950 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:11:12,950 INFO:     No hyperparam tuning for this model
2022-11-23 00:11:12,950 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:11:12,950 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:11:12,951 INFO:     None feature selector for col prot
2022-11-23 00:11:12,951 INFO:     None feature selector for col prot
2022-11-23 00:11:12,951 INFO:     None feature selector for col prot
2022-11-23 00:11:12,952 INFO:     None feature selector for col chem
2022-11-23 00:11:12,952 INFO:     None feature selector for col chem
2022-11-23 00:11:12,952 INFO:     None feature selector for col chem
2022-11-23 00:11:12,952 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:11:12,952 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:11:12,954 INFO:     Number of params in model 168571
2022-11-23 00:11:12,957 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:11:12,957 INFO:   Starting stage: TRAINING
2022-11-23 00:11:13,015 INFO:     Val loss before train {'Reaction outcome loss': 0.9766110899773511, 'Total loss': 0.9766110899773511}
2022-11-23 00:11:13,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:13,015 INFO:     Epoch: 0
2022-11-23 00:11:13,804 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8716944117437709, 'Total loss': 0.8716944117437709} | train loss {'Reaction outcome loss': 0.8882191059319114, 'Total loss': 0.8882191059319114}
2022-11-23 00:11:13,805 INFO:     Found new best model at epoch 0
2022-11-23 00:11:13,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:13,805 INFO:     Epoch: 1
2022-11-23 00:11:14,583 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8259430378675461, 'Total loss': 0.8259430378675461} | train loss {'Reaction outcome loss': 0.8649564631554761, 'Total loss': 0.8649564631554761}
2022-11-23 00:11:14,583 INFO:     Found new best model at epoch 1
2022-11-23 00:11:14,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:14,584 INFO:     Epoch: 2
2022-11-23 00:11:15,365 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8368539085442369, 'Total loss': 0.8368539085442369} | train loss {'Reaction outcome loss': 0.8506526971152919, 'Total loss': 0.8506526971152919}
2022-11-23 00:11:15,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:15,365 INFO:     Epoch: 3
2022-11-23 00:11:16,156 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8246135230768811, 'Total loss': 0.8246135230768811} | train loss {'Reaction outcome loss': 0.8455933778874787, 'Total loss': 0.8455933778874787}
2022-11-23 00:11:16,156 INFO:     Found new best model at epoch 3
2022-11-23 00:11:16,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:16,157 INFO:     Epoch: 4
2022-11-23 00:11:16,924 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8102166347882964, 'Total loss': 0.8102166347882964} | train loss {'Reaction outcome loss': 0.8405343578894612, 'Total loss': 0.8405343578894612}
2022-11-23 00:11:16,925 INFO:     Found new best model at epoch 4
2022-11-23 00:11:16,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:16,926 INFO:     Epoch: 5
2022-11-23 00:11:17,704 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8227890716357664, 'Total loss': 0.8227890716357664} | train loss {'Reaction outcome loss': 0.8448127292187108, 'Total loss': 0.8448127292187108}
2022-11-23 00:11:17,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:17,704 INFO:     Epoch: 6
2022-11-23 00:11:18,499 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8317373875867237, 'Total loss': 0.8317373875867237} | train loss {'Reaction outcome loss': 0.8372997646992989, 'Total loss': 0.8372997646992989}
2022-11-23 00:11:18,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:18,500 INFO:     Epoch: 7
2022-11-23 00:11:19,276 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.802814897488464, 'Total loss': 0.802814897488464} | train loss {'Reaction outcome loss': 0.8326691309450126, 'Total loss': 0.8326691309450126}
2022-11-23 00:11:19,276 INFO:     Found new best model at epoch 7
2022-11-23 00:11:19,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:19,277 INFO:     Epoch: 8
2022-11-23 00:11:20,065 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8089706775817004, 'Total loss': 0.8089706775817004} | train loss {'Reaction outcome loss': 0.838216083237396, 'Total loss': 0.838216083237396}
2022-11-23 00:11:20,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:20,066 INFO:     Epoch: 9
2022-11-23 00:11:20,831 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8209565755995837, 'Total loss': 0.8209565755995837} | train loss {'Reaction outcome loss': 0.8268482788854282, 'Total loss': 0.8268482788854282}
2022-11-23 00:11:20,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:20,831 INFO:     Epoch: 10
2022-11-23 00:11:21,595 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8104708038947799, 'Total loss': 0.8104708038947799} | train loss {'Reaction outcome loss': 0.8303860987004964, 'Total loss': 0.8303860987004964}
2022-11-23 00:11:21,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:21,596 INFO:     Epoch: 11
2022-11-23 00:11:22,384 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.806214418600906, 'Total loss': 0.806214418600906} | train loss {'Reaction outcome loss': 0.8200280249028312, 'Total loss': 0.8200280249028312}
2022-11-23 00:11:22,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:22,385 INFO:     Epoch: 12
2022-11-23 00:11:23,176 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8100713863968849, 'Total loss': 0.8100713863968849} | train loss {'Reaction outcome loss': 0.8219569875040518, 'Total loss': 0.8219569875040518}
2022-11-23 00:11:23,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:23,176 INFO:     Epoch: 13
2022-11-23 00:11:23,944 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8150727626952258, 'Total loss': 0.8150727626952258} | train loss {'Reaction outcome loss': 0.8265789528245385, 'Total loss': 0.8265789528245385}
2022-11-23 00:11:23,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:23,945 INFO:     Epoch: 14
2022-11-23 00:11:24,732 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8169348084113814, 'Total loss': 0.8169348084113814} | train loss {'Reaction outcome loss': 0.8296975692515431, 'Total loss': 0.8296975692515431}
2022-11-23 00:11:24,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:24,732 INFO:     Epoch: 15
2022-11-23 00:11:25,526 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8214205666021868, 'Total loss': 0.8214205666021868} | train loss {'Reaction outcome loss': 0.831219808292775, 'Total loss': 0.831219808292775}
2022-11-23 00:11:25,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:25,526 INFO:     Epoch: 16
2022-11-23 00:11:26,343 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8082962469621138, 'Total loss': 0.8082962469621138} | train loss {'Reaction outcome loss': 0.8296759537598382, 'Total loss': 0.8296759537598382}
2022-11-23 00:11:26,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:26,343 INFO:     Epoch: 17
2022-11-23 00:11:27,125 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8085394738750025, 'Total loss': 0.8085394738750025} | train loss {'Reaction outcome loss': 0.824102978474698, 'Total loss': 0.824102978474698}
2022-11-23 00:11:27,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:27,126 INFO:     Epoch: 18
2022-11-23 00:11:27,910 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8132583702152426, 'Total loss': 0.8132583702152426} | train loss {'Reaction outcome loss': 0.8255355467921809, 'Total loss': 0.8255355467921809}
2022-11-23 00:11:27,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:27,910 INFO:     Epoch: 19
2022-11-23 00:11:28,704 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7979385131462053, 'Total loss': 0.7979385131462053} | train loss {'Reaction outcome loss': 0.8216417481300802, 'Total loss': 0.8216417481300802}
2022-11-23 00:11:28,704 INFO:     Found new best model at epoch 19
2022-11-23 00:11:28,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:28,705 INFO:     Epoch: 20
2022-11-23 00:11:29,476 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.825933535667983, 'Total loss': 0.825933535667983} | train loss {'Reaction outcome loss': 0.8250865439171733, 'Total loss': 0.8250865439171733}
2022-11-23 00:11:29,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:29,476 INFO:     Epoch: 21
2022-11-23 00:11:30,311 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8070792935111306, 'Total loss': 0.8070792935111306} | train loss {'Reaction outcome loss': 0.820908496375026, 'Total loss': 0.820908496375026}
2022-11-23 00:11:30,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:30,311 INFO:     Epoch: 22
2022-11-23 00:11:31,122 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8235514170744203, 'Total loss': 0.8235514170744203} | train loss {'Reaction outcome loss': 0.8262182166460554, 'Total loss': 0.8262182166460554}
2022-11-23 00:11:31,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:31,123 INFO:     Epoch: 23
2022-11-23 00:11:31,921 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7943778275088831, 'Total loss': 0.7943778275088831} | train loss {'Reaction outcome loss': 0.8215542179249559, 'Total loss': 0.8215542179249559}
2022-11-23 00:11:31,921 INFO:     Found new best model at epoch 23
2022-11-23 00:11:31,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:31,922 INFO:     Epoch: 24
2022-11-23 00:11:32,753 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8015538372776725, 'Total loss': 0.8015538372776725} | train loss {'Reaction outcome loss': 0.8241974935840498, 'Total loss': 0.8241974935840498}
2022-11-23 00:11:32,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:32,754 INFO:     Epoch: 25
2022-11-23 00:11:33,538 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8054303350773725, 'Total loss': 0.8054303350773725} | train loss {'Reaction outcome loss': 0.8248899863799092, 'Total loss': 0.8248899863799092}
2022-11-23 00:11:33,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:33,538 INFO:     Epoch: 26
2022-11-23 00:11:34,363 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8082671097733758, 'Total loss': 0.8082671097733758} | train loss {'Reaction outcome loss': 0.8229046899538773, 'Total loss': 0.8229046899538773}
2022-11-23 00:11:34,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:34,363 INFO:     Epoch: 27
2022-11-23 00:11:35,204 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8240682089870627, 'Total loss': 0.8240682089870627} | train loss {'Reaction outcome loss': 0.8210008683414595, 'Total loss': 0.8210008683414595}
2022-11-23 00:11:35,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:35,204 INFO:     Epoch: 28
2022-11-23 00:11:36,003 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8071696961467917, 'Total loss': 0.8071696961467917} | train loss {'Reaction outcome loss': 0.820218289067388, 'Total loss': 0.820218289067388}
2022-11-23 00:11:36,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:36,003 INFO:     Epoch: 29
2022-11-23 00:11:36,809 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8031260459260507, 'Total loss': 0.8031260459260507} | train loss {'Reaction outcome loss': 0.8263498128425737, 'Total loss': 0.8263498128425737}
2022-11-23 00:11:36,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:36,809 INFO:     Epoch: 30
2022-11-23 00:11:37,617 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8234660273248499, 'Total loss': 0.8234660273248499} | train loss {'Reaction outcome loss': 0.8358055857511667, 'Total loss': 0.8358055857511667}
2022-11-23 00:11:37,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:37,617 INFO:     Epoch: 31
2022-11-23 00:11:38,466 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7963483888994564, 'Total loss': 0.7963483888994564} | train loss {'Reaction outcome loss': 0.8319320973114446, 'Total loss': 0.8319320973114446}
2022-11-23 00:11:38,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:38,466 INFO:     Epoch: 32
2022-11-23 00:11:39,285 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8099507228894667, 'Total loss': 0.8099507228894667} | train loss {'Reaction outcome loss': 0.8287816641301762, 'Total loss': 0.8287816641301762}
2022-11-23 00:11:39,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:39,285 INFO:     Epoch: 33
2022-11-23 00:11:40,091 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.805219638754021, 'Total loss': 0.805219638754021} | train loss {'Reaction outcome loss': 0.8240870481077959, 'Total loss': 0.8240870481077959}
2022-11-23 00:11:40,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:40,091 INFO:     Epoch: 34
2022-11-23 00:11:40,925 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8199753375215963, 'Total loss': 0.8199753375215963} | train loss {'Reaction outcome loss': 0.8216024646874864, 'Total loss': 0.8216024646874864}
2022-11-23 00:11:40,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:40,925 INFO:     Epoch: 35
2022-11-23 00:11:41,747 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7974058701233431, 'Total loss': 0.7974058701233431} | train loss {'Reaction outcome loss': 0.8268005985480088, 'Total loss': 0.8268005985480088}
2022-11-23 00:11:41,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:41,747 INFO:     Epoch: 36
2022-11-23 00:11:42,515 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.79308713295243, 'Total loss': 0.79308713295243} | train loss {'Reaction outcome loss': 0.8223659086082629, 'Total loss': 0.8223659086082629}
2022-11-23 00:11:42,515 INFO:     Found new best model at epoch 36
2022-11-23 00:11:42,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:42,516 INFO:     Epoch: 37
2022-11-23 00:11:43,329 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8048094849694859, 'Total loss': 0.8048094849694859} | train loss {'Reaction outcome loss': 0.8213245600823932, 'Total loss': 0.8213245600823932}
2022-11-23 00:11:43,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:43,330 INFO:     Epoch: 38
2022-11-23 00:11:44,153 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7934664989059622, 'Total loss': 0.7934664989059622} | train loss {'Reaction outcome loss': 0.8287999391073158, 'Total loss': 0.8287999391073158}
2022-11-23 00:11:44,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:44,153 INFO:     Epoch: 39
2022-11-23 00:11:44,970 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.798308780247515, 'Total loss': 0.798308780247515} | train loss {'Reaction outcome loss': 0.8235486436951981, 'Total loss': 0.8235486436951981}
2022-11-23 00:11:44,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:44,970 INFO:     Epoch: 40
2022-11-23 00:11:45,775 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7993830503387884, 'Total loss': 0.7993830503387884} | train loss {'Reaction outcome loss': 0.8247861013962672, 'Total loss': 0.8247861013962672}
2022-11-23 00:11:45,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:45,775 INFO:     Epoch: 41
2022-11-23 00:11:46,540 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.804843931035562, 'Total loss': 0.804843931035562} | train loss {'Reaction outcome loss': 0.820234297499483, 'Total loss': 0.820234297499483}
2022-11-23 00:11:46,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:46,540 INFO:     Epoch: 42
2022-11-23 00:11:47,322 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.835363472727212, 'Total loss': 0.835363472727212} | train loss {'Reaction outcome loss': 0.8221244948354327, 'Total loss': 0.8221244948354327}
2022-11-23 00:11:47,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:47,322 INFO:     Epoch: 43
2022-11-23 00:11:48,119 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8155886063521559, 'Total loss': 0.8155886063521559} | train loss {'Reaction outcome loss': 0.8141062852553269, 'Total loss': 0.8141062852553269}
2022-11-23 00:11:48,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:48,119 INFO:     Epoch: 44
2022-11-23 00:11:48,934 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8031289604577151, 'Total loss': 0.8031289604577151} | train loss {'Reaction outcome loss': 0.8288268573612336, 'Total loss': 0.8288268573612336}
2022-11-23 00:11:48,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:48,934 INFO:     Epoch: 45
2022-11-23 00:11:49,745 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8209969997406006, 'Total loss': 0.8209969997406006} | train loss {'Reaction outcome loss': 0.8211575719991676, 'Total loss': 0.8211575719991676}
2022-11-23 00:11:49,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:49,746 INFO:     Epoch: 46
2022-11-23 00:11:50,514 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8114236559380185, 'Total loss': 0.8114236559380185} | train loss {'Reaction outcome loss': 0.8197452275135256, 'Total loss': 0.8197452275135256}
2022-11-23 00:11:50,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:50,514 INFO:     Epoch: 47
2022-11-23 00:11:51,274 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7919175523248586, 'Total loss': 0.7919175523248586} | train loss {'Reaction outcome loss': 0.8255598148112355, 'Total loss': 0.8255598148112355}
2022-11-23 00:11:51,275 INFO:     Found new best model at epoch 47
2022-11-23 00:11:51,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:51,276 INFO:     Epoch: 48
2022-11-23 00:11:52,051 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8173809803344987, 'Total loss': 0.8173809803344987} | train loss {'Reaction outcome loss': 0.8126499508073938, 'Total loss': 0.8126499508073938}
2022-11-23 00:11:52,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:52,051 INFO:     Epoch: 49
2022-11-23 00:11:52,829 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8220796551216732, 'Total loss': 0.8220796551216732} | train loss {'Reaction outcome loss': 0.816666646404305, 'Total loss': 0.816666646404305}
2022-11-23 00:11:52,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:52,830 INFO:     Epoch: 50
2022-11-23 00:11:53,624 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7955889728936282, 'Total loss': 0.7955889728936282} | train loss {'Reaction outcome loss': 0.8181728297158292, 'Total loss': 0.8181728297158292}
2022-11-23 00:11:53,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:53,625 INFO:     Epoch: 51
2022-11-23 00:11:54,409 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8041583435101942, 'Total loss': 0.8041583435101942} | train loss {'Reaction outcome loss': 0.8186196103571397, 'Total loss': 0.8186196103571397}
2022-11-23 00:11:54,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:54,410 INFO:     Epoch: 52
2022-11-23 00:11:55,240 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7982019497589632, 'Total loss': 0.7982019497589632} | train loss {'Reaction outcome loss': 0.8192281416553234, 'Total loss': 0.8192281416553234}
2022-11-23 00:11:55,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:55,240 INFO:     Epoch: 53
2022-11-23 00:11:56,052 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7856008606878194, 'Total loss': 0.7856008606878194} | train loss {'Reaction outcome loss': 0.8206692633599888, 'Total loss': 0.8206692633599888}
2022-11-23 00:11:56,052 INFO:     Found new best model at epoch 53
2022-11-23 00:11:56,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:56,053 INFO:     Epoch: 54
2022-11-23 00:11:56,875 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8008367690173063, 'Total loss': 0.8008367690173063} | train loss {'Reaction outcome loss': 0.8181437101923985, 'Total loss': 0.8181437101923985}
2022-11-23 00:11:56,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:56,875 INFO:     Epoch: 55
2022-11-23 00:11:57,673 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8090601915662939, 'Total loss': 0.8090601915662939} | train loss {'Reaction outcome loss': 0.8298169752122903, 'Total loss': 0.8298169752122903}
2022-11-23 00:11:57,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:57,674 INFO:     Epoch: 56
2022-11-23 00:11:58,559 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8409464955329895, 'Total loss': 0.8409464955329895} | train loss {'Reaction outcome loss': 0.8224993250389331, 'Total loss': 0.8224993250389331}
2022-11-23 00:11:58,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:58,559 INFO:     Epoch: 57
2022-11-23 00:11:59,445 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8283491229469125, 'Total loss': 0.8283491229469125} | train loss {'Reaction outcome loss': 0.8416852172811021, 'Total loss': 0.8416852172811021}
2022-11-23 00:11:59,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:11:59,445 INFO:     Epoch: 58
2022-11-23 00:12:00,370 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7849179729819298, 'Total loss': 0.7849179729819298} | train loss {'Reaction outcome loss': 0.8223959480823293, 'Total loss': 0.8223959480823293}
2022-11-23 00:12:00,370 INFO:     Found new best model at epoch 58
2022-11-23 00:12:00,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:00,371 INFO:     Epoch: 59
2022-11-23 00:12:01,229 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.789415528151122, 'Total loss': 0.789415528151122} | train loss {'Reaction outcome loss': 0.8161028347276, 'Total loss': 0.8161028347276}
2022-11-23 00:12:01,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:01,229 INFO:     Epoch: 60
2022-11-23 00:12:02,114 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8314460651441054, 'Total loss': 0.8314460651441054} | train loss {'Reaction outcome loss': 0.8228514365821715, 'Total loss': 0.8228514365821715}
2022-11-23 00:12:02,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:02,116 INFO:     Epoch: 61
2022-11-23 00:12:02,932 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.799193070016124, 'Total loss': 0.799193070016124} | train loss {'Reaction outcome loss': 0.8219723052341446, 'Total loss': 0.8219723052341446}
2022-11-23 00:12:02,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:02,932 INFO:     Epoch: 62
2022-11-23 00:12:03,806 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7831809127872641, 'Total loss': 0.7831809127872641} | train loss {'Reaction outcome loss': 0.821998392039465, 'Total loss': 0.821998392039465}
2022-11-23 00:12:03,806 INFO:     Found new best model at epoch 62
2022-11-23 00:12:03,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:03,807 INFO:     Epoch: 63
2022-11-23 00:12:04,733 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7947891212322495, 'Total loss': 0.7947891212322495} | train loss {'Reaction outcome loss': 0.8201314865456901, 'Total loss': 0.8201314865456901}
2022-11-23 00:12:04,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:04,733 INFO:     Epoch: 64
2022-11-23 00:12:05,683 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8024630634622141, 'Total loss': 0.8024630634622141} | train loss {'Reaction outcome loss': 0.816791023832825, 'Total loss': 0.816791023832825}
2022-11-23 00:12:05,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:05,684 INFO:     Epoch: 65
2022-11-23 00:12:06,594 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7851085087115114, 'Total loss': 0.7851085087115114} | train loss {'Reaction outcome loss': 0.8215637840481422, 'Total loss': 0.8215637840481422}
2022-11-23 00:12:06,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:06,595 INFO:     Epoch: 66
2022-11-23 00:12:07,480 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8035514761101116, 'Total loss': 0.8035514761101116} | train loss {'Reaction outcome loss': 0.819229442942963, 'Total loss': 0.819229442942963}
2022-11-23 00:12:07,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:07,480 INFO:     Epoch: 67
2022-11-23 00:12:08,377 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7942175756801259, 'Total loss': 0.7942175756801259} | train loss {'Reaction outcome loss': 0.8222263868038471, 'Total loss': 0.8222263868038471}
2022-11-23 00:12:08,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:08,377 INFO:     Epoch: 68
2022-11-23 00:12:09,291 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8020155504345894, 'Total loss': 0.8020155504345894} | train loss {'Reaction outcome loss': 0.8166681655988037, 'Total loss': 0.8166681655988037}
2022-11-23 00:12:09,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:09,291 INFO:     Epoch: 69
2022-11-23 00:12:10,170 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8115512092005123, 'Total loss': 0.8115512092005123} | train loss {'Reaction outcome loss': 0.821477261873392, 'Total loss': 0.821477261873392}
2022-11-23 00:12:10,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:10,171 INFO:     Epoch: 70
2022-11-23 00:12:11,050 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7985361143946648, 'Total loss': 0.7985361143946648} | train loss {'Reaction outcome loss': 0.8253256175440815, 'Total loss': 0.8253256175440815}
2022-11-23 00:12:11,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:11,050 INFO:     Epoch: 71
2022-11-23 00:12:11,964 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7993980646133423, 'Total loss': 0.7993980646133423} | train loss {'Reaction outcome loss': 0.8200921773277072, 'Total loss': 0.8200921773277072}
2022-11-23 00:12:11,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:11,964 INFO:     Epoch: 72
2022-11-23 00:12:12,898 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8059966652230783, 'Total loss': 0.8059966652230783} | train loss {'Reaction outcome loss': 0.8297518936969973, 'Total loss': 0.8297518936969973}
2022-11-23 00:12:12,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:12,899 INFO:     Epoch: 73
2022-11-23 00:12:13,817 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7836583751169118, 'Total loss': 0.7836583751169118} | train loss {'Reaction outcome loss': 0.8217396474318949, 'Total loss': 0.8217396474318949}
2022-11-23 00:12:13,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:13,818 INFO:     Epoch: 74
2022-11-23 00:12:14,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7990949214859442, 'Total loss': 0.7990949214859442} | train loss {'Reaction outcome loss': 0.8181760385934158, 'Total loss': 0.8181760385934158}
2022-11-23 00:12:14,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:14,717 INFO:     Epoch: 75
2022-11-23 00:12:15,571 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8169039399786429, 'Total loss': 0.8169039399786429} | train loss {'Reaction outcome loss': 0.8150724078479566, 'Total loss': 0.8150724078479566}
2022-11-23 00:12:15,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:15,571 INFO:     Epoch: 76
2022-11-23 00:12:16,453 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8009809783913873, 'Total loss': 0.8009809783913873} | train loss {'Reaction outcome loss': 0.8192773727994216, 'Total loss': 0.8192773727994216}
2022-11-23 00:12:16,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:16,453 INFO:     Epoch: 77
2022-11-23 00:12:17,278 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7882752804593607, 'Total loss': 0.7882752804593607} | train loss {'Reaction outcome loss': 0.823335331913672, 'Total loss': 0.823335331913672}
2022-11-23 00:12:17,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:17,279 INFO:     Epoch: 78
2022-11-23 00:12:18,176 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.813495390794494, 'Total loss': 0.813495390794494} | train loss {'Reaction outcome loss': 0.8162728250026703, 'Total loss': 0.8162728250026703}
2022-11-23 00:12:18,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:18,176 INFO:     Epoch: 79
2022-11-23 00:12:19,121 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.784351493824612, 'Total loss': 0.784351493824612} | train loss {'Reaction outcome loss': 0.8223138038928692, 'Total loss': 0.8223138038928692}
2022-11-23 00:12:19,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:19,121 INFO:     Epoch: 80
2022-11-23 00:12:20,076 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7898845252665606, 'Total loss': 0.7898845252665606} | train loss {'Reaction outcome loss': 0.8168597319408467, 'Total loss': 0.8168597319408467}
2022-11-23 00:12:20,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:20,076 INFO:     Epoch: 81
2022-11-23 00:12:20,972 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8085395070639524, 'Total loss': 0.8085395070639524} | train loss {'Reaction outcome loss': 0.8160234904180654, 'Total loss': 0.8160234904180654}
2022-11-23 00:12:20,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:20,973 INFO:     Epoch: 82
2022-11-23 00:12:21,862 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8025300753387538, 'Total loss': 0.8025300753387538} | train loss {'Reaction outcome loss': 0.8169726476012936, 'Total loss': 0.8169726476012936}
2022-11-23 00:12:21,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:21,862 INFO:     Epoch: 83
2022-11-23 00:12:22,746 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7925585548986088, 'Total loss': 0.7925585548986088} | train loss {'Reaction outcome loss': 0.8158009297210678, 'Total loss': 0.8158009297210678}
2022-11-23 00:12:22,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:22,747 INFO:     Epoch: 84
2022-11-23 00:12:23,598 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7885017611763694, 'Total loss': 0.7885017611763694} | train loss {'Reaction outcome loss': 0.8144900568342401, 'Total loss': 0.8144900568342401}
2022-11-23 00:12:23,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:23,598 INFO:     Epoch: 85
2022-11-23 00:12:24,468 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7873659377748315, 'Total loss': 0.7873659377748315} | train loss {'Reaction outcome loss': 0.8145156279809562, 'Total loss': 0.8145156279809562}
2022-11-23 00:12:24,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:24,469 INFO:     Epoch: 86
2022-11-23 00:12:25,307 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7834329733794386, 'Total loss': 0.7834329733794386} | train loss {'Reaction outcome loss': 0.8166412186888066, 'Total loss': 0.8166412186888066}
2022-11-23 00:12:25,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:25,307 INFO:     Epoch: 87
2022-11-23 00:12:26,241 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7871895249594342, 'Total loss': 0.7871895249594342} | train loss {'Reaction outcome loss': 0.8196283695910141, 'Total loss': 0.8196283695910141}
2022-11-23 00:12:26,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:26,241 INFO:     Epoch: 88
2022-11-23 00:12:27,109 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7988890003074299, 'Total loss': 0.7988890003074299} | train loss {'Reaction outcome loss': 0.8173980222720849, 'Total loss': 0.8173980222720849}
2022-11-23 00:12:27,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:27,109 INFO:     Epoch: 89
2022-11-23 00:12:27,981 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8120167499238794, 'Total loss': 0.8120167499238794} | train loss {'Reaction outcome loss': 0.8159946358879568, 'Total loss': 0.8159946358879568}
2022-11-23 00:12:27,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:27,982 INFO:     Epoch: 90
2022-11-23 00:12:28,862 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7786661007187583, 'Total loss': 0.7786661007187583} | train loss {'Reaction outcome loss': 0.8227013414687956, 'Total loss': 0.8227013414687956}
2022-11-23 00:12:28,863 INFO:     Found new best model at epoch 90
2022-11-23 00:12:28,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:28,864 INFO:     Epoch: 91
2022-11-23 00:12:29,743 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8166465623812242, 'Total loss': 0.8166465623812242} | train loss {'Reaction outcome loss': 0.8142800525373776, 'Total loss': 0.8142800525373776}
2022-11-23 00:12:29,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:29,744 INFO:     Epoch: 92
2022-11-23 00:12:30,639 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8072602356022055, 'Total loss': 0.8072602356022055} | train loss {'Reaction outcome loss': 0.8223985820888025, 'Total loss': 0.8223985820888025}
2022-11-23 00:12:30,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:30,639 INFO:     Epoch: 93
2022-11-23 00:12:31,517 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8008732653476975, 'Total loss': 0.8008732653476975} | train loss {'Reaction outcome loss': 0.8247157768440633, 'Total loss': 0.8247157768440633}
2022-11-23 00:12:31,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:31,518 INFO:     Epoch: 94
2022-11-23 00:12:32,373 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7958650324832309, 'Total loss': 0.7958650324832309} | train loss {'Reaction outcome loss': 0.8215603106900266, 'Total loss': 0.8215603106900266}
2022-11-23 00:12:32,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:32,374 INFO:     Epoch: 95
2022-11-23 00:12:33,255 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7941428571939468, 'Total loss': 0.7941428571939468} | train loss {'Reaction outcome loss': 0.8165336805301519, 'Total loss': 0.8165336805301519}
2022-11-23 00:12:33,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:33,256 INFO:     Epoch: 96
2022-11-23 00:12:34,136 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7961953512646935, 'Total loss': 0.7961953512646935} | train loss {'Reaction outcome loss': 0.816206154432374, 'Total loss': 0.816206154432374}
2022-11-23 00:12:34,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:34,137 INFO:     Epoch: 97
2022-11-23 00:12:35,027 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.808236953209747, 'Total loss': 0.808236953209747} | train loss {'Reaction outcome loss': 0.8177856579724594, 'Total loss': 0.8177856579724594}
2022-11-23 00:12:35,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:35,027 INFO:     Epoch: 98
2022-11-23 00:12:35,886 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.785002396187999, 'Total loss': 0.785002396187999} | train loss {'Reaction outcome loss': 0.8205158732198028, 'Total loss': 0.8205158732198028}
2022-11-23 00:12:35,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:35,886 INFO:     Epoch: 99
2022-11-23 00:12:36,806 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8026223561980508, 'Total loss': 0.8026223561980508} | train loss {'Reaction outcome loss': 0.8188477205602747, 'Total loss': 0.8188477205602747}
2022-11-23 00:12:36,807 INFO:     Best model found after epoch 91 of 100.
2022-11-23 00:12:36,807 INFO:   Done with stage: TRAINING
2022-11-23 00:12:36,807 INFO:   Starting stage: EVALUATION
2022-11-23 00:12:36,936 INFO:   Done with stage: EVALUATION
2022-11-23 00:12:36,936 INFO:   Leaving out SEQ value Fold_5
2022-11-23 00:12:36,950 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:12:36,950 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:12:37,634 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:12:37,635 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:12:37,707 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:12:37,707 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:12:37,707 INFO:     No hyperparam tuning for this model
2022-11-23 00:12:37,707 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:12:37,707 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:12:37,708 INFO:     None feature selector for col prot
2022-11-23 00:12:37,708 INFO:     None feature selector for col prot
2022-11-23 00:12:37,708 INFO:     None feature selector for col prot
2022-11-23 00:12:37,709 INFO:     None feature selector for col chem
2022-11-23 00:12:37,709 INFO:     None feature selector for col chem
2022-11-23 00:12:37,709 INFO:     None feature selector for col chem
2022-11-23 00:12:37,709 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:12:37,709 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:12:37,711 INFO:     Number of params in model 168571
2022-11-23 00:12:37,714 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:12:37,714 INFO:   Starting stage: TRAINING
2022-11-23 00:12:37,774 INFO:     Val loss before train {'Reaction outcome loss': 0.9778202948245135, 'Total loss': 0.9778202948245135}
2022-11-23 00:12:37,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:37,774 INFO:     Epoch: 0
2022-11-23 00:12:38,652 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8512888591397892, 'Total loss': 0.8512888591397892} | train loss {'Reaction outcome loss': 0.8795423219280858, 'Total loss': 0.8795423219280858}
2022-11-23 00:12:38,652 INFO:     Found new best model at epoch 0
2022-11-23 00:12:38,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:38,653 INFO:     Epoch: 1
2022-11-23 00:12:39,527 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8616584133018147, 'Total loss': 0.8616584133018147} | train loss {'Reaction outcome loss': 0.8560518081630429, 'Total loss': 0.8560518081630429}
2022-11-23 00:12:39,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:39,527 INFO:     Epoch: 2
2022-11-23 00:12:40,398 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.83242386511781, 'Total loss': 0.83242386511781} | train loss {'Reaction outcome loss': 0.8443584729346537, 'Total loss': 0.8443584729346537}
2022-11-23 00:12:40,398 INFO:     Found new best model at epoch 2
2022-11-23 00:12:40,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:40,399 INFO:     Epoch: 3
2022-11-23 00:12:41,256 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8359003663063049, 'Total loss': 0.8359003663063049} | train loss {'Reaction outcome loss': 0.8446525110592765, 'Total loss': 0.8446525110592765}
2022-11-23 00:12:41,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:41,257 INFO:     Epoch: 4
2022-11-23 00:12:42,110 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.832368016242981, 'Total loss': 0.832368016242981} | train loss {'Reaction outcome loss': 0.8402220479423, 'Total loss': 0.8402220479423}
2022-11-23 00:12:42,110 INFO:     Found new best model at epoch 4
2022-11-23 00:12:42,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:42,111 INFO:     Epoch: 5
2022-11-23 00:12:42,954 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8323202112858946, 'Total loss': 0.8323202112858946} | train loss {'Reaction outcome loss': 0.8300664917595925, 'Total loss': 0.8300664917595925}
2022-11-23 00:12:42,954 INFO:     Found new best model at epoch 5
2022-11-23 00:12:42,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:42,955 INFO:     Epoch: 6
2022-11-23 00:12:43,837 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.839281829920682, 'Total loss': 0.839281829920682} | train loss {'Reaction outcome loss': 0.8301953959368891, 'Total loss': 0.8301953959368891}
2022-11-23 00:12:43,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:43,837 INFO:     Epoch: 7
2022-11-23 00:12:44,736 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8202754367481578, 'Total loss': 0.8202754367481578} | train loss {'Reaction outcome loss': 0.824089270205267, 'Total loss': 0.824089270205267}
2022-11-23 00:12:44,736 INFO:     Found new best model at epoch 7
2022-11-23 00:12:44,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:44,737 INFO:     Epoch: 8
2022-11-23 00:12:45,537 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8391672359271483, 'Total loss': 0.8391672359271483} | train loss {'Reaction outcome loss': 0.8238647386672036, 'Total loss': 0.8238647386672036}
2022-11-23 00:12:45,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:45,539 INFO:     Epoch: 9
2022-11-23 00:12:46,355 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8393108052286234, 'Total loss': 0.8393108052286234} | train loss {'Reaction outcome loss': 0.8301026678133395, 'Total loss': 0.8301026678133395}
2022-11-23 00:12:46,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:46,355 INFO:     Epoch: 10
2022-11-23 00:12:47,169 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8283341012217782, 'Total loss': 0.8283341012217782} | train loss {'Reaction outcome loss': 0.8181683671690764, 'Total loss': 0.8181683671690764}
2022-11-23 00:12:47,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:47,169 INFO:     Epoch: 11
2022-11-23 00:12:47,957 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8235538209026511, 'Total loss': 0.8235538209026511} | train loss {'Reaction outcome loss': 0.8232484413010459, 'Total loss': 0.8232484413010459}
2022-11-23 00:12:47,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:47,957 INFO:     Epoch: 12
2022-11-23 00:12:48,780 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8416325307705186, 'Total loss': 0.8416325307705186} | train loss {'Reaction outcome loss': 0.8204248391332165, 'Total loss': 0.8204248391332165}
2022-11-23 00:12:48,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:48,780 INFO:     Epoch: 13
2022-11-23 00:12:49,607 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8265221918171103, 'Total loss': 0.8265221918171103} | train loss {'Reaction outcome loss': 0.8175413865716227, 'Total loss': 0.8175413865716227}
2022-11-23 00:12:49,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:49,607 INFO:     Epoch: 14
2022-11-23 00:12:50,422 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8158211999318816, 'Total loss': 0.8158211999318816} | train loss {'Reaction outcome loss': 0.8191180351761079, 'Total loss': 0.8191180351761079}
2022-11-23 00:12:50,423 INFO:     Found new best model at epoch 14
2022-11-23 00:12:50,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:50,424 INFO:     Epoch: 15
2022-11-23 00:12:51,276 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8324337892911651, 'Total loss': 0.8324337892911651} | train loss {'Reaction outcome loss': 0.8174684174479016, 'Total loss': 0.8174684174479016}
2022-11-23 00:12:51,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:51,276 INFO:     Epoch: 16
2022-11-23 00:12:52,115 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8342820087617094, 'Total loss': 0.8342820087617094} | train loss {'Reaction outcome loss': 0.8160364538911851, 'Total loss': 0.8160364538911851}
2022-11-23 00:12:52,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:52,116 INFO:     Epoch: 17
2022-11-23 00:12:52,932 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8171520842747255, 'Total loss': 0.8171520842747255} | train loss {'Reaction outcome loss': 0.8225792515422067, 'Total loss': 0.8225792515422067}
2022-11-23 00:12:52,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:52,932 INFO:     Epoch: 18
2022-11-23 00:12:53,745 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8114803216674111, 'Total loss': 0.8114803216674111} | train loss {'Reaction outcome loss': 0.8161138125484989, 'Total loss': 0.8161138125484989}
2022-11-23 00:12:53,745 INFO:     Found new best model at epoch 18
2022-11-23 00:12:53,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:53,746 INFO:     Epoch: 19
2022-11-23 00:12:54,544 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8242075822570107, 'Total loss': 0.8242075822570107} | train loss {'Reaction outcome loss': 0.8179398559995236, 'Total loss': 0.8179398559995236}
2022-11-23 00:12:54,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:54,545 INFO:     Epoch: 20
2022-11-23 00:12:55,356 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8201361799781973, 'Total loss': 0.8201361799781973} | train loss {'Reaction outcome loss': 0.8208401376201261, 'Total loss': 0.8208401376201261}
2022-11-23 00:12:55,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:55,356 INFO:     Epoch: 21
2022-11-23 00:12:56,182 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8161054355177012, 'Total loss': 0.8161054355177012} | train loss {'Reaction outcome loss': 0.8203599108082633, 'Total loss': 0.8203599108082633}
2022-11-23 00:12:56,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:56,182 INFO:     Epoch: 22
2022-11-23 00:12:57,019 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8163743039423769, 'Total loss': 0.8163743039423769} | train loss {'Reaction outcome loss': 0.8159230648269576, 'Total loss': 0.8159230648269576}
2022-11-23 00:12:57,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:57,019 INFO:     Epoch: 23
2022-11-23 00:12:57,895 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8180703432722525, 'Total loss': 0.8180703432722525} | train loss {'Reaction outcome loss': 0.8142558976767524, 'Total loss': 0.8142558976767524}
2022-11-23 00:12:57,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:57,896 INFO:     Epoch: 24
2022-11-23 00:12:58,724 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.83949349346486, 'Total loss': 0.83949349346486} | train loss {'Reaction outcome loss': 0.8145680815702484, 'Total loss': 0.8145680815702484}
2022-11-23 00:12:58,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:58,724 INFO:     Epoch: 25
2022-11-23 00:12:59,579 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8309258981184526, 'Total loss': 0.8309258981184526} | train loss {'Reaction outcome loss': 0.8172745191522183, 'Total loss': 0.8172745191522183}
2022-11-23 00:12:59,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:12:59,579 INFO:     Epoch: 26
2022-11-23 00:13:00,408 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8203850496898998, 'Total loss': 0.8203850496898998} | train loss {'Reaction outcome loss': 0.817508606901092, 'Total loss': 0.817508606901092}
2022-11-23 00:13:00,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:00,408 INFO:     Epoch: 27
2022-11-23 00:13:01,237 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8290198160843416, 'Total loss': 0.8290198160843416} | train loss {'Reaction outcome loss': 0.8175640893318961, 'Total loss': 0.8175640893318961}
2022-11-23 00:13:01,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:01,237 INFO:     Epoch: 28
2022-11-23 00:13:02,076 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8238993300632997, 'Total loss': 0.8238993300632997} | train loss {'Reaction outcome loss': 0.8197484410578205, 'Total loss': 0.8197484410578205}
2022-11-23 00:13:02,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:02,077 INFO:     Epoch: 29
2022-11-23 00:13:02,911 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8277394040064379, 'Total loss': 0.8277394040064379} | train loss {'Reaction outcome loss': 0.8161856509264438, 'Total loss': 0.8161856509264438}
2022-11-23 00:13:02,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:02,912 INFO:     Epoch: 30
2022-11-23 00:13:03,740 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.828146561302922, 'Total loss': 0.828146561302922} | train loss {'Reaction outcome loss': 0.8174851982583923, 'Total loss': 0.8174851982583923}
2022-11-23 00:13:03,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:03,741 INFO:     Epoch: 31
2022-11-23 00:13:04,544 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8146842101758177, 'Total loss': 0.8146842101758177} | train loss {'Reaction outcome loss': 0.8168417621524103, 'Total loss': 0.8168417621524103}
2022-11-23 00:13:04,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:04,545 INFO:     Epoch: 32
2022-11-23 00:13:05,397 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8169895695014433, 'Total loss': 0.8169895695014433} | train loss {'Reaction outcome loss': 0.811288881686426, 'Total loss': 0.811288881686426}
2022-11-23 00:13:05,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:05,397 INFO:     Epoch: 33
2022-11-23 00:13:06,254 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8138640692288225, 'Total loss': 0.8138640692288225} | train loss {'Reaction outcome loss': 0.8166248907725657, 'Total loss': 0.8166248907725657}
2022-11-23 00:13:06,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:06,255 INFO:     Epoch: 34
2022-11-23 00:13:07,100 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.813519565219229, 'Total loss': 0.813519565219229} | train loss {'Reaction outcome loss': 0.8181909301107929, 'Total loss': 0.8181909301107929}
2022-11-23 00:13:07,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:07,101 INFO:     Epoch: 35
2022-11-23 00:13:07,971 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8485917719927701, 'Total loss': 0.8485917719927701} | train loss {'Reaction outcome loss': 0.8169797333257813, 'Total loss': 0.8169797333257813}
2022-11-23 00:13:07,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:07,972 INFO:     Epoch: 36
2022-11-23 00:13:08,821 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8175085735591975, 'Total loss': 0.8175085735591975} | train loss {'Reaction outcome loss': 0.8153307562874209, 'Total loss': 0.8153307562874209}
2022-11-23 00:13:08,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:08,821 INFO:     Epoch: 37
2022-11-23 00:13:09,643 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8092884583906694, 'Total loss': 0.8092884583906694} | train loss {'Reaction outcome loss': 0.8193818094028581, 'Total loss': 0.8193818094028581}
2022-11-23 00:13:09,643 INFO:     Found new best model at epoch 37
2022-11-23 00:13:09,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:09,644 INFO:     Epoch: 38
2022-11-23 00:13:10,471 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.828917609019713, 'Total loss': 0.828917609019713} | train loss {'Reaction outcome loss': 0.8141701888413199, 'Total loss': 0.8141701888413199}
2022-11-23 00:13:10,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:10,471 INFO:     Epoch: 39
2022-11-23 00:13:11,306 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8309292007576335, 'Total loss': 0.8309292007576335} | train loss {'Reaction outcome loss': 0.8176182236882948, 'Total loss': 0.8176182236882948}
2022-11-23 00:13:11,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:11,306 INFO:     Epoch: 40
2022-11-23 00:13:12,101 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8259127600626512, 'Total loss': 0.8259127600626512} | train loss {'Reaction outcome loss': 0.8124248324142348, 'Total loss': 0.8124248324142348}
2022-11-23 00:13:12,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:12,101 INFO:     Epoch: 41
2022-11-23 00:13:12,923 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8100201440128413, 'Total loss': 0.8100201440128413} | train loss {'Reaction outcome loss': 0.8140391791539807, 'Total loss': 0.8140391791539807}
2022-11-23 00:13:12,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:12,923 INFO:     Epoch: 42
2022-11-23 00:13:13,750 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8171774541789835, 'Total loss': 0.8171774541789835} | train loss {'Reaction outcome loss': 0.8183726777713145, 'Total loss': 0.8183726777713145}
2022-11-23 00:13:13,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:13,750 INFO:     Epoch: 43
2022-11-23 00:13:14,529 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8211016912351955, 'Total loss': 0.8211016912351955} | train loss {'Reaction outcome loss': 0.8194053566023227, 'Total loss': 0.8194053566023227}
2022-11-23 00:13:14,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:14,530 INFO:     Epoch: 44
2022-11-23 00:13:15,321 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8246314505284483, 'Total loss': 0.8246314505284483} | train loss {'Reaction outcome loss': 0.8189579154695233, 'Total loss': 0.8189579154695233}
2022-11-23 00:13:15,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:15,321 INFO:     Epoch: 45
2022-11-23 00:13:16,101 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8180123743685809, 'Total loss': 0.8180123743685809} | train loss {'Reaction outcome loss': 0.815713121525703, 'Total loss': 0.815713121525703}
2022-11-23 00:13:16,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:16,102 INFO:     Epoch: 46
2022-11-23 00:13:16,858 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8121690323406999, 'Total loss': 0.8121690323406999} | train loss {'Reaction outcome loss': 0.8145808498224905, 'Total loss': 0.8145808498224905}
2022-11-23 00:13:16,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:16,858 INFO:     Epoch: 47
2022-11-23 00:13:17,659 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8250111917203123, 'Total loss': 0.8250111917203123} | train loss {'Reaction outcome loss': 0.8180028420061835, 'Total loss': 0.8180028420061835}
2022-11-23 00:13:17,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:17,659 INFO:     Epoch: 48
2022-11-23 00:13:18,439 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8122160990129818, 'Total loss': 0.8122160990129818} | train loss {'Reaction outcome loss': 0.8165048946055674, 'Total loss': 0.8165048946055674}
2022-11-23 00:13:18,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:18,439 INFO:     Epoch: 49
2022-11-23 00:13:19,238 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8091987120834264, 'Total loss': 0.8091987120834264} | train loss {'Reaction outcome loss': 0.8129377956952779, 'Total loss': 0.8129377956952779}
2022-11-23 00:13:19,238 INFO:     Found new best model at epoch 49
2022-11-23 00:13:19,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:19,239 INFO:     Epoch: 50
2022-11-23 00:13:20,001 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8178082094951109, 'Total loss': 0.8178082094951109} | train loss {'Reaction outcome loss': 0.8143475400584359, 'Total loss': 0.8143475400584359}
2022-11-23 00:13:20,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:20,001 INFO:     Epoch: 51
2022-11-23 00:13:20,758 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.832739076831124, 'Total loss': 0.832739076831124} | train loss {'Reaction outcome loss': 0.8156442023333041, 'Total loss': 0.8156442023333041}
2022-11-23 00:13:20,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:20,758 INFO:     Epoch: 52
2022-11-23 00:13:21,535 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8420728052204306, 'Total loss': 0.8420728052204306} | train loss {'Reaction outcome loss': 0.8180681906880871, 'Total loss': 0.8180681906880871}
2022-11-23 00:13:21,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:21,535 INFO:     Epoch: 53
2022-11-23 00:13:22,311 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8152641017328609, 'Total loss': 0.8152641017328609} | train loss {'Reaction outcome loss': 0.8188172700184007, 'Total loss': 0.8188172700184007}
2022-11-23 00:13:22,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:22,312 INFO:     Epoch: 54
2022-11-23 00:13:23,097 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8105678856372833, 'Total loss': 0.8105678856372833} | train loss {'Reaction outcome loss': 0.8158199776324534, 'Total loss': 0.8158199776324534}
2022-11-23 00:13:23,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:23,097 INFO:     Epoch: 55
2022-11-23 00:13:23,902 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8200222985310988, 'Total loss': 0.8200222985310988} | train loss {'Reaction outcome loss': 0.8168371540884818, 'Total loss': 0.8168371540884818}
2022-11-23 00:13:23,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:23,902 INFO:     Epoch: 56
2022-11-23 00:13:24,683 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8250506005503915, 'Total loss': 0.8250506005503915} | train loss {'Reaction outcome loss': 0.8193464329646479, 'Total loss': 0.8193464329646479}
2022-11-23 00:13:24,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:24,684 INFO:     Epoch: 57
2022-11-23 00:13:25,476 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8061163452538577, 'Total loss': 0.8061163452538577} | train loss {'Reaction outcome loss': 0.8214692276331687, 'Total loss': 0.8214692276331687}
2022-11-23 00:13:25,476 INFO:     Found new best model at epoch 57
2022-11-23 00:13:25,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:25,477 INFO:     Epoch: 58
2022-11-23 00:13:26,272 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8300768001513048, 'Total loss': 0.8300768001513048} | train loss {'Reaction outcome loss': 0.8107371579014486, 'Total loss': 0.8107371579014486}
2022-11-23 00:13:26,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:26,273 INFO:     Epoch: 59
2022-11-23 00:13:27,069 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8296617445620623, 'Total loss': 0.8296617445620623} | train loss {'Reaction outcome loss': 0.8176380120698483, 'Total loss': 0.8176380120698483}
2022-11-23 00:13:27,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:27,069 INFO:     Epoch: 60
2022-11-23 00:13:27,878 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8270151303573088, 'Total loss': 0.8270151303573088} | train loss {'Reaction outcome loss': 0.8170290778000509, 'Total loss': 0.8170290778000509}
2022-11-23 00:13:27,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:27,879 INFO:     Epoch: 61
2022-11-23 00:13:28,690 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8222496055743911, 'Total loss': 0.8222496055743911} | train loss {'Reaction outcome loss': 0.8129300615720211, 'Total loss': 0.8129300615720211}
2022-11-23 00:13:28,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:28,690 INFO:     Epoch: 62
2022-11-23 00:13:29,456 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8128896260803397, 'Total loss': 0.8128896260803397} | train loss {'Reaction outcome loss': 0.816665501964669, 'Total loss': 0.816665501964669}
2022-11-23 00:13:29,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:29,457 INFO:     Epoch: 63
2022-11-23 00:13:30,247 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8254619091749191, 'Total loss': 0.8254619091749191} | train loss {'Reaction outcome loss': 0.8136885301961053, 'Total loss': 0.8136885301961053}
2022-11-23 00:13:30,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:30,248 INFO:     Epoch: 64
2022-11-23 00:13:31,023 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8313198753378608, 'Total loss': 0.8313198753378608} | train loss {'Reaction outcome loss': 0.815924397279178, 'Total loss': 0.815924397279178}
2022-11-23 00:13:31,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:31,024 INFO:     Epoch: 65
2022-11-23 00:13:31,821 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8261570903387937, 'Total loss': 0.8261570903387937} | train loss {'Reaction outcome loss': 0.8165651901114371, 'Total loss': 0.8165651901114371}
2022-11-23 00:13:31,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:31,821 INFO:     Epoch: 66
2022-11-23 00:13:32,601 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8268668881871484, 'Total loss': 0.8268668881871484} | train loss {'Reaction outcome loss': 0.8178884307703664, 'Total loss': 0.8178884307703664}
2022-11-23 00:13:32,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:32,601 INFO:     Epoch: 67
2022-11-23 00:13:33,400 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8027890940958803, 'Total loss': 0.8027890940958803} | train loss {'Reaction outcome loss': 0.8194180384518639, 'Total loss': 0.8194180384518639}
2022-11-23 00:13:33,401 INFO:     Found new best model at epoch 67
2022-11-23 00:13:33,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:33,402 INFO:     Epoch: 68
2022-11-23 00:13:34,177 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8109708116813139, 'Total loss': 0.8109708116813139} | train loss {'Reaction outcome loss': 0.8194096144889632, 'Total loss': 0.8194096144889632}
2022-11-23 00:13:34,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:34,177 INFO:     Epoch: 69
2022-11-23 00:13:34,947 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8210040412165902, 'Total loss': 0.8210040412165902} | train loss {'Reaction outcome loss': 0.8123388969369473, 'Total loss': 0.8123388969369473}
2022-11-23 00:13:34,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:34,948 INFO:     Epoch: 70
2022-11-23 00:13:35,739 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8101463683626868, 'Total loss': 0.8101463683626868} | train loss {'Reaction outcome loss': 0.821963261572584, 'Total loss': 0.821963261572584}
2022-11-23 00:13:35,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:35,739 INFO:     Epoch: 71
2022-11-23 00:13:36,527 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8148958053101193, 'Total loss': 0.8148958053101193} | train loss {'Reaction outcome loss': 0.81484118284237, 'Total loss': 0.81484118284237}
2022-11-23 00:13:36,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:36,527 INFO:     Epoch: 72
2022-11-23 00:13:37,318 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8479993329806761, 'Total loss': 0.8479993329806761} | train loss {'Reaction outcome loss': 0.8132817657484163, 'Total loss': 0.8132817657484163}
2022-11-23 00:13:37,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:37,318 INFO:     Epoch: 73
2022-11-23 00:13:38,116 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8242762982845306, 'Total loss': 0.8242762982845306} | train loss {'Reaction outcome loss': 0.8144315467967141, 'Total loss': 0.8144315467967141}
2022-11-23 00:13:38,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:38,116 INFO:     Epoch: 74
2022-11-23 00:13:38,907 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8115232349796728, 'Total loss': 0.8115232349796728} | train loss {'Reaction outcome loss': 0.8154455125331879, 'Total loss': 0.8154455125331879}
2022-11-23 00:13:38,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:38,907 INFO:     Epoch: 75
2022-11-23 00:13:39,703 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.807603966106068, 'Total loss': 0.807603966106068} | train loss {'Reaction outcome loss': 0.8170111476173324, 'Total loss': 0.8170111476173324}
2022-11-23 00:13:39,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:39,704 INFO:     Epoch: 76
2022-11-23 00:13:40,483 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8370045531879772, 'Total loss': 0.8370045531879772} | train loss {'Reaction outcome loss': 0.8113038341604895, 'Total loss': 0.8113038341604895}
2022-11-23 00:13:40,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:40,484 INFO:     Epoch: 77
2022-11-23 00:13:41,299 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8237938359379768, 'Total loss': 0.8237938359379768} | train loss {'Reaction outcome loss': 0.8155467880349005, 'Total loss': 0.8155467880349005}
2022-11-23 00:13:41,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:41,299 INFO:     Epoch: 78
2022-11-23 00:13:42,109 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8174300911751661, 'Total loss': 0.8174300911751661} | train loss {'Reaction outcome loss': 0.8110352622405175, 'Total loss': 0.8110352622405175}
2022-11-23 00:13:42,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:42,110 INFO:     Epoch: 79
2022-11-23 00:13:42,921 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8545210347934202, 'Total loss': 0.8545210347934202} | train loss {'Reaction outcome loss': 0.8118360464371019, 'Total loss': 0.8118360464371019}
2022-11-23 00:13:42,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:42,921 INFO:     Epoch: 80
2022-11-23 00:13:43,721 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8154917725107886, 'Total loss': 0.8154917725107886} | train loss {'Reaction outcome loss': 0.8094177772441218, 'Total loss': 0.8094177772441218}
2022-11-23 00:13:43,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:43,721 INFO:     Epoch: 81
2022-11-23 00:13:44,545 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8230908824638887, 'Total loss': 0.8230908824638887} | train loss {'Reaction outcome loss': 0.8158680439716385, 'Total loss': 0.8158680439716385}
2022-11-23 00:13:44,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:44,545 INFO:     Epoch: 82
2022-11-23 00:13:45,317 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8199705528942022, 'Total loss': 0.8199705528942022} | train loss {'Reaction outcome loss': 0.8120778952875445, 'Total loss': 0.8120778952875445}
2022-11-23 00:13:45,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:45,317 INFO:     Epoch: 83
2022-11-23 00:13:46,121 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8257807398384268, 'Total loss': 0.8257807398384268} | train loss {'Reaction outcome loss': 0.81608503408009, 'Total loss': 0.81608503408009}
2022-11-23 00:13:46,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:46,122 INFO:     Epoch: 84
2022-11-23 00:13:46,949 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8106416192921725, 'Total loss': 0.8106416192921725} | train loss {'Reaction outcome loss': 0.819711526435229, 'Total loss': 0.819711526435229}
2022-11-23 00:13:46,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:46,951 INFO:     Epoch: 85
2022-11-23 00:13:47,737 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8187112523750826, 'Total loss': 0.8187112523750826} | train loss {'Reaction outcome loss': 0.817120019226305, 'Total loss': 0.817120019226305}
2022-11-23 00:13:47,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:47,737 INFO:     Epoch: 86
2022-11-23 00:13:48,578 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8210132494568825, 'Total loss': 0.8210132494568825} | train loss {'Reaction outcome loss': 0.8161098195179817, 'Total loss': 0.8161098195179817}
2022-11-23 00:13:48,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:48,578 INFO:     Epoch: 87
2022-11-23 00:13:49,351 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.818979952823032, 'Total loss': 0.818979952823032} | train loss {'Reaction outcome loss': 0.8117434657629459, 'Total loss': 0.8117434657629459}
2022-11-23 00:13:49,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:49,352 INFO:     Epoch: 88
2022-11-23 00:13:50,184 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8323160179636695, 'Total loss': 0.8323160179636695} | train loss {'Reaction outcome loss': 0.8156746533969718, 'Total loss': 0.8156746533969718}
2022-11-23 00:13:50,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:50,184 INFO:     Epoch: 89
2022-11-23 00:13:50,999 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8059562011198564, 'Total loss': 0.8059562011198564} | train loss {'Reaction outcome loss': 0.8167012101940571, 'Total loss': 0.8167012101940571}
2022-11-23 00:13:51,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:51,000 INFO:     Epoch: 90
2022-11-23 00:13:51,796 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8204441077329896, 'Total loss': 0.8204441077329896} | train loss {'Reaction outcome loss': 0.813229521436076, 'Total loss': 0.813229521436076}
2022-11-23 00:13:51,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:51,797 INFO:     Epoch: 91
2022-11-23 00:13:52,600 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8116349408572371, 'Total loss': 0.8116349408572371} | train loss {'Reaction outcome loss': 0.8139174687525919, 'Total loss': 0.8139174687525919}
2022-11-23 00:13:52,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:52,600 INFO:     Epoch: 92
2022-11-23 00:13:53,406 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8745440122756091, 'Total loss': 0.8745440122756091} | train loss {'Reaction outcome loss': 0.8116116237736517, 'Total loss': 0.8116116237736517}
2022-11-23 00:13:53,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:53,407 INFO:     Epoch: 93
2022-11-23 00:13:54,177 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8181241425600919, 'Total loss': 0.8181241425600919} | train loss {'Reaction outcome loss': 0.8143466474308122, 'Total loss': 0.8143466474308122}
2022-11-23 00:13:54,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:54,178 INFO:     Epoch: 94
2022-11-23 00:13:54,960 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8346384167671204, 'Total loss': 0.8346384167671204} | train loss {'Reaction outcome loss': 0.8163694317542738, 'Total loss': 0.8163694317542738}
2022-11-23 00:13:54,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:54,960 INFO:     Epoch: 95
2022-11-23 00:13:55,794 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8119371316649697, 'Total loss': 0.8119371316649697} | train loss {'Reaction outcome loss': 0.8172904584676989, 'Total loss': 0.8172904584676989}
2022-11-23 00:13:55,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:55,795 INFO:     Epoch: 96
2022-11-23 00:13:56,608 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8373901071873578, 'Total loss': 0.8373901071873578} | train loss {'Reaction outcome loss': 0.8130263619485402, 'Total loss': 0.8130263619485402}
2022-11-23 00:13:56,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:56,609 INFO:     Epoch: 97
2022-11-23 00:13:57,399 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.817731690000404, 'Total loss': 0.817731690000404} | train loss {'Reaction outcome loss': 0.8168166812148786, 'Total loss': 0.8168166812148786}
2022-11-23 00:13:57,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:57,399 INFO:     Epoch: 98
2022-11-23 00:13:58,195 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8241692212494937, 'Total loss': 0.8241692212494937} | train loss {'Reaction outcome loss': 0.8163934431729778, 'Total loss': 0.8163934431729778}
2022-11-23 00:13:58,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:58,195 INFO:     Epoch: 99
2022-11-23 00:13:59,020 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8073030358011072, 'Total loss': 0.8073030358011072} | train loss {'Reaction outcome loss': 0.8194885595190909, 'Total loss': 0.8194885595190909}
2022-11-23 00:13:59,020 INFO:     Best model found after epoch 68 of 100.
2022-11-23 00:13:59,021 INFO:   Done with stage: TRAINING
2022-11-23 00:13:59,021 INFO:   Starting stage: EVALUATION
2022-11-23 00:13:59,139 INFO:   Done with stage: EVALUATION
2022-11-23 00:13:59,139 INFO:   Leaving out SEQ value Fold_6
2022-11-23 00:13:59,153 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:13:59,153 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:13:59,822 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:13:59,822 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:13:59,891 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:13:59,891 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:13:59,891 INFO:     No hyperparam tuning for this model
2022-11-23 00:13:59,891 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:13:59,891 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:13:59,892 INFO:     None feature selector for col prot
2022-11-23 00:13:59,892 INFO:     None feature selector for col prot
2022-11-23 00:13:59,892 INFO:     None feature selector for col prot
2022-11-23 00:13:59,893 INFO:     None feature selector for col chem
2022-11-23 00:13:59,893 INFO:     None feature selector for col chem
2022-11-23 00:13:59,893 INFO:     None feature selector for col chem
2022-11-23 00:13:59,893 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:13:59,893 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:13:59,895 INFO:     Number of params in model 168571
2022-11-23 00:13:59,898 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:13:59,898 INFO:   Starting stage: TRAINING
2022-11-23 00:13:59,956 INFO:     Val loss before train {'Reaction outcome loss': 1.0073272389444439, 'Total loss': 1.0073272389444439}
2022-11-23 00:13:59,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:13:59,956 INFO:     Epoch: 0
2022-11-23 00:14:00,770 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8408287804235112, 'Total loss': 0.8408287804235112} | train loss {'Reaction outcome loss': 0.895935459778859, 'Total loss': 0.895935459778859}
2022-11-23 00:14:00,770 INFO:     Found new best model at epoch 0
2022-11-23 00:14:00,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:00,771 INFO:     Epoch: 1
2022-11-23 00:14:01,599 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8503963798284531, 'Total loss': 0.8503963798284531} | train loss {'Reaction outcome loss': 0.8506751681870295, 'Total loss': 0.8506751681870295}
2022-11-23 00:14:01,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:01,599 INFO:     Epoch: 2
2022-11-23 00:14:02,377 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8611077402125705, 'Total loss': 0.8611077402125705} | train loss {'Reaction outcome loss': 0.8479789626381176, 'Total loss': 0.8479789626381176}
2022-11-23 00:14:02,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:02,377 INFO:     Epoch: 3
2022-11-23 00:14:03,213 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8390603702176701, 'Total loss': 0.8390603702176701} | train loss {'Reaction outcome loss': 0.8430724493284457, 'Total loss': 0.8430724493284457}
2022-11-23 00:14:03,213 INFO:     Found new best model at epoch 3
2022-11-23 00:14:03,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:03,214 INFO:     Epoch: 4
2022-11-23 00:14:04,047 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8077097623185678, 'Total loss': 0.8077097623185678} | train loss {'Reaction outcome loss': 0.845809011987829, 'Total loss': 0.845809011987829}
2022-11-23 00:14:04,047 INFO:     Found new best model at epoch 4
2022-11-23 00:14:04,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:04,048 INFO:     Epoch: 5
2022-11-23 00:14:04,819 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8151900077408011, 'Total loss': 0.8151900077408011} | train loss {'Reaction outcome loss': 0.8375247538934353, 'Total loss': 0.8375247538934353}
2022-11-23 00:14:04,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:04,819 INFO:     Epoch: 6
2022-11-23 00:14:05,582 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8692540946331891, 'Total loss': 0.8692540946331891} | train loss {'Reaction outcome loss': 0.829531884295979, 'Total loss': 0.829531884295979}
2022-11-23 00:14:05,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:05,583 INFO:     Epoch: 7
2022-11-23 00:14:06,447 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8228452002460306, 'Total loss': 0.8228452002460306} | train loss {'Reaction outcome loss': 0.8308416091599445, 'Total loss': 0.8308416091599445}
2022-11-23 00:14:06,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:06,447 INFO:     Epoch: 8
2022-11-23 00:14:07,268 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8231854438781738, 'Total loss': 0.8231854438781738} | train loss {'Reaction outcome loss': 0.8374578725953816, 'Total loss': 0.8374578725953816}
2022-11-23 00:14:07,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:07,268 INFO:     Epoch: 9
2022-11-23 00:14:08,114 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.809928991577842, 'Total loss': 0.809928991577842} | train loss {'Reaction outcome loss': 0.832636207462805, 'Total loss': 0.832636207462805}
2022-11-23 00:14:08,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:08,114 INFO:     Epoch: 10
2022-11-23 00:14:08,986 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8130854178558696, 'Total loss': 0.8130854178558696} | train loss {'Reaction outcome loss': 0.8299151993232218, 'Total loss': 0.8299151993232218}
2022-11-23 00:14:08,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:08,986 INFO:     Epoch: 11
2022-11-23 00:14:09,834 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8255797590721737, 'Total loss': 0.8255797590721737} | train loss {'Reaction outcome loss': 0.8296501381767665, 'Total loss': 0.8296501381767665}
2022-11-23 00:14:09,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:09,834 INFO:     Epoch: 12
2022-11-23 00:14:10,648 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8119144371964715, 'Total loss': 0.8119144371964715} | train loss {'Reaction outcome loss': 0.825651338557724, 'Total loss': 0.825651338557724}
2022-11-23 00:14:10,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:10,648 INFO:     Epoch: 13
2022-11-23 00:14:11,465 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8284160007130016, 'Total loss': 0.8284160007130016} | train loss {'Reaction outcome loss': 0.8266078976967074, 'Total loss': 0.8266078976967074}
2022-11-23 00:14:11,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:11,465 INFO:     Epoch: 14
2022-11-23 00:14:12,291 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8119539063085209, 'Total loss': 0.8119539063085209} | train loss {'Reaction outcome loss': 0.8372188967007858, 'Total loss': 0.8372188967007858}
2022-11-23 00:14:12,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:12,291 INFO:     Epoch: 15
2022-11-23 00:14:13,138 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8480329652401534, 'Total loss': 0.8480329652401534} | train loss {'Reaction outcome loss': 0.8237099583573669, 'Total loss': 0.8237099583573669}
2022-11-23 00:14:13,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:13,139 INFO:     Epoch: 16
2022-11-23 00:14:13,915 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8020729747685519, 'Total loss': 0.8020729747685519} | train loss {'Reaction outcome loss': 0.8274493107670232, 'Total loss': 0.8274493107670232}
2022-11-23 00:14:13,915 INFO:     Found new best model at epoch 16
2022-11-23 00:14:13,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:13,916 INFO:     Epoch: 17
2022-11-23 00:14:14,721 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8000291416590865, 'Total loss': 0.8000291416590865} | train loss {'Reaction outcome loss': 0.8220100658625243, 'Total loss': 0.8220100658625243}
2022-11-23 00:14:14,722 INFO:     Found new best model at epoch 17
2022-11-23 00:14:14,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:14,722 INFO:     Epoch: 18
2022-11-23 00:14:15,527 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.813991519537839, 'Total loss': 0.813991519537839} | train loss {'Reaction outcome loss': 0.8203762393625762, 'Total loss': 0.8203762393625762}
2022-11-23 00:14:15,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:15,527 INFO:     Epoch: 19
2022-11-23 00:14:16,269 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.816827653483911, 'Total loss': 0.816827653483911} | train loss {'Reaction outcome loss': 0.8208711960537713, 'Total loss': 0.8208711960537713}
2022-11-23 00:14:16,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:16,269 INFO:     Epoch: 20
2022-11-23 00:14:17,056 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8171635073694316, 'Total loss': 0.8171635073694316} | train loss {'Reaction outcome loss': 0.8302573075419978, 'Total loss': 0.8302573075419978}
2022-11-23 00:14:17,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:17,056 INFO:     Epoch: 21
2022-11-23 00:14:17,847 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8128933283415708, 'Total loss': 0.8128933283415708} | train loss {'Reaction outcome loss': 0.8259415999356552, 'Total loss': 0.8259415999356552}
2022-11-23 00:14:17,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:17,848 INFO:     Epoch: 22
2022-11-23 00:14:18,618 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8232828134840185, 'Total loss': 0.8232828134840185} | train loss {'Reaction outcome loss': 0.8183304729309642, 'Total loss': 0.8183304729309642}
2022-11-23 00:14:18,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:18,619 INFO:     Epoch: 23
2022-11-23 00:14:19,374 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.809413265098225, 'Total loss': 0.809413265098225} | train loss {'Reaction outcome loss': 0.8215794346110541, 'Total loss': 0.8215794346110541}
2022-11-23 00:14:19,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:19,374 INFO:     Epoch: 24
2022-11-23 00:14:20,156 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8270518590103496, 'Total loss': 0.8270518590103496} | train loss {'Reaction outcome loss': 0.8245279543433595, 'Total loss': 0.8245279543433595}
2022-11-23 00:14:20,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:20,157 INFO:     Epoch: 25
2022-11-23 00:14:20,966 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8112116307020187, 'Total loss': 0.8112116307020187} | train loss {'Reaction outcome loss': 0.823907552943056, 'Total loss': 0.823907552943056}
2022-11-23 00:14:20,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:20,966 INFO:     Epoch: 26
2022-11-23 00:14:21,753 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8262396305799484, 'Total loss': 0.8262396305799484} | train loss {'Reaction outcome loss': 0.828036641905665, 'Total loss': 0.828036641905665}
2022-11-23 00:14:21,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:21,753 INFO:     Epoch: 27
2022-11-23 00:14:22,545 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8160582794384523, 'Total loss': 0.8160582794384523} | train loss {'Reaction outcome loss': 0.8268022145095625, 'Total loss': 0.8268022145095625}
2022-11-23 00:14:22,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:22,545 INFO:     Epoch: 28
2022-11-23 00:14:23,317 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8033343959938396, 'Total loss': 0.8033343959938396} | train loss {'Reaction outcome loss': 0.8195201467405929, 'Total loss': 0.8195201467405929}
2022-11-23 00:14:23,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:23,317 INFO:     Epoch: 29
2022-11-23 00:14:24,109 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8035321228883483, 'Total loss': 0.8035321228883483} | train loss {'Reaction outcome loss': 0.8213237927027559, 'Total loss': 0.8213237927027559}
2022-11-23 00:14:24,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:24,110 INFO:     Epoch: 30
2022-11-23 00:14:24,859 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8351079899479043, 'Total loss': 0.8351079899479043} | train loss {'Reaction outcome loss': 0.8157055708560866, 'Total loss': 0.8157055708560866}
2022-11-23 00:14:24,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:24,859 INFO:     Epoch: 31
2022-11-23 00:14:25,636 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.816601378673857, 'Total loss': 0.816601378673857} | train loss {'Reaction outcome loss': 0.8208458586501689, 'Total loss': 0.8208458586501689}
2022-11-23 00:14:25,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:25,636 INFO:     Epoch: 32
2022-11-23 00:14:26,418 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8091408373280005, 'Total loss': 0.8091408373280005} | train loss {'Reaction outcome loss': 0.8196267286534251, 'Total loss': 0.8196267286534251}
2022-11-23 00:14:26,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:26,418 INFO:     Epoch: 33
2022-11-23 00:14:27,218 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.809492365880446, 'Total loss': 0.809492365880446} | train loss {'Reaction outcome loss': 0.8281361463098873, 'Total loss': 0.8281361463098873}
2022-11-23 00:14:27,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:27,218 INFO:     Epoch: 34
2022-11-23 00:14:28,057 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8094819594513286, 'Total loss': 0.8094819594513286} | train loss {'Reaction outcome loss': 0.8236304244049165, 'Total loss': 0.8236304244049165}
2022-11-23 00:14:28,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:28,057 INFO:     Epoch: 35
2022-11-23 00:14:28,821 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8112546070055529, 'Total loss': 0.8112546070055529} | train loss {'Reaction outcome loss': 0.8178893639008525, 'Total loss': 0.8178893639008525}
2022-11-23 00:14:28,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:28,821 INFO:     Epoch: 36
2022-11-23 00:14:29,598 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8103306232528253, 'Total loss': 0.8103306232528253} | train loss {'Reaction outcome loss': 0.8164079789569986, 'Total loss': 0.8164079789569986}
2022-11-23 00:14:29,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:29,598 INFO:     Epoch: 37
2022-11-23 00:14:30,369 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8139131983572786, 'Total loss': 0.8139131983572786} | train loss {'Reaction outcome loss': 0.8153259195538185, 'Total loss': 0.8153259195538185}
2022-11-23 00:14:30,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:30,369 INFO:     Epoch: 38
2022-11-23 00:14:31,216 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8099763068285856, 'Total loss': 0.8099763068285856} | train loss {'Reaction outcome loss': 0.8238180387116637, 'Total loss': 0.8238180387116637}
2022-11-23 00:14:31,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:31,216 INFO:     Epoch: 39
2022-11-23 00:14:32,015 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7975771271369674, 'Total loss': 0.7975771271369674} | train loss {'Reaction outcome loss': 0.8206152666194236, 'Total loss': 0.8206152666194236}
2022-11-23 00:14:32,015 INFO:     Found new best model at epoch 39
2022-11-23 00:14:32,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:32,016 INFO:     Epoch: 40
2022-11-23 00:14:32,799 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7970127761363983, 'Total loss': 0.7970127761363983} | train loss {'Reaction outcome loss': 0.8141519643275844, 'Total loss': 0.8141519643275844}
2022-11-23 00:14:32,799 INFO:     Found new best model at epoch 40
2022-11-23 00:14:32,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:32,800 INFO:     Epoch: 41
2022-11-23 00:14:33,587 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7992141842842102, 'Total loss': 0.7992141842842102} | train loss {'Reaction outcome loss': 0.8181803903810168, 'Total loss': 0.8181803903810168}
2022-11-23 00:14:33,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:33,587 INFO:     Epoch: 42
2022-11-23 00:14:34,341 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8214934041554277, 'Total loss': 0.8214934041554277} | train loss {'Reaction outcome loss': 0.8175837468159827, 'Total loss': 0.8175837468159827}
2022-11-23 00:14:34,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:34,341 INFO:     Epoch: 43
2022-11-23 00:14:35,132 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8079849258065224, 'Total loss': 0.8079849258065224} | train loss {'Reaction outcome loss': 0.81388675116817, 'Total loss': 0.81388675116817}
2022-11-23 00:14:35,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:35,132 INFO:     Epoch: 44
2022-11-23 00:14:35,936 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8320872458544645, 'Total loss': 0.8320872458544645} | train loss {'Reaction outcome loss': 0.8159298758033798, 'Total loss': 0.8159298758033798}
2022-11-23 00:14:35,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:35,936 INFO:     Epoch: 45
2022-11-23 00:14:36,726 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8054797134616158, 'Total loss': 0.8054797134616158} | train loss {'Reaction outcome loss': 0.8141256559353608, 'Total loss': 0.8141256559353608}
2022-11-23 00:14:36,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:36,728 INFO:     Epoch: 46
2022-11-23 00:14:37,537 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8119260980324312, 'Total loss': 0.8119260980324312} | train loss {'Reaction outcome loss': 0.8135294815910007, 'Total loss': 0.8135294815910007}
2022-11-23 00:14:37,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:37,537 INFO:     Epoch: 47
2022-11-23 00:14:38,305 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8306823569265279, 'Total loss': 0.8306823569265279} | train loss {'Reaction outcome loss': 0.8147621370836912, 'Total loss': 0.8147621370836912}
2022-11-23 00:14:38,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:38,305 INFO:     Epoch: 48
2022-11-23 00:14:39,087 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8063192123716528, 'Total loss': 0.8063192123716528} | train loss {'Reaction outcome loss': 0.8152483501415021, 'Total loss': 0.8152483501415021}
2022-11-23 00:14:39,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:39,087 INFO:     Epoch: 49
2022-11-23 00:14:39,863 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8116511851549149, 'Total loss': 0.8116511851549149} | train loss {'Reaction outcome loss': 0.8201682830629079, 'Total loss': 0.8201682830629079}
2022-11-23 00:14:39,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:39,863 INFO:     Epoch: 50
2022-11-23 00:14:40,654 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8072696402668953, 'Total loss': 0.8072696402668953} | train loss {'Reaction outcome loss': 0.8166560583751694, 'Total loss': 0.8166560583751694}
2022-11-23 00:14:40,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:40,654 INFO:     Epoch: 51
2022-11-23 00:14:41,429 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7985929000106725, 'Total loss': 0.7985929000106725} | train loss {'Reaction outcome loss': 0.8215193760539838, 'Total loss': 0.8215193760539838}
2022-11-23 00:14:41,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:41,429 INFO:     Epoch: 52
2022-11-23 00:14:42,198 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8062034676020796, 'Total loss': 0.8062034676020796} | train loss {'Reaction outcome loss': 0.8137137690476077, 'Total loss': 0.8137137690476077}
2022-11-23 00:14:42,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:42,199 INFO:     Epoch: 53
2022-11-23 00:14:42,973 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8075815662741661, 'Total loss': 0.8075815662741661} | train loss {'Reaction outcome loss': 0.816547615566717, 'Total loss': 0.816547615566717}
2022-11-23 00:14:42,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:42,973 INFO:     Epoch: 54
2022-11-23 00:14:43,776 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7998221205039457, 'Total loss': 0.7998221205039457} | train loss {'Reaction outcome loss': 0.8184055026002258, 'Total loss': 0.8184055026002258}
2022-11-23 00:14:43,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:43,776 INFO:     Epoch: 55
2022-11-23 00:14:44,552 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8156791193918749, 'Total loss': 0.8156791193918749} | train loss {'Reaction outcome loss': 0.8138773060038023, 'Total loss': 0.8138773060038023}
2022-11-23 00:14:44,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:44,552 INFO:     Epoch: 56
2022-11-23 00:14:45,336 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8223192685029723, 'Total loss': 0.8223192685029723} | train loss {'Reaction outcome loss': 0.8201148903321641, 'Total loss': 0.8201148903321641}
2022-11-23 00:14:45,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:45,336 INFO:     Epoch: 57
2022-11-23 00:14:46,130 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.810958357019858, 'Total loss': 0.810958357019858} | train loss {'Reaction outcome loss': 0.8183037100231599, 'Total loss': 0.8183037100231599}
2022-11-23 00:14:46,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:46,131 INFO:     Epoch: 58
2022-11-23 00:14:46,922 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8000755851919, 'Total loss': 0.8000755851919} | train loss {'Reaction outcome loss': 0.8135584857058429, 'Total loss': 0.8135584857058429}
2022-11-23 00:14:46,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:46,922 INFO:     Epoch: 59
2022-11-23 00:14:47,720 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8086641457947817, 'Total loss': 0.8086641457947817} | train loss {'Reaction outcome loss': 0.8226353428383105, 'Total loss': 0.8226353428383105}
2022-11-23 00:14:47,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:47,721 INFO:     Epoch: 60
2022-11-23 00:14:48,548 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8300111950798468, 'Total loss': 0.8300111950798468} | train loss {'Reaction outcome loss': 0.8124540590564249, 'Total loss': 0.8124540590564249}
2022-11-23 00:14:48,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:48,550 INFO:     Epoch: 61
2022-11-23 00:14:49,321 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8072680438106711, 'Total loss': 0.8072680438106711} | train loss {'Reaction outcome loss': 0.8176395106412139, 'Total loss': 0.8176395106412139}
2022-11-23 00:14:49,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:49,321 INFO:     Epoch: 62
2022-11-23 00:14:50,123 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8216051676056602, 'Total loss': 0.8216051676056602} | train loss {'Reaction outcome loss': 0.812879290748463, 'Total loss': 0.812879290748463}
2022-11-23 00:14:50,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:50,123 INFO:     Epoch: 63
2022-11-23 00:14:50,940 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8079220632260496, 'Total loss': 0.8079220632260496} | train loss {'Reaction outcome loss': 0.8131703957161198, 'Total loss': 0.8131703957161198}
2022-11-23 00:14:50,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:50,941 INFO:     Epoch: 64
2022-11-23 00:14:51,775 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7989750396121632, 'Total loss': 0.7989750396121632} | train loss {'Reaction outcome loss': 0.817123391488303, 'Total loss': 0.817123391488303}
2022-11-23 00:14:51,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:51,775 INFO:     Epoch: 65
2022-11-23 00:14:52,582 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7983107289130037, 'Total loss': 0.7983107289130037} | train loss {'Reaction outcome loss': 0.814753274203312, 'Total loss': 0.814753274203312}
2022-11-23 00:14:52,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:52,582 INFO:     Epoch: 66
2022-11-23 00:14:53,407 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8164863115684553, 'Total loss': 0.8164863115684553} | train loss {'Reaction outcome loss': 0.8212180702309859, 'Total loss': 0.8212180702309859}
2022-11-23 00:14:53,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:53,407 INFO:     Epoch: 67
2022-11-23 00:14:54,195 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8098999857902527, 'Total loss': 0.8098999857902527} | train loss {'Reaction outcome loss': 0.8232523441797326, 'Total loss': 0.8232523441797326}
2022-11-23 00:14:54,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:54,195 INFO:     Epoch: 68
2022-11-23 00:14:54,991 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8075576587156816, 'Total loss': 0.8075576587156816} | train loss {'Reaction outcome loss': 0.8213506961158412, 'Total loss': 0.8213506961158412}
2022-11-23 00:14:54,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:54,992 INFO:     Epoch: 69
2022-11-23 00:14:55,782 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8047460480169817, 'Total loss': 0.8047460480169817} | train loss {'Reaction outcome loss': 0.8179538820677923, 'Total loss': 0.8179538820677923}
2022-11-23 00:14:55,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:55,782 INFO:     Epoch: 70
2022-11-23 00:14:56,597 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7977818291295659, 'Total loss': 0.7977818291295659} | train loss {'Reaction outcome loss': 0.8136206353120958, 'Total loss': 0.8136206353120958}
2022-11-23 00:14:56,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:56,598 INFO:     Epoch: 71
2022-11-23 00:14:57,433 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7923210838978941, 'Total loss': 0.7923210838978941} | train loss {'Reaction outcome loss': 0.8163053596068007, 'Total loss': 0.8163053596068007}
2022-11-23 00:14:57,433 INFO:     Found new best model at epoch 71
2022-11-23 00:14:57,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:57,434 INFO:     Epoch: 72
2022-11-23 00:14:58,200 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8073618947104975, 'Total loss': 0.8073618947104975} | train loss {'Reaction outcome loss': 0.8142072312865662, 'Total loss': 0.8142072312865662}
2022-11-23 00:14:58,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:58,201 INFO:     Epoch: 73
2022-11-23 00:14:58,989 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8161980997432362, 'Total loss': 0.8161980997432362} | train loss {'Reaction outcome loss': 0.8137258139367287, 'Total loss': 0.8137258139367287}
2022-11-23 00:14:58,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:58,989 INFO:     Epoch: 74
2022-11-23 00:14:59,805 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8239176388491284, 'Total loss': 0.8239176388491284} | train loss {'Reaction outcome loss': 0.814174955431749, 'Total loss': 0.814174955431749}
2022-11-23 00:14:59,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:14:59,805 INFO:     Epoch: 75
2022-11-23 00:15:00,642 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8235889375209808, 'Total loss': 0.8235889375209808} | train loss {'Reaction outcome loss': 0.8298378131891552, 'Total loss': 0.8298378131891552}
2022-11-23 00:15:00,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:00,643 INFO:     Epoch: 76
2022-11-23 00:15:01,440 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8059235892512582, 'Total loss': 0.8059235892512582} | train loss {'Reaction outcome loss': 0.821967578368631, 'Total loss': 0.821967578368631}
2022-11-23 00:15:01,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:01,441 INFO:     Epoch: 77
2022-11-23 00:15:02,216 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8074112609028816, 'Total loss': 0.8074112609028816} | train loss {'Reaction outcome loss': 0.8160089627209945, 'Total loss': 0.8160089627209945}
2022-11-23 00:15:02,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:02,217 INFO:     Epoch: 78
2022-11-23 00:15:03,000 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8009447170929476, 'Total loss': 0.8009447170929476} | train loss {'Reaction outcome loss': 0.821377652527591, 'Total loss': 0.821377652527591}
2022-11-23 00:15:03,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:03,000 INFO:     Epoch: 79
2022-11-23 00:15:03,805 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8003176430409605, 'Total loss': 0.8003176430409605} | train loss {'Reaction outcome loss': 0.8178452742003236, 'Total loss': 0.8178452742003236}
2022-11-23 00:15:03,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:03,805 INFO:     Epoch: 80
2022-11-23 00:15:04,575 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8367964246056296, 'Total loss': 0.8367964246056296} | train loss {'Reaction outcome loss': 0.8146917352731894, 'Total loss': 0.8146917352731894}
2022-11-23 00:15:04,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:04,575 INFO:     Epoch: 81
2022-11-23 00:15:05,368 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8178079514340921, 'Total loss': 0.8178079514340921} | train loss {'Reaction outcome loss': 0.8186327295928348, 'Total loss': 0.8186327295928348}
2022-11-23 00:15:05,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:05,368 INFO:     Epoch: 82
2022-11-23 00:15:06,138 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8096715516664765, 'Total loss': 0.8096715516664765} | train loss {'Reaction outcome loss': 0.8155613312354455, 'Total loss': 0.8155613312354455}
2022-11-23 00:15:06,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:06,138 INFO:     Epoch: 83
2022-11-23 00:15:06,921 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8087287924506448, 'Total loss': 0.8087287924506448} | train loss {'Reaction outcome loss': 0.8278922206959743, 'Total loss': 0.8278922206959743}
2022-11-23 00:15:06,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:06,922 INFO:     Epoch: 84
2022-11-23 00:15:07,692 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8109711273150011, 'Total loss': 0.8109711273150011} | train loss {'Reaction outcome loss': 0.8187218287937071, 'Total loss': 0.8187218287937071}
2022-11-23 00:15:07,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:07,693 INFO:     Epoch: 85
2022-11-23 00:15:08,446 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7962575622580268, 'Total loss': 0.7962575622580268} | train loss {'Reaction outcome loss': 0.8210206643531197, 'Total loss': 0.8210206643531197}
2022-11-23 00:15:08,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:08,446 INFO:     Epoch: 86
2022-11-23 00:15:09,211 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8605649268085306, 'Total loss': 0.8605649268085306} | train loss {'Reaction outcome loss': 0.8170652175963167, 'Total loss': 0.8170652175963167}
2022-11-23 00:15:09,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:09,211 INFO:     Epoch: 87
2022-11-23 00:15:10,023 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8107472475279461, 'Total loss': 0.8107472475279461} | train loss {'Reaction outcome loss': 0.8250333226402762, 'Total loss': 0.8250333226402762}
2022-11-23 00:15:10,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:10,024 INFO:     Epoch: 88
2022-11-23 00:15:10,836 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7931067733602091, 'Total loss': 0.7931067733602091} | train loss {'Reaction outcome loss': 0.8161985337251594, 'Total loss': 0.8161985337251594}
2022-11-23 00:15:10,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:10,836 INFO:     Epoch: 89
2022-11-23 00:15:11,645 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8027739355509932, 'Total loss': 0.8027739355509932} | train loss {'Reaction outcome loss': 0.8186523074563216, 'Total loss': 0.8186523074563216}
2022-11-23 00:15:11,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:11,645 INFO:     Epoch: 90
2022-11-23 00:15:12,404 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8071056028658693, 'Total loss': 0.8071056028658693} | train loss {'Reaction outcome loss': 0.820182674085563, 'Total loss': 0.820182674085563}
2022-11-23 00:15:12,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:12,405 INFO:     Epoch: 91
2022-11-23 00:15:13,247 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7916403446685184, 'Total loss': 0.7916403446685184} | train loss {'Reaction outcome loss': 0.8175383345318227, 'Total loss': 0.8175383345318227}
2022-11-23 00:15:13,247 INFO:     Found new best model at epoch 91
2022-11-23 00:15:13,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:13,248 INFO:     Epoch: 92
2022-11-23 00:15:14,039 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.800092725591226, 'Total loss': 0.800092725591226} | train loss {'Reaction outcome loss': 0.8214445893581097, 'Total loss': 0.8214445893581097}
2022-11-23 00:15:14,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:14,039 INFO:     Epoch: 93
2022-11-23 00:15:14,831 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8072164675051515, 'Total loss': 0.8072164675051515} | train loss {'Reaction outcome loss': 0.8199203712978826, 'Total loss': 0.8199203712978826}
2022-11-23 00:15:14,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:14,832 INFO:     Epoch: 94
2022-11-23 00:15:15,575 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8232146081599322, 'Total loss': 0.8232146081599322} | train loss {'Reaction outcome loss': 0.8298925297704303, 'Total loss': 0.8298925297704303}
2022-11-23 00:15:15,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:15,575 INFO:     Epoch: 95
2022-11-23 00:15:16,377 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7892712523991411, 'Total loss': 0.7892712523991411} | train loss {'Reaction outcome loss': 0.8199884420042096, 'Total loss': 0.8199884420042096}
2022-11-23 00:15:16,377 INFO:     Found new best model at epoch 95
2022-11-23 00:15:16,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:16,378 INFO:     Epoch: 96
2022-11-23 00:15:17,148 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8136886920441281, 'Total loss': 0.8136886920441281} | train loss {'Reaction outcome loss': 0.8203042943467979, 'Total loss': 0.8203042943467979}
2022-11-23 00:15:17,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:17,148 INFO:     Epoch: 97
2022-11-23 00:15:17,913 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8247466554695909, 'Total loss': 0.8247466554695909} | train loss {'Reaction outcome loss': 0.8222856437146422, 'Total loss': 0.8222856437146422}
2022-11-23 00:15:17,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:17,913 INFO:     Epoch: 98
2022-11-23 00:15:18,670 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.813924328847365, 'Total loss': 0.813924328847365} | train loss {'Reaction outcome loss': 0.820240544042124, 'Total loss': 0.820240544042124}
2022-11-23 00:15:18,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:18,671 INFO:     Epoch: 99
2022-11-23 00:15:19,443 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8116140189495954, 'Total loss': 0.8116140189495954} | train loss {'Reaction outcome loss': 0.8158785561137354, 'Total loss': 0.8158785561137354}
2022-11-23 00:15:19,443 INFO:     Best model found after epoch 96 of 100.
2022-11-23 00:15:19,443 INFO:   Done with stage: TRAINING
2022-11-23 00:15:19,443 INFO:   Starting stage: EVALUATION
2022-11-23 00:15:19,568 INFO:   Done with stage: EVALUATION
2022-11-23 00:15:19,568 INFO:   Leaving out SEQ value Fold_7
2022-11-23 00:15:19,581 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:15:19,581 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:15:20,252 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:15:20,253 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:15:20,322 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:15:20,322 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:15:20,322 INFO:     No hyperparam tuning for this model
2022-11-23 00:15:20,322 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:15:20,322 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:15:20,323 INFO:     None feature selector for col prot
2022-11-23 00:15:20,323 INFO:     None feature selector for col prot
2022-11-23 00:15:20,323 INFO:     None feature selector for col prot
2022-11-23 00:15:20,324 INFO:     None feature selector for col chem
2022-11-23 00:15:20,324 INFO:     None feature selector for col chem
2022-11-23 00:15:20,324 INFO:     None feature selector for col chem
2022-11-23 00:15:20,324 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:15:20,324 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:15:20,326 INFO:     Number of params in model 168571
2022-11-23 00:15:20,329 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:15:20,329 INFO:   Starting stage: TRAINING
2022-11-23 00:15:20,387 INFO:     Val loss before train {'Reaction outcome loss': 1.045773514292457, 'Total loss': 1.045773514292457}
2022-11-23 00:15:20,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:20,387 INFO:     Epoch: 0
2022-11-23 00:15:21,172 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8867107501084154, 'Total loss': 0.8867107501084154} | train loss {'Reaction outcome loss': 0.871066365285441, 'Total loss': 0.871066365285441}
2022-11-23 00:15:21,173 INFO:     Found new best model at epoch 0
2022-11-23 00:15:21,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:21,174 INFO:     Epoch: 1
2022-11-23 00:15:21,954 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8872718377546831, 'Total loss': 0.8872718377546831} | train loss {'Reaction outcome loss': 0.8395630716070955, 'Total loss': 0.8395630716070955}
2022-11-23 00:15:21,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:21,954 INFO:     Epoch: 2
2022-11-23 00:15:22,718 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9046857086094943, 'Total loss': 0.9046857086094943} | train loss {'Reaction outcome loss': 0.8358063251383392, 'Total loss': 0.8358063251383392}
2022-11-23 00:15:22,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:22,718 INFO:     Epoch: 3
2022-11-23 00:15:23,501 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8793558688326315, 'Total loss': 0.8793558688326315} | train loss {'Reaction outcome loss': 0.8249946083979085, 'Total loss': 0.8249946083979085}
2022-11-23 00:15:23,501 INFO:     Found new best model at epoch 3
2022-11-23 00:15:23,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:23,502 INFO:     Epoch: 4
2022-11-23 00:15:24,296 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8730455867268823, 'Total loss': 0.8730455867268823} | train loss {'Reaction outcome loss': 0.8361635448237662, 'Total loss': 0.8361635448237662}
2022-11-23 00:15:24,296 INFO:     Found new best model at epoch 4
2022-11-23 00:15:24,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:24,297 INFO:     Epoch: 5
2022-11-23 00:15:25,087 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.9021596285429868, 'Total loss': 0.9021596285429868} | train loss {'Reaction outcome loss': 0.824700190184208, 'Total loss': 0.824700190184208}
2022-11-23 00:15:25,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:25,087 INFO:     Epoch: 6
2022-11-23 00:15:25,860 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9030063755132935, 'Total loss': 0.9030063755132935} | train loss {'Reaction outcome loss': 0.8248867147907555, 'Total loss': 0.8248867147907555}
2022-11-23 00:15:25,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:25,860 INFO:     Epoch: 7
2022-11-23 00:15:26,623 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8768753619356588, 'Total loss': 0.8768753619356588} | train loss {'Reaction outcome loss': 0.8234014528000403, 'Total loss': 0.8234014528000403}
2022-11-23 00:15:26,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:26,624 INFO:     Epoch: 8
2022-11-23 00:15:27,410 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8742778524756432, 'Total loss': 0.8742778524756432} | train loss {'Reaction outcome loss': 0.8174920711922742, 'Total loss': 0.8174920711922742}
2022-11-23 00:15:27,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:27,411 INFO:     Epoch: 9
2022-11-23 00:15:28,206 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8638201220469042, 'Total loss': 0.8638201220469042} | train loss {'Reaction outcome loss': 0.8183363172930744, 'Total loss': 0.8183363172930744}
2022-11-23 00:15:28,206 INFO:     Found new best model at epoch 9
2022-11-23 00:15:28,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:28,207 INFO:     Epoch: 10
2022-11-23 00:15:29,002 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8663592121817849, 'Total loss': 0.8663592121817849} | train loss {'Reaction outcome loss': 0.8160674855912383, 'Total loss': 0.8160674855912383}
2022-11-23 00:15:29,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:29,003 INFO:     Epoch: 11
2022-11-23 00:15:29,783 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8633910851045088, 'Total loss': 0.8633910851045088} | train loss {'Reaction outcome loss': 0.8149103433014411, 'Total loss': 0.8149103433014411}
2022-11-23 00:15:29,783 INFO:     Found new best model at epoch 11
2022-11-23 00:15:29,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:29,784 INFO:     Epoch: 12
2022-11-23 00:15:30,558 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8769030489704825, 'Total loss': 0.8769030489704825} | train loss {'Reaction outcome loss': 0.8194379737743964, 'Total loss': 0.8194379737743964}
2022-11-23 00:15:30,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:30,559 INFO:     Epoch: 13
2022-11-23 00:15:31,352 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8727721558375792, 'Total loss': 0.8727721558375792} | train loss {'Reaction outcome loss': 0.8175133025115319, 'Total loss': 0.8175133025115319}
2022-11-23 00:15:31,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:31,352 INFO:     Epoch: 14
2022-11-23 00:15:32,126 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.870145706967874, 'Total loss': 0.870145706967874} | train loss {'Reaction outcome loss': 0.811779772040815, 'Total loss': 0.811779772040815}
2022-11-23 00:15:32,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:32,127 INFO:     Epoch: 15
2022-11-23 00:15:32,917 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8688641183755614, 'Total loss': 0.8688641183755614} | train loss {'Reaction outcome loss': 0.8186460724967694, 'Total loss': 0.8186460724967694}
2022-11-23 00:15:32,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:32,918 INFO:     Epoch: 16
2022-11-23 00:15:33,694 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.897654729810628, 'Total loss': 0.897654729810628} | train loss {'Reaction outcome loss': 0.8115788707848985, 'Total loss': 0.8115788707848985}
2022-11-23 00:15:33,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:33,694 INFO:     Epoch: 17
2022-11-23 00:15:34,491 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8648257445205342, 'Total loss': 0.8648257445205342} | train loss {'Reaction outcome loss': 0.8047707276908975, 'Total loss': 0.8047707276908975}
2022-11-23 00:15:34,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:34,491 INFO:     Epoch: 18
2022-11-23 00:15:35,296 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8822288689288226, 'Total loss': 0.8822288689288226} | train loss {'Reaction outcome loss': 0.8126693261779754, 'Total loss': 0.8126693261779754}
2022-11-23 00:15:35,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:35,296 INFO:     Epoch: 19
2022-11-23 00:15:36,073 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8867377679456364, 'Total loss': 0.8867377679456364} | train loss {'Reaction outcome loss': 0.8157358991231031, 'Total loss': 0.8157358991231031}
2022-11-23 00:15:36,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:36,073 INFO:     Epoch: 20
2022-11-23 00:15:36,848 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8668427372520621, 'Total loss': 0.8668427372520621} | train loss {'Reaction outcome loss': 0.8090594813891268, 'Total loss': 0.8090594813891268}
2022-11-23 00:15:36,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:36,848 INFO:     Epoch: 21
2022-11-23 00:15:37,630 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8729976198889993, 'Total loss': 0.8729976198889993} | train loss {'Reaction outcome loss': 0.8065721601519266, 'Total loss': 0.8065721601519266}
2022-11-23 00:15:37,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:37,631 INFO:     Epoch: 22
2022-11-23 00:15:38,418 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8633519946174188, 'Total loss': 0.8633519946174188} | train loss {'Reaction outcome loss': 0.8129983283730171, 'Total loss': 0.8129983283730171}
2022-11-23 00:15:38,418 INFO:     Found new best model at epoch 22
2022-11-23 00:15:38,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:38,419 INFO:     Epoch: 23
2022-11-23 00:15:39,189 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8574867113070055, 'Total loss': 0.8574867113070055} | train loss {'Reaction outcome loss': 0.8071386569183365, 'Total loss': 0.8071386569183365}
2022-11-23 00:15:39,190 INFO:     Found new best model at epoch 23
2022-11-23 00:15:39,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:39,191 INFO:     Epoch: 24
2022-11-23 00:15:40,014 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.854273334145546, 'Total loss': 0.854273334145546} | train loss {'Reaction outcome loss': 0.8064639298056784, 'Total loss': 0.8064639298056784}
2022-11-23 00:15:40,014 INFO:     Found new best model at epoch 24
2022-11-23 00:15:40,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:40,015 INFO:     Epoch: 25
2022-11-23 00:15:40,862 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8605841093442657, 'Total loss': 0.8605841093442657} | train loss {'Reaction outcome loss': 0.8016101477539491, 'Total loss': 0.8016101477539491}
2022-11-23 00:15:40,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:40,863 INFO:     Epoch: 26
2022-11-23 00:15:41,678 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8606885759667917, 'Total loss': 0.8606885759667917} | train loss {'Reaction outcome loss': 0.800644281904707, 'Total loss': 0.800644281904707}
2022-11-23 00:15:41,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:41,678 INFO:     Epoch: 27
2022-11-23 00:15:42,514 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8636333759535443, 'Total loss': 0.8636333759535443} | train loss {'Reaction outcome loss': 0.8009973229908267, 'Total loss': 0.8009973229908267}
2022-11-23 00:15:42,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:42,515 INFO:     Epoch: 28
2022-11-23 00:15:43,325 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.903181294825944, 'Total loss': 0.903181294825944} | train loss {'Reaction outcome loss': 0.8087433915404294, 'Total loss': 0.8087433915404294}
2022-11-23 00:15:43,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:43,325 INFO:     Epoch: 29
2022-11-23 00:15:44,123 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8543551164594564, 'Total loss': 0.8543551164594564} | train loss {'Reaction outcome loss': 0.8055252662147225, 'Total loss': 0.8055252662147225}
2022-11-23 00:15:44,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:44,123 INFO:     Epoch: 30
2022-11-23 00:15:44,952 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8961921686475928, 'Total loss': 0.8961921686475928} | train loss {'Reaction outcome loss': 0.808403617698654, 'Total loss': 0.808403617698654}
2022-11-23 00:15:44,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:44,953 INFO:     Epoch: 31
2022-11-23 00:15:45,801 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8716289353641596, 'Total loss': 0.8716289353641596} | train loss {'Reaction outcome loss': 0.8126262782315011, 'Total loss': 0.8126262782315011}
2022-11-23 00:15:45,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:45,801 INFO:     Epoch: 32
2022-11-23 00:15:46,617 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8681631467559121, 'Total loss': 0.8681631467559121} | train loss {'Reaction outcome loss': 0.802855213764708, 'Total loss': 0.802855213764708}
2022-11-23 00:15:46,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:46,617 INFO:     Epoch: 33
2022-11-23 00:15:47,389 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8660951974717054, 'Total loss': 0.8660951974717054} | train loss {'Reaction outcome loss': 0.805796793959884, 'Total loss': 0.805796793959884}
2022-11-23 00:15:47,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:47,389 INFO:     Epoch: 34
2022-11-23 00:15:48,221 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8631185374476693, 'Total loss': 0.8631185374476693} | train loss {'Reaction outcome loss': 0.8017196878489212, 'Total loss': 0.8017196878489212}
2022-11-23 00:15:48,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:48,221 INFO:     Epoch: 35
2022-11-23 00:15:49,017 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.866197178309614, 'Total loss': 0.866197178309614} | train loss {'Reaction outcome loss': 0.8011166327878049, 'Total loss': 0.8011166327878049}
2022-11-23 00:15:49,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:49,017 INFO:     Epoch: 36
2022-11-23 00:15:49,842 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8563352945176038, 'Total loss': 0.8563352945176038} | train loss {'Reaction outcome loss': 0.8092953465004199, 'Total loss': 0.8092953465004199}
2022-11-23 00:15:49,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:49,842 INFO:     Epoch: 37
2022-11-23 00:15:50,690 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8689636249433864, 'Total loss': 0.8689636249433864} | train loss {'Reaction outcome loss': 0.8060591271531726, 'Total loss': 0.8060591271531726}
2022-11-23 00:15:50,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:50,690 INFO:     Epoch: 38
2022-11-23 00:15:51,521 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8697038767012683, 'Total loss': 0.8697038767012683} | train loss {'Reaction outcome loss': 0.8012249865512616, 'Total loss': 0.8012249865512616}
2022-11-23 00:15:51,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:51,522 INFO:     Epoch: 39
2022-11-23 00:15:52,318 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8712762242013757, 'Total loss': 0.8712762242013757} | train loss {'Reaction outcome loss': 0.8010973984654616, 'Total loss': 0.8010973984654616}
2022-11-23 00:15:52,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:52,319 INFO:     Epoch: 40
2022-11-23 00:15:53,152 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.9015754623846575, 'Total loss': 0.9015754623846575} | train loss {'Reaction outcome loss': 0.8017039993996562, 'Total loss': 0.8017039993996562}
2022-11-23 00:15:53,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:53,152 INFO:     Epoch: 41
2022-11-23 00:15:53,938 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8554080345413901, 'Total loss': 0.8554080345413901} | train loss {'Reaction outcome loss': 0.8052819765772414, 'Total loss': 0.8052819765772414}
2022-11-23 00:15:53,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:53,938 INFO:     Epoch: 42
2022-11-23 00:15:54,721 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8642689396034587, 'Total loss': 0.8642689396034587} | train loss {'Reaction outcome loss': 0.8046924941211577, 'Total loss': 0.8046924941211577}
2022-11-23 00:15:54,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:54,722 INFO:     Epoch: 43
2022-11-23 00:15:55,496 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8599789664149284, 'Total loss': 0.8599789664149284} | train loss {'Reaction outcome loss': 0.8037874843427527, 'Total loss': 0.8037874843427527}
2022-11-23 00:15:55,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:55,497 INFO:     Epoch: 44
2022-11-23 00:15:56,275 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.864949334751476, 'Total loss': 0.864949334751476} | train loss {'Reaction outcome loss': 0.8017031329001493, 'Total loss': 0.8017031329001493}
2022-11-23 00:15:56,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:56,276 INFO:     Epoch: 45
2022-11-23 00:15:57,057 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8714981322938745, 'Total loss': 0.8714981322938745} | train loss {'Reaction outcome loss': 0.8019140077988628, 'Total loss': 0.8019140077988628}
2022-11-23 00:15:57,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:57,057 INFO:     Epoch: 46
2022-11-23 00:15:57,842 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8599833751266653, 'Total loss': 0.8599833751266653} | train loss {'Reaction outcome loss': 0.8051597982765692, 'Total loss': 0.8051597982765692}
2022-11-23 00:15:57,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:57,843 INFO:     Epoch: 47
2022-11-23 00:15:58,605 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8546227826313539, 'Total loss': 0.8546227826313539} | train loss {'Reaction outcome loss': 0.7980374926135607, 'Total loss': 0.7980374926135607}
2022-11-23 00:15:58,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:58,605 INFO:     Epoch: 48
2022-11-23 00:15:59,385 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8847273154692217, 'Total loss': 0.8847273154692217} | train loss {'Reaction outcome loss': 0.8106080156106216, 'Total loss': 0.8106080156106216}
2022-11-23 00:15:59,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:15:59,385 INFO:     Epoch: 49
2022-11-23 00:16:00,192 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.856976109472188, 'Total loss': 0.856976109472188} | train loss {'Reaction outcome loss': 0.8079508237751872, 'Total loss': 0.8079508237751872}
2022-11-23 00:16:00,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:00,192 INFO:     Epoch: 50
2022-11-23 00:16:00,959 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8820660053329035, 'Total loss': 0.8820660053329035} | train loss {'Reaction outcome loss': 0.805898831923481, 'Total loss': 0.805898831923481}
2022-11-23 00:16:00,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:00,959 INFO:     Epoch: 51
2022-11-23 00:16:01,768 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8471416729417715, 'Total loss': 0.8471416729417715} | train loss {'Reaction outcome loss': 0.8041138451109048, 'Total loss': 0.8041138451109048}
2022-11-23 00:16:01,769 INFO:     Found new best model at epoch 51
2022-11-23 00:16:01,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:01,769 INFO:     Epoch: 52
2022-11-23 00:16:02,565 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8563588654453104, 'Total loss': 0.8563588654453104} | train loss {'Reaction outcome loss': 0.7929809019648233, 'Total loss': 0.7929809019648233}
2022-11-23 00:16:02,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:02,565 INFO:     Epoch: 53
2022-11-23 00:16:03,386 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.868657725778493, 'Total loss': 0.868657725778493} | train loss {'Reaction outcome loss': 0.8050559292196745, 'Total loss': 0.8050559292196745}
2022-11-23 00:16:03,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:03,386 INFO:     Epoch: 54
2022-11-23 00:16:04,219 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8598906418139284, 'Total loss': 0.8598906418139284} | train loss {'Reaction outcome loss': 0.7953554039542009, 'Total loss': 0.7953554039542009}
2022-11-23 00:16:04,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:04,219 INFO:     Epoch: 55
2022-11-23 00:16:05,087 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8522692769765854, 'Total loss': 0.8522692769765854} | train loss {'Reaction outcome loss': 0.7982013560982368, 'Total loss': 0.7982013560982368}
2022-11-23 00:16:05,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:05,087 INFO:     Epoch: 56
2022-11-23 00:16:05,923 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8572436137632891, 'Total loss': 0.8572436137632891} | train loss {'Reaction outcome loss': 0.8006117556259217, 'Total loss': 0.8006117556259217}
2022-11-23 00:16:05,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:05,923 INFO:     Epoch: 57
2022-11-23 00:16:06,754 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8592199439352209, 'Total loss': 0.8592199439352209} | train loss {'Reaction outcome loss': 0.7972437673010807, 'Total loss': 0.7972437673010807}
2022-11-23 00:16:06,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:06,755 INFO:     Epoch: 58
2022-11-23 00:16:07,545 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8501935479315844, 'Total loss': 0.8501935479315844} | train loss {'Reaction outcome loss': 0.7999032904744631, 'Total loss': 0.7999032904744631}
2022-11-23 00:16:07,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:07,545 INFO:     Epoch: 59
2022-11-23 00:16:08,335 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8528079688549042, 'Total loss': 0.8528079688549042} | train loss {'Reaction outcome loss': 0.8007805202654016, 'Total loss': 0.8007805202654016}
2022-11-23 00:16:08,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:08,336 INFO:     Epoch: 60
2022-11-23 00:16:09,112 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8537989726120775, 'Total loss': 0.8537989726120775} | train loss {'Reaction outcome loss': 0.7935162213167198, 'Total loss': 0.7935162213167198}
2022-11-23 00:16:09,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:09,112 INFO:     Epoch: 61
2022-11-23 00:16:09,877 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8511860953135924, 'Total loss': 0.8511860953135924} | train loss {'Reaction outcome loss': 0.7990241666071811, 'Total loss': 0.7990241666071811}
2022-11-23 00:16:09,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:09,878 INFO:     Epoch: 62
2022-11-23 00:16:10,666 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8396236964247443, 'Total loss': 0.8396236964247443} | train loss {'Reaction outcome loss': 0.7899476001378496, 'Total loss': 0.7899476001378496}
2022-11-23 00:16:10,666 INFO:     Found new best model at epoch 62
2022-11-23 00:16:10,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:10,667 INFO:     Epoch: 63
2022-11-23 00:16:11,462 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8382785929874941, 'Total loss': 0.8382785929874941} | train loss {'Reaction outcome loss': 0.7964441643552742, 'Total loss': 0.7964441643552742}
2022-11-23 00:16:11,462 INFO:     Found new best model at epoch 63
2022-11-23 00:16:11,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:11,463 INFO:     Epoch: 64
2022-11-23 00:16:12,250 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8648877333511006, 'Total loss': 0.8648877333511006} | train loss {'Reaction outcome loss': 0.7952991261218603, 'Total loss': 0.7952991261218603}
2022-11-23 00:16:12,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:12,250 INFO:     Epoch: 65
2022-11-23 00:16:13,050 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8616084090688012, 'Total loss': 0.8616084090688012} | train loss {'Reaction outcome loss': 0.7937881305270832, 'Total loss': 0.7937881305270832}
2022-11-23 00:16:13,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:13,050 INFO:     Epoch: 66
2022-11-23 00:16:13,825 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.836223378777504, 'Total loss': 0.836223378777504} | train loss {'Reaction outcome loss': 0.7924853008285708, 'Total loss': 0.7924853008285708}
2022-11-23 00:16:13,825 INFO:     Found new best model at epoch 66
2022-11-23 00:16:13,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:13,826 INFO:     Epoch: 67
2022-11-23 00:16:14,592 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8389962207187306, 'Total loss': 0.8389962207187306} | train loss {'Reaction outcome loss': 0.7850162329582068, 'Total loss': 0.7850162329582068}
2022-11-23 00:16:14,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:14,593 INFO:     Epoch: 68
2022-11-23 00:16:15,368 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.84453730691563, 'Total loss': 0.84453730691563} | train loss {'Reaction outcome loss': 0.7845806037848778, 'Total loss': 0.7845806037848778}
2022-11-23 00:16:15,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:15,369 INFO:     Epoch: 69
2022-11-23 00:16:16,139 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8354120254516602, 'Total loss': 0.8354120254516602} | train loss {'Reaction outcome loss': 0.7835068578722506, 'Total loss': 0.7835068578722506}
2022-11-23 00:16:16,139 INFO:     Found new best model at epoch 69
2022-11-23 00:16:16,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:16,140 INFO:     Epoch: 70
2022-11-23 00:16:16,931 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.860761047764258, 'Total loss': 0.860761047764258} | train loss {'Reaction outcome loss': 0.7798796585696911, 'Total loss': 0.7798796585696911}
2022-11-23 00:16:16,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:16,931 INFO:     Epoch: 71
2022-11-23 00:16:17,712 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8267265978184614, 'Total loss': 0.8267265978184614} | train loss {'Reaction outcome loss': 0.7883444835058591, 'Total loss': 0.7883444835058591}
2022-11-23 00:16:17,712 INFO:     Found new best model at epoch 71
2022-11-23 00:16:17,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:17,713 INFO:     Epoch: 72
2022-11-23 00:16:18,511 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8289235044609417, 'Total loss': 0.8289235044609417} | train loss {'Reaction outcome loss': 0.7768241771560932, 'Total loss': 0.7768241771560932}
2022-11-23 00:16:18,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:18,512 INFO:     Epoch: 73
2022-11-23 00:16:19,269 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8186373764818365, 'Total loss': 0.8186373764818365} | train loss {'Reaction outcome loss': 0.7824010091875246, 'Total loss': 0.7824010091875246}
2022-11-23 00:16:19,269 INFO:     Found new best model at epoch 73
2022-11-23 00:16:19,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:19,270 INFO:     Epoch: 74
2022-11-23 00:16:20,045 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8682610121640292, 'Total loss': 0.8682610121640292} | train loss {'Reaction outcome loss': 0.778560263183918, 'Total loss': 0.778560263183918}
2022-11-23 00:16:20,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:20,045 INFO:     Epoch: 75
2022-11-23 00:16:20,857 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8804112036119808, 'Total loss': 0.8804112036119808} | train loss {'Reaction outcome loss': 0.7740901901654387, 'Total loss': 0.7740901901654387}
2022-11-23 00:16:20,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:20,857 INFO:     Epoch: 76
2022-11-23 00:16:21,700 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8156550851735201, 'Total loss': 0.8156550851735201} | train loss {'Reaction outcome loss': 0.7736617729731416, 'Total loss': 0.7736617729731416}
2022-11-23 00:16:21,700 INFO:     Found new best model at epoch 76
2022-11-23 00:16:21,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:21,701 INFO:     Epoch: 77
2022-11-23 00:16:22,507 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.837853955951604, 'Total loss': 0.837853955951604} | train loss {'Reaction outcome loss': 0.7771018481688944, 'Total loss': 0.7771018481688944}
2022-11-23 00:16:22,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:22,508 INFO:     Epoch: 78
2022-11-23 00:16:23,300 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8498387092893774, 'Total loss': 0.8498387092893774} | train loss {'Reaction outcome loss': 0.7678531063230414, 'Total loss': 0.7678531063230414}
2022-11-23 00:16:23,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:23,301 INFO:     Epoch: 79
2022-11-23 00:16:24,075 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8325822895223444, 'Total loss': 0.8325822895223444} | train loss {'Reaction outcome loss': 0.7660334933141948, 'Total loss': 0.7660334933141948}
2022-11-23 00:16:24,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:24,076 INFO:     Epoch: 80
2022-11-23 00:16:24,890 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8042522336949002, 'Total loss': 0.8042522336949002} | train loss {'Reaction outcome loss': 0.7712135506786315, 'Total loss': 0.7712135506786315}
2022-11-23 00:16:24,890 INFO:     Found new best model at epoch 80
2022-11-23 00:16:24,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:24,891 INFO:     Epoch: 81
2022-11-23 00:16:25,683 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8434524197470058, 'Total loss': 0.8434524197470058} | train loss {'Reaction outcome loss': 0.7674669675257525, 'Total loss': 0.7674669675257525}
2022-11-23 00:16:25,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:25,683 INFO:     Epoch: 82
2022-11-23 00:16:26,510 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8226933398030021, 'Total loss': 0.8226933398030021} | train loss {'Reaction outcome loss': 0.751558073860431, 'Total loss': 0.751558073860431}
2022-11-23 00:16:26,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:26,510 INFO:     Epoch: 83
2022-11-23 00:16:27,296 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8092457218603655, 'Total loss': 0.8092457218603655} | train loss {'Reaction outcome loss': 0.756536961144764, 'Total loss': 0.756536961144764}
2022-11-23 00:16:27,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:27,296 INFO:     Epoch: 84
2022-11-23 00:16:28,106 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8148182169957594, 'Total loss': 0.8148182169957594} | train loss {'Reaction outcome loss': 0.7620083307206389, 'Total loss': 0.7620083307206389}
2022-11-23 00:16:28,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:28,106 INFO:     Epoch: 85
2022-11-23 00:16:28,906 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8673839528452266, 'Total loss': 0.8673839528452266} | train loss {'Reaction outcome loss': 0.7597053712196196, 'Total loss': 0.7597053712196196}
2022-11-23 00:16:28,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:28,908 INFO:     Epoch: 86
2022-11-23 00:16:29,682 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7952853888273239, 'Total loss': 0.7952853888273239} | train loss {'Reaction outcome loss': 0.7436279723880744, 'Total loss': 0.7436279723880744}
2022-11-23 00:16:29,682 INFO:     Found new best model at epoch 86
2022-11-23 00:16:29,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:29,683 INFO:     Epoch: 87
2022-11-23 00:16:30,517 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8370784947817976, 'Total loss': 0.8370784947817976} | train loss {'Reaction outcome loss': 0.7384913698864369, 'Total loss': 0.7384913698864369}
2022-11-23 00:16:30,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:30,517 INFO:     Epoch: 88
2022-11-23 00:16:31,374 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8040918450463902, 'Total loss': 0.8040918450463902} | train loss {'Reaction outcome loss': 0.7458180452165334, 'Total loss': 0.7458180452165334}
2022-11-23 00:16:31,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:31,375 INFO:     Epoch: 89
2022-11-23 00:16:32,198 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8289171511476691, 'Total loss': 0.8289171511476691} | train loss {'Reaction outcome loss': 0.7281224990663259, 'Total loss': 0.7281224990663259}
2022-11-23 00:16:32,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:32,198 INFO:     Epoch: 90
2022-11-23 00:16:33,019 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7551112892952833, 'Total loss': 0.7551112892952833} | train loss {'Reaction outcome loss': 0.7177464529449641, 'Total loss': 0.7177464529449641}
2022-11-23 00:16:33,019 INFO:     Found new best model at epoch 90
2022-11-23 00:16:33,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:33,020 INFO:     Epoch: 91
2022-11-23 00:16:33,833 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.781647340817885, 'Total loss': 0.781647340817885} | train loss {'Reaction outcome loss': 0.7117216859751867, 'Total loss': 0.7117216859751867}
2022-11-23 00:16:33,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:33,833 INFO:     Epoch: 92
2022-11-23 00:16:34,649 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7348060770468279, 'Total loss': 0.7348060770468279} | train loss {'Reaction outcome loss': 0.7027874328950157, 'Total loss': 0.7027874328950157}
2022-11-23 00:16:34,649 INFO:     Found new best model at epoch 92
2022-11-23 00:16:34,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:34,650 INFO:     Epoch: 93
2022-11-23 00:16:35,501 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.78265788202936, 'Total loss': 0.78265788202936} | train loss {'Reaction outcome loss': 0.6819470464082261, 'Total loss': 0.6819470464082261}
2022-11-23 00:16:35,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:35,501 INFO:     Epoch: 94
2022-11-23 00:16:36,293 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7429433295672591, 'Total loss': 0.7429433295672591} | train loss {'Reaction outcome loss': 0.6683599414371768, 'Total loss': 0.6683599414371768}
2022-11-23 00:16:36,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:36,293 INFO:     Epoch: 95
2022-11-23 00:16:37,091 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7378373437307097, 'Total loss': 0.7378373437307097} | train loss {'Reaction outcome loss': 0.6562352672762234, 'Total loss': 0.6562352672762234}
2022-11-23 00:16:37,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:37,091 INFO:     Epoch: 96
2022-11-23 00:16:37,896 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7023291581056335, 'Total loss': 0.7023291581056335} | train loss {'Reaction outcome loss': 0.6537401764257716, 'Total loss': 0.6537401764257716}
2022-11-23 00:16:37,896 INFO:     Found new best model at epoch 96
2022-11-23 00:16:37,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:37,897 INFO:     Epoch: 97
2022-11-23 00:16:38,702 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.9670235067605972, 'Total loss': 0.9670235067605972} | train loss {'Reaction outcome loss': 0.6352279341896536, 'Total loss': 0.6352279341896536}
2022-11-23 00:16:38,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:38,703 INFO:     Epoch: 98
2022-11-23 00:16:39,480 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6559003503485159, 'Total loss': 0.6559003503485159} | train loss {'Reaction outcome loss': 0.6490921661680044, 'Total loss': 0.6490921661680044}
2022-11-23 00:16:39,481 INFO:     Found new best model at epoch 98
2022-11-23 00:16:39,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:39,482 INFO:     Epoch: 99
2022-11-23 00:16:40,236 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6735501506111838, 'Total loss': 0.6735501506111838} | train loss {'Reaction outcome loss': 0.618039730951371, 'Total loss': 0.618039730951371}
2022-11-23 00:16:40,236 INFO:     Best model found after epoch 99 of 100.
2022-11-23 00:16:40,236 INFO:   Done with stage: TRAINING
2022-11-23 00:16:40,236 INFO:   Starting stage: EVALUATION
2022-11-23 00:16:40,361 INFO:   Done with stage: EVALUATION
2022-11-23 00:16:40,362 INFO:   Leaving out SEQ value Fold_8
2022-11-23 00:16:40,376 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 00:16:40,376 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:16:41,040 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:16:41,040 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:16:41,109 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:16:41,109 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:16:41,109 INFO:     No hyperparam tuning for this model
2022-11-23 00:16:41,109 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:16:41,109 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:16:41,110 INFO:     None feature selector for col prot
2022-11-23 00:16:41,110 INFO:     None feature selector for col prot
2022-11-23 00:16:41,110 INFO:     None feature selector for col prot
2022-11-23 00:16:41,110 INFO:     None feature selector for col chem
2022-11-23 00:16:41,111 INFO:     None feature selector for col chem
2022-11-23 00:16:41,111 INFO:     None feature selector for col chem
2022-11-23 00:16:41,111 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:16:41,111 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:16:41,112 INFO:     Number of params in model 168571
2022-11-23 00:16:41,115 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:16:41,115 INFO:   Starting stage: TRAINING
2022-11-23 00:16:41,172 INFO:     Val loss before train {'Reaction outcome loss': 1.0026610216429068, 'Total loss': 1.0026610216429068}
2022-11-23 00:16:41,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:41,172 INFO:     Epoch: 0
2022-11-23 00:16:41,960 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8360841059407522, 'Total loss': 0.8360841059407522} | train loss {'Reaction outcome loss': 0.8734906071522197, 'Total loss': 0.8734906071522197}
2022-11-23 00:16:41,960 INFO:     Found new best model at epoch 0
2022-11-23 00:16:41,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:41,961 INFO:     Epoch: 1
2022-11-23 00:16:42,762 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8514374480691067, 'Total loss': 0.8514374480691067} | train loss {'Reaction outcome loss': 0.8419663700901094, 'Total loss': 0.8419663700901094}
2022-11-23 00:16:42,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:42,763 INFO:     Epoch: 2
2022-11-23 00:16:43,570 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8430188374463902, 'Total loss': 0.8430188374463902} | train loss {'Reaction outcome loss': 0.8281772179437465, 'Total loss': 0.8281772179437465}
2022-11-23 00:16:43,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:43,571 INFO:     Epoch: 3
2022-11-23 00:16:44,325 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8654575070669485, 'Total loss': 0.8654575070669485} | train loss {'Reaction outcome loss': 0.8262555798301932, 'Total loss': 0.8262555798301932}
2022-11-23 00:16:44,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:44,325 INFO:     Epoch: 4
2022-11-23 00:16:45,114 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8228689348974894, 'Total loss': 0.8228689348974894} | train loss {'Reaction outcome loss': 0.8231706061079854, 'Total loss': 0.8231706061079854}
2022-11-23 00:16:45,114 INFO:     Found new best model at epoch 4
2022-11-23 00:16:45,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:45,115 INFO:     Epoch: 5
2022-11-23 00:16:45,943 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8112372125304023, 'Total loss': 0.8112372125304023} | train loss {'Reaction outcome loss': 0.819254215134949, 'Total loss': 0.819254215134949}
2022-11-23 00:16:45,943 INFO:     Found new best model at epoch 5
2022-11-23 00:16:45,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:45,944 INFO:     Epoch: 6
2022-11-23 00:16:46,737 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8453049604282823, 'Total loss': 0.8453049604282823} | train loss {'Reaction outcome loss': 0.8148068287333504, 'Total loss': 0.8148068287333504}
2022-11-23 00:16:46,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:46,737 INFO:     Epoch: 7
2022-11-23 00:16:47,538 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.830513222273006, 'Total loss': 0.830513222273006} | train loss {'Reaction outcome loss': 0.8128866591170186, 'Total loss': 0.8128866591170186}
2022-11-23 00:16:47,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:47,538 INFO:     Epoch: 8
2022-11-23 00:16:48,360 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8134332209132439, 'Total loss': 0.8134332209132439} | train loss {'Reaction outcome loss': 0.8138312111135388, 'Total loss': 0.8138312111135388}
2022-11-23 00:16:48,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:48,360 INFO:     Epoch: 9
2022-11-23 00:16:49,200 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8209636363872262, 'Total loss': 0.8209636363872262} | train loss {'Reaction outcome loss': 0.8190011819366549, 'Total loss': 0.8190011819366549}
2022-11-23 00:16:49,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:49,201 INFO:     Epoch: 10
2022-11-23 00:16:50,039 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8165128286494765, 'Total loss': 0.8165128286494765} | train loss {'Reaction outcome loss': 0.808656464956823, 'Total loss': 0.808656464956823}
2022-11-23 00:16:50,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:50,040 INFO:     Epoch: 11
2022-11-23 00:16:50,877 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8090581290943678, 'Total loss': 0.8090581290943678} | train loss {'Reaction outcome loss': 0.8138118707498566, 'Total loss': 0.8138118707498566}
2022-11-23 00:16:50,878 INFO:     Found new best model at epoch 11
2022-11-23 00:16:50,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:50,878 INFO:     Epoch: 12
2022-11-23 00:16:51,674 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8067792300568071, 'Total loss': 0.8067792300568071} | train loss {'Reaction outcome loss': 0.806668358870217, 'Total loss': 0.806668358870217}
2022-11-23 00:16:51,674 INFO:     Found new best model at epoch 12
2022-11-23 00:16:51,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:51,675 INFO:     Epoch: 13
2022-11-23 00:16:52,434 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8176023925459662, 'Total loss': 0.8176023925459662} | train loss {'Reaction outcome loss': 0.8154058717801923, 'Total loss': 0.8154058717801923}
2022-11-23 00:16:52,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:52,434 INFO:     Epoch: 14
2022-11-23 00:16:53,206 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8104337148888167, 'Total loss': 0.8104337148888167} | train loss {'Reaction outcome loss': 0.8102372692989521, 'Total loss': 0.8102372692989521}
2022-11-23 00:16:53,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:53,207 INFO:     Epoch: 15
2022-11-23 00:16:53,955 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8231793059859165, 'Total loss': 0.8231793059859165} | train loss {'Reaction outcome loss': 0.8089822931367843, 'Total loss': 0.8089822931367843}
2022-11-23 00:16:53,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:53,955 INFO:     Epoch: 16
2022-11-23 00:16:54,736 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8217140283695487, 'Total loss': 0.8217140283695487} | train loss {'Reaction outcome loss': 0.8108729841034921, 'Total loss': 0.8108729841034921}
2022-11-23 00:16:54,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:54,737 INFO:     Epoch: 17
2022-11-23 00:16:55,484 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8284891705180324, 'Total loss': 0.8284891705180324} | train loss {'Reaction outcome loss': 0.809089156814286, 'Total loss': 0.809089156814286}
2022-11-23 00:16:55,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:55,485 INFO:     Epoch: 18
2022-11-23 00:16:56,246 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8131108990935392, 'Total loss': 0.8131108990935392} | train loss {'Reaction outcome loss': 0.8082851782196858, 'Total loss': 0.8082851782196858}
2022-11-23 00:16:56,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:56,246 INFO:     Epoch: 19
2022-11-23 00:16:57,045 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8448289036750793, 'Total loss': 0.8448289036750793} | train loss {'Reaction outcome loss': 0.8059180747778689, 'Total loss': 0.8059180747778689}
2022-11-23 00:16:57,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:57,045 INFO:     Epoch: 20
2022-11-23 00:16:57,813 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8233210181081018, 'Total loss': 0.8233210181081018} | train loss {'Reaction outcome loss': 0.811018947817263, 'Total loss': 0.811018947817263}
2022-11-23 00:16:57,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:57,813 INFO:     Epoch: 21
2022-11-23 00:16:58,583 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.814452724401341, 'Total loss': 0.814452724401341} | train loss {'Reaction outcome loss': 0.8084899003877014, 'Total loss': 0.8084899003877014}
2022-11-23 00:16:58,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:58,583 INFO:     Epoch: 22
2022-11-23 00:16:59,346 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8220120460488075, 'Total loss': 0.8220120460488075} | train loss {'Reaction outcome loss': 0.8093253912740066, 'Total loss': 0.8093253912740066}
2022-11-23 00:16:59,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:16:59,347 INFO:     Epoch: 23
2022-11-23 00:17:00,156 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8437175695286241, 'Total loss': 0.8437175695286241} | train loss {'Reaction outcome loss': 0.8106336688897648, 'Total loss': 0.8106336688897648}
2022-11-23 00:17:00,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:00,156 INFO:     Epoch: 24
2022-11-23 00:17:00,933 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8126057587390723, 'Total loss': 0.8126057587390723} | train loss {'Reaction outcome loss': 0.8059291651502984, 'Total loss': 0.8059291651502984}
2022-11-23 00:17:00,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:00,933 INFO:     Epoch: 25
2022-11-23 00:17:01,694 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8213622022506802, 'Total loss': 0.8213622022506802} | train loss {'Reaction outcome loss': 0.8056254883403661, 'Total loss': 0.8056254883403661}
2022-11-23 00:17:01,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:01,694 INFO:     Epoch: 26
2022-11-23 00:17:02,491 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8118820869645407, 'Total loss': 0.8118820869645407} | train loss {'Reaction outcome loss': 0.8054863999857277, 'Total loss': 0.8054863999857277}
2022-11-23 00:17:02,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:02,491 INFO:     Epoch: 27
2022-11-23 00:17:03,305 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8150371527949045, 'Total loss': 0.8150371527949045} | train loss {'Reaction outcome loss': 0.810683760975228, 'Total loss': 0.810683760975228}
2022-11-23 00:17:03,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:03,305 INFO:     Epoch: 28
2022-11-23 00:17:04,052 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8214143445325452, 'Total loss': 0.8214143445325452} | train loss {'Reaction outcome loss': 0.8060806722181743, 'Total loss': 0.8060806722181743}
2022-11-23 00:17:04,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:04,052 INFO:     Epoch: 29
2022-11-23 00:17:04,845 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8173649359581082, 'Total loss': 0.8173649359581082} | train loss {'Reaction outcome loss': 0.8077403157949448, 'Total loss': 0.8077403157949448}
2022-11-23 00:17:04,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:04,845 INFO:     Epoch: 30
2022-11-23 00:17:05,661 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8190742855848268, 'Total loss': 0.8190742855848268} | train loss {'Reaction outcome loss': 0.8058896855008407, 'Total loss': 0.8058896855008407}
2022-11-23 00:17:05,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:05,661 INFO:     Epoch: 31
2022-11-23 00:17:06,475 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8185273637605268, 'Total loss': 0.8185273637605268} | train loss {'Reaction outcome loss': 0.8067710613373851, 'Total loss': 0.8067710613373851}
2022-11-23 00:17:06,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:06,476 INFO:     Epoch: 32
2022-11-23 00:17:07,266 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.824320608793303, 'Total loss': 0.824320608793303} | train loss {'Reaction outcome loss': 0.801739107389919, 'Total loss': 0.801739107389919}
2022-11-23 00:17:07,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:07,267 INFO:     Epoch: 33
2022-11-23 00:17:08,134 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8141893044460652, 'Total loss': 0.8141893044460652} | train loss {'Reaction outcome loss': 0.8116372059114644, 'Total loss': 0.8116372059114644}
2022-11-23 00:17:08,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:08,134 INFO:     Epoch: 34
2022-11-23 00:17:08,983 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8145776099936907, 'Total loss': 0.8145776099936907} | train loss {'Reaction outcome loss': 0.8054310790583735, 'Total loss': 0.8054310790583735}
2022-11-23 00:17:08,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:08,984 INFO:     Epoch: 35
2022-11-23 00:17:09,862 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8052009565885677, 'Total loss': 0.8052009565885677} | train loss {'Reaction outcome loss': 0.8052147469315373, 'Total loss': 0.8052147469315373}
2022-11-23 00:17:09,862 INFO:     Found new best model at epoch 35
2022-11-23 00:17:09,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:09,863 INFO:     Epoch: 36
2022-11-23 00:17:10,703 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8058902732161588, 'Total loss': 0.8058902732161588} | train loss {'Reaction outcome loss': 0.8043146791150335, 'Total loss': 0.8043146791150335}
2022-11-23 00:17:10,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:10,704 INFO:     Epoch: 37
2022-11-23 00:17:11,534 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8067673867525056, 'Total loss': 0.8067673867525056} | train loss {'Reaction outcome loss': 0.8001917185353451, 'Total loss': 0.8001917185353451}
2022-11-23 00:17:11,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:11,535 INFO:     Epoch: 38
2022-11-23 00:17:12,401 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8284731909286144, 'Total loss': 0.8284731909286144} | train loss {'Reaction outcome loss': 0.8058295265817251, 'Total loss': 0.8058295265817251}
2022-11-23 00:17:12,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:12,401 INFO:     Epoch: 39
2022-11-23 00:17:13,313 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8070314353288606, 'Total loss': 0.8070314353288606} | train loss {'Reaction outcome loss': 0.8053155690431595, 'Total loss': 0.8053155690431595}
2022-11-23 00:17:13,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:13,314 INFO:     Epoch: 40
2022-11-23 00:17:14,202 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8797645825286244, 'Total loss': 0.8797645825286244} | train loss {'Reaction outcome loss': 0.8069996769066716, 'Total loss': 0.8069996769066716}
2022-11-23 00:17:14,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:14,203 INFO:     Epoch: 41
2022-11-23 00:17:15,068 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.815432048121164, 'Total loss': 0.815432048121164} | train loss {'Reaction outcome loss': 0.8066129278941233, 'Total loss': 0.8066129278941233}
2022-11-23 00:17:15,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:15,069 INFO:     Epoch: 42
2022-11-23 00:17:15,930 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8150902224141497, 'Total loss': 0.8150902224141497} | train loss {'Reaction outcome loss': 0.8057321090190137, 'Total loss': 0.8057321090190137}
2022-11-23 00:17:15,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:15,931 INFO:     Epoch: 43
2022-11-23 00:17:16,849 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8185263996900514, 'Total loss': 0.8185263996900514} | train loss {'Reaction outcome loss': 0.8039347355971571, 'Total loss': 0.8039347355971571}
2022-11-23 00:17:16,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:16,849 INFO:     Epoch: 44
2022-11-23 00:17:17,723 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8225348522496778, 'Total loss': 0.8225348522496778} | train loss {'Reaction outcome loss': 0.8055950171146237, 'Total loss': 0.8055950171146237}
2022-11-23 00:17:17,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:17,723 INFO:     Epoch: 45
2022-11-23 00:17:18,631 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8235164714414019, 'Total loss': 0.8235164714414019} | train loss {'Reaction outcome loss': 0.8108069703715747, 'Total loss': 0.8108069703715747}
2022-11-23 00:17:18,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:18,631 INFO:     Epoch: 46
2022-11-23 00:17:19,508 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8061663598515266, 'Total loss': 0.8061663598515266} | train loss {'Reaction outcome loss': 0.8041183045897328, 'Total loss': 0.8041183045897328}
2022-11-23 00:17:19,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:19,509 INFO:     Epoch: 47
2022-11-23 00:17:20,396 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8372060684270637, 'Total loss': 0.8372060684270637} | train loss {'Reaction outcome loss': 0.808148270991982, 'Total loss': 0.808148270991982}
2022-11-23 00:17:20,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:20,396 INFO:     Epoch: 48
2022-11-23 00:17:21,269 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8096493919228398, 'Total loss': 0.8096493919228398} | train loss {'Reaction outcome loss': 0.8047950300769727, 'Total loss': 0.8047950300769727}
2022-11-23 00:17:21,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:21,270 INFO:     Epoch: 49
2022-11-23 00:17:22,166 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7949409034363059, 'Total loss': 0.7949409034363059} | train loss {'Reaction outcome loss': 0.807009083570027, 'Total loss': 0.807009083570027}
2022-11-23 00:17:22,166 INFO:     Found new best model at epoch 49
2022-11-23 00:17:22,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:22,167 INFO:     Epoch: 50
2022-11-23 00:17:23,031 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8292112329671549, 'Total loss': 0.8292112329671549} | train loss {'Reaction outcome loss': 0.8021513347010143, 'Total loss': 0.8021513347010143}
2022-11-23 00:17:23,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:23,031 INFO:     Epoch: 51
2022-11-23 00:17:23,916 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8098579270895138, 'Total loss': 0.8098579270895138} | train loss {'Reaction outcome loss': 0.8074417390295716, 'Total loss': 0.8074417390295716}
2022-11-23 00:17:23,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:23,918 INFO:     Epoch: 52
2022-11-23 00:17:24,776 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8228624691796858, 'Total loss': 0.8228624691796858} | train loss {'Reaction outcome loss': 0.8068183819290067, 'Total loss': 0.8068183819290067}
2022-11-23 00:17:24,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:24,777 INFO:     Epoch: 53
2022-11-23 00:17:25,639 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.817902626686318, 'Total loss': 0.817902626686318} | train loss {'Reaction outcome loss': 0.8061807711349159, 'Total loss': 0.8061807711349159}
2022-11-23 00:17:25,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:25,639 INFO:     Epoch: 54
2022-11-23 00:17:26,539 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8111447366171105, 'Total loss': 0.8111447366171105} | train loss {'Reaction outcome loss': 0.8078279866546881, 'Total loss': 0.8078279866546881}
2022-11-23 00:17:26,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:26,540 INFO:     Epoch: 55
2022-11-23 00:17:27,420 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.830704924672149, 'Total loss': 0.830704924672149} | train loss {'Reaction outcome loss': 0.8004627722452898, 'Total loss': 0.8004627722452898}
2022-11-23 00:17:27,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:27,421 INFO:     Epoch: 56
2022-11-23 00:17:28,289 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8089767957842627, 'Total loss': 0.8089767957842627} | train loss {'Reaction outcome loss': 0.8041656723276513, 'Total loss': 0.8041656723276513}
2022-11-23 00:17:28,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:28,289 INFO:     Epoch: 57
2022-11-23 00:17:29,155 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8231205718461857, 'Total loss': 0.8231205718461857} | train loss {'Reaction outcome loss': 0.8048536056866411, 'Total loss': 0.8048536056866411}
2022-11-23 00:17:29,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:29,155 INFO:     Epoch: 58
2022-11-23 00:17:30,047 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8239021391369575, 'Total loss': 0.8239021391369575} | train loss {'Reaction outcome loss': 0.8050568505633072, 'Total loss': 0.8050568505633072}
2022-11-23 00:17:30,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:30,048 INFO:     Epoch: 59
2022-11-23 00:17:30,975 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8169030145157216, 'Total loss': 0.8169030145157216} | train loss {'Reaction outcome loss': 0.8007056328361152, 'Total loss': 0.8007056328361152}
2022-11-23 00:17:30,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:30,975 INFO:     Epoch: 60
2022-11-23 00:17:31,916 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8076502334239871, 'Total loss': 0.8076502334239871} | train loss {'Reaction outcome loss': 0.8075993560620995, 'Total loss': 0.8075993560620995}
2022-11-23 00:17:31,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:31,916 INFO:     Epoch: 61
2022-11-23 00:17:32,765 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8178786462129548, 'Total loss': 0.8178786462129548} | train loss {'Reaction outcome loss': 0.8088715845932726, 'Total loss': 0.8088715845932726}
2022-11-23 00:17:32,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:32,766 INFO:     Epoch: 62
2022-11-23 00:17:33,607 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8292030019815578, 'Total loss': 0.8292030019815578} | train loss {'Reaction outcome loss': 0.8023723547087341, 'Total loss': 0.8023723547087341}
2022-11-23 00:17:33,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:33,608 INFO:     Epoch: 63
2022-11-23 00:17:34,477 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8262782810732375, 'Total loss': 0.8262782810732375} | train loss {'Reaction outcome loss': 0.8069687549208031, 'Total loss': 0.8069687549208031}
2022-11-23 00:17:34,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:34,477 INFO:     Epoch: 64
2022-11-23 00:17:35,387 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8198706951252249, 'Total loss': 0.8198706951252249} | train loss {'Reaction outcome loss': 0.8032705683688648, 'Total loss': 0.8032705683688648}
2022-11-23 00:17:35,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:35,388 INFO:     Epoch: 65
2022-11-23 00:17:36,256 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8325539404569671, 'Total loss': 0.8325539404569671} | train loss {'Reaction outcome loss': 0.8045024102339979, 'Total loss': 0.8045024102339979}
2022-11-23 00:17:36,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:36,256 INFO:     Epoch: 66
2022-11-23 00:17:37,108 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.811085314944733, 'Total loss': 0.811085314944733} | train loss {'Reaction outcome loss': 0.806440667661487, 'Total loss': 0.806440667661487}
2022-11-23 00:17:37,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:37,109 INFO:     Epoch: 67
2022-11-23 00:17:37,937 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8316955219867618, 'Total loss': 0.8316955219867618} | train loss {'Reaction outcome loss': 0.8072476449926369, 'Total loss': 0.8072476449926369}
2022-11-23 00:17:37,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:37,937 INFO:     Epoch: 68
2022-11-23 00:17:38,768 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8116685567900191, 'Total loss': 0.8116685567900191} | train loss {'Reaction outcome loss': 0.8063832968473434, 'Total loss': 0.8063832968473434}
2022-11-23 00:17:38,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:38,768 INFO:     Epoch: 69
2022-11-23 00:17:39,652 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.811893034813016, 'Total loss': 0.811893034813016} | train loss {'Reaction outcome loss': 0.8052496828260969, 'Total loss': 0.8052496828260969}
2022-11-23 00:17:39,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:39,652 INFO:     Epoch: 70
2022-11-23 00:17:40,538 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.819494562786679, 'Total loss': 0.819494562786679} | train loss {'Reaction outcome loss': 0.8055538914975573, 'Total loss': 0.8055538914975573}
2022-11-23 00:17:40,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:40,538 INFO:     Epoch: 71
2022-11-23 00:17:41,368 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8275297894034275, 'Total loss': 0.8275297894034275} | train loss {'Reaction outcome loss': 0.8058545224246432, 'Total loss': 0.8058545224246432}
2022-11-23 00:17:41,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:41,368 INFO:     Epoch: 72
2022-11-23 00:17:42,188 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8125290718189505, 'Total loss': 0.8125290718189505} | train loss {'Reaction outcome loss': 0.8086605059807418, 'Total loss': 0.8086605059807418}
2022-11-23 00:17:42,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:42,189 INFO:     Epoch: 73
2022-11-23 00:17:43,070 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8253034741379494, 'Total loss': 0.8253034741379494} | train loss {'Reaction outcome loss': 0.8067705649577204, 'Total loss': 0.8067705649577204}
2022-11-23 00:17:43,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:43,070 INFO:     Epoch: 74
2022-11-23 00:17:43,965 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8184027942114098, 'Total loss': 0.8184027942114098} | train loss {'Reaction outcome loss': 0.809830615877128, 'Total loss': 0.809830615877128}
2022-11-23 00:17:43,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:43,965 INFO:     Epoch: 75
2022-11-23 00:17:44,784 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8170812441859134, 'Total loss': 0.8170812441859134} | train loss {'Reaction outcome loss': 0.8032076363680792, 'Total loss': 0.8032076363680792}
2022-11-23 00:17:44,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:44,785 INFO:     Epoch: 76
2022-11-23 00:17:45,661 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8045336077379626, 'Total loss': 0.8045336077379626} | train loss {'Reaction outcome loss': 0.8088642736194563, 'Total loss': 0.8088642736194563}
2022-11-23 00:17:45,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:45,661 INFO:     Epoch: 77
2022-11-23 00:17:46,512 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8002432820408844, 'Total loss': 0.8002432820408844} | train loss {'Reaction outcome loss': 0.8034168627174174, 'Total loss': 0.8034168627174174}
2022-11-23 00:17:46,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:46,512 INFO:     Epoch: 78
2022-11-23 00:17:47,370 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8049926272658414, 'Total loss': 0.8049926272658414} | train loss {'Reaction outcome loss': 0.8071053128262036, 'Total loss': 0.8071053128262036}
2022-11-23 00:17:47,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:47,371 INFO:     Epoch: 79
2022-11-23 00:17:48,193 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8125154417614604, 'Total loss': 0.8125154417614604} | train loss {'Reaction outcome loss': 0.8020995210428707, 'Total loss': 0.8020995210428707}
2022-11-23 00:17:48,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:48,193 INFO:     Epoch: 80
2022-11-23 00:17:49,083 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8248437220274016, 'Total loss': 0.8248437220274016} | train loss {'Reaction outcome loss': 0.8037994259693584, 'Total loss': 0.8037994259693584}
2022-11-23 00:17:49,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:49,084 INFO:     Epoch: 81
2022-11-23 00:17:49,919 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8192572170911834, 'Total loss': 0.8192572170911834} | train loss {'Reaction outcome loss': 0.8106752697561608, 'Total loss': 0.8106752697561608}
2022-11-23 00:17:49,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:49,919 INFO:     Epoch: 82
2022-11-23 00:17:50,758 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.813699531000714, 'Total loss': 0.813699531000714} | train loss {'Reaction outcome loss': 0.8027905896306038, 'Total loss': 0.8027905896306038}
2022-11-23 00:17:50,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:50,758 INFO:     Epoch: 83
2022-11-23 00:17:51,575 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8133765001629674, 'Total loss': 0.8133765001629674} | train loss {'Reaction outcome loss': 0.8039538502448895, 'Total loss': 0.8039538502448895}
2022-11-23 00:17:51,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:51,576 INFO:     Epoch: 84
2022-11-23 00:17:52,415 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8171499302220899, 'Total loss': 0.8171499302220899} | train loss {'Reaction outcome loss': 0.8044151192317244, 'Total loss': 0.8044151192317244}
2022-11-23 00:17:52,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:52,415 INFO:     Epoch: 85
2022-11-23 00:17:53,272 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8109768019166104, 'Total loss': 0.8109768019166104} | train loss {'Reaction outcome loss': 0.8048658686094596, 'Total loss': 0.8048658686094596}
2022-11-23 00:17:53,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:53,273 INFO:     Epoch: 86
2022-11-23 00:17:54,081 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8283475769120593, 'Total loss': 0.8283475769120593} | train loss {'Reaction outcome loss': 0.8066319338366633, 'Total loss': 0.8066319338366633}
2022-11-23 00:17:54,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:54,082 INFO:     Epoch: 87
2022-11-23 00:17:54,927 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8302627781102824, 'Total loss': 0.8302627781102824} | train loss {'Reaction outcome loss': 0.8074318077720579, 'Total loss': 0.8074318077720579}
2022-11-23 00:17:54,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:54,927 INFO:     Epoch: 88
2022-11-23 00:17:55,773 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8204751686994419, 'Total loss': 0.8204751686994419} | train loss {'Reaction outcome loss': 0.8097282930231485, 'Total loss': 0.8097282930231485}
2022-11-23 00:17:55,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:55,774 INFO:     Epoch: 89
2022-11-23 00:17:56,611 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8196799311526987, 'Total loss': 0.8196799311526987} | train loss {'Reaction outcome loss': 0.805753374930288, 'Total loss': 0.805753374930288}
2022-11-23 00:17:56,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:56,611 INFO:     Epoch: 90
2022-11-23 00:17:57,423 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8372388648432355, 'Total loss': 0.8372388648432355} | train loss {'Reaction outcome loss': 0.8006881733165413, 'Total loss': 0.8006881733165413}
2022-11-23 00:17:57,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:57,423 INFO:     Epoch: 91
2022-11-23 00:17:58,279 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8090319037437439, 'Total loss': 0.8090319037437439} | train loss {'Reaction outcome loss': 0.8020042731869416, 'Total loss': 0.8020042731869416}
2022-11-23 00:17:58,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:58,280 INFO:     Epoch: 92
2022-11-23 00:17:59,119 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8194501393063124, 'Total loss': 0.8194501393063124} | train loss {'Reaction outcome loss': 0.8112488034807268, 'Total loss': 0.8112488034807268}
2022-11-23 00:17:59,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:59,120 INFO:     Epoch: 93
2022-11-23 00:17:59,946 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8104874096637549, 'Total loss': 0.8104874096637549} | train loss {'Reaction outcome loss': 0.80324116483575, 'Total loss': 0.80324116483575}
2022-11-23 00:17:59,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:17:59,946 INFO:     Epoch: 94
2022-11-23 00:18:00,829 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.833092202280843, 'Total loss': 0.833092202280843} | train loss {'Reaction outcome loss': 0.8066688118899454, 'Total loss': 0.8066688118899454}
2022-11-23 00:18:00,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:00,830 INFO:     Epoch: 95
2022-11-23 00:18:01,711 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8057630013587863, 'Total loss': 0.8057630013587863} | train loss {'Reaction outcome loss': 0.8046852108396467, 'Total loss': 0.8046852108396467}
2022-11-23 00:18:01,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:01,711 INFO:     Epoch: 96
2022-11-23 00:18:02,561 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8200896170943283, 'Total loss': 0.8200896170943283} | train loss {'Reaction outcome loss': 0.8035608149576382, 'Total loss': 0.8035608149576382}
2022-11-23 00:18:02,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:02,562 INFO:     Epoch: 97
2022-11-23 00:18:03,395 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8330215673113979, 'Total loss': 0.8330215673113979} | train loss {'Reaction outcome loss': 0.8063488373013793, 'Total loss': 0.8063488373013793}
2022-11-23 00:18:03,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:03,395 INFO:     Epoch: 98
2022-11-23 00:18:04,240 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.820086445919303, 'Total loss': 0.820086445919303} | train loss {'Reaction outcome loss': 0.8073951882905648, 'Total loss': 0.8073951882905648}
2022-11-23 00:18:04,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:04,240 INFO:     Epoch: 99
2022-11-23 00:18:05,073 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8160431620686553, 'Total loss': 0.8160431620686553} | train loss {'Reaction outcome loss': 0.8057507129966236, 'Total loss': 0.8057507129966236}
2022-11-23 00:18:05,074 INFO:     Best model found after epoch 50 of 100.
2022-11-23 00:18:05,074 INFO:   Done with stage: TRAINING
2022-11-23 00:18:05,074 INFO:   Starting stage: EVALUATION
2022-11-23 00:18:05,212 INFO:   Done with stage: EVALUATION
2022-11-23 00:18:05,212 INFO:   Leaving out SEQ value Fold_9
2022-11-23 00:18:05,225 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:18:05,226 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:18:05,912 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:18:05,912 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:18:05,984 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:18:05,984 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:18:05,984 INFO:     No hyperparam tuning for this model
2022-11-23 00:18:05,984 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:18:05,984 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:18:05,985 INFO:     None feature selector for col prot
2022-11-23 00:18:05,985 INFO:     None feature selector for col prot
2022-11-23 00:18:05,985 INFO:     None feature selector for col prot
2022-11-23 00:18:05,986 INFO:     None feature selector for col chem
2022-11-23 00:18:05,986 INFO:     None feature selector for col chem
2022-11-23 00:18:05,986 INFO:     None feature selector for col chem
2022-11-23 00:18:05,986 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:18:05,986 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:18:05,988 INFO:     Number of params in model 168571
2022-11-23 00:18:05,991 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:18:05,992 INFO:   Starting stage: TRAINING
2022-11-23 00:18:06,052 INFO:     Val loss before train {'Reaction outcome loss': 1.073650992729447, 'Total loss': 1.073650992729447}
2022-11-23 00:18:06,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:06,053 INFO:     Epoch: 0
2022-11-23 00:18:06,883 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.888644124973904, 'Total loss': 0.888644124973904} | train loss {'Reaction outcome loss': 0.8642566946112675, 'Total loss': 0.8642566946112675}
2022-11-23 00:18:06,883 INFO:     Found new best model at epoch 0
2022-11-23 00:18:06,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:06,884 INFO:     Epoch: 1
2022-11-23 00:18:07,725 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8740155588496815, 'Total loss': 0.8740155588496815} | train loss {'Reaction outcome loss': 0.8364897957938885, 'Total loss': 0.8364897957938885}
2022-11-23 00:18:07,725 INFO:     Found new best model at epoch 1
2022-11-23 00:18:07,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:07,726 INFO:     Epoch: 2
2022-11-23 00:18:08,582 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8545818234031851, 'Total loss': 0.8545818234031851} | train loss {'Reaction outcome loss': 0.838952361813441, 'Total loss': 0.838952361813441}
2022-11-23 00:18:08,582 INFO:     Found new best model at epoch 2
2022-11-23 00:18:08,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:08,583 INFO:     Epoch: 3
2022-11-23 00:18:09,387 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8709003302184019, 'Total loss': 0.8709003302184019} | train loss {'Reaction outcome loss': 0.8263228204749856, 'Total loss': 0.8263228204749856}
2022-11-23 00:18:09,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:09,388 INFO:     Epoch: 4
2022-11-23 00:18:10,230 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8728301335464824, 'Total loss': 0.8728301335464824} | train loss {'Reaction outcome loss': 0.8286435982958991, 'Total loss': 0.8286435982958991}
2022-11-23 00:18:10,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:10,231 INFO:     Epoch: 5
2022-11-23 00:18:11,111 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8742054551839828, 'Total loss': 0.8742054551839828} | train loss {'Reaction outcome loss': 0.8329296829970742, 'Total loss': 0.8329296829970742}
2022-11-23 00:18:11,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:11,112 INFO:     Epoch: 6
2022-11-23 00:18:11,965 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8348196521401405, 'Total loss': 0.8348196521401405} | train loss {'Reaction outcome loss': 0.8286659170982809, 'Total loss': 0.8286659170982809}
2022-11-23 00:18:11,965 INFO:     Found new best model at epoch 6
2022-11-23 00:18:11,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:11,966 INFO:     Epoch: 7
2022-11-23 00:18:12,843 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8537768653847955, 'Total loss': 0.8537768653847955} | train loss {'Reaction outcome loss': 0.8214551832994469, 'Total loss': 0.8214551832994469}
2022-11-23 00:18:12,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:12,844 INFO:     Epoch: 8
2022-11-23 00:18:13,658 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8498175198381598, 'Total loss': 0.8498175198381598} | train loss {'Reaction outcome loss': 0.8202000966197566, 'Total loss': 0.8202000966197566}
2022-11-23 00:18:13,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:13,658 INFO:     Epoch: 9
2022-11-23 00:18:14,484 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8574242598631165, 'Total loss': 0.8574242598631165} | train loss {'Reaction outcome loss': 0.8189165245907509, 'Total loss': 0.8189165245907509}
2022-11-23 00:18:14,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:14,484 INFO:     Epoch: 10
2022-11-23 00:18:15,286 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8763898123394359, 'Total loss': 0.8763898123394359} | train loss {'Reaction outcome loss': 0.8236549174496037, 'Total loss': 0.8236549174496037}
2022-11-23 00:18:15,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:15,287 INFO:     Epoch: 11
2022-11-23 00:18:16,106 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8502548763697798, 'Total loss': 0.8502548763697798} | train loss {'Reaction outcome loss': 0.8207319043425896, 'Total loss': 0.8207319043425896}
2022-11-23 00:18:16,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:16,106 INFO:     Epoch: 12
2022-11-23 00:18:16,908 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8416775614023209, 'Total loss': 0.8416775614023209} | train loss {'Reaction outcome loss': 0.8151867826457931, 'Total loss': 0.8151867826457931}
2022-11-23 00:18:16,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:16,908 INFO:     Epoch: 13
2022-11-23 00:18:17,733 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.872611326250163, 'Total loss': 0.872611326250163} | train loss {'Reaction outcome loss': 0.8177425276171341, 'Total loss': 0.8177425276171341}
2022-11-23 00:18:17,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:17,733 INFO:     Epoch: 14
2022-11-23 00:18:18,552 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8582021390849893, 'Total loss': 0.8582021390849893} | train loss {'Reaction outcome loss': 0.8143648826158963, 'Total loss': 0.8143648826158963}
2022-11-23 00:18:18,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:18,553 INFO:     Epoch: 15
2022-11-23 00:18:19,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8461730141531337, 'Total loss': 0.8461730141531337} | train loss {'Reaction outcome loss': 0.813387755922943, 'Total loss': 0.813387755922943}
2022-11-23 00:18:19,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:19,386 INFO:     Epoch: 16
2022-11-23 00:18:20,259 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.850909644907171, 'Total loss': 0.850909644907171} | train loss {'Reaction outcome loss': 0.8105335207844553, 'Total loss': 0.8105335207844553}
2022-11-23 00:18:20,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:20,259 INFO:     Epoch: 17
2022-11-23 00:18:21,063 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8713615198027004, 'Total loss': 0.8713615198027004} | train loss {'Reaction outcome loss': 0.8094313803472017, 'Total loss': 0.8094313803472017}
2022-11-23 00:18:21,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:21,063 INFO:     Epoch: 18
2022-11-23 00:18:21,863 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8518756634809754, 'Total loss': 0.8518756634809754} | train loss {'Reaction outcome loss': 0.8195139106951261, 'Total loss': 0.8195139106951261}
2022-11-23 00:18:21,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:21,863 INFO:     Epoch: 19
2022-11-23 00:18:22,669 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8523669364777479, 'Total loss': 0.8523669364777479} | train loss {'Reaction outcome loss': 0.8160487768741754, 'Total loss': 0.8160487768741754}
2022-11-23 00:18:22,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:22,669 INFO:     Epoch: 20
2022-11-23 00:18:23,469 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8340696773745797, 'Total loss': 0.8340696773745797} | train loss {'Reaction outcome loss': 0.8086034239303728, 'Total loss': 0.8086034239303728}
2022-11-23 00:18:23,469 INFO:     Found new best model at epoch 20
2022-11-23 00:18:23,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:23,470 INFO:     Epoch: 21
2022-11-23 00:18:24,268 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8518393832174215, 'Total loss': 0.8518393832174215} | train loss {'Reaction outcome loss': 0.8062236289746365, 'Total loss': 0.8062236289746365}
2022-11-23 00:18:24,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:24,269 INFO:     Epoch: 22
2022-11-23 00:18:25,071 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.847895241596482, 'Total loss': 0.847895241596482} | train loss {'Reaction outcome loss': 0.8102761039186103, 'Total loss': 0.8102761039186103}
2022-11-23 00:18:25,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:25,071 INFO:     Epoch: 23
2022-11-23 00:18:25,904 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8858081224289808, 'Total loss': 0.8858081224289808} | train loss {'Reaction outcome loss': 0.8088987335140406, 'Total loss': 0.8088987335140406}
2022-11-23 00:18:25,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:25,905 INFO:     Epoch: 24
2022-11-23 00:18:26,694 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8446692966602065, 'Total loss': 0.8446692966602065} | train loss {'Reaction outcome loss': 0.8116133681193054, 'Total loss': 0.8116133681193054}
2022-11-23 00:18:26,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:26,696 INFO:     Epoch: 25
2022-11-23 00:18:27,570 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8333221159198068, 'Total loss': 0.8333221159198068} | train loss {'Reaction outcome loss': 0.8123253050603365, 'Total loss': 0.8123253050603365}
2022-11-23 00:18:27,570 INFO:     Found new best model at epoch 25
2022-11-23 00:18:27,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:27,571 INFO:     Epoch: 26
2022-11-23 00:18:28,378 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8692564652724699, 'Total loss': 0.8692564652724699} | train loss {'Reaction outcome loss': 0.8066277733442151, 'Total loss': 0.8066277733442151}
2022-11-23 00:18:28,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:28,379 INFO:     Epoch: 27
2022-11-23 00:18:29,206 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8333024646748196, 'Total loss': 0.8333024646748196} | train loss {'Reaction outcome loss': 0.8104414793131082, 'Total loss': 0.8104414793131082}
2022-11-23 00:18:29,207 INFO:     Found new best model at epoch 27
2022-11-23 00:18:29,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:29,207 INFO:     Epoch: 28
2022-11-23 00:18:30,001 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8450291942466389, 'Total loss': 0.8450291942466389} | train loss {'Reaction outcome loss': 0.8132928863228092, 'Total loss': 0.8132928863228092}
2022-11-23 00:18:30,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:30,002 INFO:     Epoch: 29
2022-11-23 00:18:30,860 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8557077768174085, 'Total loss': 0.8557077768174085} | train loss {'Reaction outcome loss': 0.8080146582080767, 'Total loss': 0.8080146582080767}
2022-11-23 00:18:30,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:30,860 INFO:     Epoch: 30
2022-11-23 00:18:31,684 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8527319018136371, 'Total loss': 0.8527319018136371} | train loss {'Reaction outcome loss': 0.8150335827819731, 'Total loss': 0.8150335827819731}
2022-11-23 00:18:31,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:31,684 INFO:     Epoch: 31
2022-11-23 00:18:32,479 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8557493666356261, 'Total loss': 0.8557493666356261} | train loss {'Reaction outcome loss': 0.8092948323801944, 'Total loss': 0.8092948323801944}
2022-11-23 00:18:32,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:32,480 INFO:     Epoch: 32
2022-11-23 00:18:33,271 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8510545654730364, 'Total loss': 0.8510545654730364} | train loss {'Reaction outcome loss': 0.8163396343287186, 'Total loss': 0.8163396343287186}
2022-11-23 00:18:33,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:33,272 INFO:     Epoch: 33
2022-11-23 00:18:34,084 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8298176283186133, 'Total loss': 0.8298176283186133} | train loss {'Reaction outcome loss': 0.8131423849567228, 'Total loss': 0.8131423849567228}
2022-11-23 00:18:34,084 INFO:     Found new best model at epoch 33
2022-11-23 00:18:34,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:34,085 INFO:     Epoch: 34
2022-11-23 00:18:34,893 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8534853932532397, 'Total loss': 0.8534853932532397} | train loss {'Reaction outcome loss': 0.8139799030927511, 'Total loss': 0.8139799030927511}
2022-11-23 00:18:34,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:34,894 INFO:     Epoch: 35
2022-11-23 00:18:35,669 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8263356644998897, 'Total loss': 0.8263356644998897} | train loss {'Reaction outcome loss': 0.8123705148214271, 'Total loss': 0.8123705148214271}
2022-11-23 00:18:35,669 INFO:     Found new best model at epoch 35
2022-11-23 00:18:35,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:35,670 INFO:     Epoch: 36
2022-11-23 00:18:36,492 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8488435399803248, 'Total loss': 0.8488435399803248} | train loss {'Reaction outcome loss': 0.8096452104417902, 'Total loss': 0.8096452104417902}
2022-11-23 00:18:36,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:36,492 INFO:     Epoch: 37
2022-11-23 00:18:37,263 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8760300007733431, 'Total loss': 0.8760300007733431} | train loss {'Reaction outcome loss': 0.8034293002445205, 'Total loss': 0.8034293002445205}
2022-11-23 00:18:37,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:37,263 INFO:     Epoch: 38
2022-11-23 00:18:38,078 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8409908247942274, 'Total loss': 0.8409908247942274} | train loss {'Reaction outcome loss': 0.8079048705547445, 'Total loss': 0.8079048705547445}
2022-11-23 00:18:38,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:38,078 INFO:     Epoch: 39
2022-11-23 00:18:38,888 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8511687273328955, 'Total loss': 0.8511687273328955} | train loss {'Reaction outcome loss': 0.8032033285390028, 'Total loss': 0.8032033285390028}
2022-11-23 00:18:38,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:38,888 INFO:     Epoch: 40
2022-11-23 00:18:39,671 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8307158025828275, 'Total loss': 0.8307158025828275} | train loss {'Reaction outcome loss': 0.8053733410864223, 'Total loss': 0.8053733410864223}
2022-11-23 00:18:39,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:39,672 INFO:     Epoch: 41
2022-11-23 00:18:40,487 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8316132195971229, 'Total loss': 0.8316132195971229} | train loss {'Reaction outcome loss': 0.804973524712358, 'Total loss': 0.804973524712358}
2022-11-23 00:18:40,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:40,487 INFO:     Epoch: 42
2022-11-23 00:18:41,317 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.84964508427815, 'Total loss': 0.84964508427815} | train loss {'Reaction outcome loss': 0.8075269481189821, 'Total loss': 0.8075269481189821}
2022-11-23 00:18:41,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:41,317 INFO:     Epoch: 43
2022-11-23 00:18:42,149 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8178326230157505, 'Total loss': 0.8178326230157505} | train loss {'Reaction outcome loss': 0.811914758161012, 'Total loss': 0.811914758161012}
2022-11-23 00:18:42,149 INFO:     Found new best model at epoch 43
2022-11-23 00:18:42,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:42,150 INFO:     Epoch: 44
2022-11-23 00:18:42,963 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8301703157750043, 'Total loss': 0.8301703157750043} | train loss {'Reaction outcome loss': 0.8101765278741898, 'Total loss': 0.8101765278741898}
2022-11-23 00:18:42,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:42,964 INFO:     Epoch: 45
2022-11-23 00:18:43,784 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8563558262857524, 'Total loss': 0.8563558262857524} | train loss {'Reaction outcome loss': 0.8120783463663418, 'Total loss': 0.8120783463663418}
2022-11-23 00:18:43,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:43,784 INFO:     Epoch: 46
2022-11-23 00:18:44,574 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8364786458286372, 'Total loss': 0.8364786458286372} | train loss {'Reaction outcome loss': 0.817191945879083, 'Total loss': 0.817191945879083}
2022-11-23 00:18:44,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:44,575 INFO:     Epoch: 47
2022-11-23 00:18:45,365 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8454765271056782, 'Total loss': 0.8454765271056782} | train loss {'Reaction outcome loss': 0.8163859357959345, 'Total loss': 0.8163859357959345}
2022-11-23 00:18:45,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:45,366 INFO:     Epoch: 48
2022-11-23 00:18:46,142 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8494403267448599, 'Total loss': 0.8494403267448599} | train loss {'Reaction outcome loss': 0.8133093790728071, 'Total loss': 0.8133093790728071}
2022-11-23 00:18:46,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:46,142 INFO:     Epoch: 49
2022-11-23 00:18:46,951 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8538485453887419, 'Total loss': 0.8538485453887419} | train loss {'Reaction outcome loss': 0.8071811912272141, 'Total loss': 0.8071811912272141}
2022-11-23 00:18:46,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:46,951 INFO:     Epoch: 50
2022-11-23 00:18:47,746 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8263891671191562, 'Total loss': 0.8263891671191562} | train loss {'Reaction outcome loss': 0.8090763578289434, 'Total loss': 0.8090763578289434}
2022-11-23 00:18:47,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:47,747 INFO:     Epoch: 51
2022-11-23 00:18:48,542 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8405031534758481, 'Total loss': 0.8405031534758481} | train loss {'Reaction outcome loss': 0.8062114456163244, 'Total loss': 0.8062114456163244}
2022-11-23 00:18:48,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:48,543 INFO:     Epoch: 52
2022-11-23 00:18:49,385 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8603305173191157, 'Total loss': 0.8603305173191157} | train loss {'Reaction outcome loss': 0.8037608734026611, 'Total loss': 0.8037608734026611}
2022-11-23 00:18:49,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:49,385 INFO:     Epoch: 53
2022-11-23 00:18:50,177 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8317071307789196, 'Total loss': 0.8317071307789196} | train loss {'Reaction outcome loss': 0.8097798192669988, 'Total loss': 0.8097798192669988}
2022-11-23 00:18:50,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:50,177 INFO:     Epoch: 54
2022-11-23 00:18:51,004 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8384278281168505, 'Total loss': 0.8384278281168505} | train loss {'Reaction outcome loss': 0.8054481665132499, 'Total loss': 0.8054481665132499}
2022-11-23 00:18:51,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:51,004 INFO:     Epoch: 55
2022-11-23 00:18:51,840 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8667158823121678, 'Total loss': 0.8667158823121678} | train loss {'Reaction outcome loss': 0.805036301796253, 'Total loss': 0.805036301796253}
2022-11-23 00:18:51,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:51,840 INFO:     Epoch: 56
2022-11-23 00:18:52,644 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8428961031816222, 'Total loss': 0.8428961031816222} | train loss {'Reaction outcome loss': 0.8099713432885375, 'Total loss': 0.8099713432885375}
2022-11-23 00:18:52,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:52,645 INFO:     Epoch: 57
2022-11-23 00:18:53,500 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8399275595491583, 'Total loss': 0.8399275595491583} | train loss {'Reaction outcome loss': 0.8163813923293279, 'Total loss': 0.8163813923293279}
2022-11-23 00:18:53,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:53,501 INFO:     Epoch: 58
2022-11-23 00:18:54,324 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8435954390601679, 'Total loss': 0.8435954390601679} | train loss {'Reaction outcome loss': 0.8123663712730292, 'Total loss': 0.8123663712730292}
2022-11-23 00:18:54,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:54,325 INFO:     Epoch: 59
2022-11-23 00:18:55,186 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8485076441006227, 'Total loss': 0.8485076441006227} | train loss {'Reaction outcome loss': 0.8060102754608098, 'Total loss': 0.8060102754608098}
2022-11-23 00:18:55,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:55,187 INFO:     Epoch: 60
2022-11-23 00:18:56,001 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8353596410968087, 'Total loss': 0.8353596410968087} | train loss {'Reaction outcome loss': 0.8153091007881319, 'Total loss': 0.8153091007881319}
2022-11-23 00:18:56,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:56,002 INFO:     Epoch: 61
2022-11-23 00:18:56,834 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8401030952280218, 'Total loss': 0.8401030952280218} | train loss {'Reaction outcome loss': 0.8237175803314819, 'Total loss': 0.8237175803314819}
2022-11-23 00:18:56,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:56,835 INFO:     Epoch: 62
2022-11-23 00:18:57,655 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8513984632762995, 'Total loss': 0.8513984632762995} | train loss {'Reaction outcome loss': 0.812934840256386, 'Total loss': 0.812934840256386}
2022-11-23 00:18:57,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:57,656 INFO:     Epoch: 63
2022-11-23 00:18:58,464 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8497836874289946, 'Total loss': 0.8497836874289946} | train loss {'Reaction outcome loss': 0.8058160119030157, 'Total loss': 0.8058160119030157}
2022-11-23 00:18:58,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:58,465 INFO:     Epoch: 64
2022-11-23 00:18:59,302 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8504079160365191, 'Total loss': 0.8504079160365191} | train loss {'Reaction outcome loss': 0.8027988710263481, 'Total loss': 0.8027988710263481}
2022-11-23 00:18:59,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:18:59,302 INFO:     Epoch: 65
2022-11-23 00:19:00,118 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8500607243993066, 'Total loss': 0.8500607243993066} | train loss {'Reaction outcome loss': 0.8098271782340308, 'Total loss': 0.8098271782340308}
2022-11-23 00:19:00,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:00,118 INFO:     Epoch: 66
2022-11-23 00:19:00,905 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8452012823386625, 'Total loss': 0.8452012823386625} | train loss {'Reaction outcome loss': 0.8074850037030363, 'Total loss': 0.8074850037030363}
2022-11-23 00:19:00,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:00,905 INFO:     Epoch: 67
2022-11-23 00:19:01,705 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8457816039974039, 'Total loss': 0.8457816039974039} | train loss {'Reaction outcome loss': 0.8063357642546356, 'Total loss': 0.8063357642546356}
2022-11-23 00:19:01,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:01,705 INFO:     Epoch: 68
2022-11-23 00:19:02,513 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8273790431293574, 'Total loss': 0.8273790431293574} | train loss {'Reaction outcome loss': 0.8073266507899352, 'Total loss': 0.8073266507899352}
2022-11-23 00:19:02,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:02,513 INFO:     Epoch: 69
2022-11-23 00:19:03,313 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8407267013734038, 'Total loss': 0.8407267013734038} | train loss {'Reaction outcome loss': 0.8056762734888053, 'Total loss': 0.8056762734888053}
2022-11-23 00:19:03,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:03,314 INFO:     Epoch: 70
2022-11-23 00:19:04,126 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8374743034893816, 'Total loss': 0.8374743034893816} | train loss {'Reaction outcome loss': 0.8140896526184159, 'Total loss': 0.8140896526184159}
2022-11-23 00:19:04,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:04,127 INFO:     Epoch: 71
2022-11-23 00:19:04,964 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8472320166501132, 'Total loss': 0.8472320166501132} | train loss {'Reaction outcome loss': 0.8079620780732467, 'Total loss': 0.8079620780732467}
2022-11-23 00:19:04,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:04,964 INFO:     Epoch: 72
2022-11-23 00:19:05,752 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8520244021307338, 'Total loss': 0.8520244021307338} | train loss {'Reaction outcome loss': 0.8109753435922538, 'Total loss': 0.8109753435922538}
2022-11-23 00:19:05,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:05,753 INFO:     Epoch: 73
2022-11-23 00:19:06,581 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8445253311233087, 'Total loss': 0.8445253311233087} | train loss {'Reaction outcome loss': 0.8091819262215001, 'Total loss': 0.8091819262215001}
2022-11-23 00:19:06,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:06,581 INFO:     Epoch: 74
2022-11-23 00:19:07,420 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8499157279729843, 'Total loss': 0.8499157279729843} | train loss {'Reaction outcome loss': 0.8060780097598489, 'Total loss': 0.8060780097598489}
2022-11-23 00:19:07,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:07,420 INFO:     Epoch: 75
2022-11-23 00:19:08,220 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8512772226875479, 'Total loss': 0.8512772226875479} | train loss {'Reaction outcome loss': 0.8119474850926804, 'Total loss': 0.8119474850926804}
2022-11-23 00:19:08,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:08,220 INFO:     Epoch: 76
2022-11-23 00:19:09,043 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8449654077941721, 'Total loss': 0.8449654077941721} | train loss {'Reaction outcome loss': 0.8153800114928952, 'Total loss': 0.8153800114928952}
2022-11-23 00:19:09,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:09,043 INFO:     Epoch: 77
2022-11-23 00:19:09,827 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8428043980490078, 'Total loss': 0.8428043980490078} | train loss {'Reaction outcome loss': 0.8089781868071692, 'Total loss': 0.8089781868071692}
2022-11-23 00:19:09,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:09,827 INFO:     Epoch: 78
2022-11-23 00:19:10,651 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8302837908267975, 'Total loss': 0.8302837908267975} | train loss {'Reaction outcome loss': 0.807862664765192, 'Total loss': 0.807862664765192}
2022-11-23 00:19:10,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:10,652 INFO:     Epoch: 79
2022-11-23 00:19:11,445 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8310669518329881, 'Total loss': 0.8310669518329881} | train loss {'Reaction outcome loss': 0.8148533674145517, 'Total loss': 0.8148533674145517}
2022-11-23 00:19:11,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:11,445 INFO:     Epoch: 80
2022-11-23 00:19:12,261 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8619870109991594, 'Total loss': 0.8619870109991594} | train loss {'Reaction outcome loss': 0.8120049798054251, 'Total loss': 0.8120049798054251}
2022-11-23 00:19:12,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:12,262 INFO:     Epoch: 81
2022-11-23 00:19:13,111 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8351520442149856, 'Total loss': 0.8351520442149856} | train loss {'Reaction outcome loss': 0.8121471417095014, 'Total loss': 0.8121471417095014}
2022-11-23 00:19:13,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:13,111 INFO:     Epoch: 82
2022-11-23 00:19:13,938 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8302362012592229, 'Total loss': 0.8302362012592229} | train loss {'Reaction outcome loss': 0.8043729849913825, 'Total loss': 0.8043729849913825}
2022-11-23 00:19:13,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:13,938 INFO:     Epoch: 83
2022-11-23 00:19:14,743 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.843811344016682, 'Total loss': 0.843811344016682} | train loss {'Reaction outcome loss': 0.8097881215665987, 'Total loss': 0.8097881215665987}
2022-11-23 00:19:14,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:14,743 INFO:     Epoch: 84
2022-11-23 00:19:15,562 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.852171625603329, 'Total loss': 0.852171625603329} | train loss {'Reaction outcome loss': 0.8111810708938823, 'Total loss': 0.8111810708938823}
2022-11-23 00:19:15,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:15,562 INFO:     Epoch: 85
2022-11-23 00:19:16,396 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8254365683956579, 'Total loss': 0.8254365683956579} | train loss {'Reaction outcome loss': 0.8141862695757677, 'Total loss': 0.8141862695757677}
2022-11-23 00:19:16,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:16,398 INFO:     Epoch: 86
2022-11-23 00:19:17,245 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.839246968654069, 'Total loss': 0.839246968654069} | train loss {'Reaction outcome loss': 0.8106607378871455, 'Total loss': 0.8106607378871455}
2022-11-23 00:19:17,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:17,246 INFO:     Epoch: 87
2022-11-23 00:19:18,087 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8489693464203314, 'Total loss': 0.8489693464203314} | train loss {'Reaction outcome loss': 0.8024476454084218, 'Total loss': 0.8024476454084218}
2022-11-23 00:19:18,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:18,087 INFO:     Epoch: 88
2022-11-23 00:19:18,895 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8230760253288529, 'Total loss': 0.8230760253288529} | train loss {'Reaction outcome loss': 0.8086264730706388, 'Total loss': 0.8086264730706388}
2022-11-23 00:19:18,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:18,896 INFO:     Epoch: 89
2022-11-23 00:19:19,727 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8236449523405596, 'Total loss': 0.8236449523405596} | train loss {'Reaction outcome loss': 0.8094116852351045, 'Total loss': 0.8094116852351045}
2022-11-23 00:19:19,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:19,727 INFO:     Epoch: 90
2022-11-23 00:19:20,529 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8310209661722183, 'Total loss': 0.8310209661722183} | train loss {'Reaction outcome loss': 0.8149577078790318, 'Total loss': 0.8149577078790318}
2022-11-23 00:19:20,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:20,529 INFO:     Epoch: 91
2022-11-23 00:19:21,337 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8473110761154782, 'Total loss': 0.8473110761154782} | train loss {'Reaction outcome loss': 0.8175382520023146, 'Total loss': 0.8175382520023146}
2022-11-23 00:19:21,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:21,337 INFO:     Epoch: 92
2022-11-23 00:19:22,158 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8381130993366241, 'Total loss': 0.8381130993366241} | train loss {'Reaction outcome loss': 0.8008185298095348, 'Total loss': 0.8008185298095348}
2022-11-23 00:19:22,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:22,159 INFO:     Epoch: 93
2022-11-23 00:19:22,957 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.83637285977602, 'Total loss': 0.83637285977602} | train loss {'Reaction outcome loss': 0.8151652249488753, 'Total loss': 0.8151652249488753}
2022-11-23 00:19:22,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:22,957 INFO:     Epoch: 94
2022-11-23 00:19:23,790 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8384274400093339, 'Total loss': 0.8384274400093339} | train loss {'Reaction outcome loss': 0.8049029621940392, 'Total loss': 0.8049029621940392}
2022-11-23 00:19:23,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:23,790 INFO:     Epoch: 95
2022-11-23 00:19:24,572 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8452653708783063, 'Total loss': 0.8452653708783063} | train loss {'Reaction outcome loss': 0.8056811956077935, 'Total loss': 0.8056811956077935}
2022-11-23 00:19:24,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:24,572 INFO:     Epoch: 96
2022-11-23 00:19:25,419 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8577975976196203, 'Total loss': 0.8577975976196203} | train loss {'Reaction outcome loss': 0.8113515507354427, 'Total loss': 0.8113515507354427}
2022-11-23 00:19:25,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:25,419 INFO:     Epoch: 97
2022-11-23 00:19:26,229 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8355992775071751, 'Total loss': 0.8355992775071751} | train loss {'Reaction outcome loss': 0.8142156351191795, 'Total loss': 0.8142156351191795}
2022-11-23 00:19:26,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:26,230 INFO:     Epoch: 98
2022-11-23 00:19:27,040 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8353796567429196, 'Total loss': 0.8353796567429196} | train loss {'Reaction outcome loss': 0.8078476655097143, 'Total loss': 0.8078476655097143}
2022-11-23 00:19:27,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:27,040 INFO:     Epoch: 99
2022-11-23 00:19:27,868 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8392593427137895, 'Total loss': 0.8392593427137895} | train loss {'Reaction outcome loss': 0.801268005359028, 'Total loss': 0.801268005359028}
2022-11-23 00:19:27,868 INFO:     Best model found after epoch 44 of 100.
2022-11-23 00:19:27,869 INFO:   Done with stage: TRAINING
2022-11-23 00:19:27,869 INFO:   Starting stage: EVALUATION
2022-11-23 00:19:27,995 INFO:   Done with stage: EVALUATION
2022-11-23 00:19:28,003 INFO:   Leaving out SEQ value Fold_0
2022-11-23 00:19:28,016 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:19:28,016 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:19:28,684 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:19:28,685 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:19:28,769 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:19:28,769 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:19:28,769 INFO:     No hyperparam tuning for this model
2022-11-23 00:19:28,769 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:19:28,769 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:19:28,770 INFO:     None feature selector for col prot
2022-11-23 00:19:28,770 INFO:     None feature selector for col prot
2022-11-23 00:19:28,770 INFO:     None feature selector for col prot
2022-11-23 00:19:28,771 INFO:     None feature selector for col chem
2022-11-23 00:19:28,771 INFO:     None feature selector for col chem
2022-11-23 00:19:28,771 INFO:     None feature selector for col chem
2022-11-23 00:19:28,771 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:19:28,771 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:19:28,772 INFO:     Number of params in model 168571
2022-11-23 00:19:28,776 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:19:28,776 INFO:   Starting stage: TRAINING
2022-11-23 00:19:28,834 INFO:     Val loss before train {'Reaction outcome loss': 0.9659498144279827, 'Total loss': 0.9659498144279827}
2022-11-23 00:19:28,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:28,834 INFO:     Epoch: 0
2022-11-23 00:19:29,662 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8035233880985867, 'Total loss': 0.8035233880985867} | train loss {'Reaction outcome loss': 0.8898595163696691, 'Total loss': 0.8898595163696691}
2022-11-23 00:19:29,662 INFO:     Found new best model at epoch 0
2022-11-23 00:19:29,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:29,663 INFO:     Epoch: 1
2022-11-23 00:19:30,451 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.790958056395704, 'Total loss': 0.790958056395704} | train loss {'Reaction outcome loss': 0.8671180193240826, 'Total loss': 0.8671180193240826}
2022-11-23 00:19:30,451 INFO:     Found new best model at epoch 1
2022-11-23 00:19:30,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:30,452 INFO:     Epoch: 2
2022-11-23 00:19:31,253 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8111867227337577, 'Total loss': 0.8111867227337577} | train loss {'Reaction outcome loss': 0.8462711675205694, 'Total loss': 0.8462711675205694}
2022-11-23 00:19:31,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:31,254 INFO:     Epoch: 3
2022-11-23 00:19:32,062 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8135907460342754, 'Total loss': 0.8135907460342754} | train loss {'Reaction outcome loss': 0.833529559767198, 'Total loss': 0.833529559767198}
2022-11-23 00:19:32,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:32,063 INFO:     Epoch: 4
2022-11-23 00:19:32,865 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8134204183112491, 'Total loss': 0.8134204183112491} | train loss {'Reaction outcome loss': 0.835297268291234, 'Total loss': 0.835297268291234}
2022-11-23 00:19:32,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:32,865 INFO:     Epoch: 5
2022-11-23 00:19:33,670 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7868806713006713, 'Total loss': 0.7868806713006713} | train loss {'Reaction outcome loss': 0.8330615381238914, 'Total loss': 0.8330615381238914}
2022-11-23 00:19:33,670 INFO:     Found new best model at epoch 5
2022-11-23 00:19:33,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:33,671 INFO:     Epoch: 6
2022-11-23 00:19:34,427 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7666979845274579, 'Total loss': 0.7666979845274579} | train loss {'Reaction outcome loss': 0.8344692248805814, 'Total loss': 0.8344692248805814}
2022-11-23 00:19:34,427 INFO:     Found new best model at epoch 6
2022-11-23 00:19:34,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:34,428 INFO:     Epoch: 7
2022-11-23 00:19:35,199 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7963467768647454, 'Total loss': 0.7963467768647454} | train loss {'Reaction outcome loss': 0.8324641695148066, 'Total loss': 0.8324641695148066}
2022-11-23 00:19:35,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:35,200 INFO:     Epoch: 8
2022-11-23 00:19:36,015 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8021052574569528, 'Total loss': 0.8021052574569528} | train loss {'Reaction outcome loss': 0.8322706015003838, 'Total loss': 0.8322706015003838}
2022-11-23 00:19:36,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:36,015 INFO:     Epoch: 9
2022-11-23 00:19:36,891 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8026825819503177, 'Total loss': 0.8026825819503177} | train loss {'Reaction outcome loss': 0.8416723732040962, 'Total loss': 0.8416723732040962}
2022-11-23 00:19:36,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:36,891 INFO:     Epoch: 10
2022-11-23 00:19:37,676 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7865124453197826, 'Total loss': 0.7865124453197826} | train loss {'Reaction outcome loss': 0.8219335125646128, 'Total loss': 0.8219335125646128}
2022-11-23 00:19:37,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:37,677 INFO:     Epoch: 11
2022-11-23 00:19:38,523 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7780908224257556, 'Total loss': 0.7780908224257556} | train loss {'Reaction outcome loss': 0.82173563063386, 'Total loss': 0.82173563063386}
2022-11-23 00:19:38,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:38,523 INFO:     Epoch: 12
2022-11-23 00:19:39,365 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.808875897391276, 'Total loss': 0.808875897391276} | train loss {'Reaction outcome loss': 0.8281158991912116, 'Total loss': 0.8281158991912116}
2022-11-23 00:19:39,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:39,365 INFO:     Epoch: 13
2022-11-23 00:19:40,176 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7793260528282686, 'Total loss': 0.7793260528282686} | train loss {'Reaction outcome loss': 0.8244627553079775, 'Total loss': 0.8244627553079775}
2022-11-23 00:19:40,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:40,176 INFO:     Epoch: 14
2022-11-23 00:19:41,042 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8132793070240454, 'Total loss': 0.8132793070240454} | train loss {'Reaction outcome loss': 0.819697165371556, 'Total loss': 0.819697165371556}
2022-11-23 00:19:41,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:41,042 INFO:     Epoch: 15
2022-11-23 00:19:41,880 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7805647897449407, 'Total loss': 0.7805647897449407} | train loss {'Reaction outcome loss': 0.8252771920279452, 'Total loss': 0.8252771920279452}
2022-11-23 00:19:41,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:41,880 INFO:     Epoch: 16
2022-11-23 00:19:42,701 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7813371792435646, 'Total loss': 0.7813371792435646} | train loss {'Reaction outcome loss': 0.8432539094556198, 'Total loss': 0.8432539094556198}
2022-11-23 00:19:42,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:42,702 INFO:     Epoch: 17
2022-11-23 00:19:43,536 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7847401161085475, 'Total loss': 0.7847401161085475} | train loss {'Reaction outcome loss': 0.8315109917026783, 'Total loss': 0.8315109917026783}
2022-11-23 00:19:43,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:43,536 INFO:     Epoch: 18
2022-11-23 00:19:44,373 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.792082201350819, 'Total loss': 0.792082201350819} | train loss {'Reaction outcome loss': 0.8219950816891937, 'Total loss': 0.8219950816891937}
2022-11-23 00:19:44,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:44,374 INFO:     Epoch: 19
2022-11-23 00:19:45,186 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.779878824271939, 'Total loss': 0.779878824271939} | train loss {'Reaction outcome loss': 0.8250399178821548, 'Total loss': 0.8250399178821548}
2022-11-23 00:19:45,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:45,186 INFO:     Epoch: 20
2022-11-23 00:19:46,043 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.792311471294273, 'Total loss': 0.792311471294273} | train loss {'Reaction outcome loss': 0.8250787629772295, 'Total loss': 0.8250787629772295}
2022-11-23 00:19:46,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:46,043 INFO:     Epoch: 21
2022-11-23 00:19:46,851 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7794830629771407, 'Total loss': 0.7794830629771407} | train loss {'Reaction outcome loss': 0.8225267707456944, 'Total loss': 0.8225267707456944}
2022-11-23 00:19:46,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:46,851 INFO:     Epoch: 22
2022-11-23 00:19:47,653 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.777430422604084, 'Total loss': 0.777430422604084} | train loss {'Reaction outcome loss': 0.8234449670864985, 'Total loss': 0.8234449670864985}
2022-11-23 00:19:47,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:47,654 INFO:     Epoch: 23
2022-11-23 00:19:48,478 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7829771929166534, 'Total loss': 0.7829771929166534} | train loss {'Reaction outcome loss': 0.8295687341738326, 'Total loss': 0.8295687341738326}
2022-11-23 00:19:48,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:48,478 INFO:     Epoch: 24
2022-11-23 00:19:49,234 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7627001106739044, 'Total loss': 0.7627001106739044} | train loss {'Reaction outcome loss': 0.8221251059640274, 'Total loss': 0.8221251059640274}
2022-11-23 00:19:49,234 INFO:     Found new best model at epoch 24
2022-11-23 00:19:49,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:49,235 INFO:     Epoch: 25
2022-11-23 00:19:50,117 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7866206304593519, 'Total loss': 0.7866206304593519} | train loss {'Reaction outcome loss': 0.8235593012228668, 'Total loss': 0.8235593012228668}
2022-11-23 00:19:50,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:50,117 INFO:     Epoch: 26
2022-11-23 00:19:50,922 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7955030724406242, 'Total loss': 0.7955030724406242} | train loss {'Reaction outcome loss': 0.8281076520319409, 'Total loss': 0.8281076520319409}
2022-11-23 00:19:50,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:50,922 INFO:     Epoch: 27
2022-11-23 00:19:51,733 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7911370511759411, 'Total loss': 0.7911370511759411} | train loss {'Reaction outcome loss': 0.8224656336944596, 'Total loss': 0.8224656336944596}
2022-11-23 00:19:51,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:51,733 INFO:     Epoch: 28
2022-11-23 00:19:52,551 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7814353216778148, 'Total loss': 0.7814353216778148} | train loss {'Reaction outcome loss': 0.8275744965684558, 'Total loss': 0.8275744965684558}
2022-11-23 00:19:52,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:52,551 INFO:     Epoch: 29
2022-11-23 00:19:53,372 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8065116784789346, 'Total loss': 0.8065116784789346} | train loss {'Reaction outcome loss': 0.8185629216041642, 'Total loss': 0.8185629216041642}
2022-11-23 00:19:53,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:53,372 INFO:     Epoch: 30
2022-11-23 00:19:54,193 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7770577574318106, 'Total loss': 0.7770577574318106} | train loss {'Reaction outcome loss': 0.8262068398809626, 'Total loss': 0.8262068398809626}
2022-11-23 00:19:54,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:54,193 INFO:     Epoch: 31
2022-11-23 00:19:55,000 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7751521034674211, 'Total loss': 0.7751521034674211} | train loss {'Reaction outcome loss': 0.8256033371817245, 'Total loss': 0.8256033371817245}
2022-11-23 00:19:55,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:55,001 INFO:     Epoch: 32
2022-11-23 00:19:55,811 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7829472422599792, 'Total loss': 0.7829472422599792} | train loss {'Reaction outcome loss': 0.8267410846374296, 'Total loss': 0.8267410846374296}
2022-11-23 00:19:55,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:55,811 INFO:     Epoch: 33
2022-11-23 00:19:56,657 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7777042605660178, 'Total loss': 0.7777042605660178} | train loss {'Reaction outcome loss': 0.821106459085758, 'Total loss': 0.821106459085758}
2022-11-23 00:19:56,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:56,657 INFO:     Epoch: 34
2022-11-23 00:19:57,498 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7793145592917096, 'Total loss': 0.7793145592917096} | train loss {'Reaction outcome loss': 0.8246735026720564, 'Total loss': 0.8246735026720564}
2022-11-23 00:19:57,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:57,498 INFO:     Epoch: 35
2022-11-23 00:19:58,332 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7737700004469265, 'Total loss': 0.7737700004469265} | train loss {'Reaction outcome loss': 0.8232429404007761, 'Total loss': 0.8232429404007761}
2022-11-23 00:19:58,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:58,332 INFO:     Epoch: 36
2022-11-23 00:19:59,151 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7732197479768232, 'Total loss': 0.7732197479768232} | train loss {'Reaction outcome loss': 0.8216390082469354, 'Total loss': 0.8216390082469354}
2022-11-23 00:19:59,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:59,152 INFO:     Epoch: 37
2022-11-23 00:19:59,990 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7694636034694585, 'Total loss': 0.7694636034694585} | train loss {'Reaction outcome loss': 0.8285136330224242, 'Total loss': 0.8285136330224242}
2022-11-23 00:19:59,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:19:59,991 INFO:     Epoch: 38
2022-11-23 00:20:00,803 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.784084251658483, 'Total loss': 0.784084251658483} | train loss {'Reaction outcome loss': 0.8280305741769582, 'Total loss': 0.8280305741769582}
2022-11-23 00:20:00,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:00,803 INFO:     Epoch: 39
2022-11-23 00:20:01,596 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7823469726876779, 'Total loss': 0.7823469726876779} | train loss {'Reaction outcome loss': 0.8273263371545776, 'Total loss': 0.8273263371545776}
2022-11-23 00:20:01,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:01,597 INFO:     Epoch: 40
2022-11-23 00:20:02,404 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7791832407767122, 'Total loss': 0.7791832407767122} | train loss {'Reaction outcome loss': 0.8218495652743196, 'Total loss': 0.8218495652743196}
2022-11-23 00:20:02,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:02,405 INFO:     Epoch: 41
2022-11-23 00:20:03,190 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7795076681808992, 'Total loss': 0.7795076681808992} | train loss {'Reaction outcome loss': 0.819949994082393, 'Total loss': 0.819949994082393}
2022-11-23 00:20:03,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:03,191 INFO:     Epoch: 42
2022-11-23 00:20:03,956 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7742283594879237, 'Total loss': 0.7742283594879237} | train loss {'Reaction outcome loss': 0.8230318002372619, 'Total loss': 0.8230318002372619}
2022-11-23 00:20:03,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:03,956 INFO:     Epoch: 43
2022-11-23 00:20:04,800 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.765241880308498, 'Total loss': 0.765241880308498} | train loss {'Reaction outcome loss': 0.8212627719047099, 'Total loss': 0.8212627719047099}
2022-11-23 00:20:04,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:04,801 INFO:     Epoch: 44
2022-11-23 00:20:05,628 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.772315112027255, 'Total loss': 0.772315112027255} | train loss {'Reaction outcome loss': 0.8211236400944502, 'Total loss': 0.8211236400944502}
2022-11-23 00:20:05,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:05,628 INFO:     Epoch: 45
2022-11-23 00:20:06,446 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7737092165784403, 'Total loss': 0.7737092165784403} | train loss {'Reaction outcome loss': 0.8190284743000139, 'Total loss': 0.8190284743000139}
2022-11-23 00:20:06,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:06,447 INFO:     Epoch: 46
2022-11-23 00:20:07,272 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7711142227053642, 'Total loss': 0.7711142227053642} | train loss {'Reaction outcome loss': 0.8256494518716325, 'Total loss': 0.8256494518716325}
2022-11-23 00:20:07,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:07,273 INFO:     Epoch: 47
2022-11-23 00:20:08,100 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.792215187441219, 'Total loss': 0.792215187441219} | train loss {'Reaction outcome loss': 0.8186868411085384, 'Total loss': 0.8186868411085384}
2022-11-23 00:20:08,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:08,100 INFO:     Epoch: 48
2022-11-23 00:20:08,930 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7936005863276395, 'Total loss': 0.7936005863276395} | train loss {'Reaction outcome loss': 0.8173390085194335, 'Total loss': 0.8173390085194335}
2022-11-23 00:20:08,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:08,930 INFO:     Epoch: 49
2022-11-23 00:20:09,729 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7940948233008385, 'Total loss': 0.7940948233008385} | train loss {'Reaction outcome loss': 0.8285382356238269, 'Total loss': 0.8285382356238269}
2022-11-23 00:20:09,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:09,730 INFO:     Epoch: 50
2022-11-23 00:20:10,529 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7925832630558447, 'Total loss': 0.7925832630558447} | train loss {'Reaction outcome loss': 0.8211368976334329, 'Total loss': 0.8211368976334329}
2022-11-23 00:20:10,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:10,529 INFO:     Epoch: 51
2022-11-23 00:20:11,333 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7677725492553278, 'Total loss': 0.7677725492553278} | train loss {'Reaction outcome loss': 0.8213938854725255, 'Total loss': 0.8213938854725255}
2022-11-23 00:20:11,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:11,333 INFO:     Epoch: 52
2022-11-23 00:20:12,111 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7956066090952266, 'Total loss': 0.7956066090952266} | train loss {'Reaction outcome loss': 0.8185495881906707, 'Total loss': 0.8185495881906707}
2022-11-23 00:20:12,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:12,111 INFO:     Epoch: 53
2022-11-23 00:20:12,884 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.806020202961835, 'Total loss': 0.806020202961835} | train loss {'Reaction outcome loss': 0.8255686138564275, 'Total loss': 0.8255686138564275}
2022-11-23 00:20:12,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:12,884 INFO:     Epoch: 54
2022-11-23 00:20:13,688 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7926155078140172, 'Total loss': 0.7926155078140172} | train loss {'Reaction outcome loss': 0.8273643708904745, 'Total loss': 0.8273643708904745}
2022-11-23 00:20:13,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:13,688 INFO:     Epoch: 55
2022-11-23 00:20:14,466 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7655953216281804, 'Total loss': 0.7655953216281804} | train loss {'Reaction outcome loss': 0.8237467977682106, 'Total loss': 0.8237467977682106}
2022-11-23 00:20:14,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:14,467 INFO:     Epoch: 56
2022-11-23 00:20:15,274 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.791675282472914, 'Total loss': 0.791675282472914} | train loss {'Reaction outcome loss': 0.8250493408456022, 'Total loss': 0.8250493408456022}
2022-11-23 00:20:15,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:15,274 INFO:     Epoch: 57
2022-11-23 00:20:16,081 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7762427214871753, 'Total loss': 0.7762427214871753} | train loss {'Reaction outcome loss': 0.822623922998606, 'Total loss': 0.822623922998606}
2022-11-23 00:20:16,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:16,081 INFO:     Epoch: 58
2022-11-23 00:20:16,896 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7737305347215045, 'Total loss': 0.7737305347215045} | train loss {'Reaction outcome loss': 0.8232220191704599, 'Total loss': 0.8232220191704599}
2022-11-23 00:20:16,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:16,896 INFO:     Epoch: 59
2022-11-23 00:20:17,715 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.782761619172313, 'Total loss': 0.782761619172313} | train loss {'Reaction outcome loss': 0.8288016841720472, 'Total loss': 0.8288016841720472}
2022-11-23 00:20:17,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:17,715 INFO:     Epoch: 60
2022-11-23 00:20:18,508 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7834754924882542, 'Total loss': 0.7834754924882542} | train loss {'Reaction outcome loss': 0.8232589947730906, 'Total loss': 0.8232589947730906}
2022-11-23 00:20:18,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:18,509 INFO:     Epoch: 61
2022-11-23 00:20:19,303 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7761093974113464, 'Total loss': 0.7761093974113464} | train loss {'Reaction outcome loss': 0.8158299056624594, 'Total loss': 0.8158299056624594}
2022-11-23 00:20:19,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:19,303 INFO:     Epoch: 62
2022-11-23 00:20:20,113 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8040057590061968, 'Total loss': 0.8040057590061968} | train loss {'Reaction outcome loss': 0.8191377163415978, 'Total loss': 0.8191377163415978}
2022-11-23 00:20:20,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:20,113 INFO:     Epoch: 63
2022-11-23 00:20:20,920 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7740253609689799, 'Total loss': 0.7740253609689799} | train loss {'Reaction outcome loss': 0.8237430038843078, 'Total loss': 0.8237430038843078}
2022-11-23 00:20:20,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:20,921 INFO:     Epoch: 64
2022-11-23 00:20:21,711 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7701952586119826, 'Total loss': 0.7701952586119826} | train loss {'Reaction outcome loss': 0.8242334979265807, 'Total loss': 0.8242334979265807}
2022-11-23 00:20:21,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:21,711 INFO:     Epoch: 65
2022-11-23 00:20:22,498 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7730896730314601, 'Total loss': 0.7730896730314601} | train loss {'Reaction outcome loss': 0.8186636959251604, 'Total loss': 0.8186636959251604}
2022-11-23 00:20:22,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:22,498 INFO:     Epoch: 66
2022-11-23 00:20:23,285 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.779776165431196, 'Total loss': 0.779776165431196} | train loss {'Reaction outcome loss': 0.8160364970806157, 'Total loss': 0.8160364970806157}
2022-11-23 00:20:23,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:23,285 INFO:     Epoch: 67
2022-11-23 00:20:24,155 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7752036872235212, 'Total loss': 0.7752036872235212} | train loss {'Reaction outcome loss': 0.8195430203246684, 'Total loss': 0.8195430203246684}
2022-11-23 00:20:24,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:24,156 INFO:     Epoch: 68
2022-11-23 00:20:25,016 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7742333771152929, 'Total loss': 0.7742333771152929} | train loss {'Reaction outcome loss': 0.8205028896480195, 'Total loss': 0.8205028896480195}
2022-11-23 00:20:25,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:25,016 INFO:     Epoch: 69
2022-11-23 00:20:25,823 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7848338186740875, 'Total loss': 0.7848338186740875} | train loss {'Reaction outcome loss': 0.8177333483208529, 'Total loss': 0.8177333483208529}
2022-11-23 00:20:25,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:25,823 INFO:     Epoch: 70
2022-11-23 00:20:26,634 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.776850700378418, 'Total loss': 0.776850700378418} | train loss {'Reaction outcome loss': 0.8160085539344833, 'Total loss': 0.8160085539344833}
2022-11-23 00:20:26,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:26,634 INFO:     Epoch: 71
2022-11-23 00:20:27,431 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7930604090744798, 'Total loss': 0.7930604090744798} | train loss {'Reaction outcome loss': 0.8327415578278453, 'Total loss': 0.8327415578278453}
2022-11-23 00:20:27,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:27,431 INFO:     Epoch: 72
2022-11-23 00:20:28,263 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7869530218568715, 'Total loss': 0.7869530218568715} | train loss {'Reaction outcome loss': 0.8225772115383071, 'Total loss': 0.8225772115383071}
2022-11-23 00:20:28,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:28,263 INFO:     Epoch: 73
2022-11-23 00:20:29,086 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8039129593155601, 'Total loss': 0.8039129593155601} | train loss {'Reaction outcome loss': 0.8272829654245724, 'Total loss': 0.8272829654245724}
2022-11-23 00:20:29,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:29,087 INFO:     Epoch: 74
2022-11-23 00:20:29,933 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7796423543583263, 'Total loss': 0.7796423543583263} | train loss {'Reaction outcome loss': 0.8251726315451055, 'Total loss': 0.8251726315451055}
2022-11-23 00:20:29,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:29,933 INFO:     Epoch: 75
2022-11-23 00:20:30,736 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7714149261062796, 'Total loss': 0.7714149261062796} | train loss {'Reaction outcome loss': 0.8169861073315385, 'Total loss': 0.8169861073315385}
2022-11-23 00:20:30,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:30,737 INFO:     Epoch: 76
2022-11-23 00:20:31,579 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7894708277149634, 'Total loss': 0.7894708277149634} | train loss {'Reaction outcome loss': 0.8195985050095238, 'Total loss': 0.8195985050095238}
2022-11-23 00:20:31,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:31,579 INFO:     Epoch: 77
2022-11-23 00:20:32,393 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7745934616435658, 'Total loss': 0.7745934616435658} | train loss {'Reaction outcome loss': 0.8164596046030763, 'Total loss': 0.8164596046030763}
2022-11-23 00:20:32,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:32,393 INFO:     Epoch: 78
2022-11-23 00:20:33,223 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7801297469572588, 'Total loss': 0.7801297469572588} | train loss {'Reaction outcome loss': 0.8229578607960751, 'Total loss': 0.8229578607960751}
2022-11-23 00:20:33,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:33,223 INFO:     Epoch: 79
2022-11-23 00:20:34,044 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.781953023915941, 'Total loss': 0.781953023915941} | train loss {'Reaction outcome loss': 0.8218764417110999, 'Total loss': 0.8218764417110999}
2022-11-23 00:20:34,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:34,044 INFO:     Epoch: 80
2022-11-23 00:20:34,822 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7671013962138783, 'Total loss': 0.7671013962138783} | train loss {'Reaction outcome loss': 0.815225215198902, 'Total loss': 0.815225215198902}
2022-11-23 00:20:34,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:34,822 INFO:     Epoch: 81
2022-11-23 00:20:35,665 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7680959064852108, 'Total loss': 0.7680959064852108} | train loss {'Reaction outcome loss': 0.8187218532871138, 'Total loss': 0.8187218532871138}
2022-11-23 00:20:35,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:35,666 INFO:     Epoch: 82
2022-11-23 00:20:36,496 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7709000991149382, 'Total loss': 0.7709000991149382} | train loss {'Reaction outcome loss': 0.8247610236469068, 'Total loss': 0.8247610236469068}
2022-11-23 00:20:36,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:36,497 INFO:     Epoch: 83
2022-11-23 00:20:37,293 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8051972050558437, 'Total loss': 0.8051972050558437} | train loss {'Reaction outcome loss': 0.8183834790459529, 'Total loss': 0.8183834790459529}
2022-11-23 00:20:37,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:37,294 INFO:     Epoch: 84
2022-11-23 00:20:38,110 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7754387577826326, 'Total loss': 0.7754387577826326} | train loss {'Reaction outcome loss': 0.8235956853941867, 'Total loss': 0.8235956853941867}
2022-11-23 00:20:38,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:38,110 INFO:     Epoch: 85
2022-11-23 00:20:38,903 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.790845085951415, 'Total loss': 0.790845085951415} | train loss {'Reaction outcome loss': 0.8198486085121448, 'Total loss': 0.8198486085121448}
2022-11-23 00:20:38,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:38,903 INFO:     Epoch: 86
2022-11-23 00:20:39,710 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7630216052586382, 'Total loss': 0.7630216052586382} | train loss {'Reaction outcome loss': 0.8277801184760414, 'Total loss': 0.8277801184760414}
2022-11-23 00:20:39,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:39,710 INFO:     Epoch: 87
2022-11-23 00:20:40,512 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7687700905583121, 'Total loss': 0.7687700905583121} | train loss {'Reaction outcome loss': 0.8200126328328361, 'Total loss': 0.8200126328328361}
2022-11-23 00:20:40,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:40,512 INFO:     Epoch: 88
2022-11-23 00:20:41,361 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7755765732039105, 'Total loss': 0.7755765732039105} | train loss {'Reaction outcome loss': 0.8149673454915947, 'Total loss': 0.8149673454915947}
2022-11-23 00:20:41,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:41,362 INFO:     Epoch: 89
2022-11-23 00:20:42,171 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7692727913910692, 'Total loss': 0.7692727913910692} | train loss {'Reaction outcome loss': 0.8186140270971576, 'Total loss': 0.8186140270971576}
2022-11-23 00:20:42,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:42,172 INFO:     Epoch: 90
2022-11-23 00:20:42,996 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7696067074483092, 'Total loss': 0.7696067074483092} | train loss {'Reaction outcome loss': 0.8169759036558359, 'Total loss': 0.8169759036558359}
2022-11-23 00:20:42,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:42,996 INFO:     Epoch: 91
2022-11-23 00:20:43,792 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7755151255564257, 'Total loss': 0.7755151255564257} | train loss {'Reaction outcome loss': 0.8173127497738673, 'Total loss': 0.8173127497738673}
2022-11-23 00:20:43,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:43,792 INFO:     Epoch: 92
2022-11-23 00:20:44,632 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7849479676647619, 'Total loss': 0.7849479676647619} | train loss {'Reaction outcome loss': 0.8208882079915962, 'Total loss': 0.8208882079915962}
2022-11-23 00:20:44,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:44,632 INFO:     Epoch: 93
2022-11-23 00:20:45,460 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7690986340696161, 'Total loss': 0.7690986340696161} | train loss {'Reaction outcome loss': 0.8177320076386455, 'Total loss': 0.8177320076386455}
2022-11-23 00:20:45,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:45,460 INFO:     Epoch: 94
2022-11-23 00:20:46,287 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.773100455376235, 'Total loss': 0.773100455376235} | train loss {'Reaction outcome loss': 0.8177672027334993, 'Total loss': 0.8177672027334993}
2022-11-23 00:20:46,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:46,288 INFO:     Epoch: 95
2022-11-23 00:20:47,088 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8058425316756422, 'Total loss': 0.8058425316756422} | train loss {'Reaction outcome loss': 0.8252608081107198, 'Total loss': 0.8252608081107198}
2022-11-23 00:20:47,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:47,088 INFO:     Epoch: 96
2022-11-23 00:20:47,887 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7816313464533199, 'Total loss': 0.7816313464533199} | train loss {'Reaction outcome loss': 0.8224240003327127, 'Total loss': 0.8224240003327127}
2022-11-23 00:20:47,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:47,887 INFO:     Epoch: 97
2022-11-23 00:20:48,755 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7823901284824718, 'Total loss': 0.7823901284824718} | train loss {'Reaction outcome loss': 0.8245823382124727, 'Total loss': 0.8245823382124727}
2022-11-23 00:20:48,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:48,755 INFO:     Epoch: 98
2022-11-23 00:20:49,594 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7787508016282861, 'Total loss': 0.7787508016282861} | train loss {'Reaction outcome loss': 0.8224501666511118, 'Total loss': 0.8224501666511118}
2022-11-23 00:20:49,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:49,595 INFO:     Epoch: 99
2022-11-23 00:20:50,434 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7910861826755784, 'Total loss': 0.7910861826755784} | train loss {'Reaction outcome loss': 0.8170328924530431, 'Total loss': 0.8170328924530431}
2022-11-23 00:20:50,434 INFO:     Best model found after epoch 25 of 100.
2022-11-23 00:20:50,435 INFO:   Done with stage: TRAINING
2022-11-23 00:20:50,435 INFO:   Starting stage: EVALUATION
2022-11-23 00:20:50,560 INFO:   Done with stage: EVALUATION
2022-11-23 00:20:50,560 INFO:   Leaving out SEQ value Fold_1
2022-11-23 00:20:50,573 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:20:50,573 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:20:51,241 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:20:51,241 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:20:51,311 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:20:51,312 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:20:51,312 INFO:     No hyperparam tuning for this model
2022-11-23 00:20:51,312 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:20:51,312 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:20:51,313 INFO:     None feature selector for col prot
2022-11-23 00:20:51,313 INFO:     None feature selector for col prot
2022-11-23 00:20:51,313 INFO:     None feature selector for col prot
2022-11-23 00:20:51,313 INFO:     None feature selector for col chem
2022-11-23 00:20:51,313 INFO:     None feature selector for col chem
2022-11-23 00:20:51,314 INFO:     None feature selector for col chem
2022-11-23 00:20:51,314 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:20:51,314 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:20:51,315 INFO:     Number of params in model 168571
2022-11-23 00:20:51,318 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:20:51,318 INFO:   Starting stage: TRAINING
2022-11-23 00:20:51,376 INFO:     Val loss before train {'Reaction outcome loss': 0.9848779304461046, 'Total loss': 0.9848779304461046}
2022-11-23 00:20:51,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:51,376 INFO:     Epoch: 0
2022-11-23 00:20:52,149 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8417109670964155, 'Total loss': 0.8417109670964155} | train loss {'Reaction outcome loss': 0.8813016687327551, 'Total loss': 0.8813016687327551}
2022-11-23 00:20:52,149 INFO:     Found new best model at epoch 0
2022-11-23 00:20:52,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:52,150 INFO:     Epoch: 1
2022-11-23 00:20:52,952 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.825983657755635, 'Total loss': 0.825983657755635} | train loss {'Reaction outcome loss': 0.8402709510886235, 'Total loss': 0.8402709510886235}
2022-11-23 00:20:52,952 INFO:     Found new best model at epoch 1
2022-11-23 00:20:52,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:52,953 INFO:     Epoch: 2
2022-11-23 00:20:53,773 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8252883939580484, 'Total loss': 0.8252883939580484} | train loss {'Reaction outcome loss': 0.8414778498261564, 'Total loss': 0.8414778498261564}
2022-11-23 00:20:53,773 INFO:     Found new best model at epoch 2
2022-11-23 00:20:53,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:53,774 INFO:     Epoch: 3
2022-11-23 00:20:54,581 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8257100500843741, 'Total loss': 0.8257100500843741} | train loss {'Reaction outcome loss': 0.8386324569281296, 'Total loss': 0.8386324569281296}
2022-11-23 00:20:54,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:54,582 INFO:     Epoch: 4
2022-11-23 00:20:55,395 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8191981261426752, 'Total loss': 0.8191981261426752} | train loss {'Reaction outcome loss': 0.8330751799861429, 'Total loss': 0.8330751799861429}
2022-11-23 00:20:55,395 INFO:     Found new best model at epoch 4
2022-11-23 00:20:55,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:55,397 INFO:     Epoch: 5
2022-11-23 00:20:56,226 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8214936581524935, 'Total loss': 0.8214936581524935} | train loss {'Reaction outcome loss': 0.8317557479205885, 'Total loss': 0.8317557479205885}
2022-11-23 00:20:56,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:56,226 INFO:     Epoch: 6
2022-11-23 00:20:57,031 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8354753012006934, 'Total loss': 0.8354753012006934} | train loss {'Reaction outcome loss': 0.828168960597351, 'Total loss': 0.828168960597351}
2022-11-23 00:20:57,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:57,031 INFO:     Epoch: 7
2022-11-23 00:20:57,846 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8083583759990606, 'Total loss': 0.8083583759990606} | train loss {'Reaction outcome loss': 0.8278953489745676, 'Total loss': 0.8278953489745676}
2022-11-23 00:20:57,846 INFO:     Found new best model at epoch 7
2022-11-23 00:20:57,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:57,847 INFO:     Epoch: 8
2022-11-23 00:20:58,614 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8131443939425729, 'Total loss': 0.8131443939425729} | train loss {'Reaction outcome loss': 0.8307368680533127, 'Total loss': 0.8307368680533127}
2022-11-23 00:20:58,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:58,614 INFO:     Epoch: 9
2022-11-23 00:20:59,472 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.812938928604126, 'Total loss': 0.812938928604126} | train loss {'Reaction outcome loss': 0.8234775824706081, 'Total loss': 0.8234775824706081}
2022-11-23 00:20:59,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:20:59,472 INFO:     Epoch: 10
2022-11-23 00:21:00,280 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8425341526215727, 'Total loss': 0.8425341526215727} | train loss {'Reaction outcome loss': 0.8232506675276197, 'Total loss': 0.8232506675276197}
2022-11-23 00:21:00,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:00,281 INFO:     Epoch: 11
2022-11-23 00:21:01,067 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8075566522099755, 'Total loss': 0.8075566522099755} | train loss {'Reaction outcome loss': 0.8340061578432075, 'Total loss': 0.8340061578432075}
2022-11-23 00:21:01,067 INFO:     Found new best model at epoch 11
2022-11-23 00:21:01,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:01,068 INFO:     Epoch: 12
2022-11-23 00:21:01,898 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8090685280886564, 'Total loss': 0.8090685280886564} | train loss {'Reaction outcome loss': 0.8238375985670668, 'Total loss': 0.8238375985670668}
2022-11-23 00:21:01,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:01,899 INFO:     Epoch: 13
2022-11-23 00:21:02,685 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8124390014193275, 'Total loss': 0.8124390014193275} | train loss {'Reaction outcome loss': 0.8246798225742603, 'Total loss': 0.8246798225742603}
2022-11-23 00:21:02,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:02,687 INFO:     Epoch: 14
2022-11-23 00:21:03,554 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8076957965439017, 'Total loss': 0.8076957965439017} | train loss {'Reaction outcome loss': 0.823566947750717, 'Total loss': 0.823566947750717}
2022-11-23 00:21:03,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:03,554 INFO:     Epoch: 15
2022-11-23 00:21:04,458 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8597770861603997, 'Total loss': 0.8597770861603997} | train loss {'Reaction outcome loss': 0.8248631045644582, 'Total loss': 0.8248631045644582}
2022-11-23 00:21:04,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:04,458 INFO:     Epoch: 16
2022-11-23 00:21:05,399 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8201457092707808, 'Total loss': 0.8201457092707808} | train loss {'Reaction outcome loss': 0.8298077171872019, 'Total loss': 0.8298077171872019}
2022-11-23 00:21:05,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:05,399 INFO:     Epoch: 17
2022-11-23 00:21:06,311 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7980099679394201, 'Total loss': 0.7980099679394201} | train loss {'Reaction outcome loss': 0.8229129752709798, 'Total loss': 0.8229129752709798}
2022-11-23 00:21:06,311 INFO:     Found new best model at epoch 17
2022-11-23 00:21:06,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:06,312 INFO:     Epoch: 18
2022-11-23 00:21:07,148 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8239540654149923, 'Total loss': 0.8239540654149923} | train loss {'Reaction outcome loss': 0.8190899625239585, 'Total loss': 0.8190899625239585}
2022-11-23 00:21:07,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:07,148 INFO:     Epoch: 19
2022-11-23 00:21:07,939 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.830712035975673, 'Total loss': 0.830712035975673} | train loss {'Reaction outcome loss': 0.8214364454813814, 'Total loss': 0.8214364454813814}
2022-11-23 00:21:07,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:07,939 INFO:     Epoch: 20
2022-11-23 00:21:08,748 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8229540816762231, 'Total loss': 0.8229540816762231} | train loss {'Reaction outcome loss': 0.8236454424829136, 'Total loss': 0.8236454424829136}
2022-11-23 00:21:08,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:08,749 INFO:     Epoch: 21
2022-11-23 00:21:09,577 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8199520890008319, 'Total loss': 0.8199520890008319} | train loss {'Reaction outcome loss': 0.8294606381341031, 'Total loss': 0.8294606381341031}
2022-11-23 00:21:09,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:09,577 INFO:     Epoch: 22
2022-11-23 00:21:10,354 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8069445287639444, 'Total loss': 0.8069445287639444} | train loss {'Reaction outcome loss': 0.8247847126321755, 'Total loss': 0.8247847126321755}
2022-11-23 00:21:10,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:10,355 INFO:     Epoch: 23
2022-11-23 00:21:11,217 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8111722347411242, 'Total loss': 0.8111722347411242} | train loss {'Reaction outcome loss': 0.8162602784059309, 'Total loss': 0.8162602784059309}
2022-11-23 00:21:11,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:11,217 INFO:     Epoch: 24
2022-11-23 00:21:12,113 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8200435279445215, 'Total loss': 0.8200435279445215} | train loss {'Reaction outcome loss': 0.8186012289302069, 'Total loss': 0.8186012289302069}
2022-11-23 00:21:12,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:12,113 INFO:     Epoch: 25
2022-11-23 00:21:12,972 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8112396611408754, 'Total loss': 0.8112396611408754} | train loss {'Reaction outcome loss': 0.8279408699105143, 'Total loss': 0.8279408699105143}
2022-11-23 00:21:12,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:12,972 INFO:     Epoch: 26
2022-11-23 00:21:13,747 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8065434369173917, 'Total loss': 0.8065434369173917} | train loss {'Reaction outcome loss': 0.8181755443212957, 'Total loss': 0.8181755443212957}
2022-11-23 00:21:13,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:13,747 INFO:     Epoch: 27
2022-11-23 00:21:14,519 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8647695095701651, 'Total loss': 0.8647695095701651} | train loss {'Reaction outcome loss': 0.8196249872084088, 'Total loss': 0.8196249872084088}
2022-11-23 00:21:14,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:14,520 INFO:     Epoch: 28
2022-11-23 00:21:15,358 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8017748242074793, 'Total loss': 0.8017748242074793} | train loss {'Reaction outcome loss': 0.8180329293193604, 'Total loss': 0.8180329293193604}
2022-11-23 00:21:15,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:15,359 INFO:     Epoch: 29
2022-11-23 00:21:16,160 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8267587152394381, 'Total loss': 0.8267587152394381} | train loss {'Reaction outcome loss': 0.8162122044244758, 'Total loss': 0.8162122044244758}
2022-11-23 00:21:16,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:16,161 INFO:     Epoch: 30
2022-11-23 00:21:16,980 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7965520024299622, 'Total loss': 0.7965520024299622} | train loss {'Reaction outcome loss': 0.8178929634965383, 'Total loss': 0.8178929634965383}
2022-11-23 00:21:16,980 INFO:     Found new best model at epoch 30
2022-11-23 00:21:16,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:16,981 INFO:     Epoch: 31
2022-11-23 00:21:17,826 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8342682841149244, 'Total loss': 0.8342682841149244} | train loss {'Reaction outcome loss': 0.8192345148879989, 'Total loss': 0.8192345148879989}
2022-11-23 00:21:17,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:17,826 INFO:     Epoch: 32
2022-11-23 00:21:18,623 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8116435171528296, 'Total loss': 0.8116435171528296} | train loss {'Reaction outcome loss': 0.8168087636048977, 'Total loss': 0.8168087636048977}
2022-11-23 00:21:18,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:18,623 INFO:     Epoch: 33
2022-11-23 00:21:19,409 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8334611315618862, 'Total loss': 0.8334611315618862} | train loss {'Reaction outcome loss': 0.8171692105681307, 'Total loss': 0.8171692105681307}
2022-11-23 00:21:19,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:19,410 INFO:     Epoch: 34
2022-11-23 00:21:20,220 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7999504323710095, 'Total loss': 0.7999504323710095} | train loss {'Reaction outcome loss': 0.8207440342497729, 'Total loss': 0.8207440342497729}
2022-11-23 00:21:20,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:20,220 INFO:     Epoch: 35
2022-11-23 00:21:21,061 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7993406213142655, 'Total loss': 0.7993406213142655} | train loss {'Reaction outcome loss': 0.8210359714050525, 'Total loss': 0.8210359714050525}
2022-11-23 00:21:21,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:21,062 INFO:     Epoch: 36
2022-11-23 00:21:21,918 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8172377334399656, 'Total loss': 0.8172377334399656} | train loss {'Reaction outcome loss': 0.8164491804263853, 'Total loss': 0.8164491804263853}
2022-11-23 00:21:21,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:21,918 INFO:     Epoch: 37
2022-11-23 00:21:22,745 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8121743689883839, 'Total loss': 0.8121743689883839} | train loss {'Reaction outcome loss': 0.8199171458902629, 'Total loss': 0.8199171458902629}
2022-11-23 00:21:22,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:22,746 INFO:     Epoch: 38
2022-11-23 00:21:23,572 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8150313984264027, 'Total loss': 0.8150313984264027} | train loss {'Reaction outcome loss': 0.8161080229861534, 'Total loss': 0.8161080229861534}
2022-11-23 00:21:23,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:23,573 INFO:     Epoch: 39
2022-11-23 00:21:24,343 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8172442554072901, 'Total loss': 0.8172442554072901} | train loss {'Reaction outcome loss': 0.8191867192023197, 'Total loss': 0.8191867192023197}
2022-11-23 00:21:24,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:24,343 INFO:     Epoch: 40
2022-11-23 00:21:25,134 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8255051990801637, 'Total loss': 0.8255051990801637} | train loss {'Reaction outcome loss': 0.8163179606802551, 'Total loss': 0.8163179606802551}
2022-11-23 00:21:25,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:25,134 INFO:     Epoch: 41
2022-11-23 00:21:25,936 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8153588487343355, 'Total loss': 0.8153588487343355} | train loss {'Reaction outcome loss': 0.8236073514951868, 'Total loss': 0.8236073514951868}
2022-11-23 00:21:25,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:25,936 INFO:     Epoch: 42
2022-11-23 00:21:26,777 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8260602300817316, 'Total loss': 0.8260602300817316} | train loss {'Reaction outcome loss': 0.8143670234361641, 'Total loss': 0.8143670234361641}
2022-11-23 00:21:26,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:26,777 INFO:     Epoch: 43
2022-11-23 00:21:27,595 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.815140619196675, 'Total loss': 0.815140619196675} | train loss {'Reaction outcome loss': 0.8143683684017011, 'Total loss': 0.8143683684017011}
2022-11-23 00:21:27,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:27,596 INFO:     Epoch: 44
2022-11-23 00:21:28,409 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8094198039986871, 'Total loss': 0.8094198039986871} | train loss {'Reaction outcome loss': 0.814516546393213, 'Total loss': 0.814516546393213}
2022-11-23 00:21:28,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:28,409 INFO:     Epoch: 45
2022-11-23 00:21:29,199 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8041104396635835, 'Total loss': 0.8041104396635835} | train loss {'Reaction outcome loss': 0.8153875947360568, 'Total loss': 0.8153875947360568}
2022-11-23 00:21:29,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:29,199 INFO:     Epoch: 46
2022-11-23 00:21:29,995 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8218153539029035, 'Total loss': 0.8218153539029035} | train loss {'Reaction outcome loss': 0.8137118354862035, 'Total loss': 0.8137118354862035}
2022-11-23 00:21:29,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:29,996 INFO:     Epoch: 47
2022-11-23 00:21:30,805 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8338159329511903, 'Total loss': 0.8338159329511903} | train loss {'Reaction outcome loss': 0.8178596162361654, 'Total loss': 0.8178596162361654}
2022-11-23 00:21:30,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:30,806 INFO:     Epoch: 48
2022-11-23 00:21:31,634 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.801396557553248, 'Total loss': 0.801396557553248} | train loss {'Reaction outcome loss': 0.8183032537278859, 'Total loss': 0.8183032537278859}
2022-11-23 00:21:31,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:31,635 INFO:     Epoch: 49
2022-11-23 00:21:32,437 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8074255971746012, 'Total loss': 0.8074255971746012} | train loss {'Reaction outcome loss': 0.8165371607431033, 'Total loss': 0.8165371607431033}
2022-11-23 00:21:32,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:32,437 INFO:     Epoch: 50
2022-11-23 00:21:33,237 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8311292651024732, 'Total loss': 0.8311292651024732} | train loss {'Reaction outcome loss': 0.8202471233572555, 'Total loss': 0.8202471233572555}
2022-11-23 00:21:33,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:33,238 INFO:     Epoch: 51
2022-11-23 00:21:34,090 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8135446154258468, 'Total loss': 0.8135446154258468} | train loss {'Reaction outcome loss': 0.8211874981158176, 'Total loss': 0.8211874981158176}
2022-11-23 00:21:34,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:34,090 INFO:     Epoch: 52
2022-11-23 00:21:34,914 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8110893612558191, 'Total loss': 0.8110893612558191} | train loss {'Reaction outcome loss': 0.812688525630395, 'Total loss': 0.812688525630395}
2022-11-23 00:21:34,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:34,914 INFO:     Epoch: 53
2022-11-23 00:21:35,748 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8043956864963878, 'Total loss': 0.8043956864963878} | train loss {'Reaction outcome loss': 0.8157436755987314, 'Total loss': 0.8157436755987314}
2022-11-23 00:21:35,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:35,748 INFO:     Epoch: 54
2022-11-23 00:21:36,589 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.822375936941667, 'Total loss': 0.822375936941667} | train loss {'Reaction outcome loss': 0.8152789450759589, 'Total loss': 0.8152789450759589}
2022-11-23 00:21:36,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:36,589 INFO:     Epoch: 55
2022-11-23 00:21:37,372 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8073035586964, 'Total loss': 0.8073035586964} | train loss {'Reaction outcome loss': 0.8132731520574585, 'Total loss': 0.8132731520574585}
2022-11-23 00:21:37,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:37,373 INFO:     Epoch: 56
2022-11-23 00:21:38,185 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8171948451887477, 'Total loss': 0.8171948451887477} | train loss {'Reaction outcome loss': 0.8230502805729144, 'Total loss': 0.8230502805729144}
2022-11-23 00:21:38,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:38,185 INFO:     Epoch: 57
2022-11-23 00:21:39,029 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7967883558435873, 'Total loss': 0.7967883558435873} | train loss {'Reaction outcome loss': 0.8194486124795458, 'Total loss': 0.8194486124795458}
2022-11-23 00:21:39,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:39,029 INFO:     Epoch: 58
2022-11-23 00:21:39,861 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8174140710722316, 'Total loss': 0.8174140710722316} | train loss {'Reaction outcome loss': 0.8170997131208659, 'Total loss': 0.8170997131208659}
2022-11-23 00:21:39,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:39,862 INFO:     Epoch: 59
2022-11-23 00:21:40,674 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8184940923344005, 'Total loss': 0.8184940923344005} | train loss {'Reaction outcome loss': 0.8180574511709483, 'Total loss': 0.8180574511709483}
2022-11-23 00:21:40,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:40,674 INFO:     Epoch: 60
2022-11-23 00:21:41,466 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8158818178556182, 'Total loss': 0.8158818178556182} | train loss {'Reaction outcome loss': 0.8203800697075693, 'Total loss': 0.8203800697075693}
2022-11-23 00:21:41,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:41,466 INFO:     Epoch: 61
2022-11-23 00:21:42,297 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.800949901342392, 'Total loss': 0.800949901342392} | train loss {'Reaction outcome loss': 0.8212866853123252, 'Total loss': 0.8212866853123252}
2022-11-23 00:21:42,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:42,297 INFO:     Epoch: 62
2022-11-23 00:21:43,121 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8094732734290037, 'Total loss': 0.8094732734290037} | train loss {'Reaction outcome loss': 0.8163789443158911, 'Total loss': 0.8163789443158911}
2022-11-23 00:21:43,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:43,121 INFO:     Epoch: 63
2022-11-23 00:21:43,976 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8141775903376666, 'Total loss': 0.8141775903376666} | train loss {'Reaction outcome loss': 0.815982307861691, 'Total loss': 0.815982307861691}
2022-11-23 00:21:43,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:43,976 INFO:     Epoch: 64
2022-11-23 00:21:44,755 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7935412925752726, 'Total loss': 0.7935412925752726} | train loss {'Reaction outcome loss': 0.8236140600341534, 'Total loss': 0.8236140600341534}
2022-11-23 00:21:44,755 INFO:     Found new best model at epoch 64
2022-11-23 00:21:44,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:44,756 INFO:     Epoch: 65
2022-11-23 00:21:45,636 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.806446639651602, 'Total loss': 0.806446639651602} | train loss {'Reaction outcome loss': 0.8213179382959358, 'Total loss': 0.8213179382959358}
2022-11-23 00:21:45,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:45,637 INFO:     Epoch: 66
2022-11-23 00:21:46,473 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8258753175085242, 'Total loss': 0.8258753175085242} | train loss {'Reaction outcome loss': 0.8267385951179241, 'Total loss': 0.8267385951179241}
2022-11-23 00:21:46,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:46,474 INFO:     Epoch: 67
2022-11-23 00:21:47,332 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8006939948959784, 'Total loss': 0.8006939948959784} | train loss {'Reaction outcome loss': 0.8141609846580367, 'Total loss': 0.8141609846580367}
2022-11-23 00:21:47,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:47,332 INFO:     Epoch: 68
2022-11-23 00:21:48,202 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8047236983071674, 'Total loss': 0.8047236983071674} | train loss {'Reaction outcome loss': 0.8153880576071469, 'Total loss': 0.8153880576071469}
2022-11-23 00:21:48,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:48,202 INFO:     Epoch: 69
2022-11-23 00:21:49,019 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.800499670884826, 'Total loss': 0.800499670884826} | train loss {'Reaction outcome loss': 0.8091477500764948, 'Total loss': 0.8091477500764948}
2022-11-23 00:21:49,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:49,020 INFO:     Epoch: 70
2022-11-23 00:21:49,830 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8031831336292353, 'Total loss': 0.8031831336292353} | train loss {'Reaction outcome loss': 0.8144987067471632, 'Total loss': 0.8144987067471632}
2022-11-23 00:21:49,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:49,830 INFO:     Epoch: 71
2022-11-23 00:21:50,654 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8340867879715833, 'Total loss': 0.8340867879715833} | train loss {'Reaction outcome loss': 0.8214137895628508, 'Total loss': 0.8214137895628508}
2022-11-23 00:21:50,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:50,655 INFO:     Epoch: 72
2022-11-23 00:21:51,506 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8107311833988536, 'Total loss': 0.8107311833988536} | train loss {'Reaction outcome loss': 0.8100676009589843, 'Total loss': 0.8100676009589843}
2022-11-23 00:21:51,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:51,506 INFO:     Epoch: 73
2022-11-23 00:21:52,384 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8167589103633707, 'Total loss': 0.8167589103633707} | train loss {'Reaction outcome loss': 0.8090495875007228, 'Total loss': 0.8090495875007228}
2022-11-23 00:21:52,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:52,385 INFO:     Epoch: 74
2022-11-23 00:21:53,176 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7979564985091036, 'Total loss': 0.7979564985091036} | train loss {'Reaction outcome loss': 0.8146300289312355, 'Total loss': 0.8146300289312355}
2022-11-23 00:21:53,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:53,176 INFO:     Epoch: 75
2022-11-23 00:21:54,078 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8106635395776142, 'Total loss': 0.8106635395776142} | train loss {'Reaction outcome loss': 0.8160205748882371, 'Total loss': 0.8160205748882371}
2022-11-23 00:21:54,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:54,078 INFO:     Epoch: 76
2022-11-23 00:21:54,947 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8107314482331276, 'Total loss': 0.8107314482331276} | train loss {'Reaction outcome loss': 0.8174224614131789, 'Total loss': 0.8174224614131789}
2022-11-23 00:21:54,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:54,948 INFO:     Epoch: 77
2022-11-23 00:21:55,790 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.799620808525519, 'Total loss': 0.799620808525519} | train loss {'Reaction outcome loss': 0.8177285516551631, 'Total loss': 0.8177285516551631}
2022-11-23 00:21:55,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:55,790 INFO:     Epoch: 78
2022-11-23 00:21:56,633 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8148097768425941, 'Total loss': 0.8148097768425941} | train loss {'Reaction outcome loss': 0.8201970501467284, 'Total loss': 0.8201970501467284}
2022-11-23 00:21:56,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:56,633 INFO:     Epoch: 79
2022-11-23 00:21:57,429 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8268389458006079, 'Total loss': 0.8268389458006079} | train loss {'Reaction outcome loss': 0.8114563296002294, 'Total loss': 0.8114563296002294}
2022-11-23 00:21:57,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:57,429 INFO:     Epoch: 80
2022-11-23 00:21:58,267 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8119631280953233, 'Total loss': 0.8119631280953233} | train loss {'Reaction outcome loss': 0.8149852056041179, 'Total loss': 0.8149852056041179}
2022-11-23 00:21:58,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:58,268 INFO:     Epoch: 81
2022-11-23 00:21:59,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8049561482938853, 'Total loss': 0.8049561482938853} | train loss {'Reaction outcome loss': 0.8168509141636281, 'Total loss': 0.8168509141636281}
2022-11-23 00:21:59,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:59,140 INFO:     Epoch: 82
2022-11-23 00:21:59,984 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8047111691399054, 'Total loss': 0.8047111691399054} | train loss {'Reaction outcome loss': 0.8146141607027787, 'Total loss': 0.8146141607027787}
2022-11-23 00:21:59,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:21:59,984 INFO:     Epoch: 83
2022-11-23 00:22:00,853 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8209351301193237, 'Total loss': 0.8209351301193237} | train loss {'Reaction outcome loss': 0.8212219730079898, 'Total loss': 0.8212219730079898}
2022-11-23 00:22:00,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:00,853 INFO:     Epoch: 84
2022-11-23 00:22:01,719 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8060907437042757, 'Total loss': 0.8060907437042757} | train loss {'Reaction outcome loss': 0.81454415504749, 'Total loss': 0.81454415504749}
2022-11-23 00:22:01,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:01,719 INFO:     Epoch: 85
2022-11-23 00:22:02,579 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8121353469111703, 'Total loss': 0.8121353469111703} | train loss {'Reaction outcome loss': 0.8218916408446154, 'Total loss': 0.8218916408446154}
2022-11-23 00:22:02,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:02,579 INFO:     Epoch: 86
2022-11-23 00:22:03,469 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8459968878464266, 'Total loss': 0.8459968878464266} | train loss {'Reaction outcome loss': 0.8202497255705629, 'Total loss': 0.8202497255705629}
2022-11-23 00:22:03,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:03,469 INFO:     Epoch: 87
2022-11-23 00:22:04,343 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8419457267631184, 'Total loss': 0.8419457267631184} | train loss {'Reaction outcome loss': 0.8174647002326332, 'Total loss': 0.8174647002326332}
2022-11-23 00:22:04,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:04,343 INFO:     Epoch: 88
2022-11-23 00:22:05,196 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8177576024423946, 'Total loss': 0.8177576024423946} | train loss {'Reaction outcome loss': 0.8272550434236102, 'Total loss': 0.8272550434236102}
2022-11-23 00:22:05,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:05,197 INFO:     Epoch: 89
2022-11-23 00:22:06,044 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8047571534460242, 'Total loss': 0.8047571534460242} | train loss {'Reaction outcome loss': 0.8202791158486957, 'Total loss': 0.8202791158486957}
2022-11-23 00:22:06,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:06,044 INFO:     Epoch: 90
2022-11-23 00:22:06,925 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8017962073737924, 'Total loss': 0.8017962073737924} | train loss {'Reaction outcome loss': 0.8146219456545737, 'Total loss': 0.8146219456545737}
2022-11-23 00:22:06,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:06,925 INFO:     Epoch: 91
2022-11-23 00:22:07,806 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8238303918730129, 'Total loss': 0.8238303918730129} | train loss {'Reaction outcome loss': 0.8111919013232838, 'Total loss': 0.8111919013232838}
2022-11-23 00:22:07,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:07,806 INFO:     Epoch: 92
2022-11-23 00:22:08,746 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8002884279597889, 'Total loss': 0.8002884279597889} | train loss {'Reaction outcome loss': 0.8176250303322486, 'Total loss': 0.8176250303322486}
2022-11-23 00:22:08,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:08,746 INFO:     Epoch: 93
2022-11-23 00:22:09,679 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8112972873178396, 'Total loss': 0.8112972873178396} | train loss {'Reaction outcome loss': 0.814807134842583, 'Total loss': 0.814807134842583}
2022-11-23 00:22:09,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:09,680 INFO:     Epoch: 94
2022-11-23 00:22:10,551 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8208791437474164, 'Total loss': 0.8208791437474164} | train loss {'Reaction outcome loss': 0.818573043715616, 'Total loss': 0.818573043715616}
2022-11-23 00:22:10,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:10,551 INFO:     Epoch: 95
2022-11-23 00:22:11,431 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8031783171675422, 'Total loss': 0.8031783171675422} | train loss {'Reaction outcome loss': 0.8138075076375413, 'Total loss': 0.8138075076375413}
2022-11-23 00:22:11,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:11,432 INFO:     Epoch: 96
2022-11-23 00:22:12,284 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7934641438451681, 'Total loss': 0.7934641438451681} | train loss {'Reaction outcome loss': 0.8101815095676584, 'Total loss': 0.8101815095676584}
2022-11-23 00:22:12,284 INFO:     Found new best model at epoch 96
2022-11-23 00:22:12,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:12,285 INFO:     Epoch: 97
2022-11-23 00:22:13,182 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8169330819086595, 'Total loss': 0.8169330819086595} | train loss {'Reaction outcome loss': 0.8216993487798251, 'Total loss': 0.8216993487798251}
2022-11-23 00:22:13,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:13,182 INFO:     Epoch: 98
2022-11-23 00:22:14,068 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7901684059338137, 'Total loss': 0.7901684059338137} | train loss {'Reaction outcome loss': 0.8157257644029764, 'Total loss': 0.8157257644029764}
2022-11-23 00:22:14,068 INFO:     Found new best model at epoch 98
2022-11-23 00:22:14,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:14,069 INFO:     Epoch: 99
2022-11-23 00:22:15,056 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8127336156639186, 'Total loss': 0.8127336156639186} | train loss {'Reaction outcome loss': 0.8112532237039404, 'Total loss': 0.8112532237039404}
2022-11-23 00:22:15,056 INFO:     Best model found after epoch 99 of 100.
2022-11-23 00:22:15,056 INFO:   Done with stage: TRAINING
2022-11-23 00:22:15,057 INFO:   Starting stage: EVALUATION
2022-11-23 00:22:15,183 INFO:   Done with stage: EVALUATION
2022-11-23 00:22:15,183 INFO:   Leaving out SEQ value Fold_2
2022-11-23 00:22:15,197 INFO:   examples: 20,544| examples in train: 15,422 | examples in val: 2,722| examples in test: 2,400
2022-11-23 00:22:15,197 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:22:15,877 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:22:15,877 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:22:15,948 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:22:15,948 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:22:15,948 INFO:     No hyperparam tuning for this model
2022-11-23 00:22:15,948 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:22:15,948 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:22:15,949 INFO:     None feature selector for col prot
2022-11-23 00:22:15,949 INFO:     None feature selector for col prot
2022-11-23 00:22:15,949 INFO:     None feature selector for col prot
2022-11-23 00:22:15,950 INFO:     None feature selector for col chem
2022-11-23 00:22:15,950 INFO:     None feature selector for col chem
2022-11-23 00:22:15,950 INFO:     None feature selector for col chem
2022-11-23 00:22:15,950 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:22:15,951 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:22:15,952 INFO:     Number of params in model 168571
2022-11-23 00:22:15,956 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:22:15,956 INFO:   Starting stage: TRAINING
2022-11-23 00:22:16,015 INFO:     Val loss before train {'Reaction outcome loss': 1.0100091543308525, 'Total loss': 1.0100091543308525}
2022-11-23 00:22:16,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:16,015 INFO:     Epoch: 0
2022-11-23 00:22:16,888 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.844460865092832, 'Total loss': 0.844460865092832} | train loss {'Reaction outcome loss': 0.8626954220389924, 'Total loss': 0.8626954220389924}
2022-11-23 00:22:16,888 INFO:     Found new best model at epoch 0
2022-11-23 00:22:16,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:16,889 INFO:     Epoch: 1
2022-11-23 00:22:17,783 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8564880434856859, 'Total loss': 0.8564880434856859} | train loss {'Reaction outcome loss': 0.8369114577028267, 'Total loss': 0.8369114577028267}
2022-11-23 00:22:17,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:17,783 INFO:     Epoch: 2
2022-11-23 00:22:18,657 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8780045530130697, 'Total loss': 0.8780045530130697} | train loss {'Reaction outcome loss': 0.8348435047256502, 'Total loss': 0.8348435047256502}
2022-11-23 00:22:18,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:18,657 INFO:     Epoch: 3
2022-11-23 00:22:19,530 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8345827481081319, 'Total loss': 0.8345827481081319} | train loss {'Reaction outcome loss': 0.8281761187735435, 'Total loss': 0.8281761187735435}
2022-11-23 00:22:19,531 INFO:     Found new best model at epoch 3
2022-11-23 00:22:19,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:19,531 INFO:     Epoch: 4
2022-11-23 00:22:20,393 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8301443693249725, 'Total loss': 0.8301443693249725} | train loss {'Reaction outcome loss': 0.8281181381698466, 'Total loss': 0.8281181381698466}
2022-11-23 00:22:20,393 INFO:     Found new best model at epoch 4
2022-11-23 00:22:20,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:20,394 INFO:     Epoch: 5
2022-11-23 00:22:21,251 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8271434182344481, 'Total loss': 0.8271434182344481} | train loss {'Reaction outcome loss': 0.8213480370915283, 'Total loss': 0.8213480370915283}
2022-11-23 00:22:21,251 INFO:     Found new best model at epoch 5
2022-11-23 00:22:21,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:21,252 INFO:     Epoch: 6
2022-11-23 00:22:22,139 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8013773768447167, 'Total loss': 0.8013773768447167} | train loss {'Reaction outcome loss': 0.8207614207910799, 'Total loss': 0.8207614207910799}
2022-11-23 00:22:22,139 INFO:     Found new best model at epoch 6
2022-11-23 00:22:22,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:22,140 INFO:     Epoch: 7
2022-11-23 00:22:22,991 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8603931887205257, 'Total loss': 0.8603931887205257} | train loss {'Reaction outcome loss': 0.8202438248143651, 'Total loss': 0.8202438248143651}
2022-11-23 00:22:22,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:22,991 INFO:     Epoch: 8
2022-11-23 00:22:23,826 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8239174901052962, 'Total loss': 0.8239174901052962} | train loss {'Reaction outcome loss': 0.8159213482838943, 'Total loss': 0.8159213482838943}
2022-11-23 00:22:23,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:23,827 INFO:     Epoch: 9
2022-11-23 00:22:24,701 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8260522886764171, 'Total loss': 0.8260522886764171} | train loss {'Reaction outcome loss': 0.8178294308452685, 'Total loss': 0.8178294308452685}
2022-11-23 00:22:24,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:24,701 INFO:     Epoch: 10
2022-11-23 00:22:25,555 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8245846414288809, 'Total loss': 0.8245846414288809} | train loss {'Reaction outcome loss': 0.8211293339234664, 'Total loss': 0.8211293339234664}
2022-11-23 00:22:25,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:25,555 INFO:     Epoch: 11
2022-11-23 00:22:26,404 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8187014273432798, 'Total loss': 0.8187014273432798} | train loss {'Reaction outcome loss': 0.8170853975650186, 'Total loss': 0.8170853975650186}
2022-11-23 00:22:26,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:26,404 INFO:     Epoch: 12
2022-11-23 00:22:27,259 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8474507719971413, 'Total loss': 0.8474507719971413} | train loss {'Reaction outcome loss': 0.813827307763436, 'Total loss': 0.813827307763436}
2022-11-23 00:22:27,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:27,260 INFO:     Epoch: 13
2022-11-23 00:22:28,097 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8065999893601551, 'Total loss': 0.8065999893601551} | train loss {'Reaction outcome loss': 0.8138044755983155, 'Total loss': 0.8138044755983155}
2022-11-23 00:22:28,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:28,098 INFO:     Epoch: 14
2022-11-23 00:22:28,950 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8397675128870232, 'Total loss': 0.8397675128870232} | train loss {'Reaction outcome loss': 0.8175250082837101, 'Total loss': 0.8175250082837101}
2022-11-23 00:22:28,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:28,950 INFO:     Epoch: 15
2022-11-23 00:22:29,813 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8139398881169253, 'Total loss': 0.8139398881169253} | train loss {'Reaction outcome loss': 0.8133245764678939, 'Total loss': 0.8133245764678939}
2022-11-23 00:22:29,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:29,814 INFO:     Epoch: 16
2022-11-23 00:22:30,681 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7954119132008663, 'Total loss': 0.7954119132008663} | train loss {'Reaction outcome loss': 0.8145956837290056, 'Total loss': 0.8145956837290056}
2022-11-23 00:22:30,681 INFO:     Found new best model at epoch 16
2022-11-23 00:22:30,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:30,682 INFO:     Epoch: 17
2022-11-23 00:22:31,505 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8124025769011919, 'Total loss': 0.8124025769011919} | train loss {'Reaction outcome loss': 0.8114823488773647, 'Total loss': 0.8114823488773647}
2022-11-23 00:22:31,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:31,505 INFO:     Epoch: 18
2022-11-23 00:22:32,405 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8310481850491014, 'Total loss': 0.8310481850491014} | train loss {'Reaction outcome loss': 0.8089126029449875, 'Total loss': 0.8089126029449875}
2022-11-23 00:22:32,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:32,405 INFO:     Epoch: 19
2022-11-23 00:22:33,251 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8227220309335131, 'Total loss': 0.8227220309335131} | train loss {'Reaction outcome loss': 0.8132345046987177, 'Total loss': 0.8132345046987177}
2022-11-23 00:22:33,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:33,252 INFO:     Epoch: 20
2022-11-23 00:22:34,099 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8073212199432905, 'Total loss': 0.8073212199432905} | train loss {'Reaction outcome loss': 0.8156135822974795, 'Total loss': 0.8156135822974795}
2022-11-23 00:22:34,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:34,099 INFO:     Epoch: 21
2022-11-23 00:22:34,957 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8104749495206878, 'Total loss': 0.8104749495206878} | train loss {'Reaction outcome loss': 0.810644981153773, 'Total loss': 0.810644981153773}
2022-11-23 00:22:34,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:34,958 INFO:     Epoch: 22
2022-11-23 00:22:35,824 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8005317116892615, 'Total loss': 0.8005317116892615} | train loss {'Reaction outcome loss': 0.8132462032850353, 'Total loss': 0.8132462032850353}
2022-11-23 00:22:35,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:35,826 INFO:     Epoch: 23
2022-11-23 00:22:36,697 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8112530694451443, 'Total loss': 0.8112530694451443} | train loss {'Reaction outcome loss': 0.8103622598766786, 'Total loss': 0.8103622598766786}
2022-11-23 00:22:36,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:36,698 INFO:     Epoch: 24
2022-11-23 00:22:37,544 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8113568009332169, 'Total loss': 0.8113568009332169} | train loss {'Reaction outcome loss': 0.8127085612275293, 'Total loss': 0.8127085612275293}
2022-11-23 00:22:37,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:37,545 INFO:     Epoch: 25
2022-11-23 00:22:38,388 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8119844683381015, 'Total loss': 0.8119844683381015} | train loss {'Reaction outcome loss': 0.810503369297724, 'Total loss': 0.810503369297724}
2022-11-23 00:22:38,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:38,388 INFO:     Epoch: 26
2022-11-23 00:22:39,239 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8102667581203372, 'Total loss': 0.8102667581203372} | train loss {'Reaction outcome loss': 0.8082389020326226, 'Total loss': 0.8082389020326226}
2022-11-23 00:22:39,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:39,240 INFO:     Epoch: 27
2022-11-23 00:22:40,141 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8049295059470243, 'Total loss': 0.8049295059470243} | train loss {'Reaction outcome loss': 0.8084269825106339, 'Total loss': 0.8084269825106339}
2022-11-23 00:22:40,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:40,141 INFO:     Epoch: 28
2022-11-23 00:22:41,019 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.819000335626824, 'Total loss': 0.819000335626824} | train loss {'Reaction outcome loss': 0.8086360038810746, 'Total loss': 0.8086360038810746}
2022-11-23 00:22:41,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:41,020 INFO:     Epoch: 29
2022-11-23 00:22:41,813 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8103389490482419, 'Total loss': 0.8103389490482419} | train loss {'Reaction outcome loss': 0.8088258593903538, 'Total loss': 0.8088258593903538}
2022-11-23 00:22:41,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:41,813 INFO:     Epoch: 30
2022-11-23 00:22:42,693 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8191608405390451, 'Total loss': 0.8191608405390451} | train loss {'Reaction outcome loss': 0.8062320953830149, 'Total loss': 0.8062320953830149}
2022-11-23 00:22:42,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:42,694 INFO:     Epoch: 31
2022-11-23 00:22:43,588 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8072092990542568, 'Total loss': 0.8072092990542568} | train loss {'Reaction outcome loss': 0.8088140012812318, 'Total loss': 0.8088140012812318}
2022-11-23 00:22:43,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:43,588 INFO:     Epoch: 32
2022-11-23 00:22:44,415 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8194846039594605, 'Total loss': 0.8194846039594605} | train loss {'Reaction outcome loss': 0.8060602286049934, 'Total loss': 0.8060602286049934}
2022-11-23 00:22:44,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:44,415 INFO:     Epoch: 33
2022-11-23 00:22:45,206 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8002956987813462, 'Total loss': 0.8002956987813462} | train loss {'Reaction outcome loss': 0.8057348702211103, 'Total loss': 0.8057348702211103}
2022-11-23 00:22:45,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:45,206 INFO:     Epoch: 34
2022-11-23 00:22:46,076 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8139591861602872, 'Total loss': 0.8139591861602872} | train loss {'Reaction outcome loss': 0.8093363637746123, 'Total loss': 0.8093363637746123}
2022-11-23 00:22:46,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:46,077 INFO:     Epoch: 35
2022-11-23 00:22:46,880 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8074118619741395, 'Total loss': 0.8074118619741395} | train loss {'Reaction outcome loss': 0.8037563114740047, 'Total loss': 0.8037563114740047}
2022-11-23 00:22:46,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:46,880 INFO:     Epoch: 36
2022-11-23 00:22:47,744 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8132285149984582, 'Total loss': 0.8132285149984582} | train loss {'Reaction outcome loss': 0.8105595481593579, 'Total loss': 0.8105595481593579}
2022-11-23 00:22:47,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:47,745 INFO:     Epoch: 37
2022-11-23 00:22:48,624 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8115912966949995, 'Total loss': 0.8115912966949995} | train loss {'Reaction outcome loss': 0.8082983577894473, 'Total loss': 0.8082983577894473}
2022-11-23 00:22:48,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:48,624 INFO:     Epoch: 38
2022-11-23 00:22:49,522 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.796370197174161, 'Total loss': 0.796370197174161} | train loss {'Reaction outcome loss': 0.8094549261930077, 'Total loss': 0.8094549261930077}
2022-11-23 00:22:49,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:49,522 INFO:     Epoch: 39
2022-11-23 00:22:50,389 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7981857643571011, 'Total loss': 0.7981857643571011} | train loss {'Reaction outcome loss': 0.8061803095815587, 'Total loss': 0.8061803095815587}
2022-11-23 00:22:50,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:50,389 INFO:     Epoch: 40
2022-11-23 00:22:51,265 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8017917774444403, 'Total loss': 0.8017917774444403} | train loss {'Reaction outcome loss': 0.8057201121357961, 'Total loss': 0.8057201121357961}
2022-11-23 00:22:51,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:51,265 INFO:     Epoch: 41
2022-11-23 00:22:52,109 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8363896254883256, 'Total loss': 0.8363896254883256} | train loss {'Reaction outcome loss': 0.80718140236075, 'Total loss': 0.80718140236075}
2022-11-23 00:22:52,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:52,109 INFO:     Epoch: 42
2022-11-23 00:22:52,933 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8217456507128339, 'Total loss': 0.8217456507128339} | train loss {'Reaction outcome loss': 0.8072552406441621, 'Total loss': 0.8072552406441621}
2022-11-23 00:22:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:52,934 INFO:     Epoch: 43
2022-11-23 00:22:53,798 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7996065283930579, 'Total loss': 0.7996065283930579} | train loss {'Reaction outcome loss': 0.809414140663701, 'Total loss': 0.809414140663701}
2022-11-23 00:22:53,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:53,798 INFO:     Epoch: 44
2022-11-23 00:22:54,645 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8098214282545932, 'Total loss': 0.8098214282545932} | train loss {'Reaction outcome loss': 0.8083013753673348, 'Total loss': 0.8083013753673348}
2022-11-23 00:22:54,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:54,646 INFO:     Epoch: 45
2022-11-23 00:22:55,497 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8325553231461104, 'Total loss': 0.8325553231461104} | train loss {'Reaction outcome loss': 0.8046110048580961, 'Total loss': 0.8046110048580961}
2022-11-23 00:22:55,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:55,498 INFO:     Epoch: 46
2022-11-23 00:22:56,354 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.813561420801074, 'Total loss': 0.813561420801074} | train loss {'Reaction outcome loss': 0.8065021023216089, 'Total loss': 0.8065021023216089}
2022-11-23 00:22:56,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:56,354 INFO:     Epoch: 47
2022-11-23 00:22:57,225 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8036372897236846, 'Total loss': 0.8036372897236846} | train loss {'Reaction outcome loss': 0.8035197481822176, 'Total loss': 0.8035197481822176}
2022-11-23 00:22:57,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:57,225 INFO:     Epoch: 48
2022-11-23 00:22:58,099 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8138686141302419, 'Total loss': 0.8138686141302419} | train loss {'Reaction outcome loss': 0.8074841609386982, 'Total loss': 0.8074841609386982}
2022-11-23 00:22:58,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:58,100 INFO:     Epoch: 49
2022-11-23 00:22:58,908 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.798962461393933, 'Total loss': 0.798962461393933} | train loss {'Reaction outcome loss': 0.803305382921488, 'Total loss': 0.803305382921488}
2022-11-23 00:22:58,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:58,908 INFO:     Epoch: 50
2022-11-23 00:22:59,768 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8012381341568259, 'Total loss': 0.8012381341568259} | train loss {'Reaction outcome loss': 0.8137405070773793, 'Total loss': 0.8137405070773793}
2022-11-23 00:22:59,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:22:59,768 INFO:     Epoch: 51
2022-11-23 00:23:00,687 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8160004567268283, 'Total loss': 0.8160004567268283} | train loss {'Reaction outcome loss': 0.8023659809496393, 'Total loss': 0.8023659809496393}
2022-11-23 00:23:00,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:00,688 INFO:     Epoch: 52
2022-11-23 00:23:01,553 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8385810789673828, 'Total loss': 0.8385810789673828} | train loss {'Reaction outcome loss': 0.8033510021154316, 'Total loss': 0.8033510021154316}
2022-11-23 00:23:01,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:01,553 INFO:     Epoch: 53
2022-11-23 00:23:02,424 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7976593139559723, 'Total loss': 0.7976593139559723} | train loss {'Reaction outcome loss': 0.8035756652533266, 'Total loss': 0.8035756652533266}
2022-11-23 00:23:02,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:02,425 INFO:     Epoch: 54
2022-11-23 00:23:03,312 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8144691018171089, 'Total loss': 0.8144691018171089} | train loss {'Reaction outcome loss': 0.8059707899805916, 'Total loss': 0.8059707899805916}
2022-11-23 00:23:03,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:03,312 INFO:     Epoch: 55
2022-11-23 00:23:04,166 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8098161296789036, 'Total loss': 0.8098161296789036} | train loss {'Reaction outcome loss': 0.8038839393631552, 'Total loss': 0.8038839393631552}
2022-11-23 00:23:04,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:04,167 INFO:     Epoch: 56
2022-11-23 00:23:04,927 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7961458307366038, 'Total loss': 0.7961458307366038} | train loss {'Reaction outcome loss': 0.8037410113821386, 'Total loss': 0.8037410113821386}
2022-11-23 00:23:04,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:04,927 INFO:     Epoch: 57
2022-11-23 00:23:05,718 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8103472514207973, 'Total loss': 0.8103472514207973} | train loss {'Reaction outcome loss': 0.8044075354995569, 'Total loss': 0.8044075354995569}
2022-11-23 00:23:05,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:05,719 INFO:     Epoch: 58
2022-11-23 00:23:06,497 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8463688381882601, 'Total loss': 0.8463688381882601} | train loss {'Reaction outcome loss': 0.8052320628739986, 'Total loss': 0.8052320628739986}
2022-11-23 00:23:06,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:06,497 INFO:     Epoch: 59
2022-11-23 00:23:07,292 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8074634241503339, 'Total loss': 0.8074634241503339} | train loss {'Reaction outcome loss': 0.8037621218139205, 'Total loss': 0.8037621218139205}
2022-11-23 00:23:07,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:07,294 INFO:     Epoch: 60
2022-11-23 00:23:08,079 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7934280675511027, 'Total loss': 0.7934280675511027} | train loss {'Reaction outcome loss': 0.803564314772974, 'Total loss': 0.803564314772974}
2022-11-23 00:23:08,080 INFO:     Found new best model at epoch 60
2022-11-23 00:23:08,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:08,080 INFO:     Epoch: 61
2022-11-23 00:23:08,858 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7936488840469095, 'Total loss': 0.7936488840469095} | train loss {'Reaction outcome loss': 0.8060588390253391, 'Total loss': 0.8060588390253391}
2022-11-23 00:23:08,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:08,858 INFO:     Epoch: 62
2022-11-23 00:23:09,638 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8015777621158334, 'Total loss': 0.8015777621158334} | train loss {'Reaction outcome loss': 0.8032053825271575, 'Total loss': 0.8032053825271575}
2022-11-23 00:23:09,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:09,638 INFO:     Epoch: 63
2022-11-23 00:23:10,404 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7998237817786461, 'Total loss': 0.7998237817786461} | train loss {'Reaction outcome loss': 0.8048168727471126, 'Total loss': 0.8048168727471126}
2022-11-23 00:23:10,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:10,404 INFO:     Epoch: 64
2022-11-23 00:23:11,165 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8039458525735278, 'Total loss': 0.8039458525735278} | train loss {'Reaction outcome loss': 0.8036153595971863, 'Total loss': 0.8036153595971863}
2022-11-23 00:23:11,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:11,166 INFO:     Epoch: 65
2022-11-23 00:23:11,926 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8483059863711513, 'Total loss': 0.8483059863711513} | train loss {'Reaction outcome loss': 0.8041570066663735, 'Total loss': 0.8041570066663735}
2022-11-23 00:23:11,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:11,926 INFO:     Epoch: 66
2022-11-23 00:23:12,699 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8377599750840387, 'Total loss': 0.8377599750840387} | train loss {'Reaction outcome loss': 0.8055981257891753, 'Total loss': 0.8055981257891753}
2022-11-23 00:23:12,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:12,700 INFO:     Epoch: 67
2022-11-23 00:23:13,469 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7998573599859725, 'Total loss': 0.7998573599859725} | train loss {'Reaction outcome loss': 0.80334135432461, 'Total loss': 0.80334135432461}
2022-11-23 00:23:13,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:13,470 INFO:     Epoch: 68
2022-11-23 00:23:14,235 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8066999288492425, 'Total loss': 0.8066999288492425} | train loss {'Reaction outcome loss': 0.8060046010863237, 'Total loss': 0.8060046010863237}
2022-11-23 00:23:14,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:14,235 INFO:     Epoch: 69
2022-11-23 00:23:15,002 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7997936246006988, 'Total loss': 0.7997936246006988} | train loss {'Reaction outcome loss': 0.8021660815630711, 'Total loss': 0.8021660815630711}
2022-11-23 00:23:15,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:15,002 INFO:     Epoch: 70
2022-11-23 00:23:15,772 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7931780309178108, 'Total loss': 0.7931780309178108} | train loss {'Reaction outcome loss': 0.8031424110855799, 'Total loss': 0.8031424110855799}
2022-11-23 00:23:15,772 INFO:     Found new best model at epoch 70
2022-11-23 00:23:15,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:15,773 INFO:     Epoch: 71
2022-11-23 00:23:16,523 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7915669416272363, 'Total loss': 0.7915669416272363} | train loss {'Reaction outcome loss': 0.8036064257018299, 'Total loss': 0.8036064257018299}
2022-11-23 00:23:16,524 INFO:     Found new best model at epoch 71
2022-11-23 00:23:16,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:16,524 INFO:     Epoch: 72
2022-11-23 00:23:17,299 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8296710744846699, 'Total loss': 0.8296710744846699} | train loss {'Reaction outcome loss': 0.8014552141868228, 'Total loss': 0.8014552141868228}
2022-11-23 00:23:17,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:17,299 INFO:     Epoch: 73
2022-11-23 00:23:18,063 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8121345604574958, 'Total loss': 0.8121345604574958} | train loss {'Reaction outcome loss': 0.8026442479543171, 'Total loss': 0.8026442479543171}
2022-11-23 00:23:18,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:18,063 INFO:     Epoch: 74
2022-11-23 00:23:18,830 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8001289728075959, 'Total loss': 0.8001289728075959} | train loss {'Reaction outcome loss': 0.7971967079085434, 'Total loss': 0.7971967079085434}
2022-11-23 00:23:18,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:18,830 INFO:     Epoch: 75
2022-11-23 00:23:19,584 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8308343526928924, 'Total loss': 0.8308343526928924} | train loss {'Reaction outcome loss': 0.7992729121100358, 'Total loss': 0.7992729121100358}
2022-11-23 00:23:19,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:19,584 INFO:     Epoch: 76
2022-11-23 00:23:20,340 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8019812924917354, 'Total loss': 0.8019812924917354} | train loss {'Reaction outcome loss': 0.806508097596683, 'Total loss': 0.806508097596683}
2022-11-23 00:23:20,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:20,340 INFO:     Epoch: 77
2022-11-23 00:23:21,117 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7924798733966295, 'Total loss': 0.7924798733966295} | train loss {'Reaction outcome loss': 0.8039035366778552, 'Total loss': 0.8039035366778552}
2022-11-23 00:23:21,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:21,117 INFO:     Epoch: 78
2022-11-23 00:23:21,946 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7981363410173461, 'Total loss': 0.7981363410173461} | train loss {'Reaction outcome loss': 0.80068833031595, 'Total loss': 0.80068833031595}
2022-11-23 00:23:21,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:21,946 INFO:     Epoch: 79
2022-11-23 00:23:22,784 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7910442920618279, 'Total loss': 0.7910442920618279} | train loss {'Reaction outcome loss': 0.798873291037884, 'Total loss': 0.798873291037884}
2022-11-23 00:23:22,784 INFO:     Found new best model at epoch 79
2022-11-23 00:23:22,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:22,785 INFO:     Epoch: 80
2022-11-23 00:23:23,583 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8001521423805592, 'Total loss': 0.8001521423805592} | train loss {'Reaction outcome loss': 0.7996806823861055, 'Total loss': 0.7996806823861055}
2022-11-23 00:23:23,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:23,583 INFO:     Epoch: 81
2022-11-23 00:23:24,343 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8021630443805872, 'Total loss': 0.8021630443805872} | train loss {'Reaction outcome loss': 0.7983028575839838, 'Total loss': 0.7983028575839838}
2022-11-23 00:23:24,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:24,344 INFO:     Epoch: 82
2022-11-23 00:23:25,137 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7963383433430694, 'Total loss': 0.7963383433430694} | train loss {'Reaction outcome loss': 0.7981336372769225, 'Total loss': 0.7981336372769225}
2022-11-23 00:23:25,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:25,137 INFO:     Epoch: 83
2022-11-23 00:23:25,922 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8257055019223413, 'Total loss': 0.8257055019223413} | train loss {'Reaction outcome loss': 0.8012583046780583, 'Total loss': 0.8012583046780583}
2022-11-23 00:23:25,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:25,923 INFO:     Epoch: 84
2022-11-23 00:23:26,691 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7933498343756032, 'Total loss': 0.7933498343756032} | train loss {'Reaction outcome loss': 0.8043562747630836, 'Total loss': 0.8043562747630836}
2022-11-23 00:23:26,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:26,691 INFO:     Epoch: 85
2022-11-23 00:23:27,463 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7956177550692891, 'Total loss': 0.7956177550692891} | train loss {'Reaction outcome loss': 0.7993508579820023, 'Total loss': 0.7993508579820023}
2022-11-23 00:23:27,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:27,464 INFO:     Epoch: 86
2022-11-23 00:23:28,238 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7973602857700613, 'Total loss': 0.7973602857700613} | train loss {'Reaction outcome loss': 0.800934743584439, 'Total loss': 0.800934743584439}
2022-11-23 00:23:28,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:28,238 INFO:     Epoch: 87
2022-11-23 00:23:29,009 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8001422556333764, 'Total loss': 0.8001422556333764} | train loss {'Reaction outcome loss': 0.8003536144974815, 'Total loss': 0.8003536144974815}
2022-11-23 00:23:29,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:29,010 INFO:     Epoch: 88
2022-11-23 00:23:29,773 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7856396519860556, 'Total loss': 0.7856396519860556} | train loss {'Reaction outcome loss': 0.8003544765389312, 'Total loss': 0.8003544765389312}
2022-11-23 00:23:29,774 INFO:     Found new best model at epoch 88
2022-11-23 00:23:29,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:29,774 INFO:     Epoch: 89
2022-11-23 00:23:30,519 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8089041231676589, 'Total loss': 0.8089041231676589} | train loss {'Reaction outcome loss': 0.8026056464034986, 'Total loss': 0.8026056464034986}
2022-11-23 00:23:30,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:30,519 INFO:     Epoch: 90
2022-11-23 00:23:31,337 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8154431262681651, 'Total loss': 0.8154431262681651} | train loss {'Reaction outcome loss': 0.7983592909401384, 'Total loss': 0.7983592909401384}
2022-11-23 00:23:31,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:31,337 INFO:     Epoch: 91
2022-11-23 00:23:32,119 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8249839918557987, 'Total loss': 0.8249839918557987} | train loss {'Reaction outcome loss': 0.7970563806438842, 'Total loss': 0.7970563806438842}
2022-11-23 00:23:32,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:32,119 INFO:     Epoch: 92
2022-11-23 00:23:32,940 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8067264986592669, 'Total loss': 0.8067264986592669} | train loss {'Reaction outcome loss': 0.803502001826694, 'Total loss': 0.803502001826694}
2022-11-23 00:23:32,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:32,941 INFO:     Epoch: 93
2022-11-23 00:23:33,728 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8057537771934686, 'Total loss': 0.8057537771934686} | train loss {'Reaction outcome loss': 0.7983733535554893, 'Total loss': 0.7983733535554893}
2022-11-23 00:23:33,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:33,729 INFO:     Epoch: 94
2022-11-23 00:23:34,530 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7883787855159404, 'Total loss': 0.7883787855159404} | train loss {'Reaction outcome loss': 0.8011151552200317, 'Total loss': 0.8011151552200317}
2022-11-23 00:23:34,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:34,531 INFO:     Epoch: 95
2022-11-23 00:23:35,308 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8016508311726326, 'Total loss': 0.8016508311726326} | train loss {'Reaction outcome loss': 0.7962328604890103, 'Total loss': 0.7962328604890103}
2022-11-23 00:23:35,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:35,308 INFO:     Epoch: 96
2022-11-23 00:23:36,059 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7904121785662895, 'Total loss': 0.7904121785662895} | train loss {'Reaction outcome loss': 0.7975205598530433, 'Total loss': 0.7975205598530433}
2022-11-23 00:23:36,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:36,059 INFO:     Epoch: 97
2022-11-23 00:23:36,802 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8193699031375176, 'Total loss': 0.8193699031375176} | train loss {'Reaction outcome loss': 0.7958807490178659, 'Total loss': 0.7958807490178659}
2022-11-23 00:23:36,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:36,802 INFO:     Epoch: 98
2022-11-23 00:23:37,550 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7985855736011682, 'Total loss': 0.7985855736011682} | train loss {'Reaction outcome loss': 0.7968328868452444, 'Total loss': 0.7968328868452444}
2022-11-23 00:23:37,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:37,551 INFO:     Epoch: 99
2022-11-23 00:23:38,317 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8133430487887804, 'Total loss': 0.8133430487887804} | train loss {'Reaction outcome loss': 0.7963042280238694, 'Total loss': 0.7963042280238694}
2022-11-23 00:23:38,318 INFO:     Best model found after epoch 89 of 100.
2022-11-23 00:23:38,318 INFO:   Done with stage: TRAINING
2022-11-23 00:23:38,318 INFO:   Starting stage: EVALUATION
2022-11-23 00:23:38,466 INFO:   Done with stage: EVALUATION
2022-11-23 00:23:38,466 INFO:   Leaving out SEQ value Fold_3
2022-11-23 00:23:38,479 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 00:23:38,479 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:23:39,139 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:23:39,139 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:23:39,210 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:23:39,210 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:23:39,211 INFO:     No hyperparam tuning for this model
2022-11-23 00:23:39,211 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:23:39,211 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:23:39,212 INFO:     None feature selector for col prot
2022-11-23 00:23:39,212 INFO:     None feature selector for col prot
2022-11-23 00:23:39,212 INFO:     None feature selector for col prot
2022-11-23 00:23:39,213 INFO:     None feature selector for col chem
2022-11-23 00:23:39,213 INFO:     None feature selector for col chem
2022-11-23 00:23:39,213 INFO:     None feature selector for col chem
2022-11-23 00:23:39,213 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:23:39,213 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:23:39,215 INFO:     Number of params in model 168571
2022-11-23 00:23:39,218 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:23:39,218 INFO:   Starting stage: TRAINING
2022-11-23 00:23:39,275 INFO:     Val loss before train {'Reaction outcome loss': 1.0042959645737048, 'Total loss': 1.0042959645737048}
2022-11-23 00:23:39,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:39,275 INFO:     Epoch: 0
2022-11-23 00:23:40,031 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8139446031215579, 'Total loss': 0.8139446031215579} | train loss {'Reaction outcome loss': 0.87868384064221, 'Total loss': 0.87868384064221}
2022-11-23 00:23:40,032 INFO:     Found new best model at epoch 0
2022-11-23 00:23:40,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:40,033 INFO:     Epoch: 1
2022-11-23 00:23:40,790 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8089104079922964, 'Total loss': 0.8089104079922964} | train loss {'Reaction outcome loss': 0.8445433143709526, 'Total loss': 0.8445433143709526}
2022-11-23 00:23:40,790 INFO:     Found new best model at epoch 1
2022-11-23 00:23:40,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:40,790 INFO:     Epoch: 2
2022-11-23 00:23:41,560 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8187996648078741, 'Total loss': 0.8187996648078741} | train loss {'Reaction outcome loss': 0.8412701922361968, 'Total loss': 0.8412701922361968}
2022-11-23 00:23:41,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:41,560 INFO:     Epoch: 3
2022-11-23 00:23:42,349 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8136008478874384, 'Total loss': 0.8136008478874384} | train loss {'Reaction outcome loss': 0.8343249679100319, 'Total loss': 0.8343249679100319}
2022-11-23 00:23:42,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:42,349 INFO:     Epoch: 4
2022-11-23 00:23:43,118 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8002342630264371, 'Total loss': 0.8002342630264371} | train loss {'Reaction outcome loss': 0.8264283664890977, 'Total loss': 0.8264283664890977}
2022-11-23 00:23:43,118 INFO:     Found new best model at epoch 4
2022-11-23 00:23:43,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:43,119 INFO:     Epoch: 5
2022-11-23 00:23:43,892 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8035486985084622, 'Total loss': 0.8035486985084622} | train loss {'Reaction outcome loss': 0.8248863541444794, 'Total loss': 0.8248863541444794}
2022-11-23 00:23:43,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:43,892 INFO:     Epoch: 6
2022-11-23 00:23:44,699 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7907272660455038, 'Total loss': 0.7907272660455038} | train loss {'Reaction outcome loss': 0.8275421819970256, 'Total loss': 0.8275421819970256}
2022-11-23 00:23:44,700 INFO:     Found new best model at epoch 6
2022-11-23 00:23:44,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:44,701 INFO:     Epoch: 7
2022-11-23 00:23:45,491 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8007872208606365, 'Total loss': 0.8007872208606365} | train loss {'Reaction outcome loss': 0.822183999370356, 'Total loss': 0.822183999370356}
2022-11-23 00:23:45,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:45,491 INFO:     Epoch: 8
2022-11-23 00:23:46,260 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8037827139677003, 'Total loss': 0.8037827139677003} | train loss {'Reaction outcome loss': 0.8249393177569889, 'Total loss': 0.8249393177569889}
2022-11-23 00:23:46,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:46,260 INFO:     Epoch: 9
2022-11-23 00:23:47,059 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8021109270495038, 'Total loss': 0.8021109270495038} | train loss {'Reaction outcome loss': 0.8206670184726598, 'Total loss': 0.8206670184726598}
2022-11-23 00:23:47,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:47,059 INFO:     Epoch: 10
2022-11-23 00:23:47,845 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8198740787284319, 'Total loss': 0.8198740787284319} | train loss {'Reaction outcome loss': 0.8185033946007979, 'Total loss': 0.8185033946007979}
2022-11-23 00:23:47,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:47,845 INFO:     Epoch: 11
2022-11-23 00:23:48,636 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8025605158750401, 'Total loss': 0.8025605158750401} | train loss {'Reaction outcome loss': 0.8227871558705314, 'Total loss': 0.8227871558705314}
2022-11-23 00:23:48,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:48,636 INFO:     Epoch: 12
2022-11-23 00:23:49,423 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7963917394017064, 'Total loss': 0.7963917394017064} | train loss {'Reaction outcome loss': 0.8190837287511982, 'Total loss': 0.8190837287511982}
2022-11-23 00:23:49,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:49,423 INFO:     Epoch: 13
2022-11-23 00:23:50,227 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8010925082273261, 'Total loss': 0.8010925082273261} | train loss {'Reaction outcome loss': 0.8231149886230953, 'Total loss': 0.8231149886230953}
2022-11-23 00:23:50,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:50,227 INFO:     Epoch: 14
2022-11-23 00:23:50,991 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8043407250282376, 'Total loss': 0.8043407250282376} | train loss {'Reaction outcome loss': 0.8211296193423818, 'Total loss': 0.8211296193423818}
2022-11-23 00:23:50,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:50,991 INFO:     Epoch: 15
2022-11-23 00:23:51,786 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7919692390186842, 'Total loss': 0.7919692390186842} | train loss {'Reaction outcome loss': 0.8180750318970836, 'Total loss': 0.8180750318970836}
2022-11-23 00:23:51,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:51,786 INFO:     Epoch: 16
2022-11-23 00:23:52,590 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7900931710420653, 'Total loss': 0.7900931710420653} | train loss {'Reaction outcome loss': 0.8198932569290771, 'Total loss': 0.8198932569290771}
2022-11-23 00:23:52,590 INFO:     Found new best model at epoch 16
2022-11-23 00:23:52,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:52,591 INFO:     Epoch: 17
2022-11-23 00:23:53,387 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.804498307233633, 'Total loss': 0.804498307233633} | train loss {'Reaction outcome loss': 0.8192761432929118, 'Total loss': 0.8192761432929118}
2022-11-23 00:23:53,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:53,388 INFO:     Epoch: 18
2022-11-23 00:23:54,187 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8027778032214142, 'Total loss': 0.8027778032214142} | train loss {'Reaction outcome loss': 0.8169817192876925, 'Total loss': 0.8169817192876925}
2022-11-23 00:23:54,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:54,187 INFO:     Epoch: 19
2022-11-23 00:23:55,004 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8108825967755429, 'Total loss': 0.8108825967755429} | train loss {'Reaction outcome loss': 0.8187323133232164, 'Total loss': 0.8187323133232164}
2022-11-23 00:23:55,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:55,005 INFO:     Epoch: 20
2022-11-23 00:23:55,817 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7970487551633701, 'Total loss': 0.7970487551633701} | train loss {'Reaction outcome loss': 0.8138280201886521, 'Total loss': 0.8138280201886521}
2022-11-23 00:23:55,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:55,817 INFO:     Epoch: 21
2022-11-23 00:23:56,614 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7924960636815359, 'Total loss': 0.7924960636815359} | train loss {'Reaction outcome loss': 0.819563663763101, 'Total loss': 0.819563663763101}
2022-11-23 00:23:56,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:56,614 INFO:     Epoch: 22
2022-11-23 00:23:57,403 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8511654720749966, 'Total loss': 0.8511654720749966} | train loss {'Reaction outcome loss': 0.8138187449486529, 'Total loss': 0.8138187449486529}
2022-11-23 00:23:57,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:57,404 INFO:     Epoch: 23
2022-11-23 00:23:58,211 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7964009857454966, 'Total loss': 0.7964009857454966} | train loss {'Reaction outcome loss': 0.8171930374180685, 'Total loss': 0.8171930374180685}
2022-11-23 00:23:58,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:58,211 INFO:     Epoch: 24
2022-11-23 00:23:59,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7931477690851966, 'Total loss': 0.7931477690851966} | train loss {'Reaction outcome loss': 0.8154750692306972, 'Total loss': 0.8154750692306972}
2022-11-23 00:23:59,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:59,029 INFO:     Epoch: 25
2022-11-23 00:23:59,847 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7930522540280985, 'Total loss': 0.7930522540280985} | train loss {'Reaction outcome loss': 0.817648645673619, 'Total loss': 0.817648645673619}
2022-11-23 00:23:59,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:23:59,847 INFO:     Epoch: 26
2022-11-23 00:24:00,638 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7854276978692343, 'Total loss': 0.7854276978692343} | train loss {'Reaction outcome loss': 0.8144913690744854, 'Total loss': 0.8144913690744854}
2022-11-23 00:24:00,639 INFO:     Found new best model at epoch 26
2022-11-23 00:24:00,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:00,639 INFO:     Epoch: 27
2022-11-23 00:24:01,426 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7975365263085032, 'Total loss': 0.7975365263085032} | train loss {'Reaction outcome loss': 0.8123342161540126, 'Total loss': 0.8123342161540126}
2022-11-23 00:24:01,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:01,427 INFO:     Epoch: 28
2022-11-23 00:24:02,255 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7929008415965146, 'Total loss': 0.7929008415965146} | train loss {'Reaction outcome loss': 0.8153785057976598, 'Total loss': 0.8153785057976598}
2022-11-23 00:24:02,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:02,255 INFO:     Epoch: 29
2022-11-23 00:24:03,037 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7882753271003102, 'Total loss': 0.7882753271003102} | train loss {'Reaction outcome loss': 0.8151206134772692, 'Total loss': 0.8151206134772692}
2022-11-23 00:24:03,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:03,037 INFO:     Epoch: 30
2022-11-23 00:24:03,853 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8120880792307299, 'Total loss': 0.8120880792307299} | train loss {'Reaction outcome loss': 0.814433828729098, 'Total loss': 0.814433828729098}
2022-11-23 00:24:03,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:03,853 INFO:     Epoch: 31
2022-11-23 00:24:04,671 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7895843816357989, 'Total loss': 0.7895843816357989} | train loss {'Reaction outcome loss': 0.8127946795010176, 'Total loss': 0.8127946795010176}
2022-11-23 00:24:04,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:04,671 INFO:     Epoch: 32
2022-11-23 00:24:05,556 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8070737178935561, 'Total loss': 0.8070737178935561} | train loss {'Reaction outcome loss': 0.8120905690383716, 'Total loss': 0.8120905690383716}
2022-11-23 00:24:05,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:05,556 INFO:     Epoch: 33
2022-11-23 00:24:06,341 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7895138291425483, 'Total loss': 0.7895138291425483} | train loss {'Reaction outcome loss': 0.81564185792794, 'Total loss': 0.81564185792794}
2022-11-23 00:24:06,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:06,342 INFO:     Epoch: 34
2022-11-23 00:24:07,122 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8072594425012899, 'Total loss': 0.8072594425012899} | train loss {'Reaction outcome loss': 0.8122761028467632, 'Total loss': 0.8122761028467632}
2022-11-23 00:24:07,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:07,122 INFO:     Epoch: 35
2022-11-23 00:24:07,903 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7915464833725331, 'Total loss': 0.7915464833725331} | train loss {'Reaction outcome loss': 0.8179744788613476, 'Total loss': 0.8179744788613476}
2022-11-23 00:24:07,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:07,903 INFO:     Epoch: 36
2022-11-23 00:24:08,712 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7960907913917719, 'Total loss': 0.7960907913917719} | train loss {'Reaction outcome loss': 0.8101473964872907, 'Total loss': 0.8101473964872907}
2022-11-23 00:24:08,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:08,712 INFO:     Epoch: 37
2022-11-23 00:24:09,525 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7841050818909047, 'Total loss': 0.7841050818909047} | train loss {'Reaction outcome loss': 0.8125982148969759, 'Total loss': 0.8125982148969759}
2022-11-23 00:24:09,527 INFO:     Found new best model at epoch 37
2022-11-23 00:24:09,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:09,527 INFO:     Epoch: 38
2022-11-23 00:24:10,326 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8075900964958723, 'Total loss': 0.8075900964958723} | train loss {'Reaction outcome loss': 0.8117026784380929, 'Total loss': 0.8117026784380929}
2022-11-23 00:24:10,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:10,326 INFO:     Epoch: 39
2022-11-23 00:24:11,121 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7929859085138454, 'Total loss': 0.7929859085138454} | train loss {'Reaction outcome loss': 0.8102802724623289, 'Total loss': 0.8102802724623289}
2022-11-23 00:24:11,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:11,121 INFO:     Epoch: 40
2022-11-23 00:24:11,908 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7856962708539741, 'Total loss': 0.7856962708539741} | train loss {'Reaction outcome loss': 0.813194813420538, 'Total loss': 0.813194813420538}
2022-11-23 00:24:11,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:11,908 INFO:     Epoch: 41
2022-11-23 00:24:12,697 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7884147354336672, 'Total loss': 0.7884147354336672} | train loss {'Reaction outcome loss': 0.8166143449603535, 'Total loss': 0.8166143449603535}
2022-11-23 00:24:12,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:12,697 INFO:     Epoch: 42
2022-11-23 00:24:13,488 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7984946092893911, 'Total loss': 0.7984946092893911} | train loss {'Reaction outcome loss': 0.810409025334921, 'Total loss': 0.810409025334921}
2022-11-23 00:24:13,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:13,489 INFO:     Epoch: 43
2022-11-23 00:24:14,330 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7967433735381725, 'Total loss': 0.7967433735381725} | train loss {'Reaction outcome loss': 0.8124554733761021, 'Total loss': 0.8124554733761021}
2022-11-23 00:24:14,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:14,330 INFO:     Epoch: 44
2022-11-23 00:24:15,124 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7844795161901519, 'Total loss': 0.7844795161901519} | train loss {'Reaction outcome loss': 0.8126577011874465, 'Total loss': 0.8126577011874465}
2022-11-23 00:24:15,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:15,125 INFO:     Epoch: 45
2022-11-23 00:24:15,910 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8060726689737897, 'Total loss': 0.8060726689737897} | train loss {'Reaction outcome loss': 0.8074940670220578, 'Total loss': 0.8074940670220578}
2022-11-23 00:24:15,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:15,911 INFO:     Epoch: 46
2022-11-23 00:24:16,711 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8173986416916514, 'Total loss': 0.8173986416916514} | train loss {'Reaction outcome loss': 0.8138564636961358, 'Total loss': 0.8138564636961358}
2022-11-23 00:24:16,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:16,711 INFO:     Epoch: 47
2022-11-23 00:24:17,523 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7889731318451637, 'Total loss': 0.7889731318451637} | train loss {'Reaction outcome loss': 0.8114637775255031, 'Total loss': 0.8114637775255031}
2022-11-23 00:24:17,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:17,524 INFO:     Epoch: 48
2022-11-23 00:24:18,323 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7945702228435251, 'Total loss': 0.7945702228435251} | train loss {'Reaction outcome loss': 0.8125371686259254, 'Total loss': 0.8125371686259254}
2022-11-23 00:24:18,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:18,323 INFO:     Epoch: 49
2022-11-23 00:24:19,129 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8114660798117171, 'Total loss': 0.8114660798117171} | train loss {'Reaction outcome loss': 0.8118033948980394, 'Total loss': 0.8118033948980394}
2022-11-23 00:24:19,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:19,130 INFO:     Epoch: 50
2022-11-23 00:24:19,941 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.793819326994031, 'Total loss': 0.793819326994031} | train loss {'Reaction outcome loss': 0.8119492230356716, 'Total loss': 0.8119492230356716}
2022-11-23 00:24:19,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:19,941 INFO:     Epoch: 51
2022-11-23 00:24:20,726 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.785210438939028, 'Total loss': 0.785210438939028} | train loss {'Reaction outcome loss': 0.8116417770258716, 'Total loss': 0.8116417770258716}
2022-11-23 00:24:20,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:20,726 INFO:     Epoch: 52
2022-11-23 00:24:21,503 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8003085241761319, 'Total loss': 0.8003085241761319} | train loss {'Reaction outcome loss': 0.815876696197713, 'Total loss': 0.815876696197713}
2022-11-23 00:24:21,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:21,503 INFO:     Epoch: 53
2022-11-23 00:24:22,285 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.820563486842222, 'Total loss': 0.820563486842222} | train loss {'Reaction outcome loss': 0.807624103837326, 'Total loss': 0.807624103837326}
2022-11-23 00:24:22,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:22,285 INFO:     Epoch: 54
2022-11-23 00:24:23,087 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7794945337051569, 'Total loss': 0.7794945337051569} | train loss {'Reaction outcome loss': 0.8143184376788921, 'Total loss': 0.8143184376788921}
2022-11-23 00:24:23,087 INFO:     Found new best model at epoch 54
2022-11-23 00:24:23,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:23,088 INFO:     Epoch: 55
2022-11-23 00:24:23,880 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7955576791319736, 'Total loss': 0.7955576791319736} | train loss {'Reaction outcome loss': 0.8088562748715525, 'Total loss': 0.8088562748715525}
2022-11-23 00:24:23,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:23,880 INFO:     Epoch: 56
2022-11-23 00:24:24,681 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7998242766358131, 'Total loss': 0.7998242766358131} | train loss {'Reaction outcome loss': 0.8098021329182093, 'Total loss': 0.8098021329182093}
2022-11-23 00:24:24,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:24,681 INFO:     Epoch: 57
2022-11-23 00:24:25,444 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7837183551732884, 'Total loss': 0.7837183551732884} | train loss {'Reaction outcome loss': 0.8126601856507238, 'Total loss': 0.8126601856507238}
2022-11-23 00:24:25,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:25,444 INFO:     Epoch: 58
2022-11-23 00:24:26,276 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7865798618904379, 'Total loss': 0.7865798618904379} | train loss {'Reaction outcome loss': 0.8163202668799728, 'Total loss': 0.8163202668799728}
2022-11-23 00:24:26,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:26,276 INFO:     Epoch: 59
2022-11-23 00:24:27,098 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7945134792216989, 'Total loss': 0.7945134792216989} | train loss {'Reaction outcome loss': 0.810620684115613, 'Total loss': 0.810620684115613}
2022-11-23 00:24:27,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:27,098 INFO:     Epoch: 60
2022-11-23 00:24:27,906 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7986008386279262, 'Total loss': 0.7986008386279262} | train loss {'Reaction outcome loss': 0.8144106001394694, 'Total loss': 0.8144106001394694}
2022-11-23 00:24:27,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:27,906 INFO:     Epoch: 61
2022-11-23 00:24:28,713 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7952182029568872, 'Total loss': 0.7952182029568872} | train loss {'Reaction outcome loss': 0.8144970881890078, 'Total loss': 0.8144970881890078}
2022-11-23 00:24:28,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:28,714 INFO:     Epoch: 62
2022-11-23 00:24:29,505 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7958099544048309, 'Total loss': 0.7958099544048309} | train loss {'Reaction outcome loss': 0.8087715317235619, 'Total loss': 0.8087715317235619}
2022-11-23 00:24:29,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:29,506 INFO:     Epoch: 63
2022-11-23 00:24:30,316 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7899558842182159, 'Total loss': 0.7899558842182159} | train loss {'Reaction outcome loss': 0.8124411901245352, 'Total loss': 0.8124411901245352}
2022-11-23 00:24:30,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:30,316 INFO:     Epoch: 64
2022-11-23 00:24:31,119 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7962002379949703, 'Total loss': 0.7962002379949703} | train loss {'Reaction outcome loss': 0.8100207739921866, 'Total loss': 0.8100207739921866}
2022-11-23 00:24:31,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:31,119 INFO:     Epoch: 65
2022-11-23 00:24:31,906 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7968137395936389, 'Total loss': 0.7968137395936389} | train loss {'Reaction outcome loss': 0.8130368475542694, 'Total loss': 0.8130368475542694}
2022-11-23 00:24:31,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:31,906 INFO:     Epoch: 66
2022-11-23 00:24:32,705 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8505302175532939, 'Total loss': 0.8505302175532939} | train loss {'Reaction outcome loss': 0.8156591631838532, 'Total loss': 0.8156591631838532}
2022-11-23 00:24:32,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:32,705 INFO:     Epoch: 67
2022-11-23 00:24:33,521 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7836237882458886, 'Total loss': 0.7836237882458886} | train loss {'Reaction outcome loss': 0.8122727735365023, 'Total loss': 0.8122727735365023}
2022-11-23 00:24:33,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:33,521 INFO:     Epoch: 68
2022-11-23 00:24:34,322 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7902534728826478, 'Total loss': 0.7902534728826478} | train loss {'Reaction outcome loss': 0.8079151324317103, 'Total loss': 0.8079151324317103}
2022-11-23 00:24:34,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:34,322 INFO:     Epoch: 69
2022-11-23 00:24:35,135 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7982322802377302, 'Total loss': 0.7982322802377302} | train loss {'Reaction outcome loss': 0.8121386484288778, 'Total loss': 0.8121386484288778}
2022-11-23 00:24:35,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:35,135 INFO:     Epoch: 70
2022-11-23 00:24:35,914 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7932400786599447, 'Total loss': 0.7932400786599447} | train loss {'Reaction outcome loss': 0.8109451925656834, 'Total loss': 0.8109451925656834}
2022-11-23 00:24:35,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:35,914 INFO:     Epoch: 71
2022-11-23 00:24:36,705 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7897729242956916, 'Total loss': 0.7897729242956916} | train loss {'Reaction outcome loss': 0.8150136130022221, 'Total loss': 0.8150136130022221}
2022-11-23 00:24:36,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:36,706 INFO:     Epoch: 72
2022-11-23 00:24:37,456 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8177354890246724, 'Total loss': 0.8177354890246724} | train loss {'Reaction outcome loss': 0.8110141395056834, 'Total loss': 0.8110141395056834}
2022-11-23 00:24:37,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:37,457 INFO:     Epoch: 73
2022-11-23 00:24:38,209 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7987377338631209, 'Total loss': 0.7987377338631209} | train loss {'Reaction outcome loss': 0.8149706955815925, 'Total loss': 0.8149706955815925}
2022-11-23 00:24:38,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:38,209 INFO:     Epoch: 74
2022-11-23 00:24:38,997 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.785449646240057, 'Total loss': 0.785449646240057} | train loss {'Reaction outcome loss': 0.8089886815821539, 'Total loss': 0.8089886815821539}
2022-11-23 00:24:38,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:38,997 INFO:     Epoch: 75
2022-11-23 00:24:39,810 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7754342840161434, 'Total loss': 0.7754342840161434} | train loss {'Reaction outcome loss': 0.8128208316496162, 'Total loss': 0.8128208316496162}
2022-11-23 00:24:39,810 INFO:     Found new best model at epoch 75
2022-11-23 00:24:39,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:39,811 INFO:     Epoch: 76
2022-11-23 00:24:40,604 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7923286571059116, 'Total loss': 0.7923286571059116} | train loss {'Reaction outcome loss': 0.8097226857894757, 'Total loss': 0.8097226857894757}
2022-11-23 00:24:40,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:40,605 INFO:     Epoch: 77
2022-11-23 00:24:41,391 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8051101828730384, 'Total loss': 0.8051101828730384} | train loss {'Reaction outcome loss': 0.8179316550004677, 'Total loss': 0.8179316550004677}
2022-11-23 00:24:41,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:41,391 INFO:     Epoch: 78
2022-11-23 00:24:42,224 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7924866253553435, 'Total loss': 0.7924866253553435} | train loss {'Reaction outcome loss': 0.8104163369194406, 'Total loss': 0.8104163369194406}
2022-11-23 00:24:42,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:42,225 INFO:     Epoch: 79
2022-11-23 00:24:43,023 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.776271826999132, 'Total loss': 0.776271826999132} | train loss {'Reaction outcome loss': 0.8109647185831773, 'Total loss': 0.8109647185831773}
2022-11-23 00:24:43,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:43,023 INFO:     Epoch: 80
2022-11-23 00:24:43,867 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8020007125166959, 'Total loss': 0.8020007125166959} | train loss {'Reaction outcome loss': 0.8136672719580228, 'Total loss': 0.8136672719580228}
2022-11-23 00:24:43,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:43,867 INFO:     Epoch: 81
2022-11-23 00:24:44,655 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.801096404707709, 'Total loss': 0.801096404707709} | train loss {'Reaction outcome loss': 0.8132536797249903, 'Total loss': 0.8132536797249903}
2022-11-23 00:24:44,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:44,655 INFO:     Epoch: 82
2022-11-23 00:24:45,430 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7845203890356907, 'Total loss': 0.7845203890356907} | train loss {'Reaction outcome loss': 0.8108162690625816, 'Total loss': 0.8108162690625816}
2022-11-23 00:24:45,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:45,430 INFO:     Epoch: 83
2022-11-23 00:24:46,202 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7838723077330478, 'Total loss': 0.7838723077330478} | train loss {'Reaction outcome loss': 0.8076064662366617, 'Total loss': 0.8076064662366617}
2022-11-23 00:24:46,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:46,202 INFO:     Epoch: 84
2022-11-23 00:24:46,966 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7804864603419637, 'Total loss': 0.7804864603419637} | train loss {'Reaction outcome loss': 0.8172663055726739, 'Total loss': 0.8172663055726739}
2022-11-23 00:24:46,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:46,967 INFO:     Epoch: 85
2022-11-23 00:24:47,736 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7931849027788916, 'Total loss': 0.7931849027788916} | train loss {'Reaction outcome loss': 0.8103485795073821, 'Total loss': 0.8103485795073821}
2022-11-23 00:24:47,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:47,737 INFO:     Epoch: 86
2022-11-23 00:24:48,525 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7908253586569498, 'Total loss': 0.7908253586569498} | train loss {'Reaction outcome loss': 0.8136929769496448, 'Total loss': 0.8136929769496448}
2022-11-23 00:24:48,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:48,525 INFO:     Epoch: 87
2022-11-23 00:24:49,305 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7886603634024776, 'Total loss': 0.7886603634024776} | train loss {'Reaction outcome loss': 0.8097409757434345, 'Total loss': 0.8097409757434345}
2022-11-23 00:24:49,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:49,305 INFO:     Epoch: 88
2022-11-23 00:24:50,089 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7900883423727613, 'Total loss': 0.7900883423727613} | train loss {'Reaction outcome loss': 0.8165945757607944, 'Total loss': 0.8165945757607944}
2022-11-23 00:24:50,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:50,089 INFO:     Epoch: 89
2022-11-23 00:24:50,862 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7898798494838005, 'Total loss': 0.7898798494838005} | train loss {'Reaction outcome loss': 0.8128529107961499, 'Total loss': 0.8128529107961499}
2022-11-23 00:24:50,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:50,863 INFO:     Epoch: 90
2022-11-23 00:24:51,648 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7846531653127005, 'Total loss': 0.7846531653127005} | train loss {'Reaction outcome loss': 0.8163082082984877, 'Total loss': 0.8163082082984877}
2022-11-23 00:24:51,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:51,648 INFO:     Epoch: 91
2022-11-23 00:24:52,413 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7988432992336362, 'Total loss': 0.7988432992336362} | train loss {'Reaction outcome loss': 0.815688964040553, 'Total loss': 0.815688964040553}
2022-11-23 00:24:52,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:52,413 INFO:     Epoch: 92
2022-11-23 00:24:53,177 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7856204391911973, 'Total loss': 0.7856204391911973} | train loss {'Reaction outcome loss': 0.8101611705344232, 'Total loss': 0.8101611705344232}
2022-11-23 00:24:53,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:53,178 INFO:     Epoch: 93
2022-11-23 00:24:53,963 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.793465445207995, 'Total loss': 0.793465445207995} | train loss {'Reaction outcome loss': 0.8116091526434069, 'Total loss': 0.8116091526434069}
2022-11-23 00:24:53,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:53,963 INFO:     Epoch: 94
2022-11-23 00:24:54,821 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7974956569283508, 'Total loss': 0.7974956569283508} | train loss {'Reaction outcome loss': 0.8094093491796588, 'Total loss': 0.8094093491796588}
2022-11-23 00:24:54,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:54,821 INFO:     Epoch: 95
2022-11-23 00:24:55,649 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7926017759844314, 'Total loss': 0.7926017759844314} | train loss {'Reaction outcome loss': 0.8117538381551133, 'Total loss': 0.8117538381551133}
2022-11-23 00:24:55,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:55,649 INFO:     Epoch: 96
2022-11-23 00:24:56,443 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7959749740223552, 'Total loss': 0.7959749740223552} | train loss {'Reaction outcome loss': 0.8100534528493881, 'Total loss': 0.8100534528493881}
2022-11-23 00:24:56,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:56,443 INFO:     Epoch: 97
2022-11-23 00:24:57,193 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7811931648919749, 'Total loss': 0.7811931648919749} | train loss {'Reaction outcome loss': 0.812637953362504, 'Total loss': 0.812637953362504}
2022-11-23 00:24:57,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:57,193 INFO:     Epoch: 98
2022-11-23 00:24:58,006 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7998099632041399, 'Total loss': 0.7998099632041399} | train loss {'Reaction outcome loss': 0.8131168356440106, 'Total loss': 0.8131168356440106}
2022-11-23 00:24:58,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:58,006 INFO:     Epoch: 99
2022-11-23 00:24:58,795 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.820719626060752, 'Total loss': 0.820719626060752} | train loss {'Reaction outcome loss': 0.8134894709362358, 'Total loss': 0.8134894709362358}
2022-11-23 00:24:58,795 INFO:     Best model found after epoch 76 of 100.
2022-11-23 00:24:58,795 INFO:   Done with stage: TRAINING
2022-11-23 00:24:58,795 INFO:   Starting stage: EVALUATION
2022-11-23 00:24:58,931 INFO:   Done with stage: EVALUATION
2022-11-23 00:24:58,931 INFO:   Leaving out SEQ value Fold_4
2022-11-23 00:24:58,944 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:24:58,944 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:24:59,615 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:24:59,616 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:24:59,685 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:24:59,685 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:24:59,685 INFO:     No hyperparam tuning for this model
2022-11-23 00:24:59,685 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:24:59,685 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:24:59,686 INFO:     None feature selector for col prot
2022-11-23 00:24:59,686 INFO:     None feature selector for col prot
2022-11-23 00:24:59,686 INFO:     None feature selector for col prot
2022-11-23 00:24:59,687 INFO:     None feature selector for col chem
2022-11-23 00:24:59,687 INFO:     None feature selector for col chem
2022-11-23 00:24:59,687 INFO:     None feature selector for col chem
2022-11-23 00:24:59,687 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:24:59,687 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:24:59,690 INFO:     Number of params in model 168571
2022-11-23 00:24:59,695 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:24:59,695 INFO:   Starting stage: TRAINING
2022-11-23 00:24:59,759 INFO:     Val loss before train {'Reaction outcome loss': 0.9831697669896212, 'Total loss': 0.9831697669896212}
2022-11-23 00:24:59,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:24:59,760 INFO:     Epoch: 0
2022-11-23 00:25:00,580 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8129612004215067, 'Total loss': 0.8129612004215067} | train loss {'Reaction outcome loss': 0.8816735390950794, 'Total loss': 0.8816735390950794}
2022-11-23 00:25:00,580 INFO:     Found new best model at epoch 0
2022-11-23 00:25:00,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:00,581 INFO:     Epoch: 1
2022-11-23 00:25:01,372 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8412181613120165, 'Total loss': 0.8412181613120165} | train loss {'Reaction outcome loss': 0.8488520759078655, 'Total loss': 0.8488520759078655}
2022-11-23 00:25:01,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:01,372 INFO:     Epoch: 2
2022-11-23 00:25:02,176 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7933780605142767, 'Total loss': 0.7933780605142767} | train loss {'Reaction outcome loss': 0.8454045208269044, 'Total loss': 0.8454045208269044}
2022-11-23 00:25:02,176 INFO:     Found new best model at epoch 2
2022-11-23 00:25:02,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:02,177 INFO:     Epoch: 3
2022-11-23 00:25:02,987 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8180246380242434, 'Total loss': 0.8180246380242434} | train loss {'Reaction outcome loss': 0.8388938864595011, 'Total loss': 0.8388938864595011}
2022-11-23 00:25:02,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:02,987 INFO:     Epoch: 4
2022-11-23 00:25:03,797 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8076184378428892, 'Total loss': 0.8076184378428892} | train loss {'Reaction outcome loss': 0.8348264520467534, 'Total loss': 0.8348264520467534}
2022-11-23 00:25:03,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:03,797 INFO:     Epoch: 5
2022-11-23 00:25:04,652 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8078184635801748, 'Total loss': 0.8078184635801748} | train loss {'Reaction outcome loss': 0.8422645288199065, 'Total loss': 0.8422645288199065}
2022-11-23 00:25:04,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:04,652 INFO:     Epoch: 6
2022-11-23 00:25:05,497 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.791280363093723, 'Total loss': 0.791280363093723} | train loss {'Reaction outcome loss': 0.8379027537006115, 'Total loss': 0.8379027537006115}
2022-11-23 00:25:05,497 INFO:     Found new best model at epoch 6
2022-11-23 00:25:05,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:05,498 INFO:     Epoch: 7
2022-11-23 00:25:06,306 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.787870239127766, 'Total loss': 0.787870239127766} | train loss {'Reaction outcome loss': 0.8340395234133068, 'Total loss': 0.8340395234133068}
2022-11-23 00:25:06,306 INFO:     Found new best model at epoch 7
2022-11-23 00:25:06,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:06,307 INFO:     Epoch: 8
2022-11-23 00:25:07,137 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8143093843351711, 'Total loss': 0.8143093843351711} | train loss {'Reaction outcome loss': 0.8322334662381454, 'Total loss': 0.8322334662381454}
2022-11-23 00:25:07,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:07,137 INFO:     Epoch: 9
2022-11-23 00:25:07,932 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7874860032038256, 'Total loss': 0.7874860032038256} | train loss {'Reaction outcome loss': 0.8282323220239477, 'Total loss': 0.8282323220239477}
2022-11-23 00:25:07,932 INFO:     Found new best model at epoch 9
2022-11-23 00:25:07,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:07,933 INFO:     Epoch: 10
2022-11-23 00:25:08,739 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7979851879856803, 'Total loss': 0.7979851879856803} | train loss {'Reaction outcome loss': 0.8259949579171324, 'Total loss': 0.8259949579171324}
2022-11-23 00:25:08,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:08,739 INFO:     Epoch: 11
2022-11-23 00:25:09,570 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7818990370089357, 'Total loss': 0.7818990370089357} | train loss {'Reaction outcome loss': 0.8361091525689793, 'Total loss': 0.8361091525689793}
2022-11-23 00:25:09,570 INFO:     Found new best model at epoch 11
2022-11-23 00:25:09,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:09,571 INFO:     Epoch: 12
2022-11-23 00:25:10,375 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7983379844914783, 'Total loss': 0.7983379844914783} | train loss {'Reaction outcome loss': 0.8384698474938087, 'Total loss': 0.8384698474938087}
2022-11-23 00:25:10,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:10,375 INFO:     Epoch: 13
2022-11-23 00:25:11,188 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8023889274759726, 'Total loss': 0.8023889274759726} | train loss {'Reaction outcome loss': 0.8298536884760567, 'Total loss': 0.8298536884760567}
2022-11-23 00:25:11,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:11,189 INFO:     Epoch: 14
2022-11-23 00:25:12,044 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7867614836855368, 'Total loss': 0.7867614836855368} | train loss {'Reaction outcome loss': 0.8237730025310024, 'Total loss': 0.8237730025310024}
2022-11-23 00:25:12,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:12,045 INFO:     Epoch: 15
2022-11-23 00:25:12,870 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7914454449306835, 'Total loss': 0.7914454449306835} | train loss {'Reaction outcome loss': 0.8174077214499716, 'Total loss': 0.8174077214499716}
2022-11-23 00:25:12,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:12,871 INFO:     Epoch: 16
2022-11-23 00:25:13,671 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7830362719568339, 'Total loss': 0.7830362719568339} | train loss {'Reaction outcome loss': 0.8248796553505577, 'Total loss': 0.8248796553505577}
2022-11-23 00:25:13,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:13,671 INFO:     Epoch: 17
2022-11-23 00:25:14,451 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7800427621061151, 'Total loss': 0.7800427621061151} | train loss {'Reaction outcome loss': 0.816854576274813, 'Total loss': 0.816854576274813}
2022-11-23 00:25:14,451 INFO:     Found new best model at epoch 17
2022-11-23 00:25:14,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:14,452 INFO:     Epoch: 18
2022-11-23 00:25:15,242 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7823362079533663, 'Total loss': 0.7823362079533663} | train loss {'Reaction outcome loss': 0.819686423549768, 'Total loss': 0.819686423549768}
2022-11-23 00:25:15,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:15,242 INFO:     Epoch: 19
2022-11-23 00:25:16,081 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7826980040831999, 'Total loss': 0.7826980040831999} | train loss {'Reaction outcome loss': 0.8231131216051125, 'Total loss': 0.8231131216051125}
2022-11-23 00:25:16,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:16,082 INFO:     Epoch: 20
2022-11-23 00:25:16,879 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8043405278162523, 'Total loss': 0.8043405278162523} | train loss {'Reaction outcome loss': 0.8274032837948818, 'Total loss': 0.8274032837948818}
2022-11-23 00:25:16,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:16,880 INFO:     Epoch: 21
2022-11-23 00:25:17,685 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7847976176576181, 'Total loss': 0.7847976176576181} | train loss {'Reaction outcome loss': 0.8181587887196405, 'Total loss': 0.8181587887196405}
2022-11-23 00:25:17,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:17,686 INFO:     Epoch: 22
2022-11-23 00:25:18,499 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7909618223255331, 'Total loss': 0.7909618223255331} | train loss {'Reaction outcome loss': 0.8206116508858406, 'Total loss': 0.8206116508858406}
2022-11-23 00:25:18,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:18,499 INFO:     Epoch: 23
2022-11-23 00:25:19,319 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7929049709981139, 'Total loss': 0.7929049709981139} | train loss {'Reaction outcome loss': 0.819711285021141, 'Total loss': 0.819711285021141}
2022-11-23 00:25:19,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:19,319 INFO:     Epoch: 24
2022-11-23 00:25:20,111 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7889120721004226, 'Total loss': 0.7889120721004226} | train loss {'Reaction outcome loss': 0.8163576325182973, 'Total loss': 0.8163576325182973}
2022-11-23 00:25:20,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:20,111 INFO:     Epoch: 25
2022-11-23 00:25:20,985 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8008941276506945, 'Total loss': 0.8008941276506945} | train loss {'Reaction outcome loss': 0.8169762363076692, 'Total loss': 0.8169762363076692}
2022-11-23 00:25:20,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:20,986 INFO:     Epoch: 26
2022-11-23 00:25:21,788 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7964543883096088, 'Total loss': 0.7964543883096088} | train loss {'Reaction outcome loss': 0.8145650280149359, 'Total loss': 0.8145650280149359}
2022-11-23 00:25:21,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:21,788 INFO:     Epoch: 27
2022-11-23 00:25:22,583 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7876592515544458, 'Total loss': 0.7876592515544458} | train loss {'Reaction outcome loss': 0.8159200516548234, 'Total loss': 0.8159200516548234}
2022-11-23 00:25:22,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:22,584 INFO:     Epoch: 28
2022-11-23 00:25:23,401 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7750103256919167, 'Total loss': 0.7750103256919167} | train loss {'Reaction outcome loss': 0.8147742252661149, 'Total loss': 0.8147742252661149}
2022-11-23 00:25:23,401 INFO:     Found new best model at epoch 28
2022-11-23 00:25:23,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:23,402 INFO:     Epoch: 29
2022-11-23 00:25:24,207 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7874471707777544, 'Total loss': 0.7874471707777544} | train loss {'Reaction outcome loss': 0.818569275773006, 'Total loss': 0.818569275773006}
2022-11-23 00:25:24,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:24,207 INFO:     Epoch: 30
2022-11-23 00:25:24,979 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7797148810191588, 'Total loss': 0.7797148810191588} | train loss {'Reaction outcome loss': 0.8220444441082989, 'Total loss': 0.8220444441082989}
2022-11-23 00:25:24,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:24,980 INFO:     Epoch: 31
2022-11-23 00:25:25,790 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7888415916399523, 'Total loss': 0.7888415916399523} | train loss {'Reaction outcome loss': 0.813465363885227, 'Total loss': 0.813465363885227}
2022-11-23 00:25:25,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:25,790 INFO:     Epoch: 32
2022-11-23 00:25:26,631 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7859998629851774, 'Total loss': 0.7859998629851774} | train loss {'Reaction outcome loss': 0.8212008234942972, 'Total loss': 0.8212008234942972}
2022-11-23 00:25:26,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:26,632 INFO:     Epoch: 33
2022-11-23 00:25:27,440 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7808531143448569, 'Total loss': 0.7808531143448569} | train loss {'Reaction outcome loss': 0.8122418864294585, 'Total loss': 0.8122418864294585}
2022-11-23 00:25:27,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:27,441 INFO:     Epoch: 34
2022-11-23 00:25:28,304 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7757215046069839, 'Total loss': 0.7757215046069839} | train loss {'Reaction outcome loss': 0.8144920265023042, 'Total loss': 0.8144920265023042}
2022-11-23 00:25:28,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:28,305 INFO:     Epoch: 35
2022-11-23 00:25:29,132 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7780967456373301, 'Total loss': 0.7780967456373301} | train loss {'Reaction outcome loss': 0.8259979681930079, 'Total loss': 0.8259979681930079}
2022-11-23 00:25:29,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:29,132 INFO:     Epoch: 36
2022-11-23 00:25:29,933 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7801397916945544, 'Total loss': 0.7801397916945544} | train loss {'Reaction outcome loss': 0.8272112711721104, 'Total loss': 0.8272112711721104}
2022-11-23 00:25:29,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:29,934 INFO:     Epoch: 37
2022-11-23 00:25:30,761 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.811552420258522, 'Total loss': 0.811552420258522} | train loss {'Reaction outcome loss': 0.812833259704142, 'Total loss': 0.812833259704142}
2022-11-23 00:25:30,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:30,761 INFO:     Epoch: 38
2022-11-23 00:25:31,578 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7842658649791371, 'Total loss': 0.7842658649791371} | train loss {'Reaction outcome loss': 0.816553846303268, 'Total loss': 0.816553846303268}
2022-11-23 00:25:31,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:31,578 INFO:     Epoch: 39
2022-11-23 00:25:32,405 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8064059811559591, 'Total loss': 0.8064059811559591} | train loss {'Reaction outcome loss': 0.8179614017849509, 'Total loss': 0.8179614017849509}
2022-11-23 00:25:32,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:32,405 INFO:     Epoch: 40
2022-11-23 00:25:33,213 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7668147446079687, 'Total loss': 0.7668147446079687} | train loss {'Reaction outcome loss': 0.8232916641814506, 'Total loss': 0.8232916641814506}
2022-11-23 00:25:33,213 INFO:     Found new best model at epoch 40
2022-11-23 00:25:33,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:33,214 INFO:     Epoch: 41
2022-11-23 00:25:34,014 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7875854291699149, 'Total loss': 0.7875854291699149} | train loss {'Reaction outcome loss': 0.822437776727715, 'Total loss': 0.822437776727715}
2022-11-23 00:25:34,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:34,014 INFO:     Epoch: 42
2022-11-23 00:25:34,831 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7783479975028471, 'Total loss': 0.7783479975028471} | train loss {'Reaction outcome loss': 0.8157656163821819, 'Total loss': 0.8157656163821819}
2022-11-23 00:25:34,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:34,831 INFO:     Epoch: 43
2022-11-23 00:25:35,634 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8077092441645536, 'Total loss': 0.8077092441645536} | train loss {'Reaction outcome loss': 0.8224188004910704, 'Total loss': 0.8224188004910704}
2022-11-23 00:25:35,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:35,634 INFO:     Epoch: 44
2022-11-23 00:25:36,384 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7841054485602812, 'Total loss': 0.7841054485602812} | train loss {'Reaction outcome loss': 0.8107000116997884, 'Total loss': 0.8107000116997884}
2022-11-23 00:25:36,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:36,385 INFO:     Epoch: 45
2022-11-23 00:25:37,155 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.777103753252463, 'Total loss': 0.777103753252463} | train loss {'Reaction outcome loss': 0.8132236157110345, 'Total loss': 0.8132236157110345}
2022-11-23 00:25:37,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:37,155 INFO:     Epoch: 46
2022-11-23 00:25:37,935 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7816480242393233, 'Total loss': 0.7816480242393233} | train loss {'Reaction outcome loss': 0.8229870239974033, 'Total loss': 0.8229870239974033}
2022-11-23 00:25:37,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:37,935 INFO:     Epoch: 47
2022-11-23 00:25:38,732 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7853289070454511, 'Total loss': 0.7853289070454511} | train loss {'Reaction outcome loss': 0.8141358307739983, 'Total loss': 0.8141358307739983}
2022-11-23 00:25:38,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:38,732 INFO:     Epoch: 48
2022-11-23 00:25:39,501 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7757060737772421, 'Total loss': 0.7757060737772421} | train loss {'Reaction outcome loss': 0.8129316405487447, 'Total loss': 0.8129316405487447}
2022-11-23 00:25:39,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:39,502 INFO:     Epoch: 49
2022-11-23 00:25:40,281 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7707993347536434, 'Total loss': 0.7707993347536434} | train loss {'Reaction outcome loss': 0.8148484957755094, 'Total loss': 0.8148484957755094}
2022-11-23 00:25:40,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:40,281 INFO:     Epoch: 50
2022-11-23 00:25:41,072 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7885137376460162, 'Total loss': 0.7885137376460162} | train loss {'Reaction outcome loss': 0.8103307701556789, 'Total loss': 0.8103307701556789}
2022-11-23 00:25:41,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:41,072 INFO:     Epoch: 51
2022-11-23 00:25:41,849 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.789310413328084, 'Total loss': 0.789310413328084} | train loss {'Reaction outcome loss': 0.8188882690933552, 'Total loss': 0.8188882690933552}
2022-11-23 00:25:41,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:41,849 INFO:     Epoch: 52
2022-11-23 00:25:42,655 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.762754965912212, 'Total loss': 0.762754965912212} | train loss {'Reaction outcome loss': 0.8171380870496696, 'Total loss': 0.8171380870496696}
2022-11-23 00:25:42,657 INFO:     Found new best model at epoch 52
2022-11-23 00:25:42,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:42,657 INFO:     Epoch: 53
2022-11-23 00:25:43,417 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8038509914820845, 'Total loss': 0.8038509914820845} | train loss {'Reaction outcome loss': 0.8221936322416854, 'Total loss': 0.8221936322416854}
2022-11-23 00:25:43,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:43,417 INFO:     Epoch: 54
2022-11-23 00:25:44,184 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8062235699458555, 'Total loss': 0.8062235699458555} | train loss {'Reaction outcome loss': 0.817389911485587, 'Total loss': 0.817389911485587}
2022-11-23 00:25:44,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:44,184 INFO:     Epoch: 55
2022-11-23 00:25:44,973 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8238993923772465, 'Total loss': 0.8238993923772465} | train loss {'Reaction outcome loss': 0.812012350028343, 'Total loss': 0.812012350028343}
2022-11-23 00:25:44,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:44,973 INFO:     Epoch: 56
2022-11-23 00:25:45,776 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7971089590679515, 'Total loss': 0.7971089590679515} | train loss {'Reaction outcome loss': 0.8127106458310657, 'Total loss': 0.8127106458310657}
2022-11-23 00:25:45,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:45,777 INFO:     Epoch: 57
2022-11-23 00:25:46,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7831434106284921, 'Total loss': 0.7831434106284921} | train loss {'Reaction outcome loss': 0.8154652847452202, 'Total loss': 0.8154652847452202}
2022-11-23 00:25:46,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:46,544 INFO:     Epoch: 58
2022-11-23 00:25:47,319 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7803152609955181, 'Total loss': 0.7803152609955181} | train loss {'Reaction outcome loss': 0.8143834851169394, 'Total loss': 0.8143834851169394}
2022-11-23 00:25:47,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:47,320 INFO:     Epoch: 59
2022-11-23 00:25:48,122 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8067029789090157, 'Total loss': 0.8067029789090157} | train loss {'Reaction outcome loss': 0.8065676764257041, 'Total loss': 0.8065676764257041}
2022-11-23 00:25:48,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:48,122 INFO:     Epoch: 60
2022-11-23 00:25:48,892 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7834343436089429, 'Total loss': 0.7834343436089429} | train loss {'Reaction outcome loss': 0.8145711352588677, 'Total loss': 0.8145711352588677}
2022-11-23 00:25:48,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:48,894 INFO:     Epoch: 61
2022-11-23 00:25:49,685 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7826012447476387, 'Total loss': 0.7826012447476387} | train loss {'Reaction outcome loss': 0.8135262834217384, 'Total loss': 0.8135262834217384}
2022-11-23 00:25:49,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:49,685 INFO:     Epoch: 62
2022-11-23 00:25:50,458 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7652457187121565, 'Total loss': 0.7652457187121565} | train loss {'Reaction outcome loss': 0.8073719830557644, 'Total loss': 0.8073719830557644}
2022-11-23 00:25:50,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:50,458 INFO:     Epoch: 63
2022-11-23 00:25:51,244 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.770745454186743, 'Total loss': 0.770745454186743} | train loss {'Reaction outcome loss': 0.8045460408033147, 'Total loss': 0.8045460408033147}
2022-11-23 00:25:51,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:51,245 INFO:     Epoch: 64
2022-11-23 00:25:52,020 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7922329360788519, 'Total loss': 0.7922329360788519} | train loss {'Reaction outcome loss': 0.8118170184283121, 'Total loss': 0.8118170184283121}
2022-11-23 00:25:52,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:52,020 INFO:     Epoch: 65
2022-11-23 00:25:52,803 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7773541259494695, 'Total loss': 0.7773541259494695} | train loss {'Reaction outcome loss': 0.8158010772847937, 'Total loss': 0.8158010772847937}
2022-11-23 00:25:52,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:52,803 INFO:     Epoch: 66
2022-11-23 00:25:53,619 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7754657471721823, 'Total loss': 0.7754657471721823} | train loss {'Reaction outcome loss': 0.8194684345229917, 'Total loss': 0.8194684345229917}
2022-11-23 00:25:53,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:53,619 INFO:     Epoch: 67
2022-11-23 00:25:54,433 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7707425836812366, 'Total loss': 0.7707425836812366} | train loss {'Reaction outcome loss': 0.816135864870751, 'Total loss': 0.816135864870751}
2022-11-23 00:25:54,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:54,435 INFO:     Epoch: 68
2022-11-23 00:25:55,238 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7606498565186154, 'Total loss': 0.7606498565186154} | train loss {'Reaction outcome loss': 0.8046428342821145, 'Total loss': 0.8046428342821145}
2022-11-23 00:25:55,238 INFO:     Found new best model at epoch 68
2022-11-23 00:25:55,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:55,239 INFO:     Epoch: 69
2022-11-23 00:25:56,056 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7924503169276498, 'Total loss': 0.7924503169276498} | train loss {'Reaction outcome loss': 0.8125019293082388, 'Total loss': 0.8125019293082388}
2022-11-23 00:25:56,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:56,057 INFO:     Epoch: 70
2022-11-23 00:25:56,865 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7760511867024682, 'Total loss': 0.7760511867024682} | train loss {'Reaction outcome loss': 0.811155907055627, 'Total loss': 0.811155907055627}
2022-11-23 00:25:56,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:56,865 INFO:     Epoch: 71
2022-11-23 00:25:57,633 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7975081591443582, 'Total loss': 0.7975081591443582} | train loss {'Reaction outcome loss': 0.8016550775602279, 'Total loss': 0.8016550775602279}
2022-11-23 00:25:57,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:57,633 INFO:     Epoch: 72
2022-11-23 00:25:58,471 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7634526193141937, 'Total loss': 0.7634526193141937} | train loss {'Reaction outcome loss': 0.8070772998487419, 'Total loss': 0.8070772998487419}
2022-11-23 00:25:58,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:58,472 INFO:     Epoch: 73
2022-11-23 00:25:59,275 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.756731437688524, 'Total loss': 0.756731437688524} | train loss {'Reaction outcome loss': 0.8093530768566286, 'Total loss': 0.8093530768566286}
2022-11-23 00:25:59,275 INFO:     Found new best model at epoch 73
2022-11-23 00:25:59,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:25:59,276 INFO:     Epoch: 74
2022-11-23 00:26:00,091 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7587032799016346, 'Total loss': 0.7587032799016346} | train loss {'Reaction outcome loss': 0.8054671456456667, 'Total loss': 0.8054671456456667}
2022-11-23 00:26:00,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:00,092 INFO:     Epoch: 75
2022-11-23 00:26:00,925 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7671186483719132, 'Total loss': 0.7671186483719132} | train loss {'Reaction outcome loss': 0.8033917380971947, 'Total loss': 0.8033917380971947}
2022-11-23 00:26:00,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:00,925 INFO:     Epoch: 76
2022-11-23 00:26:01,743 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7583262662995945, 'Total loss': 0.7583262662995945} | train loss {'Reaction outcome loss': 0.7980892554468472, 'Total loss': 0.7980892554468472}
2022-11-23 00:26:01,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:01,744 INFO:     Epoch: 77
2022-11-23 00:26:02,631 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.764184911142696, 'Total loss': 0.764184911142696} | train loss {'Reaction outcome loss': 0.7960343383825742, 'Total loss': 0.7960343383825742}
2022-11-23 00:26:02,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:02,631 INFO:     Epoch: 78
2022-11-23 00:26:03,522 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7867824557152662, 'Total loss': 0.7867824557152662} | train loss {'Reaction outcome loss': 0.8061631377409344, 'Total loss': 0.8061631377409344}
2022-11-23 00:26:03,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:03,522 INFO:     Epoch: 79
2022-11-23 00:26:04,366 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.765777892687104, 'Total loss': 0.765777892687104} | train loss {'Reaction outcome loss': 0.7994635138917066, 'Total loss': 0.7994635138917066}
2022-11-23 00:26:04,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:04,367 INFO:     Epoch: 80
2022-11-23 00:26:05,261 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7757951210845601, 'Total loss': 0.7757951210845601} | train loss {'Reaction outcome loss': 0.7996197059328257, 'Total loss': 0.7996197059328257}
2022-11-23 00:26:05,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:05,262 INFO:     Epoch: 81
2022-11-23 00:26:06,072 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7423764656890522, 'Total loss': 0.7423764656890522} | train loss {'Reaction outcome loss': 0.8067160252376124, 'Total loss': 0.8067160252376124}
2022-11-23 00:26:06,072 INFO:     Found new best model at epoch 81
2022-11-23 00:26:06,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:06,073 INFO:     Epoch: 82
2022-11-23 00:26:06,901 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7638288749889894, 'Total loss': 0.7638288749889894} | train loss {'Reaction outcome loss': 0.8050689551270442, 'Total loss': 0.8050689551270442}
2022-11-23 00:26:06,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:06,901 INFO:     Epoch: 83
2022-11-23 00:26:07,754 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7601678791371259, 'Total loss': 0.7601678791371259} | train loss {'Reaction outcome loss': 0.7919024230256254, 'Total loss': 0.7919024230256254}
2022-11-23 00:26:07,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:07,754 INFO:     Epoch: 84
2022-11-23 00:26:08,554 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8246349028565667, 'Total loss': 0.8246349028565667} | train loss {'Reaction outcome loss': 0.7940695273128116, 'Total loss': 0.7940695273128116}
2022-11-23 00:26:08,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:08,555 INFO:     Epoch: 85
2022-11-23 00:26:09,402 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7468044751069762, 'Total loss': 0.7468044751069762} | train loss {'Reaction outcome loss': 0.7970962922582742, 'Total loss': 0.7970962922582742}
2022-11-23 00:26:09,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:09,402 INFO:     Epoch: 86
2022-11-23 00:26:10,213 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7522760135206309, 'Total loss': 0.7522760135206309} | train loss {'Reaction outcome loss': 0.792840161183585, 'Total loss': 0.792840161183585}
2022-11-23 00:26:10,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:10,213 INFO:     Epoch: 87
2022-11-23 00:26:11,061 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.772495757449757, 'Total loss': 0.772495757449757} | train loss {'Reaction outcome loss': 0.7923358363902521, 'Total loss': 0.7923358363902521}
2022-11-23 00:26:11,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:11,062 INFO:     Epoch: 88
2022-11-23 00:26:11,852 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8260489465160803, 'Total loss': 0.8260489465160803} | train loss {'Reaction outcome loss': 0.7845771313316909, 'Total loss': 0.7845771313316909}
2022-11-23 00:26:11,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:11,853 INFO:     Epoch: 89
2022-11-23 00:26:12,659 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.746192145076665, 'Total loss': 0.746192145076665} | train loss {'Reaction outcome loss': 0.7979565195226477, 'Total loss': 0.7979565195226477}
2022-11-23 00:26:12,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:12,660 INFO:     Epoch: 90
2022-11-23 00:26:13,451 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7487018501216715, 'Total loss': 0.7487018501216715} | train loss {'Reaction outcome loss': 0.7866889222672111, 'Total loss': 0.7866889222672111}
2022-11-23 00:26:13,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:13,451 INFO:     Epoch: 91
2022-11-23 00:26:14,256 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7411974248560992, 'Total loss': 0.7411974248560992} | train loss {'Reaction outcome loss': 0.7826103809240618, 'Total loss': 0.7826103809240618}
2022-11-23 00:26:14,256 INFO:     Found new best model at epoch 91
2022-11-23 00:26:14,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:14,257 INFO:     Epoch: 92
2022-11-23 00:26:15,129 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7486015151847493, 'Total loss': 0.7486015151847493} | train loss {'Reaction outcome loss': 0.7755274023362982, 'Total loss': 0.7755274023362982}
2022-11-23 00:26:15,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:15,129 INFO:     Epoch: 93
2022-11-23 00:26:15,996 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7883277244188569, 'Total loss': 0.7883277244188569} | train loss {'Reaction outcome loss': 0.7778663373427835, 'Total loss': 0.7778663373427835}
2022-11-23 00:26:15,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:15,996 INFO:     Epoch: 94
2022-11-23 00:26:16,756 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7295580499551513, 'Total loss': 0.7295580499551513} | train loss {'Reaction outcome loss': 0.7833888394388593, 'Total loss': 0.7833888394388593}
2022-11-23 00:26:16,756 INFO:     Found new best model at epoch 94
2022-11-23 00:26:16,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:16,757 INFO:     Epoch: 95
2022-11-23 00:26:17,519 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8522473167289387, 'Total loss': 0.8522473167289387} | train loss {'Reaction outcome loss': 0.7684984798976767, 'Total loss': 0.7684984798976767}
2022-11-23 00:26:17,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:17,519 INFO:     Epoch: 96
2022-11-23 00:26:18,291 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.72980808602138, 'Total loss': 0.72980808602138} | train loss {'Reaction outcome loss': 0.7724615003657245, 'Total loss': 0.7724615003657245}
2022-11-23 00:26:18,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:18,291 INFO:     Epoch: 97
2022-11-23 00:26:19,080 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7087857682596553, 'Total loss': 0.7087857682596553} | train loss {'Reaction outcome loss': 0.7555486948383965, 'Total loss': 0.7555486948383965}
2022-11-23 00:26:19,080 INFO:     Found new best model at epoch 97
2022-11-23 00:26:19,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:19,081 INFO:     Epoch: 98
2022-11-23 00:26:19,870 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7474355419928377, 'Total loss': 0.7474355419928377} | train loss {'Reaction outcome loss': 0.7561564120927803, 'Total loss': 0.7561564120927803}
2022-11-23 00:26:19,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:19,871 INFO:     Epoch: 99
2022-11-23 00:26:20,670 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7289048094641079, 'Total loss': 0.7289048094641079} | train loss {'Reaction outcome loss': 0.754018939986282, 'Total loss': 0.754018939986282}
2022-11-23 00:26:20,670 INFO:     Best model found after epoch 98 of 100.
2022-11-23 00:26:20,670 INFO:   Done with stage: TRAINING
2022-11-23 00:26:20,671 INFO:   Starting stage: EVALUATION
2022-11-23 00:26:20,796 INFO:   Done with stage: EVALUATION
2022-11-23 00:26:20,796 INFO:   Leaving out SEQ value Fold_5
2022-11-23 00:26:20,810 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:26:20,810 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:26:21,477 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:26:21,477 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:26:21,547 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:26:21,547 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:26:21,547 INFO:     No hyperparam tuning for this model
2022-11-23 00:26:21,547 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:26:21,547 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:26:21,548 INFO:     None feature selector for col prot
2022-11-23 00:26:21,548 INFO:     None feature selector for col prot
2022-11-23 00:26:21,548 INFO:     None feature selector for col prot
2022-11-23 00:26:21,549 INFO:     None feature selector for col chem
2022-11-23 00:26:21,549 INFO:     None feature selector for col chem
2022-11-23 00:26:21,549 INFO:     None feature selector for col chem
2022-11-23 00:26:21,549 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:26:21,549 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:26:21,550 INFO:     Number of params in model 168571
2022-11-23 00:26:21,554 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:26:21,554 INFO:   Starting stage: TRAINING
2022-11-23 00:26:21,612 INFO:     Val loss before train {'Reaction outcome loss': 1.0430793118747799, 'Total loss': 1.0430793118747799}
2022-11-23 00:26:21,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:21,613 INFO:     Epoch: 0
2022-11-23 00:26:22,381 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9013895412737672, 'Total loss': 0.9013895412737672} | train loss {'Reaction outcome loss': 0.872894076200632, 'Total loss': 0.872894076200632}
2022-11-23 00:26:22,381 INFO:     Found new best model at epoch 0
2022-11-23 00:26:22,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:22,382 INFO:     Epoch: 1
2022-11-23 00:26:23,184 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8978369669480757, 'Total loss': 0.8978369669480757} | train loss {'Reaction outcome loss': 0.8516327499860694, 'Total loss': 0.8516327499860694}
2022-11-23 00:26:23,184 INFO:     Found new best model at epoch 1
2022-11-23 00:26:23,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:23,185 INFO:     Epoch: 2
2022-11-23 00:26:23,992 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9127867235378786, 'Total loss': 0.9127867235378786} | train loss {'Reaction outcome loss': 0.8385426783670298, 'Total loss': 0.8385426783670298}
2022-11-23 00:26:23,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:23,993 INFO:     Epoch: 3
2022-11-23 00:26:24,770 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8682972998781637, 'Total loss': 0.8682972998781637} | train loss {'Reaction outcome loss': 0.8279158460949114, 'Total loss': 0.8279158460949114}
2022-11-23 00:26:24,771 INFO:     Found new best model at epoch 3
2022-11-23 00:26:24,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:24,772 INFO:     Epoch: 4
2022-11-23 00:26:25,562 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9121611687270078, 'Total loss': 0.9121611687270078} | train loss {'Reaction outcome loss': 0.8320074414434703, 'Total loss': 0.8320074414434703}
2022-11-23 00:26:25,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:25,562 INFO:     Epoch: 5
2022-11-23 00:26:26,367 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8717221570285884, 'Total loss': 0.8717221570285884} | train loss {'Reaction outcome loss': 0.8307663788076355, 'Total loss': 0.8307663788076355}
2022-11-23 00:26:26,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:26,368 INFO:     Epoch: 6
2022-11-23 00:26:27,140 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8869010203263976, 'Total loss': 0.8869010203263976} | train loss {'Reaction outcome loss': 0.8207842504515158, 'Total loss': 0.8207842504515158}
2022-11-23 00:26:27,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:27,140 INFO:     Epoch: 7
2022-11-23 00:26:27,956 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8537305817008018, 'Total loss': 0.8537305817008018} | train loss {'Reaction outcome loss': 0.8172385066385693, 'Total loss': 0.8172385066385693}
2022-11-23 00:26:27,956 INFO:     Found new best model at epoch 7
2022-11-23 00:26:27,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:27,957 INFO:     Epoch: 8
2022-11-23 00:26:28,736 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8705649172717874, 'Total loss': 0.8705649172717874} | train loss {'Reaction outcome loss': 0.8195872183753411, 'Total loss': 0.8195872183753411}
2022-11-23 00:26:28,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:28,737 INFO:     Epoch: 9
2022-11-23 00:26:29,542 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8957558673891154, 'Total loss': 0.8957558673891154} | train loss {'Reaction outcome loss': 0.8251554822390862, 'Total loss': 0.8251554822390862}
2022-11-23 00:26:29,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:29,542 INFO:     Epoch: 10
2022-11-23 00:26:30,328 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8594174832105637, 'Total loss': 0.8594174832105637} | train loss {'Reaction outcome loss': 0.8153075189423947, 'Total loss': 0.8153075189423947}
2022-11-23 00:26:30,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:30,328 INFO:     Epoch: 11
2022-11-23 00:26:31,130 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8523380261930552, 'Total loss': 0.8523380261930552} | train loss {'Reaction outcome loss': 0.8138407863344741, 'Total loss': 0.8138407863344741}
2022-11-23 00:26:31,130 INFO:     Found new best model at epoch 11
2022-11-23 00:26:31,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:31,131 INFO:     Epoch: 12
2022-11-23 00:26:31,917 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8606961057944731, 'Total loss': 0.8606961057944731} | train loss {'Reaction outcome loss': 0.8141539917904356, 'Total loss': 0.8141539917904356}
2022-11-23 00:26:31,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:31,917 INFO:     Epoch: 13
2022-11-23 00:26:32,727 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.878012250770222, 'Total loss': 0.878012250770222} | train loss {'Reaction outcome loss': 0.8147788255924155, 'Total loss': 0.8147788255924155}
2022-11-23 00:26:32,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:32,728 INFO:     Epoch: 14
2022-11-23 00:26:33,546 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8884415856816552, 'Total loss': 0.8884415856816552} | train loss {'Reaction outcome loss': 0.8135965231217837, 'Total loss': 0.8135965231217837}
2022-11-23 00:26:33,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:33,546 INFO:     Epoch: 15
2022-11-23 00:26:34,318 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8956287449056451, 'Total loss': 0.8956287449056451} | train loss {'Reaction outcome loss': 0.8132396864625606, 'Total loss': 0.8132396864625606}
2022-11-23 00:26:34,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:34,319 INFO:     Epoch: 16
2022-11-23 00:26:35,121 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8485169979658994, 'Total loss': 0.8485169979658994} | train loss {'Reaction outcome loss': 0.812470226997306, 'Total loss': 0.812470226997306}
2022-11-23 00:26:35,121 INFO:     Found new best model at epoch 16
2022-11-23 00:26:35,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:35,122 INFO:     Epoch: 17
2022-11-23 00:26:35,925 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8597005822441794, 'Total loss': 0.8597005822441794} | train loss {'Reaction outcome loss': 0.8140372398049243, 'Total loss': 0.8140372398049243}
2022-11-23 00:26:35,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:35,926 INFO:     Epoch: 18
2022-11-23 00:26:36,745 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8672074973583221, 'Total loss': 0.8672074973583221} | train loss {'Reaction outcome loss': 0.8125916380389981, 'Total loss': 0.8125916380389981}
2022-11-23 00:26:36,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:36,746 INFO:     Epoch: 19
2022-11-23 00:26:37,566 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8868941082195803, 'Total loss': 0.8868941082195803} | train loss {'Reaction outcome loss': 0.8143391376323545, 'Total loss': 0.8143391376323545}
2022-11-23 00:26:37,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:37,566 INFO:     Epoch: 20
2022-11-23 00:26:38,352 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8701956949450753, 'Total loss': 0.8701956949450753} | train loss {'Reaction outcome loss': 0.8095875476535997, 'Total loss': 0.8095875476535997}
2022-11-23 00:26:38,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:38,353 INFO:     Epoch: 21
2022-11-23 00:26:39,233 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8791931447657672, 'Total loss': 0.8791931447657672} | train loss {'Reaction outcome loss': 0.8141144583461738, 'Total loss': 0.8141144583461738}
2022-11-23 00:26:39,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:39,233 INFO:     Epoch: 22
2022-11-23 00:26:40,067 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8642902401360598, 'Total loss': 0.8642902401360598} | train loss {'Reaction outcome loss': 0.8060844177870374, 'Total loss': 0.8060844177870374}
2022-11-23 00:26:40,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:40,068 INFO:     Epoch: 23
2022-11-23 00:26:40,884 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8561290610920299, 'Total loss': 0.8561290610920299} | train loss {'Reaction outcome loss': 0.8109668140951921, 'Total loss': 0.8109668140951921}
2022-11-23 00:26:40,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:40,885 INFO:     Epoch: 24
2022-11-23 00:26:41,736 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8756047297607769, 'Total loss': 0.8756047297607769} | train loss {'Reaction outcome loss': 0.8107685850940736, 'Total loss': 0.8107685850940736}
2022-11-23 00:26:41,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:41,736 INFO:     Epoch: 25
2022-11-23 00:26:42,561 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8927926963025873, 'Total loss': 0.8927926963025873} | train loss {'Reaction outcome loss': 0.8127989584376455, 'Total loss': 0.8127989584376455}
2022-11-23 00:26:42,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:42,561 INFO:     Epoch: 26
2022-11-23 00:26:43,351 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8612204221161929, 'Total loss': 0.8612204221161929} | train loss {'Reaction outcome loss': 0.813900369381615, 'Total loss': 0.813900369381615}
2022-11-23 00:26:43,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:43,352 INFO:     Epoch: 27
2022-11-23 00:26:44,177 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8638173544948752, 'Total loss': 0.8638173544948752} | train loss {'Reaction outcome loss': 0.8092132318116393, 'Total loss': 0.8092132318116393}
2022-11-23 00:26:44,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:44,177 INFO:     Epoch: 28
2022-11-23 00:26:44,988 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8586430590261113, 'Total loss': 0.8586430590261113} | train loss {'Reaction outcome loss': 0.8119339550796308, 'Total loss': 0.8119339550796308}
2022-11-23 00:26:44,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:44,989 INFO:     Epoch: 29
2022-11-23 00:26:45,804 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8534411777826872, 'Total loss': 0.8534411777826872} | train loss {'Reaction outcome loss': 0.8097516101019585, 'Total loss': 0.8097516101019585}
2022-11-23 00:26:45,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:45,804 INFO:     Epoch: 30
2022-11-23 00:26:46,619 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8562107729640874, 'Total loss': 0.8562107729640874} | train loss {'Reaction outcome loss': 0.811899771091909, 'Total loss': 0.811899771091909}
2022-11-23 00:26:46,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:46,619 INFO:     Epoch: 31
2022-11-23 00:26:47,382 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8677742399952628, 'Total loss': 0.8677742399952628} | train loss {'Reaction outcome loss': 0.8101856276800155, 'Total loss': 0.8101856276800155}
2022-11-23 00:26:47,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:47,382 INFO:     Epoch: 32
2022-11-23 00:26:48,203 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8832784620198336, 'Total loss': 0.8832784620198336} | train loss {'Reaction outcome loss': 0.8141044959848226, 'Total loss': 0.8141044959848226}
2022-11-23 00:26:48,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:48,203 INFO:     Epoch: 33
2022-11-23 00:26:49,014 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8553241897713054, 'Total loss': 0.8553241897713054} | train loss {'Reaction outcome loss': 0.8169358121721368, 'Total loss': 0.8169358121721368}
2022-11-23 00:26:49,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:49,014 INFO:     Epoch: 34
2022-11-23 00:26:49,819 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8677737672220577, 'Total loss': 0.8677737672220577} | train loss {'Reaction outcome loss': 0.8081727832676429, 'Total loss': 0.8081727832676429}
2022-11-23 00:26:49,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:49,819 INFO:     Epoch: 35
2022-11-23 00:26:50,615 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8606926250186834, 'Total loss': 0.8606926250186834} | train loss {'Reaction outcome loss': 0.8047941702037205, 'Total loss': 0.8047941702037205}
2022-11-23 00:26:50,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:50,616 INFO:     Epoch: 36
2022-11-23 00:26:51,433 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8647625094110315, 'Total loss': 0.8647625094110315} | train loss {'Reaction outcome loss': 0.809847350575422, 'Total loss': 0.809847350575422}
2022-11-23 00:26:51,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:51,434 INFO:     Epoch: 37
2022-11-23 00:26:52,237 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8598486774347045, 'Total loss': 0.8598486774347045} | train loss {'Reaction outcome loss': 0.8112208723177311, 'Total loss': 0.8112208723177311}
2022-11-23 00:26:52,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:52,237 INFO:     Epoch: 38
2022-11-23 00:26:53,063 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8467929566448386, 'Total loss': 0.8467929566448386} | train loss {'Reaction outcome loss': 0.8128447960986782, 'Total loss': 0.8128447960986782}
2022-11-23 00:26:53,063 INFO:     Found new best model at epoch 38
2022-11-23 00:26:53,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:53,064 INFO:     Epoch: 39
2022-11-23 00:26:53,885 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8591175179251216, 'Total loss': 0.8591175179251216} | train loss {'Reaction outcome loss': 0.8113744372600004, 'Total loss': 0.8113744372600004}
2022-11-23 00:26:53,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:53,885 INFO:     Epoch: 40
2022-11-23 00:26:54,685 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8668600971048529, 'Total loss': 0.8668600971048529} | train loss {'Reaction outcome loss': 0.8097910964295931, 'Total loss': 0.8097910964295931}
2022-11-23 00:26:54,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:54,686 INFO:     Epoch: 41
2022-11-23 00:26:55,486 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.861845657906749, 'Total loss': 0.861845657906749} | train loss {'Reaction outcome loss': 0.8102858753098168, 'Total loss': 0.8102858753098168}
2022-11-23 00:26:55,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:55,487 INFO:     Epoch: 42
2022-11-23 00:26:56,313 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8497197370637547, 'Total loss': 0.8497197370637547} | train loss {'Reaction outcome loss': 0.8121955148604235, 'Total loss': 0.8121955148604235}
2022-11-23 00:26:56,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:56,313 INFO:     Epoch: 43
2022-11-23 00:26:57,119 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8794131780212576, 'Total loss': 0.8794131780212576} | train loss {'Reaction outcome loss': 0.817663760441035, 'Total loss': 0.817663760441035}
2022-11-23 00:26:57,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:57,119 INFO:     Epoch: 44
2022-11-23 00:26:57,903 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8614579168233004, 'Total loss': 0.8614579168233004} | train loss {'Reaction outcome loss': 0.8162309504472293, 'Total loss': 0.8162309504472293}
2022-11-23 00:26:57,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:57,904 INFO:     Epoch: 45
2022-11-23 00:26:58,747 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.870881197127429, 'Total loss': 0.870881197127429} | train loss {'Reaction outcome loss': 0.8133820659718533, 'Total loss': 0.8133820659718533}
2022-11-23 00:26:58,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:58,748 INFO:     Epoch: 46
2022-11-23 00:26:59,700 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8671067614446987, 'Total loss': 0.8671067614446987} | train loss {'Reaction outcome loss': 0.8176388769497273, 'Total loss': 0.8176388769497273}
2022-11-23 00:26:59,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:26:59,700 INFO:     Epoch: 47
2022-11-23 00:27:00,530 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8563611988316883, 'Total loss': 0.8563611988316883} | train loss {'Reaction outcome loss': 0.8108752514066001, 'Total loss': 0.8108752514066001}
2022-11-23 00:27:00,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:00,531 INFO:     Epoch: 48
2022-11-23 00:27:01,378 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8884507018056783, 'Total loss': 0.8884507018056783} | train loss {'Reaction outcome loss': 0.8079042808729627, 'Total loss': 0.8079042808729627}
2022-11-23 00:27:01,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:01,379 INFO:     Epoch: 49
2022-11-23 00:27:02,283 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8677938058972359, 'Total loss': 0.8677938058972359} | train loss {'Reaction outcome loss': 0.8145263219169276, 'Total loss': 0.8145263219169276}
2022-11-23 00:27:02,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:02,283 INFO:     Epoch: 50
2022-11-23 00:27:03,144 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.872099448334087, 'Total loss': 0.872099448334087} | train loss {'Reaction outcome loss': 0.8048476468213657, 'Total loss': 0.8048476468213657}
2022-11-23 00:27:03,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:03,144 INFO:     Epoch: 51
2022-11-23 00:27:04,006 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8489209643819116, 'Total loss': 0.8489209643819116} | train loss {'Reaction outcome loss': 0.8173047042327372, 'Total loss': 0.8173047042327372}
2022-11-23 00:27:04,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:04,007 INFO:     Epoch: 52
2022-11-23 00:27:04,944 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8521192398938265, 'Total loss': 0.8521192398938265} | train loss {'Reaction outcome loss': 0.8095870130216545, 'Total loss': 0.8095870130216545}
2022-11-23 00:27:04,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:04,945 INFO:     Epoch: 53
2022-11-23 00:27:05,865 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8564718372442506, 'Total loss': 0.8564718372442506} | train loss {'Reaction outcome loss': 0.8087483155220626, 'Total loss': 0.8087483155220626}
2022-11-23 00:27:05,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:05,866 INFO:     Epoch: 54
2022-11-23 00:27:06,764 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8707127699797804, 'Total loss': 0.8707127699797804} | train loss {'Reaction outcome loss': 0.8048598096679579, 'Total loss': 0.8048598096679579}
2022-11-23 00:27:06,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:06,765 INFO:     Epoch: 55
2022-11-23 00:27:07,653 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8496145037087527, 'Total loss': 0.8496145037087527} | train loss {'Reaction outcome loss': 0.8102171862807109, 'Total loss': 0.8102171862807109}
2022-11-23 00:27:07,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:07,655 INFO:     Epoch: 56
2022-11-23 00:27:08,625 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8726877217943018, 'Total loss': 0.8726877217943018} | train loss {'Reaction outcome loss': 0.8071773369543949, 'Total loss': 0.8071773369543949}
2022-11-23 00:27:08,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:08,625 INFO:     Epoch: 57
2022-11-23 00:27:09,539 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8747198060154915, 'Total loss': 0.8747198060154915} | train loss {'Reaction outcome loss': 0.8108925252308247, 'Total loss': 0.8108925252308247}
2022-11-23 00:27:09,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:09,540 INFO:     Epoch: 58
2022-11-23 00:27:10,478 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8660624582659114, 'Total loss': 0.8660624582659114} | train loss {'Reaction outcome loss': 0.8144677280173128, 'Total loss': 0.8144677280173128}
2022-11-23 00:27:10,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:10,478 INFO:     Epoch: 59
2022-11-23 00:27:11,381 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8751223514025862, 'Total loss': 0.8751223514025862} | train loss {'Reaction outcome loss': 0.8103213549746193, 'Total loss': 0.8103213549746193}
2022-11-23 00:27:11,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:11,381 INFO:     Epoch: 60
2022-11-23 00:27:12,261 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8509723611853339, 'Total loss': 0.8509723611853339} | train loss {'Reaction outcome loss': 0.8148978294631247, 'Total loss': 0.8148978294631247}
2022-11-23 00:27:12,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:12,261 INFO:     Epoch: 61
2022-11-23 00:27:13,131 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8501891785047271, 'Total loss': 0.8501891785047271} | train loss {'Reaction outcome loss': 0.8080766466465074, 'Total loss': 0.8080766466465074}
2022-11-23 00:27:13,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:13,132 INFO:     Epoch: 62
2022-11-23 00:27:14,070 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8587364093823866, 'Total loss': 0.8587364093823866} | train loss {'Reaction outcome loss': 0.8173883044526644, 'Total loss': 0.8173883044526644}
2022-11-23 00:27:14,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:14,071 INFO:     Epoch: 63
2022-11-23 00:27:14,985 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8513356176289645, 'Total loss': 0.8513356176289645} | train loss {'Reaction outcome loss': 0.8116297248886665, 'Total loss': 0.8116297248886665}
2022-11-23 00:27:14,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:14,986 INFO:     Epoch: 64
2022-11-23 00:27:15,905 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8816615261814811, 'Total loss': 0.8816615261814811} | train loss {'Reaction outcome loss': 0.8132006296744714, 'Total loss': 0.8132006296744714}
2022-11-23 00:27:15,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:15,905 INFO:     Epoch: 65
2022-11-23 00:27:16,843 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8602589131756262, 'Total loss': 0.8602589131756262} | train loss {'Reaction outcome loss': 0.811629929281922, 'Total loss': 0.811629929281922}
2022-11-23 00:27:16,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:16,843 INFO:     Epoch: 66
2022-11-23 00:27:17,747 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.862636914307421, 'Total loss': 0.862636914307421} | train loss {'Reaction outcome loss': 0.8074198803197035, 'Total loss': 0.8074198803197035}
2022-11-23 00:27:17,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:17,747 INFO:     Epoch: 67
2022-11-23 00:27:18,654 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8741464323618195, 'Total loss': 0.8741464323618195} | train loss {'Reaction outcome loss': 0.8064817090024833, 'Total loss': 0.8064817090024833}
2022-11-23 00:27:18,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:18,654 INFO:     Epoch: 68
2022-11-23 00:27:19,547 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8706095990809527, 'Total loss': 0.8706095990809527} | train loss {'Reaction outcome loss': 0.8123964423592757, 'Total loss': 0.8123964423592757}
2022-11-23 00:27:19,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:19,548 INFO:     Epoch: 69
2022-11-23 00:27:20,459 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.852283389730887, 'Total loss': 0.852283389730887} | train loss {'Reaction outcome loss': 0.8100619412626815, 'Total loss': 0.8100619412626815}
2022-11-23 00:27:20,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:20,459 INFO:     Epoch: 70
2022-11-23 00:27:21,320 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8717534731734883, 'Total loss': 0.8717534731734883} | train loss {'Reaction outcome loss': 0.8052086613936583, 'Total loss': 0.8052086613936583}
2022-11-23 00:27:21,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:21,321 INFO:     Epoch: 71
2022-11-23 00:27:22,235 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8812113085930998, 'Total loss': 0.8812113085930998} | train loss {'Reaction outcome loss': 0.8066401322360947, 'Total loss': 0.8066401322360947}
2022-11-23 00:27:22,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:22,236 INFO:     Epoch: 72
2022-11-23 00:27:23,163 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8819594180042093, 'Total loss': 0.8819594180042093} | train loss {'Reaction outcome loss': 0.8086730165761492, 'Total loss': 0.8086730165761492}
2022-11-23 00:27:23,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:23,163 INFO:     Epoch: 73
2022-11-23 00:27:24,013 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8453746695410121, 'Total loss': 0.8453746695410121} | train loss {'Reaction outcome loss': 0.8077001668784299, 'Total loss': 0.8077001668784299}
2022-11-23 00:27:24,013 INFO:     Found new best model at epoch 73
2022-11-23 00:27:24,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:24,014 INFO:     Epoch: 74
2022-11-23 00:27:24,871 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8642717640508305, 'Total loss': 0.8642717640508305} | train loss {'Reaction outcome loss': 0.8083824594976449, 'Total loss': 0.8083824594976449}
2022-11-23 00:27:24,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:24,871 INFO:     Epoch: 75
2022-11-23 00:27:25,787 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8493544283238325, 'Total loss': 0.8493544283238325} | train loss {'Reaction outcome loss': 0.8078853151334925, 'Total loss': 0.8078853151334925}
2022-11-23 00:27:25,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:25,787 INFO:     Epoch: 76
2022-11-23 00:27:26,674 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8599638796665452, 'Total loss': 0.8599638796665452} | train loss {'Reaction outcome loss': 0.8185601531252688, 'Total loss': 0.8185601531252688}
2022-11-23 00:27:26,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:26,675 INFO:     Epoch: 77
2022-11-23 00:27:27,548 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8695750798691403, 'Total loss': 0.8695750798691403} | train loss {'Reaction outcome loss': 0.8136230362089056, 'Total loss': 0.8136230362089056}
2022-11-23 00:27:27,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:27,549 INFO:     Epoch: 78
2022-11-23 00:27:28,457 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8513597818938169, 'Total loss': 0.8513597818938169} | train loss {'Reaction outcome loss': 0.8072935307798116, 'Total loss': 0.8072935307798116}
2022-11-23 00:27:28,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:28,457 INFO:     Epoch: 79
2022-11-23 00:27:29,318 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8831239742311564, 'Total loss': 0.8831239742311564} | train loss {'Reaction outcome loss': 0.813269134475152, 'Total loss': 0.813269134475152}
2022-11-23 00:27:29,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:29,318 INFO:     Epoch: 80
2022-11-23 00:27:30,165 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8674204593355005, 'Total loss': 0.8674204593355005} | train loss {'Reaction outcome loss': 0.8102234334115558, 'Total loss': 0.8102234334115558}
2022-11-23 00:27:30,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:30,165 INFO:     Epoch: 81
2022-11-23 00:27:31,012 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8916895538568497, 'Total loss': 0.8916895538568497} | train loss {'Reaction outcome loss': 0.8138782497842302, 'Total loss': 0.8138782497842302}
2022-11-23 00:27:31,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:31,012 INFO:     Epoch: 82
2022-11-23 00:27:31,890 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8582968759265813, 'Total loss': 0.8582968759265813} | train loss {'Reaction outcome loss': 0.8156043110106156, 'Total loss': 0.8156043110106156}
2022-11-23 00:27:31,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:31,890 INFO:     Epoch: 83
2022-11-23 00:27:32,747 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8768276490948417, 'Total loss': 0.8768276490948417} | train loss {'Reaction outcome loss': 0.8247890225064899, 'Total loss': 0.8247890225064899}
2022-11-23 00:27:32,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:32,747 INFO:     Epoch: 84
2022-11-23 00:27:33,584 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8583682328462601, 'Total loss': 0.8583682328462601} | train loss {'Reaction outcome loss': 0.8083715467800495, 'Total loss': 0.8083715467800495}
2022-11-23 00:27:33,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:33,585 INFO:     Epoch: 85
2022-11-23 00:27:34,475 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.866213440217755, 'Total loss': 0.866213440217755} | train loss {'Reaction outcome loss': 0.8059029517024152, 'Total loss': 0.8059029517024152}
2022-11-23 00:27:34,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:34,475 INFO:     Epoch: 86
2022-11-23 00:27:35,393 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8630885508927432, 'Total loss': 0.8630885508927432} | train loss {'Reaction outcome loss': 0.8063074244178741, 'Total loss': 0.8063074244178741}
2022-11-23 00:27:35,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:35,394 INFO:     Epoch: 87
2022-11-23 00:27:36,287 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8604085933078419, 'Total loss': 0.8604085933078419} | train loss {'Reaction outcome loss': 0.8045325408339018, 'Total loss': 0.8045325408339018}
2022-11-23 00:27:36,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:36,287 INFO:     Epoch: 88
2022-11-23 00:27:37,164 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8441934450106188, 'Total loss': 0.8441934450106188} | train loss {'Reaction outcome loss': 0.8146633277779166, 'Total loss': 0.8146633277779166}
2022-11-23 00:27:37,165 INFO:     Found new best model at epoch 88
2022-11-23 00:27:37,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:37,166 INFO:     Epoch: 89
2022-11-23 00:27:38,053 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8463550948283889, 'Total loss': 0.8463550948283889} | train loss {'Reaction outcome loss': 0.8087634947678821, 'Total loss': 0.8087634947678821}
2022-11-23 00:27:38,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:38,053 INFO:     Epoch: 90
2022-11-23 00:27:38,887 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8558376986872066, 'Total loss': 0.8558376986872066} | train loss {'Reaction outcome loss': 0.8099320300436212, 'Total loss': 0.8099320300436212}
2022-11-23 00:27:38,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:38,889 INFO:     Epoch: 91
2022-11-23 00:27:39,735 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.841135947541757, 'Total loss': 0.841135947541757} | train loss {'Reaction outcome loss': 0.810026111028455, 'Total loss': 0.810026111028455}
2022-11-23 00:27:39,736 INFO:     Found new best model at epoch 91
2022-11-23 00:27:39,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:39,736 INFO:     Epoch: 92
2022-11-23 00:27:40,594 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.869460599666292, 'Total loss': 0.869460599666292} | train loss {'Reaction outcome loss': 0.8099840823938007, 'Total loss': 0.8099840823938007}
2022-11-23 00:27:40,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:40,595 INFO:     Epoch: 93
2022-11-23 00:27:41,495 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8634074628353119, 'Total loss': 0.8634074628353119} | train loss {'Reaction outcome loss': 0.8068826447734948, 'Total loss': 0.8068826447734948}
2022-11-23 00:27:41,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:41,496 INFO:     Epoch: 94
2022-11-23 00:27:42,348 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8660978837446733, 'Total loss': 0.8660978837446733} | train loss {'Reaction outcome loss': 0.8066354205130566, 'Total loss': 0.8066354205130566}
2022-11-23 00:27:42,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:42,349 INFO:     Epoch: 95
2022-11-23 00:27:43,258 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8570797294378281, 'Total loss': 0.8570797294378281} | train loss {'Reaction outcome loss': 0.8125497543136118, 'Total loss': 0.8125497543136118}
2022-11-23 00:27:43,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:43,258 INFO:     Epoch: 96
2022-11-23 00:27:44,148 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8503361357883974, 'Total loss': 0.8503361357883974} | train loss {'Reaction outcome loss': 0.8056070592239318, 'Total loss': 0.8056070592239318}
2022-11-23 00:27:44,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:44,148 INFO:     Epoch: 97
2022-11-23 00:27:45,034 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8490767336704514, 'Total loss': 0.8490767336704514} | train loss {'Reaction outcome loss': 0.8146798202866002, 'Total loss': 0.8146798202866002}
2022-11-23 00:27:45,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:45,035 INFO:     Epoch: 98
2022-11-23 00:27:45,918 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8726737973364916, 'Total loss': 0.8726737973364916} | train loss {'Reaction outcome loss': 0.811320770245332, 'Total loss': 0.811320770245332}
2022-11-23 00:27:45,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:45,918 INFO:     Epoch: 99
2022-11-23 00:27:46,768 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8579949634996328, 'Total loss': 0.8579949634996328} | train loss {'Reaction outcome loss': 0.806933522405412, 'Total loss': 0.806933522405412}
2022-11-23 00:27:46,768 INFO:     Best model found after epoch 92 of 100.
2022-11-23 00:27:46,768 INFO:   Done with stage: TRAINING
2022-11-23 00:27:46,769 INFO:   Starting stage: EVALUATION
2022-11-23 00:27:46,897 INFO:   Done with stage: EVALUATION
2022-11-23 00:27:46,897 INFO:   Leaving out SEQ value Fold_6
2022-11-23 00:27:46,911 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:27:46,911 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:27:47,588 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:27:47,588 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:27:47,662 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:27:47,662 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:27:47,662 INFO:     No hyperparam tuning for this model
2022-11-23 00:27:47,662 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:27:47,662 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:27:47,663 INFO:     None feature selector for col prot
2022-11-23 00:27:47,663 INFO:     None feature selector for col prot
2022-11-23 00:27:47,664 INFO:     None feature selector for col prot
2022-11-23 00:27:47,664 INFO:     None feature selector for col chem
2022-11-23 00:27:47,664 INFO:     None feature selector for col chem
2022-11-23 00:27:47,664 INFO:     None feature selector for col chem
2022-11-23 00:27:47,665 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:27:47,665 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:27:47,666 INFO:     Number of params in model 168571
2022-11-23 00:27:47,670 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:27:47,670 INFO:   Starting stage: TRAINING
2022-11-23 00:27:47,730 INFO:     Val loss before train {'Reaction outcome loss': 1.0386670008301735, 'Total loss': 1.0386670008301735}
2022-11-23 00:27:47,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:47,730 INFO:     Epoch: 0
2022-11-23 00:27:48,612 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8849630789323286, 'Total loss': 0.8849630789323286} | train loss {'Reaction outcome loss': 0.875744563968558, 'Total loss': 0.875744563968558}
2022-11-23 00:27:48,612 INFO:     Found new best model at epoch 0
2022-11-23 00:27:48,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:48,613 INFO:     Epoch: 1
2022-11-23 00:27:49,461 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.87327245216478, 'Total loss': 0.87327245216478} | train loss {'Reaction outcome loss': 0.8366981449156154, 'Total loss': 0.8366981449156154}
2022-11-23 00:27:49,461 INFO:     Found new best model at epoch 1
2022-11-23 00:27:49,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:49,462 INFO:     Epoch: 2
2022-11-23 00:27:50,325 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8516900986433029, 'Total loss': 0.8516900986433029} | train loss {'Reaction outcome loss': 0.8292806629951184, 'Total loss': 0.8292806629951184}
2022-11-23 00:27:50,325 INFO:     Found new best model at epoch 2
2022-11-23 00:27:50,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:50,326 INFO:     Epoch: 3
2022-11-23 00:27:51,237 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8475224172527139, 'Total loss': 0.8475224172527139} | train loss {'Reaction outcome loss': 0.8244251102088433, 'Total loss': 0.8244251102088433}
2022-11-23 00:27:51,237 INFO:     Found new best model at epoch 3
2022-11-23 00:27:51,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:51,238 INFO:     Epoch: 4
2022-11-23 00:27:52,113 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8853558952158148, 'Total loss': 0.8853558952158148} | train loss {'Reaction outcome loss': 0.8196279517552147, 'Total loss': 0.8196279517552147}
2022-11-23 00:27:52,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:52,114 INFO:     Epoch: 5
2022-11-23 00:27:52,986 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8534377393397418, 'Total loss': 0.8534377393397418} | train loss {'Reaction outcome loss': 0.8200123807196675, 'Total loss': 0.8200123807196675}
2022-11-23 00:27:52,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:52,986 INFO:     Epoch: 6
2022-11-23 00:27:53,836 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8518561849539931, 'Total loss': 0.8518561849539931} | train loss {'Reaction outcome loss': 0.8134052211094481, 'Total loss': 0.8134052211094481}
2022-11-23 00:27:53,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:53,836 INFO:     Epoch: 7
2022-11-23 00:27:54,728 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8229567469521002, 'Total loss': 0.8229567469521002} | train loss {'Reaction outcome loss': 0.821420274524071, 'Total loss': 0.821420274524071}
2022-11-23 00:27:54,729 INFO:     Found new best model at epoch 7
2022-11-23 00:27:54,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:54,730 INFO:     Epoch: 8
2022-11-23 00:27:55,555 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8286591524427588, 'Total loss': 0.8286591524427588} | train loss {'Reaction outcome loss': 0.8139253275597144, 'Total loss': 0.8139253275597144}
2022-11-23 00:27:55,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:55,555 INFO:     Epoch: 9
2022-11-23 00:27:56,391 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8739475580778989, 'Total loss': 0.8739475580778989} | train loss {'Reaction outcome loss': 0.8060696491828332, 'Total loss': 0.8060696491828332}
2022-11-23 00:27:56,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:56,391 INFO:     Epoch: 10
2022-11-23 00:27:57,205 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8345700935883955, 'Total loss': 0.8345700935883955} | train loss {'Reaction outcome loss': 0.818047397653101, 'Total loss': 0.818047397653101}
2022-11-23 00:27:57,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:57,207 INFO:     Epoch: 11
2022-11-23 00:27:58,036 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8442870026284998, 'Total loss': 0.8442870026284998} | train loss {'Reaction outcome loss': 0.8148190541426662, 'Total loss': 0.8148190541426662}
2022-11-23 00:27:58,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:58,037 INFO:     Epoch: 12
2022-11-23 00:27:58,867 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8246971287510612, 'Total loss': 0.8246971287510612} | train loss {'Reaction outcome loss': 0.8121477928962785, 'Total loss': 0.8121477928962785}
2022-11-23 00:27:58,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:58,867 INFO:     Epoch: 13
2022-11-23 00:27:59,678 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.868646654215726, 'Total loss': 0.868646654215726} | train loss {'Reaction outcome loss': 0.810546458732744, 'Total loss': 0.810546458732744}
2022-11-23 00:27:59,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:27:59,678 INFO:     Epoch: 14
2022-11-23 00:28:00,527 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8339333242990754, 'Total loss': 0.8339333242990754} | train loss {'Reaction outcome loss': 0.8131621505326105, 'Total loss': 0.8131621505326105}
2022-11-23 00:28:00,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:00,527 INFO:     Epoch: 15
2022-11-23 00:28:01,364 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8374203287742354, 'Total loss': 0.8374203287742354} | train loss {'Reaction outcome loss': 0.8046725766454269, 'Total loss': 0.8046725766454269}
2022-11-23 00:28:01,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:01,364 INFO:     Epoch: 16
2022-11-23 00:28:02,191 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8523504368283532, 'Total loss': 0.8523504368283532} | train loss {'Reaction outcome loss': 0.8132595526062043, 'Total loss': 0.8132595526062043}
2022-11-23 00:28:02,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:02,191 INFO:     Epoch: 17
2022-11-23 00:28:02,999 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8236889216032895, 'Total loss': 0.8236889216032895} | train loss {'Reaction outcome loss': 0.8070229311748917, 'Total loss': 0.8070229311748917}
2022-11-23 00:28:02,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:02,999 INFO:     Epoch: 18
2022-11-23 00:28:03,809 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8256140893155878, 'Total loss': 0.8256140893155878} | train loss {'Reaction outcome loss': 0.8054502781344811, 'Total loss': 0.8054502781344811}
2022-11-23 00:28:03,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:03,810 INFO:     Epoch: 19
2022-11-23 00:28:04,618 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8361670327457514, 'Total loss': 0.8361670327457514} | train loss {'Reaction outcome loss': 0.8090020900795817, 'Total loss': 0.8090020900795817}
2022-11-23 00:28:04,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:04,618 INFO:     Epoch: 20
2022-11-23 00:28:05,441 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8384376974268393, 'Total loss': 0.8384376974268393} | train loss {'Reaction outcome loss': 0.8070888511444393, 'Total loss': 0.8070888511444393}
2022-11-23 00:28:05,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:05,442 INFO:     Epoch: 21
2022-11-23 00:28:06,259 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8415525298226963, 'Total loss': 0.8415525298226963} | train loss {'Reaction outcome loss': 0.809133834684426, 'Total loss': 0.809133834684426}
2022-11-23 00:28:06,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:06,259 INFO:     Epoch: 22
2022-11-23 00:28:07,063 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.844829954884269, 'Total loss': 0.844829954884269} | train loss {'Reaction outcome loss': 0.8067155562431706, 'Total loss': 0.8067155562431706}
2022-11-23 00:28:07,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:07,064 INFO:     Epoch: 23
2022-11-23 00:28:07,861 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8351235525174574, 'Total loss': 0.8351235525174574} | train loss {'Reaction outcome loss': 0.803477395310817, 'Total loss': 0.803477395310817}
2022-11-23 00:28:07,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:07,861 INFO:     Epoch: 24
2022-11-23 00:28:08,668 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8232150192965161, 'Total loss': 0.8232150192965161} | train loss {'Reaction outcome loss': 0.8110376169324404, 'Total loss': 0.8110376169324404}
2022-11-23 00:28:08,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:08,669 INFO:     Epoch: 25
2022-11-23 00:28:09,460 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8402986594221808, 'Total loss': 0.8402986594221808} | train loss {'Reaction outcome loss': 0.8063518744007296, 'Total loss': 0.8063518744007296}
2022-11-23 00:28:09,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:09,460 INFO:     Epoch: 26
2022-11-23 00:28:10,274 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8222789540886879, 'Total loss': 0.8222789540886879} | train loss {'Reaction outcome loss': 0.8080702191181028, 'Total loss': 0.8080702191181028}
2022-11-23 00:28:10,275 INFO:     Found new best model at epoch 26
2022-11-23 00:28:10,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:10,276 INFO:     Epoch: 27
2022-11-23 00:28:11,077 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.823329668153416, 'Total loss': 0.823329668153416} | train loss {'Reaction outcome loss': 0.8058666024613477, 'Total loss': 0.8058666024613477}
2022-11-23 00:28:11,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:11,078 INFO:     Epoch: 28
2022-11-23 00:28:11,863 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8326597999442708, 'Total loss': 0.8326597999442708} | train loss {'Reaction outcome loss': 0.8017853474327428, 'Total loss': 0.8017853474327428}
2022-11-23 00:28:11,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:11,863 INFO:     Epoch: 29
2022-11-23 00:28:12,659 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8331420204856179, 'Total loss': 0.8331420204856179} | train loss {'Reaction outcome loss': 0.8118770614809353, 'Total loss': 0.8118770614809353}
2022-11-23 00:28:12,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:12,660 INFO:     Epoch: 30
2022-11-23 00:28:13,442 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8287160999395631, 'Total loss': 0.8287160999395631} | train loss {'Reaction outcome loss': 0.8039823022448582, 'Total loss': 0.8039823022448582}
2022-11-23 00:28:13,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:13,442 INFO:     Epoch: 31
2022-11-23 00:28:14,241 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8216374103318561, 'Total loss': 0.8216374103318561} | train loss {'Reaction outcome loss': 0.8061709703221495, 'Total loss': 0.8061709703221495}
2022-11-23 00:28:14,241 INFO:     Found new best model at epoch 31
2022-11-23 00:28:14,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:14,242 INFO:     Epoch: 32
2022-11-23 00:28:15,052 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.843822907995094, 'Total loss': 0.843822907995094} | train loss {'Reaction outcome loss': 0.8038298994423407, 'Total loss': 0.8038298994423407}
2022-11-23 00:28:15,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:15,053 INFO:     Epoch: 33
2022-11-23 00:28:15,885 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.824565783820369, 'Total loss': 0.824565783820369} | train loss {'Reaction outcome loss': 0.7999193767907649, 'Total loss': 0.7999193767907649}
2022-11-23 00:28:15,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:15,885 INFO:     Epoch: 34
2022-11-23 00:28:16,705 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8352387459440664, 'Total loss': 0.8352387459440664} | train loss {'Reaction outcome loss': 0.7988522178248355, 'Total loss': 0.7988522178248355}
2022-11-23 00:28:16,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:16,706 INFO:     Epoch: 35
2022-11-23 00:28:17,550 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8202011700380932, 'Total loss': 0.8202011700380932} | train loss {'Reaction outcome loss': 0.8102967936982993, 'Total loss': 0.8102967936982993}
2022-11-23 00:28:17,550 INFO:     Found new best model at epoch 35
2022-11-23 00:28:17,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:17,551 INFO:     Epoch: 36
2022-11-23 00:28:18,378 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8275505324656313, 'Total loss': 0.8275505324656313} | train loss {'Reaction outcome loss': 0.8046421874389957, 'Total loss': 0.8046421874389957}
2022-11-23 00:28:18,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:18,379 INFO:     Epoch: 37
2022-11-23 00:28:19,188 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8333468274636702, 'Total loss': 0.8333468274636702} | train loss {'Reaction outcome loss': 0.7999932919195306, 'Total loss': 0.7999932919195306}
2022-11-23 00:28:19,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:19,188 INFO:     Epoch: 38
2022-11-23 00:28:20,010 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.820267759940841, 'Total loss': 0.820267759940841} | train loss {'Reaction outcome loss': 0.8142721689181772, 'Total loss': 0.8142721689181772}
2022-11-23 00:28:20,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:20,010 INFO:     Epoch: 39
2022-11-23 00:28:20,808 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8279477750713174, 'Total loss': 0.8279477750713174} | train loss {'Reaction outcome loss': 0.808497947478584, 'Total loss': 0.808497947478584}
2022-11-23 00:28:20,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:20,809 INFO:     Epoch: 40
2022-11-23 00:28:21,603 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8305771933360533, 'Total loss': 0.8305771933360533} | train loss {'Reaction outcome loss': 0.8015713592470899, 'Total loss': 0.8015713592470899}
2022-11-23 00:28:21,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:21,603 INFO:     Epoch: 41
2022-11-23 00:28:22,407 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.817912648347291, 'Total loss': 0.817912648347291} | train loss {'Reaction outcome loss': 0.8016097076267366, 'Total loss': 0.8016097076267366}
2022-11-23 00:28:22,408 INFO:     Found new best model at epoch 41
2022-11-23 00:28:22,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:22,408 INFO:     Epoch: 42
2022-11-23 00:28:23,245 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8190578466111963, 'Total loss': 0.8190578466111963} | train loss {'Reaction outcome loss': 0.8050769534912187, 'Total loss': 0.8050769534912187}
2022-11-23 00:28:23,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:23,245 INFO:     Epoch: 43
2022-11-23 00:28:24,113 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8274549713188951, 'Total loss': 0.8274549713188951} | train loss {'Reaction outcome loss': 0.7997125665306563, 'Total loss': 0.7997125665306563}
2022-11-23 00:28:24,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:24,113 INFO:     Epoch: 44
2022-11-23 00:28:24,884 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.842745454473929, 'Total loss': 0.842745454473929} | train loss {'Reaction outcome loss': 0.8006610108335853, 'Total loss': 0.8006610108335853}
2022-11-23 00:28:24,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:24,884 INFO:     Epoch: 45
2022-11-23 00:28:25,708 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8189856504852121, 'Total loss': 0.8189856504852121} | train loss {'Reaction outcome loss': 0.8016980450886947, 'Total loss': 0.8016980450886947}
2022-11-23 00:28:25,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:25,708 INFO:     Epoch: 46
2022-11-23 00:28:26,564 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8150381513617255, 'Total loss': 0.8150381513617255} | train loss {'Reaction outcome loss': 0.8019791015306947, 'Total loss': 0.8019791015306947}
2022-11-23 00:28:26,564 INFO:     Found new best model at epoch 46
2022-11-23 00:28:26,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:26,565 INFO:     Epoch: 47
2022-11-23 00:28:27,419 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8262752057476477, 'Total loss': 0.8262752057476477} | train loss {'Reaction outcome loss': 0.8069975495579754, 'Total loss': 0.8069975495579754}
2022-11-23 00:28:27,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:27,419 INFO:     Epoch: 48
2022-11-23 00:28:28,239 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8237244527448307, 'Total loss': 0.8237244527448307} | train loss {'Reaction outcome loss': 0.8051199943189197, 'Total loss': 0.8051199943189197}
2022-11-23 00:28:28,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:28,240 INFO:     Epoch: 49
2022-11-23 00:28:29,071 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8314356106248769, 'Total loss': 0.8314356106248769} | train loss {'Reaction outcome loss': 0.8013160748158389, 'Total loss': 0.8013160748158389}
2022-11-23 00:28:29,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:29,072 INFO:     Epoch: 50
2022-11-23 00:28:29,875 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8155334226109765, 'Total loss': 0.8155334226109765} | train loss {'Reaction outcome loss': 0.800303043986139, 'Total loss': 0.800303043986139}
2022-11-23 00:28:29,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:29,876 INFO:     Epoch: 51
2022-11-23 00:28:30,660 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8524583395231854, 'Total loss': 0.8524583395231854} | train loss {'Reaction outcome loss': 0.7982444683248214, 'Total loss': 0.7982444683248214}
2022-11-23 00:28:30,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:30,660 INFO:     Epoch: 52
2022-11-23 00:28:31,478 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8421227518807758, 'Total loss': 0.8421227518807758} | train loss {'Reaction outcome loss': 0.8039144180443606, 'Total loss': 0.8039144180443606}
2022-11-23 00:28:31,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:31,479 INFO:     Epoch: 53
2022-11-23 00:28:32,318 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8276762461120432, 'Total loss': 0.8276762461120432} | train loss {'Reaction outcome loss': 0.8053743311992059, 'Total loss': 0.8053743311992059}
2022-11-23 00:28:32,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:32,318 INFO:     Epoch: 54
2022-11-23 00:28:33,158 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8286213217811151, 'Total loss': 0.8286213217811151} | train loss {'Reaction outcome loss': 0.8002363719679566, 'Total loss': 0.8002363719679566}
2022-11-23 00:28:33,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:33,158 INFO:     Epoch: 55
2022-11-23 00:28:33,961 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.830754236064174, 'Total loss': 0.830754236064174} | train loss {'Reaction outcome loss': 0.8034712386276075, 'Total loss': 0.8034712386276075}
2022-11-23 00:28:33,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:33,962 INFO:     Epoch: 56
2022-11-23 00:28:34,756 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8514086983420632, 'Total loss': 0.8514086983420632} | train loss {'Reaction outcome loss': 0.800194743673811, 'Total loss': 0.800194743673811}
2022-11-23 00:28:34,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:34,757 INFO:     Epoch: 57
2022-11-23 00:28:35,549 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8249828131361441, 'Total loss': 0.8249828131361441} | train loss {'Reaction outcome loss': 0.8005290572203485, 'Total loss': 0.8005290572203485}
2022-11-23 00:28:35,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:35,550 INFO:     Epoch: 58
2022-11-23 00:28:36,357 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8843155110424216, 'Total loss': 0.8843155110424216} | train loss {'Reaction outcome loss': 0.7956967023823426, 'Total loss': 0.7956967023823426}
2022-11-23 00:28:36,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:36,357 INFO:     Epoch: 59
2022-11-23 00:28:37,185 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8381929052146998, 'Total loss': 0.8381929052146998} | train loss {'Reaction outcome loss': 0.8055375481424062, 'Total loss': 0.8055375481424062}
2022-11-23 00:28:37,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:37,185 INFO:     Epoch: 60
2022-11-23 00:28:37,941 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8352662853219293, 'Total loss': 0.8352662853219293} | train loss {'Reaction outcome loss': 0.808169526851129, 'Total loss': 0.808169526851129}
2022-11-23 00:28:37,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:37,942 INFO:     Epoch: 61
2022-11-23 00:28:38,735 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.844482653520324, 'Total loss': 0.844482653520324} | train loss {'Reaction outcome loss': 0.7989734353625823, 'Total loss': 0.7989734353625823}
2022-11-23 00:28:38,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:38,735 INFO:     Epoch: 62
2022-11-23 00:28:39,542 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8223529539325021, 'Total loss': 0.8223529539325021} | train loss {'Reaction outcome loss': 0.8004468632975088, 'Total loss': 0.8004468632975088}
2022-11-23 00:28:39,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:39,542 INFO:     Epoch: 63
2022-11-23 00:28:40,340 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.82681450789625, 'Total loss': 0.82681450789625} | train loss {'Reaction outcome loss': 0.8091937505040574, 'Total loss': 0.8091937505040574}
2022-11-23 00:28:40,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:40,341 INFO:     Epoch: 64
2022-11-23 00:28:41,142 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8396116935394027, 'Total loss': 0.8396116935394027} | train loss {'Reaction outcome loss': 0.8077756054246956, 'Total loss': 0.8077756054246956}
2022-11-23 00:28:41,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:41,143 INFO:     Epoch: 65
2022-11-23 00:28:41,933 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8627469607374885, 'Total loss': 0.8627469607374885} | train loss {'Reaction outcome loss': 0.804069710163935, 'Total loss': 0.804069710163935}
2022-11-23 00:28:41,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:41,933 INFO:     Epoch: 66
2022-11-23 00:28:42,770 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8401057395068082, 'Total loss': 0.8401057395068082} | train loss {'Reaction outcome loss': 0.8029321357230788, 'Total loss': 0.8029321357230788}
2022-11-23 00:28:42,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:42,770 INFO:     Epoch: 67
2022-11-23 00:28:43,570 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8205527764829722, 'Total loss': 0.8205527764829722} | train loss {'Reaction outcome loss': 0.7977857045557818, 'Total loss': 0.7977857045557818}
2022-11-23 00:28:43,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:43,570 INFO:     Epoch: 68
2022-11-23 00:28:44,394 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8263235979459502, 'Total loss': 0.8263235979459502} | train loss {'Reaction outcome loss': 0.8001717755246741, 'Total loss': 0.8001717755246741}
2022-11-23 00:28:44,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:44,394 INFO:     Epoch: 69
2022-11-23 00:28:45,214 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8199314502152529, 'Total loss': 0.8199314502152529} | train loss {'Reaction outcome loss': 0.8014169898381841, 'Total loss': 0.8014169898381841}
2022-11-23 00:28:45,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:45,214 INFO:     Epoch: 70
2022-11-23 00:28:46,040 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8239833766763861, 'Total loss': 0.8239833766763861} | train loss {'Reaction outcome loss': 0.8010943541642626, 'Total loss': 0.8010943541642626}
2022-11-23 00:28:46,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:46,040 INFO:     Epoch: 71
2022-11-23 00:28:46,873 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8359639739448373, 'Total loss': 0.8359639739448373} | train loss {'Reaction outcome loss': 0.81130143034796, 'Total loss': 0.81130143034796}
2022-11-23 00:28:46,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:46,873 INFO:     Epoch: 72
2022-11-23 00:28:47,680 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8312571333213286, 'Total loss': 0.8312571333213286} | train loss {'Reaction outcome loss': 0.8057351448395957, 'Total loss': 0.8057351448395957}
2022-11-23 00:28:47,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:47,681 INFO:     Epoch: 73
2022-11-23 00:28:48,497 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8618990020318464, 'Total loss': 0.8618990020318464} | train loss {'Reaction outcome loss': 0.8094676568923209, 'Total loss': 0.8094676568923209}
2022-11-23 00:28:48,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:48,497 INFO:     Epoch: 74
2022-11-23 00:28:49,318 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8187806497920643, 'Total loss': 0.8187806497920643} | train loss {'Reaction outcome loss': 0.8032972743274712, 'Total loss': 0.8032972743274712}
2022-11-23 00:28:49,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:49,318 INFO:     Epoch: 75
2022-11-23 00:28:50,099 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8345057578249411, 'Total loss': 0.8345057578249411} | train loss {'Reaction outcome loss': 0.8025955468536872, 'Total loss': 0.8025955468536872}
2022-11-23 00:28:50,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:50,099 INFO:     Epoch: 76
2022-11-23 00:28:50,910 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8127178996801376, 'Total loss': 0.8127178996801376} | train loss {'Reaction outcome loss': 0.8055675267449275, 'Total loss': 0.8055675267449275}
2022-11-23 00:28:50,910 INFO:     Found new best model at epoch 76
2022-11-23 00:28:50,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:50,911 INFO:     Epoch: 77
2022-11-23 00:28:51,706 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.847784318707206, 'Total loss': 0.847784318707206} | train loss {'Reaction outcome loss': 0.7991000534853472, 'Total loss': 0.7991000534853472}
2022-11-23 00:28:51,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:51,706 INFO:     Epoch: 78
2022-11-23 00:28:52,550 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8174361288547516, 'Total loss': 0.8174361288547516} | train loss {'Reaction outcome loss': 0.8002931087726524, 'Total loss': 0.8002931087726524}
2022-11-23 00:28:52,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:52,550 INFO:     Epoch: 79
2022-11-23 00:28:53,356 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.842592450028116, 'Total loss': 0.842592450028116} | train loss {'Reaction outcome loss': 0.810717914630527, 'Total loss': 0.810717914630527}
2022-11-23 00:28:53,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:53,356 INFO:     Epoch: 80
2022-11-23 00:28:54,167 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8254788179289211, 'Total loss': 0.8254788179289211} | train loss {'Reaction outcome loss': 0.805155526409265, 'Total loss': 0.805155526409265}
2022-11-23 00:28:54,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:54,167 INFO:     Epoch: 81
2022-11-23 00:28:54,994 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8279692869294774, 'Total loss': 0.8279692869294774} | train loss {'Reaction outcome loss': 0.8037523226699366, 'Total loss': 0.8037523226699366}
2022-11-23 00:28:54,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:54,994 INFO:     Epoch: 82
2022-11-23 00:28:55,783 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8371660357171838, 'Total loss': 0.8371660357171838} | train loss {'Reaction outcome loss': 0.8008297651040892, 'Total loss': 0.8008297651040892}
2022-11-23 00:28:55,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:55,783 INFO:     Epoch: 83
2022-11-23 00:28:56,640 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8344817405397241, 'Total loss': 0.8344817405397241} | train loss {'Reaction outcome loss': 0.807481152808618, 'Total loss': 0.807481152808618}
2022-11-23 00:28:56,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:56,640 INFO:     Epoch: 84
2022-11-23 00:28:57,457 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8353728597814386, 'Total loss': 0.8353728597814386} | train loss {'Reaction outcome loss': 0.8059391132009174, 'Total loss': 0.8059391132009174}
2022-11-23 00:28:57,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:57,457 INFO:     Epoch: 85
2022-11-23 00:28:58,282 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8254333971576258, 'Total loss': 0.8254333971576258} | train loss {'Reaction outcome loss': 0.8031064657426557, 'Total loss': 0.8031064657426557}
2022-11-23 00:28:58,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:58,283 INFO:     Epoch: 86
2022-11-23 00:28:59,043 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8376041840423237, 'Total loss': 0.8376041840423237} | train loss {'Reaction outcome loss': 0.8046400547027588, 'Total loss': 0.8046400547027588}
2022-11-23 00:28:59,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:59,043 INFO:     Epoch: 87
2022-11-23 00:28:59,849 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8247996649958871, 'Total loss': 0.8247996649958871} | train loss {'Reaction outcome loss': 0.8045013889610043, 'Total loss': 0.8045013889610043}
2022-11-23 00:28:59,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:28:59,850 INFO:     Epoch: 88
2022-11-23 00:29:00,661 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8183693757111375, 'Total loss': 0.8183693757111375} | train loss {'Reaction outcome loss': 0.8037433867995073, 'Total loss': 0.8037433867995073}
2022-11-23 00:29:00,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:00,661 INFO:     Epoch: 89
2022-11-23 00:29:01,481 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8364267714998939, 'Total loss': 0.8364267714998939} | train loss {'Reaction outcome loss': 0.800239067781068, 'Total loss': 0.800239067781068}
2022-11-23 00:29:01,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:01,482 INFO:     Epoch: 90
2022-11-23 00:29:02,317 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8332747952504591, 'Total loss': 0.8332747952504591} | train loss {'Reaction outcome loss': 0.8023765299484314, 'Total loss': 0.8023765299484314}
2022-11-23 00:29:02,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:02,317 INFO:     Epoch: 91
2022-11-23 00:29:03,167 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8432707854292609, 'Total loss': 0.8432707854292609} | train loss {'Reaction outcome loss': 0.8007126057799528, 'Total loss': 0.8007126057799528}
2022-11-23 00:29:03,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:03,167 INFO:     Epoch: 92
2022-11-23 00:29:03,991 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8177568350325931, 'Total loss': 0.8177568350325931} | train loss {'Reaction outcome loss': 0.812207403815227, 'Total loss': 0.812207403815227}
2022-11-23 00:29:03,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:03,992 INFO:     Epoch: 93
2022-11-23 00:29:04,800 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8384645486419852, 'Total loss': 0.8384645486419852} | train loss {'Reaction outcome loss': 0.801383018252338, 'Total loss': 0.801383018252338}
2022-11-23 00:29:04,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:04,800 INFO:     Epoch: 94
2022-11-23 00:29:05,602 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8488553389906883, 'Total loss': 0.8488553389906883} | train loss {'Reaction outcome loss': 0.8095547949012957, 'Total loss': 0.8095547949012957}
2022-11-23 00:29:05,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:05,602 INFO:     Epoch: 95
2022-11-23 00:29:06,412 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8290447728200392, 'Total loss': 0.8290447728200392} | train loss {'Reaction outcome loss': 0.8019676319500695, 'Total loss': 0.8019676319500695}
2022-11-23 00:29:06,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:06,413 INFO:     Epoch: 96
2022-11-23 00:29:07,198 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8270419822497801, 'Total loss': 0.8270419822497801} | train loss {'Reaction outcome loss': 0.7979462600430014, 'Total loss': 0.7979462600430014}
2022-11-23 00:29:07,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:07,198 INFO:     Epoch: 97
2022-11-23 00:29:08,000 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.824329370802099, 'Total loss': 0.824329370802099} | train loss {'Reaction outcome loss': 0.8034832302616676, 'Total loss': 0.8034832302616676}
2022-11-23 00:29:08,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:08,000 INFO:     Epoch: 98
2022-11-23 00:29:08,853 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8317174010656097, 'Total loss': 0.8317174010656097} | train loss {'Reaction outcome loss': 0.7976434306818464, 'Total loss': 0.7976434306818464}
2022-11-23 00:29:08,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:08,853 INFO:     Epoch: 99
2022-11-23 00:29:09,646 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8225981051271612, 'Total loss': 0.8225981051271612} | train loss {'Reaction outcome loss': 0.7997985896069993, 'Total loss': 0.7997985896069993}
2022-11-23 00:29:09,646 INFO:     Best model found after epoch 77 of 100.
2022-11-23 00:29:09,646 INFO:   Done with stage: TRAINING
2022-11-23 00:29:09,646 INFO:   Starting stage: EVALUATION
2022-11-23 00:29:09,772 INFO:   Done with stage: EVALUATION
2022-11-23 00:29:09,772 INFO:   Leaving out SEQ value Fold_7
2022-11-23 00:29:09,785 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:29:09,785 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:29:10,461 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:29:10,461 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:29:10,531 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:29:10,531 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:29:10,531 INFO:     No hyperparam tuning for this model
2022-11-23 00:29:10,531 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:29:10,531 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:29:10,532 INFO:     None feature selector for col prot
2022-11-23 00:29:10,532 INFO:     None feature selector for col prot
2022-11-23 00:29:10,532 INFO:     None feature selector for col prot
2022-11-23 00:29:10,533 INFO:     None feature selector for col chem
2022-11-23 00:29:10,533 INFO:     None feature selector for col chem
2022-11-23 00:29:10,533 INFO:     None feature selector for col chem
2022-11-23 00:29:10,533 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:29:10,533 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:29:10,535 INFO:     Number of params in model 168571
2022-11-23 00:29:10,538 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:29:10,539 INFO:   Starting stage: TRAINING
2022-11-23 00:29:10,597 INFO:     Val loss before train {'Reaction outcome loss': 0.9378925697370009, 'Total loss': 0.9378925697370009}
2022-11-23 00:29:10,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:10,597 INFO:     Epoch: 0
2022-11-23 00:29:11,421 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.78651332042434, 'Total loss': 0.78651332042434} | train loss {'Reaction outcome loss': 0.8902138452376088, 'Total loss': 0.8902138452376088}
2022-11-23 00:29:11,421 INFO:     Found new best model at epoch 0
2022-11-23 00:29:11,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:11,422 INFO:     Epoch: 1
2022-11-23 00:29:12,245 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8014557178724896, 'Total loss': 0.8014557178724896} | train loss {'Reaction outcome loss': 0.8500539354018627, 'Total loss': 0.8500539354018627}
2022-11-23 00:29:12,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:12,247 INFO:     Epoch: 2
2022-11-23 00:29:13,064 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.790212640708143, 'Total loss': 0.790212640708143} | train loss {'Reaction outcome loss': 0.8506752376354509, 'Total loss': 0.8506752376354509}
2022-11-23 00:29:13,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:13,064 INFO:     Epoch: 3
2022-11-23 00:29:13,865 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.793534324250438, 'Total loss': 0.793534324250438} | train loss {'Reaction outcome loss': 0.8478438484091912, 'Total loss': 0.8478438484091912}
2022-11-23 00:29:13,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:13,865 INFO:     Epoch: 4
2022-11-23 00:29:14,654 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7696156806566499, 'Total loss': 0.7696156806566499} | train loss {'Reaction outcome loss': 0.8420307296178033, 'Total loss': 0.8420307296178033}
2022-11-23 00:29:14,654 INFO:     Found new best model at epoch 4
2022-11-23 00:29:14,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:14,655 INFO:     Epoch: 5
2022-11-23 00:29:15,476 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7778273536400362, 'Total loss': 0.7778273536400362} | train loss {'Reaction outcome loss': 0.8397844094903238, 'Total loss': 0.8397844094903238}
2022-11-23 00:29:15,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:15,476 INFO:     Epoch: 6
2022-11-23 00:29:16,270 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7730519026517868, 'Total loss': 0.7730519026517868} | train loss {'Reaction outcome loss': 0.8340800367295742, 'Total loss': 0.8340800367295742}
2022-11-23 00:29:16,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:16,270 INFO:     Epoch: 7
2022-11-23 00:29:17,075 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7876118821176615, 'Total loss': 0.7876118821176615} | train loss {'Reaction outcome loss': 0.8314874803106631, 'Total loss': 0.8314874803106631}
2022-11-23 00:29:17,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:17,075 INFO:     Epoch: 8
2022-11-23 00:29:17,890 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7852561331608079, 'Total loss': 0.7852561331608079} | train loss {'Reaction outcome loss': 0.8299212991710632, 'Total loss': 0.8299212991710632}
2022-11-23 00:29:17,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:17,890 INFO:     Epoch: 9
2022-11-23 00:29:18,705 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7688651694492861, 'Total loss': 0.7688651694492861} | train loss {'Reaction outcome loss': 0.8302954157754299, 'Total loss': 0.8302954157754299}
2022-11-23 00:29:18,706 INFO:     Found new best model at epoch 9
2022-11-23 00:29:18,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:18,706 INFO:     Epoch: 10
2022-11-23 00:29:19,498 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7624145902015946, 'Total loss': 0.7624145902015946} | train loss {'Reaction outcome loss': 0.8265067661000837, 'Total loss': 0.8265067661000837}
2022-11-23 00:29:19,499 INFO:     Found new best model at epoch 10
2022-11-23 00:29:19,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:19,499 INFO:     Epoch: 11
2022-11-23 00:29:20,334 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7657167782837694, 'Total loss': 0.7657167782837694} | train loss {'Reaction outcome loss': 0.8261773499750322, 'Total loss': 0.8261773499750322}
2022-11-23 00:29:20,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:20,334 INFO:     Epoch: 12
2022-11-23 00:29:21,124 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7637976909225638, 'Total loss': 0.7637976909225638} | train loss {'Reaction outcome loss': 0.8266248622488591, 'Total loss': 0.8266248622488591}
2022-11-23 00:29:21,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:21,124 INFO:     Epoch: 13
2022-11-23 00:29:21,920 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7648982879790392, 'Total loss': 0.7648982879790392} | train loss {'Reaction outcome loss': 0.8224655126612033, 'Total loss': 0.8224655126612033}
2022-11-23 00:29:21,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:21,920 INFO:     Epoch: 14
2022-11-23 00:29:22,698 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7621673332019285, 'Total loss': 0.7621673332019285} | train loss {'Reaction outcome loss': 0.8232402187441626, 'Total loss': 0.8232402187441626}
2022-11-23 00:29:22,698 INFO:     Found new best model at epoch 14
2022-11-23 00:29:22,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:22,699 INFO:     Epoch: 15
2022-11-23 00:29:23,528 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7644684538245201, 'Total loss': 0.7644684538245201} | train loss {'Reaction outcome loss': 0.8191596292439969, 'Total loss': 0.8191596292439969}
2022-11-23 00:29:23,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:23,528 INFO:     Epoch: 16
2022-11-23 00:29:24,344 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.772665833207694, 'Total loss': 0.772665833207694} | train loss {'Reaction outcome loss': 0.8234957741393197, 'Total loss': 0.8234957741393197}
2022-11-23 00:29:24,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:24,344 INFO:     Epoch: 17
2022-11-23 00:29:25,166 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7710966901345686, 'Total loss': 0.7710966901345686} | train loss {'Reaction outcome loss': 0.8199481715358072, 'Total loss': 0.8199481715358072}
2022-11-23 00:29:25,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:25,166 INFO:     Epoch: 18
2022-11-23 00:29:25,985 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7593669403683055, 'Total loss': 0.7593669403683055} | train loss {'Reaction outcome loss': 0.8264856092151134, 'Total loss': 0.8264856092151134}
2022-11-23 00:29:25,985 INFO:     Found new best model at epoch 18
2022-11-23 00:29:25,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:25,986 INFO:     Epoch: 19
2022-11-23 00:29:26,849 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7720855623483658, 'Total loss': 0.7720855623483658} | train loss {'Reaction outcome loss': 0.8191381435721151, 'Total loss': 0.8191381435721151}
2022-11-23 00:29:26,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:26,849 INFO:     Epoch: 20
2022-11-23 00:29:27,713 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7658244025978175, 'Total loss': 0.7658244025978175} | train loss {'Reaction outcome loss': 0.8215739465048236, 'Total loss': 0.8215739465048236}
2022-11-23 00:29:27,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:27,714 INFO:     Epoch: 21
2022-11-23 00:29:28,532 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7570491121573881, 'Total loss': 0.7570491121573881} | train loss {'Reaction outcome loss': 0.8212171651182636, 'Total loss': 0.8212171651182636}
2022-11-23 00:29:28,532 INFO:     Found new best model at epoch 21
2022-11-23 00:29:28,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:28,533 INFO:     Epoch: 22
2022-11-23 00:29:29,352 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7788667719472538, 'Total loss': 0.7788667719472538} | train loss {'Reaction outcome loss': 0.821777623627455, 'Total loss': 0.821777623627455}
2022-11-23 00:29:29,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:29,353 INFO:     Epoch: 23
2022-11-23 00:29:30,215 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8008041740818457, 'Total loss': 0.8008041740818457} | train loss {'Reaction outcome loss': 0.8211945333788472, 'Total loss': 0.8211945333788472}
2022-11-23 00:29:30,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:30,216 INFO:     Epoch: 24
2022-11-23 00:29:30,982 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7511564073237506, 'Total loss': 0.7511564073237506} | train loss {'Reaction outcome loss': 0.8186161598611262, 'Total loss': 0.8186161598611262}
2022-11-23 00:29:30,983 INFO:     Found new best model at epoch 24
2022-11-23 00:29:30,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:30,984 INFO:     Epoch: 25
2022-11-23 00:29:31,773 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7780994881283153, 'Total loss': 0.7780994881283153} | train loss {'Reaction outcome loss': 0.8186100841529907, 'Total loss': 0.8186100841529907}
2022-11-23 00:29:31,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:31,774 INFO:     Epoch: 26
2022-11-23 00:29:32,598 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.800369375131347, 'Total loss': 0.800369375131347} | train loss {'Reaction outcome loss': 0.8161801105785754, 'Total loss': 0.8161801105785754}
2022-11-23 00:29:32,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:32,599 INFO:     Epoch: 27
2022-11-23 00:29:33,405 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7701529907909307, 'Total loss': 0.7701529907909307} | train loss {'Reaction outcome loss': 0.8243422490214148, 'Total loss': 0.8243422490214148}
2022-11-23 00:29:33,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:33,406 INFO:     Epoch: 28
2022-11-23 00:29:34,242 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7666506137360226, 'Total loss': 0.7666506137360226} | train loss {'Reaction outcome loss': 0.8174560545913635, 'Total loss': 0.8174560545913635}
2022-11-23 00:29:34,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:34,242 INFO:     Epoch: 29
2022-11-23 00:29:35,089 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7903009104457769, 'Total loss': 0.7903009104457769} | train loss {'Reaction outcome loss': 0.816759594866345, 'Total loss': 0.816759594866345}
2022-11-23 00:29:35,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:35,089 INFO:     Epoch: 30
2022-11-23 00:29:35,927 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7670826871286739, 'Total loss': 0.7670826871286739} | train loss {'Reaction outcome loss': 0.8202999176517609, 'Total loss': 0.8202999176517609}
2022-11-23 00:29:35,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:35,927 INFO:     Epoch: 31
2022-11-23 00:29:36,777 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.784971758723259, 'Total loss': 0.784971758723259} | train loss {'Reaction outcome loss': 0.8156587680982005, 'Total loss': 0.8156587680982005}
2022-11-23 00:29:36,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:36,777 INFO:     Epoch: 32
2022-11-23 00:29:37,586 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7659440799192949, 'Total loss': 0.7659440799192949} | train loss {'Reaction outcome loss': 0.8206317820135625, 'Total loss': 0.8206317820135625}
2022-11-23 00:29:37,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:37,586 INFO:     Epoch: 33
2022-11-23 00:29:38,405 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7840972041541879, 'Total loss': 0.7840972041541879} | train loss {'Reaction outcome loss': 0.8223704087638086, 'Total loss': 0.8223704087638086}
2022-11-23 00:29:38,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:38,406 INFO:     Epoch: 34
2022-11-23 00:29:39,210 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7508503544059667, 'Total loss': 0.7508503544059667} | train loss {'Reaction outcome loss': 0.824161152084989, 'Total loss': 0.824161152084989}
2022-11-23 00:29:39,210 INFO:     Found new best model at epoch 34
2022-11-23 00:29:39,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:39,211 INFO:     Epoch: 35
2022-11-23 00:29:40,007 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7684817442839796, 'Total loss': 0.7684817442839796} | train loss {'Reaction outcome loss': 0.8230945707088516, 'Total loss': 0.8230945707088516}
2022-11-23 00:29:40,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:40,007 INFO:     Epoch: 36
2022-11-23 00:29:40,801 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.768276955593716, 'Total loss': 0.768276955593716} | train loss {'Reaction outcome loss': 0.8142067342996597, 'Total loss': 0.8142067342996597}
2022-11-23 00:29:40,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:40,802 INFO:     Epoch: 37
2022-11-23 00:29:41,640 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7816366749730977, 'Total loss': 0.7816366749730977} | train loss {'Reaction outcome loss': 0.8165018547686839, 'Total loss': 0.8165018547686839}
2022-11-23 00:29:41,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:41,640 INFO:     Epoch: 38
2022-11-23 00:29:42,455 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7667241299694235, 'Total loss': 0.7667241299694235} | train loss {'Reaction outcome loss': 0.820192789478648, 'Total loss': 0.820192789478648}
2022-11-23 00:29:42,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:42,455 INFO:     Epoch: 39
2022-11-23 00:29:43,306 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.766280200671066, 'Total loss': 0.766280200671066} | train loss {'Reaction outcome loss': 0.819126189235718, 'Total loss': 0.819126189235718}
2022-11-23 00:29:43,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:43,307 INFO:     Epoch: 40
2022-11-23 00:29:44,154 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7708560546690767, 'Total loss': 0.7708560546690767} | train loss {'Reaction outcome loss': 0.818329046270059, 'Total loss': 0.818329046270059}
2022-11-23 00:29:44,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:44,154 INFO:     Epoch: 41
2022-11-23 00:29:44,987 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7868685126304626, 'Total loss': 0.7868685126304626} | train loss {'Reaction outcome loss': 0.8217275670218852, 'Total loss': 0.8217275670218852}
2022-11-23 00:29:44,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:44,987 INFO:     Epoch: 42
2022-11-23 00:29:45,794 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7848091511563822, 'Total loss': 0.7848091511563822} | train loss {'Reaction outcome loss': 0.8218897974058506, 'Total loss': 0.8218897974058506}
2022-11-23 00:29:45,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:45,795 INFO:     Epoch: 43
2022-11-23 00:29:46,607 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7863053090193055, 'Total loss': 0.7863053090193055} | train loss {'Reaction outcome loss': 0.816687781604067, 'Total loss': 0.816687781604067}
2022-11-23 00:29:46,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:46,607 INFO:     Epoch: 44
2022-11-23 00:29:47,430 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7645123052326116, 'Total loss': 0.7645123052326116} | train loss {'Reaction outcome loss': 0.8174488263264779, 'Total loss': 0.8174488263264779}
2022-11-23 00:29:47,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:47,431 INFO:     Epoch: 45
2022-11-23 00:29:48,264 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7729980275034904, 'Total loss': 0.7729980275034904} | train loss {'Reaction outcome loss': 0.8193915637750779, 'Total loss': 0.8193915637750779}
2022-11-23 00:29:48,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:48,264 INFO:     Epoch: 46
2022-11-23 00:29:49,071 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8009689189493656, 'Total loss': 0.8009689189493656} | train loss {'Reaction outcome loss': 0.8174944167896625, 'Total loss': 0.8174944167896625}
2022-11-23 00:29:49,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:49,071 INFO:     Epoch: 47
2022-11-23 00:29:49,864 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7686702155254104, 'Total loss': 0.7686702155254104} | train loss {'Reaction outcome loss': 0.8174111357619686, 'Total loss': 0.8174111357619686}
2022-11-23 00:29:49,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:49,865 INFO:     Epoch: 48
2022-11-23 00:29:50,709 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7621925337748094, 'Total loss': 0.7621925337748094} | train loss {'Reaction outcome loss': 0.8203197994059132, 'Total loss': 0.8203197994059132}
2022-11-23 00:29:50,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:50,709 INFO:     Epoch: 49
2022-11-23 00:29:51,532 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7784348543394696, 'Total loss': 0.7784348543394696} | train loss {'Reaction outcome loss': 0.8149356087369304, 'Total loss': 0.8149356087369304}
2022-11-23 00:29:51,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:51,532 INFO:     Epoch: 50
2022-11-23 00:29:52,322 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7681218338283625, 'Total loss': 0.7681218338283625} | train loss {'Reaction outcome loss': 0.815493902972629, 'Total loss': 0.815493902972629}
2022-11-23 00:29:52,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:52,322 INFO:     Epoch: 51
2022-11-23 00:29:53,162 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7544517036188733, 'Total loss': 0.7544517036188733} | train loss {'Reaction outcome loss': 0.8186755058986526, 'Total loss': 0.8186755058986526}
2022-11-23 00:29:53,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:53,163 INFO:     Epoch: 52
2022-11-23 00:29:53,999 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7630798667669296, 'Total loss': 0.7630798667669296} | train loss {'Reaction outcome loss': 0.8169966418175928, 'Total loss': 0.8169966418175928}
2022-11-23 00:29:53,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:53,999 INFO:     Epoch: 53
2022-11-23 00:29:54,808 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7898356565697626, 'Total loss': 0.7898356565697626} | train loss {'Reaction outcome loss': 0.8178661656716177, 'Total loss': 0.8178661656716177}
2022-11-23 00:29:54,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:54,808 INFO:     Epoch: 54
2022-11-23 00:29:55,662 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8064237453720786, 'Total loss': 0.8064237453720786} | train loss {'Reaction outcome loss': 0.8217353614107255, 'Total loss': 0.8217353614107255}
2022-11-23 00:29:55,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:55,663 INFO:     Epoch: 55
2022-11-23 00:29:56,477 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7924009561538696, 'Total loss': 0.7924009561538696} | train loss {'Reaction outcome loss': 0.8158425041023762, 'Total loss': 0.8158425041023762}
2022-11-23 00:29:56,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:56,477 INFO:     Epoch: 56
2022-11-23 00:29:57,271 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7572398233142766, 'Total loss': 0.7572398233142766} | train loss {'Reaction outcome loss': 0.8225442120625127, 'Total loss': 0.8225442120625127}
2022-11-23 00:29:57,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:57,271 INFO:     Epoch: 57
2022-11-23 00:29:58,091 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7645159275694327, 'Total loss': 0.7645159275694327} | train loss {'Reaction outcome loss': 0.8172569264687838, 'Total loss': 0.8172569264687838}
2022-11-23 00:29:58,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:58,091 INFO:     Epoch: 58
2022-11-23 00:29:58,937 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7640913826498118, 'Total loss': 0.7640913826498118} | train loss {'Reaction outcome loss': 0.8212065115090339, 'Total loss': 0.8212065115090339}
2022-11-23 00:29:58,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:58,937 INFO:     Epoch: 59
2022-11-23 00:29:59,756 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7591746537522837, 'Total loss': 0.7591746537522837} | train loss {'Reaction outcome loss': 0.8212412058586075, 'Total loss': 0.8212412058586075}
2022-11-23 00:29:59,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:29:59,756 INFO:     Epoch: 60
2022-11-23 00:30:00,563 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8027089929038828, 'Total loss': 0.8027089929038828} | train loss {'Reaction outcome loss': 0.8200664229450687, 'Total loss': 0.8200664229450687}
2022-11-23 00:30:00,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:00,564 INFO:     Epoch: 61
2022-11-23 00:30:01,398 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7634798430583694, 'Total loss': 0.7634798430583694} | train loss {'Reaction outcome loss': 0.8216252605761251, 'Total loss': 0.8216252605761251}
2022-11-23 00:30:01,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:01,399 INFO:     Epoch: 62
2022-11-23 00:30:02,204 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7563760138370774, 'Total loss': 0.7563760138370774} | train loss {'Reaction outcome loss': 0.8183215136729902, 'Total loss': 0.8183215136729902}
2022-11-23 00:30:02,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:02,205 INFO:     Epoch: 63
2022-11-23 00:30:03,037 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7903574339368127, 'Total loss': 0.7903574339368127} | train loss {'Reaction outcome loss': 0.8206233473554734, 'Total loss': 0.8206233473554734}
2022-11-23 00:30:03,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:03,038 INFO:     Epoch: 64
2022-11-23 00:30:03,893 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7615171379663728, 'Total loss': 0.7615171379663728} | train loss {'Reaction outcome loss': 0.8184646867936657, 'Total loss': 0.8184646867936657}
2022-11-23 00:30:03,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:03,893 INFO:     Epoch: 65
2022-11-23 00:30:04,681 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7639378065412695, 'Total loss': 0.7639378065412695} | train loss {'Reaction outcome loss': 0.8217628323022397, 'Total loss': 0.8217628323022397}
2022-11-23 00:30:04,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:04,681 INFO:     Epoch: 66
2022-11-23 00:30:05,491 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7634792720729654, 'Total loss': 0.7634792720729654} | train loss {'Reaction outcome loss': 0.8197734897896167, 'Total loss': 0.8197734897896167}
2022-11-23 00:30:05,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:05,491 INFO:     Epoch: 67
2022-11-23 00:30:06,290 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7445577335628596, 'Total loss': 0.7445577335628596} | train loss {'Reaction outcome loss': 0.816236129331012, 'Total loss': 0.816236129331012}
2022-11-23 00:30:06,290 INFO:     Found new best model at epoch 67
2022-11-23 00:30:06,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:06,291 INFO:     Epoch: 68
2022-11-23 00:30:07,099 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7512308142401956, 'Total loss': 0.7512308142401956} | train loss {'Reaction outcome loss': 0.8179537347487865, 'Total loss': 0.8179537347487865}
2022-11-23 00:30:07,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:07,100 INFO:     Epoch: 69
2022-11-23 00:30:07,873 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7662390849807046, 'Total loss': 0.7662390849807046} | train loss {'Reaction outcome loss': 0.8237334672481783, 'Total loss': 0.8237334672481783}
2022-11-23 00:30:07,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:07,873 INFO:     Epoch: 70
2022-11-23 00:30:08,647 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7472978383302689, 'Total loss': 0.7472978383302689} | train loss {'Reaction outcome loss': 0.8146999312504646, 'Total loss': 0.8146999312504646}
2022-11-23 00:30:08,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:08,647 INFO:     Epoch: 71
2022-11-23 00:30:09,470 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7776670665903525, 'Total loss': 0.7776670665903525} | train loss {'Reaction outcome loss': 0.8211191407134456, 'Total loss': 0.8211191407134456}
2022-11-23 00:30:09,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:09,470 INFO:     Epoch: 72
2022-11-23 00:30:10,287 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7827324813062494, 'Total loss': 0.7827324813062494} | train loss {'Reaction outcome loss': 0.8201595932966278, 'Total loss': 0.8201595932966278}
2022-11-23 00:30:10,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:10,287 INFO:     Epoch: 73
2022-11-23 00:30:11,119 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7866662862625989, 'Total loss': 0.7866662862625989} | train loss {'Reaction outcome loss': 0.8235747668771974, 'Total loss': 0.8235747668771974}
2022-11-23 00:30:11,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:11,119 INFO:     Epoch: 74
2022-11-23 00:30:11,969 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7759560272097588, 'Total loss': 0.7759560272097588} | train loss {'Reaction outcome loss': 0.819106504441269, 'Total loss': 0.819106504441269}
2022-11-23 00:30:11,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:11,970 INFO:     Epoch: 75
2022-11-23 00:30:12,748 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7775093513456258, 'Total loss': 0.7775093513456258} | train loss {'Reaction outcome loss': 0.8136899186478507, 'Total loss': 0.8136899186478507}
2022-11-23 00:30:12,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:12,748 INFO:     Epoch: 76
2022-11-23 00:30:13,532 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7675858397375454, 'Total loss': 0.7675858397375454} | train loss {'Reaction outcome loss': 0.8167931361784858, 'Total loss': 0.8167931361784858}
2022-11-23 00:30:13,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:13,533 INFO:     Epoch: 77
2022-11-23 00:30:14,315 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7605690576813438, 'Total loss': 0.7605690576813438} | train loss {'Reaction outcome loss': 0.8194723428497391, 'Total loss': 0.8194723428497391}
2022-11-23 00:30:14,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:14,316 INFO:     Epoch: 78
2022-11-23 00:30:15,166 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7850774072787978, 'Total loss': 0.7850774072787978} | train loss {'Reaction outcome loss': 0.8155401159198054, 'Total loss': 0.8155401159198054}
2022-11-23 00:30:15,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:15,166 INFO:     Epoch: 79
2022-11-23 00:30:15,994 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7568439048799601, 'Total loss': 0.7568439048799601} | train loss {'Reaction outcome loss': 0.8169263868081954, 'Total loss': 0.8169263868081954}
2022-11-23 00:30:15,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:15,995 INFO:     Epoch: 80
2022-11-23 00:30:16,818 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7672660858793692, 'Total loss': 0.7672660858793692} | train loss {'Reaction outcome loss': 0.8206626265760391, 'Total loss': 0.8206626265760391}
2022-11-23 00:30:16,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:16,818 INFO:     Epoch: 81
2022-11-23 00:30:17,665 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7660165110772307, 'Total loss': 0.7660165110772307} | train loss {'Reaction outcome loss': 0.822471831955256, 'Total loss': 0.822471831955256}
2022-11-23 00:30:17,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:17,665 INFO:     Epoch: 82
2022-11-23 00:30:18,483 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7664845924485814, 'Total loss': 0.7664845924485814} | train loss {'Reaction outcome loss': 0.8145597442503898, 'Total loss': 0.8145597442503898}
2022-11-23 00:30:18,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:18,483 INFO:     Epoch: 83
2022-11-23 00:30:19,314 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7582379687916149, 'Total loss': 0.7582379687916149} | train loss {'Reaction outcome loss': 0.8217012753650066, 'Total loss': 0.8217012753650066}
2022-11-23 00:30:19,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:19,315 INFO:     Epoch: 84
2022-11-23 00:30:20,155 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7684686021371321, 'Total loss': 0.7684686021371321} | train loss {'Reaction outcome loss': 0.8191135687933814, 'Total loss': 0.8191135687933814}
2022-11-23 00:30:20,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:20,155 INFO:     Epoch: 85
2022-11-23 00:30:21,003 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7620144723491236, 'Total loss': 0.7620144723491236} | train loss {'Reaction outcome loss': 0.8135424979752109, 'Total loss': 0.8135424979752109}
2022-11-23 00:30:21,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:21,004 INFO:     Epoch: 86
2022-11-23 00:30:21,790 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.761460346931761, 'Total loss': 0.761460346931761} | train loss {'Reaction outcome loss': 0.8198332993253585, 'Total loss': 0.8198332993253585}
2022-11-23 00:30:21,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:21,790 INFO:     Epoch: 87
2022-11-23 00:30:22,609 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7566940107128837, 'Total loss': 0.7566940107128837} | train loss {'Reaction outcome loss': 0.8161635213801938, 'Total loss': 0.8161635213801938}
2022-11-23 00:30:22,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:22,609 INFO:     Epoch: 88
2022-11-23 00:30:23,431 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8086515881798484, 'Total loss': 0.8086515881798484} | train loss {'Reaction outcome loss': 0.8193856696448019, 'Total loss': 0.8193856696448019}
2022-11-23 00:30:23,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:23,431 INFO:     Epoch: 89
2022-11-23 00:30:24,230 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7539182169870897, 'Total loss': 0.7539182169870897} | train loss {'Reaction outcome loss': 0.8124180501026492, 'Total loss': 0.8124180501026492}
2022-11-23 00:30:24,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:24,230 INFO:     Epoch: 90
2022-11-23 00:30:25,063 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7587082128633152, 'Total loss': 0.7587082128633152} | train loss {'Reaction outcome loss': 0.8164335181636195, 'Total loss': 0.8164335181636195}
2022-11-23 00:30:25,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:25,063 INFO:     Epoch: 91
2022-11-23 00:30:25,877 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7892094938592478, 'Total loss': 0.7892094938592478} | train loss {'Reaction outcome loss': 0.8152024202769802, 'Total loss': 0.8152024202769802}
2022-11-23 00:30:25,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:25,878 INFO:     Epoch: 92
2022-11-23 00:30:26,683 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7583195384253155, 'Total loss': 0.7583195384253155} | train loss {'Reaction outcome loss': 0.817843534052372, 'Total loss': 0.817843534052372}
2022-11-23 00:30:26,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:26,684 INFO:     Epoch: 93
2022-11-23 00:30:27,554 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.771777482195334, 'Total loss': 0.771777482195334} | train loss {'Reaction outcome loss': 0.8197080268254203, 'Total loss': 0.8197080268254203}
2022-11-23 00:30:27,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:27,554 INFO:     Epoch: 94
2022-11-23 00:30:28,336 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7848300371657718, 'Total loss': 0.7848300371657718} | train loss {'Reaction outcome loss': 0.8205195817976229, 'Total loss': 0.8205195817976229}
2022-11-23 00:30:28,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:28,336 INFO:     Epoch: 95
2022-11-23 00:30:29,173 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7789496434005824, 'Total loss': 0.7789496434005824} | train loss {'Reaction outcome loss': 0.8198297875783136, 'Total loss': 0.8198297875783136}
2022-11-23 00:30:29,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:29,174 INFO:     Epoch: 96
2022-11-23 00:30:29,991 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7716008566997268, 'Total loss': 0.7716008566997268} | train loss {'Reaction outcome loss': 0.8190167092027203, 'Total loss': 0.8190167092027203}
2022-11-23 00:30:29,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:29,991 INFO:     Epoch: 97
2022-11-23 00:30:30,809 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7538729289715941, 'Total loss': 0.7538729289715941} | train loss {'Reaction outcome loss': 0.8146844223862694, 'Total loss': 0.8146844223862694}
2022-11-23 00:30:30,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:30,809 INFO:     Epoch: 98
2022-11-23 00:30:31,615 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7796916832978075, 'Total loss': 0.7796916832978075} | train loss {'Reaction outcome loss': 0.823079154616402, 'Total loss': 0.823079154616402}
2022-11-23 00:30:31,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:31,615 INFO:     Epoch: 99
2022-11-23 00:30:32,424 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7786589339375496, 'Total loss': 0.7786589339375496} | train loss {'Reaction outcome loss': 0.8167167399679461, 'Total loss': 0.8167167399679461}
2022-11-23 00:30:32,424 INFO:     Best model found after epoch 68 of 100.
2022-11-23 00:30:32,424 INFO:   Done with stage: TRAINING
2022-11-23 00:30:32,425 INFO:   Starting stage: EVALUATION
2022-11-23 00:30:32,544 INFO:   Done with stage: EVALUATION
2022-11-23 00:30:32,544 INFO:   Leaving out SEQ value Fold_8
2022-11-23 00:30:32,558 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:30:32,558 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:30:33,235 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:30:33,236 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:30:33,305 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:30:33,305 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:30:33,305 INFO:     No hyperparam tuning for this model
2022-11-23 00:30:33,305 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:30:33,305 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:30:33,306 INFO:     None feature selector for col prot
2022-11-23 00:30:33,306 INFO:     None feature selector for col prot
2022-11-23 00:30:33,306 INFO:     None feature selector for col prot
2022-11-23 00:30:33,307 INFO:     None feature selector for col chem
2022-11-23 00:30:33,307 INFO:     None feature selector for col chem
2022-11-23 00:30:33,307 INFO:     None feature selector for col chem
2022-11-23 00:30:33,307 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:30:33,307 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:30:33,309 INFO:     Number of params in model 168571
2022-11-23 00:30:33,312 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:30:33,312 INFO:   Starting stage: TRAINING
2022-11-23 00:30:33,370 INFO:     Val loss before train {'Reaction outcome loss': 1.0335851555520839, 'Total loss': 1.0335851555520839}
2022-11-23 00:30:33,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:33,370 INFO:     Epoch: 0
2022-11-23 00:30:34,192 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9005089117722078, 'Total loss': 0.9005089117722078} | train loss {'Reaction outcome loss': 0.8847266501717029, 'Total loss': 0.8847266501717029}
2022-11-23 00:30:34,192 INFO:     Found new best model at epoch 0
2022-11-23 00:30:34,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:34,193 INFO:     Epoch: 1
2022-11-23 00:30:35,018 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.877389749342745, 'Total loss': 0.877389749342745} | train loss {'Reaction outcome loss': 0.8542433566143436, 'Total loss': 0.8542433566143436}
2022-11-23 00:30:35,018 INFO:     Found new best model at epoch 1
2022-11-23 00:30:35,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:35,019 INFO:     Epoch: 2
2022-11-23 00:30:35,824 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8716465099291368, 'Total loss': 0.8716465099291368} | train loss {'Reaction outcome loss': 0.8513762235881821, 'Total loss': 0.8513762235881821}
2022-11-23 00:30:35,824 INFO:     Found new best model at epoch 2
2022-11-23 00:30:35,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:35,825 INFO:     Epoch: 3
2022-11-23 00:30:36,622 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8503798598592932, 'Total loss': 0.8503798598592932} | train loss {'Reaction outcome loss': 0.8430979941641131, 'Total loss': 0.8430979941641131}
2022-11-23 00:30:36,623 INFO:     Found new best model at epoch 3
2022-11-23 00:30:36,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:36,623 INFO:     Epoch: 4
2022-11-23 00:30:37,436 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8510703051632101, 'Total loss': 0.8510703051632101} | train loss {'Reaction outcome loss': 0.8358012270783225, 'Total loss': 0.8358012270783225}
2022-11-23 00:30:37,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:37,436 INFO:     Epoch: 5
2022-11-23 00:30:38,248 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.9070808961987495, 'Total loss': 0.9070808961987495} | train loss {'Reaction outcome loss': 0.8328284394116171, 'Total loss': 0.8328284394116171}
2022-11-23 00:30:38,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:38,248 INFO:     Epoch: 6
2022-11-23 00:30:39,052 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8736219758337195, 'Total loss': 0.8736219758337195} | train loss {'Reaction outcome loss': 0.8319407824066377, 'Total loss': 0.8319407824066377}
2022-11-23 00:30:39,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:39,053 INFO:     Epoch: 7
2022-11-23 00:30:39,866 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8793093169277365, 'Total loss': 0.8793093169277365} | train loss {'Reaction outcome loss': 0.8295990092860114, 'Total loss': 0.8295990092860114}
2022-11-23 00:30:39,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:39,866 INFO:     Epoch: 8
2022-11-23 00:30:40,664 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8662984466010873, 'Total loss': 0.8662984466010873} | train loss {'Reaction outcome loss': 0.8269988908883064, 'Total loss': 0.8269988908883064}
2022-11-23 00:30:40,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:40,664 INFO:     Epoch: 9
2022-11-23 00:30:41,441 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8544490574435755, 'Total loss': 0.8544490574435755} | train loss {'Reaction outcome loss': 0.828461992524324, 'Total loss': 0.828461992524324}
2022-11-23 00:30:41,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:41,441 INFO:     Epoch: 10
2022-11-23 00:30:42,271 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.86101995408535, 'Total loss': 0.86101995408535} | train loss {'Reaction outcome loss': 0.8319718010963932, 'Total loss': 0.8319718010963932}
2022-11-23 00:30:42,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:42,271 INFO:     Epoch: 11
2022-11-23 00:30:43,098 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.880069071596319, 'Total loss': 0.880069071596319} | train loss {'Reaction outcome loss': 0.8267064014029119, 'Total loss': 0.8267064014029119}
2022-11-23 00:30:43,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:43,098 INFO:     Epoch: 12
2022-11-23 00:30:43,947 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8806733583862131, 'Total loss': 0.8806733583862131} | train loss {'Reaction outcome loss': 0.8299934063707629, 'Total loss': 0.8299934063707629}
2022-11-23 00:30:43,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:43,947 INFO:     Epoch: 13
2022-11-23 00:30:44,753 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8741479949517683, 'Total loss': 0.8741479949517683} | train loss {'Reaction outcome loss': 0.8297445921888275, 'Total loss': 0.8297445921888275}
2022-11-23 00:30:44,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:44,753 INFO:     Epoch: 14
2022-11-23 00:30:45,588 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8734306286681782, 'Total loss': 0.8734306286681782} | train loss {'Reaction outcome loss': 0.8206492770583399, 'Total loss': 0.8206492770583399}
2022-11-23 00:30:45,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:45,589 INFO:     Epoch: 15
2022-11-23 00:30:46,436 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8893841924992475, 'Total loss': 0.8893841924992475} | train loss {'Reaction outcome loss': 0.8273215683237198, 'Total loss': 0.8273215683237198}
2022-11-23 00:30:46,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:46,436 INFO:     Epoch: 16
2022-11-23 00:30:47,239 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8514949720014225, 'Total loss': 0.8514949720014225} | train loss {'Reaction outcome loss': 0.8260609883694879, 'Total loss': 0.8260609883694879}
2022-11-23 00:30:47,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:47,240 INFO:     Epoch: 17
2022-11-23 00:30:48,076 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8543162786147811, 'Total loss': 0.8543162786147811} | train loss {'Reaction outcome loss': 0.8277715744991456, 'Total loss': 0.8277715744991456}
2022-11-23 00:30:48,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:48,077 INFO:     Epoch: 18
2022-11-23 00:30:48,913 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.860577290031043, 'Total loss': 0.860577290031043} | train loss {'Reaction outcome loss': 0.831696363586572, 'Total loss': 0.831696363586572}
2022-11-23 00:30:48,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:48,914 INFO:     Epoch: 19
2022-11-23 00:30:49,724 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8758418939330361, 'Total loss': 0.8758418939330361} | train loss {'Reaction outcome loss': 0.8250381497125472, 'Total loss': 0.8250381497125472}
2022-11-23 00:30:49,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:49,725 INFO:     Epoch: 20
2022-11-23 00:30:50,542 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8584477915005251, 'Total loss': 0.8584477915005251} | train loss {'Reaction outcome loss': 0.8301353102489826, 'Total loss': 0.8301353102489826}
2022-11-23 00:30:50,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:50,542 INFO:     Epoch: 21
2022-11-23 00:30:51,344 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8835322646932169, 'Total loss': 0.8835322646932169} | train loss {'Reaction outcome loss': 0.8263062713367324, 'Total loss': 0.8263062713367324}
2022-11-23 00:30:51,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:51,344 INFO:     Epoch: 22
2022-11-23 00:30:52,158 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8624605685472488, 'Total loss': 0.8624605685472488} | train loss {'Reaction outcome loss': 0.828330212062405, 'Total loss': 0.828330212062405}
2022-11-23 00:30:52,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:52,159 INFO:     Epoch: 23
2022-11-23 00:30:52,958 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8545975434509191, 'Total loss': 0.8545975434509191} | train loss {'Reaction outcome loss': 0.829555578770176, 'Total loss': 0.829555578770176}
2022-11-23 00:30:52,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:52,958 INFO:     Epoch: 24
2022-11-23 00:30:53,752 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8708053759553216, 'Total loss': 0.8708053759553216} | train loss {'Reaction outcome loss': 0.8242127405058953, 'Total loss': 0.8242127405058953}
2022-11-23 00:30:53,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:53,753 INFO:     Epoch: 25
2022-11-23 00:30:54,602 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.874300863255154, 'Total loss': 0.874300863255154} | train loss {'Reaction outcome loss': 0.8254743809661558, 'Total loss': 0.8254743809661558}
2022-11-23 00:30:54,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:54,602 INFO:     Epoch: 26
2022-11-23 00:30:55,431 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.847920760512352, 'Total loss': 0.847920760512352} | train loss {'Reaction outcome loss': 0.8284577328351236, 'Total loss': 0.8284577328351236}
2022-11-23 00:30:55,431 INFO:     Found new best model at epoch 26
2022-11-23 00:30:55,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:55,432 INFO:     Epoch: 27
2022-11-23 00:30:56,251 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8571918870915066, 'Total loss': 0.8571918870915066} | train loss {'Reaction outcome loss': 0.8291398894882971, 'Total loss': 0.8291398894882971}
2022-11-23 00:30:56,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:56,251 INFO:     Epoch: 28
2022-11-23 00:30:57,062 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8589332144368779, 'Total loss': 0.8589332144368779} | train loss {'Reaction outcome loss': 0.8246852304906614, 'Total loss': 0.8246852304906614}
2022-11-23 00:30:57,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:57,062 INFO:     Epoch: 29
2022-11-23 00:30:57,918 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8632034537467089, 'Total loss': 0.8632034537467089} | train loss {'Reaction outcome loss': 0.8309083994357817, 'Total loss': 0.8309083994357817}
2022-11-23 00:30:57,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:57,918 INFO:     Epoch: 30
2022-11-23 00:30:58,745 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8725405884059992, 'Total loss': 0.8725405884059992} | train loss {'Reaction outcome loss': 0.8228447315914016, 'Total loss': 0.8228447315914016}
2022-11-23 00:30:58,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:58,745 INFO:     Epoch: 31
2022-11-23 00:30:59,569 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8908084522594105, 'Total loss': 0.8908084522594105} | train loss {'Reaction outcome loss': 0.8268355476039071, 'Total loss': 0.8268355476039071}
2022-11-23 00:30:59,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:30:59,569 INFO:     Epoch: 32
2022-11-23 00:31:00,399 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8492080501534722, 'Total loss': 0.8492080501534722} | train loss {'Reaction outcome loss': 0.825946953748503, 'Total loss': 0.825946953748503}
2022-11-23 00:31:00,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:00,400 INFO:     Epoch: 33
2022-11-23 00:31:01,180 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8619232245466926, 'Total loss': 0.8619232245466926} | train loss {'Reaction outcome loss': 0.8241651388666322, 'Total loss': 0.8241651388666322}
2022-11-23 00:31:01,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:01,180 INFO:     Epoch: 34
2022-11-23 00:31:02,023 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8481834266673435, 'Total loss': 0.8481834266673435} | train loss {'Reaction outcome loss': 0.8253010379210595, 'Total loss': 0.8253010379210595}
2022-11-23 00:31:02,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:02,023 INFO:     Epoch: 35
2022-11-23 00:31:02,851 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8677765523845499, 'Total loss': 0.8677765523845499} | train loss {'Reaction outcome loss': 0.8249369018500851, 'Total loss': 0.8249369018500851}
2022-11-23 00:31:02,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:02,851 INFO:     Epoch: 36
2022-11-23 00:31:03,681 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.867191885005344, 'Total loss': 0.867191885005344} | train loss {'Reaction outcome loss': 0.825334669481362, 'Total loss': 0.825334669481362}
2022-11-23 00:31:03,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:03,681 INFO:     Epoch: 37
2022-11-23 00:31:04,512 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8495471287857402, 'Total loss': 0.8495471287857402} | train loss {'Reaction outcome loss': 0.8219519283983016, 'Total loss': 0.8219519283983016}
2022-11-23 00:31:04,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:04,513 INFO:     Epoch: 38
2022-11-23 00:31:05,361 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8705916675654325, 'Total loss': 0.8705916675654325} | train loss {'Reaction outcome loss': 0.8216689016309476, 'Total loss': 0.8216689016309476}
2022-11-23 00:31:05,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:05,361 INFO:     Epoch: 39
2022-11-23 00:31:06,264 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8553103574297645, 'Total loss': 0.8553103574297645} | train loss {'Reaction outcome loss': 0.8283423430496647, 'Total loss': 0.8283423430496647}
2022-11-23 00:31:06,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:06,264 INFO:     Epoch: 40
2022-11-23 00:31:07,124 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8718426051464948, 'Total loss': 0.8718426051464948} | train loss {'Reaction outcome loss': 0.8199276020449977, 'Total loss': 0.8199276020449977}
2022-11-23 00:31:07,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:07,125 INFO:     Epoch: 41
2022-11-23 00:31:07,937 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8595856468785893, 'Total loss': 0.8595856468785893} | train loss {'Reaction outcome loss': 0.8246470158619266, 'Total loss': 0.8246470158619266}
2022-11-23 00:31:07,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:07,937 INFO:     Epoch: 42
2022-11-23 00:31:08,731 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8835975378751755, 'Total loss': 0.8835975378751755} | train loss {'Reaction outcome loss': 0.8220193116895614, 'Total loss': 0.8220193116895614}
2022-11-23 00:31:08,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:08,731 INFO:     Epoch: 43
2022-11-23 00:31:09,583 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8604074222120371, 'Total loss': 0.8604074222120371} | train loss {'Reaction outcome loss': 0.8241225895622084, 'Total loss': 0.8241225895622084}
2022-11-23 00:31:09,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:09,583 INFO:     Epoch: 44
2022-11-23 00:31:10,407 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8513008105483922, 'Total loss': 0.8513008105483922} | train loss {'Reaction outcome loss': 0.8255395557611219, 'Total loss': 0.8255395557611219}
2022-11-23 00:31:10,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:10,407 INFO:     Epoch: 45
2022-11-23 00:31:11,230 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8551831170916557, 'Total loss': 0.8551831170916557} | train loss {'Reaction outcome loss': 0.8230280805258982, 'Total loss': 0.8230280805258982}
2022-11-23 00:31:11,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:11,230 INFO:     Epoch: 46
2022-11-23 00:31:12,061 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8467562144452875, 'Total loss': 0.8467562144452875} | train loss {'Reaction outcome loss': 0.8248660002023943, 'Total loss': 0.8248660002023943}
2022-11-23 00:31:12,061 INFO:     Found new best model at epoch 46
2022-11-23 00:31:12,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:12,062 INFO:     Epoch: 47
2022-11-23 00:31:12,890 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8485994704745032, 'Total loss': 0.8485994704745032} | train loss {'Reaction outcome loss': 0.8244150417947, 'Total loss': 0.8244150417947}
2022-11-23 00:31:12,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:12,890 INFO:     Epoch: 48
2022-11-23 00:31:13,718 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8598899881948124, 'Total loss': 0.8598899881948124} | train loss {'Reaction outcome loss': 0.8290655090804061, 'Total loss': 0.8290655090804061}
2022-11-23 00:31:13,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:13,718 INFO:     Epoch: 49
2022-11-23 00:31:14,520 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8819415840235624, 'Total loss': 0.8819415840235624} | train loss {'Reaction outcome loss': 0.8211478634226707, 'Total loss': 0.8211478634226707}
2022-11-23 00:31:14,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:14,520 INFO:     Epoch: 50
2022-11-23 00:31:15,323 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8676736449653452, 'Total loss': 0.8676736449653452} | train loss {'Reaction outcome loss': 0.8207029729120193, 'Total loss': 0.8207029729120193}
2022-11-23 00:31:15,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:15,323 INFO:     Epoch: 51
2022-11-23 00:31:16,103 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8586720038544048, 'Total loss': 0.8586720038544048} | train loss {'Reaction outcome loss': 0.8214243279109078, 'Total loss': 0.8214243279109078}
2022-11-23 00:31:16,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:16,104 INFO:     Epoch: 52
2022-11-23 00:31:16,955 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8603121794082902, 'Total loss': 0.8603121794082902} | train loss {'Reaction outcome loss': 0.8288693462889041, 'Total loss': 0.8288693462889041}
2022-11-23 00:31:16,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:16,956 INFO:     Epoch: 53
2022-11-23 00:31:17,758 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8510545336387374, 'Total loss': 0.8510545336387374} | train loss {'Reaction outcome loss': 0.8235400953600484, 'Total loss': 0.8235400953600484}
2022-11-23 00:31:17,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:17,758 INFO:     Epoch: 54
2022-11-23 00:31:18,557 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8520185026255521, 'Total loss': 0.8520185026255521} | train loss {'Reaction outcome loss': 0.8193408874494414, 'Total loss': 0.8193408874494414}
2022-11-23 00:31:18,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:18,557 INFO:     Epoch: 55
2022-11-23 00:31:19,377 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8520581126213074, 'Total loss': 0.8520581126213074} | train loss {'Reaction outcome loss': 0.8191034740978672, 'Total loss': 0.8191034740978672}
2022-11-23 00:31:19,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:19,377 INFO:     Epoch: 56
2022-11-23 00:31:20,219 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8642979839986021, 'Total loss': 0.8642979839986021} | train loss {'Reaction outcome loss': 0.8241313103466265, 'Total loss': 0.8241313103466265}
2022-11-23 00:31:20,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:20,219 INFO:     Epoch: 57
2022-11-23 00:31:21,025 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8563108850609172, 'Total loss': 0.8563108850609172} | train loss {'Reaction outcome loss': 0.82148279045378, 'Total loss': 0.82148279045378}
2022-11-23 00:31:21,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:21,026 INFO:     Epoch: 58
2022-11-23 00:31:21,839 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8637181676246903, 'Total loss': 0.8637181676246903} | train loss {'Reaction outcome loss': 0.8220688579303603, 'Total loss': 0.8220688579303603}
2022-11-23 00:31:21,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:21,839 INFO:     Epoch: 59
2022-11-23 00:31:22,668 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8609955900094726, 'Total loss': 0.8609955900094726} | train loss {'Reaction outcome loss': 0.8221789721039033, 'Total loss': 0.8221789721039033}
2022-11-23 00:31:22,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:22,669 INFO:     Epoch: 60
2022-11-23 00:31:23,485 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8441596600142393, 'Total loss': 0.8441596600142393} | train loss {'Reaction outcome loss': 0.8252283022288354, 'Total loss': 0.8252283022288354}
2022-11-23 00:31:23,485 INFO:     Found new best model at epoch 60
2022-11-23 00:31:23,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:23,486 INFO:     Epoch: 61
2022-11-23 00:31:24,261 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8589791337197478, 'Total loss': 0.8589791337197478} | train loss {'Reaction outcome loss': 0.8217513757126946, 'Total loss': 0.8217513757126946}
2022-11-23 00:31:24,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:24,261 INFO:     Epoch: 62
2022-11-23 00:31:25,073 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8630724474787712, 'Total loss': 0.8630724474787712} | train loss {'Reaction outcome loss': 0.8220666404212674, 'Total loss': 0.8220666404212674}
2022-11-23 00:31:25,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:25,073 INFO:     Epoch: 63
2022-11-23 00:31:25,881 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8532689295031808, 'Total loss': 0.8532689295031808} | train loss {'Reaction outcome loss': 0.8216450120652875, 'Total loss': 0.8216450120652875}
2022-11-23 00:31:25,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:25,881 INFO:     Epoch: 64
2022-11-23 00:31:26,699 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8402580740776929, 'Total loss': 0.8402580740776929} | train loss {'Reaction outcome loss': 0.8199382043413578, 'Total loss': 0.8199382043413578}
2022-11-23 00:31:26,699 INFO:     Found new best model at epoch 64
2022-11-23 00:31:26,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:26,700 INFO:     Epoch: 65
2022-11-23 00:31:27,529 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8578965867107565, 'Total loss': 0.8578965867107565} | train loss {'Reaction outcome loss': 0.8237827517572911, 'Total loss': 0.8237827517572911}
2022-11-23 00:31:27,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:27,529 INFO:     Epoch: 66
2022-11-23 00:31:28,318 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8737942576408386, 'Total loss': 0.8737942576408386} | train loss {'Reaction outcome loss': 0.8249677501378521, 'Total loss': 0.8249677501378521}
2022-11-23 00:31:28,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:28,318 INFO:     Epoch: 67
2022-11-23 00:31:29,129 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8571989543058656, 'Total loss': 0.8571989543058656} | train loss {'Reaction outcome loss': 0.8233407728614346, 'Total loss': 0.8233407728614346}
2022-11-23 00:31:29,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:29,129 INFO:     Epoch: 68
2022-11-23 00:31:29,983 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8400061780756171, 'Total loss': 0.8400061780756171} | train loss {'Reaction outcome loss': 0.8264743706151363, 'Total loss': 0.8264743706151363}
2022-11-23 00:31:29,983 INFO:     Found new best model at epoch 68
2022-11-23 00:31:29,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:29,984 INFO:     Epoch: 69
2022-11-23 00:31:30,826 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8552453213117339, 'Total loss': 0.8552453213117339} | train loss {'Reaction outcome loss': 0.8254668899481336, 'Total loss': 0.8254668899481336}
2022-11-23 00:31:30,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:30,827 INFO:     Epoch: 70
2022-11-23 00:31:31,641 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8468368622389707, 'Total loss': 0.8468368622389707} | train loss {'Reaction outcome loss': 0.823109099941869, 'Total loss': 0.823109099941869}
2022-11-23 00:31:31,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:31,642 INFO:     Epoch: 71
2022-11-23 00:31:32,442 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8578977435827255, 'Total loss': 0.8578977435827255} | train loss {'Reaction outcome loss': 0.8209709990168771, 'Total loss': 0.8209709990168771}
2022-11-23 00:31:32,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:32,442 INFO:     Epoch: 72
2022-11-23 00:31:33,234 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8542996821078387, 'Total loss': 0.8542996821078387} | train loss {'Reaction outcome loss': 0.821117437294414, 'Total loss': 0.821117437294414}
2022-11-23 00:31:33,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:33,235 INFO:     Epoch: 73
2022-11-23 00:31:34,083 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8579255396669562, 'Total loss': 0.8579255396669562} | train loss {'Reaction outcome loss': 0.8152105986110626, 'Total loss': 0.8152105986110626}
2022-11-23 00:31:34,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:34,084 INFO:     Epoch: 74
2022-11-23 00:31:34,922 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8696708692745729, 'Total loss': 0.8696708692745729} | train loss {'Reaction outcome loss': 0.8201875687847214, 'Total loss': 0.8201875687847214}
2022-11-23 00:31:34,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:34,923 INFO:     Epoch: 75
2022-11-23 00:31:35,772 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8648811836134304, 'Total loss': 0.8648811836134304} | train loss {'Reaction outcome loss': 0.8179686654719615, 'Total loss': 0.8179686654719615}
2022-11-23 00:31:35,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:35,773 INFO:     Epoch: 76
2022-11-23 00:31:36,603 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8615175235000524, 'Total loss': 0.8615175235000524} | train loss {'Reaction outcome loss': 0.8239531521835635, 'Total loss': 0.8239531521835635}
2022-11-23 00:31:36,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:36,603 INFO:     Epoch: 77
2022-11-23 00:31:37,434 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8571408269080248, 'Total loss': 0.8571408269080248} | train loss {'Reaction outcome loss': 0.8229095893761804, 'Total loss': 0.8229095893761804}
2022-11-23 00:31:37,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:37,434 INFO:     Epoch: 78
2022-11-23 00:31:38,216 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8551515300165523, 'Total loss': 0.8551515300165523} | train loss {'Reaction outcome loss': 0.8245097652318016, 'Total loss': 0.8245097652318016}
2022-11-23 00:31:38,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:38,217 INFO:     Epoch: 79
2022-11-23 00:31:39,017 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8762086873704736, 'Total loss': 0.8762086873704736} | train loss {'Reaction outcome loss': 0.8162597392595583, 'Total loss': 0.8162597392595583}
2022-11-23 00:31:39,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:39,017 INFO:     Epoch: 80
2022-11-23 00:31:39,834 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8573744764382188, 'Total loss': 0.8573744764382188} | train loss {'Reaction outcome loss': 0.8258024234204523, 'Total loss': 0.8258024234204523}
2022-11-23 00:31:39,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:39,835 INFO:     Epoch: 81
2022-11-23 00:31:40,649 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8678494488651102, 'Total loss': 0.8678494488651102} | train loss {'Reaction outcome loss': 0.8186098695282014, 'Total loss': 0.8186098695282014}
2022-11-23 00:31:40,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:40,649 INFO:     Epoch: 82
2022-11-23 00:31:41,473 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8411850563504479, 'Total loss': 0.8411850563504479} | train loss {'Reaction outcome loss': 0.8211873734910642, 'Total loss': 0.8211873734910642}
2022-11-23 00:31:41,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:41,474 INFO:     Epoch: 83
2022-11-23 00:31:42,267 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8464696529236707, 'Total loss': 0.8464696529236707} | train loss {'Reaction outcome loss': 0.8219504178531708, 'Total loss': 0.8219504178531708}
2022-11-23 00:31:42,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:42,268 INFO:     Epoch: 84
2022-11-23 00:31:43,113 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.850852913477204, 'Total loss': 0.850852913477204} | train loss {'Reaction outcome loss': 0.8213389531498955, 'Total loss': 0.8213389531498955}
2022-11-23 00:31:43,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:43,113 INFO:     Epoch: 85
2022-11-23 00:31:43,903 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.872240116650408, 'Total loss': 0.872240116650408} | train loss {'Reaction outcome loss': 0.8195082103052447, 'Total loss': 0.8195082103052447}
2022-11-23 00:31:43,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:43,903 INFO:     Epoch: 86
2022-11-23 00:31:44,759 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8807783424854279, 'Total loss': 0.8807783424854279} | train loss {'Reaction outcome loss': 0.8223596713956325, 'Total loss': 0.8223596713956325}
2022-11-23 00:31:44,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:44,759 INFO:     Epoch: 87
2022-11-23 00:31:45,566 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8536372211846438, 'Total loss': 0.8536372211846438} | train loss {'Reaction outcome loss': 0.8215978083110624, 'Total loss': 0.8215978083110624}
2022-11-23 00:31:45,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:45,566 INFO:     Epoch: 88
2022-11-23 00:31:46,351 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8685938106341795, 'Total loss': 0.8685938106341795} | train loss {'Reaction outcome loss': 0.8217397981113003, 'Total loss': 0.8217397981113003}
2022-11-23 00:31:46,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:46,351 INFO:     Epoch: 89
2022-11-23 00:31:47,161 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8463187908584421, 'Total loss': 0.8463187908584421} | train loss {'Reaction outcome loss': 0.82555265364147, 'Total loss': 0.82555265364147}
2022-11-23 00:31:47,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:47,162 INFO:     Epoch: 90
2022-11-23 00:31:47,976 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8629118725657463, 'Total loss': 0.8629118725657463} | train loss {'Reaction outcome loss': 0.8184304883883845, 'Total loss': 0.8184304883883845}
2022-11-23 00:31:47,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:47,976 INFO:     Epoch: 91
2022-11-23 00:31:48,740 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8595035049048337, 'Total loss': 0.8595035049048337} | train loss {'Reaction outcome loss': 0.8208734175610927, 'Total loss': 0.8208734175610927}
2022-11-23 00:31:48,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:48,740 INFO:     Epoch: 92
2022-11-23 00:31:49,523 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8588812324133787, 'Total loss': 0.8588812324133787} | train loss {'Reaction outcome loss': 0.8236839694361533, 'Total loss': 0.8236839694361533}
2022-11-23 00:31:49,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:49,523 INFO:     Epoch: 93
2022-11-23 00:31:50,354 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8540622280402617, 'Total loss': 0.8540622280402617} | train loss {'Reaction outcome loss': 0.8174411283145028, 'Total loss': 0.8174411283145028}
2022-11-23 00:31:50,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:50,355 INFO:     Epoch: 94
2022-11-23 00:31:51,168 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8671408810398795, 'Total loss': 0.8671408810398795} | train loss {'Reaction outcome loss': 0.8204207664295551, 'Total loss': 0.8204207664295551}
2022-11-23 00:31:51,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:51,168 INFO:     Epoch: 95
2022-11-23 00:31:51,972 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8589699071916667, 'Total loss': 0.8589699071916667} | train loss {'Reaction outcome loss': 0.8219501102162946, 'Total loss': 0.8219501102162946}
2022-11-23 00:31:51,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:51,973 INFO:     Epoch: 96
2022-11-23 00:31:52,813 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8460208516229283, 'Total loss': 0.8460208516229283} | train loss {'Reaction outcome loss': 0.825132631486462, 'Total loss': 0.825132631486462}
2022-11-23 00:31:52,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:52,813 INFO:     Epoch: 97
2022-11-23 00:31:53,661 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8521220074458555, 'Total loss': 0.8521220074458555} | train loss {'Reaction outcome loss': 0.8180905804038048, 'Total loss': 0.8180905804038048}
2022-11-23 00:31:53,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:53,662 INFO:     Epoch: 98
2022-11-23 00:31:54,469 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8669954714449969, 'Total loss': 0.8669954714449969} | train loss {'Reaction outcome loss': 0.8239629883919993, 'Total loss': 0.8239629883919993}
2022-11-23 00:31:54,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:54,469 INFO:     Epoch: 99
2022-11-23 00:31:55,276 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8575592664155093, 'Total loss': 0.8575592664155093} | train loss {'Reaction outcome loss': 0.8208728185103785, 'Total loss': 0.8208728185103785}
2022-11-23 00:31:55,276 INFO:     Best model found after epoch 69 of 100.
2022-11-23 00:31:55,276 INFO:   Done with stage: TRAINING
2022-11-23 00:31:55,276 INFO:   Starting stage: EVALUATION
2022-11-23 00:31:55,395 INFO:   Done with stage: EVALUATION
2022-11-23 00:31:55,395 INFO:   Leaving out SEQ value Fold_9
2022-11-23 00:31:55,408 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:31:55,408 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:31:56,077 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:31:56,077 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:31:56,146 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:31:56,146 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:31:56,146 INFO:     No hyperparam tuning for this model
2022-11-23 00:31:56,146 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:31:56,146 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:31:56,147 INFO:     None feature selector for col prot
2022-11-23 00:31:56,147 INFO:     None feature selector for col prot
2022-11-23 00:31:56,147 INFO:     None feature selector for col prot
2022-11-23 00:31:56,148 INFO:     None feature selector for col chem
2022-11-23 00:31:56,148 INFO:     None feature selector for col chem
2022-11-23 00:31:56,148 INFO:     None feature selector for col chem
2022-11-23 00:31:56,148 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:31:56,148 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:31:56,150 INFO:     Number of params in model 168571
2022-11-23 00:31:56,153 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:31:56,153 INFO:   Starting stage: TRAINING
2022-11-23 00:31:56,211 INFO:     Val loss before train {'Reaction outcome loss': 0.9938602102073756, 'Total loss': 0.9938602102073756}
2022-11-23 00:31:56,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:56,211 INFO:     Epoch: 0
2022-11-23 00:31:57,069 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8144482909278437, 'Total loss': 0.8144482909278437} | train loss {'Reaction outcome loss': 0.8860042447503279, 'Total loss': 0.8860042447503279}
2022-11-23 00:31:57,069 INFO:     Found new best model at epoch 0
2022-11-23 00:31:57,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:57,070 INFO:     Epoch: 1
2022-11-23 00:31:57,898 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8267423822121187, 'Total loss': 0.8267423822121187} | train loss {'Reaction outcome loss': 0.862853151463304, 'Total loss': 0.862853151463304}
2022-11-23 00:31:57,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:57,898 INFO:     Epoch: 2
2022-11-23 00:31:58,739 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8072912110523744, 'Total loss': 0.8072912110523744} | train loss {'Reaction outcome loss': 0.8519640290272622, 'Total loss': 0.8519640290272622}
2022-11-23 00:31:58,739 INFO:     Found new best model at epoch 2
2022-11-23 00:31:58,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:58,740 INFO:     Epoch: 3
2022-11-23 00:31:59,597 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8201965852217241, 'Total loss': 0.8201965852217241} | train loss {'Reaction outcome loss': 0.847822794472037, 'Total loss': 0.847822794472037}
2022-11-23 00:31:59,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:31:59,597 INFO:     Epoch: 4
2022-11-23 00:32:00,401 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8192104941064661, 'Total loss': 0.8192104941064661} | train loss {'Reaction outcome loss': 0.8435583378863238, 'Total loss': 0.8435583378863238}
2022-11-23 00:32:00,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:00,401 INFO:     Epoch: 5
2022-11-23 00:32:01,219 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7911901013417677, 'Total loss': 0.7911901013417677} | train loss {'Reaction outcome loss': 0.848411491525318, 'Total loss': 0.848411491525318}
2022-11-23 00:32:01,220 INFO:     Found new best model at epoch 5
2022-11-23 00:32:01,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:01,220 INFO:     Epoch: 6
2022-11-23 00:32:02,047 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8095125989480452, 'Total loss': 0.8095125989480452} | train loss {'Reaction outcome loss': 0.839515485985559, 'Total loss': 0.839515485985559}
2022-11-23 00:32:02,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:02,047 INFO:     Epoch: 7
2022-11-23 00:32:02,915 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8406255570324984, 'Total loss': 0.8406255570324984} | train loss {'Reaction outcome loss': 0.841535416691892, 'Total loss': 0.841535416691892}
2022-11-23 00:32:02,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:02,916 INFO:     Epoch: 8
2022-11-23 00:32:03,809 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8242750655521046, 'Total loss': 0.8242750655521046} | train loss {'Reaction outcome loss': 0.846704830162921, 'Total loss': 0.846704830162921}
2022-11-23 00:32:03,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:03,809 INFO:     Epoch: 9
2022-11-23 00:32:04,658 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8192860700867393, 'Total loss': 0.8192860700867393} | train loss {'Reaction outcome loss': 0.8455773168488553, 'Total loss': 0.8455773168488553}
2022-11-23 00:32:04,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:04,658 INFO:     Epoch: 10
2022-11-23 00:32:05,472 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7950097295370969, 'Total loss': 0.7950097295370969} | train loss {'Reaction outcome loss': 0.8469799305745948, 'Total loss': 0.8469799305745948}
2022-11-23 00:32:05,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:05,473 INFO:     Epoch: 11
2022-11-23 00:32:06,334 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8013108548792925, 'Total loss': 0.8013108548792925} | train loss {'Reaction outcome loss': 0.8454771123916996, 'Total loss': 0.8454771123916996}
2022-11-23 00:32:06,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:06,335 INFO:     Epoch: 12
2022-11-23 00:32:07,178 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8013061928478155, 'Total loss': 0.8013061928478155} | train loss {'Reaction outcome loss': 0.8354524930237759, 'Total loss': 0.8354524930237759}
2022-11-23 00:32:07,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:07,178 INFO:     Epoch: 13
2022-11-23 00:32:08,070 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.80310911888426, 'Total loss': 0.80310911888426} | train loss {'Reaction outcome loss': 0.8432372495954336, 'Total loss': 0.8432372495954336}
2022-11-23 00:32:08,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:08,070 INFO:     Epoch: 14
2022-11-23 00:32:08,969 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7860997867855158, 'Total loss': 0.7860997867855158} | train loss {'Reaction outcome loss': 0.832975236993087, 'Total loss': 0.832975236993087}
2022-11-23 00:32:08,970 INFO:     Found new best model at epoch 14
2022-11-23 00:32:08,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:08,970 INFO:     Epoch: 15
2022-11-23 00:32:09,892 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8217017813162371, 'Total loss': 0.8217017813162371} | train loss {'Reaction outcome loss': 0.8412393592147209, 'Total loss': 0.8412393592147209}
2022-11-23 00:32:09,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:09,893 INFO:     Epoch: 16
2022-11-23 00:32:10,790 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7967986640605059, 'Total loss': 0.7967986640605059} | train loss {'Reaction outcome loss': 0.836225250230627, 'Total loss': 0.836225250230627}
2022-11-23 00:32:10,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:10,790 INFO:     Epoch: 17
2022-11-23 00:32:11,687 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8103414503010836, 'Total loss': 0.8103414503010836} | train loss {'Reaction outcome loss': 0.828537816702113, 'Total loss': 0.828537816702113}
2022-11-23 00:32:11,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:11,688 INFO:     Epoch: 18
2022-11-23 00:32:12,590 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8169240274212577, 'Total loss': 0.8169240274212577} | train loss {'Reaction outcome loss': 0.833978320784897, 'Total loss': 0.833978320784897}
2022-11-23 00:32:12,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:12,591 INFO:     Epoch: 19
2022-11-23 00:32:13,499 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7965714342214845, 'Total loss': 0.7965714342214845} | train loss {'Reaction outcome loss': 0.8350632133995474, 'Total loss': 0.8350632133995474}
2022-11-23 00:32:13,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:13,500 INFO:     Epoch: 20
2022-11-23 00:32:14,438 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8153922943906351, 'Total loss': 0.8153922943906351} | train loss {'Reaction outcome loss': 0.8301743825196255, 'Total loss': 0.8301743825196255}
2022-11-23 00:32:14,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:14,438 INFO:     Epoch: 21
2022-11-23 00:32:15,327 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8003424907272513, 'Total loss': 0.8003424907272513} | train loss {'Reaction outcome loss': 0.8284188172353907, 'Total loss': 0.8284188172353907}
2022-11-23 00:32:15,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:15,327 INFO:     Epoch: 22
2022-11-23 00:32:16,282 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7877138521183621, 'Total loss': 0.7877138521183621} | train loss {'Reaction outcome loss': 0.8345466668789203, 'Total loss': 0.8345466668789203}
2022-11-23 00:32:16,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:16,282 INFO:     Epoch: 23
2022-11-23 00:32:17,159 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8030570501630957, 'Total loss': 0.8030570501630957} | train loss {'Reaction outcome loss': 0.8248908954713992, 'Total loss': 0.8248908954713992}
2022-11-23 00:32:17,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:17,159 INFO:     Epoch: 24
2022-11-23 00:32:18,100 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7879417003555731, 'Total loss': 0.7879417003555731} | train loss {'Reaction outcome loss': 0.8315421560032648, 'Total loss': 0.8315421560032648}
2022-11-23 00:32:18,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:18,101 INFO:     Epoch: 25
2022-11-23 00:32:19,013 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7904976145787672, 'Total loss': 0.7904976145787672} | train loss {'Reaction outcome loss': 0.8311999324362288, 'Total loss': 0.8311999324362288}
2022-11-23 00:32:19,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:19,013 INFO:     Epoch: 26
2022-11-23 00:32:19,947 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7866425541314211, 'Total loss': 0.7866425541314211} | train loss {'Reaction outcome loss': 0.8349490969287239, 'Total loss': 0.8349490969287239}
2022-11-23 00:32:19,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:19,947 INFO:     Epoch: 27
2022-11-23 00:32:20,875 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7839614180001345, 'Total loss': 0.7839614180001345} | train loss {'Reaction outcome loss': 0.83414248856697, 'Total loss': 0.83414248856697}
2022-11-23 00:32:20,875 INFO:     Found new best model at epoch 27
2022-11-23 00:32:20,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:20,876 INFO:     Epoch: 28
2022-11-23 00:32:21,830 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7864649079062722, 'Total loss': 0.7864649079062722} | train loss {'Reaction outcome loss': 0.8183266997096027, 'Total loss': 0.8183266997096027}
2022-11-23 00:32:21,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:21,830 INFO:     Epoch: 29
2022-11-23 00:32:22,764 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8010524233633821, 'Total loss': 0.8010524233633821} | train loss {'Reaction outcome loss': 0.8356686940318659, 'Total loss': 0.8356686940318659}
2022-11-23 00:32:22,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:22,764 INFO:     Epoch: 30
2022-11-23 00:32:23,626 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7999445701187308, 'Total loss': 0.7999445701187308} | train loss {'Reaction outcome loss': 0.827071021563611, 'Total loss': 0.827071021563611}
2022-11-23 00:32:23,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:23,626 INFO:     Epoch: 31
2022-11-23 00:32:24,542 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7971344170245257, 'Total loss': 0.7971344170245257} | train loss {'Reaction outcome loss': 0.8346104473478881, 'Total loss': 0.8346104473478881}
2022-11-23 00:32:24,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:24,543 INFO:     Epoch: 32
2022-11-23 00:32:25,434 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8089432309974324, 'Total loss': 0.8089432309974324} | train loss {'Reaction outcome loss': 0.8281402219886239, 'Total loss': 0.8281402219886239}
2022-11-23 00:32:25,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:25,434 INFO:     Epoch: 33
2022-11-23 00:32:26,339 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.803203246132894, 'Total loss': 0.803203246132894} | train loss {'Reaction outcome loss': 0.820644037172138, 'Total loss': 0.820644037172138}
2022-11-23 00:32:26,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:26,340 INFO:     Epoch: 34
2022-11-23 00:32:27,276 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7919653064825318, 'Total loss': 0.7919653064825318} | train loss {'Reaction outcome loss': 0.8254822793035854, 'Total loss': 0.8254822793035854}
2022-11-23 00:32:27,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:27,276 INFO:     Epoch: 35
2022-11-23 00:32:28,168 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8010035048831593, 'Total loss': 0.8010035048831593} | train loss {'Reaction outcome loss': 0.8307565311912583, 'Total loss': 0.8307565311912583}
2022-11-23 00:32:28,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:28,169 INFO:     Epoch: 36
2022-11-23 00:32:29,073 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7889838110316884, 'Total loss': 0.7889838110316884} | train loss {'Reaction outcome loss': 0.8305788556121381, 'Total loss': 0.8305788556121381}
2022-11-23 00:32:29,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:29,073 INFO:     Epoch: 37
2022-11-23 00:32:29,918 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8098490766503594, 'Total loss': 0.8098490766503594} | train loss {'Reaction outcome loss': 0.8236773886419984, 'Total loss': 0.8236773886419984}
2022-11-23 00:32:29,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:29,918 INFO:     Epoch: 38
2022-11-23 00:32:30,786 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7955373454500329, 'Total loss': 0.7955373454500329} | train loss {'Reaction outcome loss': 0.8247927160036226, 'Total loss': 0.8247927160036226}
2022-11-23 00:32:30,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:30,786 INFO:     Epoch: 39
2022-11-23 00:32:31,639 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8119803308085962, 'Total loss': 0.8119803308085962} | train loss {'Reaction outcome loss': 0.8281850002796544, 'Total loss': 0.8281850002796544}
2022-11-23 00:32:31,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:31,640 INFO:     Epoch: 40
2022-11-23 00:32:32,580 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7932000993327661, 'Total loss': 0.7932000993327661} | train loss {'Reaction outcome loss': 0.8286293419266519, 'Total loss': 0.8286293419266519}
2022-11-23 00:32:32,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:32,580 INFO:     Epoch: 41
2022-11-23 00:32:33,478 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8077676804228262, 'Total loss': 0.8077676804228262} | train loss {'Reaction outcome loss': 0.8234718215127705, 'Total loss': 0.8234718215127705}
2022-11-23 00:32:33,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:33,478 INFO:     Epoch: 42
2022-11-23 00:32:34,383 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7792059548876502, 'Total loss': 0.7792059548876502} | train loss {'Reaction outcome loss': 0.8270188985083268, 'Total loss': 0.8270188985083268}
2022-11-23 00:32:34,383 INFO:     Found new best model at epoch 42
2022-11-23 00:32:34,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:34,384 INFO:     Epoch: 43
2022-11-23 00:32:35,255 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7818788046186621, 'Total loss': 0.7818788046186621} | train loss {'Reaction outcome loss': 0.8244985286523456, 'Total loss': 0.8244985286523456}
2022-11-23 00:32:35,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:35,256 INFO:     Epoch: 44
2022-11-23 00:32:36,160 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7858893512324854, 'Total loss': 0.7858893512324854} | train loss {'Reaction outcome loss': 0.8235428963112927, 'Total loss': 0.8235428963112927}
2022-11-23 00:32:36,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:36,160 INFO:     Epoch: 45
2022-11-23 00:32:37,031 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7906951186331835, 'Total loss': 0.7906951186331835} | train loss {'Reaction outcome loss': 0.8260901280742908, 'Total loss': 0.8260901280742908}
2022-11-23 00:32:37,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:37,032 INFO:     Epoch: 46
2022-11-23 00:32:37,900 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7812900041992014, 'Total loss': 0.7812900041992014} | train loss {'Reaction outcome loss': 0.8295133963287601, 'Total loss': 0.8295133963287601}
2022-11-23 00:32:37,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:37,900 INFO:     Epoch: 47
2022-11-23 00:32:38,778 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7926082577217709, 'Total loss': 0.7926082577217709} | train loss {'Reaction outcome loss': 0.8294593054755979, 'Total loss': 0.8294593054755979}
2022-11-23 00:32:38,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:38,779 INFO:     Epoch: 48
2022-11-23 00:32:39,683 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7931367802349004, 'Total loss': 0.7931367802349004} | train loss {'Reaction outcome loss': 0.8250384103914021, 'Total loss': 0.8250384103914021}
2022-11-23 00:32:39,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:39,683 INFO:     Epoch: 49
2022-11-23 00:32:40,577 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7983121858401732, 'Total loss': 0.7983121858401732} | train loss {'Reaction outcome loss': 0.8354043643242917, 'Total loss': 0.8354043643242917}
2022-11-23 00:32:40,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:40,577 INFO:     Epoch: 50
2022-11-23 00:32:41,485 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7813174365596338, 'Total loss': 0.7813174365596338} | train loss {'Reaction outcome loss': 0.8360523643039981, 'Total loss': 0.8360523643039981}
2022-11-23 00:32:41,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:41,485 INFO:     Epoch: 51
2022-11-23 00:32:42,366 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7992460842836987, 'Total loss': 0.7992460842836987} | train loss {'Reaction outcome loss': 0.82210761694773, 'Total loss': 0.82210761694773}
2022-11-23 00:32:42,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:42,366 INFO:     Epoch: 52
2022-11-23 00:32:43,284 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7878007590770721, 'Total loss': 0.7878007590770721} | train loss {'Reaction outcome loss': 0.8309882607778557, 'Total loss': 0.8309882607778557}
2022-11-23 00:32:43,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:43,284 INFO:     Epoch: 53
2022-11-23 00:32:44,221 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7933022237636826, 'Total loss': 0.7933022237636826} | train loss {'Reaction outcome loss': 0.8236969589945758, 'Total loss': 0.8236969589945758}
2022-11-23 00:32:44,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:44,221 INFO:     Epoch: 54
2022-11-23 00:32:45,125 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7941482893445275, 'Total loss': 0.7941482893445275} | train loss {'Reaction outcome loss': 0.8204402916344554, 'Total loss': 0.8204402916344554}
2022-11-23 00:32:45,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:45,126 INFO:     Epoch: 55
2022-11-23 00:32:46,016 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8083557337522507, 'Total loss': 0.8083557337522507} | train loss {'Reaction outcome loss': 0.8302034240985207, 'Total loss': 0.8302034240985207}
2022-11-23 00:32:46,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:46,016 INFO:     Epoch: 56
2022-11-23 00:32:46,912 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8084771165793593, 'Total loss': 0.8084771165793593} | train loss {'Reaction outcome loss': 0.8211372785481365, 'Total loss': 0.8211372785481365}
2022-11-23 00:32:46,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:46,912 INFO:     Epoch: 57
2022-11-23 00:32:47,784 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.803606850179759, 'Total loss': 0.803606850179759} | train loss {'Reaction outcome loss': 0.8258694342756079, 'Total loss': 0.8258694342756079}
2022-11-23 00:32:47,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:47,784 INFO:     Epoch: 58
2022-11-23 00:32:48,619 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7881602306257595, 'Total loss': 0.7881602306257595} | train loss {'Reaction outcome loss': 0.8282486195506354, 'Total loss': 0.8282486195506354}
2022-11-23 00:32:48,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:48,620 INFO:     Epoch: 59
2022-11-23 00:32:49,486 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7882260504094037, 'Total loss': 0.7882260504094037} | train loss {'Reaction outcome loss': 0.820227808556576, 'Total loss': 0.820227808556576}
2022-11-23 00:32:49,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:49,488 INFO:     Epoch: 60
2022-11-23 00:32:50,345 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7856194322759454, 'Total loss': 0.7856194322759454} | train loss {'Reaction outcome loss': 0.8170476813728993, 'Total loss': 0.8170476813728993}
2022-11-23 00:32:50,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:50,346 INFO:     Epoch: 61
2022-11-23 00:32:51,200 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8042011071335186, 'Total loss': 0.8042011071335186} | train loss {'Reaction outcome loss': 0.8262628765723966, 'Total loss': 0.8262628765723966}
2022-11-23 00:32:51,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:51,200 INFO:     Epoch: 62
2022-11-23 00:32:52,075 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7875744314356283, 'Total loss': 0.7875744314356283} | train loss {'Reaction outcome loss': 0.8223251586681918, 'Total loss': 0.8223251586681918}
2022-11-23 00:32:52,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:52,075 INFO:     Epoch: 63
2022-11-23 00:32:52,956 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.798614079979333, 'Total loss': 0.798614079979333} | train loss {'Reaction outcome loss': 0.8270327177366265, 'Total loss': 0.8270327177366265}
2022-11-23 00:32:52,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:52,956 INFO:     Epoch: 64
2022-11-23 00:32:53,784 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.788498268886046, 'Total loss': 0.788498268886046} | train loss {'Reaction outcome loss': 0.8248211836766618, 'Total loss': 0.8248211836766618}
2022-11-23 00:32:53,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:53,784 INFO:     Epoch: 65
2022-11-23 00:32:54,628 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7872386127710342, 'Total loss': 0.7872386127710342} | train loss {'Reaction outcome loss': 0.8263695195226776, 'Total loss': 0.8263695195226776}
2022-11-23 00:32:54,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:54,629 INFO:     Epoch: 66
2022-11-23 00:32:55,489 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8097966144030745, 'Total loss': 0.8097966144030745} | train loss {'Reaction outcome loss': 0.8209413201868655, 'Total loss': 0.8209413201868655}
2022-11-23 00:32:55,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:55,490 INFO:     Epoch: 67
2022-11-23 00:32:56,382 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.797967559911988, 'Total loss': 0.797967559911988} | train loss {'Reaction outcome loss': 0.8217828268946906, 'Total loss': 0.8217828268946906}
2022-11-23 00:32:56,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:56,382 INFO:     Epoch: 68
2022-11-23 00:32:57,217 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.803448149426417, 'Total loss': 0.803448149426417} | train loss {'Reaction outcome loss': 0.830154749877781, 'Total loss': 0.830154749877781}
2022-11-23 00:32:57,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:57,218 INFO:     Epoch: 69
2022-11-23 00:32:58,073 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7885190350088206, 'Total loss': 0.7885190350088206} | train loss {'Reaction outcome loss': 0.8184863870684435, 'Total loss': 0.8184863870684435}
2022-11-23 00:32:58,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:58,073 INFO:     Epoch: 70
2022-11-23 00:32:58,981 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.789775209670717, 'Total loss': 0.789775209670717} | train loss {'Reaction outcome loss': 0.8289513148759541, 'Total loss': 0.8289513148759541}
2022-11-23 00:32:58,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:58,982 INFO:     Epoch: 71
2022-11-23 00:32:59,822 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8071321994066238, 'Total loss': 0.8071321994066238} | train loss {'Reaction outcome loss': 0.832681854364843, 'Total loss': 0.832681854364843}
2022-11-23 00:32:59,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:32:59,822 INFO:     Epoch: 72
2022-11-23 00:33:00,670 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7784936692227017, 'Total loss': 0.7784936692227017} | train loss {'Reaction outcome loss': 0.8408866790142137, 'Total loss': 0.8408866790142137}
2022-11-23 00:33:00,670 INFO:     Found new best model at epoch 72
2022-11-23 00:33:00,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:00,671 INFO:     Epoch: 73
2022-11-23 00:33:01,484 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7818142338232561, 'Total loss': 0.7818142338232561} | train loss {'Reaction outcome loss': 0.8231565280240557, 'Total loss': 0.8231565280240557}
2022-11-23 00:33:01,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:01,485 INFO:     Epoch: 74
2022-11-23 00:33:02,354 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7930643490769647, 'Total loss': 0.7930643490769647} | train loss {'Reaction outcome loss': 0.8312598469286312, 'Total loss': 0.8312598469286312}
2022-11-23 00:33:02,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:02,354 INFO:     Epoch: 75
2022-11-23 00:33:03,220 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8034765246239576, 'Total loss': 0.8034765246239576} | train loss {'Reaction outcome loss': 0.8268979180920945, 'Total loss': 0.8268979180920945}
2022-11-23 00:33:03,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:03,220 INFO:     Epoch: 76
2022-11-23 00:33:04,068 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7861186116933823, 'Total loss': 0.7861186116933823} | train loss {'Reaction outcome loss': 0.8285950707037922, 'Total loss': 0.8285950707037922}
2022-11-23 00:33:04,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:04,068 INFO:     Epoch: 77
2022-11-23 00:33:04,929 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7973486286672679, 'Total loss': 0.7973486286672679} | train loss {'Reaction outcome loss': 0.8204960112388318, 'Total loss': 0.8204960112388318}
2022-11-23 00:33:04,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:04,930 INFO:     Epoch: 78
2022-11-23 00:33:05,765 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8033533401109956, 'Total loss': 0.8033533401109956} | train loss {'Reaction outcome loss': 0.8250608207725803, 'Total loss': 0.8250608207725803}
2022-11-23 00:33:05,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:05,765 INFO:     Epoch: 79
2022-11-23 00:33:06,590 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7896039221774448, 'Total loss': 0.7896039221774448} | train loss {'Reaction outcome loss': 0.8319305633967705, 'Total loss': 0.8319305633967705}
2022-11-23 00:33:06,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:06,591 INFO:     Epoch: 80
2022-11-23 00:33:07,476 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7926339303905313, 'Total loss': 0.7926339303905313} | train loss {'Reaction outcome loss': 0.8273626089337384, 'Total loss': 0.8273626089337384}
2022-11-23 00:33:07,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:07,476 INFO:     Epoch: 81
2022-11-23 00:33:08,358 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7887472882866859, 'Total loss': 0.7887472882866859} | train loss {'Reaction outcome loss': 0.82709768088723, 'Total loss': 0.82709768088723}
2022-11-23 00:33:08,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:08,359 INFO:     Epoch: 82
2022-11-23 00:33:09,210 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7862094430760904, 'Total loss': 0.7862094430760904} | train loss {'Reaction outcome loss': 0.8239516541663452, 'Total loss': 0.8239516541663452}
2022-11-23 00:33:09,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:09,211 INFO:     Epoch: 83
2022-11-23 00:33:10,064 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8202289220961657, 'Total loss': 0.8202289220961657} | train loss {'Reaction outcome loss': 0.8254168499336552, 'Total loss': 0.8254168499336552}
2022-11-23 00:33:10,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:10,064 INFO:     Epoch: 84
2022-11-23 00:33:10,850 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.82341668009758, 'Total loss': 0.82341668009758} | train loss {'Reaction outcome loss': 0.826862558722496, 'Total loss': 0.826862558722496}
2022-11-23 00:33:10,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:10,851 INFO:     Epoch: 85
2022-11-23 00:33:11,673 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7777469293637709, 'Total loss': 0.7777469293637709} | train loss {'Reaction outcome loss': 0.8310803848239574, 'Total loss': 0.8310803848239574}
2022-11-23 00:33:11,673 INFO:     Found new best model at epoch 85
2022-11-23 00:33:11,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:11,674 INFO:     Epoch: 86
2022-11-23 00:33:12,475 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8251111907037821, 'Total loss': 0.8251111907037821} | train loss {'Reaction outcome loss': 0.8275005605056701, 'Total loss': 0.8275005605056701}
2022-11-23 00:33:12,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:12,475 INFO:     Epoch: 87
2022-11-23 00:33:13,321 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8286336436867714, 'Total loss': 0.8286336436867714} | train loss {'Reaction outcome loss': 0.8242923969681929, 'Total loss': 0.8242923969681929}
2022-11-23 00:33:13,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:13,321 INFO:     Epoch: 88
2022-11-23 00:33:14,130 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7936273677782579, 'Total loss': 0.7936273677782579} | train loss {'Reaction outcome loss': 0.8293574892798898, 'Total loss': 0.8293574892798898}
2022-11-23 00:33:14,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:14,130 INFO:     Epoch: 89
2022-11-23 00:33:14,938 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8161003670909188, 'Total loss': 0.8161003670909188} | train loss {'Reaction outcome loss': 0.8221692887515675, 'Total loss': 0.8221692887515675}
2022-11-23 00:33:14,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:14,938 INFO:     Epoch: 90
2022-11-23 00:33:15,772 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7888954789801077, 'Total loss': 0.7888954789801077} | train loss {'Reaction outcome loss': 0.8252912978170371, 'Total loss': 0.8252912978170371}
2022-11-23 00:33:15,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:15,773 INFO:     Epoch: 91
2022-11-23 00:33:16,576 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7993637641722505, 'Total loss': 0.7993637641722505} | train loss {'Reaction outcome loss': 0.833760089478512, 'Total loss': 0.833760089478512}
2022-11-23 00:33:16,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:16,576 INFO:     Epoch: 92
2022-11-23 00:33:17,365 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7935508848591284, 'Total loss': 0.7935508848591284} | train loss {'Reaction outcome loss': 0.8249759135941263, 'Total loss': 0.8249759135941263}
2022-11-23 00:33:17,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:17,366 INFO:     Epoch: 93
2022-11-23 00:33:18,165 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8051973560994322, 'Total loss': 0.8051973560994322} | train loss {'Reaction outcome loss': 0.8234593715021002, 'Total loss': 0.8234593715021002}
2022-11-23 00:33:18,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:18,165 INFO:     Epoch: 94
2022-11-23 00:33:19,001 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7925111035054381, 'Total loss': 0.7925111035054381} | train loss {'Reaction outcome loss': 0.8342465128493213, 'Total loss': 0.8342465128493213}
2022-11-23 00:33:19,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:19,001 INFO:     Epoch: 95
2022-11-23 00:33:19,807 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7730804112824526, 'Total loss': 0.7730804112824526} | train loss {'Reaction outcome loss': 0.8266827940699543, 'Total loss': 0.8266827940699543}
2022-11-23 00:33:19,807 INFO:     Found new best model at epoch 95
2022-11-23 00:33:19,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:19,808 INFO:     Epoch: 96
2022-11-23 00:33:20,635 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7864986244927753, 'Total loss': 0.7864986244927753} | train loss {'Reaction outcome loss': 0.8241974852587047, 'Total loss': 0.8241974852587047}
2022-11-23 00:33:20,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:20,636 INFO:     Epoch: 97
2022-11-23 00:33:21,455 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8039367727257989, 'Total loss': 0.8039367727257989} | train loss {'Reaction outcome loss': 0.8319923673805437, 'Total loss': 0.8319923673805437}
2022-11-23 00:33:21,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:21,455 INFO:     Epoch: 98
2022-11-23 00:33:22,291 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8719702945514158, 'Total loss': 0.8719702945514158} | train loss {'Reaction outcome loss': 0.825752576835725, 'Total loss': 0.825752576835725}
2022-11-23 00:33:22,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:22,292 INFO:     Epoch: 99
2022-11-23 00:33:23,092 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8275187584486875, 'Total loss': 0.8275187584486875} | train loss {'Reaction outcome loss': 0.8356888878200701, 'Total loss': 0.8356888878200701}
2022-11-23 00:33:23,092 INFO:     Best model found after epoch 96 of 100.
2022-11-23 00:33:23,092 INFO:   Done with stage: TRAINING
2022-11-23 00:33:23,092 INFO:   Starting stage: EVALUATION
2022-11-23 00:33:23,218 INFO:   Done with stage: EVALUATION
2022-11-23 00:33:23,218 INFO: Done with stage: RUNNING SPLITS
2022-11-23 00:33:23,218 INFO: Starting stage: COMPUTE METRICS
2022-11-23 00:33:24,429 INFO: Done with stage: COMPUTE METRICS
2022-11-23 00:33:24,429 INFO: Starting stage: EXPORT RESULTS
2022-11-23 00:33:24,447 INFO:   Final results averaged over 50 folds: 
2022-11-23 00:33:24,451 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.253829           NaN  0.345102       NaN
2022-11-23 00:33:26,113 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-23 00:33:26,118 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-23 00:33:26,120 DEBUG:   interactive is False
2022-11-23 00:33:26,120 DEBUG:   platform is linux
2022-11-23 00:33:26,120 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-23 00:33:26,298 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-23 00:33:26,300 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-23 00:33:26,759 DEBUG:   Loaded backend agg version unknown.
2022-11-23 00:33:26,763 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-23 00:33:26,764 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,764 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,764 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,764 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 00:33:26,765 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 00:33:26,766 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,767 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,768 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 00:33:26,769 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,769 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 00:33:26,819 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,820 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,821 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,822 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 00:33:26,823 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,823 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 00:33:26,833 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,833 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 00:33:26,834 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,835 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,836 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 00:33:26,836 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 00:33:26,836 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,836 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,836 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 00:33:26,836 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 00:33:26,836 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 00:33:26,836 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 00:33:27,263 INFO: Done with stage: EXPORT RESULTS
2022-11-23 00:33:27,263 INFO: Starting stage: SAVE MODEL
2022-11-23 00:33:27,327 INFO: Done with stage: SAVE MODEL
2022-11-23 00:33:27,328 INFO: Wall time for program:  4171.86 seconds
