2022-12-05 22:41:01,817 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/21a75a63ae596df0503bc441b63af632/2022_12_05-191941",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-05 22:41:01,825 INFO: Starting stage: BUILD FEATURIZERS
2022-12-05 22:41:01,828 INFO:   Creating esm representation model
2022-12-05 22:41:01,828 INFO:   Done esm representation model
2022-12-05 22:41:01,828 INFO: Done with stage: BUILD FEATURIZERS
2022-12-05 22:41:01,828 INFO: Starting stage: BUILDING DATASET
2022-12-05 22:41:01,881 INFO: Done with stage: BUILDING DATASET
2022-12-05 22:41:01,881 INFO: Starting stage: FEATURIZING DATA
2022-12-05 22:41:01,881 INFO:   Featurizing proteins
2022-12-05 22:41:01,883 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-05 22:41:01,899 INFO:   Loaded feature cache of size 204
2022-12-05 22:41:01,900 INFO:   Starting to pool ESM Embeddings
2022-12-05 22:41:02,008 INFO:   Featurizing molecules
2022-12-05 22:41:02,010 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-05 22:41:02,013 INFO:   Loaded feature cache of size 495
2022-12-05 22:41:03,374 INFO: Done with stage: FEATURIZING DATA
2022-12-05 22:41:03,374 INFO: Starting stage: RUNNING SPLITS
2022-12-05 22:41:03,382 INFO:   Leaving out SEQ value Fold_0
2022-12-05 22:41:03,396 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 22:41:03,397 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:41:04,048 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:41:04,048 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:41:04,117 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:41:04,117 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:41:04,117 INFO:     No hyperparam tuning for this model
2022-12-05 22:41:04,117 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:41:04,117 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:41:04,118 INFO:     None feature selector for col prot
2022-12-05 22:41:04,118 INFO:     None feature selector for col prot
2022-12-05 22:41:04,118 INFO:     None feature selector for col prot
2022-12-05 22:41:04,119 INFO:     None feature selector for col chem
2022-12-05 22:41:04,119 INFO:     None feature selector for col chem
2022-12-05 22:41:04,119 INFO:     None feature selector for col chem
2022-12-05 22:41:04,119 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:41:04,119 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:41:04,121 INFO:     Number of params in model 215731
2022-12-05 22:41:04,121 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:41:04,121 INFO:   Starting stage: TRAINING
2022-12-05 22:41:06,187 INFO:     Val loss before train {'Reaction outcome loss': 1.0538989430250123, 'Total loss': 1.0538989430250123}
2022-12-05 22:41:06,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:06,188 INFO:     Epoch: 0
2022-12-05 22:41:06,882 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6936367978883344, 'Total loss': 0.6936367978883344} | train loss {'Reaction outcome loss': 0.8042521377811667, 'Total loss': 0.8042521377811667}
2022-12-05 22:41:06,882 INFO:     Found new best model at epoch 0
2022-12-05 22:41:06,883 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:06,883 INFO:     Epoch: 1
2022-12-05 22:41:07,578 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6998293164164521, 'Total loss': 0.6998293164164521} | train loss {'Reaction outcome loss': 0.6546124715785511, 'Total loss': 0.6546124715785511}
2022-12-05 22:41:07,578 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:07,578 INFO:     Epoch: 2
2022-12-05 22:41:08,274 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.616693450961002, 'Total loss': 0.616693450961002} | train loss {'Reaction outcome loss': 0.6167554518238443, 'Total loss': 0.6167554518238443}
2022-12-05 22:41:08,274 INFO:     Found new best model at epoch 2
2022-12-05 22:41:08,275 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:08,275 INFO:     Epoch: 3
2022-12-05 22:41:08,973 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6610916125219922, 'Total loss': 0.6610916125219922} | train loss {'Reaction outcome loss': 0.5893770972358399, 'Total loss': 0.5893770972358399}
2022-12-05 22:41:08,973 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:08,973 INFO:     Epoch: 4
2022-12-05 22:41:09,665 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5802664846874946, 'Total loss': 0.5802664846874946} | train loss {'Reaction outcome loss': 0.578807104806431, 'Total loss': 0.578807104806431}
2022-12-05 22:41:09,665 INFO:     Found new best model at epoch 4
2022-12-05 22:41:09,666 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:09,666 INFO:     Epoch: 5
2022-12-05 22:41:10,358 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6020094877065614, 'Total loss': 0.6020094877065614} | train loss {'Reaction outcome loss': 0.5730205965457392, 'Total loss': 0.5730205965457392}
2022-12-05 22:41:10,358 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:10,358 INFO:     Epoch: 6
2022-12-05 22:41:11,050 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6067544862974522, 'Total loss': 0.6067544862974522} | train loss {'Reaction outcome loss': 0.5610883091805411, 'Total loss': 0.5610883091805411}
2022-12-05 22:41:11,051 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:11,051 INFO:     Epoch: 7
2022-12-05 22:41:11,745 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5697536818509878, 'Total loss': 0.5697536818509878} | train loss {'Reaction outcome loss': 0.5490858413156916, 'Total loss': 0.5490858413156916}
2022-12-05 22:41:11,745 INFO:     Found new best model at epoch 7
2022-12-05 22:41:11,746 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:11,746 INFO:     Epoch: 8
2022-12-05 22:41:12,444 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5769488056038701, 'Total loss': 0.5769488056038701} | train loss {'Reaction outcome loss': 0.5491870964159731, 'Total loss': 0.5491870964159731}
2022-12-05 22:41:12,445 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:12,445 INFO:     Epoch: 9
2022-12-05 22:41:13,141 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.6068368921446246, 'Total loss': 0.6068368921446246} | train loss {'Reaction outcome loss': 0.5575145097663168, 'Total loss': 0.5575145097663168}
2022-12-05 22:41:13,141 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:13,141 INFO:     Epoch: 10
2022-12-05 22:41:13,833 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6019004784351172, 'Total loss': 0.6019004784351172} | train loss {'Reaction outcome loss': 0.5371853755023636, 'Total loss': 0.5371853755023636}
2022-12-05 22:41:13,833 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:13,833 INFO:     Epoch: 11
2022-12-05 22:41:14,525 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5655440403971561, 'Total loss': 0.5655440403971561} | train loss {'Reaction outcome loss': 0.5334317578521909, 'Total loss': 0.5334317578521909}
2022-12-05 22:41:14,525 INFO:     Found new best model at epoch 11
2022-12-05 22:41:14,526 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:14,526 INFO:     Epoch: 12
2022-12-05 22:41:15,223 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5744152089884115, 'Total loss': 0.5744152089884115} | train loss {'Reaction outcome loss': 0.5310682605524533, 'Total loss': 0.5310682605524533}
2022-12-05 22:41:15,223 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:15,223 INFO:     Epoch: 13
2022-12-05 22:41:15,916 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5606493783551593, 'Total loss': 0.5606493783551593} | train loss {'Reaction outcome loss': 0.5393115212438536, 'Total loss': 0.5393115212438536}
2022-12-05 22:41:15,916 INFO:     Found new best model at epoch 13
2022-12-05 22:41:15,917 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:15,917 INFO:     Epoch: 14
2022-12-05 22:41:16,610 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5656866500543993, 'Total loss': 0.5656866500543993} | train loss {'Reaction outcome loss': 0.5365133112082716, 'Total loss': 0.5365133112082716}
2022-12-05 22:41:16,610 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:16,610 INFO:     Epoch: 15
2022-12-05 22:41:17,305 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5854712392008582, 'Total loss': 0.5854712392008582} | train loss {'Reaction outcome loss': 0.5307640799733458, 'Total loss': 0.5307640799733458}
2022-12-05 22:41:17,306 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:17,306 INFO:     Epoch: 16
2022-12-05 22:41:17,999 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5883562925250031, 'Total loss': 0.5883562925250031} | train loss {'Reaction outcome loss': 0.523835865566965, 'Total loss': 0.523835865566965}
2022-12-05 22:41:17,999 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:17,999 INFO:     Epoch: 17
2022-12-05 22:41:18,699 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5660648571197376, 'Total loss': 0.5660648571197376} | train loss {'Reaction outcome loss': 0.5323158463493722, 'Total loss': 0.5323158463493722}
2022-12-05 22:41:18,699 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:18,699 INFO:     Epoch: 18
2022-12-05 22:41:19,392 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.56217655192974, 'Total loss': 0.56217655192974} | train loss {'Reaction outcome loss': 0.5261450870970233, 'Total loss': 0.5261450870970233}
2022-12-05 22:41:19,392 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:19,392 INFO:     Epoch: 19
2022-12-05 22:41:20,086 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5362673103809357, 'Total loss': 0.5362673103809357} | train loss {'Reaction outcome loss': 0.5285864025354385, 'Total loss': 0.5285864025354385}
2022-12-05 22:41:20,086 INFO:     Found new best model at epoch 19
2022-12-05 22:41:20,087 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:20,087 INFO:     Epoch: 20
2022-12-05 22:41:20,783 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5732339894355729, 'Total loss': 0.5732339894355729} | train loss {'Reaction outcome loss': 0.5203980156449509, 'Total loss': 0.5203980156449509}
2022-12-05 22:41:20,783 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:20,783 INFO:     Epoch: 21
2022-12-05 22:41:21,477 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5693501850893331, 'Total loss': 0.5693501850893331} | train loss {'Reaction outcome loss': 0.5187648979366802, 'Total loss': 0.5187648979366802}
2022-12-05 22:41:21,477 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:21,477 INFO:     Epoch: 22
2022-12-05 22:41:22,171 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5621273191862328, 'Total loss': 0.5621273191862328} | train loss {'Reaction outcome loss': 0.5224498944570783, 'Total loss': 0.5224498944570783}
2022-12-05 22:41:22,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:22,171 INFO:     Epoch: 23
2022-12-05 22:41:22,866 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5566842348076576, 'Total loss': 0.5566842348076576} | train loss {'Reaction outcome loss': 0.5180308651484427, 'Total loss': 0.5180308651484427}
2022-12-05 22:41:22,866 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:22,866 INFO:     Epoch: 24
2022-12-05 22:41:23,558 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.573778222466624, 'Total loss': 0.573778222466624} | train loss {'Reaction outcome loss': 0.5204538710903927, 'Total loss': 0.5204538710903927}
2022-12-05 22:41:23,558 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:23,558 INFO:     Epoch: 25
2022-12-05 22:41:24,250 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5326672459757605, 'Total loss': 0.5326672459757605} | train loss {'Reaction outcome loss': 0.509595265031838, 'Total loss': 0.509595265031838}
2022-12-05 22:41:24,250 INFO:     Found new best model at epoch 25
2022-12-05 22:41:24,250 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:24,250 INFO:     Epoch: 26
2022-12-05 22:41:24,943 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.6110981938450836, 'Total loss': 0.6110981938450836} | train loss {'Reaction outcome loss': 0.5164134931735328, 'Total loss': 0.5164134931735328}
2022-12-05 22:41:24,944 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:24,944 INFO:     Epoch: 27
2022-12-05 22:41:25,637 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5243947083173797, 'Total loss': 0.5243947083173797} | train loss {'Reaction outcome loss': 0.5175511176835318, 'Total loss': 0.5175511176835318}
2022-12-05 22:41:25,637 INFO:     Found new best model at epoch 27
2022-12-05 22:41:25,638 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:25,638 INFO:     Epoch: 28
2022-12-05 22:41:26,333 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5492532596338627, 'Total loss': 0.5492532596338627} | train loss {'Reaction outcome loss': 0.5074638336530475, 'Total loss': 0.5074638336530475}
2022-12-05 22:41:26,333 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:26,333 INFO:     Epoch: 29
2022-12-05 22:41:27,028 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.6029293246047441, 'Total loss': 0.6029293246047441} | train loss {'Reaction outcome loss': 0.5179240497775742, 'Total loss': 0.5179240497775742}
2022-12-05 22:41:27,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:27,029 INFO:     Epoch: 30
2022-12-05 22:41:27,722 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5631834327481514, 'Total loss': 0.5631834327481514} | train loss {'Reaction outcome loss': 0.5144810424354233, 'Total loss': 0.5144810424354233}
2022-12-05 22:41:27,722 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:27,722 INFO:     Epoch: 31
2022-12-05 22:41:28,418 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5732016168361487, 'Total loss': 0.5732016168361487} | train loss {'Reaction outcome loss': 0.5059692291084861, 'Total loss': 0.5059692291084861}
2022-12-05 22:41:28,418 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:28,418 INFO:     Epoch: 32
2022-12-05 22:41:29,111 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5580347727897556, 'Total loss': 0.5580347727897556} | train loss {'Reaction outcome loss': 0.5211827719553572, 'Total loss': 0.5211827719553572}
2022-12-05 22:41:29,112 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:29,112 INFO:     Epoch: 33
2022-12-05 22:41:29,804 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5707562960857568, 'Total loss': 0.5707562960857568} | train loss {'Reaction outcome loss': 0.5099719818376127, 'Total loss': 0.5099719818376127}
2022-12-05 22:41:29,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:29,804 INFO:     Epoch: 34
2022-12-05 22:41:30,495 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5780484059522318, 'Total loss': 0.5780484059522318} | train loss {'Reaction outcome loss': 0.5137647790376281, 'Total loss': 0.5137647790376281}
2022-12-05 22:41:30,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:30,496 INFO:     Epoch: 35
2022-12-05 22:41:31,188 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5438313532707303, 'Total loss': 0.5438313532707303} | train loss {'Reaction outcome loss': 0.5143257409456323, 'Total loss': 0.5143257409456323}
2022-12-05 22:41:31,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:31,188 INFO:     Epoch: 36
2022-12-05 22:41:31,879 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5430756051873051, 'Total loss': 0.5430756051873051} | train loss {'Reaction outcome loss': 0.5140039561713328, 'Total loss': 0.5140039561713328}
2022-12-05 22:41:31,879 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:31,879 INFO:     Epoch: 37
2022-12-05 22:41:32,575 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5364374199578928, 'Total loss': 0.5364374199578928} | train loss {'Reaction outcome loss': 0.5177219557102586, 'Total loss': 0.5177219557102586}
2022-12-05 22:41:32,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:32,575 INFO:     Epoch: 38
2022-12-05 22:41:33,269 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5475937848867372, 'Total loss': 0.5475937848867372} | train loss {'Reaction outcome loss': 0.5006717446519703, 'Total loss': 0.5006717446519703}
2022-12-05 22:41:33,269 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:33,269 INFO:     Epoch: 39
2022-12-05 22:41:33,966 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5850677247657332, 'Total loss': 0.5850677247657332} | train loss {'Reaction outcome loss': 0.5125624982059979, 'Total loss': 0.5125624982059979}
2022-12-05 22:41:33,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:33,966 INFO:     Epoch: 40
2022-12-05 22:41:34,659 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5501241143359694, 'Total loss': 0.5501241143359694} | train loss {'Reaction outcome loss': 0.511944195591524, 'Total loss': 0.511944195591524}
2022-12-05 22:41:34,659 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:34,659 INFO:     Epoch: 41
2022-12-05 22:41:35,352 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.539601570645044, 'Total loss': 0.539601570645044} | train loss {'Reaction outcome loss': 0.5168188465911834, 'Total loss': 0.5168188465911834}
2022-12-05 22:41:35,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:35,352 INFO:     Epoch: 42
2022-12-05 22:41:36,044 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5529018099917922, 'Total loss': 0.5529018099917922} | train loss {'Reaction outcome loss': 0.5038500784239808, 'Total loss': 0.5038500784239808}
2022-12-05 22:41:36,044 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:36,045 INFO:     Epoch: 43
2022-12-05 22:41:36,741 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5447276165319044, 'Total loss': 0.5447276165319044} | train loss {'Reaction outcome loss': 0.5077001363283298, 'Total loss': 0.5077001363283298}
2022-12-05 22:41:36,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:36,741 INFO:     Epoch: 44
2022-12-05 22:41:37,440 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5927105393520621, 'Total loss': 0.5927105393520621} | train loss {'Reaction outcome loss': 0.5090267151960584, 'Total loss': 0.5090267151960584}
2022-12-05 22:41:37,440 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:37,440 INFO:     Epoch: 45
2022-12-05 22:41:38,133 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5902773301268733, 'Total loss': 0.5902773301268733} | train loss {'Reaction outcome loss': 0.505044406005105, 'Total loss': 0.505044406005105}
2022-12-05 22:41:38,133 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:38,133 INFO:     Epoch: 46
2022-12-05 22:41:38,826 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.532549089470575, 'Total loss': 0.532549089470575} | train loss {'Reaction outcome loss': 0.5194279604637232, 'Total loss': 0.5194279604637232}
2022-12-05 22:41:38,826 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:38,826 INFO:     Epoch: 47
2022-12-05 22:41:39,523 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5620653047118076, 'Total loss': 0.5620653047118076} | train loss {'Reaction outcome loss': 0.4997284939421005, 'Total loss': 0.4997284939421005}
2022-12-05 22:41:39,524 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:39,524 INFO:     Epoch: 48
2022-12-05 22:41:40,220 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5363174614518188, 'Total loss': 0.5363174614518188} | train loss {'Reaction outcome loss': 0.5131014937260112, 'Total loss': 0.5131014937260112}
2022-12-05 22:41:40,221 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:40,221 INFO:     Epoch: 49
2022-12-05 22:41:40,915 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5614220732173254, 'Total loss': 0.5614220732173254} | train loss {'Reaction outcome loss': 0.4994426032864168, 'Total loss': 0.4994426032864168}
2022-12-05 22:41:40,915 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:40,915 INFO:     Epoch: 50
2022-12-05 22:41:41,608 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5225593614023786, 'Total loss': 0.5225593614023786} | train loss {'Reaction outcome loss': 0.509407958657038, 'Total loss': 0.509407958657038}
2022-12-05 22:41:41,608 INFO:     Found new best model at epoch 50
2022-12-05 22:41:41,609 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:41,609 INFO:     Epoch: 51
2022-12-05 22:41:42,305 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.6393670800120331, 'Total loss': 0.6393670800120331} | train loss {'Reaction outcome loss': 0.5027693688380913, 'Total loss': 0.5027693688380913}
2022-12-05 22:41:42,305 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:42,305 INFO:     Epoch: 52
2022-12-05 22:41:42,999 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5383695107559825, 'Total loss': 0.5383695107559825} | train loss {'Reaction outcome loss': 0.5041779436659618, 'Total loss': 0.5041779436659618}
2022-12-05 22:41:42,999 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:42,999 INFO:     Epoch: 53
2022-12-05 22:41:43,698 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5643647462129593, 'Total loss': 0.5643647462129593} | train loss {'Reaction outcome loss': 0.5089213701545215, 'Total loss': 0.5089213701545215}
2022-12-05 22:41:43,698 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:43,698 INFO:     Epoch: 54
2022-12-05 22:41:44,390 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5365761837293935, 'Total loss': 0.5365761837293935} | train loss {'Reaction outcome loss': 0.5166333693949903, 'Total loss': 0.5166333693949903}
2022-12-05 22:41:44,391 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:44,391 INFO:     Epoch: 55
2022-12-05 22:41:45,085 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5388397806605627, 'Total loss': 0.5388397806605627} | train loss {'Reaction outcome loss': 0.5030983651026351, 'Total loss': 0.5030983651026351}
2022-12-05 22:41:45,085 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:45,085 INFO:     Epoch: 56
2022-12-05 22:41:45,778 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5740566731885423, 'Total loss': 0.5740566731885423} | train loss {'Reaction outcome loss': 0.5022919077853687, 'Total loss': 0.5022919077853687}
2022-12-05 22:41:45,779 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:45,779 INFO:     Epoch: 57
2022-12-05 22:41:46,473 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5383582662704379, 'Total loss': 0.5383582662704379} | train loss {'Reaction outcome loss': 0.5101213424054326, 'Total loss': 0.5101213424054326}
2022-12-05 22:41:46,473 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:46,473 INFO:     Epoch: 58
2022-12-05 22:41:47,166 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5420503339102102, 'Total loss': 0.5420503339102102} | train loss {'Reaction outcome loss': 0.504154163733369, 'Total loss': 0.504154163733369}
2022-12-05 22:41:47,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:47,167 INFO:     Epoch: 59
2022-12-05 22:41:47,860 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.545035369174425, 'Total loss': 0.545035369174425} | train loss {'Reaction outcome loss': 0.5043419917098811, 'Total loss': 0.5043419917098811}
2022-12-05 22:41:47,860 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:47,861 INFO:     Epoch: 60
2022-12-05 22:41:48,554 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5199044291363206, 'Total loss': 0.5199044291363206} | train loss {'Reaction outcome loss': 0.5072330344529425, 'Total loss': 0.5072330344529425}
2022-12-05 22:41:48,554 INFO:     Found new best model at epoch 60
2022-12-05 22:41:48,554 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:48,554 INFO:     Epoch: 61
2022-12-05 22:41:49,247 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5283642376578132, 'Total loss': 0.5283642376578132} | train loss {'Reaction outcome loss': 0.5106264878308675, 'Total loss': 0.5106264878308675}
2022-12-05 22:41:49,247 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:49,247 INFO:     Epoch: 62
2022-12-05 22:41:49,941 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.564777075551277, 'Total loss': 0.564777075551277} | train loss {'Reaction outcome loss': 0.5105820449038607, 'Total loss': 0.5105820449038607}
2022-12-05 22:41:49,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:49,941 INFO:     Epoch: 63
2022-12-05 22:41:50,640 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5416009550870851, 'Total loss': 0.5416009550870851} | train loss {'Reaction outcome loss': 0.5053439023064785, 'Total loss': 0.5053439023064785}
2022-12-05 22:41:50,640 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:50,640 INFO:     Epoch: 64
2022-12-05 22:41:51,339 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5556813007177308, 'Total loss': 0.5556813007177308} | train loss {'Reaction outcome loss': 0.50851686078994, 'Total loss': 0.50851686078994}
2022-12-05 22:41:51,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:51,339 INFO:     Epoch: 65
2022-12-05 22:41:52,037 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.517864290364953, 'Total loss': 0.517864290364953} | train loss {'Reaction outcome loss': 0.5075234980246083, 'Total loss': 0.5075234980246083}
2022-12-05 22:41:52,037 INFO:     Found new best model at epoch 65
2022-12-05 22:41:52,038 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:52,038 INFO:     Epoch: 66
2022-12-05 22:41:52,733 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5418729705865993, 'Total loss': 0.5418729705865993} | train loss {'Reaction outcome loss': 0.5040643723895315, 'Total loss': 0.5040643723895315}
2022-12-05 22:41:52,733 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:52,733 INFO:     Epoch: 67
2022-12-05 22:41:53,430 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5367567192676456, 'Total loss': 0.5367567192676456} | train loss {'Reaction outcome loss': 0.5093152650067063, 'Total loss': 0.5093152650067063}
2022-12-05 22:41:53,430 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:53,430 INFO:     Epoch: 68
2022-12-05 22:41:54,128 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5185874114895976, 'Total loss': 0.5185874114895976} | train loss {'Reaction outcome loss': 0.5084182278665362, 'Total loss': 0.5084182278665362}
2022-12-05 22:41:54,128 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:54,128 INFO:     Epoch: 69
2022-12-05 22:41:54,825 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5351224260967832, 'Total loss': 0.5351224260967832} | train loss {'Reaction outcome loss': 0.5049904021510824, 'Total loss': 0.5049904021510824}
2022-12-05 22:41:54,825 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:54,826 INFO:     Epoch: 70
2022-12-05 22:41:55,520 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5519129263107166, 'Total loss': 0.5519129263107166} | train loss {'Reaction outcome loss': 0.5023520118022551, 'Total loss': 0.5023520118022551}
2022-12-05 22:41:55,520 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:55,520 INFO:     Epoch: 71
2022-12-05 22:41:56,218 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5328864829484806, 'Total loss': 0.5328864829484806} | train loss {'Reaction outcome loss': 0.5025376304984093, 'Total loss': 0.5025376304984093}
2022-12-05 22:41:56,218 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:56,218 INFO:     Epoch: 72
2022-12-05 22:41:56,915 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5125718712806702, 'Total loss': 0.5125718712806702} | train loss {'Reaction outcome loss': 0.5044240590917771, 'Total loss': 0.5044240590917771}
2022-12-05 22:41:56,915 INFO:     Found new best model at epoch 72
2022-12-05 22:41:56,916 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:56,916 INFO:     Epoch: 73
2022-12-05 22:41:57,616 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5732917459898217, 'Total loss': 0.5732917459898217} | train loss {'Reaction outcome loss': 0.49646257078389594, 'Total loss': 0.49646257078389594}
2022-12-05 22:41:57,616 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:57,616 INFO:     Epoch: 74
2022-12-05 22:41:58,314 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5571614749902902, 'Total loss': 0.5571614749902902} | train loss {'Reaction outcome loss': 0.5000987529266075, 'Total loss': 0.5000987529266075}
2022-12-05 22:41:58,315 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:58,315 INFO:     Epoch: 75
2022-12-05 22:41:59,016 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5299208885015443, 'Total loss': 0.5299208885015443} | train loss {'Reaction outcome loss': 0.49808177498520395, 'Total loss': 0.49808177498520395}
2022-12-05 22:41:59,016 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:59,016 INFO:     Epoch: 76
2022-12-05 22:41:59,714 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5320976196333419, 'Total loss': 0.5320976196333419} | train loss {'Reaction outcome loss': 0.516669649447574, 'Total loss': 0.516669649447574}
2022-12-05 22:41:59,714 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:41:59,714 INFO:     Epoch: 77
2022-12-05 22:42:00,410 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.525945650630219, 'Total loss': 0.525945650630219} | train loss {'Reaction outcome loss': 0.5105456954143086, 'Total loss': 0.5105456954143086}
2022-12-05 22:42:00,410 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:00,410 INFO:     Epoch: 78
2022-12-05 22:42:01,106 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4943225948616516, 'Total loss': 0.4943225948616516} | train loss {'Reaction outcome loss': 0.5063743844750475, 'Total loss': 0.5063743844750475}
2022-12-05 22:42:01,106 INFO:     Found new best model at epoch 78
2022-12-05 22:42:01,107 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:01,107 INFO:     Epoch: 79
2022-12-05 22:42:01,805 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5981565554474675, 'Total loss': 0.5981565554474675} | train loss {'Reaction outcome loss': 0.4977465743412737, 'Total loss': 0.4977465743412737}
2022-12-05 22:42:01,805 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:01,805 INFO:     Epoch: 80
2022-12-05 22:42:02,507 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5400661895441454, 'Total loss': 0.5400661895441454} | train loss {'Reaction outcome loss': 0.5004927701942745, 'Total loss': 0.5004927701942745}
2022-12-05 22:42:02,507 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:02,507 INFO:     Epoch: 81
2022-12-05 22:42:03,204 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5675681943810263, 'Total loss': 0.5675681943810263} | train loss {'Reaction outcome loss': 0.5130434533978094, 'Total loss': 0.5130434533978094}
2022-12-05 22:42:03,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:03,205 INFO:     Epoch: 82
2022-12-05 22:42:03,901 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.561915724776512, 'Total loss': 0.561915724776512} | train loss {'Reaction outcome loss': 0.5024495202376217, 'Total loss': 0.5024495202376217}
2022-12-05 22:42:03,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:03,902 INFO:     Epoch: 83
2022-12-05 22:42:04,598 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5494787408862003, 'Total loss': 0.5494787408862003} | train loss {'Reaction outcome loss': 0.5008838620097911, 'Total loss': 0.5008838620097911}
2022-12-05 22:42:04,598 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:04,599 INFO:     Epoch: 84
2022-12-05 22:42:05,295 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5378277800803961, 'Total loss': 0.5378277800803961} | train loss {'Reaction outcome loss': 0.49732684912007363, 'Total loss': 0.49732684912007363}
2022-12-05 22:42:05,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:05,296 INFO:     Epoch: 85
2022-12-05 22:42:05,993 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5378697864538016, 'Total loss': 0.5378697864538016} | train loss {'Reaction outcome loss': 0.5097856191826649, 'Total loss': 0.5097856191826649}
2022-12-05 22:42:05,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:05,993 INFO:     Epoch: 86
2022-12-05 22:42:06,692 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5461792710215546, 'Total loss': 0.5461792710215546} | train loss {'Reaction outcome loss': 0.5126714854821807, 'Total loss': 0.5126714854821807}
2022-12-05 22:42:06,692 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:06,692 INFO:     Epoch: 87
2022-12-05 22:42:07,390 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6006429749865865, 'Total loss': 0.6006429749865865} | train loss {'Reaction outcome loss': 0.49870474935799347, 'Total loss': 0.49870474935799347}
2022-12-05 22:42:07,390 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:07,390 INFO:     Epoch: 88
2022-12-05 22:42:08,088 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5674735377001208, 'Total loss': 0.5674735377001208} | train loss {'Reaction outcome loss': 0.5154961511248448, 'Total loss': 0.5154961511248448}
2022-12-05 22:42:08,088 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:08,088 INFO:     Epoch: 89
2022-12-05 22:42:08,786 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5742772027503612, 'Total loss': 0.5742772027503612} | train loss {'Reaction outcome loss': 0.5064794716776394, 'Total loss': 0.5064794716776394}
2022-12-05 22:42:08,786 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:08,786 INFO:     Epoch: 90
2022-12-05 22:42:09,488 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5839587186658105, 'Total loss': 0.5839587186658105} | train loss {'Reaction outcome loss': 0.5034390719699078, 'Total loss': 0.5034390719699078}
2022-12-05 22:42:09,489 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:09,489 INFO:     Epoch: 91
2022-12-05 22:42:10,193 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5291868534892105, 'Total loss': 0.5291868534892105} | train loss {'Reaction outcome loss': 0.5044568298292942, 'Total loss': 0.5044568298292942}
2022-12-05 22:42:10,194 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:10,194 INFO:     Epoch: 92
2022-12-05 22:42:10,896 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5408549156299857, 'Total loss': 0.5408549156299857} | train loss {'Reaction outcome loss': 0.5055081498061047, 'Total loss': 0.5055081498061047}
2022-12-05 22:42:10,896 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:10,897 INFO:     Epoch: 93
2022-12-05 22:42:11,599 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5323340768037841, 'Total loss': 0.5323340768037841} | train loss {'Reaction outcome loss': 0.5047166289486846, 'Total loss': 0.5047166289486846}
2022-12-05 22:42:11,599 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:11,599 INFO:     Epoch: 94
2022-12-05 22:42:12,303 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.533632718546446, 'Total loss': 0.533632718546446} | train loss {'Reaction outcome loss': 0.5027504604248727, 'Total loss': 0.5027504604248727}
2022-12-05 22:42:12,303 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:12,303 INFO:     Epoch: 95
2022-12-05 22:42:13,004 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5330132897510085, 'Total loss': 0.5330132897510085} | train loss {'Reaction outcome loss': 0.5011974046709108, 'Total loss': 0.5011974046709108}
2022-12-05 22:42:13,004 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:13,004 INFO:     Epoch: 96
2022-12-05 22:42:13,705 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5502358023510423, 'Total loss': 0.5502358023510423} | train loss {'Reaction outcome loss': 0.5105580784014014, 'Total loss': 0.5105580784014014}
2022-12-05 22:42:13,705 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:13,706 INFO:     Epoch: 97
2022-12-05 22:42:14,409 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5611259472924609, 'Total loss': 0.5611259472924609} | train loss {'Reaction outcome loss': 0.5103775588948218, 'Total loss': 0.5103775588948218}
2022-12-05 22:42:14,409 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:14,409 INFO:     Epoch: 98
2022-12-05 22:42:15,113 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5492214182781618, 'Total loss': 0.5492214182781618} | train loss {'Reaction outcome loss': 0.5052804655899279, 'Total loss': 0.5052804655899279}
2022-12-05 22:42:15,113 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:15,113 INFO:     Epoch: 99
2022-12-05 22:42:15,813 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5886985929899438, 'Total loss': 0.5886985929899438} | train loss {'Reaction outcome loss': 0.5039110108293959, 'Total loss': 0.5039110108293959}
2022-12-05 22:42:15,813 INFO:     Best model found after epoch 79 of 100.
2022-12-05 22:42:15,813 INFO:   Done with stage: TRAINING
2022-12-05 22:42:15,813 INFO:   Starting stage: EVALUATION
2022-12-05 22:42:15,948 INFO:   Done with stage: EVALUATION
2022-12-05 22:42:15,948 INFO:   Leaving out SEQ value Fold_1
2022-12-05 22:42:15,960 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:42:15,961 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:42:16,612 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:42:16,613 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:42:16,683 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:42:16,683 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:42:16,683 INFO:     No hyperparam tuning for this model
2022-12-05 22:42:16,683 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:42:16,684 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:42:16,684 INFO:     None feature selector for col prot
2022-12-05 22:42:16,684 INFO:     None feature selector for col prot
2022-12-05 22:42:16,684 INFO:     None feature selector for col prot
2022-12-05 22:42:16,685 INFO:     None feature selector for col chem
2022-12-05 22:42:16,685 INFO:     None feature selector for col chem
2022-12-05 22:42:16,685 INFO:     None feature selector for col chem
2022-12-05 22:42:16,685 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:42:16,685 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:42:16,687 INFO:     Number of params in model 215731
2022-12-05 22:42:16,690 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:42:16,690 INFO:   Starting stage: TRAINING
2022-12-05 22:42:16,747 INFO:     Val loss before train {'Reaction outcome loss': 1.0183002163063397, 'Total loss': 1.0183002163063397}
2022-12-05 22:42:16,747 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:16,747 INFO:     Epoch: 0
2022-12-05 22:42:17,454 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.827893043783578, 'Total loss': 0.827893043783578} | train loss {'Reaction outcome loss': 0.798599673548208, 'Total loss': 0.798599673548208}
2022-12-05 22:42:17,454 INFO:     Found new best model at epoch 0
2022-12-05 22:42:17,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:17,455 INFO:     Epoch: 1
2022-12-05 22:42:18,169 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7118620296770876, 'Total loss': 0.7118620296770876} | train loss {'Reaction outcome loss': 0.6571451312134623, 'Total loss': 0.6571451312134623}
2022-12-05 22:42:18,169 INFO:     Found new best model at epoch 1
2022-12-05 22:42:18,170 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:18,170 INFO:     Epoch: 2
2022-12-05 22:42:18,875 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6693744666197083, 'Total loss': 0.6693744666197083} | train loss {'Reaction outcome loss': 0.6160227674463017, 'Total loss': 0.6160227674463017}
2022-12-05 22:42:18,875 INFO:     Found new best model at epoch 2
2022-12-05 22:42:18,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:18,876 INFO:     Epoch: 3
2022-12-05 22:42:19,579 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6985828453166918, 'Total loss': 0.6985828453166918} | train loss {'Reaction outcome loss': 0.5836793127571523, 'Total loss': 0.5836793127571523}
2022-12-05 22:42:19,579 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:19,579 INFO:     Epoch: 4
2022-12-05 22:42:20,282 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6285295019095595, 'Total loss': 0.6285295019095595} | train loss {'Reaction outcome loss': 0.5716556320607904, 'Total loss': 0.5716556320607904}
2022-12-05 22:42:20,282 INFO:     Found new best model at epoch 4
2022-12-05 22:42:20,283 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:20,283 INFO:     Epoch: 5
2022-12-05 22:42:20,992 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6044394648210569, 'Total loss': 0.6044394648210569} | train loss {'Reaction outcome loss': 0.569534349115754, 'Total loss': 0.569534349115754}
2022-12-05 22:42:20,992 INFO:     Found new best model at epoch 5
2022-12-05 22:42:20,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:20,993 INFO:     Epoch: 6
2022-12-05 22:42:21,696 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6294084245508368, 'Total loss': 0.6294084245508368} | train loss {'Reaction outcome loss': 0.5792175102451069, 'Total loss': 0.5792175102451069}
2022-12-05 22:42:21,697 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:21,697 INFO:     Epoch: 7
2022-12-05 22:42:22,404 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.644796106625687, 'Total loss': 0.644796106625687} | train loss {'Reaction outcome loss': 0.5635296506920324, 'Total loss': 0.5635296506920324}
2022-12-05 22:42:22,405 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:22,405 INFO:     Epoch: 8
2022-12-05 22:42:23,113 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6188943657008085, 'Total loss': 0.6188943657008085} | train loss {'Reaction outcome loss': 0.5485391675943305, 'Total loss': 0.5485391675943305}
2022-12-05 22:42:23,113 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:23,113 INFO:     Epoch: 9
2022-12-05 22:42:23,821 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5975181853229349, 'Total loss': 0.5975181853229349} | train loss {'Reaction outcome loss': 0.5450651732533567, 'Total loss': 0.5450651732533567}
2022-12-05 22:42:23,821 INFO:     Found new best model at epoch 9
2022-12-05 22:42:23,821 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:23,822 INFO:     Epoch: 10
2022-12-05 22:42:24,525 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5826188610358671, 'Total loss': 0.5826188610358671} | train loss {'Reaction outcome loss': 0.5400031201752574, 'Total loss': 0.5400031201752574}
2022-12-05 22:42:24,526 INFO:     Found new best model at epoch 10
2022-12-05 22:42:24,526 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:24,526 INFO:     Epoch: 11
2022-12-05 22:42:25,229 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.600748052651232, 'Total loss': 0.600748052651232} | train loss {'Reaction outcome loss': 0.53578442371703, 'Total loss': 0.53578442371703}
2022-12-05 22:42:25,229 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:25,229 INFO:     Epoch: 12
2022-12-05 22:42:25,932 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5750771137801084, 'Total loss': 0.5750771137801084} | train loss {'Reaction outcome loss': 0.5281957640700977, 'Total loss': 0.5281957640700977}
2022-12-05 22:42:25,933 INFO:     Found new best model at epoch 12
2022-12-05 22:42:25,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:25,933 INFO:     Epoch: 13
2022-12-05 22:42:26,636 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.6242056665095416, 'Total loss': 0.6242056665095416} | train loss {'Reaction outcome loss': 0.5318021431625614, 'Total loss': 0.5318021431625614}
2022-12-05 22:42:26,636 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:26,636 INFO:     Epoch: 14
2022-12-05 22:42:27,338 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.6029800684614615, 'Total loss': 0.6029800684614615} | train loss {'Reaction outcome loss': 0.5357537189355264, 'Total loss': 0.5357537189355264}
2022-12-05 22:42:27,338 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:27,338 INFO:     Epoch: 15
2022-12-05 22:42:28,042 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5853790200569413, 'Total loss': 0.5853790200569413} | train loss {'Reaction outcome loss': 0.528705901157126, 'Total loss': 0.528705901157126}
2022-12-05 22:42:28,042 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:28,042 INFO:     Epoch: 16
2022-12-05 22:42:28,752 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5792893970554526, 'Total loss': 0.5792893970554526} | train loss {'Reaction outcome loss': 0.5283586936983985, 'Total loss': 0.5283586936983985}
2022-12-05 22:42:28,752 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:28,753 INFO:     Epoch: 17
2022-12-05 22:42:29,455 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.597015571187843, 'Total loss': 0.597015571187843} | train loss {'Reaction outcome loss': 0.5278682989871454, 'Total loss': 0.5278682989871454}
2022-12-05 22:42:29,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:29,455 INFO:     Epoch: 18
2022-12-05 22:42:30,158 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5829328508539633, 'Total loss': 0.5829328508539633} | train loss {'Reaction outcome loss': 0.5254910529670325, 'Total loss': 0.5254910529670325}
2022-12-05 22:42:30,158 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:30,158 INFO:     Epoch: 19
2022-12-05 22:42:30,862 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5984700274738398, 'Total loss': 0.5984700274738398} | train loss {'Reaction outcome loss': 0.5350609856095874, 'Total loss': 0.5350609856095874}
2022-12-05 22:42:30,862 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:30,862 INFO:     Epoch: 20
2022-12-05 22:42:31,571 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5752979483116757, 'Total loss': 0.5752979483116757} | train loss {'Reaction outcome loss': 0.5228765302824105, 'Total loss': 0.5228765302824105}
2022-12-05 22:42:31,571 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:31,571 INFO:     Epoch: 21
2022-12-05 22:42:32,274 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5955225642431866, 'Total loss': 0.5955225642431866} | train loss {'Reaction outcome loss': 0.5314642217477806, 'Total loss': 0.5314642217477806}
2022-12-05 22:42:32,274 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:32,275 INFO:     Epoch: 22
2022-12-05 22:42:32,978 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5640222613107074, 'Total loss': 0.5640222613107074} | train loss {'Reaction outcome loss': 0.5217415273249874, 'Total loss': 0.5217415273249874}
2022-12-05 22:42:32,978 INFO:     Found new best model at epoch 22
2022-12-05 22:42:32,979 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:32,979 INFO:     Epoch: 23
2022-12-05 22:42:33,681 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.6122012612494555, 'Total loss': 0.6122012612494555} | train loss {'Reaction outcome loss': 0.5199212232220028, 'Total loss': 0.5199212232220028}
2022-12-05 22:42:33,681 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:33,681 INFO:     Epoch: 24
2022-12-05 22:42:34,388 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.607045863839713, 'Total loss': 0.607045863839713} | train loss {'Reaction outcome loss': 0.5394425513863805, 'Total loss': 0.5394425513863805}
2022-12-05 22:42:34,388 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:34,388 INFO:     Epoch: 25
2022-12-05 22:42:35,092 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5914750038222834, 'Total loss': 0.5914750038222834} | train loss {'Reaction outcome loss': 0.5159051880421426, 'Total loss': 0.5159051880421426}
2022-12-05 22:42:35,092 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:35,092 INFO:     Epoch: 26
2022-12-05 22:42:35,796 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5911237319762056, 'Total loss': 0.5911237319762056} | train loss {'Reaction outcome loss': 0.5189392830316837, 'Total loss': 0.5189392830316837}
2022-12-05 22:42:35,796 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:35,796 INFO:     Epoch: 27
2022-12-05 22:42:36,501 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.6045181988315149, 'Total loss': 0.6045181988315149} | train loss {'Reaction outcome loss': 0.5155635874281045, 'Total loss': 0.5155635874281045}
2022-12-05 22:42:36,501 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:36,501 INFO:     Epoch: 28
2022-12-05 22:42:37,204 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5692699118094011, 'Total loss': 0.5692699118094011} | train loss {'Reaction outcome loss': 0.5172972140102251, 'Total loss': 0.5172972140102251}
2022-12-05 22:42:37,204 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:37,205 INFO:     Epoch: 29
2022-12-05 22:42:37,911 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5713136765089902, 'Total loss': 0.5713136765089902} | train loss {'Reaction outcome loss': 0.5264078167527311, 'Total loss': 0.5264078167527311}
2022-12-05 22:42:37,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:37,911 INFO:     Epoch: 30
2022-12-05 22:42:38,618 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.553353029218587, 'Total loss': 0.553353029218587} | train loss {'Reaction outcome loss': 0.522684212308377, 'Total loss': 0.522684212308377}
2022-12-05 22:42:38,618 INFO:     Found new best model at epoch 30
2022-12-05 22:42:38,619 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:38,619 INFO:     Epoch: 31
2022-12-05 22:42:39,325 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5856753973798319, 'Total loss': 0.5856753973798319} | train loss {'Reaction outcome loss': 0.5184593922062682, 'Total loss': 0.5184593922062682}
2022-12-05 22:42:39,325 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:39,326 INFO:     Epoch: 32
2022-12-05 22:42:40,030 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.6643826060674407, 'Total loss': 0.6643826060674407} | train loss {'Reaction outcome loss': 0.5196919466561152, 'Total loss': 0.5196919466561152}
2022-12-05 22:42:40,030 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:40,030 INFO:     Epoch: 33
2022-12-05 22:42:40,734 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5839936191385443, 'Total loss': 0.5839936191385443} | train loss {'Reaction outcome loss': 0.5426805140639124, 'Total loss': 0.5426805140639124}
2022-12-05 22:42:40,734 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:40,734 INFO:     Epoch: 34
2022-12-05 22:42:41,440 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5791433561931957, 'Total loss': 0.5791433561931957} | train loss {'Reaction outcome loss': 0.5331124638014959, 'Total loss': 0.5331124638014959}
2022-12-05 22:42:41,441 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:41,441 INFO:     Epoch: 35
2022-12-05 22:42:42,146 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5596713630313223, 'Total loss': 0.5596713630313223} | train loss {'Reaction outcome loss': 0.5159436975745296, 'Total loss': 0.5159436975745296}
2022-12-05 22:42:42,147 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:42,147 INFO:     Epoch: 36
2022-12-05 22:42:42,851 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.6124857786026868, 'Total loss': 0.6124857786026868} | train loss {'Reaction outcome loss': 0.5137259012412446, 'Total loss': 0.5137259012412446}
2022-12-05 22:42:42,851 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:42,851 INFO:     Epoch: 37
2022-12-05 22:42:43,558 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5886461165818301, 'Total loss': 0.5886461165818301} | train loss {'Reaction outcome loss': 0.5222144211955398, 'Total loss': 0.5222144211955398}
2022-12-05 22:42:43,558 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:43,558 INFO:     Epoch: 38
2022-12-05 22:42:44,262 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.578783044083552, 'Total loss': 0.578783044083552} | train loss {'Reaction outcome loss': 0.5255562519788486, 'Total loss': 0.5255562519788486}
2022-12-05 22:42:44,262 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:44,262 INFO:     Epoch: 39
2022-12-05 22:42:44,965 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.558356100185351, 'Total loss': 0.558356100185351} | train loss {'Reaction outcome loss': 0.5231617047236516, 'Total loss': 0.5231617047236516}
2022-12-05 22:42:44,965 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:44,965 INFO:     Epoch: 40
2022-12-05 22:42:45,668 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5811835859309543, 'Total loss': 0.5811835859309543} | train loss {'Reaction outcome loss': 0.5212997523483326, 'Total loss': 0.5212997523483326}
2022-12-05 22:42:45,669 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:45,669 INFO:     Epoch: 41
2022-12-05 22:42:46,376 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5835594971748915, 'Total loss': 0.5835594971748915} | train loss {'Reaction outcome loss': 0.5217590282184754, 'Total loss': 0.5217590282184754}
2022-12-05 22:42:46,376 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:46,377 INFO:     Epoch: 42
2022-12-05 22:42:47,082 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5982947112484411, 'Total loss': 0.5982947112484411} | train loss {'Reaction outcome loss': 0.5178204719354267, 'Total loss': 0.5178204719354267}
2022-12-05 22:42:47,082 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:47,082 INFO:     Epoch: 43
2022-12-05 22:42:47,787 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5766535099934448, 'Total loss': 0.5766535099934448} | train loss {'Reaction outcome loss': 0.528948384981889, 'Total loss': 0.528948384981889}
2022-12-05 22:42:47,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:47,788 INFO:     Epoch: 44
2022-12-05 22:42:48,494 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.6005534048784863, 'Total loss': 0.6005534048784863} | train loss {'Reaction outcome loss': 0.5182941946302831, 'Total loss': 0.5182941946302831}
2022-12-05 22:42:48,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:48,494 INFO:     Epoch: 45
2022-12-05 22:42:49,198 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5619672943245281, 'Total loss': 0.5619672943245281} | train loss {'Reaction outcome loss': 0.5230215830117585, 'Total loss': 0.5230215830117585}
2022-12-05 22:42:49,198 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:49,198 INFO:     Epoch: 46
2022-12-05 22:42:49,904 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5651525794105097, 'Total loss': 0.5651525794105097} | train loss {'Reaction outcome loss': 0.5145845310460881, 'Total loss': 0.5145845310460881}
2022-12-05 22:42:49,904 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:49,905 INFO:     Epoch: 47
2022-12-05 22:42:50,611 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.6153416484594345, 'Total loss': 0.6153416484594345} | train loss {'Reaction outcome loss': 0.5195117762334917, 'Total loss': 0.5195117762334917}
2022-12-05 22:42:50,611 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:50,611 INFO:     Epoch: 48
2022-12-05 22:42:51,315 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5593419196930799, 'Total loss': 0.5593419196930799} | train loss {'Reaction outcome loss': 0.5207650230119103, 'Total loss': 0.5207650230119103}
2022-12-05 22:42:51,315 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:51,315 INFO:     Epoch: 49
2022-12-05 22:42:52,019 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.6204198849472132, 'Total loss': 0.6204198849472132} | train loss {'Reaction outcome loss': 0.5213526424005447, 'Total loss': 0.5213526424005447}
2022-12-05 22:42:52,019 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:52,019 INFO:     Epoch: 50
2022-12-05 22:42:52,727 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5801532417535782, 'Total loss': 0.5801532417535782} | train loss {'Reaction outcome loss': 0.5439783175992459, 'Total loss': 0.5439783175992459}
2022-12-05 22:42:52,727 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:52,727 INFO:     Epoch: 51
2022-12-05 22:42:53,434 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5696242289109663, 'Total loss': 0.5696242289109663} | train loss {'Reaction outcome loss': 0.509853107243897, 'Total loss': 0.509853107243897}
2022-12-05 22:42:53,434 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:53,434 INFO:     Epoch: 52
2022-12-05 22:42:54,142 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5849853185090151, 'Total loss': 0.5849853185090151} | train loss {'Reaction outcome loss': 0.5190252476496252, 'Total loss': 0.5190252476496252}
2022-12-05 22:42:54,142 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:54,142 INFO:     Epoch: 53
2022-12-05 22:42:54,854 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5775538628751581, 'Total loss': 0.5775538628751581} | train loss {'Reaction outcome loss': 0.516404605647813, 'Total loss': 0.516404605647813}
2022-12-05 22:42:54,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:54,855 INFO:     Epoch: 54
2022-12-05 22:42:55,559 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.6756706034595316, 'Total loss': 0.6756706034595316} | train loss {'Reaction outcome loss': 0.5149067934104788, 'Total loss': 0.5149067934104788}
2022-12-05 22:42:55,559 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:55,559 INFO:     Epoch: 55
2022-12-05 22:42:56,263 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.638379726220261, 'Total loss': 0.638379726220261} | train loss {'Reaction outcome loss': 0.5239399159968141, 'Total loss': 0.5239399159968141}
2022-12-05 22:42:56,264 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:56,264 INFO:     Epoch: 56
2022-12-05 22:42:56,972 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5790774104270068, 'Total loss': 0.5790774104270068} | train loss {'Reaction outcome loss': 0.5227965964117514, 'Total loss': 0.5227965964117514}
2022-12-05 22:42:56,972 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:56,972 INFO:     Epoch: 57
2022-12-05 22:42:57,679 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.6178448403423483, 'Total loss': 0.6178448403423483} | train loss {'Reaction outcome loss': 0.5142129316986331, 'Total loss': 0.5142129316986331}
2022-12-05 22:42:57,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:57,679 INFO:     Epoch: 58
2022-12-05 22:42:58,383 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.619711996479468, 'Total loss': 0.619711996479468} | train loss {'Reaction outcome loss': 0.511232714481682, 'Total loss': 0.511232714481682}
2022-12-05 22:42:58,383 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:58,383 INFO:     Epoch: 59
2022-12-05 22:42:59,087 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5679164549166505, 'Total loss': 0.5679164549166505} | train loss {'Reaction outcome loss': 0.5310057760008916, 'Total loss': 0.5310057760008916}
2022-12-05 22:42:59,087 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:59,087 INFO:     Epoch: 60
2022-12-05 22:42:59,791 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.6134462532672015, 'Total loss': 0.6134462532672015} | train loss {'Reaction outcome loss': 0.5117370071274187, 'Total loss': 0.5117370071274187}
2022-12-05 22:42:59,792 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:42:59,792 INFO:     Epoch: 61
2022-12-05 22:43:00,501 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5644818944009867, 'Total loss': 0.5644818944009867} | train loss {'Reaction outcome loss': 0.5171739978466922, 'Total loss': 0.5171739978466922}
2022-12-05 22:43:00,502 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:00,502 INFO:     Epoch: 62
2022-12-05 22:43:01,208 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5930381268262863, 'Total loss': 0.5930381268262863} | train loss {'Reaction outcome loss': 0.5170828406868676, 'Total loss': 0.5170828406868676}
2022-12-05 22:43:01,208 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:01,208 INFO:     Epoch: 63
2022-12-05 22:43:01,914 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5839985439723189, 'Total loss': 0.5839985439723189} | train loss {'Reaction outcome loss': 0.5231498217413783, 'Total loss': 0.5231498217413783}
2022-12-05 22:43:01,914 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:01,914 INFO:     Epoch: 64
2022-12-05 22:43:02,621 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5635496499863538, 'Total loss': 0.5635496499863538} | train loss {'Reaction outcome loss': 0.5197578348852845, 'Total loss': 0.5197578348852845}
2022-12-05 22:43:02,621 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:02,621 INFO:     Epoch: 65
2022-12-05 22:43:03,325 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.6018174527720972, 'Total loss': 0.6018174527720972} | train loss {'Reaction outcome loss': 0.5130789763490228, 'Total loss': 0.5130789763490228}
2022-12-05 22:43:03,325 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:03,325 INFO:     Epoch: 66
2022-12-05 22:43:04,029 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5856323563917116, 'Total loss': 0.5856323563917116} | train loss {'Reaction outcome loss': 0.5226602961539257, 'Total loss': 0.5226602961539257}
2022-12-05 22:43:04,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:04,029 INFO:     Epoch: 67
2022-12-05 22:43:04,736 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5623110434548422, 'Total loss': 0.5623110434548422} | train loss {'Reaction outcome loss': 0.5397148380274714, 'Total loss': 0.5397148380274714}
2022-12-05 22:43:04,736 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:04,737 INFO:     Epoch: 68
2022-12-05 22:43:05,446 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.6729523180560633, 'Total loss': 0.6729523180560633} | train loss {'Reaction outcome loss': 0.5226813600764342, 'Total loss': 0.5226813600764342}
2022-12-05 22:43:05,446 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:05,446 INFO:     Epoch: 69
2022-12-05 22:43:06,151 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6307108544490554, 'Total loss': 0.6307108544490554} | train loss {'Reaction outcome loss': 0.5207549063300314, 'Total loss': 0.5207549063300314}
2022-12-05 22:43:06,151 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:06,151 INFO:     Epoch: 70
2022-12-05 22:43:06,859 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.6051105978814039, 'Total loss': 0.6051105978814039} | train loss {'Reaction outcome loss': 0.5210467704273911, 'Total loss': 0.5210467704273911}
2022-12-05 22:43:06,859 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:06,859 INFO:     Epoch: 71
2022-12-05 22:43:07,562 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6144356280565262, 'Total loss': 0.6144356280565262} | train loss {'Reaction outcome loss': 0.5343283861875534, 'Total loss': 0.5343283861875534}
2022-12-05 22:43:07,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:07,563 INFO:     Epoch: 72
2022-12-05 22:43:08,268 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6144886098124764, 'Total loss': 0.6144886098124764} | train loss {'Reaction outcome loss': 0.5246491876208348, 'Total loss': 0.5246491876208348}
2022-12-05 22:43:08,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:08,268 INFO:     Epoch: 73
2022-12-05 22:43:08,977 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5867458879947662, 'Total loss': 0.5867458879947662} | train loss {'Reaction outcome loss': 0.5197143471434049, 'Total loss': 0.5197143471434049}
2022-12-05 22:43:08,977 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:08,977 INFO:     Epoch: 74
2022-12-05 22:43:09,681 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5963206853378903, 'Total loss': 0.5963206853378903} | train loss {'Reaction outcome loss': 0.5193077956254666, 'Total loss': 0.5193077956254666}
2022-12-05 22:43:09,682 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:09,682 INFO:     Epoch: 75
2022-12-05 22:43:10,386 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5705437687310305, 'Total loss': 0.5705437687310305} | train loss {'Reaction outcome loss': 0.514241115676488, 'Total loss': 0.514241115676488}
2022-12-05 22:43:10,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:10,386 INFO:     Epoch: 76
2022-12-05 22:43:11,098 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5489382527091287, 'Total loss': 0.5489382527091287} | train loss {'Reaction outcome loss': 0.5168448415724373, 'Total loss': 0.5168448415724373}
2022-12-05 22:43:11,098 INFO:     Found new best model at epoch 76
2022-12-05 22:43:11,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:11,099 INFO:     Epoch: 77
2022-12-05 22:43:11,802 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.6044660071757707, 'Total loss': 0.6044660071757707} | train loss {'Reaction outcome loss': 0.5113028990489389, 'Total loss': 0.5113028990489389}
2022-12-05 22:43:11,802 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:11,802 INFO:     Epoch: 78
2022-12-05 22:43:12,505 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6741007200696252, 'Total loss': 0.6741007200696252} | train loss {'Reaction outcome loss': 0.5216518379898689, 'Total loss': 0.5216518379898689}
2022-12-05 22:43:12,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:12,506 INFO:     Epoch: 79
2022-12-05 22:43:13,214 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5659536549990828, 'Total loss': 0.5659536549990828} | train loss {'Reaction outcome loss': 0.5194574506417943, 'Total loss': 0.5194574506417943}
2022-12-05 22:43:13,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:13,215 INFO:     Epoch: 80
2022-12-05 22:43:13,922 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6012797856872732, 'Total loss': 0.6012797856872732} | train loss {'Reaction outcome loss': 0.5190164749831082, 'Total loss': 0.5190164749831082}
2022-12-05 22:43:13,922 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:13,922 INFO:     Epoch: 81
2022-12-05 22:43:14,626 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5697463154792786, 'Total loss': 0.5697463154792786} | train loss {'Reaction outcome loss': 0.5109868907117048, 'Total loss': 0.5109868907117048}
2022-12-05 22:43:14,626 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:14,626 INFO:     Epoch: 82
2022-12-05 22:43:15,329 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5931553129445423, 'Total loss': 0.5931553129445423} | train loss {'Reaction outcome loss': 0.5216875513676207, 'Total loss': 0.5216875513676207}
2022-12-05 22:43:15,329 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:15,329 INFO:     Epoch: 83
2022-12-05 22:43:16,035 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5630598135969855, 'Total loss': 0.5630598135969855} | train loss {'Reaction outcome loss': 0.5246949381673867, 'Total loss': 0.5246949381673867}
2022-12-05 22:43:16,036 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:16,036 INFO:     Epoch: 84
2022-12-05 22:43:16,741 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5656133537942712, 'Total loss': 0.5656133537942712} | train loss {'Reaction outcome loss': 0.5116518078426555, 'Total loss': 0.5116518078426555}
2022-12-05 22:43:16,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:16,741 INFO:     Epoch: 85
2022-12-05 22:43:17,444 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5630858012221076, 'Total loss': 0.5630858012221076} | train loss {'Reaction outcome loss': 0.5189117270065584, 'Total loss': 0.5189117270065584}
2022-12-05 22:43:17,445 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:17,445 INFO:     Epoch: 86
2022-12-05 22:43:18,148 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.593382207507437, 'Total loss': 0.593382207507437} | train loss {'Reaction outcome loss': 0.5144117271248628, 'Total loss': 0.5144117271248628}
2022-12-05 22:43:18,149 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:18,149 INFO:     Epoch: 87
2022-12-05 22:43:18,856 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5747142129323699, 'Total loss': 0.5747142129323699} | train loss {'Reaction outcome loss': 0.5244413483963322, 'Total loss': 0.5244413483963322}
2022-12-05 22:43:18,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:18,857 INFO:     Epoch: 88
2022-12-05 22:43:19,560 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5864932990886949, 'Total loss': 0.5864932990886949} | train loss {'Reaction outcome loss': 0.523487336541477, 'Total loss': 0.523487336541477}
2022-12-05 22:43:19,561 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:19,561 INFO:     Epoch: 89
2022-12-05 22:43:20,268 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5957232381809842, 'Total loss': 0.5957232381809842} | train loss {'Reaction outcome loss': 0.5168705078875006, 'Total loss': 0.5168705078875006}
2022-12-05 22:43:20,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:20,268 INFO:     Epoch: 90
2022-12-05 22:43:20,975 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5717108330943368, 'Total loss': 0.5717108330943368} | train loss {'Reaction outcome loss': 0.5187578668086393, 'Total loss': 0.5187578668086393}
2022-12-05 22:43:20,976 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:20,976 INFO:     Epoch: 91
2022-12-05 22:43:21,679 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5679001462730494, 'Total loss': 0.5679001462730494} | train loss {'Reaction outcome loss': 0.5092860277146403, 'Total loss': 0.5092860277146403}
2022-12-05 22:43:21,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:21,679 INFO:     Epoch: 92
2022-12-05 22:43:22,385 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5786716904152523, 'Total loss': 0.5786716904152523} | train loss {'Reaction outcome loss': 0.5142870775239188, 'Total loss': 0.5142870775239188}
2022-12-05 22:43:22,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:22,386 INFO:     Epoch: 93
2022-12-05 22:43:23,090 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.582767244767059, 'Total loss': 0.582767244767059} | train loss {'Reaction outcome loss': 0.5106748107232546, 'Total loss': 0.5106748107232546}
2022-12-05 22:43:23,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:23,090 INFO:     Epoch: 94
2022-12-05 22:43:23,794 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5687236684289846, 'Total loss': 0.5687236684289846} | train loss {'Reaction outcome loss': 0.5112373816520579, 'Total loss': 0.5112373816520579}
2022-12-05 22:43:23,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:23,794 INFO:     Epoch: 95
2022-12-05 22:43:24,501 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6064548519524661, 'Total loss': 0.6064548519524661} | train loss {'Reaction outcome loss': 0.5189864316932585, 'Total loss': 0.5189864316932585}
2022-12-05 22:43:24,501 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:24,502 INFO:     Epoch: 96
2022-12-05 22:43:25,206 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5802360745993528, 'Total loss': 0.5802360745993528} | train loss {'Reaction outcome loss': 0.5169066451339104, 'Total loss': 0.5169066451339104}
2022-12-05 22:43:25,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:25,206 INFO:     Epoch: 97
2022-12-05 22:43:25,910 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5743012976917353, 'Total loss': 0.5743012976917353} | train loss {'Reaction outcome loss': 0.5113787840833126, 'Total loss': 0.5113787840833126}
2022-12-05 22:43:25,910 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:25,910 INFO:     Epoch: 98
2022-12-05 22:43:26,613 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5879553908651526, 'Total loss': 0.5879553908651526} | train loss {'Reaction outcome loss': 0.5100567895270552, 'Total loss': 0.5100567895270552}
2022-12-05 22:43:26,613 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:26,613 INFO:     Epoch: 99
2022-12-05 22:43:27,317 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5841871960596605, 'Total loss': 0.5841871960596605} | train loss {'Reaction outcome loss': 0.5175241205977043, 'Total loss': 0.5175241205977043}
2022-12-05 22:43:27,318 INFO:     Best model found after epoch 77 of 100.
2022-12-05 22:43:27,318 INFO:   Done with stage: TRAINING
2022-12-05 22:43:27,318 INFO:   Starting stage: EVALUATION
2022-12-05 22:43:27,441 INFO:   Done with stage: EVALUATION
2022-12-05 22:43:27,441 INFO:   Leaving out SEQ value Fold_2
2022-12-05 22:43:27,453 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:43:27,454 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:43:28,091 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:43:28,091 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:43:28,163 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:43:28,163 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:43:28,163 INFO:     No hyperparam tuning for this model
2022-12-05 22:43:28,163 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:43:28,163 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:43:28,164 INFO:     None feature selector for col prot
2022-12-05 22:43:28,164 INFO:     None feature selector for col prot
2022-12-05 22:43:28,164 INFO:     None feature selector for col prot
2022-12-05 22:43:28,164 INFO:     None feature selector for col chem
2022-12-05 22:43:28,164 INFO:     None feature selector for col chem
2022-12-05 22:43:28,164 INFO:     None feature selector for col chem
2022-12-05 22:43:28,165 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:43:28,165 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:43:28,166 INFO:     Number of params in model 215731
2022-12-05 22:43:28,169 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:43:28,169 INFO:   Starting stage: TRAINING
2022-12-05 22:43:28,227 INFO:     Val loss before train {'Reaction outcome loss': 0.9277906052090905, 'Total loss': 0.9277906052090905}
2022-12-05 22:43:28,227 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:28,227 INFO:     Epoch: 0
2022-12-05 22:43:28,927 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.661782600662925, 'Total loss': 0.661782600662925} | train loss {'Reaction outcome loss': 0.8196158208409134, 'Total loss': 0.8196158208409134}
2022-12-05 22:43:28,927 INFO:     Found new best model at epoch 0
2022-12-05 22:43:28,928 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:28,928 INFO:     Epoch: 1
2022-12-05 22:43:29,632 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6272687756202437, 'Total loss': 0.6272687756202437} | train loss {'Reaction outcome loss': 0.6758363228671405, 'Total loss': 0.6758363228671405}
2022-12-05 22:43:29,632 INFO:     Found new best model at epoch 1
2022-12-05 22:43:29,633 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:29,633 INFO:     Epoch: 2
2022-12-05 22:43:30,336 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.536533766172149, 'Total loss': 0.536533766172149} | train loss {'Reaction outcome loss': 0.6429198968167208, 'Total loss': 0.6429198968167208}
2022-12-05 22:43:30,336 INFO:     Found new best model at epoch 2
2022-12-05 22:43:30,336 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:30,336 INFO:     Epoch: 3
2022-12-05 22:43:31,039 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5439863083037463, 'Total loss': 0.5439863083037463} | train loss {'Reaction outcome loss': 0.6144285558437814, 'Total loss': 0.6144285558437814}
2022-12-05 22:43:31,040 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:31,040 INFO:     Epoch: 4
2022-12-05 22:43:31,739 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5332151676782153, 'Total loss': 0.5332151676782153} | train loss {'Reaction outcome loss': 0.601761502392438, 'Total loss': 0.601761502392438}
2022-12-05 22:43:31,740 INFO:     Found new best model at epoch 4
2022-12-05 22:43:31,740 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:31,740 INFO:     Epoch: 5
2022-12-05 22:43:32,444 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5340650007128716, 'Total loss': 0.5340650007128716} | train loss {'Reaction outcome loss': 0.5843390262248565, 'Total loss': 0.5843390262248565}
2022-12-05 22:43:32,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:32,444 INFO:     Epoch: 6
2022-12-05 22:43:33,144 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5797948038036173, 'Total loss': 0.5797948038036173} | train loss {'Reaction outcome loss': 0.5822829748903002, 'Total loss': 0.5822829748903002}
2022-12-05 22:43:33,144 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:33,144 INFO:     Epoch: 7
2022-12-05 22:43:33,844 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5106688744642518, 'Total loss': 0.5106688744642518} | train loss {'Reaction outcome loss': 0.5696264541270781, 'Total loss': 0.5696264541270781}
2022-12-05 22:43:33,844 INFO:     Found new best model at epoch 7
2022-12-05 22:43:33,845 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:33,845 INFO:     Epoch: 8
2022-12-05 22:43:34,547 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5113837539472363, 'Total loss': 0.5113837539472363} | train loss {'Reaction outcome loss': 0.5716808854317178, 'Total loss': 0.5716808854317178}
2022-12-05 22:43:34,547 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:34,548 INFO:     Epoch: 9
2022-12-05 22:43:35,250 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5171682529828765, 'Total loss': 0.5171682529828765} | train loss {'Reaction outcome loss': 0.562317349959393, 'Total loss': 0.562317349959393}
2022-12-05 22:43:35,250 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:35,250 INFO:     Epoch: 10
2022-12-05 22:43:35,950 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4815920482982289, 'Total loss': 0.4815920482982289} | train loss {'Reaction outcome loss': 0.563279694926982, 'Total loss': 0.563279694926982}
2022-12-05 22:43:35,951 INFO:     Found new best model at epoch 10
2022-12-05 22:43:35,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:35,951 INFO:     Epoch: 11
2022-12-05 22:43:36,654 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5492049144072966, 'Total loss': 0.5492049144072966} | train loss {'Reaction outcome loss': 0.551697946932851, 'Total loss': 0.551697946932851}
2022-12-05 22:43:36,654 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:36,654 INFO:     Epoch: 12
2022-12-05 22:43:37,355 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4832491102543744, 'Total loss': 0.4832491102543744} | train loss {'Reaction outcome loss': 0.5572474471768555, 'Total loss': 0.5572474471768555}
2022-12-05 22:43:37,355 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:37,356 INFO:     Epoch: 13
2022-12-05 22:43:38,057 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4715650183233348, 'Total loss': 0.4715650183233348} | train loss {'Reaction outcome loss': 0.5460611017382875, 'Total loss': 0.5460611017382875}
2022-12-05 22:43:38,057 INFO:     Found new best model at epoch 13
2022-12-05 22:43:38,058 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:38,058 INFO:     Epoch: 14
2022-12-05 22:43:38,765 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4858535260639407, 'Total loss': 0.4858535260639407} | train loss {'Reaction outcome loss': 0.5542443484067917, 'Total loss': 0.5542443484067917}
2022-12-05 22:43:38,765 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:38,765 INFO:     Epoch: 15
2022-12-05 22:43:39,465 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4791203188625249, 'Total loss': 0.4791203188625249} | train loss {'Reaction outcome loss': 0.5474437012356155, 'Total loss': 0.5474437012356155}
2022-12-05 22:43:39,465 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:39,465 INFO:     Epoch: 16
2022-12-05 22:43:40,166 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5000078359788115, 'Total loss': 0.5000078359788115} | train loss {'Reaction outcome loss': 0.5484619555424671, 'Total loss': 0.5484619555424671}
2022-12-05 22:43:40,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:40,166 INFO:     Epoch: 17
2022-12-05 22:43:40,867 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5143876549872485, 'Total loss': 0.5143876549872485} | train loss {'Reaction outcome loss': 0.5452505208399832, 'Total loss': 0.5452505208399832}
2022-12-05 22:43:40,867 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:40,867 INFO:     Epoch: 18
2022-12-05 22:43:41,572 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4829583503305912, 'Total loss': 0.4829583503305912} | train loss {'Reaction outcome loss': 0.5389417730423869, 'Total loss': 0.5389417730423869}
2022-12-05 22:43:41,572 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:41,572 INFO:     Epoch: 19
2022-12-05 22:43:42,276 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5103566605936397, 'Total loss': 0.5103566605936397} | train loss {'Reaction outcome loss': 0.5387433916938548, 'Total loss': 0.5387433916938548}
2022-12-05 22:43:42,277 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:42,277 INFO:     Epoch: 20
2022-12-05 22:43:42,980 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4762777421962131, 'Total loss': 0.4762777421962131} | train loss {'Reaction outcome loss': 0.5333886270620385, 'Total loss': 0.5333886270620385}
2022-12-05 22:43:42,980 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:42,980 INFO:     Epoch: 21
2022-12-05 22:43:43,682 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4826970621943474, 'Total loss': 0.4826970621943474} | train loss {'Reaction outcome loss': 0.534449529009206, 'Total loss': 0.534449529009206}
2022-12-05 22:43:43,683 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:43,683 INFO:     Epoch: 22
2022-12-05 22:43:44,386 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4930435608733784, 'Total loss': 0.4930435608733784} | train loss {'Reaction outcome loss': 0.5355710237001886, 'Total loss': 0.5355710237001886}
2022-12-05 22:43:44,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:44,386 INFO:     Epoch: 23
2022-12-05 22:43:45,087 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.549107151613994, 'Total loss': 0.549107151613994} | train loss {'Reaction outcome loss': 0.5422144359471847, 'Total loss': 0.5422144359471847}
2022-12-05 22:43:45,087 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:45,087 INFO:     Epoch: 24
2022-12-05 22:43:45,787 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4802996827797456, 'Total loss': 0.4802996827797456} | train loss {'Reaction outcome loss': 0.5365567914077214, 'Total loss': 0.5365567914077214}
2022-12-05 22:43:45,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:45,787 INFO:     Epoch: 25
2022-12-05 22:43:46,488 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4689973367547447, 'Total loss': 0.4689973367547447} | train loss {'Reaction outcome loss': 0.5330203280765183, 'Total loss': 0.5330203280765183}
2022-12-05 22:43:46,488 INFO:     Found new best model at epoch 25
2022-12-05 22:43:46,488 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:46,489 INFO:     Epoch: 26
2022-12-05 22:43:47,190 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5114117894660343, 'Total loss': 0.5114117894660343} | train loss {'Reaction outcome loss': 0.5336172994910454, 'Total loss': 0.5336172994910454}
2022-12-05 22:43:47,190 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:47,190 INFO:     Epoch: 27
2022-12-05 22:43:47,894 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4560403370044448, 'Total loss': 0.4560403370044448} | train loss {'Reaction outcome loss': 0.5324139489203084, 'Total loss': 0.5324139489203084}
2022-12-05 22:43:47,894 INFO:     Found new best model at epoch 27
2022-12-05 22:43:47,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:47,895 INFO:     Epoch: 28
2022-12-05 22:43:48,597 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4699060381813483, 'Total loss': 0.4699060381813483} | train loss {'Reaction outcome loss': 0.5197117778719688, 'Total loss': 0.5197117778719688}
2022-12-05 22:43:48,597 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:48,597 INFO:     Epoch: 29
2022-12-05 22:43:49,299 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.504261411387812, 'Total loss': 0.504261411387812} | train loss {'Reaction outcome loss': 0.5285649098303853, 'Total loss': 0.5285649098303853}
2022-12-05 22:43:49,299 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:49,299 INFO:     Epoch: 30
2022-12-05 22:43:50,005 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4711201675236225, 'Total loss': 0.4711201675236225} | train loss {'Reaction outcome loss': 0.5281646362372807, 'Total loss': 0.5281646362372807}
2022-12-05 22:43:50,006 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:50,006 INFO:     Epoch: 31
2022-12-05 22:43:50,708 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5777968655933033, 'Total loss': 0.5777968655933033} | train loss {'Reaction outcome loss': 0.5285861365649165, 'Total loss': 0.5285861365649165}
2022-12-05 22:43:50,708 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:50,708 INFO:     Epoch: 32
2022-12-05 22:43:51,412 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47154600444165146, 'Total loss': 0.47154600444165146} | train loss {'Reaction outcome loss': 0.5253468220331231, 'Total loss': 0.5253468220331231}
2022-12-05 22:43:51,412 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:51,412 INFO:     Epoch: 33
2022-12-05 22:43:52,114 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5159936621785164, 'Total loss': 0.5159936621785164} | train loss {'Reaction outcome loss': 0.5248732606975399, 'Total loss': 0.5248732606975399}
2022-12-05 22:43:52,114 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:52,114 INFO:     Epoch: 34
2022-12-05 22:43:52,818 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46572277220812713, 'Total loss': 0.46572277220812713} | train loss {'Reaction outcome loss': 0.5290771221019783, 'Total loss': 0.5290771221019783}
2022-12-05 22:43:52,818 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:52,818 INFO:     Epoch: 35
2022-12-05 22:43:53,524 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5103822326795622, 'Total loss': 0.5103822326795622} | train loss {'Reaction outcome loss': 0.52611841839187, 'Total loss': 0.52611841839187}
2022-12-05 22:43:53,524 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:53,524 INFO:     Epoch: 36
2022-12-05 22:43:54,225 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48625273833220656, 'Total loss': 0.48625273833220656} | train loss {'Reaction outcome loss': 0.5255119521398933, 'Total loss': 0.5255119521398933}
2022-12-05 22:43:54,225 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:54,225 INFO:     Epoch: 37
2022-12-05 22:43:54,925 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49927785010500386, 'Total loss': 0.49927785010500386} | train loss {'Reaction outcome loss': 0.5253469538323733, 'Total loss': 0.5253469538323733}
2022-12-05 22:43:54,925 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:54,925 INFO:     Epoch: 38
2022-12-05 22:43:55,628 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4767605059526183, 'Total loss': 0.4767605059526183} | train loss {'Reaction outcome loss': 0.5161651237582674, 'Total loss': 0.5161651237582674}
2022-12-05 22:43:55,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:55,628 INFO:     Epoch: 39
2022-12-05 22:43:56,328 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4811886731873859, 'Total loss': 0.4811886731873859} | train loss {'Reaction outcome loss': 0.5188874995830107, 'Total loss': 0.5188874995830107}
2022-12-05 22:43:56,328 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:56,329 INFO:     Epoch: 40
2022-12-05 22:43:57,029 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5131910741329193, 'Total loss': 0.5131910741329193} | train loss {'Reaction outcome loss': 0.5314132400313202, 'Total loss': 0.5314132400313202}
2022-12-05 22:43:57,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:57,029 INFO:     Epoch: 41
2022-12-05 22:43:57,730 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46589046953753993, 'Total loss': 0.46589046953753993} | train loss {'Reaction outcome loss': 0.522727277327557, 'Total loss': 0.522727277327557}
2022-12-05 22:43:57,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:57,730 INFO:     Epoch: 42
2022-12-05 22:43:58,431 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4742330109531229, 'Total loss': 0.4742330109531229} | train loss {'Reaction outcome loss': 0.5265487425789541, 'Total loss': 0.5265487425789541}
2022-12-05 22:43:58,431 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:58,431 INFO:     Epoch: 43
2022-12-05 22:43:59,135 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4612339206717231, 'Total loss': 0.4612339206717231} | train loss {'Reaction outcome loss': 0.5180237171601276, 'Total loss': 0.5180237171601276}
2022-12-05 22:43:59,136 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:59,136 INFO:     Epoch: 44
2022-12-05 22:43:59,838 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.45864963497627864, 'Total loss': 0.45864963497627864} | train loss {'Reaction outcome loss': 0.5178838364932001, 'Total loss': 0.5178838364932001}
2022-12-05 22:43:59,838 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:43:59,838 INFO:     Epoch: 45
2022-12-05 22:44:00,538 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.47029297290877864, 'Total loss': 0.47029297290877864} | train loss {'Reaction outcome loss': 0.5191761553287506, 'Total loss': 0.5191761553287506}
2022-12-05 22:44:00,539 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:00,539 INFO:     Epoch: 46
2022-12-05 22:44:01,240 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48216331513090566, 'Total loss': 0.48216331513090566} | train loss {'Reaction outcome loss': 0.5275614704404559, 'Total loss': 0.5275614704404559}
2022-12-05 22:44:01,240 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:01,240 INFO:     Epoch: 47
2022-12-05 22:44:01,941 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49681285362352023, 'Total loss': 0.49681285362352023} | train loss {'Reaction outcome loss': 0.5218014388060083, 'Total loss': 0.5218014388060083}
2022-12-05 22:44:01,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:01,941 INFO:     Epoch: 48
2022-12-05 22:44:02,642 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5195699787952683, 'Total loss': 0.5195699787952683} | train loss {'Reaction outcome loss': 0.5211975841497888, 'Total loss': 0.5211975841497888}
2022-12-05 22:44:02,643 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:02,643 INFO:     Epoch: 49
2022-12-05 22:44:03,344 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5209238332780924, 'Total loss': 0.5209238332780924} | train loss {'Reaction outcome loss': 0.5239264968706637, 'Total loss': 0.5239264968706637}
2022-12-05 22:44:03,344 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:03,344 INFO:     Epoch: 50
2022-12-05 22:44:04,045 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.576381252231923, 'Total loss': 0.576381252231923} | train loss {'Reaction outcome loss': 0.5218133951328239, 'Total loss': 0.5218133951328239}
2022-12-05 22:44:04,045 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:04,045 INFO:     Epoch: 51
2022-12-05 22:44:04,748 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4822391366416758, 'Total loss': 0.4822391366416758} | train loss {'Reaction outcome loss': 0.5229611563439271, 'Total loss': 0.5229611563439271}
2022-12-05 22:44:04,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:04,748 INFO:     Epoch: 52
2022-12-05 22:44:05,449 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4671897833997553, 'Total loss': 0.4671897833997553} | train loss {'Reaction outcome loss': 0.5126047561363298, 'Total loss': 0.5126047561363298}
2022-12-05 22:44:05,449 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:05,449 INFO:     Epoch: 53
2022-12-05 22:44:06,155 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4792414199222218, 'Total loss': 0.4792414199222218} | train loss {'Reaction outcome loss': 0.517264304112415, 'Total loss': 0.517264304112415}
2022-12-05 22:44:06,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:06,156 INFO:     Epoch: 54
2022-12-05 22:44:06,857 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49386706067757175, 'Total loss': 0.49386706067757175} | train loss {'Reaction outcome loss': 0.5184932987908928, 'Total loss': 0.5184932987908928}
2022-12-05 22:44:06,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:06,857 INFO:     Epoch: 55
2022-12-05 22:44:07,559 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4762148931622505, 'Total loss': 0.4762148931622505} | train loss {'Reaction outcome loss': 0.520189574391258, 'Total loss': 0.520189574391258}
2022-12-05 22:44:07,559 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:07,559 INFO:     Epoch: 56
2022-12-05 22:44:08,261 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4742629196156155, 'Total loss': 0.4742629196156155} | train loss {'Reaction outcome loss': 0.5191088736057281, 'Total loss': 0.5191088736057281}
2022-12-05 22:44:08,262 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:08,262 INFO:     Epoch: 57
2022-12-05 22:44:08,964 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47616180777549744, 'Total loss': 0.47616180777549744} | train loss {'Reaction outcome loss': 0.5128568653549467, 'Total loss': 0.5128568653549467}
2022-12-05 22:44:08,964 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:08,964 INFO:     Epoch: 58
2022-12-05 22:44:09,669 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4556430524045771, 'Total loss': 0.4556430524045771} | train loss {'Reaction outcome loss': 0.5328058879594414, 'Total loss': 0.5328058879594414}
2022-12-05 22:44:09,670 INFO:     Found new best model at epoch 58
2022-12-05 22:44:09,670 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:09,670 INFO:     Epoch: 59
2022-12-05 22:44:10,374 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44621509516781027, 'Total loss': 0.44621509516781027} | train loss {'Reaction outcome loss': 0.5177917923854322, 'Total loss': 0.5177917923854322}
2022-12-05 22:44:10,374 INFO:     Found new best model at epoch 59
2022-12-05 22:44:10,375 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:10,375 INFO:     Epoch: 60
2022-12-05 22:44:11,079 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4883355897935954, 'Total loss': 0.4883355897935954} | train loss {'Reaction outcome loss': 0.5184491915362222, 'Total loss': 0.5184491915362222}
2022-12-05 22:44:11,079 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:11,079 INFO:     Epoch: 61
2022-12-05 22:44:11,780 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4622249088504098, 'Total loss': 0.4622249088504098} | train loss {'Reaction outcome loss': 0.5272072866254923, 'Total loss': 0.5272072866254923}
2022-12-05 22:44:11,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:11,781 INFO:     Epoch: 62
2022-12-05 22:44:12,483 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4827286418188702, 'Total loss': 0.4827286418188702} | train loss {'Reaction outcome loss': 0.5185801276138851, 'Total loss': 0.5185801276138851}
2022-12-05 22:44:12,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:12,483 INFO:     Epoch: 63
2022-12-05 22:44:13,185 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5467522279782728, 'Total loss': 0.5467522279782728} | train loss {'Reaction outcome loss': 0.5174349065946073, 'Total loss': 0.5174349065946073}
2022-12-05 22:44:13,185 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:13,185 INFO:     Epoch: 64
2022-12-05 22:44:13,886 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4941871833394874, 'Total loss': 0.4941871833394874} | train loss {'Reaction outcome loss': 0.515740822346843, 'Total loss': 0.515740822346843}
2022-12-05 22:44:13,886 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:13,886 INFO:     Epoch: 65
2022-12-05 22:44:14,588 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46535457018762827, 'Total loss': 0.46535457018762827} | train loss {'Reaction outcome loss': 0.5119417317667786, 'Total loss': 0.5119417317667786}
2022-12-05 22:44:14,588 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:14,588 INFO:     Epoch: 66
2022-12-05 22:44:15,292 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4863435612483458, 'Total loss': 0.4863435612483458} | train loss {'Reaction outcome loss': 0.5241168643747057, 'Total loss': 0.5241168643747057}
2022-12-05 22:44:15,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:15,293 INFO:     Epoch: 67
2022-12-05 22:44:15,997 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4740361110730605, 'Total loss': 0.4740361110730605} | train loss {'Reaction outcome loss': 0.5139609792402813, 'Total loss': 0.5139609792402813}
2022-12-05 22:44:15,997 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:15,997 INFO:     Epoch: 68
2022-12-05 22:44:16,700 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4564206217500297, 'Total loss': 0.4564206217500297} | train loss {'Reaction outcome loss': 0.5238198726152887, 'Total loss': 0.5238198726152887}
2022-12-05 22:44:16,700 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:16,700 INFO:     Epoch: 69
2022-12-05 22:44:17,402 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46933815120296046, 'Total loss': 0.46933815120296046} | train loss {'Reaction outcome loss': 0.5200539705400564, 'Total loss': 0.5200539705400564}
2022-12-05 22:44:17,402 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:17,402 INFO:     Epoch: 70
2022-12-05 22:44:18,103 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4648217582567172, 'Total loss': 0.4648217582567172} | train loss {'Reaction outcome loss': 0.5143447905170674, 'Total loss': 0.5143447905170674}
2022-12-05 22:44:18,103 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:18,103 INFO:     Epoch: 71
2022-12-05 22:44:18,804 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47327080876989797, 'Total loss': 0.47327080876989797} | train loss {'Reaction outcome loss': 0.5157221670053443, 'Total loss': 0.5157221670053443}
2022-12-05 22:44:18,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:18,804 INFO:     Epoch: 72
2022-12-05 22:44:19,510 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5035522763024677, 'Total loss': 0.5035522763024677} | train loss {'Reaction outcome loss': 0.5194934106602961, 'Total loss': 0.5194934106602961}
2022-12-05 22:44:19,510 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:19,510 INFO:     Epoch: 73
2022-12-05 22:44:20,217 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5584892760962248, 'Total loss': 0.5584892760962248} | train loss {'Reaction outcome loss': 0.5264685291416791, 'Total loss': 0.5264685291416791}
2022-12-05 22:44:20,217 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:20,217 INFO:     Epoch: 74
2022-12-05 22:44:20,923 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4806683966043321, 'Total loss': 0.4806683966043321} | train loss {'Reaction outcome loss': 0.524319744596676, 'Total loss': 0.524319744596676}
2022-12-05 22:44:20,923 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:20,923 INFO:     Epoch: 75
2022-12-05 22:44:21,630 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46333977817134425, 'Total loss': 0.46333977817134425} | train loss {'Reaction outcome loss': 0.5286890660013471, 'Total loss': 0.5286890660013471}
2022-12-05 22:44:21,631 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:21,631 INFO:     Epoch: 76
2022-12-05 22:44:22,343 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.48434978689659725, 'Total loss': 0.48434978689659725} | train loss {'Reaction outcome loss': 0.5145811766994243, 'Total loss': 0.5145811766994243}
2022-12-05 22:44:22,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:22,343 INFO:     Epoch: 77
2022-12-05 22:44:23,054 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4540663341229612, 'Total loss': 0.4540663341229612} | train loss {'Reaction outcome loss': 0.5169237676931887, 'Total loss': 0.5169237676931887}
2022-12-05 22:44:23,054 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:23,054 INFO:     Epoch: 78
2022-12-05 22:44:23,761 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.49072475799105386, 'Total loss': 0.49072475799105386} | train loss {'Reaction outcome loss': 0.5205312039170946, 'Total loss': 0.5205312039170946}
2022-12-05 22:44:23,762 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:23,762 INFO:     Epoch: 79
2022-12-05 22:44:24,468 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.464351468465545, 'Total loss': 0.464351468465545} | train loss {'Reaction outcome loss': 0.5183375027714944, 'Total loss': 0.5183375027714944}
2022-12-05 22:44:24,468 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:24,469 INFO:     Epoch: 80
2022-12-05 22:44:25,174 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4759427173571153, 'Total loss': 0.4759427173571153} | train loss {'Reaction outcome loss': 0.515696362329989, 'Total loss': 0.515696362329989}
2022-12-05 22:44:25,174 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:25,174 INFO:     Epoch: 81
2022-12-05 22:44:25,880 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4945026304234158, 'Total loss': 0.4945026304234158} | train loss {'Reaction outcome loss': 0.5184070420508482, 'Total loss': 0.5184070420508482}
2022-12-05 22:44:25,880 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:25,881 INFO:     Epoch: 82
2022-12-05 22:44:26,586 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4677158946340734, 'Total loss': 0.4677158946340734} | train loss {'Reaction outcome loss': 0.5205907343601693, 'Total loss': 0.5205907343601693}
2022-12-05 22:44:26,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:26,586 INFO:     Epoch: 83
2022-12-05 22:44:27,294 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47097370434891095, 'Total loss': 0.47097370434891095} | train loss {'Reaction outcome loss': 0.516342928214949, 'Total loss': 0.516342928214949}
2022-12-05 22:44:27,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:27,295 INFO:     Epoch: 84
2022-12-05 22:44:28,005 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4914425252513452, 'Total loss': 0.4914425252513452} | train loss {'Reaction outcome loss': 0.5220583606739433, 'Total loss': 0.5220583606739433}
2022-12-05 22:44:28,005 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:28,005 INFO:     Epoch: 85
2022-12-05 22:44:28,711 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5114994482560591, 'Total loss': 0.5114994482560591} | train loss {'Reaction outcome loss': 0.5210129521331008, 'Total loss': 0.5210129521331008}
2022-12-05 22:44:28,712 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:28,712 INFO:     Epoch: 86
2022-12-05 22:44:29,419 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46612130207094277, 'Total loss': 0.46612130207094277} | train loss {'Reaction outcome loss': 0.5184006913584106, 'Total loss': 0.5184006913584106}
2022-12-05 22:44:29,419 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:29,419 INFO:     Epoch: 87
2022-12-05 22:44:30,122 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4805028872056441, 'Total loss': 0.4805028872056441} | train loss {'Reaction outcome loss': 0.5181031228936448, 'Total loss': 0.5181031228936448}
2022-12-05 22:44:30,122 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:30,122 INFO:     Epoch: 88
2022-12-05 22:44:30,824 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4757534150372852, 'Total loss': 0.4757534150372852} | train loss {'Reaction outcome loss': 0.5138350775047225, 'Total loss': 0.5138350775047225}
2022-12-05 22:44:30,824 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:30,824 INFO:     Epoch: 89
2022-12-05 22:44:31,523 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5002891699021513, 'Total loss': 0.5002891699021513} | train loss {'Reaction outcome loss': 0.5171371792652169, 'Total loss': 0.5171371792652169}
2022-12-05 22:44:31,523 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:31,524 INFO:     Epoch: 90
2022-12-05 22:44:32,224 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46885632452639664, 'Total loss': 0.46885632452639664} | train loss {'Reaction outcome loss': 0.5189917367331836, 'Total loss': 0.5189917367331836}
2022-12-05 22:44:32,224 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:32,224 INFO:     Epoch: 91
2022-12-05 22:44:32,922 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4763057448647239, 'Total loss': 0.4763057448647239} | train loss {'Reaction outcome loss': 0.5200888083905589, 'Total loss': 0.5200888083905589}
2022-12-05 22:44:32,922 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:32,923 INFO:     Epoch: 92
2022-12-05 22:44:33,621 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49165019528432324, 'Total loss': 0.49165019528432324} | train loss {'Reaction outcome loss': 0.5147369539859343, 'Total loss': 0.5147369539859343}
2022-12-05 22:44:33,622 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:33,622 INFO:     Epoch: 93
2022-12-05 22:44:34,322 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.473017500882799, 'Total loss': 0.473017500882799} | train loss {'Reaction outcome loss': 0.5173395973079059, 'Total loss': 0.5173395973079059}
2022-12-05 22:44:34,323 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:34,323 INFO:     Epoch: 94
2022-12-05 22:44:35,022 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48963152193887666, 'Total loss': 0.48963152193887666} | train loss {'Reaction outcome loss': 0.5121688407902815, 'Total loss': 0.5121688407902815}
2022-12-05 22:44:35,023 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:35,023 INFO:     Epoch: 95
2022-12-05 22:44:35,722 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4836611097509211, 'Total loss': 0.4836611097509211} | train loss {'Reaction outcome loss': 0.5232902679516345, 'Total loss': 0.5232902679516345}
2022-12-05 22:44:35,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:35,723 INFO:     Epoch: 96
2022-12-05 22:44:36,425 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4888531762090596, 'Total loss': 0.4888531762090596} | train loss {'Reaction outcome loss': 0.5169184404976513, 'Total loss': 0.5169184404976513}
2022-12-05 22:44:36,425 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:36,425 INFO:     Epoch: 97
2022-12-05 22:44:37,128 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46432874046943406, 'Total loss': 0.46432874046943406} | train loss {'Reaction outcome loss': 0.5158562925397133, 'Total loss': 0.5158562925397133}
2022-12-05 22:44:37,128 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:37,128 INFO:     Epoch: 98
2022-12-05 22:44:37,833 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4795283756472848, 'Total loss': 0.4795283756472848} | train loss {'Reaction outcome loss': 0.5188707739722972, 'Total loss': 0.5188707739722972}
2022-12-05 22:44:37,833 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:37,833 INFO:     Epoch: 99
2022-12-05 22:44:38,535 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46316912973468954, 'Total loss': 0.46316912973468954} | train loss {'Reaction outcome loss': 0.5208844079655044, 'Total loss': 0.5208844079655044}
2022-12-05 22:44:38,535 INFO:     Best model found after epoch 60 of 100.
2022-12-05 22:44:38,535 INFO:   Done with stage: TRAINING
2022-12-05 22:44:38,535 INFO:   Starting stage: EVALUATION
2022-12-05 22:44:38,664 INFO:   Done with stage: EVALUATION
2022-12-05 22:44:38,664 INFO:   Leaving out SEQ value Fold_3
2022-12-05 22:44:38,677 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:44:38,677 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:44:39,319 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:44:39,319 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:44:39,390 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:44:39,390 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:44:39,390 INFO:     No hyperparam tuning for this model
2022-12-05 22:44:39,390 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:44:39,390 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:44:39,391 INFO:     None feature selector for col prot
2022-12-05 22:44:39,391 INFO:     None feature selector for col prot
2022-12-05 22:44:39,391 INFO:     None feature selector for col prot
2022-12-05 22:44:39,392 INFO:     None feature selector for col chem
2022-12-05 22:44:39,392 INFO:     None feature selector for col chem
2022-12-05 22:44:39,392 INFO:     None feature selector for col chem
2022-12-05 22:44:39,392 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:44:39,392 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:44:39,394 INFO:     Number of params in model 215731
2022-12-05 22:44:39,397 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:44:39,397 INFO:   Starting stage: TRAINING
2022-12-05 22:44:39,454 INFO:     Val loss before train {'Reaction outcome loss': 0.9592256823723967, 'Total loss': 0.9592256823723967}
2022-12-05 22:44:39,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:39,455 INFO:     Epoch: 0
2022-12-05 22:44:40,156 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6767794408581473, 'Total loss': 0.6767794408581473} | train loss {'Reaction outcome loss': 0.822160378280951, 'Total loss': 0.822160378280951}
2022-12-05 22:44:40,156 INFO:     Found new best model at epoch 0
2022-12-05 22:44:40,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:40,157 INFO:     Epoch: 1
2022-12-05 22:44:40,856 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6308321946046569, 'Total loss': 0.6308321946046569} | train loss {'Reaction outcome loss': 0.6673131790088147, 'Total loss': 0.6673131790088147}
2022-12-05 22:44:40,856 INFO:     Found new best model at epoch 1
2022-12-05 22:44:40,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:40,857 INFO:     Epoch: 2
2022-12-05 22:44:41,556 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6221556555141102, 'Total loss': 0.6221556555141102} | train loss {'Reaction outcome loss': 0.6357373621999001, 'Total loss': 0.6357373621999001}
2022-12-05 22:44:41,556 INFO:     Found new best model at epoch 2
2022-12-05 22:44:41,557 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:41,557 INFO:     Epoch: 3
2022-12-05 22:44:42,257 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5574080036445097, 'Total loss': 0.5574080036445097} | train loss {'Reaction outcome loss': 0.6114954366975901, 'Total loss': 0.6114954366975901}
2022-12-05 22:44:42,257 INFO:     Found new best model at epoch 3
2022-12-05 22:44:42,258 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:42,258 INFO:     Epoch: 4
2022-12-05 22:44:42,961 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5986056686802343, 'Total loss': 0.5986056686802343} | train loss {'Reaction outcome loss': 0.5933395444738622, 'Total loss': 0.5933395444738622}
2022-12-05 22:44:42,961 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:42,961 INFO:     Epoch: 5
2022-12-05 22:44:43,665 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5736416266723112, 'Total loss': 0.5736416266723112} | train loss {'Reaction outcome loss': 0.5884524880623331, 'Total loss': 0.5884524880623331}
2022-12-05 22:44:43,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:43,665 INFO:     Epoch: 6
2022-12-05 22:44:44,365 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6120763895186511, 'Total loss': 0.6120763895186511} | train loss {'Reaction outcome loss': 0.583168330484507, 'Total loss': 0.583168330484507}
2022-12-05 22:44:44,365 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:44,365 INFO:     Epoch: 7
2022-12-05 22:44:45,065 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5645262199369344, 'Total loss': 0.5645262199369344} | train loss {'Reaction outcome loss': 0.5757359761972817, 'Total loss': 0.5757359761972817}
2022-12-05 22:44:45,065 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:45,065 INFO:     Epoch: 8
2022-12-05 22:44:45,765 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5435928844592788, 'Total loss': 0.5435928844592788} | train loss {'Reaction outcome loss': 0.5765701146150122, 'Total loss': 0.5765701146150122}
2022-12-05 22:44:45,766 INFO:     Found new best model at epoch 8
2022-12-05 22:44:45,766 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:45,767 INFO:     Epoch: 9
2022-12-05 22:44:46,467 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5498038598082282, 'Total loss': 0.5498038598082282} | train loss {'Reaction outcome loss': 0.5805549420872513, 'Total loss': 0.5805549420872513}
2022-12-05 22:44:46,468 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:46,468 INFO:     Epoch: 10
2022-12-05 22:44:47,168 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5462756143374876, 'Total loss': 0.5462756143374876} | train loss {'Reaction outcome loss': 0.5647377359015601, 'Total loss': 0.5647377359015601}
2022-12-05 22:44:47,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:47,168 INFO:     Epoch: 11
2022-12-05 22:44:47,874 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5625486922535029, 'Total loss': 0.5625486922535029} | train loss {'Reaction outcome loss': 0.5681276881573152, 'Total loss': 0.5681276881573152}
2022-12-05 22:44:47,874 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:47,875 INFO:     Epoch: 12
2022-12-05 22:44:48,582 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5984734540635889, 'Total loss': 0.5984734540635889} | train loss {'Reaction outcome loss': 0.5582448911910154, 'Total loss': 0.5582448911910154}
2022-12-05 22:44:48,583 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:48,583 INFO:     Epoch: 13
2022-12-05 22:44:49,285 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5183177156881853, 'Total loss': 0.5183177156881853} | train loss {'Reaction outcome loss': 0.561749552828925, 'Total loss': 0.561749552828925}
2022-12-05 22:44:49,285 INFO:     Found new best model at epoch 13
2022-12-05 22:44:49,286 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:49,286 INFO:     Epoch: 14
2022-12-05 22:44:49,991 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5127521160651337, 'Total loss': 0.5127521160651337} | train loss {'Reaction outcome loss': 0.5595189536104397, 'Total loss': 0.5595189536104397}
2022-12-05 22:44:49,991 INFO:     Found new best model at epoch 14
2022-12-05 22:44:49,992 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:49,992 INFO:     Epoch: 15
2022-12-05 22:44:50,694 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5381624414162203, 'Total loss': 0.5381624414162203} | train loss {'Reaction outcome loss': 0.5548197864269724, 'Total loss': 0.5548197864269724}
2022-12-05 22:44:50,695 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:50,695 INFO:     Epoch: 16
2022-12-05 22:44:51,396 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5374404280023142, 'Total loss': 0.5374404280023142} | train loss {'Reaction outcome loss': 0.5414828453745161, 'Total loss': 0.5414828453745161}
2022-12-05 22:44:51,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:51,396 INFO:     Epoch: 17
2022-12-05 22:44:52,097 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5389485758813944, 'Total loss': 0.5389485758813944} | train loss {'Reaction outcome loss': 0.5506695584983242, 'Total loss': 0.5506695584983242}
2022-12-05 22:44:52,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:52,098 INFO:     Epoch: 18
2022-12-05 22:44:52,799 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.559392829425633, 'Total loss': 0.559392829425633} | train loss {'Reaction outcome loss': 0.5456271485406525, 'Total loss': 0.5456271485406525}
2022-12-05 22:44:52,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:52,799 INFO:     Epoch: 19
2022-12-05 22:44:53,500 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5392922759056091, 'Total loss': 0.5392922759056091} | train loss {'Reaction outcome loss': 0.5528344934083977, 'Total loss': 0.5528344934083977}
2022-12-05 22:44:53,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:53,500 INFO:     Epoch: 20
2022-12-05 22:44:54,206 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5375073921274055, 'Total loss': 0.5375073921274055} | train loss {'Reaction outcome loss': 0.5519396065449228, 'Total loss': 0.5519396065449228}
2022-12-05 22:44:54,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:54,207 INFO:     Epoch: 21
2022-12-05 22:44:54,911 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5253493501381441, 'Total loss': 0.5253493501381441} | train loss {'Reaction outcome loss': 0.5373193434306553, 'Total loss': 0.5373193434306553}
2022-12-05 22:44:54,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:54,912 INFO:     Epoch: 22
2022-12-05 22:44:55,613 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5725782933560285, 'Total loss': 0.5725782933560285} | train loss {'Reaction outcome loss': 0.5373592462466688, 'Total loss': 0.5373592462466688}
2022-12-05 22:44:55,614 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:55,614 INFO:     Epoch: 23
2022-12-05 22:44:56,319 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5326310416514223, 'Total loss': 0.5326310416514223} | train loss {'Reaction outcome loss': 0.5411377940859113, 'Total loss': 0.5411377940859113}
2022-12-05 22:44:56,319 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:56,319 INFO:     Epoch: 24
2022-12-05 22:44:57,021 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5368906005539678, 'Total loss': 0.5368906005539678} | train loss {'Reaction outcome loss': 0.5385972199999556, 'Total loss': 0.5385972199999556}
2022-12-05 22:44:57,021 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:57,021 INFO:     Epoch: 25
2022-12-05 22:44:57,723 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5210609100759029, 'Total loss': 0.5210609100759029} | train loss {'Reaction outcome loss': 0.5337138678346361, 'Total loss': 0.5337138678346361}
2022-12-05 22:44:57,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:57,723 INFO:     Epoch: 26
2022-12-05 22:44:58,424 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5710447471250187, 'Total loss': 0.5710447471250187} | train loss {'Reaction outcome loss': 0.5350543927781436, 'Total loss': 0.5350543927781436}
2022-12-05 22:44:58,424 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:58,424 INFO:     Epoch: 27
2022-12-05 22:44:59,128 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5179254873232408, 'Total loss': 0.5179254873232408} | train loss {'Reaction outcome loss': 0.5302976930628017, 'Total loss': 0.5302976930628017}
2022-12-05 22:44:59,128 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:59,128 INFO:     Epoch: 28
2022-12-05 22:44:59,829 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5157471874898131, 'Total loss': 0.5157471874898131} | train loss {'Reaction outcome loss': 0.5397855360289009, 'Total loss': 0.5397855360289009}
2022-12-05 22:44:59,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:44:59,829 INFO:     Epoch: 29
2022-12-05 22:45:00,532 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5067429495128718, 'Total loss': 0.5067429495128718} | train loss {'Reaction outcome loss': 0.5324561595308538, 'Total loss': 0.5324561595308538}
2022-12-05 22:45:00,532 INFO:     Found new best model at epoch 29
2022-12-05 22:45:00,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:00,533 INFO:     Epoch: 30
2022-12-05 22:45:01,239 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5351533137939193, 'Total loss': 0.5351533137939193} | train loss {'Reaction outcome loss': 0.5248048129130383, 'Total loss': 0.5248048129130383}
2022-12-05 22:45:01,239 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:01,239 INFO:     Epoch: 31
2022-12-05 22:45:01,947 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.504191782664169, 'Total loss': 0.504191782664169} | train loss {'Reaction outcome loss': 0.5196175684126056, 'Total loss': 0.5196175684126056}
2022-12-05 22:45:01,947 INFO:     Found new best model at epoch 31
2022-12-05 22:45:01,947 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:01,948 INFO:     Epoch: 32
2022-12-05 22:45:02,653 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5099512684074315, 'Total loss': 0.5099512684074315} | train loss {'Reaction outcome loss': 0.5227477126583762, 'Total loss': 0.5227477126583762}
2022-12-05 22:45:02,654 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:02,654 INFO:     Epoch: 33
2022-12-05 22:45:03,358 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5107286728241227, 'Total loss': 0.5107286728241227} | train loss {'Reaction outcome loss': 0.5270579736451714, 'Total loss': 0.5270579736451714}
2022-12-05 22:45:03,358 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:03,359 INFO:     Epoch: 34
2022-12-05 22:45:04,063 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4809202585708011, 'Total loss': 0.4809202585708011} | train loss {'Reaction outcome loss': 0.5246462722822112, 'Total loss': 0.5246462722822112}
2022-12-05 22:45:04,063 INFO:     Found new best model at epoch 34
2022-12-05 22:45:04,064 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:04,064 INFO:     Epoch: 35
2022-12-05 22:45:04,775 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5417567071589556, 'Total loss': 0.5417567071589556} | train loss {'Reaction outcome loss': 0.5169564952655714, 'Total loss': 0.5169564952655714}
2022-12-05 22:45:04,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:04,776 INFO:     Epoch: 36
2022-12-05 22:45:05,489 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5082198445769873, 'Total loss': 0.5082198445769873} | train loss {'Reaction outcome loss': 0.5265130089862006, 'Total loss': 0.5265130089862006}
2022-12-05 22:45:05,489 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:05,489 INFO:     Epoch: 37
2022-12-05 22:45:06,201 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5340062860738147, 'Total loss': 0.5340062860738147} | train loss {'Reaction outcome loss': 0.5184092407323876, 'Total loss': 0.5184092407323876}
2022-12-05 22:45:06,201 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:06,201 INFO:     Epoch: 38
2022-12-05 22:45:06,911 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4970309246670116, 'Total loss': 0.4970309246670116} | train loss {'Reaction outcome loss': 0.5162856042385101, 'Total loss': 0.5162856042385101}
2022-12-05 22:45:06,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:06,911 INFO:     Epoch: 39
2022-12-05 22:45:07,616 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5414001061157747, 'Total loss': 0.5414001061157747} | train loss {'Reaction outcome loss': 0.5225552714600855, 'Total loss': 0.5225552714600855}
2022-12-05 22:45:07,617 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:07,617 INFO:     Epoch: 40
2022-12-05 22:45:08,321 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5951607207005675, 'Total loss': 0.5951607207005675} | train loss {'Reaction outcome loss': 0.5203428682015867, 'Total loss': 0.5203428682015867}
2022-12-05 22:45:08,321 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:08,321 INFO:     Epoch: 41
2022-12-05 22:45:09,026 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5882390564815565, 'Total loss': 0.5882390564815565} | train loss {'Reaction outcome loss': 0.514710531794295, 'Total loss': 0.514710531794295}
2022-12-05 22:45:09,026 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:09,026 INFO:     Epoch: 42
2022-12-05 22:45:09,731 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5198688402094624, 'Total loss': 0.5198688402094624} | train loss {'Reaction outcome loss': 0.5205174589035463, 'Total loss': 0.5205174589035463}
2022-12-05 22:45:09,731 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:09,731 INFO:     Epoch: 43
2022-12-05 22:45:10,440 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4973759315907955, 'Total loss': 0.4973759315907955} | train loss {'Reaction outcome loss': 0.5174229346367778, 'Total loss': 0.5174229346367778}
2022-12-05 22:45:10,441 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:10,441 INFO:     Epoch: 44
2022-12-05 22:45:11,152 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5010810904204845, 'Total loss': 0.5010810904204845} | train loss {'Reaction outcome loss': 0.523591547231285, 'Total loss': 0.523591547231285}
2022-12-05 22:45:11,152 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:11,152 INFO:     Epoch: 45
2022-12-05 22:45:11,867 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5124027884819291, 'Total loss': 0.5124027884819291} | train loss {'Reaction outcome loss': 0.5154083593159305, 'Total loss': 0.5154083593159305}
2022-12-05 22:45:11,867 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:11,867 INFO:     Epoch: 46
2022-12-05 22:45:12,579 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5230968421833082, 'Total loss': 0.5230968421833082} | train loss {'Reaction outcome loss': 0.5137452339639469, 'Total loss': 0.5137452339639469}
2022-12-05 22:45:12,579 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:12,579 INFO:     Epoch: 47
2022-12-05 22:45:13,284 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5338338423858989, 'Total loss': 0.5338338423858989} | train loss {'Reaction outcome loss': 0.5116857461783351, 'Total loss': 0.5116857461783351}
2022-12-05 22:45:13,284 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:13,284 INFO:     Epoch: 48
2022-12-05 22:45:13,993 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5263998847116124, 'Total loss': 0.5263998847116124} | train loss {'Reaction outcome loss': 0.5142798688338728, 'Total loss': 0.5142798688338728}
2022-12-05 22:45:13,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:13,993 INFO:     Epoch: 49
2022-12-05 22:45:14,701 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5054833861914548, 'Total loss': 0.5054833861914548} | train loss {'Reaction outcome loss': 0.517541909704403, 'Total loss': 0.517541909704403}
2022-12-05 22:45:14,702 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:14,702 INFO:     Epoch: 50
2022-12-05 22:45:15,409 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49453360959887505, 'Total loss': 0.49453360959887505} | train loss {'Reaction outcome loss': 0.5170172412784733, 'Total loss': 0.5170172412784733}
2022-12-05 22:45:15,409 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:15,409 INFO:     Epoch: 51
2022-12-05 22:45:16,121 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.511208158663728, 'Total loss': 0.511208158663728} | train loss {'Reaction outcome loss': 0.513035386861587, 'Total loss': 0.513035386861587}
2022-12-05 22:45:16,122 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:16,122 INFO:     Epoch: 52
2022-12-05 22:45:16,832 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5059740475632928, 'Total loss': 0.5059740475632928} | train loss {'Reaction outcome loss': 0.5093581829752241, 'Total loss': 0.5093581829752241}
2022-12-05 22:45:16,833 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:16,833 INFO:     Epoch: 53
2022-12-05 22:45:17,539 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49695322527126834, 'Total loss': 0.49695322527126834} | train loss {'Reaction outcome loss': 0.5213823714426585, 'Total loss': 0.5213823714426585}
2022-12-05 22:45:17,539 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:17,539 INFO:     Epoch: 54
2022-12-05 22:45:18,247 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5467252026904713, 'Total loss': 0.5467252026904713} | train loss {'Reaction outcome loss': 0.5056947611120283, 'Total loss': 0.5056947611120283}
2022-12-05 22:45:18,247 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:18,248 INFO:     Epoch: 55
2022-12-05 22:45:18,955 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4919956908984618, 'Total loss': 0.4919956908984618} | train loss {'Reaction outcome loss': 0.5100415388540346, 'Total loss': 0.5100415388540346}
2022-12-05 22:45:18,955 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:18,955 INFO:     Epoch: 56
2022-12-05 22:45:19,666 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5274170447479595, 'Total loss': 0.5274170447479595} | train loss {'Reaction outcome loss': 0.5142829770336346, 'Total loss': 0.5142829770336346}
2022-12-05 22:45:19,666 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:19,666 INFO:     Epoch: 57
2022-12-05 22:45:20,379 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5421057651666078, 'Total loss': 0.5421057651666078} | train loss {'Reaction outcome loss': 0.5127169036135382, 'Total loss': 0.5127169036135382}
2022-12-05 22:45:20,379 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:20,379 INFO:     Epoch: 58
2022-12-05 22:45:21,085 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5048639726909724, 'Total loss': 0.5048639726909724} | train loss {'Reaction outcome loss': 0.5181643252470055, 'Total loss': 0.5181643252470055}
2022-12-05 22:45:21,086 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:21,086 INFO:     Epoch: 59
2022-12-05 22:45:21,794 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5206428779797121, 'Total loss': 0.5206428779797121} | train loss {'Reaction outcome loss': 0.5088622334052105, 'Total loss': 0.5088622334052105}
2022-12-05 22:45:21,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:21,794 INFO:     Epoch: 60
2022-12-05 22:45:22,501 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.516388675705953, 'Total loss': 0.516388675705953} | train loss {'Reaction outcome loss': 0.5235405005362569, 'Total loss': 0.5235405005362569}
2022-12-05 22:45:22,501 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:22,501 INFO:     Epoch: 61
2022-12-05 22:45:23,206 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.536731267855926, 'Total loss': 0.536731267855926} | train loss {'Reaction outcome loss': 0.5091410151549748, 'Total loss': 0.5091410151549748}
2022-12-05 22:45:23,207 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:23,207 INFO:     Epoch: 62
2022-12-05 22:45:23,915 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5225747471505945, 'Total loss': 0.5225747471505945} | train loss {'Reaction outcome loss': 0.5079669071399435, 'Total loss': 0.5079669071399435}
2022-12-05 22:45:23,915 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:23,915 INFO:     Epoch: 63
2022-12-05 22:45:24,622 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5028585236180912, 'Total loss': 0.5028585236180912} | train loss {'Reaction outcome loss': 0.5098038247653416, 'Total loss': 0.5098038247653416}
2022-12-05 22:45:24,622 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:24,622 INFO:     Epoch: 64
2022-12-05 22:45:25,331 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4996831295165149, 'Total loss': 0.4996831295165149} | train loss {'Reaction outcome loss': 0.5110247526241809, 'Total loss': 0.5110247526241809}
2022-12-05 22:45:25,331 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:25,331 INFO:     Epoch: 65
2022-12-05 22:45:26,036 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5203622264618223, 'Total loss': 0.5203622264618223} | train loss {'Reaction outcome loss': 0.5029983975449387, 'Total loss': 0.5029983975449387}
2022-12-05 22:45:26,036 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:26,036 INFO:     Epoch: 66
2022-12-05 22:45:26,741 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.525766136971387, 'Total loss': 0.525766136971387} | train loss {'Reaction outcome loss': 0.5095049653734479, 'Total loss': 0.5095049653734479}
2022-12-05 22:45:26,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:26,742 INFO:     Epoch: 67
2022-12-05 22:45:27,447 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5118760447949171, 'Total loss': 0.5118760447949171} | train loss {'Reaction outcome loss': 0.5118573163845102, 'Total loss': 0.5118573163845102}
2022-12-05 22:45:27,447 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:27,447 INFO:     Epoch: 68
2022-12-05 22:45:28,154 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5530988330190832, 'Total loss': 0.5530988330190832} | train loss {'Reaction outcome loss': 0.5039379166097057, 'Total loss': 0.5039379166097057}
2022-12-05 22:45:28,154 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:28,154 INFO:     Epoch: 69
2022-12-05 22:45:28,859 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5298494920134544, 'Total loss': 0.5298494920134544} | train loss {'Reaction outcome loss': 0.5111695459302591, 'Total loss': 0.5111695459302591}
2022-12-05 22:45:28,859 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:28,859 INFO:     Epoch: 70
2022-12-05 22:45:29,569 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5038598508320071, 'Total loss': 0.5038598508320071} | train loss {'Reaction outcome loss': 0.5164560251089991, 'Total loss': 0.5164560251089991}
2022-12-05 22:45:29,569 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:29,569 INFO:     Epoch: 71
2022-12-05 22:45:30,277 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5498020035976713, 'Total loss': 0.5498020035976713} | train loss {'Reaction outcome loss': 0.517145150778245, 'Total loss': 0.517145150778245}
2022-12-05 22:45:30,277 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:30,277 INFO:     Epoch: 72
2022-12-05 22:45:30,980 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5342105874283747, 'Total loss': 0.5342105874283747} | train loss {'Reaction outcome loss': 0.5074720827900634, 'Total loss': 0.5074720827900634}
2022-12-05 22:45:30,980 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:30,980 INFO:     Epoch: 73
2022-12-05 22:45:31,686 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5216963900761171, 'Total loss': 0.5216963900761171} | train loss {'Reaction outcome loss': 0.5085420107963133, 'Total loss': 0.5085420107963133}
2022-12-05 22:45:31,686 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:31,686 INFO:     Epoch: 74
2022-12-05 22:45:32,393 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5056130425496534, 'Total loss': 0.5056130425496534} | train loss {'Reaction outcome loss': 0.5058456336357156, 'Total loss': 0.5058456336357156}
2022-12-05 22:45:32,393 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:32,393 INFO:     Epoch: 75
2022-12-05 22:45:33,098 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5127596885643222, 'Total loss': 0.5127596885643222} | train loss {'Reaction outcome loss': 0.5063109169809186, 'Total loss': 0.5063109169809186}
2022-12-05 22:45:33,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:33,098 INFO:     Epoch: 76
2022-12-05 22:45:33,801 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5052454810250889, 'Total loss': 0.5052454810250889} | train loss {'Reaction outcome loss': 0.5170257727710568, 'Total loss': 0.5170257727710568}
2022-12-05 22:45:33,801 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:33,801 INFO:     Epoch: 77
2022-12-05 22:45:34,504 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5171801447868347, 'Total loss': 0.5171801447868347} | train loss {'Reaction outcome loss': 0.505387078134381, 'Total loss': 0.505387078134381}
2022-12-05 22:45:34,504 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:34,504 INFO:     Epoch: 78
2022-12-05 22:45:35,209 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5494449267333205, 'Total loss': 0.5494449267333205} | train loss {'Reaction outcome loss': 0.5053224587318849, 'Total loss': 0.5053224587318849}
2022-12-05 22:45:35,209 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:35,209 INFO:     Epoch: 79
2022-12-05 22:45:35,916 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4890868291258812, 'Total loss': 0.4890868291258812} | train loss {'Reaction outcome loss': 0.5140469093103798, 'Total loss': 0.5140469093103798}
2022-12-05 22:45:35,916 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:35,916 INFO:     Epoch: 80
2022-12-05 22:45:36,621 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5018834447996183, 'Total loss': 0.5018834447996183} | train loss {'Reaction outcome loss': 0.5100140716348376, 'Total loss': 0.5100140716348376}
2022-12-05 22:45:36,621 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:36,621 INFO:     Epoch: 81
2022-12-05 22:45:37,326 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.532977800138972, 'Total loss': 0.532977800138972} | train loss {'Reaction outcome loss': 0.5062379975099953, 'Total loss': 0.5062379975099953}
2022-12-05 22:45:37,326 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:37,326 INFO:     Epoch: 82
2022-12-05 22:45:38,034 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5396870090202852, 'Total loss': 0.5396870090202852} | train loss {'Reaction outcome loss': 0.5139161525940409, 'Total loss': 0.5139161525940409}
2022-12-05 22:45:38,034 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:38,034 INFO:     Epoch: 83
2022-12-05 22:45:38,741 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48700989511880005, 'Total loss': 0.48700989511880005} | train loss {'Reaction outcome loss': 0.5059823751449585, 'Total loss': 0.5059823751449585}
2022-12-05 22:45:38,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:38,741 INFO:     Epoch: 84
2022-12-05 22:45:39,451 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5399941388856281, 'Total loss': 0.5399941388856281} | train loss {'Reaction outcome loss': 0.5055844595845864, 'Total loss': 0.5055844595845864}
2022-12-05 22:45:39,452 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:39,452 INFO:     Epoch: 85
2022-12-05 22:45:40,160 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5397868291898207, 'Total loss': 0.5397868291898207} | train loss {'Reaction outcome loss': 0.5189515677641849, 'Total loss': 0.5189515677641849}
2022-12-05 22:45:40,160 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:40,160 INFO:     Epoch: 86
2022-12-05 22:45:40,868 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5227268084206365, 'Total loss': 0.5227268084206365} | train loss {'Reaction outcome loss': 0.5189154109784535, 'Total loss': 0.5189154109784535}
2022-12-05 22:45:40,868 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:40,868 INFO:     Epoch: 87
2022-12-05 22:45:41,574 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5042842335321687, 'Total loss': 0.5042842335321687} | train loss {'Reaction outcome loss': 0.5058364191833807, 'Total loss': 0.5058364191833807}
2022-12-05 22:45:41,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:41,575 INFO:     Epoch: 88
2022-12-05 22:45:42,280 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4990374398502437, 'Total loss': 0.4990374398502437} | train loss {'Reaction outcome loss': 0.5098796291618931, 'Total loss': 0.5098796291618931}
2022-12-05 22:45:42,280 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:42,280 INFO:     Epoch: 89
2022-12-05 22:45:42,988 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5405907949263399, 'Total loss': 0.5405907949263399} | train loss {'Reaction outcome loss': 0.5049212989150261, 'Total loss': 0.5049212989150261}
2022-12-05 22:45:42,988 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:42,988 INFO:     Epoch: 90
2022-12-05 22:45:43,695 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5035800967704166, 'Total loss': 0.5035800967704166} | train loss {'Reaction outcome loss': 0.5103486555571459, 'Total loss': 0.5103486555571459}
2022-12-05 22:45:43,695 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:43,695 INFO:     Epoch: 91
2022-12-05 22:45:44,401 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.51861965470016, 'Total loss': 0.51861965470016} | train loss {'Reaction outcome loss': 0.501169650956076, 'Total loss': 0.501169650956076}
2022-12-05 22:45:44,401 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:44,401 INFO:     Epoch: 92
2022-12-05 22:45:45,109 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5587847842411562, 'Total loss': 0.5587847842411562} | train loss {'Reaction outcome loss': 0.5154143549349843, 'Total loss': 0.5154143549349843}
2022-12-05 22:45:45,109 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:45,109 INFO:     Epoch: 93
2022-12-05 22:45:45,815 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5073245607993819, 'Total loss': 0.5073245607993819} | train loss {'Reaction outcome loss': 0.5061378392637993, 'Total loss': 0.5061378392637993}
2022-12-05 22:45:45,815 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:45,815 INFO:     Epoch: 94
2022-12-05 22:45:46,524 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.557404448362914, 'Total loss': 0.557404448362914} | train loss {'Reaction outcome loss': 0.5104832852373318, 'Total loss': 0.5104832852373318}
2022-12-05 22:45:46,524 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:46,524 INFO:     Epoch: 95
2022-12-05 22:45:47,232 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5265966647050597, 'Total loss': 0.5265966647050597} | train loss {'Reaction outcome loss': 0.507369572349957, 'Total loss': 0.507369572349957}
2022-12-05 22:45:47,232 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:47,233 INFO:     Epoch: 96
2022-12-05 22:45:47,944 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4952512093904344, 'Total loss': 0.4952512093904344} | train loss {'Reaction outcome loss': 0.5064475526006854, 'Total loss': 0.5064475526006854}
2022-12-05 22:45:47,945 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:47,945 INFO:     Epoch: 97
2022-12-05 22:45:48,652 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5161656385118311, 'Total loss': 0.5161656385118311} | train loss {'Reaction outcome loss': 0.5082709342241287, 'Total loss': 0.5082709342241287}
2022-12-05 22:45:48,652 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:48,652 INFO:     Epoch: 98
2022-12-05 22:45:49,362 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5062411176887426, 'Total loss': 0.5062411176887426} | train loss {'Reaction outcome loss': 0.5041163179947405, 'Total loss': 0.5041163179947405}
2022-12-05 22:45:49,362 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:49,362 INFO:     Epoch: 99
2022-12-05 22:45:50,069 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5000154237178239, 'Total loss': 0.5000154237178239} | train loss {'Reaction outcome loss': 0.5105339922467057, 'Total loss': 0.5105339922467057}
2022-12-05 22:45:50,069 INFO:     Best model found after epoch 35 of 100.
2022-12-05 22:45:50,069 INFO:   Done with stage: TRAINING
2022-12-05 22:45:50,070 INFO:   Starting stage: EVALUATION
2022-12-05 22:45:50,200 INFO:   Done with stage: EVALUATION
2022-12-05 22:45:50,200 INFO:   Leaving out SEQ value Fold_4
2022-12-05 22:45:50,213 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:45:50,213 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:45:50,850 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:45:50,851 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:45:50,921 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:45:50,921 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:45:50,921 INFO:     No hyperparam tuning for this model
2022-12-05 22:45:50,921 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:45:50,921 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:45:50,922 INFO:     None feature selector for col prot
2022-12-05 22:45:50,922 INFO:     None feature selector for col prot
2022-12-05 22:45:50,922 INFO:     None feature selector for col prot
2022-12-05 22:45:50,923 INFO:     None feature selector for col chem
2022-12-05 22:45:50,923 INFO:     None feature selector for col chem
2022-12-05 22:45:50,923 INFO:     None feature selector for col chem
2022-12-05 22:45:50,923 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:45:50,923 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:45:50,925 INFO:     Number of params in model 215731
2022-12-05 22:45:50,928 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:45:50,928 INFO:   Starting stage: TRAINING
2022-12-05 22:45:50,987 INFO:     Val loss before train {'Reaction outcome loss': 1.0105578384616158, 'Total loss': 1.0105578384616158}
2022-12-05 22:45:50,987 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:50,987 INFO:     Epoch: 0
2022-12-05 22:45:51,699 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7726589705456387, 'Total loss': 0.7726589705456387} | train loss {'Reaction outcome loss': 0.7894442069287203, 'Total loss': 0.7894442069287203}
2022-12-05 22:45:51,699 INFO:     Found new best model at epoch 0
2022-12-05 22:45:51,700 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:51,700 INFO:     Epoch: 1
2022-12-05 22:45:52,409 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6678672107783231, 'Total loss': 0.6678672107783231} | train loss {'Reaction outcome loss': 0.6706498142407865, 'Total loss': 0.6706498142407865}
2022-12-05 22:45:52,409 INFO:     Found new best model at epoch 1
2022-12-05 22:45:52,410 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:52,410 INFO:     Epoch: 2
2022-12-05 22:45:53,118 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6645711850036274, 'Total loss': 0.6645711850036274} | train loss {'Reaction outcome loss': 0.6332553338031379, 'Total loss': 0.6332553338031379}
2022-12-05 22:45:53,118 INFO:     Found new best model at epoch 2
2022-12-05 22:45:53,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:53,119 INFO:     Epoch: 3
2022-12-05 22:45:53,830 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5771412781693719, 'Total loss': 0.5771412781693719} | train loss {'Reaction outcome loss': 0.6067370176923518, 'Total loss': 0.6067370176923518}
2022-12-05 22:45:53,830 INFO:     Found new best model at epoch 3
2022-12-05 22:45:53,830 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:53,831 INFO:     Epoch: 4
2022-12-05 22:45:54,542 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6456494629383087, 'Total loss': 0.6456494629383087} | train loss {'Reaction outcome loss': 0.5831549440111433, 'Total loss': 0.5831549440111433}
2022-12-05 22:45:54,542 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:54,543 INFO:     Epoch: 5
2022-12-05 22:45:55,255 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5883546901697462, 'Total loss': 0.5883546901697462} | train loss {'Reaction outcome loss': 0.5750922319232201, 'Total loss': 0.5750922319232201}
2022-12-05 22:45:55,255 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:55,256 INFO:     Epoch: 6
2022-12-05 22:45:55,966 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5324595560404387, 'Total loss': 0.5324595560404387} | train loss {'Reaction outcome loss': 0.5588750219466735, 'Total loss': 0.5588750219466735}
2022-12-05 22:45:55,966 INFO:     Found new best model at epoch 6
2022-12-05 22:45:55,967 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:55,967 INFO:     Epoch: 7
2022-12-05 22:45:56,675 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5529184734279459, 'Total loss': 0.5529184734279459} | train loss {'Reaction outcome loss': 0.5467564199651991, 'Total loss': 0.5467564199651991}
2022-12-05 22:45:56,675 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:56,675 INFO:     Epoch: 8
2022-12-05 22:45:57,382 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5427253639156168, 'Total loss': 0.5427253639156168} | train loss {'Reaction outcome loss': 0.5462665578540491, 'Total loss': 0.5462665578540491}
2022-12-05 22:45:57,382 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:57,382 INFO:     Epoch: 9
2022-12-05 22:45:58,088 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5433659621260383, 'Total loss': 0.5433659621260383} | train loss {'Reaction outcome loss': 0.5500668807297336, 'Total loss': 0.5500668807297336}
2022-12-05 22:45:58,088 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:58,088 INFO:     Epoch: 10
2022-12-05 22:45:58,798 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5287536402994936, 'Total loss': 0.5287536402994936} | train loss {'Reaction outcome loss': 0.5419160976093642, 'Total loss': 0.5419160976093642}
2022-12-05 22:45:58,799 INFO:     Found new best model at epoch 10
2022-12-05 22:45:58,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:58,799 INFO:     Epoch: 11
2022-12-05 22:45:59,510 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5595033859664743, 'Total loss': 0.5595033859664743} | train loss {'Reaction outcome loss': 0.5356895355545744, 'Total loss': 0.5356895355545744}
2022-12-05 22:45:59,510 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:45:59,510 INFO:     Epoch: 12
2022-12-05 22:46:00,222 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.588758612898263, 'Total loss': 0.588758612898263} | train loss {'Reaction outcome loss': 0.5401491149347656, 'Total loss': 0.5401491149347656}
2022-12-05 22:46:00,222 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:00,222 INFO:     Epoch: 13
2022-12-05 22:46:00,933 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5510948537425562, 'Total loss': 0.5510948537425562} | train loss {'Reaction outcome loss': 0.5224109611949143, 'Total loss': 0.5224109611949143}
2022-12-05 22:46:00,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:00,933 INFO:     Epoch: 14
2022-12-05 22:46:01,643 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5462898842313073, 'Total loss': 0.5462898842313073} | train loss {'Reaction outcome loss': 0.5343875380803128, 'Total loss': 0.5343875380803128}
2022-12-05 22:46:01,643 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:01,643 INFO:     Epoch: 15
2022-12-05 22:46:02,354 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5618378404866565, 'Total loss': 0.5618378404866565} | train loss {'Reaction outcome loss': 0.5300171672689672, 'Total loss': 0.5300171672689672}
2022-12-05 22:46:02,354 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:02,354 INFO:     Epoch: 16
2022-12-05 22:46:03,065 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.542772057720206, 'Total loss': 0.542772057720206} | train loss {'Reaction outcome loss': 0.5392324086050598, 'Total loss': 0.5392324086050598}
2022-12-05 22:46:03,065 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:03,065 INFO:     Epoch: 17
2022-12-05 22:46:03,775 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5183289274573326, 'Total loss': 0.5183289274573326} | train loss {'Reaction outcome loss': 0.5175077443220177, 'Total loss': 0.5175077443220177}
2022-12-05 22:46:03,775 INFO:     Found new best model at epoch 17
2022-12-05 22:46:03,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:03,776 INFO:     Epoch: 18
2022-12-05 22:46:04,487 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5351319868456234, 'Total loss': 0.5351319868456234} | train loss {'Reaction outcome loss': 0.5347952851835562, 'Total loss': 0.5347952851835562}
2022-12-05 22:46:04,487 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:04,487 INFO:     Epoch: 19
2022-12-05 22:46:05,195 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5566461912610314, 'Total loss': 0.5566461912610314} | train loss {'Reaction outcome loss': 0.5248001590675238, 'Total loss': 0.5248001590675238}
2022-12-05 22:46:05,195 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:05,195 INFO:     Epoch: 20
2022-12-05 22:46:05,902 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5352998253974047, 'Total loss': 0.5352998253974047} | train loss {'Reaction outcome loss': 0.5188857726904811, 'Total loss': 0.5188857726904811}
2022-12-05 22:46:05,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:05,902 INFO:     Epoch: 21
2022-12-05 22:46:06,609 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5354199108075012, 'Total loss': 0.5354199108075012} | train loss {'Reaction outcome loss': 0.5181594731856366, 'Total loss': 0.5181594731856366}
2022-12-05 22:46:06,609 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:06,610 INFO:     Epoch: 22
2022-12-05 22:46:07,317 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5695261271162466, 'Total loss': 0.5695261271162466} | train loss {'Reaction outcome loss': 0.5186965761136035, 'Total loss': 0.5186965761136035}
2022-12-05 22:46:07,317 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:07,318 INFO:     Epoch: 23
2022-12-05 22:46:08,028 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5452638383616101, 'Total loss': 0.5452638383616101} | train loss {'Reaction outcome loss': 0.5138260891851114, 'Total loss': 0.5138260891851114}
2022-12-05 22:46:08,028 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:08,028 INFO:     Epoch: 24
2022-12-05 22:46:08,734 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5097495473243974, 'Total loss': 0.5097495473243974} | train loss {'Reaction outcome loss': 0.5180371845255093, 'Total loss': 0.5180371845255093}
2022-12-05 22:46:08,735 INFO:     Found new best model at epoch 24
2022-12-05 22:46:08,735 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:08,735 INFO:     Epoch: 25
2022-12-05 22:46:09,443 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5127999037504196, 'Total loss': 0.5127999037504196} | train loss {'Reaction outcome loss': 0.51022175675144, 'Total loss': 0.51022175675144}
2022-12-05 22:46:09,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:09,444 INFO:     Epoch: 26
2022-12-05 22:46:10,158 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5416554578325965, 'Total loss': 0.5416554578325965} | train loss {'Reaction outcome loss': 0.5089058515368675, 'Total loss': 0.5089058515368675}
2022-12-05 22:46:10,158 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:10,158 INFO:     Epoch: 27
2022-12-05 22:46:10,868 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5457173721356825, 'Total loss': 0.5457173721356825} | train loss {'Reaction outcome loss': 0.5137123263003874, 'Total loss': 0.5137123263003874}
2022-12-05 22:46:10,868 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:10,868 INFO:     Epoch: 28
2022-12-05 22:46:11,578 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5150026489387859, 'Total loss': 0.5150026489387859} | train loss {'Reaction outcome loss': 0.5145083296663907, 'Total loss': 0.5145083296663907}
2022-12-05 22:46:11,578 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:11,578 INFO:     Epoch: 29
2022-12-05 22:46:12,291 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5182746855372732, 'Total loss': 0.5182746855372732} | train loss {'Reaction outcome loss': 0.5153703893933977, 'Total loss': 0.5153703893933977}
2022-12-05 22:46:12,292 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:12,292 INFO:     Epoch: 30
2022-12-05 22:46:13,001 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.6179080903530121, 'Total loss': 0.6179080903530121} | train loss {'Reaction outcome loss': 0.5158209218662613, 'Total loss': 0.5158209218662613}
2022-12-05 22:46:13,001 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:13,001 INFO:     Epoch: 31
2022-12-05 22:46:13,709 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5133199786598032, 'Total loss': 0.5133199786598032} | train loss {'Reaction outcome loss': 0.512478085135927, 'Total loss': 0.512478085135927}
2022-12-05 22:46:13,709 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:13,709 INFO:     Epoch: 32
2022-12-05 22:46:14,420 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5293474972925403, 'Total loss': 0.5293474972925403} | train loss {'Reaction outcome loss': 0.5080373847971157, 'Total loss': 0.5080373847971157}
2022-12-05 22:46:14,420 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:14,420 INFO:     Epoch: 33
2022-12-05 22:46:15,127 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5232436223463579, 'Total loss': 0.5232436223463579} | train loss {'Reaction outcome loss': 0.5135270642990969, 'Total loss': 0.5135270642990969}
2022-12-05 22:46:15,128 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:15,128 INFO:     Epoch: 34
2022-12-05 22:46:15,839 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5200376287102699, 'Total loss': 0.5200376287102699} | train loss {'Reaction outcome loss': 0.5074659620012556, 'Total loss': 0.5074659620012556}
2022-12-05 22:46:15,839 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:15,839 INFO:     Epoch: 35
2022-12-05 22:46:16,546 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.499540469863198, 'Total loss': 0.499540469863198} | train loss {'Reaction outcome loss': 0.5149396463316314, 'Total loss': 0.5149396463316314}
2022-12-05 22:46:16,546 INFO:     Found new best model at epoch 35
2022-12-05 22:46:16,547 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:16,547 INFO:     Epoch: 36
2022-12-05 22:46:17,254 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5359365598044612, 'Total loss': 0.5359365598044612} | train loss {'Reaction outcome loss': 0.5164619091822177, 'Total loss': 0.5164619091822177}
2022-12-05 22:46:17,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:17,255 INFO:     Epoch: 37
2022-12-05 22:46:17,962 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5118621865456755, 'Total loss': 0.5118621865456755} | train loss {'Reaction outcome loss': 0.5085657161717512, 'Total loss': 0.5085657161717512}
2022-12-05 22:46:17,962 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:17,963 INFO:     Epoch: 38
2022-12-05 22:46:18,670 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5259971936995332, 'Total loss': 0.5259971936995332} | train loss {'Reaction outcome loss': 0.5045970488567741, 'Total loss': 0.5045970488567741}
2022-12-05 22:46:18,670 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:18,670 INFO:     Epoch: 39
2022-12-05 22:46:19,377 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.508904466913505, 'Total loss': 0.508904466913505} | train loss {'Reaction outcome loss': 0.508516820717831, 'Total loss': 0.508516820717831}
2022-12-05 22:46:19,378 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:19,378 INFO:     Epoch: 40
2022-12-05 22:46:20,087 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5387302542274649, 'Total loss': 0.5387302542274649} | train loss {'Reaction outcome loss': 0.5045942878236576, 'Total loss': 0.5045942878236576}
2022-12-05 22:46:20,087 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:20,087 INFO:     Epoch: 41
2022-12-05 22:46:20,797 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5053673576224934, 'Total loss': 0.5053673576224934} | train loss {'Reaction outcome loss': 0.5024253687688283, 'Total loss': 0.5024253687688283}
2022-12-05 22:46:20,797 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:20,797 INFO:     Epoch: 42
2022-12-05 22:46:21,506 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5050085241144354, 'Total loss': 0.5050085241144354} | train loss {'Reaction outcome loss': 0.5034844048169195, 'Total loss': 0.5034844048169195}
2022-12-05 22:46:21,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:21,507 INFO:     Epoch: 43
2022-12-05 22:46:22,215 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5334108827466314, 'Total loss': 0.5334108827466314} | train loss {'Reaction outcome loss': 0.5088363408434148, 'Total loss': 0.5088363408434148}
2022-12-05 22:46:22,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:22,216 INFO:     Epoch: 44
2022-12-05 22:46:22,923 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5091077510944821, 'Total loss': 0.5091077510944821} | train loss {'Reaction outcome loss': 0.505264641557421, 'Total loss': 0.505264641557421}
2022-12-05 22:46:22,923 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:22,923 INFO:     Epoch: 45
2022-12-05 22:46:23,632 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5035894120281393, 'Total loss': 0.5035894120281393} | train loss {'Reaction outcome loss': 0.504785621896082, 'Total loss': 0.504785621896082}
2022-12-05 22:46:23,632 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:23,632 INFO:     Epoch: 46
2022-12-05 22:46:24,345 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5147481173149903, 'Total loss': 0.5147481173149903} | train loss {'Reaction outcome loss': 0.5077326162737243, 'Total loss': 0.5077326162737243}
2022-12-05 22:46:24,345 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:24,345 INFO:     Epoch: 47
2022-12-05 22:46:25,053 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5709426362406124, 'Total loss': 0.5709426362406124} | train loss {'Reaction outcome loss': 0.5055887323253009, 'Total loss': 0.5055887323253009}
2022-12-05 22:46:25,053 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:25,054 INFO:     Epoch: 48
2022-12-05 22:46:25,760 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5102293381509795, 'Total loss': 0.5102293381509795} | train loss {'Reaction outcome loss': 0.5066223597039982, 'Total loss': 0.5066223597039982}
2022-12-05 22:46:25,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:25,761 INFO:     Epoch: 49
2022-12-05 22:46:26,464 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.514184711331671, 'Total loss': 0.514184711331671} | train loss {'Reaction outcome loss': 0.5168966092017232, 'Total loss': 0.5168966092017232}
2022-12-05 22:46:26,464 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:26,464 INFO:     Epoch: 50
2022-12-05 22:46:27,164 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5633340423757379, 'Total loss': 0.5633340423757379} | train loss {'Reaction outcome loss': 0.5113783850353592, 'Total loss': 0.5113783850353592}
2022-12-05 22:46:27,164 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:27,164 INFO:     Epoch: 51
2022-12-05 22:46:27,869 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.562172301536934, 'Total loss': 0.562172301536934} | train loss {'Reaction outcome loss': 0.5073369727450974, 'Total loss': 0.5073369727450974}
2022-12-05 22:46:27,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:27,869 INFO:     Epoch: 52
2022-12-05 22:46:28,570 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.524270310997963, 'Total loss': 0.524270310997963} | train loss {'Reaction outcome loss': 0.5066883492834714, 'Total loss': 0.5066883492834714}
2022-12-05 22:46:28,570 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:28,570 INFO:     Epoch: 53
2022-12-05 22:46:29,271 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5448390638286417, 'Total loss': 0.5448390638286417} | train loss {'Reaction outcome loss': 0.5127942762204579, 'Total loss': 0.5127942762204579}
2022-12-05 22:46:29,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:29,271 INFO:     Epoch: 54
2022-12-05 22:46:29,977 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.526838287033818, 'Total loss': 0.526838287033818} | train loss {'Reaction outcome loss': 0.5075891750807665, 'Total loss': 0.5075891750807665}
2022-12-05 22:46:29,977 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:29,977 INFO:     Epoch: 55
2022-12-05 22:46:30,678 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5315342132340778, 'Total loss': 0.5315342132340778} | train loss {'Reaction outcome loss': 0.5120329643998828, 'Total loss': 0.5120329643998828}
2022-12-05 22:46:30,678 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:30,678 INFO:     Epoch: 56
2022-12-05 22:46:31,382 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5283064401962541, 'Total loss': 0.5283064401962541} | train loss {'Reaction outcome loss': 0.513157306216201, 'Total loss': 0.513157306216201}
2022-12-05 22:46:31,383 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:31,383 INFO:     Epoch: 57
2022-12-05 22:46:32,086 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5167669426988472, 'Total loss': 0.5167669426988472} | train loss {'Reaction outcome loss': 0.5070575500021175, 'Total loss': 0.5070575500021175}
2022-12-05 22:46:32,086 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:32,086 INFO:     Epoch: 58
2022-12-05 22:46:32,787 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.504012620923194, 'Total loss': 0.504012620923194} | train loss {'Reaction outcome loss': 0.5034948025430952, 'Total loss': 0.5034948025430952}
2022-12-05 22:46:32,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:32,787 INFO:     Epoch: 59
2022-12-05 22:46:33,488 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.523882813074372, 'Total loss': 0.523882813074372} | train loss {'Reaction outcome loss': 0.5127490050330454, 'Total loss': 0.5127490050330454}
2022-12-05 22:46:33,488 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:33,489 INFO:     Epoch: 60
2022-12-05 22:46:34,189 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.492947459559549, 'Total loss': 0.492947459559549} | train loss {'Reaction outcome loss': 0.5110080212962871, 'Total loss': 0.5110080212962871}
2022-12-05 22:46:34,189 INFO:     Found new best model at epoch 60
2022-12-05 22:46:34,190 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:34,190 INFO:     Epoch: 61
2022-12-05 22:46:34,891 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.505046603015878, 'Total loss': 0.505046603015878} | train loss {'Reaction outcome loss': 0.5043959223494238, 'Total loss': 0.5043959223494238}
2022-12-05 22:46:34,891 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:34,891 INFO:     Epoch: 62
2022-12-05 22:46:35,593 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5223968936638399, 'Total loss': 0.5223968936638399} | train loss {'Reaction outcome loss': 0.5066115551457113, 'Total loss': 0.5066115551457113}
2022-12-05 22:46:35,593 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:35,593 INFO:     Epoch: 63
2022-12-05 22:46:36,297 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5126750533553687, 'Total loss': 0.5126750533553687} | train loss {'Reaction outcome loss': 0.5052450729267938, 'Total loss': 0.5052450729267938}
2022-12-05 22:46:36,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:36,297 INFO:     Epoch: 64
2022-12-05 22:46:36,999 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5046881589699875, 'Total loss': 0.5046881589699875} | train loss {'Reaction outcome loss': 0.5088536908431929, 'Total loss': 0.5088536908431929}
2022-12-05 22:46:36,999 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:36,999 INFO:     Epoch: 65
2022-12-05 22:46:37,705 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5141684890470721, 'Total loss': 0.5141684890470721} | train loss {'Reaction outcome loss': 0.5070739448070526, 'Total loss': 0.5070739448070526}
2022-12-05 22:46:37,705 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:37,705 INFO:     Epoch: 66
2022-12-05 22:46:38,409 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5252746357159181, 'Total loss': 0.5252746357159181} | train loss {'Reaction outcome loss': 0.5062935523840846, 'Total loss': 0.5062935523840846}
2022-12-05 22:46:38,410 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:38,410 INFO:     Epoch: 67
2022-12-05 22:46:39,111 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5222499824383042, 'Total loss': 0.5222499824383042} | train loss {'Reaction outcome loss': 0.5016952408819783, 'Total loss': 0.5016952408819783}
2022-12-05 22:46:39,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:39,111 INFO:     Epoch: 68
2022-12-05 22:46:39,812 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5207087336616083, 'Total loss': 0.5207087336616083} | train loss {'Reaction outcome loss': 0.5059503418450453, 'Total loss': 0.5059503418450453}
2022-12-05 22:46:39,812 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:39,812 INFO:     Epoch: 69
2022-12-05 22:46:40,519 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.571609350090677, 'Total loss': 0.571609350090677} | train loss {'Reaction outcome loss': 0.5034325370374991, 'Total loss': 0.5034325370374991}
2022-12-05 22:46:40,519 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:40,519 INFO:     Epoch: 70
2022-12-05 22:46:41,223 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5059988180344756, 'Total loss': 0.5059988180344756} | train loss {'Reaction outcome loss': 0.5094022710104378, 'Total loss': 0.5094022710104378}
2022-12-05 22:46:41,223 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:41,223 INFO:     Epoch: 71
2022-12-05 22:46:41,925 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5150837437673048, 'Total loss': 0.5150837437673048} | train loss {'Reaction outcome loss': 0.5136602492356787, 'Total loss': 0.5136602492356787}
2022-12-05 22:46:41,925 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:41,925 INFO:     Epoch: 72
2022-12-05 22:46:42,628 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5054931528866291, 'Total loss': 0.5054931528866291} | train loss {'Reaction outcome loss': 0.5058766543256993, 'Total loss': 0.5058766543256993}
2022-12-05 22:46:42,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:42,628 INFO:     Epoch: 73
2022-12-05 22:46:43,329 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5494921957565979, 'Total loss': 0.5494921957565979} | train loss {'Reaction outcome loss': 0.5004901748530719, 'Total loss': 0.5004901748530719}
2022-12-05 22:46:43,329 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:43,329 INFO:     Epoch: 74
2022-12-05 22:46:44,031 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.514607404104688, 'Total loss': 0.514607404104688} | train loss {'Reaction outcome loss': 0.5098559227524971, 'Total loss': 0.5098559227524971}
2022-12-05 22:46:44,031 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:44,032 INFO:     Epoch: 75
2022-12-05 22:46:44,733 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5173590318723158, 'Total loss': 0.5173590318723158} | train loss {'Reaction outcome loss': 0.5102774844485887, 'Total loss': 0.5102774844485887}
2022-12-05 22:46:44,733 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:44,733 INFO:     Epoch: 76
2022-12-05 22:46:45,441 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5096509879962965, 'Total loss': 0.5096509879962965} | train loss {'Reaction outcome loss': 0.5107326197989133, 'Total loss': 0.5107326197989133}
2022-12-05 22:46:45,441 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:45,441 INFO:     Epoch: 77
2022-12-05 22:46:46,145 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5354578285054727, 'Total loss': 0.5354578285054727} | train loss {'Reaction outcome loss': 0.5144168899375565, 'Total loss': 0.5144168899375565}
2022-12-05 22:46:46,145 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:46,145 INFO:     Epoch: 78
2022-12-05 22:46:46,850 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5331273332915523, 'Total loss': 0.5331273332915523} | train loss {'Reaction outcome loss': 0.5083718582075469, 'Total loss': 0.5083718582075469}
2022-12-05 22:46:46,850 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:46,850 INFO:     Epoch: 79
2022-12-05 22:46:47,552 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.504735697738149, 'Total loss': 0.504735697738149} | train loss {'Reaction outcome loss': 0.5107091131258984, 'Total loss': 0.5107091131258984}
2022-12-05 22:46:47,552 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:47,553 INFO:     Epoch: 80
2022-12-05 22:46:48,258 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5242158370939168, 'Total loss': 0.5242158370939168} | train loss {'Reaction outcome loss': 0.504487139473156, 'Total loss': 0.504487139473156}
2022-12-05 22:46:48,258 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:48,258 INFO:     Epoch: 81
2022-12-05 22:46:48,959 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5056307024576447, 'Total loss': 0.5056307024576447} | train loss {'Reaction outcome loss': 0.5088717357236512, 'Total loss': 0.5088717357236512}
2022-12-05 22:46:48,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:48,959 INFO:     Epoch: 82
2022-12-05 22:46:49,664 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49421065978028555, 'Total loss': 0.49421065978028555} | train loss {'Reaction outcome loss': 0.504360339471272, 'Total loss': 0.504360339471272}
2022-12-05 22:46:49,664 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:49,664 INFO:     Epoch: 83
2022-12-05 22:46:50,372 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5218163119121031, 'Total loss': 0.5218163119121031} | train loss {'Reaction outcome loss': 0.5053539986513099, 'Total loss': 0.5053539986513099}
2022-12-05 22:46:50,373 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:50,374 INFO:     Epoch: 84
2022-12-05 22:46:51,081 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5369667497209527, 'Total loss': 0.5369667497209527} | train loss {'Reaction outcome loss': 0.5124047255029484, 'Total loss': 0.5124047255029484}
2022-12-05 22:46:51,081 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:51,081 INFO:     Epoch: 85
2022-12-05 22:46:51,785 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.512347477403554, 'Total loss': 0.512347477403554} | train loss {'Reaction outcome loss': 0.5070011889447972, 'Total loss': 0.5070011889447972}
2022-12-05 22:46:51,785 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:51,785 INFO:     Epoch: 86
2022-12-05 22:46:52,488 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4852353421632539, 'Total loss': 0.4852353421632539} | train loss {'Reaction outcome loss': 0.5044358742480375, 'Total loss': 0.5044358742480375}
2022-12-05 22:46:52,488 INFO:     Found new best model at epoch 86
2022-12-05 22:46:52,489 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:52,489 INFO:     Epoch: 87
2022-12-05 22:46:53,189 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5889222655784, 'Total loss': 0.5889222655784} | train loss {'Reaction outcome loss': 0.49982788282997753, 'Total loss': 0.49982788282997753}
2022-12-05 22:46:53,189 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:53,189 INFO:     Epoch: 88
2022-12-05 22:46:53,890 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.515957170250741, 'Total loss': 0.515957170250741} | train loss {'Reaction outcome loss': 0.5103856489366415, 'Total loss': 0.5103856489366415}
2022-12-05 22:46:53,890 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:53,890 INFO:     Epoch: 89
2022-12-05 22:46:54,592 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5080532299524004, 'Total loss': 0.5080532299524004} | train loss {'Reaction outcome loss': 0.5017477812207475, 'Total loss': 0.5017477812207475}
2022-12-05 22:46:54,593 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:54,593 INFO:     Epoch: 90
2022-12-05 22:46:55,291 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5166433595798232, 'Total loss': 0.5166433595798232} | train loss {'Reaction outcome loss': 0.5084336039971332, 'Total loss': 0.5084336039971332}
2022-12-05 22:46:55,291 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:55,291 INFO:     Epoch: 91
2022-12-05 22:46:55,988 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5167101994156837, 'Total loss': 0.5167101994156837} | train loss {'Reaction outcome loss': 0.5056477996767784, 'Total loss': 0.5056477996767784}
2022-12-05 22:46:55,988 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:55,989 INFO:     Epoch: 92
2022-12-05 22:46:56,690 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5353853465481238, 'Total loss': 0.5353853465481238} | train loss {'Reaction outcome loss': 0.5080333912859157, 'Total loss': 0.5080333912859157}
2022-12-05 22:46:56,691 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:56,691 INFO:     Epoch: 93
2022-12-05 22:46:57,388 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5222916318611666, 'Total loss': 0.5222916318611666} | train loss {'Reaction outcome loss': 0.5091729681102597, 'Total loss': 0.5091729681102597}
2022-12-05 22:46:57,388 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:57,388 INFO:     Epoch: 94
2022-12-05 22:46:58,083 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5128153186630119, 'Total loss': 0.5128153186630119} | train loss {'Reaction outcome loss': 0.5043799496426874, 'Total loss': 0.5043799496426874}
2022-12-05 22:46:58,084 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:58,084 INFO:     Epoch: 95
2022-12-05 22:46:58,780 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5243409187956289, 'Total loss': 0.5243409187956289} | train loss {'Reaction outcome loss': 0.5089719773555289, 'Total loss': 0.5089719773555289}
2022-12-05 22:46:58,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:58,780 INFO:     Epoch: 96
2022-12-05 22:46:59,478 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5277225212617354, 'Total loss': 0.5277225212617354} | train loss {'Reaction outcome loss': 0.5067690547631711, 'Total loss': 0.5067690547631711}
2022-12-05 22:46:59,479 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:46:59,479 INFO:     Epoch: 97
2022-12-05 22:47:00,182 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5147210803221572, 'Total loss': 0.5147210803221572} | train loss {'Reaction outcome loss': 0.5099733535124331, 'Total loss': 0.5099733535124331}
2022-12-05 22:47:00,182 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:00,182 INFO:     Epoch: 98
2022-12-05 22:47:00,884 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5198845605958592, 'Total loss': 0.5198845605958592} | train loss {'Reaction outcome loss': 0.5093348810259177, 'Total loss': 0.5093348810259177}
2022-12-05 22:47:00,884 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:00,884 INFO:     Epoch: 99
2022-12-05 22:47:01,585 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5028940832073038, 'Total loss': 0.5028940832073038} | train loss {'Reaction outcome loss': 0.5090470015394445, 'Total loss': 0.5090470015394445}
2022-12-05 22:47:01,585 INFO:     Best model found after epoch 87 of 100.
2022-12-05 22:47:01,585 INFO:   Done with stage: TRAINING
2022-12-05 22:47:01,585 INFO:   Starting stage: EVALUATION
2022-12-05 22:47:01,714 INFO:   Done with stage: EVALUATION
2022-12-05 22:47:01,714 INFO:   Leaving out SEQ value Fold_5
2022-12-05 22:47:01,726 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:47:01,726 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:47:02,365 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:47:02,365 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:47:02,436 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:47:02,436 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:47:02,436 INFO:     No hyperparam tuning for this model
2022-12-05 22:47:02,436 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:47:02,436 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:47:02,437 INFO:     None feature selector for col prot
2022-12-05 22:47:02,437 INFO:     None feature selector for col prot
2022-12-05 22:47:02,437 INFO:     None feature selector for col prot
2022-12-05 22:47:02,437 INFO:     None feature selector for col chem
2022-12-05 22:47:02,438 INFO:     None feature selector for col chem
2022-12-05 22:47:02,438 INFO:     None feature selector for col chem
2022-12-05 22:47:02,438 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:47:02,438 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:47:02,439 INFO:     Number of params in model 215731
2022-12-05 22:47:02,442 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:47:02,442 INFO:   Starting stage: TRAINING
2022-12-05 22:47:02,500 INFO:     Val loss before train {'Reaction outcome loss': 1.0222082463177768, 'Total loss': 1.0222082463177768}
2022-12-05 22:47:02,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:02,500 INFO:     Epoch: 0
2022-12-05 22:47:03,200 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7126189456744627, 'Total loss': 0.7126189456744627} | train loss {'Reaction outcome loss': 0.8166943832568312, 'Total loss': 0.8166943832568312}
2022-12-05 22:47:03,200 INFO:     Found new best model at epoch 0
2022-12-05 22:47:03,201 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:03,201 INFO:     Epoch: 1
2022-12-05 22:47:03,901 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6357530125162818, 'Total loss': 0.6357530125162818} | train loss {'Reaction outcome loss': 0.6761767823203855, 'Total loss': 0.6761767823203855}
2022-12-05 22:47:03,901 INFO:     Found new best model at epoch 1
2022-12-05 22:47:03,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:03,902 INFO:     Epoch: 2
2022-12-05 22:47:04,603 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6589703187346458, 'Total loss': 0.6589703187346458} | train loss {'Reaction outcome loss': 0.6222079446320592, 'Total loss': 0.6222079446320592}
2022-12-05 22:47:04,603 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:04,603 INFO:     Epoch: 3
2022-12-05 22:47:05,307 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5938599868254228, 'Total loss': 0.5938599868254228} | train loss {'Reaction outcome loss': 0.5950828444981865, 'Total loss': 0.5950828444981865}
2022-12-05 22:47:05,307 INFO:     Found new best model at epoch 3
2022-12-05 22:47:05,308 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:05,308 INFO:     Epoch: 4
2022-12-05 22:47:06,010 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5942065763202581, 'Total loss': 0.5942065763202581} | train loss {'Reaction outcome loss': 0.5865479697462036, 'Total loss': 0.5865479697462036}
2022-12-05 22:47:06,010 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:06,010 INFO:     Epoch: 5
2022-12-05 22:47:06,711 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5876793197610162, 'Total loss': 0.5876793197610162} | train loss {'Reaction outcome loss': 0.5626506616591442, 'Total loss': 0.5626506616591442}
2022-12-05 22:47:06,711 INFO:     Found new best model at epoch 5
2022-12-05 22:47:06,712 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:06,712 INFO:     Epoch: 6
2022-12-05 22:47:07,413 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5563685460524126, 'Total loss': 0.5563685460524126} | train loss {'Reaction outcome loss': 0.5609617778646802, 'Total loss': 0.5609617778646802}
2022-12-05 22:47:07,413 INFO:     Found new best model at epoch 6
2022-12-05 22:47:07,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:07,414 INFO:     Epoch: 7
2022-12-05 22:47:08,116 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5836830173026432, 'Total loss': 0.5836830173026432} | train loss {'Reaction outcome loss': 0.5579536670615316, 'Total loss': 0.5579536670615316}
2022-12-05 22:47:08,116 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:08,116 INFO:     Epoch: 8
2022-12-05 22:47:08,818 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5768433653495528, 'Total loss': 0.5768433653495528} | train loss {'Reaction outcome loss': 0.5571607696985909, 'Total loss': 0.5571607696985909}
2022-12-05 22:47:08,819 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:08,819 INFO:     Epoch: 9
2022-12-05 22:47:09,525 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5594566572796215, 'Total loss': 0.5594566572796215} | train loss {'Reaction outcome loss': 0.55589405196881, 'Total loss': 0.55589405196881}
2022-12-05 22:47:09,525 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:09,525 INFO:     Epoch: 10
2022-12-05 22:47:10,229 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5671250677921555, 'Total loss': 0.5671250677921555} | train loss {'Reaction outcome loss': 0.5388034923899512, 'Total loss': 0.5388034923899512}
2022-12-05 22:47:10,229 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:10,229 INFO:     Epoch: 11
2022-12-05 22:47:10,931 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5595539110628042, 'Total loss': 0.5595539110628042} | train loss {'Reaction outcome loss': 0.5332062353006741, 'Total loss': 0.5332062353006741}
2022-12-05 22:47:10,931 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:10,931 INFO:     Epoch: 12
2022-12-05 22:47:11,632 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5506533797491681, 'Total loss': 0.5506533797491681} | train loss {'Reaction outcome loss': 0.5392687578312299, 'Total loss': 0.5392687578312299}
2022-12-05 22:47:11,633 INFO:     Found new best model at epoch 12
2022-12-05 22:47:11,633 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:11,633 INFO:     Epoch: 13
2022-12-05 22:47:12,340 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5489825199950825, 'Total loss': 0.5489825199950825} | train loss {'Reaction outcome loss': 0.5292937420647938, 'Total loss': 0.5292937420647938}
2022-12-05 22:47:12,340 INFO:     Found new best model at epoch 13
2022-12-05 22:47:12,341 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:12,341 INFO:     Epoch: 14
2022-12-05 22:47:13,043 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5477532940832052, 'Total loss': 0.5477532940832052} | train loss {'Reaction outcome loss': 0.5260530650947499, 'Total loss': 0.5260530650947499}
2022-12-05 22:47:13,043 INFO:     Found new best model at epoch 14
2022-12-05 22:47:13,043 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:13,044 INFO:     Epoch: 15
2022-12-05 22:47:13,744 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5476544790647246, 'Total loss': 0.5476544790647246} | train loss {'Reaction outcome loss': 0.5346945479572544, 'Total loss': 0.5346945479572544}
2022-12-05 22:47:13,744 INFO:     Found new best model at epoch 15
2022-12-05 22:47:13,745 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:13,745 INFO:     Epoch: 16
2022-12-05 22:47:14,446 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5836852050640366, 'Total loss': 0.5836852050640366} | train loss {'Reaction outcome loss': 0.5280690857865339, 'Total loss': 0.5280690857865339}
2022-12-05 22:47:14,446 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:14,446 INFO:     Epoch: 17
2022-12-05 22:47:15,147 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5823526592417196, 'Total loss': 0.5823526592417196} | train loss {'Reaction outcome loss': 0.5268959995464757, 'Total loss': 0.5268959995464757}
2022-12-05 22:47:15,148 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:15,148 INFO:     Epoch: 18
2022-12-05 22:47:15,849 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5457221831787716, 'Total loss': 0.5457221831787716} | train loss {'Reaction outcome loss': 0.5189626969789204, 'Total loss': 0.5189626969789204}
2022-12-05 22:47:15,849 INFO:     Found new best model at epoch 18
2022-12-05 22:47:15,849 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:15,849 INFO:     Epoch: 19
2022-12-05 22:47:16,552 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5352006534283812, 'Total loss': 0.5352006534283812} | train loss {'Reaction outcome loss': 0.5159024173310893, 'Total loss': 0.5159024173310893}
2022-12-05 22:47:16,552 INFO:     Found new best model at epoch 19
2022-12-05 22:47:16,552 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:16,553 INFO:     Epoch: 20
2022-12-05 22:47:17,254 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5371647788719698, 'Total loss': 0.5371647788719698} | train loss {'Reaction outcome loss': 0.523937118318882, 'Total loss': 0.523937118318882}
2022-12-05 22:47:17,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:17,254 INFO:     Epoch: 21
2022-12-05 22:47:17,955 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5372931764207103, 'Total loss': 0.5372931764207103} | train loss {'Reaction outcome loss': 0.5344002325887139, 'Total loss': 0.5344002325887139}
2022-12-05 22:47:17,955 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:17,955 INFO:     Epoch: 22
2022-12-05 22:47:18,656 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5555486076257445, 'Total loss': 0.5555486076257445} | train loss {'Reaction outcome loss': 0.5191047726131162, 'Total loss': 0.5191047726131162}
2022-12-05 22:47:18,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:18,656 INFO:     Epoch: 23
2022-12-05 22:47:19,360 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.527955633672801, 'Total loss': 0.527955633672801} | train loss {'Reaction outcome loss': 0.5058847419495284, 'Total loss': 0.5058847419495284}
2022-12-05 22:47:19,360 INFO:     Found new best model at epoch 23
2022-12-05 22:47:19,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:19,361 INFO:     Epoch: 24
2022-12-05 22:47:20,062 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5320687768134204, 'Total loss': 0.5320687768134204} | train loss {'Reaction outcome loss': 0.5152846851540722, 'Total loss': 0.5152846851540722}
2022-12-05 22:47:20,062 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:20,062 INFO:     Epoch: 25
2022-12-05 22:47:20,766 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.52813315696337, 'Total loss': 0.52813315696337} | train loss {'Reaction outcome loss': 0.5062922216982011, 'Total loss': 0.5062922216982011}
2022-12-05 22:47:20,766 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:20,766 INFO:     Epoch: 26
2022-12-05 22:47:21,470 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5118994895707477, 'Total loss': 0.5118994895707477} | train loss {'Reaction outcome loss': 0.5034399020527056, 'Total loss': 0.5034399020527056}
2022-12-05 22:47:21,471 INFO:     Found new best model at epoch 26
2022-12-05 22:47:21,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:21,471 INFO:     Epoch: 27
2022-12-05 22:47:22,173 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5306687273762443, 'Total loss': 0.5306687273762443} | train loss {'Reaction outcome loss': 0.5093198628409913, 'Total loss': 0.5093198628409913}
2022-12-05 22:47:22,173 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:22,174 INFO:     Epoch: 28
2022-12-05 22:47:22,875 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.6944894126870416, 'Total loss': 0.6944894126870416} | train loss {'Reaction outcome loss': 0.5210944971574946, 'Total loss': 0.5210944971574946}
2022-12-05 22:47:22,875 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:22,875 INFO:     Epoch: 29
2022-12-05 22:47:23,578 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5005951364609328, 'Total loss': 0.5005951364609328} | train loss {'Reaction outcome loss': 0.5086252635065843, 'Total loss': 0.5086252635065843}
2022-12-05 22:47:23,578 INFO:     Found new best model at epoch 29
2022-12-05 22:47:23,579 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:23,579 INFO:     Epoch: 30
2022-12-05 22:47:24,293 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5143086212602529, 'Total loss': 0.5143086212602529} | train loss {'Reaction outcome loss': 0.5128488156959595, 'Total loss': 0.5128488156959595}
2022-12-05 22:47:24,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:24,293 INFO:     Epoch: 31
2022-12-05 22:47:25,004 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5483545078472658, 'Total loss': 0.5483545078472658} | train loss {'Reaction outcome loss': 0.5097286264272595, 'Total loss': 0.5097286264272595}
2022-12-05 22:47:25,004 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:25,004 INFO:     Epoch: 32
2022-12-05 22:47:25,712 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5460048006339506, 'Total loss': 0.5460048006339506} | train loss {'Reaction outcome loss': 0.5142042180787214, 'Total loss': 0.5142042180787214}
2022-12-05 22:47:25,712 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:25,712 INFO:     Epoch: 33
2022-12-05 22:47:26,422 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5039164048026908, 'Total loss': 0.5039164048026908} | train loss {'Reaction outcome loss': 0.5084688847937323, 'Total loss': 0.5084688847937323}
2022-12-05 22:47:26,422 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:26,422 INFO:     Epoch: 34
2022-12-05 22:47:27,131 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5553817217322913, 'Total loss': 0.5553817217322913} | train loss {'Reaction outcome loss': 0.5045389721268102, 'Total loss': 0.5045389721268102}
2022-12-05 22:47:27,131 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:27,131 INFO:     Epoch: 35
2022-12-05 22:47:27,847 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5526546869765628, 'Total loss': 0.5526546869765628} | train loss {'Reaction outcome loss': 0.505763654585792, 'Total loss': 0.505763654585792}
2022-12-05 22:47:27,847 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:27,848 INFO:     Epoch: 36
2022-12-05 22:47:28,558 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5253177637403662, 'Total loss': 0.5253177637403662} | train loss {'Reaction outcome loss': 0.5088662181873448, 'Total loss': 0.5088662181873448}
2022-12-05 22:47:28,558 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:28,558 INFO:     Epoch: 37
2022-12-05 22:47:29,267 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5492821322246031, 'Total loss': 0.5492821322246031} | train loss {'Reaction outcome loss': 0.505896868915693, 'Total loss': 0.505896868915693}
2022-12-05 22:47:29,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:29,268 INFO:     Epoch: 38
2022-12-05 22:47:29,976 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5614021671089259, 'Total loss': 0.5614021671089259} | train loss {'Reaction outcome loss': 0.5166533483184783, 'Total loss': 0.5166533483184783}
2022-12-05 22:47:29,977 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:29,977 INFO:     Epoch: 39
2022-12-05 22:47:30,687 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5798102949153293, 'Total loss': 0.5798102949153293} | train loss {'Reaction outcome loss': 0.5087974884732049, 'Total loss': 0.5087974884732049}
2022-12-05 22:47:30,687 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:30,688 INFO:     Epoch: 40
2022-12-05 22:47:31,404 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5475210689685561, 'Total loss': 0.5475210689685561} | train loss {'Reaction outcome loss': 0.5090325786864106, 'Total loss': 0.5090325786864106}
2022-12-05 22:47:31,405 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:31,405 INFO:     Epoch: 41
2022-12-05 22:47:32,118 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5319447646086867, 'Total loss': 0.5319447646086867} | train loss {'Reaction outcome loss': 0.5043936529864184, 'Total loss': 0.5043936529864184}
2022-12-05 22:47:32,118 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:32,118 INFO:     Epoch: 42
2022-12-05 22:47:32,832 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5414247478951107, 'Total loss': 0.5414247478951107} | train loss {'Reaction outcome loss': 0.503252288937448, 'Total loss': 0.503252288937448}
2022-12-05 22:47:32,832 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:32,832 INFO:     Epoch: 43
2022-12-05 22:47:33,543 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5265705368735574, 'Total loss': 0.5265705368735574} | train loss {'Reaction outcome loss': 0.5048569580200712, 'Total loss': 0.5048569580200712}
2022-12-05 22:47:33,543 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:33,543 INFO:     Epoch: 44
2022-12-05 22:47:34,254 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.6192455379800363, 'Total loss': 0.6192455379800363} | train loss {'Reaction outcome loss': 0.5045551169165957, 'Total loss': 0.5045551169165957}
2022-12-05 22:47:34,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:34,254 INFO:     Epoch: 45
2022-12-05 22:47:34,965 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5107148469171741, 'Total loss': 0.5107148469171741} | train loss {'Reaction outcome loss': 0.5036509256726998, 'Total loss': 0.5036509256726998}
2022-12-05 22:47:34,965 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:34,965 INFO:     Epoch: 46
2022-12-05 22:47:35,677 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5297115360471335, 'Total loss': 0.5297115360471335} | train loss {'Reaction outcome loss': 0.5100250502346981, 'Total loss': 0.5100250502346981}
2022-12-05 22:47:35,677 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:35,677 INFO:     Epoch: 47
2022-12-05 22:47:36,387 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.535170817239718, 'Total loss': 0.535170817239718} | train loss {'Reaction outcome loss': 0.5141893775477583, 'Total loss': 0.5141893775477583}
2022-12-05 22:47:36,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:36,388 INFO:     Epoch: 48
2022-12-05 22:47:37,098 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5450559007850561, 'Total loss': 0.5450559007850561} | train loss {'Reaction outcome loss': 0.5178363747924928, 'Total loss': 0.5178363747924928}
2022-12-05 22:47:37,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:37,099 INFO:     Epoch: 49
2022-12-05 22:47:37,811 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5284954380582679, 'Total loss': 0.5284954380582679} | train loss {'Reaction outcome loss': 0.5117408879372755, 'Total loss': 0.5117408879372755}
2022-12-05 22:47:37,811 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:37,811 INFO:     Epoch: 50
2022-12-05 22:47:38,528 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5242003256624396, 'Total loss': 0.5242003256624396} | train loss {'Reaction outcome loss': 0.5175531779826894, 'Total loss': 0.5175531779826894}
2022-12-05 22:47:38,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:38,528 INFO:     Epoch: 51
2022-12-05 22:47:39,242 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5339088690551844, 'Total loss': 0.5339088690551844} | train loss {'Reaction outcome loss': 0.5117015979791942, 'Total loss': 0.5117015979791942}
2022-12-05 22:47:39,242 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:39,242 INFO:     Epoch: 52
2022-12-05 22:47:39,953 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5180696594444189, 'Total loss': 0.5180696594444189} | train loss {'Reaction outcome loss': 0.5067872941960121, 'Total loss': 0.5067872941960121}
2022-12-05 22:47:39,954 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:39,954 INFO:     Epoch: 53
2022-12-05 22:47:40,665 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5544805282896216, 'Total loss': 0.5544805282896216} | train loss {'Reaction outcome loss': 0.49597479644333303, 'Total loss': 0.49597479644333303}
2022-12-05 22:47:40,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:40,666 INFO:     Epoch: 54
2022-12-05 22:47:41,376 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5264785100113262, 'Total loss': 0.5264785100113262} | train loss {'Reaction outcome loss': 0.5044472196444809, 'Total loss': 0.5044472196444809}
2022-12-05 22:47:41,376 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:41,376 INFO:     Epoch: 55
2022-12-05 22:47:42,092 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5567870570177381, 'Total loss': 0.5567870570177381} | train loss {'Reaction outcome loss': 0.5046348782927401, 'Total loss': 0.5046348782927401}
2022-12-05 22:47:42,092 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:42,092 INFO:     Epoch: 56
2022-12-05 22:47:42,806 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5480983480811119, 'Total loss': 0.5480983480811119} | train loss {'Reaction outcome loss': 0.5029155767337996, 'Total loss': 0.5029155767337996}
2022-12-05 22:47:42,807 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:42,807 INFO:     Epoch: 57
2022-12-05 22:47:43,517 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5145999088206075, 'Total loss': 0.5145999088206075} | train loss {'Reaction outcome loss': 0.5066181298662052, 'Total loss': 0.5066181298662052}
2022-12-05 22:47:43,517 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:43,518 INFO:     Epoch: 58
2022-12-05 22:47:44,227 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5220392725684426, 'Total loss': 0.5220392725684426} | train loss {'Reaction outcome loss': 0.5119510128913138, 'Total loss': 0.5119510128913138}
2022-12-05 22:47:44,227 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:44,227 INFO:     Epoch: 59
2022-12-05 22:47:44,938 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5495145750994032, 'Total loss': 0.5495145750994032} | train loss {'Reaction outcome loss': 0.5193136736207645, 'Total loss': 0.5193136736207645}
2022-12-05 22:47:44,938 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:44,938 INFO:     Epoch: 60
2022-12-05 22:47:45,648 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5215197632258589, 'Total loss': 0.5215197632258589} | train loss {'Reaction outcome loss': 0.5156720452173708, 'Total loss': 0.5156720452173708}
2022-12-05 22:47:45,648 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:45,649 INFO:     Epoch: 61
2022-12-05 22:47:46,363 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5424086038361896, 'Total loss': 0.5424086038361896} | train loss {'Reaction outcome loss': 0.5134474995889162, 'Total loss': 0.5134474995889162}
2022-12-05 22:47:46,363 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:46,363 INFO:     Epoch: 62
2022-12-05 22:47:47,079 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.518863859501752, 'Total loss': 0.518863859501752} | train loss {'Reaction outcome loss': 0.5096878996835306, 'Total loss': 0.5096878996835306}
2022-12-05 22:47:47,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:47,080 INFO:     Epoch: 63
2022-12-05 22:47:47,797 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5283085697076537, 'Total loss': 0.5283085697076537} | train loss {'Reaction outcome loss': 0.5005259947014241, 'Total loss': 0.5005259947014241}
2022-12-05 22:47:47,797 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:47,797 INFO:     Epoch: 64
2022-12-05 22:47:48,507 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.6008949862285093, 'Total loss': 0.6008949862285093} | train loss {'Reaction outcome loss': 0.4967226393912968, 'Total loss': 0.4967226393912968}
2022-12-05 22:47:48,507 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:48,507 INFO:     Epoch: 65
2022-12-05 22:47:49,216 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5219186144796285, 'Total loss': 0.5219186144796285} | train loss {'Reaction outcome loss': 0.5043652526400833, 'Total loss': 0.5043652526400833}
2022-12-05 22:47:49,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:49,217 INFO:     Epoch: 66
2022-12-05 22:47:49,925 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5133292390541597, 'Total loss': 0.5133292390541597} | train loss {'Reaction outcome loss': 0.5201434117971886, 'Total loss': 0.5201434117971886}
2022-12-05 22:47:49,926 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:49,926 INFO:     Epoch: 67
2022-12-05 22:47:50,636 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5687294947830114, 'Total loss': 0.5687294947830114} | train loss {'Reaction outcome loss': 0.509884318299139, 'Total loss': 0.509884318299139}
2022-12-05 22:47:50,636 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:50,636 INFO:     Epoch: 68
2022-12-05 22:47:51,345 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5627405975352634, 'Total loss': 0.5627405975352634} | train loss {'Reaction outcome loss': 0.512651473313932, 'Total loss': 0.512651473313932}
2022-12-05 22:47:51,345 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:51,346 INFO:     Epoch: 69
2022-12-05 22:47:52,055 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5226801464503462, 'Total loss': 0.5226801464503462} | train loss {'Reaction outcome loss': 0.5170171894283913, 'Total loss': 0.5170171894283913}
2022-12-05 22:47:52,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:52,056 INFO:     Epoch: 70
2022-12-05 22:47:52,766 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5214641507376324, 'Total loss': 0.5214641507376324} | train loss {'Reaction outcome loss': 0.5057375266439157, 'Total loss': 0.5057375266439157}
2022-12-05 22:47:52,767 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:52,767 INFO:     Epoch: 71
2022-12-05 22:47:53,477 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5098292370411482, 'Total loss': 0.5098292370411482} | train loss {'Reaction outcome loss': 0.49320552916631766, 'Total loss': 0.49320552916631766}
2022-12-05 22:47:53,477 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:53,477 INFO:     Epoch: 72
2022-12-05 22:47:54,186 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.533812327818437, 'Total loss': 0.533812327818437} | train loss {'Reaction outcome loss': 0.49844216033514693, 'Total loss': 0.49844216033514693}
2022-12-05 22:47:54,186 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:54,186 INFO:     Epoch: 73
2022-12-05 22:47:54,897 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.510951123454354, 'Total loss': 0.510951123454354} | train loss {'Reaction outcome loss': 0.5098210718889951, 'Total loss': 0.5098210718889951}
2022-12-05 22:47:54,897 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:54,897 INFO:     Epoch: 74
2022-12-05 22:47:55,612 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5227040414783087, 'Total loss': 0.5227040414783087} | train loss {'Reaction outcome loss': 0.5084080745127648, 'Total loss': 0.5084080745127648}
2022-12-05 22:47:55,612 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:55,612 INFO:     Epoch: 75
2022-12-05 22:47:56,324 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5675006590106271, 'Total loss': 0.5675006590106271} | train loss {'Reaction outcome loss': 0.5039887524809432, 'Total loss': 0.5039887524809432}
2022-12-05 22:47:56,324 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:56,324 INFO:     Epoch: 76
2022-12-05 22:47:57,036 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5047701133245771, 'Total loss': 0.5047701133245771} | train loss {'Reaction outcome loss': 0.5110211533452818, 'Total loss': 0.5110211533452818}
2022-12-05 22:47:57,036 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:57,037 INFO:     Epoch: 77
2022-12-05 22:47:57,749 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5161744691431522, 'Total loss': 0.5161744691431522} | train loss {'Reaction outcome loss': 0.5012017461935036, 'Total loss': 0.5012017461935036}
2022-12-05 22:47:57,749 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:57,749 INFO:     Epoch: 78
2022-12-05 22:47:58,460 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5041993416168473, 'Total loss': 0.5041993416168473} | train loss {'Reaction outcome loss': 0.5160379510326688, 'Total loss': 0.5160379510326688}
2022-12-05 22:47:58,460 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:58,460 INFO:     Epoch: 79
2022-12-05 22:47:59,172 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5335890427231789, 'Total loss': 0.5335890427231789} | train loss {'Reaction outcome loss': 0.49975810209025257, 'Total loss': 0.49975810209025257}
2022-12-05 22:47:59,173 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:59,173 INFO:     Epoch: 80
2022-12-05 22:47:59,885 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5478572141040455, 'Total loss': 0.5478572141040455} | train loss {'Reaction outcome loss': 0.4948636136726601, 'Total loss': 0.4948636136726601}
2022-12-05 22:47:59,885 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:47:59,886 INFO:     Epoch: 81
2022-12-05 22:48:00,601 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5356894081289117, 'Total loss': 0.5356894081289117} | train loss {'Reaction outcome loss': 0.5118346027275811, 'Total loss': 0.5118346027275811}
2022-12-05 22:48:00,601 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:00,601 INFO:     Epoch: 82
2022-12-05 22:48:01,315 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5360430062494494, 'Total loss': 0.5360430062494494} | train loss {'Reaction outcome loss': 0.5070448089466404, 'Total loss': 0.5070448089466404}
2022-12-05 22:48:01,315 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:01,315 INFO:     Epoch: 83
2022-12-05 22:48:02,027 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5186650427904996, 'Total loss': 0.5186650427904996} | train loss {'Reaction outcome loss': 0.5121337164510117, 'Total loss': 0.5121337164510117}
2022-12-05 22:48:02,028 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:02,028 INFO:     Epoch: 84
2022-12-05 22:48:02,740 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5492312434044752, 'Total loss': 0.5492312434044752} | train loss {'Reaction outcome loss': 0.5075122572873768, 'Total loss': 0.5075122572873768}
2022-12-05 22:48:02,740 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:02,740 INFO:     Epoch: 85
2022-12-05 22:48:03,455 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5485691929405386, 'Total loss': 0.5485691929405386} | train loss {'Reaction outcome loss': 0.5076011565743912, 'Total loss': 0.5076011565743912}
2022-12-05 22:48:03,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:03,455 INFO:     Epoch: 86
2022-12-05 22:48:04,170 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5356715497645465, 'Total loss': 0.5356715497645465} | train loss {'Reaction outcome loss': 0.49829151237059216, 'Total loss': 0.49829151237059216}
2022-12-05 22:48:04,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:04,171 INFO:     Epoch: 87
2022-12-05 22:48:04,883 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.491655347360806, 'Total loss': 0.491655347360806} | train loss {'Reaction outcome loss': 0.5074894969202653, 'Total loss': 0.5074894969202653}
2022-12-05 22:48:04,884 INFO:     Found new best model at epoch 87
2022-12-05 22:48:04,884 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:04,884 INFO:     Epoch: 88
2022-12-05 22:48:05,599 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5441601757298816, 'Total loss': 0.5441601757298816} | train loss {'Reaction outcome loss': 0.49714134049484965, 'Total loss': 0.49714134049484965}
2022-12-05 22:48:05,599 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:05,599 INFO:     Epoch: 89
2022-12-05 22:48:06,311 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5185304033485326, 'Total loss': 0.5185304033485326} | train loss {'Reaction outcome loss': 0.4985662462860949, 'Total loss': 0.4985662462860949}
2022-12-05 22:48:06,311 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:06,311 INFO:     Epoch: 90
2022-12-05 22:48:07,022 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5179820379072969, 'Total loss': 0.5179820379072969} | train loss {'Reaction outcome loss': 0.5036658667676482, 'Total loss': 0.5036658667676482}
2022-12-05 22:48:07,022 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:07,022 INFO:     Epoch: 91
2022-12-05 22:48:07,737 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5173732916062529, 'Total loss': 0.5173732916062529} | train loss {'Reaction outcome loss': 0.50436739520988, 'Total loss': 0.50436739520988}
2022-12-05 22:48:07,737 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:07,737 INFO:     Epoch: 92
2022-12-05 22:48:08,449 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5203665244308385, 'Total loss': 0.5203665244308385} | train loss {'Reaction outcome loss': 0.5061284007451795, 'Total loss': 0.5061284007451795}
2022-12-05 22:48:08,449 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:08,449 INFO:     Epoch: 93
2022-12-05 22:48:09,163 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5875076685439456, 'Total loss': 0.5875076685439456} | train loss {'Reaction outcome loss': 0.5068278937988918, 'Total loss': 0.5068278937988918}
2022-12-05 22:48:09,164 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:09,164 INFO:     Epoch: 94
2022-12-05 22:48:09,876 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5194075893272053, 'Total loss': 0.5194075893272053} | train loss {'Reaction outcome loss': 0.5157802534489496, 'Total loss': 0.5157802534489496}
2022-12-05 22:48:09,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:09,876 INFO:     Epoch: 95
2022-12-05 22:48:10,590 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5687387456948106, 'Total loss': 0.5687387456948106} | train loss {'Reaction outcome loss': 0.5460890416312314, 'Total loss': 0.5460890416312314}
2022-12-05 22:48:10,590 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:10,590 INFO:     Epoch: 96
2022-12-05 22:48:11,304 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5356060046363961, 'Total loss': 0.5356060046363961} | train loss {'Reaction outcome loss': 0.5113671951689701, 'Total loss': 0.5113671951689701}
2022-12-05 22:48:11,305 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:11,305 INFO:     Epoch: 97
2022-12-05 22:48:12,017 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5697572258385745, 'Total loss': 0.5697572258385745} | train loss {'Reaction outcome loss': 0.5082499793606249, 'Total loss': 0.5082499793606249}
2022-12-05 22:48:12,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:12,017 INFO:     Epoch: 98
2022-12-05 22:48:12,734 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.522543846883557, 'Total loss': 0.522543846883557} | train loss {'Reaction outcome loss': 0.5058975653941573, 'Total loss': 0.5058975653941573}
2022-12-05 22:48:12,734 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:12,734 INFO:     Epoch: 99
2022-12-05 22:48:13,445 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5639419454065236, 'Total loss': 0.5639419454065236} | train loss {'Reaction outcome loss': 0.5083014088482992, 'Total loss': 0.5083014088482992}
2022-12-05 22:48:13,446 INFO:     Best model found after epoch 88 of 100.
2022-12-05 22:48:13,446 INFO:   Done with stage: TRAINING
2022-12-05 22:48:13,446 INFO:   Starting stage: EVALUATION
2022-12-05 22:48:13,570 INFO:   Done with stage: EVALUATION
2022-12-05 22:48:13,570 INFO:   Leaving out SEQ value Fold_6
2022-12-05 22:48:13,583 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 22:48:13,583 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:48:14,227 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:48:14,227 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:48:14,299 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:48:14,299 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:48:14,299 INFO:     No hyperparam tuning for this model
2022-12-05 22:48:14,299 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:48:14,299 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:48:14,300 INFO:     None feature selector for col prot
2022-12-05 22:48:14,300 INFO:     None feature selector for col prot
2022-12-05 22:48:14,300 INFO:     None feature selector for col prot
2022-12-05 22:48:14,300 INFO:     None feature selector for col chem
2022-12-05 22:48:14,301 INFO:     None feature selector for col chem
2022-12-05 22:48:14,301 INFO:     None feature selector for col chem
2022-12-05 22:48:14,301 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:48:14,301 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:48:14,302 INFO:     Number of params in model 215731
2022-12-05 22:48:14,306 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:48:14,306 INFO:   Starting stage: TRAINING
2022-12-05 22:48:14,365 INFO:     Val loss before train {'Reaction outcome loss': 1.0240305465730755, 'Total loss': 1.0240305465730755}
2022-12-05 22:48:14,365 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:14,365 INFO:     Epoch: 0
2022-12-05 22:48:15,080 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6650014194575223, 'Total loss': 0.6650014194575223} | train loss {'Reaction outcome loss': 0.8042871324766067, 'Total loss': 0.8042871324766067}
2022-12-05 22:48:15,080 INFO:     Found new best model at epoch 0
2022-12-05 22:48:15,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:15,080 INFO:     Epoch: 1
2022-12-05 22:48:15,798 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6080826771530238, 'Total loss': 0.6080826771530238} | train loss {'Reaction outcome loss': 0.6536793533352113, 'Total loss': 0.6536793533352113}
2022-12-05 22:48:15,798 INFO:     Found new best model at epoch 1
2022-12-05 22:48:15,798 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:15,799 INFO:     Epoch: 2
2022-12-05 22:48:16,513 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6264881213957613, 'Total loss': 0.6264881213957613} | train loss {'Reaction outcome loss': 0.6005523590551268, 'Total loss': 0.6005523590551268}
2022-12-05 22:48:16,513 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:16,513 INFO:     Epoch: 3
2022-12-05 22:48:17,228 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5545389320362698, 'Total loss': 0.5545389320362698} | train loss {'Reaction outcome loss': 0.5901910193985508, 'Total loss': 0.5901910193985508}
2022-12-05 22:48:17,228 INFO:     Found new best model at epoch 3
2022-12-05 22:48:17,229 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:17,229 INFO:     Epoch: 4
2022-12-05 22:48:17,946 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.57611452720382, 'Total loss': 0.57611452720382} | train loss {'Reaction outcome loss': 0.564095452788376, 'Total loss': 0.564095452788376}
2022-12-05 22:48:17,946 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:17,946 INFO:     Epoch: 5
2022-12-05 22:48:18,662 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5938553126020865, 'Total loss': 0.5938553126020865} | train loss {'Reaction outcome loss': 0.564453452044437, 'Total loss': 0.564453452044437}
2022-12-05 22:48:18,663 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:18,663 INFO:     Epoch: 6
2022-12-05 22:48:19,380 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5385272990573536, 'Total loss': 0.5385272990573536} | train loss {'Reaction outcome loss': 0.5594954688943201, 'Total loss': 0.5594954688943201}
2022-12-05 22:48:19,380 INFO:     Found new best model at epoch 6
2022-12-05 22:48:19,381 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:19,381 INFO:     Epoch: 7
2022-12-05 22:48:20,098 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.561991864646023, 'Total loss': 0.561991864646023} | train loss {'Reaction outcome loss': 0.5511172841032667, 'Total loss': 0.5511172841032667}
2022-12-05 22:48:20,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:20,098 INFO:     Epoch: 8
2022-12-05 22:48:20,815 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5373564027249813, 'Total loss': 0.5373564027249813} | train loss {'Reaction outcome loss': 0.5525026372483661, 'Total loss': 0.5525026372483661}
2022-12-05 22:48:20,815 INFO:     Found new best model at epoch 8
2022-12-05 22:48:20,815 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:20,816 INFO:     Epoch: 9
2022-12-05 22:48:21,533 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.564496519213373, 'Total loss': 0.564496519213373} | train loss {'Reaction outcome loss': 0.5496606208504208, 'Total loss': 0.5496606208504208}
2022-12-05 22:48:21,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:21,534 INFO:     Epoch: 10
2022-12-05 22:48:22,248 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5834524204785173, 'Total loss': 0.5834524204785173} | train loss {'Reaction outcome loss': 0.5459067685709845, 'Total loss': 0.5459067685709845}
2022-12-05 22:48:22,248 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:22,248 INFO:     Epoch: 11
2022-12-05 22:48:22,962 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.540774829685688, 'Total loss': 0.540774829685688} | train loss {'Reaction outcome loss': 0.5454522173010534, 'Total loss': 0.5454522173010534}
2022-12-05 22:48:22,962 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:22,963 INFO:     Epoch: 12
2022-12-05 22:48:23,680 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5454329468987205, 'Total loss': 0.5454329468987205} | train loss {'Reaction outcome loss': 0.543997272128059, 'Total loss': 0.543997272128059}
2022-12-05 22:48:23,680 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:23,681 INFO:     Epoch: 13
2022-12-05 22:48:24,396 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5423241359266368, 'Total loss': 0.5423241359266368} | train loss {'Reaction outcome loss': 0.5484060561584849, 'Total loss': 0.5484060561584849}
2022-12-05 22:48:24,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:24,397 INFO:     Epoch: 14
2022-12-05 22:48:25,114 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.553917454724962, 'Total loss': 0.553917454724962} | train loss {'Reaction outcome loss': 0.5387967439788964, 'Total loss': 0.5387967439788964}
2022-12-05 22:48:25,114 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:25,114 INFO:     Epoch: 15
2022-12-05 22:48:25,829 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.535899493843317, 'Total loss': 0.535899493843317} | train loss {'Reaction outcome loss': 0.5394741297969895, 'Total loss': 0.5394741297969895}
2022-12-05 22:48:25,829 INFO:     Found new best model at epoch 15
2022-12-05 22:48:25,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:25,830 INFO:     Epoch: 16
2022-12-05 22:48:26,543 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.524127105420286, 'Total loss': 0.524127105420286} | train loss {'Reaction outcome loss': 0.5526191166812374, 'Total loss': 0.5526191166812374}
2022-12-05 22:48:26,543 INFO:     Found new best model at epoch 16
2022-12-05 22:48:26,544 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:26,544 INFO:     Epoch: 17
2022-12-05 22:48:27,259 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5374896594069221, 'Total loss': 0.5374896594069221} | train loss {'Reaction outcome loss': 0.5294029686239458, 'Total loss': 0.5294029686239458}
2022-12-05 22:48:27,259 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:27,259 INFO:     Epoch: 18
2022-12-05 22:48:27,977 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5478497432036833, 'Total loss': 0.5478497432036833} | train loss {'Reaction outcome loss': 0.5308098832085248, 'Total loss': 0.5308098832085248}
2022-12-05 22:48:27,977 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:27,977 INFO:     Epoch: 19
2022-12-05 22:48:28,691 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5231083611195738, 'Total loss': 0.5231083611195738} | train loss {'Reaction outcome loss': 0.5378190152827771, 'Total loss': 0.5378190152827771}
2022-12-05 22:48:28,691 INFO:     Found new best model at epoch 19
2022-12-05 22:48:28,692 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:28,692 INFO:     Epoch: 20
2022-12-05 22:48:29,409 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5583042651414871, 'Total loss': 0.5583042651414871} | train loss {'Reaction outcome loss': 0.5330308914304741, 'Total loss': 0.5330308914304741}
2022-12-05 22:48:29,409 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:29,409 INFO:     Epoch: 21
2022-12-05 22:48:30,123 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.6115621368993412, 'Total loss': 0.6115621368993412} | train loss {'Reaction outcome loss': 0.5367820705136945, 'Total loss': 0.5367820705136945}
2022-12-05 22:48:30,123 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:30,124 INFO:     Epoch: 22
2022-12-05 22:48:30,841 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5278870050202716, 'Total loss': 0.5278870050202716} | train loss {'Reaction outcome loss': 0.5375656685641697, 'Total loss': 0.5375656685641697}
2022-12-05 22:48:30,842 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:30,842 INFO:     Epoch: 23
2022-12-05 22:48:31,558 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5537536449053071, 'Total loss': 0.5537536449053071} | train loss {'Reaction outcome loss': 0.5281830786937668, 'Total loss': 0.5281830786937668}
2022-12-05 22:48:31,558 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:31,558 INFO:     Epoch: 24
2022-12-05 22:48:32,274 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5661429424177516, 'Total loss': 0.5661429424177516} | train loss {'Reaction outcome loss': 0.5350074116290817, 'Total loss': 0.5350074116290817}
2022-12-05 22:48:32,275 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:32,275 INFO:     Epoch: 25
2022-12-05 22:48:32,991 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.547331955622543, 'Total loss': 0.547331955622543} | train loss {'Reaction outcome loss': 0.525635403010153, 'Total loss': 0.525635403010153}
2022-12-05 22:48:32,991 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:32,991 INFO:     Epoch: 26
2022-12-05 22:48:33,712 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5672009106386792, 'Total loss': 0.5672009106386792} | train loss {'Reaction outcome loss': 0.5387707779244069, 'Total loss': 0.5387707779244069}
2022-12-05 22:48:33,712 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:33,712 INFO:     Epoch: 27
2022-12-05 22:48:34,429 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.563718241724101, 'Total loss': 0.563718241724101} | train loss {'Reaction outcome loss': 0.5330265401111495, 'Total loss': 0.5330265401111495}
2022-12-05 22:48:34,429 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:34,429 INFO:     Epoch: 28
2022-12-05 22:48:35,151 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5625496479597959, 'Total loss': 0.5625496479597959} | train loss {'Reaction outcome loss': 0.5362480881233369, 'Total loss': 0.5362480881233369}
2022-12-05 22:48:35,152 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:35,152 INFO:     Epoch: 29
2022-12-05 22:48:35,870 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5351646650921215, 'Total loss': 0.5351646650921215} | train loss {'Reaction outcome loss': 0.5270074769373863, 'Total loss': 0.5270074769373863}
2022-12-05 22:48:35,870 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:35,870 INFO:     Epoch: 30
2022-12-05 22:48:36,593 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5674205612052571, 'Total loss': 0.5674205612052571} | train loss {'Reaction outcome loss': 0.5287515022942135, 'Total loss': 0.5287515022942135}
2022-12-05 22:48:36,594 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:36,594 INFO:     Epoch: 31
2022-12-05 22:48:37,312 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5683803680268201, 'Total loss': 0.5683803680268201} | train loss {'Reaction outcome loss': 0.5355020722434405, 'Total loss': 0.5355020722434405}
2022-12-05 22:48:37,312 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:37,313 INFO:     Epoch: 32
2022-12-05 22:48:38,032 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.526095696809617, 'Total loss': 0.526095696809617} | train loss {'Reaction outcome loss': 0.5317808706914225, 'Total loss': 0.5317808706914225}
2022-12-05 22:48:38,032 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:38,032 INFO:     Epoch: 33
2022-12-05 22:48:38,753 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5474626638672568, 'Total loss': 0.5474626638672568} | train loss {'Reaction outcome loss': 0.5316609600258451, 'Total loss': 0.5316609600258451}
2022-12-05 22:48:38,753 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:38,754 INFO:     Epoch: 34
2022-12-05 22:48:39,469 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.562020680443807, 'Total loss': 0.562020680443807} | train loss {'Reaction outcome loss': 0.5373412076263658, 'Total loss': 0.5373412076263658}
2022-12-05 22:48:39,469 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:39,469 INFO:     Epoch: 35
2022-12-05 22:48:40,185 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5475713434544477, 'Total loss': 0.5475713434544477} | train loss {'Reaction outcome loss': 0.5321957705722701, 'Total loss': 0.5321957705722701}
2022-12-05 22:48:40,186 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:40,186 INFO:     Epoch: 36
2022-12-05 22:48:40,903 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5577609450979666, 'Total loss': 0.5577609450979666} | train loss {'Reaction outcome loss': 0.5279336629976188, 'Total loss': 0.5279336629976188}
2022-12-05 22:48:40,903 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:40,903 INFO:     Epoch: 37
2022-12-05 22:48:41,620 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5505397035316988, 'Total loss': 0.5505397035316988} | train loss {'Reaction outcome loss': 0.5307750413494725, 'Total loss': 0.5307750413494725}
2022-12-05 22:48:41,620 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:41,620 INFO:     Epoch: 38
2022-12-05 22:48:42,336 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5347848568450321, 'Total loss': 0.5347848568450321} | train loss {'Reaction outcome loss': 0.5337900392590992, 'Total loss': 0.5337900392590992}
2022-12-05 22:48:42,336 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:42,336 INFO:     Epoch: 39
2022-12-05 22:48:43,052 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5379288965328173, 'Total loss': 0.5379288965328173} | train loss {'Reaction outcome loss': 0.5314331016833743, 'Total loss': 0.5314331016833743}
2022-12-05 22:48:43,053 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:43,053 INFO:     Epoch: 40
2022-12-05 22:48:43,770 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5322799601338126, 'Total loss': 0.5322799601338126} | train loss {'Reaction outcome loss': 0.5311856915152842, 'Total loss': 0.5311856915152842}
2022-12-05 22:48:43,770 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:43,770 INFO:     Epoch: 41
2022-12-05 22:48:44,486 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5469297983429648, 'Total loss': 0.5469297983429648} | train loss {'Reaction outcome loss': 0.5327128146084086, 'Total loss': 0.5327128146084086}
2022-12-05 22:48:44,486 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:44,487 INFO:     Epoch: 42
2022-12-05 22:48:45,202 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5402873808687384, 'Total loss': 0.5402873808687384} | train loss {'Reaction outcome loss': 0.5286297143827523, 'Total loss': 0.5286297143827523}
2022-12-05 22:48:45,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:45,202 INFO:     Epoch: 43
2022-12-05 22:48:45,922 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5546931651505557, 'Total loss': 0.5546931651505557} | train loss {'Reaction outcome loss': 0.532924332145241, 'Total loss': 0.532924332145241}
2022-12-05 22:48:45,922 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:45,922 INFO:     Epoch: 44
2022-12-05 22:48:46,649 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5510374287312682, 'Total loss': 0.5510374287312682} | train loss {'Reaction outcome loss': 0.5263668810648303, 'Total loss': 0.5263668810648303}
2022-12-05 22:48:46,649 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:46,649 INFO:     Epoch: 45
2022-12-05 22:48:47,366 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5591888867995956, 'Total loss': 0.5591888867995956} | train loss {'Reaction outcome loss': 0.5392121148085401, 'Total loss': 0.5392121148085401}
2022-12-05 22:48:47,366 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:47,366 INFO:     Epoch: 46
2022-12-05 22:48:48,083 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.576844025741924, 'Total loss': 0.576844025741924} | train loss {'Reaction outcome loss': 0.5270474752291076, 'Total loss': 0.5270474752291076}
2022-12-05 22:48:48,083 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:48,083 INFO:     Epoch: 47
2022-12-05 22:48:48,799 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5378209047696807, 'Total loss': 0.5378209047696807} | train loss {'Reaction outcome loss': 0.5360424721072758, 'Total loss': 0.5360424721072758}
2022-12-05 22:48:48,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:48,799 INFO:     Epoch: 48
2022-12-05 22:48:49,515 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5418198968876492, 'Total loss': 0.5418198968876492} | train loss {'Reaction outcome loss': 0.5273292005182274, 'Total loss': 0.5273292005182274}
2022-12-05 22:48:49,515 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:49,515 INFO:     Epoch: 49
2022-12-05 22:48:50,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5416027795184742, 'Total loss': 0.5416027795184742} | train loss {'Reaction outcome loss': 0.5330864889246802, 'Total loss': 0.5330864889246802}
2022-12-05 22:48:50,233 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:50,234 INFO:     Epoch: 50
2022-12-05 22:48:50,954 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5659267265688289, 'Total loss': 0.5659267265688289} | train loss {'Reaction outcome loss': 0.523662013542508, 'Total loss': 0.523662013542508}
2022-12-05 22:48:50,954 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:50,954 INFO:     Epoch: 51
2022-12-05 22:48:51,673 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5291553668000482, 'Total loss': 0.5291553668000482} | train loss {'Reaction outcome loss': 0.5357268917103929, 'Total loss': 0.5357268917103929}
2022-12-05 22:48:51,673 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:51,673 INFO:     Epoch: 52
2022-12-05 22:48:52,390 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5493033372543075, 'Total loss': 0.5493033372543075} | train loss {'Reaction outcome loss': 0.5306809903873552, 'Total loss': 0.5306809903873552}
2022-12-05 22:48:52,390 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:52,390 INFO:     Epoch: 53
2022-12-05 22:48:53,106 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5409474745392799, 'Total loss': 0.5409474745392799} | train loss {'Reaction outcome loss': 0.5280372289520118, 'Total loss': 0.5280372289520118}
2022-12-05 22:48:53,106 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:53,107 INFO:     Epoch: 54
2022-12-05 22:48:53,822 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5470959198745814, 'Total loss': 0.5470959198745814} | train loss {'Reaction outcome loss': 0.5306161534521849, 'Total loss': 0.5306161534521849}
2022-12-05 22:48:53,822 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:53,822 INFO:     Epoch: 55
2022-12-05 22:48:54,538 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5255511345511134, 'Total loss': 0.5255511345511134} | train loss {'Reaction outcome loss': 0.5260112131795576, 'Total loss': 0.5260112131795576}
2022-12-05 22:48:54,539 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:54,540 INFO:     Epoch: 56
2022-12-05 22:48:55,258 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5516180785542185, 'Total loss': 0.5516180785542185} | train loss {'Reaction outcome loss': 0.5246118480159391, 'Total loss': 0.5246118480159391}
2022-12-05 22:48:55,258 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:55,258 INFO:     Epoch: 57
2022-12-05 22:48:55,974 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5410634370690043, 'Total loss': 0.5410634370690043} | train loss {'Reaction outcome loss': 0.5317695811390877, 'Total loss': 0.5317695811390877}
2022-12-05 22:48:55,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:55,974 INFO:     Epoch: 58
2022-12-05 22:48:56,690 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5496328141201626, 'Total loss': 0.5496328141201626} | train loss {'Reaction outcome loss': 0.5234766153678778, 'Total loss': 0.5234766153678778}
2022-12-05 22:48:56,690 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:56,690 INFO:     Epoch: 59
2022-12-05 22:48:57,407 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5447370464151556, 'Total loss': 0.5447370464151556} | train loss {'Reaction outcome loss': 0.52488748458845, 'Total loss': 0.52488748458845}
2022-12-05 22:48:57,407 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:57,407 INFO:     Epoch: 60
2022-12-05 22:48:58,124 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5260809578678824, 'Total loss': 0.5260809578678824} | train loss {'Reaction outcome loss': 0.533476888712856, 'Total loss': 0.533476888712856}
2022-12-05 22:48:58,124 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:58,124 INFO:     Epoch: 61
2022-12-05 22:48:58,840 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5373476933349263, 'Total loss': 0.5373476933349263} | train loss {'Reaction outcome loss': 0.5310356944438911, 'Total loss': 0.5310356944438911}
2022-12-05 22:48:58,840 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:58,840 INFO:     Epoch: 62
2022-12-05 22:48:59,556 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5491260134361007, 'Total loss': 0.5491260134361007} | train loss {'Reaction outcome loss': 0.5246434038084361, 'Total loss': 0.5246434038084361}
2022-12-05 22:48:59,556 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:48:59,556 INFO:     Epoch: 63
2022-12-05 22:49:00,273 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5419520146467469, 'Total loss': 0.5419520146467469} | train loss {'Reaction outcome loss': 0.5295577375518699, 'Total loss': 0.5295577375518699}
2022-12-05 22:49:00,273 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:00,274 INFO:     Epoch: 64
2022-12-05 22:49:00,993 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5366400730880824, 'Total loss': 0.5366400730880824} | train loss {'Reaction outcome loss': 0.527229858862777, 'Total loss': 0.527229858862777}
2022-12-05 22:49:00,994 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:00,994 INFO:     Epoch: 65
2022-12-05 22:49:01,711 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5569989213889296, 'Total loss': 0.5569989213889296} | train loss {'Reaction outcome loss': 0.5212868916531724, 'Total loss': 0.5212868916531724}
2022-12-05 22:49:01,711 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:01,711 INFO:     Epoch: 66
2022-12-05 22:49:02,430 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.555474000220949, 'Total loss': 0.555474000220949} | train loss {'Reaction outcome loss': 0.5269445851745624, 'Total loss': 0.5269445851745624}
2022-12-05 22:49:02,430 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:02,430 INFO:     Epoch: 67
2022-12-05 22:49:03,149 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5272660946304147, 'Total loss': 0.5272660946304147} | train loss {'Reaction outcome loss': 0.534621734772959, 'Total loss': 0.534621734772959}
2022-12-05 22:49:03,149 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:03,149 INFO:     Epoch: 68
2022-12-05 22:49:03,866 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5767676112326708, 'Total loss': 0.5767676112326708} | train loss {'Reaction outcome loss': 0.5298306719670373, 'Total loss': 0.5298306719670373}
2022-12-05 22:49:03,866 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:03,866 INFO:     Epoch: 69
2022-12-05 22:49:04,586 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5497312071648511, 'Total loss': 0.5497312071648511} | train loss {'Reaction outcome loss': 0.5292646289472619, 'Total loss': 0.5292646289472619}
2022-12-05 22:49:04,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:04,586 INFO:     Epoch: 70
2022-12-05 22:49:05,305 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5409120002930815, 'Total loss': 0.5409120002930815} | train loss {'Reaction outcome loss': 0.5387060446965117, 'Total loss': 0.5387060446965117}
2022-12-05 22:49:05,305 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:05,305 INFO:     Epoch: 71
2022-12-05 22:49:06,025 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5421113253317096, 'Total loss': 0.5421113253317096} | train loss {'Reaction outcome loss': 0.5287357132521368, 'Total loss': 0.5287357132521368}
2022-12-05 22:49:06,025 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:06,025 INFO:     Epoch: 72
2022-12-05 22:49:06,743 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5568597377701239, 'Total loss': 0.5568597377701239} | train loss {'Reaction outcome loss': 0.5274079034044858, 'Total loss': 0.5274079034044858}
2022-12-05 22:49:06,744 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:06,744 INFO:     Epoch: 73
2022-12-05 22:49:07,467 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.546892446550456, 'Total loss': 0.546892446550456} | train loss {'Reaction outcome loss': 0.5237085407659892, 'Total loss': 0.5237085407659892}
2022-12-05 22:49:07,467 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:07,467 INFO:     Epoch: 74
2022-12-05 22:49:08,185 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.537160761654377, 'Total loss': 0.537160761654377} | train loss {'Reaction outcome loss': 0.5339816975136918, 'Total loss': 0.5339816975136918}
2022-12-05 22:49:08,185 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:08,185 INFO:     Epoch: 75
2022-12-05 22:49:08,901 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5265216316011819, 'Total loss': 0.5265216316011819} | train loss {'Reaction outcome loss': 0.5339477099177818, 'Total loss': 0.5339477099177818}
2022-12-05 22:49:08,901 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:08,901 INFO:     Epoch: 76
2022-12-05 22:49:09,617 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5567209950902245, 'Total loss': 0.5567209950902245} | train loss {'Reaction outcome loss': 0.5360307968672244, 'Total loss': 0.5360307968672244}
2022-12-05 22:49:09,617 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:09,617 INFO:     Epoch: 77
2022-12-05 22:49:10,337 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5322683602571487, 'Total loss': 0.5322683602571487} | train loss {'Reaction outcome loss': 0.5323938833129022, 'Total loss': 0.5323938833129022}
2022-12-05 22:49:10,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:10,337 INFO:     Epoch: 78
2022-12-05 22:49:11,052 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5421287945725701, 'Total loss': 0.5421287945725701} | train loss {'Reaction outcome loss': 0.5328033934197118, 'Total loss': 0.5328033934197118}
2022-12-05 22:49:11,053 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:11,053 INFO:     Epoch: 79
2022-12-05 22:49:11,770 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5517337362874638, 'Total loss': 0.5517337362874638} | train loss {'Reaction outcome loss': 0.5314712279265926, 'Total loss': 0.5314712279265926}
2022-12-05 22:49:11,771 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:11,771 INFO:     Epoch: 80
2022-12-05 22:49:12,486 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5712320506572723, 'Total loss': 0.5712320506572723} | train loss {'Reaction outcome loss': 0.5242782030855456, 'Total loss': 0.5242782030855456}
2022-12-05 22:49:12,486 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:12,486 INFO:     Epoch: 81
2022-12-05 22:49:13,205 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5377092066813599, 'Total loss': 0.5377092066813599} | train loss {'Reaction outcome loss': 0.532535266191248, 'Total loss': 0.532535266191248}
2022-12-05 22:49:13,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:13,206 INFO:     Epoch: 82
2022-12-05 22:49:13,924 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5880940637805245, 'Total loss': 0.5880940637805245} | train loss {'Reaction outcome loss': 0.5254218640827364, 'Total loss': 0.5254218640827364}
2022-12-05 22:49:13,924 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:13,924 INFO:     Epoch: 83
2022-12-05 22:49:14,639 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.555107219652696, 'Total loss': 0.555107219652696} | train loss {'Reaction outcome loss': 0.5260363119624315, 'Total loss': 0.5260363119624315}
2022-12-05 22:49:14,639 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:14,639 INFO:     Epoch: 84
2022-12-05 22:49:15,355 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5598604652014646, 'Total loss': 0.5598604652014646} | train loss {'Reaction outcome loss': 0.5373059172303446, 'Total loss': 0.5373059172303446}
2022-12-05 22:49:15,355 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:15,355 INFO:     Epoch: 85
2022-12-05 22:49:16,072 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5402274253693494, 'Total loss': 0.5402274253693494} | train loss {'Reaction outcome loss': 0.5388007776871804, 'Total loss': 0.5388007776871804}
2022-12-05 22:49:16,072 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:16,072 INFO:     Epoch: 86
2022-12-05 22:49:16,787 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5489356653256849, 'Total loss': 0.5489356653256849} | train loss {'Reaction outcome loss': 0.5316021968760798, 'Total loss': 0.5316021968760798}
2022-12-05 22:49:16,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:16,787 INFO:     Epoch: 87
2022-12-05 22:49:17,501 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5393679263916883, 'Total loss': 0.5393679263916883} | train loss {'Reaction outcome loss': 0.5329864499790054, 'Total loss': 0.5329864499790054}
2022-12-05 22:49:17,501 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:17,501 INFO:     Epoch: 88
2022-12-05 22:49:18,215 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5365865501490507, 'Total loss': 0.5365865501490507} | train loss {'Reaction outcome loss': 0.535100378336445, 'Total loss': 0.535100378336445}
2022-12-05 22:49:18,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:18,215 INFO:     Epoch: 89
2022-12-05 22:49:18,933 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5566170117394491, 'Total loss': 0.5566170117394491} | train loss {'Reaction outcome loss': 0.5287472073950114, 'Total loss': 0.5287472073950114}
2022-12-05 22:49:18,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:18,933 INFO:     Epoch: 90
2022-12-05 22:49:19,645 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.526298507370732, 'Total loss': 0.526298507370732} | train loss {'Reaction outcome loss': 0.5386236094298863, 'Total loss': 0.5386236094298863}
2022-12-05 22:49:19,645 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:19,645 INFO:     Epoch: 91
2022-12-05 22:49:20,359 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5783937051892281, 'Total loss': 0.5783937051892281} | train loss {'Reaction outcome loss': 0.5375351256300365, 'Total loss': 0.5375351256300365}
2022-12-05 22:49:20,359 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:20,360 INFO:     Epoch: 92
2022-12-05 22:49:21,073 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5176142826676369, 'Total loss': 0.5176142826676369} | train loss {'Reaction outcome loss': 0.5294551130744719, 'Total loss': 0.5294551130744719}
2022-12-05 22:49:21,073 INFO:     Found new best model at epoch 92
2022-12-05 22:49:21,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:21,074 INFO:     Epoch: 93
2022-12-05 22:49:21,786 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5272398191419515, 'Total loss': 0.5272398191419515} | train loss {'Reaction outcome loss': 0.5248461965050909, 'Total loss': 0.5248461965050909}
2022-12-05 22:49:21,786 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:21,786 INFO:     Epoch: 94
2022-12-05 22:49:22,500 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5557777244936336, 'Total loss': 0.5557777244936336} | train loss {'Reaction outcome loss': 0.5312964287135871, 'Total loss': 0.5312964287135871}
2022-12-05 22:49:22,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:22,500 INFO:     Epoch: 95
2022-12-05 22:49:23,214 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.576577060601928, 'Total loss': 0.576577060601928} | train loss {'Reaction outcome loss': 0.533147401446777, 'Total loss': 0.533147401446777}
2022-12-05 22:49:23,214 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:23,215 INFO:     Epoch: 96
2022-12-05 22:49:23,929 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5516775819388303, 'Total loss': 0.5516775819388303} | train loss {'Reaction outcome loss': 0.5366553607426824, 'Total loss': 0.5366553607426824}
2022-12-05 22:49:23,930 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:23,930 INFO:     Epoch: 97
2022-12-05 22:49:24,643 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5542053844441067, 'Total loss': 0.5542053844441067} | train loss {'Reaction outcome loss': 0.5277410764247179, 'Total loss': 0.5277410764247179}
2022-12-05 22:49:24,643 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:24,643 INFO:     Epoch: 98
2022-12-05 22:49:25,356 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5319300239736383, 'Total loss': 0.5319300239736383} | train loss {'Reaction outcome loss': 0.5302715802024449, 'Total loss': 0.5302715802024449}
2022-12-05 22:49:25,356 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:25,356 INFO:     Epoch: 99
2022-12-05 22:49:26,077 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5373508340933106, 'Total loss': 0.5373508340933106} | train loss {'Reaction outcome loss': 0.5326664850356118, 'Total loss': 0.5326664850356118}
2022-12-05 22:49:26,078 INFO:     Best model found after epoch 93 of 100.
2022-12-05 22:49:26,078 INFO:   Done with stage: TRAINING
2022-12-05 22:49:26,078 INFO:   Starting stage: EVALUATION
2022-12-05 22:49:26,196 INFO:   Done with stage: EVALUATION
2022-12-05 22:49:26,197 INFO:   Leaving out SEQ value Fold_7
2022-12-05 22:49:26,209 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:49:26,210 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:49:26,856 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:49:26,856 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:49:26,926 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:49:26,926 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:49:26,927 INFO:     No hyperparam tuning for this model
2022-12-05 22:49:26,927 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:49:26,927 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:49:26,927 INFO:     None feature selector for col prot
2022-12-05 22:49:26,927 INFO:     None feature selector for col prot
2022-12-05 22:49:26,928 INFO:     None feature selector for col prot
2022-12-05 22:49:26,928 INFO:     None feature selector for col chem
2022-12-05 22:49:26,928 INFO:     None feature selector for col chem
2022-12-05 22:49:26,928 INFO:     None feature selector for col chem
2022-12-05 22:49:26,928 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:49:26,928 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:49:26,930 INFO:     Number of params in model 215731
2022-12-05 22:49:26,933 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:49:26,933 INFO:   Starting stage: TRAINING
2022-12-05 22:49:26,992 INFO:     Val loss before train {'Reaction outcome loss': 1.0180689489299601, 'Total loss': 1.0180689489299601}
2022-12-05 22:49:26,992 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:26,992 INFO:     Epoch: 0
2022-12-05 22:49:27,702 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7234030108560215, 'Total loss': 0.7234030108560215} | train loss {'Reaction outcome loss': 0.818107373680663, 'Total loss': 0.818107373680663}
2022-12-05 22:49:27,702 INFO:     Found new best model at epoch 0
2022-12-05 22:49:27,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:27,703 INFO:     Epoch: 1
2022-12-05 22:49:28,413 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6555796028538183, 'Total loss': 0.6555796028538183} | train loss {'Reaction outcome loss': 0.6818925563381751, 'Total loss': 0.6818925563381751}
2022-12-05 22:49:28,414 INFO:     Found new best model at epoch 1
2022-12-05 22:49:28,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:28,414 INFO:     Epoch: 2
2022-12-05 22:49:29,124 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6868482794273983, 'Total loss': 0.6868482794273983} | train loss {'Reaction outcome loss': 0.6245084762090614, 'Total loss': 0.6245084762090614}
2022-12-05 22:49:29,125 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:29,125 INFO:     Epoch: 3
2022-12-05 22:49:29,838 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6257767216725783, 'Total loss': 0.6257767216725783} | train loss {'Reaction outcome loss': 0.59583259962107, 'Total loss': 0.59583259962107}
2022-12-05 22:49:29,838 INFO:     Found new best model at epoch 3
2022-12-05 22:49:29,839 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:29,839 INFO:     Epoch: 4
2022-12-05 22:49:30,551 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6452876373448155, 'Total loss': 0.6452876373448155} | train loss {'Reaction outcome loss': 0.5745980081823372, 'Total loss': 0.5745980081823372}
2022-12-05 22:49:30,552 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:30,552 INFO:     Epoch: 5
2022-12-05 22:49:31,261 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.570165911858732, 'Total loss': 0.570165911858732} | train loss {'Reaction outcome loss': 0.5618017332153282, 'Total loss': 0.5618017332153282}
2022-12-05 22:49:31,261 INFO:     Found new best model at epoch 5
2022-12-05 22:49:31,262 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:31,262 INFO:     Epoch: 6
2022-12-05 22:49:31,974 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.598618381741372, 'Total loss': 0.598618381741372} | train loss {'Reaction outcome loss': 0.5462840489952671, 'Total loss': 0.5462840489952671}
2022-12-05 22:49:31,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:31,975 INFO:     Epoch: 7
2022-12-05 22:49:32,687 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5867513817819682, 'Total loss': 0.5867513817819682} | train loss {'Reaction outcome loss': 0.541765695128605, 'Total loss': 0.541765695128605}
2022-12-05 22:49:32,688 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:32,688 INFO:     Epoch: 8
2022-12-05 22:49:33,399 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6034811775792729, 'Total loss': 0.6034811775792729} | train loss {'Reaction outcome loss': 0.5476670105326996, 'Total loss': 0.5476670105326996}
2022-12-05 22:49:33,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:33,399 INFO:     Epoch: 9
2022-12-05 22:49:34,112 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5616368143395944, 'Total loss': 0.5616368143395944} | train loss {'Reaction outcome loss': 0.5450384801457285, 'Total loss': 0.5450384801457285}
2022-12-05 22:49:34,112 INFO:     Found new best model at epoch 9
2022-12-05 22:49:34,112 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:34,113 INFO:     Epoch: 10
2022-12-05 22:49:34,826 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5744251121174205, 'Total loss': 0.5744251121174205} | train loss {'Reaction outcome loss': 0.53193291611517, 'Total loss': 0.53193291611517}
2022-12-05 22:49:34,826 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:34,826 INFO:     Epoch: 11
2022-12-05 22:49:35,541 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5648503222248771, 'Total loss': 0.5648503222248771} | train loss {'Reaction outcome loss': 0.5333963000867893, 'Total loss': 0.5333963000867893}
2022-12-05 22:49:35,541 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:35,541 INFO:     Epoch: 12
2022-12-05 22:49:36,251 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5839647325602445, 'Total loss': 0.5839647325602445} | train loss {'Reaction outcome loss': 0.5347919112998947, 'Total loss': 0.5347919112998947}
2022-12-05 22:49:36,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:36,251 INFO:     Epoch: 13
2022-12-05 22:49:36,964 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5748197998512875, 'Total loss': 0.5748197998512875} | train loss {'Reaction outcome loss': 0.5403433353734403, 'Total loss': 0.5403433353734403}
2022-12-05 22:49:36,964 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:36,964 INFO:     Epoch: 14
2022-12-05 22:49:37,676 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5677171010862697, 'Total loss': 0.5677171010862697} | train loss {'Reaction outcome loss': 0.5255730730681284, 'Total loss': 0.5255730730681284}
2022-12-05 22:49:37,676 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:37,676 INFO:     Epoch: 15
2022-12-05 22:49:38,386 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6249364076012914, 'Total loss': 0.6249364076012914} | train loss {'Reaction outcome loss': 0.5387674010837609, 'Total loss': 0.5387674010837609}
2022-12-05 22:49:38,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:38,386 INFO:     Epoch: 16
2022-12-05 22:49:39,098 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.6006111726164818, 'Total loss': 0.6006111726164818} | train loss {'Reaction outcome loss': 0.5249277058581592, 'Total loss': 0.5249277058581592}
2022-12-05 22:49:39,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:39,099 INFO:     Epoch: 17
2022-12-05 22:49:39,808 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.577934630215168, 'Total loss': 0.577934630215168} | train loss {'Reaction outcome loss': 0.5202799643340864, 'Total loss': 0.5202799643340864}
2022-12-05 22:49:39,808 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:39,808 INFO:     Epoch: 18
2022-12-05 22:49:40,518 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5751534978097136, 'Total loss': 0.5751534978097136} | train loss {'Reaction outcome loss': 0.5273436367934049, 'Total loss': 0.5273436367934049}
2022-12-05 22:49:40,518 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:40,518 INFO:     Epoch: 19
2022-12-05 22:49:41,231 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.56773076612841, 'Total loss': 0.56773076612841} | train loss {'Reaction outcome loss': 0.517533125996831, 'Total loss': 0.517533125996831}
2022-12-05 22:49:41,231 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:41,231 INFO:     Epoch: 20
2022-12-05 22:49:41,944 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.6110302670435472, 'Total loss': 0.6110302670435472} | train loss {'Reaction outcome loss': 0.5220549134650694, 'Total loss': 0.5220549134650694}
2022-12-05 22:49:41,944 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:41,944 INFO:     Epoch: 21
2022-12-05 22:49:42,655 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.6533765623515303, 'Total loss': 0.6533765623515303} | train loss {'Reaction outcome loss': 0.5344710065888972, 'Total loss': 0.5344710065888972}
2022-12-05 22:49:42,655 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:42,655 INFO:     Epoch: 22
2022-12-05 22:49:43,370 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5563901120966132, 'Total loss': 0.5563901120966132} | train loss {'Reaction outcome loss': 0.5398235123016333, 'Total loss': 0.5398235123016333}
2022-12-05 22:49:43,370 INFO:     Found new best model at epoch 22
2022-12-05 22:49:43,371 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:43,371 INFO:     Epoch: 23
2022-12-05 22:49:44,082 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5640744837847623, 'Total loss': 0.5640744837847623} | train loss {'Reaction outcome loss': 0.5296302270068813, 'Total loss': 0.5296302270068813}
2022-12-05 22:49:44,082 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:44,082 INFO:     Epoch: 24
2022-12-05 22:49:44,798 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5839496092362837, 'Total loss': 0.5839496092362837} | train loss {'Reaction outcome loss': 0.518094792117474, 'Total loss': 0.518094792117474}
2022-12-05 22:49:44,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:44,799 INFO:     Epoch: 25
2022-12-05 22:49:45,516 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5652461234818805, 'Total loss': 0.5652461234818805} | train loss {'Reaction outcome loss': 0.5264184071007467, 'Total loss': 0.5264184071007467}
2022-12-05 22:49:45,516 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:45,516 INFO:     Epoch: 26
2022-12-05 22:49:46,238 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.6108180670575662, 'Total loss': 0.6108180670575662} | train loss {'Reaction outcome loss': 0.5258144735007996, 'Total loss': 0.5258144735007996}
2022-12-05 22:49:46,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:46,238 INFO:     Epoch: 27
2022-12-05 22:49:46,951 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5516107346523892, 'Total loss': 0.5516107346523892} | train loss {'Reaction outcome loss': 0.5262834052687232, 'Total loss': 0.5262834052687232}
2022-12-05 22:49:46,951 INFO:     Found new best model at epoch 27
2022-12-05 22:49:46,952 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:46,952 INFO:     Epoch: 28
2022-12-05 22:49:47,666 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.6132168119603937, 'Total loss': 0.6132168119603937} | train loss {'Reaction outcome loss': 0.525719199887654, 'Total loss': 0.525719199887654}
2022-12-05 22:49:47,666 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:47,666 INFO:     Epoch: 29
2022-12-05 22:49:48,379 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5758554901589047, 'Total loss': 0.5758554901589047} | train loss {'Reaction outcome loss': 0.5282393472518033, 'Total loss': 0.5282393472518033}
2022-12-05 22:49:48,379 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:48,379 INFO:     Epoch: 30
2022-12-05 22:49:49,094 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5440268557180058, 'Total loss': 0.5440268557180058} | train loss {'Reaction outcome loss': 0.5294130768491189, 'Total loss': 0.5294130768491189}
2022-12-05 22:49:49,094 INFO:     Found new best model at epoch 30
2022-12-05 22:49:49,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:49,095 INFO:     Epoch: 31
2022-12-05 22:49:49,814 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5501104430718855, 'Total loss': 0.5501104430718855} | train loss {'Reaction outcome loss': 0.5180023603955743, 'Total loss': 0.5180023603955743}
2022-12-05 22:49:49,814 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:49,814 INFO:     Epoch: 32
2022-12-05 22:49:50,536 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5737805413928899, 'Total loss': 0.5737805413928899} | train loss {'Reaction outcome loss': 0.5339699421334363, 'Total loss': 0.5339699421334363}
2022-12-05 22:49:50,536 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:50,536 INFO:     Epoch: 33
2022-12-05 22:49:51,248 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5891646092588251, 'Total loss': 0.5891646092588251} | train loss {'Reaction outcome loss': 0.5243085745254509, 'Total loss': 0.5243085745254509}
2022-12-05 22:49:51,248 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:51,248 INFO:     Epoch: 34
2022-12-05 22:49:51,960 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5852329236539927, 'Total loss': 0.5852329236539927} | train loss {'Reaction outcome loss': 0.527143060316441, 'Total loss': 0.527143060316441}
2022-12-05 22:49:51,960 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:51,960 INFO:     Epoch: 35
2022-12-05 22:49:52,672 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5560527288100936, 'Total loss': 0.5560527288100936} | train loss {'Reaction outcome loss': 0.5201239885634136, 'Total loss': 0.5201239885634136}
2022-12-05 22:49:52,672 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:52,672 INFO:     Epoch: 36
2022-12-05 22:49:53,385 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5559010207653046, 'Total loss': 0.5559010207653046} | train loss {'Reaction outcome loss': 0.5212251886665097, 'Total loss': 0.5212251886665097}
2022-12-05 22:49:53,385 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:53,385 INFO:     Epoch: 37
2022-12-05 22:49:54,099 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5740556791424751, 'Total loss': 0.5740556791424751} | train loss {'Reaction outcome loss': 0.5263440792377179, 'Total loss': 0.5263440792377179}
2022-12-05 22:49:54,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:54,099 INFO:     Epoch: 38
2022-12-05 22:49:54,812 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5688869975168597, 'Total loss': 0.5688869975168597} | train loss {'Reaction outcome loss': 0.5206830773638328, 'Total loss': 0.5206830773638328}
2022-12-05 22:49:54,812 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:54,812 INFO:     Epoch: 39
2022-12-05 22:49:55,527 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5717679329893806, 'Total loss': 0.5717679329893806} | train loss {'Reaction outcome loss': 0.5149784506588932, 'Total loss': 0.5149784506588932}
2022-12-05 22:49:55,527 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:55,527 INFO:     Epoch: 40
2022-12-05 22:49:56,238 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5670851184563204, 'Total loss': 0.5670851184563204} | train loss {'Reaction outcome loss': 0.524562723783829, 'Total loss': 0.524562723783829}
2022-12-05 22:49:56,239 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:56,239 INFO:     Epoch: 41
2022-12-05 22:49:56,950 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5818199511956085, 'Total loss': 0.5818199511956085} | train loss {'Reaction outcome loss': 0.5289154798999006, 'Total loss': 0.5289154798999006}
2022-12-05 22:49:56,950 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:56,950 INFO:     Epoch: 42
2022-12-05 22:49:57,664 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5749451382593675, 'Total loss': 0.5749451382593675} | train loss {'Reaction outcome loss': 0.5179017800045943, 'Total loss': 0.5179017800045943}
2022-12-05 22:49:57,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:57,665 INFO:     Epoch: 43
2022-12-05 22:49:58,376 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5941255058754574, 'Total loss': 0.5941255058754574} | train loss {'Reaction outcome loss': 0.5187272062366791, 'Total loss': 0.5187272062366791}
2022-12-05 22:49:58,376 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:58,376 INFO:     Epoch: 44
2022-12-05 22:49:59,088 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.6016862629489466, 'Total loss': 0.6016862629489466} | train loss {'Reaction outcome loss': 0.5288180320972373, 'Total loss': 0.5288180320972373}
2022-12-05 22:49:59,088 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:59,088 INFO:     Epoch: 45
2022-12-05 22:49:59,799 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.554382591762326, 'Total loss': 0.554382591762326} | train loss {'Reaction outcome loss': 0.5278117852172388, 'Total loss': 0.5278117852172388}
2022-12-05 22:49:59,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:49:59,799 INFO:     Epoch: 46
2022-12-05 22:50:00,510 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.6607329391620376, 'Total loss': 0.6607329391620376} | train loss {'Reaction outcome loss': 0.513541434105365, 'Total loss': 0.513541434105365}
2022-12-05 22:50:00,510 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:00,510 INFO:     Epoch: 47
2022-12-05 22:50:01,222 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5674281333657828, 'Total loss': 0.5674281333657828} | train loss {'Reaction outcome loss': 0.5156803543751056, 'Total loss': 0.5156803543751056}
2022-12-05 22:50:01,222 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:01,222 INFO:     Epoch: 48
2022-12-05 22:50:01,935 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5648686137389053, 'Total loss': 0.5648686137389053} | train loss {'Reaction outcome loss': 0.5179237644470897, 'Total loss': 0.5179237644470897}
2022-12-05 22:50:01,935 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:01,935 INFO:     Epoch: 49
2022-12-05 22:50:02,648 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5607587938958948, 'Total loss': 0.5607587938958948} | train loss {'Reaction outcome loss': 0.5208469398229228, 'Total loss': 0.5208469398229228}
2022-12-05 22:50:02,649 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:02,649 INFO:     Epoch: 50
2022-12-05 22:50:03,361 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5843775604258884, 'Total loss': 0.5843775604258884} | train loss {'Reaction outcome loss': 0.5248565142936552, 'Total loss': 0.5248565142936552}
2022-12-05 22:50:03,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:03,361 INFO:     Epoch: 51
2022-12-05 22:50:04,075 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.561311040412296, 'Total loss': 0.561311040412296} | train loss {'Reaction outcome loss': 0.5199257181240962, 'Total loss': 0.5199257181240962}
2022-12-05 22:50:04,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:04,075 INFO:     Epoch: 52
2022-12-05 22:50:04,787 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5809632749720053, 'Total loss': 0.5809632749720053} | train loss {'Reaction outcome loss': 0.5237967730518657, 'Total loss': 0.5237967730518657}
2022-12-05 22:50:04,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:04,787 INFO:     Epoch: 53
2022-12-05 22:50:05,500 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5769329795783217, 'Total loss': 0.5769329795783217} | train loss {'Reaction outcome loss': 0.527817486811746, 'Total loss': 0.527817486811746}
2022-12-05 22:50:05,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:05,500 INFO:     Epoch: 54
2022-12-05 22:50:06,216 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.6148391708054326, 'Total loss': 0.6148391708054326} | train loss {'Reaction outcome loss': 0.5248889824156819, 'Total loss': 0.5248889824156819}
2022-12-05 22:50:06,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:06,216 INFO:     Epoch: 55
2022-12-05 22:50:06,929 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5718973854726012, 'Total loss': 0.5718973854726012} | train loss {'Reaction outcome loss': 0.51789657445813, 'Total loss': 0.51789657445813}
2022-12-05 22:50:06,929 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:06,929 INFO:     Epoch: 56
2022-12-05 22:50:07,642 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5759830176830292, 'Total loss': 0.5759830176830292} | train loss {'Reaction outcome loss': 0.5222082884326155, 'Total loss': 0.5222082884326155}
2022-12-05 22:50:07,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:07,642 INFO:     Epoch: 57
2022-12-05 22:50:08,352 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5650300607085228, 'Total loss': 0.5650300607085228} | train loss {'Reaction outcome loss': 0.5231180927652096, 'Total loss': 0.5231180927652096}
2022-12-05 22:50:08,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:08,352 INFO:     Epoch: 58
2022-12-05 22:50:09,063 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5878078375350345, 'Total loss': 0.5878078375350345} | train loss {'Reaction outcome loss': 0.5122993971684925, 'Total loss': 0.5122993971684925}
2022-12-05 22:50:09,063 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:09,063 INFO:     Epoch: 59
2022-12-05 22:50:09,774 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5599539693106305, 'Total loss': 0.5599539693106305} | train loss {'Reaction outcome loss': 0.520233475425948, 'Total loss': 0.520233475425948}
2022-12-05 22:50:09,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:09,774 INFO:     Epoch: 60
2022-12-05 22:50:10,486 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5629769197919152, 'Total loss': 0.5629769197919152} | train loss {'Reaction outcome loss': 0.5246424744968955, 'Total loss': 0.5246424744968955}
2022-12-05 22:50:10,486 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:10,486 INFO:     Epoch: 61
2022-12-05 22:50:11,203 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5886426446112719, 'Total loss': 0.5886426446112719} | train loss {'Reaction outcome loss': 0.5202517797831099, 'Total loss': 0.5202517797831099}
2022-12-05 22:50:11,203 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:11,203 INFO:     Epoch: 62
2022-12-05 22:50:11,915 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5808417146856134, 'Total loss': 0.5808417146856134} | train loss {'Reaction outcome loss': 0.5266649611445091, 'Total loss': 0.5266649611445091}
2022-12-05 22:50:11,915 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:11,915 INFO:     Epoch: 63
2022-12-05 22:50:12,631 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.595813435587016, 'Total loss': 0.595813435587016} | train loss {'Reaction outcome loss': 0.5271849866526631, 'Total loss': 0.5271849866526631}
2022-12-05 22:50:12,632 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:12,632 INFO:     Epoch: 64
2022-12-05 22:50:13,344 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5483863258903677, 'Total loss': 0.5483863258903677} | train loss {'Reaction outcome loss': 0.5123626431110899, 'Total loss': 0.5123626431110899}
2022-12-05 22:50:13,344 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:13,344 INFO:     Epoch: 65
2022-12-05 22:50:14,057 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5867545956915076, 'Total loss': 0.5867545956915076} | train loss {'Reaction outcome loss': 0.5143944657283274, 'Total loss': 0.5143944657283274}
2022-12-05 22:50:14,057 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:14,057 INFO:     Epoch: 66
2022-12-05 22:50:14,771 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5383102738044478, 'Total loss': 0.5383102738044478} | train loss {'Reaction outcome loss': 0.5148334468890223, 'Total loss': 0.5148334468890223}
2022-12-05 22:50:14,772 INFO:     Found new best model at epoch 66
2022-12-05 22:50:14,773 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:14,773 INFO:     Epoch: 67
2022-12-05 22:50:15,484 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5949580547484484, 'Total loss': 0.5949580547484484} | train loss {'Reaction outcome loss': 0.5209664598650295, 'Total loss': 0.5209664598650295}
2022-12-05 22:50:15,484 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:15,484 INFO:     Epoch: 68
2022-12-05 22:50:16,200 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5618716478347778, 'Total loss': 0.5618716478347778} | train loss {'Reaction outcome loss': 0.5276094932516335, 'Total loss': 0.5276094932516335}
2022-12-05 22:50:16,200 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:16,201 INFO:     Epoch: 69
2022-12-05 22:50:16,912 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5572368465363979, 'Total loss': 0.5572368465363979} | train loss {'Reaction outcome loss': 0.5148943253012321, 'Total loss': 0.5148943253012321}
2022-12-05 22:50:16,912 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:16,912 INFO:     Epoch: 70
2022-12-05 22:50:17,624 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5626766393807802, 'Total loss': 0.5626766393807802} | train loss {'Reaction outcome loss': 0.5210707037585226, 'Total loss': 0.5210707037585226}
2022-12-05 22:50:17,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:17,624 INFO:     Epoch: 71
2022-12-05 22:50:18,346 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.569269210100174, 'Total loss': 0.569269210100174} | train loss {'Reaction outcome loss': 0.5162226938103375, 'Total loss': 0.5162226938103375}
2022-12-05 22:50:18,346 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:18,346 INFO:     Epoch: 72
2022-12-05 22:50:19,075 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5502416417002678, 'Total loss': 0.5502416417002678} | train loss {'Reaction outcome loss': 0.520858517059913, 'Total loss': 0.520858517059913}
2022-12-05 22:50:19,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:19,075 INFO:     Epoch: 73
2022-12-05 22:50:19,809 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.578225857832215, 'Total loss': 0.578225857832215} | train loss {'Reaction outcome loss': 0.525660898762676, 'Total loss': 0.525660898762676}
2022-12-05 22:50:19,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:19,809 INFO:     Epoch: 74
2022-12-05 22:50:20,538 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5508314818143845, 'Total loss': 0.5508314818143845} | train loss {'Reaction outcome loss': 0.5305613222633779, 'Total loss': 0.5305613222633779}
2022-12-05 22:50:20,539 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:20,539 INFO:     Epoch: 75
2022-12-05 22:50:21,268 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5492245121435686, 'Total loss': 0.5492245121435686} | train loss {'Reaction outcome loss': 0.5224066597488728, 'Total loss': 0.5224066597488728}
2022-12-05 22:50:21,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:21,268 INFO:     Epoch: 76
2022-12-05 22:50:21,997 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.579954781992869, 'Total loss': 0.579954781992869} | train loss {'Reaction outcome loss': 0.5179252161188164, 'Total loss': 0.5179252161188164}
2022-12-05 22:50:21,997 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:21,997 INFO:     Epoch: 77
2022-12-05 22:50:22,726 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5619779188524593, 'Total loss': 0.5619779188524593} | train loss {'Reaction outcome loss': 0.5174025317676637, 'Total loss': 0.5174025317676637}
2022-12-05 22:50:22,726 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:22,726 INFO:     Epoch: 78
2022-12-05 22:50:23,456 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6075793992389332, 'Total loss': 0.6075793992389332} | train loss {'Reaction outcome loss': 0.519615958983961, 'Total loss': 0.519615958983961}
2022-12-05 22:50:23,457 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:23,457 INFO:     Epoch: 79
2022-12-05 22:50:24,188 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.573177558793263, 'Total loss': 0.573177558793263} | train loss {'Reaction outcome loss': 0.5168409235926292, 'Total loss': 0.5168409235926292}
2022-12-05 22:50:24,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:24,189 INFO:     Epoch: 80
2022-12-05 22:50:24,917 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5739162083376538, 'Total loss': 0.5739162083376538} | train loss {'Reaction outcome loss': 0.5308932832740096, 'Total loss': 0.5308932832740096}
2022-12-05 22:50:24,918 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:24,918 INFO:     Epoch: 81
2022-12-05 22:50:25,646 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5622076094150543, 'Total loss': 0.5622076094150543} | train loss {'Reaction outcome loss': 0.5203849880198236, 'Total loss': 0.5203849880198236}
2022-12-05 22:50:25,646 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:25,646 INFO:     Epoch: 82
2022-12-05 22:50:26,377 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.6149471317502585, 'Total loss': 0.6149471317502585} | train loss {'Reaction outcome loss': 0.5138037275930165, 'Total loss': 0.5138037275930165}
2022-12-05 22:50:26,377 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:26,377 INFO:     Epoch: 83
2022-12-05 22:50:27,109 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6015275161374699, 'Total loss': 0.6015275161374699} | train loss {'Reaction outcome loss': 0.5203580178229915, 'Total loss': 0.5203580178229915}
2022-12-05 22:50:27,109 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:27,109 INFO:     Epoch: 84
2022-12-05 22:50:27,842 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5637252086942847, 'Total loss': 0.5637252086942847} | train loss {'Reaction outcome loss': 0.5295160580501865, 'Total loss': 0.5295160580501865}
2022-12-05 22:50:27,843 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:27,844 INFO:     Epoch: 85
2022-12-05 22:50:28,580 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5692631896923889, 'Total loss': 0.5692631896923889} | train loss {'Reaction outcome loss': 0.5189852539189763, 'Total loss': 0.5189852539189763}
2022-12-05 22:50:28,580 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:28,580 INFO:     Epoch: 86
2022-12-05 22:50:29,309 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5971377024596388, 'Total loss': 0.5971377024596388} | train loss {'Reaction outcome loss': 0.5199591855891803, 'Total loss': 0.5199591855891803}
2022-12-05 22:50:29,310 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:29,310 INFO:     Epoch: 87
2022-12-05 22:50:30,042 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5530857569114729, 'Total loss': 0.5530857569114729} | train loss {'Reaction outcome loss': 0.5188251699882782, 'Total loss': 0.5188251699882782}
2022-12-05 22:50:30,042 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:30,042 INFO:     Epoch: 88
2022-12-05 22:50:30,777 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5619603361595761, 'Total loss': 0.5619603361595761} | train loss {'Reaction outcome loss': 0.5169841621093724, 'Total loss': 0.5169841621093724}
2022-12-05 22:50:30,777 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:30,777 INFO:     Epoch: 89
2022-12-05 22:50:31,506 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5964916111393408, 'Total loss': 0.5964916111393408} | train loss {'Reaction outcome loss': 0.5301062499101346, 'Total loss': 0.5301062499101346}
2022-12-05 22:50:31,507 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:31,507 INFO:     Epoch: 90
2022-12-05 22:50:32,235 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5738955830985849, 'Total loss': 0.5738955830985849} | train loss {'Reaction outcome loss': 0.5259820116525479, 'Total loss': 0.5259820116525479}
2022-12-05 22:50:32,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:32,235 INFO:     Epoch: 91
2022-12-05 22:50:32,963 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.6260535341094841, 'Total loss': 0.6260535341094841} | train loss {'Reaction outcome loss': 0.5184848209624349, 'Total loss': 0.5184848209624349}
2022-12-05 22:50:32,963 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:32,963 INFO:     Epoch: 92
2022-12-05 22:50:33,691 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6209484528411519, 'Total loss': 0.6209484528411519} | train loss {'Reaction outcome loss': 0.5222666381824355, 'Total loss': 0.5222666381824355}
2022-12-05 22:50:33,691 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:33,692 INFO:     Epoch: 93
2022-12-05 22:50:34,424 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5537536719983275, 'Total loss': 0.5537536719983275} | train loss {'Reaction outcome loss': 0.5264244371881852, 'Total loss': 0.5264244371881852}
2022-12-05 22:50:34,425 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:34,425 INFO:     Epoch: 94
2022-12-05 22:50:35,155 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5709713345224207, 'Total loss': 0.5709713345224207} | train loss {'Reaction outcome loss': 0.5129246602083749, 'Total loss': 0.5129246602083749}
2022-12-05 22:50:35,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:35,156 INFO:     Epoch: 95
2022-12-05 22:50:35,876 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5663613497533582, 'Total loss': 0.5663613497533582} | train loss {'Reaction outcome loss': 0.5216575313796882, 'Total loss': 0.5216575313796882}
2022-12-05 22:50:35,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:35,876 INFO:     Epoch: 96
2022-12-05 22:50:36,586 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5605159364640713, 'Total loss': 0.5605159364640713} | train loss {'Reaction outcome loss': 0.523834314366976, 'Total loss': 0.523834314366976}
2022-12-05 22:50:36,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:36,586 INFO:     Epoch: 97
2022-12-05 22:50:37,297 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5572025508365848, 'Total loss': 0.5572025508365848} | train loss {'Reaction outcome loss': 0.5102481108973262, 'Total loss': 0.5102481108973262}
2022-12-05 22:50:37,298 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:37,298 INFO:     Epoch: 98
2022-12-05 22:50:38,007 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5822499380870299, 'Total loss': 0.5822499380870299} | train loss {'Reaction outcome loss': 0.5185988923527209, 'Total loss': 0.5185988923527209}
2022-12-05 22:50:38,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:38,007 INFO:     Epoch: 99
2022-12-05 22:50:38,716 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5631074207750234, 'Total loss': 0.5631074207750234} | train loss {'Reaction outcome loss': 0.5128111524247236, 'Total loss': 0.5128111524247236}
2022-12-05 22:50:38,716 INFO:     Best model found after epoch 67 of 100.
2022-12-05 22:50:38,717 INFO:   Done with stage: TRAINING
2022-12-05 22:50:38,717 INFO:   Starting stage: EVALUATION
2022-12-05 22:50:38,841 INFO:   Done with stage: EVALUATION
2022-12-05 22:50:38,841 INFO:   Leaving out SEQ value Fold_8
2022-12-05 22:50:38,854 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:50:38,854 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:50:39,500 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:50:39,500 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:50:39,571 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:50:39,571 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:50:39,571 INFO:     No hyperparam tuning for this model
2022-12-05 22:50:39,572 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:50:39,572 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:50:39,572 INFO:     None feature selector for col prot
2022-12-05 22:50:39,572 INFO:     None feature selector for col prot
2022-12-05 22:50:39,572 INFO:     None feature selector for col prot
2022-12-05 22:50:39,573 INFO:     None feature selector for col chem
2022-12-05 22:50:39,573 INFO:     None feature selector for col chem
2022-12-05 22:50:39,573 INFO:     None feature selector for col chem
2022-12-05 22:50:39,573 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:50:39,573 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:50:39,575 INFO:     Number of params in model 215731
2022-12-05 22:50:39,578 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:50:39,578 INFO:   Starting stage: TRAINING
2022-12-05 22:50:39,637 INFO:     Val loss before train {'Reaction outcome loss': 0.9801063016057014, 'Total loss': 0.9801063016057014}
2022-12-05 22:50:39,637 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:39,637 INFO:     Epoch: 0
2022-12-05 22:50:40,346 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6840813356367025, 'Total loss': 0.6840813356367025} | train loss {'Reaction outcome loss': 0.8282796850329951, 'Total loss': 0.8282796850329951}
2022-12-05 22:50:40,346 INFO:     Found new best model at epoch 0
2022-12-05 22:50:40,347 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:40,347 INFO:     Epoch: 1
2022-12-05 22:50:41,056 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6911712024699558, 'Total loss': 0.6911712024699558} | train loss {'Reaction outcome loss': 0.6815250372355767, 'Total loss': 0.6815250372355767}
2022-12-05 22:50:41,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:41,056 INFO:     Epoch: 2
2022-12-05 22:50:41,771 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6626749499277635, 'Total loss': 0.6626749499277635} | train loss {'Reaction outcome loss': 0.6603104641683671, 'Total loss': 0.6603104641683671}
2022-12-05 22:50:41,772 INFO:     Found new best model at epoch 2
2022-12-05 22:50:41,772 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:41,772 INFO:     Epoch: 3
2022-12-05 22:50:42,483 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5753729363734071, 'Total loss': 0.5753729363734071} | train loss {'Reaction outcome loss': 0.6147475900196353, 'Total loss': 0.6147475900196353}
2022-12-05 22:50:42,484 INFO:     Found new best model at epoch 3
2022-12-05 22:50:42,484 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:42,484 INFO:     Epoch: 4
2022-12-05 22:50:43,195 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6210656694390557, 'Total loss': 0.6210656694390557} | train loss {'Reaction outcome loss': 0.5989248472066061, 'Total loss': 0.5989248472066061}
2022-12-05 22:50:43,195 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:43,195 INFO:     Epoch: 5
2022-12-05 22:50:43,910 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5847422433170405, 'Total loss': 0.5847422433170405} | train loss {'Reaction outcome loss': 0.5906184639042689, 'Total loss': 0.5906184639042689}
2022-12-05 22:50:43,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:43,911 INFO:     Epoch: 6
2022-12-05 22:50:44,621 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5619265616617419, 'Total loss': 0.5619265616617419} | train loss {'Reaction outcome loss': 0.5687823426958761, 'Total loss': 0.5687823426958761}
2022-12-05 22:50:44,621 INFO:     Found new best model at epoch 6
2022-12-05 22:50:44,622 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:44,622 INFO:     Epoch: 7
2022-12-05 22:50:45,336 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5728073546832259, 'Total loss': 0.5728073546832259} | train loss {'Reaction outcome loss': 0.5600494958596071, 'Total loss': 0.5600494958596071}
2022-12-05 22:50:45,336 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:45,336 INFO:     Epoch: 8
2022-12-05 22:50:46,043 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5369824384423819, 'Total loss': 0.5369824384423819} | train loss {'Reaction outcome loss': 0.5689368870576866, 'Total loss': 0.5689368870576866}
2022-12-05 22:50:46,043 INFO:     Found new best model at epoch 8
2022-12-05 22:50:46,044 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:46,044 INFO:     Epoch: 9
2022-12-05 22:50:46,748 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5687512958591635, 'Total loss': 0.5687512958591635} | train loss {'Reaction outcome loss': 0.5588923040852856, 'Total loss': 0.5588923040852856}
2022-12-05 22:50:46,749 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:46,749 INFO:     Epoch: 10
2022-12-05 22:50:47,453 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5679851147261533, 'Total loss': 0.5679851147261533} | train loss {'Reaction outcome loss': 0.5531443141491307, 'Total loss': 0.5531443141491307}
2022-12-05 22:50:47,454 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:47,454 INFO:     Epoch: 11
2022-12-05 22:50:48,162 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5825435546311465, 'Total loss': 0.5825435546311465} | train loss {'Reaction outcome loss': 0.5565079913327569, 'Total loss': 0.5565079913327569}
2022-12-05 22:50:48,162 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:48,162 INFO:     Epoch: 12
2022-12-05 22:50:48,874 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.6042184369130568, 'Total loss': 0.6042184369130568} | train loss {'Reaction outcome loss': 0.5663426920228641, 'Total loss': 0.5663426920228641}
2022-12-05 22:50:48,875 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:48,875 INFO:     Epoch: 13
2022-12-05 22:50:49,582 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5525492301041429, 'Total loss': 0.5525492301041429} | train loss {'Reaction outcome loss': 0.5560094966941517, 'Total loss': 0.5560094966941517}
2022-12-05 22:50:49,583 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:49,583 INFO:     Epoch: 14
2022-12-05 22:50:50,288 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5701931552453474, 'Total loss': 0.5701931552453474} | train loss {'Reaction outcome loss': 0.5515830911967435, 'Total loss': 0.5515830911967435}
2022-12-05 22:50:50,289 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:50,289 INFO:     Epoch: 15
2022-12-05 22:50:50,996 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5472758811983195, 'Total loss': 0.5472758811983195} | train loss {'Reaction outcome loss': 0.550453776953674, 'Total loss': 0.550453776953674}
2022-12-05 22:50:50,996 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:50,996 INFO:     Epoch: 16
2022-12-05 22:50:51,700 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5622472011230208, 'Total loss': 0.5622472011230208} | train loss {'Reaction outcome loss': 0.544981980432383, 'Total loss': 0.544981980432383}
2022-12-05 22:50:51,700 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:51,700 INFO:     Epoch: 17
2022-12-05 22:50:52,407 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5662963928824122, 'Total loss': 0.5662963928824122} | train loss {'Reaction outcome loss': 0.5522225093443384, 'Total loss': 0.5522225093443384}
2022-12-05 22:50:52,408 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:52,408 INFO:     Epoch: 18
2022-12-05 22:50:53,111 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.573313291777264, 'Total loss': 0.573313291777264} | train loss {'Reaction outcome loss': 0.5520069262518091, 'Total loss': 0.5520069262518091}
2022-12-05 22:50:53,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:53,111 INFO:     Epoch: 19
2022-12-05 22:50:53,820 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5713239197026599, 'Total loss': 0.5713239197026599} | train loss {'Reaction outcome loss': 0.5467882299350824, 'Total loss': 0.5467882299350824}
2022-12-05 22:50:53,821 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:53,821 INFO:     Epoch: 20
2022-12-05 22:50:54,530 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.6045188558372584, 'Total loss': 0.6045188558372584} | train loss {'Reaction outcome loss': 0.5497619390849643, 'Total loss': 0.5497619390849643}
2022-12-05 22:50:54,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:54,530 INFO:     Epoch: 21
2022-12-05 22:50:55,237 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5335597229952161, 'Total loss': 0.5335597229952161} | train loss {'Reaction outcome loss': 0.5510599243677097, 'Total loss': 0.5510599243677097}
2022-12-05 22:50:55,237 INFO:     Found new best model at epoch 21
2022-12-05 22:50:55,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:55,238 INFO:     Epoch: 22
2022-12-05 22:50:55,949 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5375244800340045, 'Total loss': 0.5375244800340045} | train loss {'Reaction outcome loss': 0.5397630167695192, 'Total loss': 0.5397630167695192}
2022-12-05 22:50:55,949 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:55,949 INFO:     Epoch: 23
2022-12-05 22:50:56,656 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.627950677817518, 'Total loss': 0.627950677817518} | train loss {'Reaction outcome loss': 0.5530948814472206, 'Total loss': 0.5530948814472206}
2022-12-05 22:50:56,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:56,656 INFO:     Epoch: 24
2022-12-05 22:50:57,361 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5440552559765902, 'Total loss': 0.5440552559765902} | train loss {'Reaction outcome loss': 0.5394769778950252, 'Total loss': 0.5394769778950252}
2022-12-05 22:50:57,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:57,361 INFO:     Epoch: 25
2022-12-05 22:50:58,066 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5526070946996863, 'Total loss': 0.5526070946996863} | train loss {'Reaction outcome loss': 0.5431110418518545, 'Total loss': 0.5431110418518545}
2022-12-05 22:50:58,067 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:58,067 INFO:     Epoch: 26
2022-12-05 22:50:58,774 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.6431178650395437, 'Total loss': 0.6431178650395437} | train loss {'Reaction outcome loss': 0.5506535658107595, 'Total loss': 0.5506535658107595}
2022-12-05 22:50:58,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:58,774 INFO:     Epoch: 27
2022-12-05 22:50:59,479 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5411043255166574, 'Total loss': 0.5411043255166574} | train loss {'Reaction outcome loss': 0.5422049483834852, 'Total loss': 0.5422049483834852}
2022-12-05 22:50:59,479 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:50:59,479 INFO:     Epoch: 28
2022-12-05 22:51:00,190 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5518539371815595, 'Total loss': 0.5518539371815595} | train loss {'Reaction outcome loss': 0.5440588012631786, 'Total loss': 0.5440588012631786}
2022-12-05 22:51:00,190 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:00,190 INFO:     Epoch: 29
2022-12-05 22:51:00,898 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5738588757812977, 'Total loss': 0.5738588757812977} | train loss {'Reaction outcome loss': 0.5510632887422314, 'Total loss': 0.5510632887422314}
2022-12-05 22:51:00,898 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:00,898 INFO:     Epoch: 30
2022-12-05 22:51:01,608 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5478652187369086, 'Total loss': 0.5478652187369086} | train loss {'Reaction outcome loss': 0.5471819143908226, 'Total loss': 0.5471819143908226}
2022-12-05 22:51:01,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:01,608 INFO:     Epoch: 31
2022-12-05 22:51:02,316 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5665571052919735, 'Total loss': 0.5665571052919735} | train loss {'Reaction outcome loss': 0.5451755984592052, 'Total loss': 0.5451755984592052}
2022-12-05 22:51:02,317 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:02,317 INFO:     Epoch: 32
2022-12-05 22:51:03,024 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5338611311533235, 'Total loss': 0.5338611311533235} | train loss {'Reaction outcome loss': 0.5506849434483148, 'Total loss': 0.5506849434483148}
2022-12-05 22:51:03,024 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:03,024 INFO:     Epoch: 33
2022-12-05 22:51:03,730 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5403355793519453, 'Total loss': 0.5403355793519453} | train loss {'Reaction outcome loss': 0.5383479759278085, 'Total loss': 0.5383479759278085}
2022-12-05 22:51:03,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:03,730 INFO:     Epoch: 34
2022-12-05 22:51:04,434 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5492199713533575, 'Total loss': 0.5492199713533575} | train loss {'Reaction outcome loss': 0.5478092630503149, 'Total loss': 0.5478092630503149}
2022-12-05 22:51:04,435 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:04,435 INFO:     Epoch: 35
2022-12-05 22:51:05,143 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5566137788647955, 'Total loss': 0.5566137788647955} | train loss {'Reaction outcome loss': 0.542389615084448, 'Total loss': 0.542389615084448}
2022-12-05 22:51:05,143 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:05,143 INFO:     Epoch: 36
2022-12-05 22:51:05,848 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5377378511157903, 'Total loss': 0.5377378511157903} | train loss {'Reaction outcome loss': 0.545227321716938, 'Total loss': 0.545227321716938}
2022-12-05 22:51:05,848 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:05,848 INFO:     Epoch: 37
2022-12-05 22:51:06,554 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5268802060322328, 'Total loss': 0.5268802060322328} | train loss {'Reaction outcome loss': 0.5403293943115575, 'Total loss': 0.5403293943115575}
2022-12-05 22:51:06,554 INFO:     Found new best model at epoch 37
2022-12-05 22:51:06,555 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:06,555 INFO:     Epoch: 38
2022-12-05 22:51:07,260 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5630224469033155, 'Total loss': 0.5630224469033155} | train loss {'Reaction outcome loss': 0.5449626141110895, 'Total loss': 0.5449626141110895}
2022-12-05 22:51:07,260 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:07,260 INFO:     Epoch: 39
2022-12-05 22:51:07,973 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5730484591966326, 'Total loss': 0.5730484591966326} | train loss {'Reaction outcome loss': 0.5560323878338462, 'Total loss': 0.5560323878338462}
2022-12-05 22:51:07,973 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:07,973 INFO:     Epoch: 40
2022-12-05 22:51:08,681 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5252857353876937, 'Total loss': 0.5252857353876937} | train loss {'Reaction outcome loss': 0.560266049586327, 'Total loss': 0.560266049586327}
2022-12-05 22:51:08,681 INFO:     Found new best model at epoch 40
2022-12-05 22:51:08,681 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:08,682 INFO:     Epoch: 41
2022-12-05 22:51:09,386 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5604241564869881, 'Total loss': 0.5604241564869881} | train loss {'Reaction outcome loss': 0.5389528715839753, 'Total loss': 0.5389528715839753}
2022-12-05 22:51:09,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:09,387 INFO:     Epoch: 42
2022-12-05 22:51:10,095 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5399941185658629, 'Total loss': 0.5399941185658629} | train loss {'Reaction outcome loss': 0.5437045536543194, 'Total loss': 0.5437045536543194}
2022-12-05 22:51:10,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:10,095 INFO:     Epoch: 43
2022-12-05 22:51:10,801 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5588016178120266, 'Total loss': 0.5588016178120266} | train loss {'Reaction outcome loss': 0.5424490592137039, 'Total loss': 0.5424490592137039}
2022-12-05 22:51:10,801 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:10,802 INFO:     Epoch: 44
2022-12-05 22:51:11,507 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.546552466059273, 'Total loss': 0.546552466059273} | train loss {'Reaction outcome loss': 0.5501208514699086, 'Total loss': 0.5501208514699086}
2022-12-05 22:51:11,507 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:11,508 INFO:     Epoch: 45
2022-12-05 22:51:12,219 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5550870638002049, 'Total loss': 0.5550870638002049} | train loss {'Reaction outcome loss': 0.5439799558899181, 'Total loss': 0.5439799558899181}
2022-12-05 22:51:12,219 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:12,219 INFO:     Epoch: 46
2022-12-05 22:51:12,924 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5362859104167331, 'Total loss': 0.5362859104167331} | train loss {'Reaction outcome loss': 0.5330693769732467, 'Total loss': 0.5330693769732467}
2022-12-05 22:51:12,925 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:12,925 INFO:     Epoch: 47
2022-12-05 22:51:13,629 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5386424003676935, 'Total loss': 0.5386424003676935} | train loss {'Reaction outcome loss': 0.5314411461986752, 'Total loss': 0.5314411461986752}
2022-12-05 22:51:13,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:13,630 INFO:     Epoch: 48
2022-12-05 22:51:14,340 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5410495525733992, 'Total loss': 0.5410495525733992} | train loss {'Reaction outcome loss': 0.5399864151383852, 'Total loss': 0.5399864151383852}
2022-12-05 22:51:14,340 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:14,340 INFO:     Epoch: 49
2022-12-05 22:51:15,048 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.554468420418826, 'Total loss': 0.554468420418826} | train loss {'Reaction outcome loss': 0.5388713195818186, 'Total loss': 0.5388713195818186}
2022-12-05 22:51:15,048 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:15,048 INFO:     Epoch: 50
2022-12-05 22:51:15,760 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5301183570515026, 'Total loss': 0.5301183570515026} | train loss {'Reaction outcome loss': 0.5386465612934669, 'Total loss': 0.5386465612934669}
2022-12-05 22:51:15,760 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:15,760 INFO:     Epoch: 51
2022-12-05 22:51:16,468 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5385803986679424, 'Total loss': 0.5385803986679424} | train loss {'Reaction outcome loss': 0.5422579927241754, 'Total loss': 0.5422579927241754}
2022-12-05 22:51:16,469 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:16,469 INFO:     Epoch: 52
2022-12-05 22:51:17,173 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5415035086599264, 'Total loss': 0.5415035086599264} | train loss {'Reaction outcome loss': 0.5476789429693328, 'Total loss': 0.5476789429693328}
2022-12-05 22:51:17,173 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:17,173 INFO:     Epoch: 53
2022-12-05 22:51:17,885 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5317160697145895, 'Total loss': 0.5317160697145895} | train loss {'Reaction outcome loss': 0.539287305855558, 'Total loss': 0.539287305855558}
2022-12-05 22:51:17,885 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:17,885 INFO:     Epoch: 54
2022-12-05 22:51:18,593 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5679542124271393, 'Total loss': 0.5679542124271393} | train loss {'Reaction outcome loss': 0.5455225794783488, 'Total loss': 0.5455225794783488}
2022-12-05 22:51:18,593 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:18,593 INFO:     Epoch: 55
2022-12-05 22:51:19,298 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5575750212777745, 'Total loss': 0.5575750212777745} | train loss {'Reaction outcome loss': 0.5443310555869992, 'Total loss': 0.5443310555869992}
2022-12-05 22:51:19,298 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:19,298 INFO:     Epoch: 56
2022-12-05 22:51:20,009 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7074265778064728, 'Total loss': 0.7074265778064728} | train loss {'Reaction outcome loss': 0.5448762296061767, 'Total loss': 0.5448762296061767}
2022-12-05 22:51:20,009 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:20,009 INFO:     Epoch: 57
2022-12-05 22:51:20,716 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5451077449728142, 'Total loss': 0.5451077449728142} | train loss {'Reaction outcome loss': 0.5562320798032196, 'Total loss': 0.5562320798032196}
2022-12-05 22:51:20,716 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:20,716 INFO:     Epoch: 58
2022-12-05 22:51:21,421 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5490069094706665, 'Total loss': 0.5490069094706665} | train loss {'Reaction outcome loss': 0.5452159275772118, 'Total loss': 0.5452159275772118}
2022-12-05 22:51:21,421 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:21,421 INFO:     Epoch: 59
2022-12-05 22:51:22,126 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5343557819724083, 'Total loss': 0.5343557819724083} | train loss {'Reaction outcome loss': 0.5449206240867314, 'Total loss': 0.5449206240867314}
2022-12-05 22:51:22,126 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:22,127 INFO:     Epoch: 60
2022-12-05 22:51:22,832 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5704071718183431, 'Total loss': 0.5704071718183431} | train loss {'Reaction outcome loss': 0.5436807812949424, 'Total loss': 0.5436807812949424}
2022-12-05 22:51:22,832 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:22,832 INFO:     Epoch: 61
2022-12-05 22:51:23,536 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5371767749840562, 'Total loss': 0.5371767749840562} | train loss {'Reaction outcome loss': 0.541320797191699, 'Total loss': 0.541320797191699}
2022-12-05 22:51:23,536 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:23,536 INFO:     Epoch: 62
2022-12-05 22:51:24,240 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5660355253653093, 'Total loss': 0.5660355253653093} | train loss {'Reaction outcome loss': 0.5515287321830086, 'Total loss': 0.5515287321830086}
2022-12-05 22:51:24,240 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:24,240 INFO:     Epoch: 63
2022-12-05 22:51:24,946 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5395834865895185, 'Total loss': 0.5395834865895185} | train loss {'Reaction outcome loss': 0.5437715977792316, 'Total loss': 0.5437715977792316}
2022-12-05 22:51:24,946 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:24,946 INFO:     Epoch: 64
2022-12-05 22:51:25,650 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5602559677579186, 'Total loss': 0.5602559677579186} | train loss {'Reaction outcome loss': 0.5418211617450482, 'Total loss': 0.5418211617450482}
2022-12-05 22:51:25,650 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:25,650 INFO:     Epoch: 65
2022-12-05 22:51:26,356 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5474766316738996, 'Total loss': 0.5474766316738996} | train loss {'Reaction outcome loss': 0.5465153515459555, 'Total loss': 0.5465153515459555}
2022-12-05 22:51:26,356 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:26,356 INFO:     Epoch: 66
2022-12-05 22:51:27,061 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.581846335394816, 'Total loss': 0.581846335394816} | train loss {'Reaction outcome loss': 0.5420486096307816, 'Total loss': 0.5420486096307816}
2022-12-05 22:51:27,061 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:27,061 INFO:     Epoch: 67
2022-12-05 22:51:27,774 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5360412692481821, 'Total loss': 0.5360412692481821} | train loss {'Reaction outcome loss': 0.5445795416726396, 'Total loss': 0.5445795416726396}
2022-12-05 22:51:27,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:27,774 INFO:     Epoch: 68
2022-12-05 22:51:28,482 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5600066875869577, 'Total loss': 0.5600066875869577} | train loss {'Reaction outcome loss': 0.5401122101888001, 'Total loss': 0.5401122101888001}
2022-12-05 22:51:28,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:28,483 INFO:     Epoch: 69
2022-12-05 22:51:29,191 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5404740494083274, 'Total loss': 0.5404740494083274} | train loss {'Reaction outcome loss': 0.5379206298394241, 'Total loss': 0.5379206298394241}
2022-12-05 22:51:29,192 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:29,192 INFO:     Epoch: 70
2022-12-05 22:51:29,897 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5258741710673679, 'Total loss': 0.5258741710673679} | train loss {'Reaction outcome loss': 0.5441315323717681, 'Total loss': 0.5441315323717681}
2022-12-05 22:51:29,897 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:29,897 INFO:     Epoch: 71
2022-12-05 22:51:30,607 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5445312573151155, 'Total loss': 0.5445312573151155} | train loss {'Reaction outcome loss': 0.5383936866980257, 'Total loss': 0.5383936866980257}
2022-12-05 22:51:30,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:30,607 INFO:     Epoch: 72
2022-12-05 22:51:31,314 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5453605624762449, 'Total loss': 0.5453605624762449} | train loss {'Reaction outcome loss': 0.54640482731073, 'Total loss': 0.54640482731073}
2022-12-05 22:51:31,314 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:31,314 INFO:     Epoch: 73
2022-12-05 22:51:32,019 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5412485762075945, 'Total loss': 0.5412485762075945} | train loss {'Reaction outcome loss': 0.5400225181087308, 'Total loss': 0.5400225181087308}
2022-12-05 22:51:32,019 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:32,019 INFO:     Epoch: 74
2022-12-05 22:51:32,726 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5407417091456327, 'Total loss': 0.5407417091456327} | train loss {'Reaction outcome loss': 0.5472280809029877, 'Total loss': 0.5472280809029877}
2022-12-05 22:51:32,726 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:32,726 INFO:     Epoch: 75
2022-12-05 22:51:33,439 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5243213281712749, 'Total loss': 0.5243213281712749} | train loss {'Reaction outcome loss': 0.5466965433315709, 'Total loss': 0.5466965433315709}
2022-12-05 22:51:33,439 INFO:     Found new best model at epoch 75
2022-12-05 22:51:33,439 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:33,439 INFO:     Epoch: 76
2022-12-05 22:51:34,144 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5618330538272858, 'Total loss': 0.5618330538272858} | train loss {'Reaction outcome loss': 0.5424237790016028, 'Total loss': 0.5424237790016028}
2022-12-05 22:51:34,144 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:34,144 INFO:     Epoch: 77
2022-12-05 22:51:34,851 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5347123135897246, 'Total loss': 0.5347123135897246} | train loss {'Reaction outcome loss': 0.533574167301554, 'Total loss': 0.533574167301554}
2022-12-05 22:51:34,852 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:34,852 INFO:     Epoch: 78
2022-12-05 22:51:35,557 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6551165154034441, 'Total loss': 0.6551165154034441} | train loss {'Reaction outcome loss': 0.5459311971297631, 'Total loss': 0.5459311971297631}
2022-12-05 22:51:35,558 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:35,558 INFO:     Epoch: 79
2022-12-05 22:51:36,263 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5318059636787935, 'Total loss': 0.5318059636787935} | train loss {'Reaction outcome loss': 0.5428683077445186, 'Total loss': 0.5428683077445186}
2022-12-05 22:51:36,263 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:36,263 INFO:     Epoch: 80
2022-12-05 22:51:36,970 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5268497206270695, 'Total loss': 0.5268497206270695} | train loss {'Reaction outcome loss': 0.5434046781618103, 'Total loss': 0.5434046781618103}
2022-12-05 22:51:36,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:36,971 INFO:     Epoch: 81
2022-12-05 22:51:37,679 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6012941409241069, 'Total loss': 0.6012941409241069} | train loss {'Reaction outcome loss': 0.5306617686080064, 'Total loss': 0.5306617686080064}
2022-12-05 22:51:37,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:37,679 INFO:     Epoch: 82
2022-12-05 22:51:38,387 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5433505089445547, 'Total loss': 0.5433505089445547} | train loss {'Reaction outcome loss': 0.5455056893439428, 'Total loss': 0.5455056893439428}
2022-12-05 22:51:38,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:38,387 INFO:     Epoch: 83
2022-12-05 22:51:39,095 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5448308617553927, 'Total loss': 0.5448308617553927} | train loss {'Reaction outcome loss': 0.5495297150301789, 'Total loss': 0.5495297150301789}
2022-12-05 22:51:39,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:39,095 INFO:     Epoch: 84
2022-12-05 22:51:39,800 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5663019554181532, 'Total loss': 0.5663019554181532} | train loss {'Reaction outcome loss': 0.5402788682746501, 'Total loss': 0.5402788682746501}
2022-12-05 22:51:39,800 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:39,800 INFO:     Epoch: 85
2022-12-05 22:51:40,505 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.525767823511904, 'Total loss': 0.525767823511904} | train loss {'Reaction outcome loss': 0.5418746990230885, 'Total loss': 0.5418746990230885}
2022-12-05 22:51:40,505 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:40,505 INFO:     Epoch: 86
2022-12-05 22:51:41,214 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5754931291395967, 'Total loss': 0.5754931291395967} | train loss {'Reaction outcome loss': 0.5376725819019359, 'Total loss': 0.5376725819019359}
2022-12-05 22:51:41,214 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:41,214 INFO:     Epoch: 87
2022-12-05 22:51:41,920 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6363515759056265, 'Total loss': 0.6363515759056265} | train loss {'Reaction outcome loss': 0.5376563492091561, 'Total loss': 0.5376563492091561}
2022-12-05 22:51:41,920 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:41,920 INFO:     Epoch: 88
2022-12-05 22:51:42,629 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5491950769316066, 'Total loss': 0.5491950769316066} | train loss {'Reaction outcome loss': 0.5367298503613726, 'Total loss': 0.5367298503613726}
2022-12-05 22:51:42,629 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:42,629 INFO:     Epoch: 89
2022-12-05 22:51:43,333 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5348882322961633, 'Total loss': 0.5348882322961633} | train loss {'Reaction outcome loss': 0.5408284049405743, 'Total loss': 0.5408284049405743}
2022-12-05 22:51:43,333 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:43,334 INFO:     Epoch: 90
2022-12-05 22:51:44,039 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5556761534376577, 'Total loss': 0.5556761534376577} | train loss {'Reaction outcome loss': 0.5419241109116357, 'Total loss': 0.5419241109116357}
2022-12-05 22:51:44,039 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:44,039 INFO:     Epoch: 91
2022-12-05 22:51:44,748 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5399750159545378, 'Total loss': 0.5399750159545378} | train loss {'Reaction outcome loss': 0.5458821141526766, 'Total loss': 0.5458821141526766}
2022-12-05 22:51:44,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:44,748 INFO:     Epoch: 92
2022-12-05 22:51:45,456 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5542708824981343, 'Total loss': 0.5542708824981343} | train loss {'Reaction outcome loss': 0.5450850322178984, 'Total loss': 0.5450850322178984}
2022-12-05 22:51:45,457 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:45,457 INFO:     Epoch: 93
2022-12-05 22:51:46,167 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5745763321491805, 'Total loss': 0.5745763321491805} | train loss {'Reaction outcome loss': 0.5363550062785264, 'Total loss': 0.5363550062785264}
2022-12-05 22:51:46,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:46,168 INFO:     Epoch: 94
2022-12-05 22:51:46,875 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5495783916928552, 'Total loss': 0.5495783916928552} | train loss {'Reaction outcome loss': 0.5461563928286556, 'Total loss': 0.5461563928286556}
2022-12-05 22:51:46,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:46,876 INFO:     Epoch: 95
2022-12-05 22:51:47,581 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5470899187705733, 'Total loss': 0.5470899187705733} | train loss {'Reaction outcome loss': 0.5414459622667269, 'Total loss': 0.5414459622667269}
2022-12-05 22:51:47,582 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:47,582 INFO:     Epoch: 96
2022-12-05 22:51:48,294 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5329933098771356, 'Total loss': 0.5329933098771356} | train loss {'Reaction outcome loss': 0.5408515013181247, 'Total loss': 0.5408515013181247}
2022-12-05 22:51:48,295 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:48,295 INFO:     Epoch: 97
2022-12-05 22:51:49,006 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5554839057678526, 'Total loss': 0.5554839057678526} | train loss {'Reaction outcome loss': 0.5439948314717906, 'Total loss': 0.5439948314717906}
2022-12-05 22:51:49,006 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:49,006 INFO:     Epoch: 98
2022-12-05 22:51:49,711 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.545656172389334, 'Total loss': 0.545656172389334} | train loss {'Reaction outcome loss': 0.5369303109433486, 'Total loss': 0.5369303109433486}
2022-12-05 22:51:49,712 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:49,712 INFO:     Epoch: 99
2022-12-05 22:51:50,419 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5267036093229597, 'Total loss': 0.5267036093229597} | train loss {'Reaction outcome loss': 0.5479059612853565, 'Total loss': 0.5479059612853565}
2022-12-05 22:51:50,420 INFO:     Best model found after epoch 76 of 100.
2022-12-05 22:51:50,420 INFO:   Done with stage: TRAINING
2022-12-05 22:51:50,420 INFO:   Starting stage: EVALUATION
2022-12-05 22:51:50,543 INFO:   Done with stage: EVALUATION
2022-12-05 22:51:50,543 INFO:   Leaving out SEQ value Fold_9
2022-12-05 22:51:50,555 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:51:50,556 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:51:51,200 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:51:51,200 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:51:51,270 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:51:51,270 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:51:51,270 INFO:     No hyperparam tuning for this model
2022-12-05 22:51:51,270 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:51:51,270 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:51:51,271 INFO:     None feature selector for col prot
2022-12-05 22:51:51,271 INFO:     None feature selector for col prot
2022-12-05 22:51:51,271 INFO:     None feature selector for col prot
2022-12-05 22:51:51,272 INFO:     None feature selector for col chem
2022-12-05 22:51:51,272 INFO:     None feature selector for col chem
2022-12-05 22:51:51,272 INFO:     None feature selector for col chem
2022-12-05 22:51:51,272 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:51:51,272 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:51:51,274 INFO:     Number of params in model 215731
2022-12-05 22:51:51,277 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:51:51,277 INFO:   Starting stage: TRAINING
2022-12-05 22:51:51,335 INFO:     Val loss before train {'Reaction outcome loss': 1.025424675507979, 'Total loss': 1.025424675507979}
2022-12-05 22:51:51,335 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:51,335 INFO:     Epoch: 0
2022-12-05 22:51:52,040 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7425582883032885, 'Total loss': 0.7425582883032885} | train loss {'Reaction outcome loss': 0.7978058443951462, 'Total loss': 0.7978058443951462}
2022-12-05 22:51:52,041 INFO:     Found new best model at epoch 0
2022-12-05 22:51:52,041 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:52,041 INFO:     Epoch: 1
2022-12-05 22:51:52,748 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6751456619663672, 'Total loss': 0.6751456619663672} | train loss {'Reaction outcome loss': 0.6537740808206531, 'Total loss': 0.6537740808206531}
2022-12-05 22:51:52,748 INFO:     Found new best model at epoch 1
2022-12-05 22:51:52,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:52,749 INFO:     Epoch: 2
2022-12-05 22:51:53,457 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6706018596887589, 'Total loss': 0.6706018596887589} | train loss {'Reaction outcome loss': 0.6206815990841823, 'Total loss': 0.6206815990841823}
2022-12-05 22:51:53,457 INFO:     Found new best model at epoch 2
2022-12-05 22:51:53,458 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:53,458 INFO:     Epoch: 3
2022-12-05 22:51:54,162 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5709472921761599, 'Total loss': 0.5709472921761599} | train loss {'Reaction outcome loss': 0.602018912552822, 'Total loss': 0.602018912552822}
2022-12-05 22:51:54,162 INFO:     Found new best model at epoch 3
2022-12-05 22:51:54,163 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:54,163 INFO:     Epoch: 4
2022-12-05 22:51:54,869 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6257676035165787, 'Total loss': 0.6257676035165787} | train loss {'Reaction outcome loss': 0.5934952871519544, 'Total loss': 0.5934952871519544}
2022-12-05 22:51:54,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:54,869 INFO:     Epoch: 5
2022-12-05 22:51:55,579 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5758357772772963, 'Total loss': 0.5758357772772963} | train loss {'Reaction outcome loss': 0.5818055072867194, 'Total loss': 0.5818055072867194}
2022-12-05 22:51:55,580 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:55,580 INFO:     Epoch: 6
2022-12-05 22:51:56,289 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5701221667907455, 'Total loss': 0.5701221667907455} | train loss {'Reaction outcome loss': 0.5702207362362248, 'Total loss': 0.5702207362362248}
2022-12-05 22:51:56,289 INFO:     Found new best model at epoch 6
2022-12-05 22:51:56,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:56,290 INFO:     Epoch: 7
2022-12-05 22:51:56,996 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6297119002450596, 'Total loss': 0.6297119002450596} | train loss {'Reaction outcome loss': 0.5763377963531355, 'Total loss': 0.5763377963531355}
2022-12-05 22:51:56,996 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:56,996 INFO:     Epoch: 8
2022-12-05 22:51:57,701 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5720644352788274, 'Total loss': 0.5720644352788274} | train loss {'Reaction outcome loss': 0.5738203096003668, 'Total loss': 0.5738203096003668}
2022-12-05 22:51:57,701 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:57,702 INFO:     Epoch: 9
2022-12-05 22:51:58,407 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5226888135075569, 'Total loss': 0.5226888135075569} | train loss {'Reaction outcome loss': 0.5524082080676005, 'Total loss': 0.5524082080676005}
2022-12-05 22:51:58,407 INFO:     Found new best model at epoch 9
2022-12-05 22:51:58,408 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:58,408 INFO:     Epoch: 10
2022-12-05 22:51:59,113 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5723734653808854, 'Total loss': 0.5723734653808854} | train loss {'Reaction outcome loss': 0.5600498087312046, 'Total loss': 0.5600498087312046}
2022-12-05 22:51:59,114 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:59,114 INFO:     Epoch: 11
2022-12-05 22:51:59,826 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5576300038532778, 'Total loss': 0.5576300038532778} | train loss {'Reaction outcome loss': 0.5584556230528634, 'Total loss': 0.5584556230528634}
2022-12-05 22:51:59,826 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:51:59,827 INFO:     Epoch: 12
2022-12-05 22:52:00,536 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5411112051118504, 'Total loss': 0.5411112051118504} | train loss {'Reaction outcome loss': 0.5613989626709749, 'Total loss': 0.5613989626709749}
2022-12-05 22:52:00,537 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:00,537 INFO:     Epoch: 13
2022-12-05 22:52:01,242 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5252093923362818, 'Total loss': 0.5252093923362818} | train loss {'Reaction outcome loss': 0.5553215301109229, 'Total loss': 0.5553215301109229}
2022-12-05 22:52:01,242 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:01,243 INFO:     Epoch: 14
2022-12-05 22:52:01,947 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5521062050353397, 'Total loss': 0.5521062050353397} | train loss {'Reaction outcome loss': 0.5688605800813992, 'Total loss': 0.5688605800813992}
2022-12-05 22:52:01,947 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:01,947 INFO:     Epoch: 15
2022-12-05 22:52:02,654 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5287115912545811, 'Total loss': 0.5287115912545811} | train loss {'Reaction outcome loss': 0.5541690811213211, 'Total loss': 0.5541690811213211}
2022-12-05 22:52:02,654 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:02,655 INFO:     Epoch: 16
2022-12-05 22:52:03,365 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5426557179201733, 'Total loss': 0.5426557179201733} | train loss {'Reaction outcome loss': 0.5541503009525871, 'Total loss': 0.5541503009525871}
2022-12-05 22:52:03,365 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:03,365 INFO:     Epoch: 17
2022-12-05 22:52:04,070 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5447799246758223, 'Total loss': 0.5447799246758223} | train loss {'Reaction outcome loss': 0.5381798440220988, 'Total loss': 0.5381798440220988}
2022-12-05 22:52:04,070 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:04,070 INFO:     Epoch: 18
2022-12-05 22:52:04,777 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5346395386890932, 'Total loss': 0.5346395386890932} | train loss {'Reaction outcome loss': 0.5362899187002105, 'Total loss': 0.5362899187002105}
2022-12-05 22:52:04,777 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:04,778 INFO:     Epoch: 19
2022-12-05 22:52:05,487 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5588048208843578, 'Total loss': 0.5588048208843578} | train loss {'Reaction outcome loss': 0.5485493766996059, 'Total loss': 0.5485493766996059}
2022-12-05 22:52:05,487 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:05,487 INFO:     Epoch: 20
2022-12-05 22:52:06,195 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5171587863429026, 'Total loss': 0.5171587863429026} | train loss {'Reaction outcome loss': 0.5523913791667112, 'Total loss': 0.5523913791667112}
2022-12-05 22:52:06,195 INFO:     Found new best model at epoch 20
2022-12-05 22:52:06,196 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:06,196 INFO:     Epoch: 21
2022-12-05 22:52:06,902 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.554819184270772, 'Total loss': 0.554819184270772} | train loss {'Reaction outcome loss': 0.5233145325410704, 'Total loss': 0.5233145325410704}
2022-12-05 22:52:06,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:06,902 INFO:     Epoch: 22
2022-12-05 22:52:07,608 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5683075941421769, 'Total loss': 0.5683075941421769} | train loss {'Reaction outcome loss': 0.5413597102469279, 'Total loss': 0.5413597102469279}
2022-12-05 22:52:07,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:07,608 INFO:     Epoch: 23
2022-12-05 22:52:08,319 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5124767192385413, 'Total loss': 0.5124767192385413} | train loss {'Reaction outcome loss': 0.5335721132846979, 'Total loss': 0.5335721132846979}
2022-12-05 22:52:08,319 INFO:     Found new best model at epoch 23
2022-12-05 22:52:08,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:08,320 INFO:     Epoch: 24
2022-12-05 22:52:09,030 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5490689250555906, 'Total loss': 0.5490689250555906} | train loss {'Reaction outcome loss': 0.5266179903617755, 'Total loss': 0.5266179903617755}
2022-12-05 22:52:09,030 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:09,030 INFO:     Epoch: 25
2022-12-05 22:52:09,737 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5068825578147714, 'Total loss': 0.5068825578147714} | train loss {'Reaction outcome loss': 0.5308080438056938, 'Total loss': 0.5308080438056938}
2022-12-05 22:52:09,737 INFO:     Found new best model at epoch 25
2022-12-05 22:52:09,737 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:09,737 INFO:     Epoch: 26
2022-12-05 22:52:10,451 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.510865178975192, 'Total loss': 0.510865178975192} | train loss {'Reaction outcome loss': 0.5301831914225088, 'Total loss': 0.5301831914225088}
2022-12-05 22:52:10,451 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:10,451 INFO:     Epoch: 27
2022-12-05 22:52:11,162 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5420244380154393, 'Total loss': 0.5420244380154393} | train loss {'Reaction outcome loss': 0.5253743361003003, 'Total loss': 0.5253743361003003}
2022-12-05 22:52:11,162 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:11,162 INFO:     Epoch: 28
2022-12-05 22:52:11,868 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5081171149557288, 'Total loss': 0.5081171149557288} | train loss {'Reaction outcome loss': 0.5277297260496117, 'Total loss': 0.5277297260496117}
2022-12-05 22:52:11,868 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:11,869 INFO:     Epoch: 29
2022-12-05 22:52:12,581 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5735797231847589, 'Total loss': 0.5735797231847589} | train loss {'Reaction outcome loss': 0.5169793791495837, 'Total loss': 0.5169793791495837}
2022-12-05 22:52:12,581 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:12,581 INFO:     Epoch: 30
2022-12-05 22:52:13,288 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4887331043454734, 'Total loss': 0.4887331043454734} | train loss {'Reaction outcome loss': 0.535674681004725, 'Total loss': 0.535674681004725}
2022-12-05 22:52:13,288 INFO:     Found new best model at epoch 30
2022-12-05 22:52:13,288 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:13,289 INFO:     Epoch: 31
2022-12-05 22:52:13,998 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5151697261766954, 'Total loss': 0.5151697261766954} | train loss {'Reaction outcome loss': 0.5288739535610686, 'Total loss': 0.5288739535610686}
2022-12-05 22:52:13,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:13,999 INFO:     Epoch: 32
2022-12-05 22:52:14,704 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5061954507096247, 'Total loss': 0.5061954507096247} | train loss {'Reaction outcome loss': 0.5220467550774305, 'Total loss': 0.5220467550774305}
2022-12-05 22:52:14,704 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:14,704 INFO:     Epoch: 33
2022-12-05 22:52:15,411 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5285455869002775, 'Total loss': 0.5285455869002775} | train loss {'Reaction outcome loss': 0.5143976726753992, 'Total loss': 0.5143976726753992}
2022-12-05 22:52:15,412 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:15,412 INFO:     Epoch: 34
2022-12-05 22:52:16,119 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5620108063925396, 'Total loss': 0.5620108063925396} | train loss {'Reaction outcome loss': 0.5166759719612145, 'Total loss': 0.5166759719612145}
2022-12-05 22:52:16,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:16,119 INFO:     Epoch: 35
2022-12-05 22:52:16,828 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.6572831909764897, 'Total loss': 0.6572831909764897} | train loss {'Reaction outcome loss': 0.5312244219456607, 'Total loss': 0.5312244219456607}
2022-12-05 22:52:16,828 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:16,828 INFO:     Epoch: 36
2022-12-05 22:52:17,537 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5673571572723713, 'Total loss': 0.5673571572723713} | train loss {'Reaction outcome loss': 0.5643604307884147, 'Total loss': 0.5643604307884147}
2022-12-05 22:52:17,537 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:17,537 INFO:     Epoch: 37
2022-12-05 22:52:18,244 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5396383127028291, 'Total loss': 0.5396383127028291} | train loss {'Reaction outcome loss': 0.5287545837974741, 'Total loss': 0.5287545837974741}
2022-12-05 22:52:18,244 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:18,244 INFO:     Epoch: 38
2022-12-05 22:52:18,954 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5290320664644241, 'Total loss': 0.5290320664644241} | train loss {'Reaction outcome loss': 0.5145683915312835, 'Total loss': 0.5145683915312835}
2022-12-05 22:52:18,955 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:18,955 INFO:     Epoch: 39
2022-12-05 22:52:19,667 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5277204428884116, 'Total loss': 0.5277204428884116} | train loss {'Reaction outcome loss': 0.5128937391375723, 'Total loss': 0.5128937391375723}
2022-12-05 22:52:19,667 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:19,667 INFO:     Epoch: 40
2022-12-05 22:52:20,372 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5574183985590935, 'Total loss': 0.5574183985590935} | train loss {'Reaction outcome loss': 0.5190625322251184, 'Total loss': 0.5190625322251184}
2022-12-05 22:52:20,372 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:20,372 INFO:     Epoch: 41
2022-12-05 22:52:21,078 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5203101255676963, 'Total loss': 0.5203101255676963} | train loss {'Reaction outcome loss': 0.5140372709736891, 'Total loss': 0.5140372709736891}
2022-12-05 22:52:21,079 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:21,079 INFO:     Epoch: 42
2022-12-05 22:52:21,787 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5433795011856339, 'Total loss': 0.5433795011856339} | train loss {'Reaction outcome loss': 0.5251595984827652, 'Total loss': 0.5251595984827652}
2022-12-05 22:52:21,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:21,788 INFO:     Epoch: 43
2022-12-05 22:52:22,497 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4962700077078559, 'Total loss': 0.4962700077078559} | train loss {'Reaction outcome loss': 0.5207743528280181, 'Total loss': 0.5207743528280181}
2022-12-05 22:52:22,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:22,497 INFO:     Epoch: 44
2022-12-05 22:52:23,205 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49803986332633277, 'Total loss': 0.49803986332633277} | train loss {'Reaction outcome loss': 0.5191118086231985, 'Total loss': 0.5191118086231985}
2022-12-05 22:52:23,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:23,206 INFO:     Epoch: 45
2022-12-05 22:52:23,911 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5209739777174863, 'Total loss': 0.5209739777174863} | train loss {'Reaction outcome loss': 0.516519995666437, 'Total loss': 0.516519995666437}
2022-12-05 22:52:23,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:23,911 INFO:     Epoch: 46
2022-12-05 22:52:24,618 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.535928107120774, 'Total loss': 0.535928107120774} | train loss {'Reaction outcome loss': 0.516471030077471, 'Total loss': 0.516471030077471}
2022-12-05 22:52:24,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:24,618 INFO:     Epoch: 47
2022-12-05 22:52:25,328 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5291613787412643, 'Total loss': 0.5291613787412643} | train loss {'Reaction outcome loss': 0.5228463516906205, 'Total loss': 0.5228463516906205}
2022-12-05 22:52:25,328 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:25,328 INFO:     Epoch: 48
2022-12-05 22:52:26,033 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5424365248869766, 'Total loss': 0.5424365248869766} | train loss {'Reaction outcome loss': 0.5097064730609476, 'Total loss': 0.5097064730609476}
2022-12-05 22:52:26,033 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:26,033 INFO:     Epoch: 49
2022-12-05 22:52:26,744 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5549304214390841, 'Total loss': 0.5549304214390841} | train loss {'Reaction outcome loss': 0.5211523794210874, 'Total loss': 0.5211523794210874}
2022-12-05 22:52:26,744 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:26,744 INFO:     Epoch: 50
2022-12-05 22:52:27,451 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5426690615713596, 'Total loss': 0.5426690615713596} | train loss {'Reaction outcome loss': 0.5156486600275464, 'Total loss': 0.5156486600275464}
2022-12-05 22:52:27,451 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:27,451 INFO:     Epoch: 51
2022-12-05 22:52:28,165 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5284475142305548, 'Total loss': 0.5284475142305548} | train loss {'Reaction outcome loss': 0.5272730714396426, 'Total loss': 0.5272730714396426}
2022-12-05 22:52:28,165 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:28,165 INFO:     Epoch: 52
2022-12-05 22:52:28,870 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4878530925647779, 'Total loss': 0.4878530925647779} | train loss {'Reaction outcome loss': 0.5129082818262973, 'Total loss': 0.5129082818262973}
2022-12-05 22:52:28,870 INFO:     Found new best model at epoch 52
2022-12-05 22:52:28,871 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:28,871 INFO:     Epoch: 53
2022-12-05 22:52:29,579 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5459104844114997, 'Total loss': 0.5459104844114997} | train loss {'Reaction outcome loss': 0.5092786756242335, 'Total loss': 0.5092786756242335}
2022-12-05 22:52:29,579 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:29,579 INFO:     Epoch: 54
2022-12-05 22:52:30,289 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5466321804984049, 'Total loss': 0.5466321804984049} | train loss {'Reaction outcome loss': 0.5191530961286925, 'Total loss': 0.5191530961286925}
2022-12-05 22:52:30,289 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:30,289 INFO:     Epoch: 55
2022-12-05 22:52:31,001 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5277276323600248, 'Total loss': 0.5277276323600248} | train loss {'Reaction outcome loss': 0.526499459799002, 'Total loss': 0.526499459799002}
2022-12-05 22:52:31,001 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:31,001 INFO:     Epoch: 56
2022-12-05 22:52:31,712 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5140864645892923, 'Total loss': 0.5140864645892923} | train loss {'Reaction outcome loss': 0.5185864897452386, 'Total loss': 0.5185864897452386}
2022-12-05 22:52:31,713 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:31,714 INFO:     Epoch: 57
2022-12-05 22:52:32,423 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.497823377224532, 'Total loss': 0.497823377224532} | train loss {'Reaction outcome loss': 0.5176432938710881, 'Total loss': 0.5176432938710881}
2022-12-05 22:52:32,424 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:32,424 INFO:     Epoch: 58
2022-12-05 22:52:33,139 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5188424661755562, 'Total loss': 0.5188424661755562} | train loss {'Reaction outcome loss': 0.5174666707694289, 'Total loss': 0.5174666707694289}
2022-12-05 22:52:33,139 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:33,139 INFO:     Epoch: 59
2022-12-05 22:52:33,851 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5258106629956852, 'Total loss': 0.5258106629956852} | train loss {'Reaction outcome loss': 0.5288444035931638, 'Total loss': 0.5288444035931638}
2022-12-05 22:52:33,851 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:33,851 INFO:     Epoch: 60
2022-12-05 22:52:34,556 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5289948122067885, 'Total loss': 0.5289948122067885} | train loss {'Reaction outcome loss': 0.5303861221924484, 'Total loss': 0.5303861221924484}
2022-12-05 22:52:34,556 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:34,557 INFO:     Epoch: 61
2022-12-05 22:52:35,263 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5259855362502012, 'Total loss': 0.5259855362502012} | train loss {'Reaction outcome loss': 0.5235265915693059, 'Total loss': 0.5235265915693059}
2022-12-05 22:52:35,263 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:35,263 INFO:     Epoch: 62
2022-12-05 22:52:35,968 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5144687565890226, 'Total loss': 0.5144687565890226} | train loss {'Reaction outcome loss': 0.5105040761140677, 'Total loss': 0.5105040761140677}
2022-12-05 22:52:35,969 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:35,969 INFO:     Epoch: 63
2022-12-05 22:52:36,675 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5248505229299719, 'Total loss': 0.5248505229299719} | train loss {'Reaction outcome loss': 0.5281775217910527, 'Total loss': 0.5281775217910527}
2022-12-05 22:52:36,675 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:36,675 INFO:     Epoch: 64
2022-12-05 22:52:37,384 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5465032112869349, 'Total loss': 0.5465032112869349} | train loss {'Reaction outcome loss': 0.5244321321789552, 'Total loss': 0.5244321321789552}
2022-12-05 22:52:37,384 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:37,385 INFO:     Epoch: 65
2022-12-05 22:52:38,091 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.504502264613455, 'Total loss': 0.504502264613455} | train loss {'Reaction outcome loss': 0.525321373633045, 'Total loss': 0.525321373633045}
2022-12-05 22:52:38,091 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:38,091 INFO:     Epoch: 66
2022-12-05 22:52:38,798 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.50915854153308, 'Total loss': 0.50915854153308} | train loss {'Reaction outcome loss': 0.5199812148746691, 'Total loss': 0.5199812148746691}
2022-12-05 22:52:38,798 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:38,799 INFO:     Epoch: 67
2022-12-05 22:52:39,506 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4977852502329783, 'Total loss': 0.4977852502329783} | train loss {'Reaction outcome loss': 0.5173759312644178, 'Total loss': 0.5173759312644178}
2022-12-05 22:52:39,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:39,506 INFO:     Epoch: 68
2022-12-05 22:52:40,213 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5227732356976379, 'Total loss': 0.5227732356976379} | train loss {'Reaction outcome loss': 0.5197191492857992, 'Total loss': 0.5197191492857992}
2022-12-05 22:52:40,213 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:40,213 INFO:     Epoch: 69
2022-12-05 22:52:40,930 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49451127208091994, 'Total loss': 0.49451127208091994} | train loss {'Reaction outcome loss': 0.518712649581886, 'Total loss': 0.518712649581886}
2022-12-05 22:52:40,931 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:40,931 INFO:     Epoch: 70
2022-12-05 22:52:41,643 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5044958638873968, 'Total loss': 0.5044958638873968} | train loss {'Reaction outcome loss': 0.5153104538844544, 'Total loss': 0.5153104538844544}
2022-12-05 22:52:41,643 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:41,643 INFO:     Epoch: 71
2022-12-05 22:52:42,352 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5226010930809107, 'Total loss': 0.5226010930809107} | train loss {'Reaction outcome loss': 0.5089334172879153, 'Total loss': 0.5089334172879153}
2022-12-05 22:52:42,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:42,352 INFO:     Epoch: 72
2022-12-05 22:52:43,060 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5456104773012075, 'Total loss': 0.5456104773012075} | train loss {'Reaction outcome loss': 0.5155407846094626, 'Total loss': 0.5155407846094626}
2022-12-05 22:52:43,060 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:43,060 INFO:     Epoch: 73
2022-12-05 22:52:43,769 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.516893784430894, 'Total loss': 0.516893784430894} | train loss {'Reaction outcome loss': 0.5198904947954633, 'Total loss': 0.5198904947954633}
2022-12-05 22:52:43,769 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:43,769 INFO:     Epoch: 74
2022-12-05 22:52:44,474 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5246938013217666, 'Total loss': 0.5246938013217666} | train loss {'Reaction outcome loss': 0.5195648327530155, 'Total loss': 0.5195648327530155}
2022-12-05 22:52:44,474 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:44,474 INFO:     Epoch: 75
2022-12-05 22:52:45,179 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.509736992418766, 'Total loss': 0.509736992418766} | train loss {'Reaction outcome loss': 0.5255667749256921, 'Total loss': 0.5255667749256921}
2022-12-05 22:52:45,180 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:45,180 INFO:     Epoch: 76
2022-12-05 22:52:45,889 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5321936214512045, 'Total loss': 0.5321936214512045} | train loss {'Reaction outcome loss': 0.519200017331696, 'Total loss': 0.519200017331696}
2022-12-05 22:52:45,889 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:45,889 INFO:     Epoch: 77
2022-12-05 22:52:46,595 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5231540050696243, 'Total loss': 0.5231540050696243} | train loss {'Reaction outcome loss': 0.5053227526335581, 'Total loss': 0.5053227526335581}
2022-12-05 22:52:46,596 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:46,596 INFO:     Epoch: 78
2022-12-05 22:52:47,302 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5015108944340185, 'Total loss': 0.5015108944340185} | train loss {'Reaction outcome loss': 0.515898177980894, 'Total loss': 0.515898177980894}
2022-12-05 22:52:47,302 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:47,302 INFO:     Epoch: 79
2022-12-05 22:52:48,011 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5272222835231911, 'Total loss': 0.5272222835231911} | train loss {'Reaction outcome loss': 0.5104449339482465, 'Total loss': 0.5104449339482465}
2022-12-05 22:52:48,011 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:48,011 INFO:     Epoch: 80
2022-12-05 22:52:48,718 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.514294387603348, 'Total loss': 0.514294387603348} | train loss {'Reaction outcome loss': 0.5237393037751619, 'Total loss': 0.5237393037751619}
2022-12-05 22:52:48,718 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:48,718 INFO:     Epoch: 81
2022-12-05 22:52:49,424 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5152405463159084, 'Total loss': 0.5152405463159084} | train loss {'Reaction outcome loss': 0.5088634202143683, 'Total loss': 0.5088634202143683}
2022-12-05 22:52:49,424 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:49,424 INFO:     Epoch: 82
2022-12-05 22:52:50,134 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5100061730905012, 'Total loss': 0.5100061730905012} | train loss {'Reaction outcome loss': 0.5098078344516863, 'Total loss': 0.5098078344516863}
2022-12-05 22:52:50,135 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:50,135 INFO:     Epoch: 83
2022-12-05 22:52:50,844 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5666312453421679, 'Total loss': 0.5666312453421679} | train loss {'Reaction outcome loss': 0.5182720043881219, 'Total loss': 0.5182720043881219}
2022-12-05 22:52:50,844 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:50,844 INFO:     Epoch: 84
2022-12-05 22:52:51,551 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5105232955379919, 'Total loss': 0.5105232955379919} | train loss {'Reaction outcome loss': 0.5167266466477622, 'Total loss': 0.5167266466477622}
2022-12-05 22:52:51,551 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:51,551 INFO:     Epoch: 85
2022-12-05 22:52:52,260 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5229957496578043, 'Total loss': 0.5229957496578043} | train loss {'Reaction outcome loss': 0.5201566196367265, 'Total loss': 0.5201566196367265}
2022-12-05 22:52:52,260 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:52,260 INFO:     Epoch: 86
2022-12-05 22:52:52,970 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5100921693850647, 'Total loss': 0.5100921693850647} | train loss {'Reaction outcome loss': 0.5096041157442005, 'Total loss': 0.5096041157442005}
2022-12-05 22:52:52,970 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:52,970 INFO:     Epoch: 87
2022-12-05 22:52:53,680 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5582855286245997, 'Total loss': 0.5582855286245997} | train loss {'Reaction outcome loss': 0.5145749700696844, 'Total loss': 0.5145749700696844}
2022-12-05 22:52:53,680 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:53,680 INFO:     Epoch: 88
2022-12-05 22:52:54,386 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5543296513232318, 'Total loss': 0.5543296513232318} | train loss {'Reaction outcome loss': 0.5231145953058232, 'Total loss': 0.5231145953058232}
2022-12-05 22:52:54,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:54,386 INFO:     Epoch: 89
2022-12-05 22:52:55,095 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5114815475588496, 'Total loss': 0.5114815475588496} | train loss {'Reaction outcome loss': 0.5193542289059337, 'Total loss': 0.5193542289059337}
2022-12-05 22:52:55,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:55,095 INFO:     Epoch: 90
2022-12-05 22:52:55,803 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5194347263737158, 'Total loss': 0.5194347263737158} | train loss {'Reaction outcome loss': 0.5186588900533282, 'Total loss': 0.5186588900533282}
2022-12-05 22:52:55,803 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:55,803 INFO:     Epoch: 91
2022-12-05 22:52:56,514 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5035140687091784, 'Total loss': 0.5035140687091784} | train loss {'Reaction outcome loss': 0.5259784800320985, 'Total loss': 0.5259784800320985}
2022-12-05 22:52:56,514 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:56,514 INFO:     Epoch: 92
2022-12-05 22:52:57,223 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4890183291651986, 'Total loss': 0.4890183291651986} | train loss {'Reaction outcome loss': 0.5140476822325213, 'Total loss': 0.5140476822325213}
2022-12-05 22:52:57,224 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:57,224 INFO:     Epoch: 93
2022-12-05 22:52:57,934 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.49872187101705506, 'Total loss': 0.49872187101705506} | train loss {'Reaction outcome loss': 0.5193666500842523, 'Total loss': 0.5193666500842523}
2022-12-05 22:52:57,934 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:57,934 INFO:     Epoch: 94
2022-12-05 22:52:58,642 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5238616659559987, 'Total loss': 0.5238616659559987} | train loss {'Reaction outcome loss': 0.5283847265397972, 'Total loss': 0.5283847265397972}
2022-12-05 22:52:58,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:58,642 INFO:     Epoch: 95
2022-12-05 22:52:59,348 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5007307089187882, 'Total loss': 0.5007307089187882} | train loss {'Reaction outcome loss': 0.5177185805702982, 'Total loss': 0.5177185805702982}
2022-12-05 22:52:59,348 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:52:59,348 INFO:     Epoch: 96
2022-12-05 22:53:00,055 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5001156750050458, 'Total loss': 0.5001156750050458} | train loss {'Reaction outcome loss': 0.520964346976898, 'Total loss': 0.520964346976898}
2022-12-05 22:53:00,055 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:00,055 INFO:     Epoch: 97
2022-12-05 22:53:00,761 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5579702766104178, 'Total loss': 0.5579702766104178} | train loss {'Reaction outcome loss': 0.5192712506784601, 'Total loss': 0.5192712506784601}
2022-12-05 22:53:00,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:00,761 INFO:     Epoch: 98
2022-12-05 22:53:01,470 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5189026533202692, 'Total loss': 0.5189026533202692} | train loss {'Reaction outcome loss': 0.519406605214974, 'Total loss': 0.519406605214974}
2022-12-05 22:53:01,470 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:01,470 INFO:     Epoch: 99
2022-12-05 22:53:02,177 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4919755065982992, 'Total loss': 0.4919755065982992} | train loss {'Reaction outcome loss': 0.5075356369679757, 'Total loss': 0.5075356369679757}
2022-12-05 22:53:02,177 INFO:     Best model found after epoch 53 of 100.
2022-12-05 22:53:02,177 INFO:   Done with stage: TRAINING
2022-12-05 22:53:02,177 INFO:   Starting stage: EVALUATION
2022-12-05 22:53:02,301 INFO:   Done with stage: EVALUATION
2022-12-05 22:53:02,309 INFO:   Leaving out SEQ value Fold_0
2022-12-05 22:53:02,322 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 22:53:02,322 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:53:02,955 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:53:02,956 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:53:03,025 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:53:03,025 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:53:03,025 INFO:     No hyperparam tuning for this model
2022-12-05 22:53:03,025 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:53:03,025 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:53:03,026 INFO:     None feature selector for col prot
2022-12-05 22:53:03,026 INFO:     None feature selector for col prot
2022-12-05 22:53:03,026 INFO:     None feature selector for col prot
2022-12-05 22:53:03,027 INFO:     None feature selector for col chem
2022-12-05 22:53:03,027 INFO:     None feature selector for col chem
2022-12-05 22:53:03,027 INFO:     None feature selector for col chem
2022-12-05 22:53:03,027 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:53:03,027 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:53:03,029 INFO:     Number of params in model 215731
2022-12-05 22:53:03,032 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:53:03,032 INFO:   Starting stage: TRAINING
2022-12-05 22:53:03,088 INFO:     Val loss before train {'Reaction outcome loss': 0.9818605475647505, 'Total loss': 0.9818605475647505}
2022-12-05 22:53:03,089 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:03,089 INFO:     Epoch: 0
2022-12-05 22:53:03,787 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6448121403538903, 'Total loss': 0.6448121403538903} | train loss {'Reaction outcome loss': 0.8129700786537595, 'Total loss': 0.8129700786537595}
2022-12-05 22:53:03,787 INFO:     Found new best model at epoch 0
2022-12-05 22:53:03,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:03,788 INFO:     Epoch: 1
2022-12-05 22:53:04,481 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5994973452978356, 'Total loss': 0.5994973452978356} | train loss {'Reaction outcome loss': 0.6728270909913774, 'Total loss': 0.6728270909913774}
2022-12-05 22:53:04,481 INFO:     Found new best model at epoch 1
2022-12-05 22:53:04,482 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:04,482 INFO:     Epoch: 2
2022-12-05 22:53:05,177 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5621117031158402, 'Total loss': 0.5621117031158402} | train loss {'Reaction outcome loss': 0.6150255525798954, 'Total loss': 0.6150255525798954}
2022-12-05 22:53:05,177 INFO:     Found new best model at epoch 2
2022-12-05 22:53:05,178 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:05,178 INFO:     Epoch: 3
2022-12-05 22:53:05,872 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.534292142751605, 'Total loss': 0.534292142751605} | train loss {'Reaction outcome loss': 0.5889921193260225, 'Total loss': 0.5889921193260225}
2022-12-05 22:53:05,872 INFO:     Found new best model at epoch 3
2022-12-05 22:53:05,873 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:05,873 INFO:     Epoch: 4
2022-12-05 22:53:06,567 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5369083985339763, 'Total loss': 0.5369083985339763} | train loss {'Reaction outcome loss': 0.5788058582156774, 'Total loss': 0.5788058582156774}
2022-12-05 22:53:06,567 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:06,567 INFO:     Epoch: 5
2022-12-05 22:53:07,265 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5334225206874138, 'Total loss': 0.5334225206874138} | train loss {'Reaction outcome loss': 0.5662639123299484, 'Total loss': 0.5662639123299484}
2022-12-05 22:53:07,265 INFO:     Found new best model at epoch 5
2022-12-05 22:53:07,265 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:07,266 INFO:     Epoch: 6
2022-12-05 22:53:07,962 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5238330537496612, 'Total loss': 0.5238330537496612} | train loss {'Reaction outcome loss': 0.5628443235232506, 'Total loss': 0.5628443235232506}
2022-12-05 22:53:07,962 INFO:     Found new best model at epoch 6
2022-12-05 22:53:07,963 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:07,963 INFO:     Epoch: 7
2022-12-05 22:53:08,659 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5372805006282274, 'Total loss': 0.5372805006282274} | train loss {'Reaction outcome loss': 0.5633550385020888, 'Total loss': 0.5633550385020888}
2022-12-05 22:53:08,659 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:08,660 INFO:     Epoch: 8
2022-12-05 22:53:09,360 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5156402421552081, 'Total loss': 0.5156402421552081} | train loss {'Reaction outcome loss': 0.5473901688929939, 'Total loss': 0.5473901688929939}
2022-12-05 22:53:09,360 INFO:     Found new best model at epoch 8
2022-12-05 22:53:09,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:09,361 INFO:     Epoch: 9
2022-12-05 22:53:10,056 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5269888514696166, 'Total loss': 0.5269888514696166} | train loss {'Reaction outcome loss': 0.5616526716530569, 'Total loss': 0.5616526716530569}
2022-12-05 22:53:10,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:10,056 INFO:     Epoch: 10
2022-12-05 22:53:10,753 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5516212769719058, 'Total loss': 0.5516212769719058} | train loss {'Reaction outcome loss': 0.5434253743155993, 'Total loss': 0.5434253743155993}
2022-12-05 22:53:10,753 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:10,753 INFO:     Epoch: 11
2022-12-05 22:53:11,452 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5385423413542814, 'Total loss': 0.5385423413542814} | train loss {'Reaction outcome loss': 0.5524727497326494, 'Total loss': 0.5524727497326494}
2022-12-05 22:53:11,452 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:11,452 INFO:     Epoch: 12
2022-12-05 22:53:12,155 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5020039857820023, 'Total loss': 0.5020039857820023} | train loss {'Reaction outcome loss': 0.5492308632213883, 'Total loss': 0.5492308632213883}
2022-12-05 22:53:12,155 INFO:     Found new best model at epoch 12
2022-12-05 22:53:12,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:12,156 INFO:     Epoch: 13
2022-12-05 22:53:12,855 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5251194391139719, 'Total loss': 0.5251194391139719} | train loss {'Reaction outcome loss': 0.5513199507699582, 'Total loss': 0.5513199507699582}
2022-12-05 22:53:12,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:12,856 INFO:     Epoch: 14
2022-12-05 22:53:13,554 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5026242400324622, 'Total loss': 0.5026242400324622} | train loss {'Reaction outcome loss': 0.5395672526133894, 'Total loss': 0.5395672526133894}
2022-12-05 22:53:13,554 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:13,554 INFO:     Epoch: 15
2022-12-05 22:53:14,255 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5281022904917251, 'Total loss': 0.5281022904917251} | train loss {'Reaction outcome loss': 0.5365628383348509, 'Total loss': 0.5365628383348509}
2022-12-05 22:53:14,255 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:14,255 INFO:     Epoch: 16
2022-12-05 22:53:14,951 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5090816284334937, 'Total loss': 0.5090816284334937} | train loss {'Reaction outcome loss': 0.5405785835696837, 'Total loss': 0.5405785835696837}
2022-12-05 22:53:14,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:14,951 INFO:     Epoch: 17
2022-12-05 22:53:15,645 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5329111045183137, 'Total loss': 0.5329111045183137} | train loss {'Reaction outcome loss': 0.5339305502029112, 'Total loss': 0.5339305502029112}
2022-12-05 22:53:15,645 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:15,645 INFO:     Epoch: 18
2022-12-05 22:53:16,339 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.509109307167142, 'Total loss': 0.509109307167142} | train loss {'Reaction outcome loss': 0.5389178959430491, 'Total loss': 0.5389178959430491}
2022-12-05 22:53:16,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:16,340 INFO:     Epoch: 19
2022-12-05 22:53:17,033 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5220508242762366, 'Total loss': 0.5220508242762366} | train loss {'Reaction outcome loss': 0.5284021226344285, 'Total loss': 0.5284021226344285}
2022-12-05 22:53:17,033 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:17,033 INFO:     Epoch: 20
2022-12-05 22:53:17,727 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.522681419932565, 'Total loss': 0.522681419932565} | train loss {'Reaction outcome loss': 0.5389589263210571, 'Total loss': 0.5389589263210571}
2022-12-05 22:53:17,727 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:17,727 INFO:     Epoch: 21
2022-12-05 22:53:18,421 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5022777104100515, 'Total loss': 0.5022777104100515} | train loss {'Reaction outcome loss': 0.5301961074640722, 'Total loss': 0.5301961074640722}
2022-12-05 22:53:18,421 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:18,421 INFO:     Epoch: 22
2022-12-05 22:53:19,117 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.520104237767153, 'Total loss': 0.520104237767153} | train loss {'Reaction outcome loss': 0.5309475767636986, 'Total loss': 0.5309475767636986}
2022-12-05 22:53:19,117 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:19,117 INFO:     Epoch: 23
2022-12-05 22:53:19,816 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5005340499933376, 'Total loss': 0.5005340499933376} | train loss {'Reaction outcome loss': 0.5306545295465139, 'Total loss': 0.5306545295465139}
2022-12-05 22:53:19,816 INFO:     Found new best model at epoch 23
2022-12-05 22:53:19,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:19,817 INFO:     Epoch: 24
2022-12-05 22:53:20,511 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5123899884002153, 'Total loss': 0.5123899884002153} | train loss {'Reaction outcome loss': 0.5324539939255871, 'Total loss': 0.5324539939255871}
2022-12-05 22:53:20,511 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:20,511 INFO:     Epoch: 25
2022-12-05 22:53:21,204 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5293264707853628, 'Total loss': 0.5293264707853628} | train loss {'Reaction outcome loss': 0.5336094626796589, 'Total loss': 0.5336094626796589}
2022-12-05 22:53:21,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:21,205 INFO:     Epoch: 26
2022-12-05 22:53:21,898 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5280932506849599, 'Total loss': 0.5280932506849599} | train loss {'Reaction outcome loss': 0.5298980896365005, 'Total loss': 0.5298980896365005}
2022-12-05 22:53:21,899 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:21,899 INFO:     Epoch: 27
2022-12-05 22:53:22,596 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5121989624444828, 'Total loss': 0.5121989624444828} | train loss {'Reaction outcome loss': 0.5334686683529198, 'Total loss': 0.5334686683529198}
2022-12-05 22:53:22,596 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:22,596 INFO:     Epoch: 28
2022-12-05 22:53:23,289 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5196996982707534, 'Total loss': 0.5196996982707534} | train loss {'Reaction outcome loss': 0.5313651585652505, 'Total loss': 0.5313651585652505}
2022-12-05 22:53:23,289 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:23,289 INFO:     Epoch: 29
2022-12-05 22:53:23,986 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5197231339853864, 'Total loss': 0.5197231339853864} | train loss {'Reaction outcome loss': 0.5326589115975816, 'Total loss': 0.5326589115975816}
2022-12-05 22:53:23,986 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:23,986 INFO:     Epoch: 30
2022-12-05 22:53:24,687 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4923435324846312, 'Total loss': 0.4923435324846312} | train loss {'Reaction outcome loss': 0.5300483951965967, 'Total loss': 0.5300483951965967}
2022-12-05 22:53:24,687 INFO:     Found new best model at epoch 30
2022-12-05 22:53:24,687 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:24,687 INFO:     Epoch: 31
2022-12-05 22:53:25,384 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5473988593317741, 'Total loss': 0.5473988593317741} | train loss {'Reaction outcome loss': 0.5354755750776808, 'Total loss': 0.5354755750776808}
2022-12-05 22:53:25,384 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:25,384 INFO:     Epoch: 32
2022-12-05 22:53:26,080 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4963122318650401, 'Total loss': 0.4963122318650401} | train loss {'Reaction outcome loss': 0.5309800851492235, 'Total loss': 0.5309800851492235}
2022-12-05 22:53:26,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:26,080 INFO:     Epoch: 33
2022-12-05 22:53:26,775 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5341872697652772, 'Total loss': 0.5341872697652772} | train loss {'Reaction outcome loss': 0.5337023361597533, 'Total loss': 0.5337023361597533}
2022-12-05 22:53:26,775 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:26,776 INFO:     Epoch: 34
2022-12-05 22:53:27,473 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5014084043890931, 'Total loss': 0.5014084043890931} | train loss {'Reaction outcome loss': 0.5309271204741404, 'Total loss': 0.5309271204741404}
2022-12-05 22:53:27,473 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:27,473 INFO:     Epoch: 35
2022-12-05 22:53:28,168 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5161781491235246, 'Total loss': 0.5161781491235246} | train loss {'Reaction outcome loss': 0.5296983455802188, 'Total loss': 0.5296983455802188}
2022-12-05 22:53:28,169 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:28,169 INFO:     Epoch: 36
2022-12-05 22:53:28,862 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5150930541892385, 'Total loss': 0.5150930541892385} | train loss {'Reaction outcome loss': 0.5256592655255471, 'Total loss': 0.5256592655255471}
2022-12-05 22:53:28,862 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:28,862 INFO:     Epoch: 37
2022-12-05 22:53:29,557 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.565595282371654, 'Total loss': 0.565595282371654} | train loss {'Reaction outcome loss': 0.5318827394840648, 'Total loss': 0.5318827394840648}
2022-12-05 22:53:29,557 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:29,557 INFO:     Epoch: 38
2022-12-05 22:53:30,249 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5137243520381839, 'Total loss': 0.5137243520381839} | train loss {'Reaction outcome loss': 0.5343039511039914, 'Total loss': 0.5343039511039914}
2022-12-05 22:53:30,249 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:30,249 INFO:     Epoch: 39
2022-12-05 22:53:30,943 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5152761326279751, 'Total loss': 0.5152761326279751} | train loss {'Reaction outcome loss': 0.536432043024542, 'Total loss': 0.536432043024542}
2022-12-05 22:53:30,943 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:30,943 INFO:     Epoch: 40
2022-12-05 22:53:31,633 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4887572783370351, 'Total loss': 0.4887572783370351} | train loss {'Reaction outcome loss': 0.5297151151814579, 'Total loss': 0.5297151151814579}
2022-12-05 22:53:31,633 INFO:     Found new best model at epoch 40
2022-12-05 22:53:31,634 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:31,634 INFO:     Epoch: 41
2022-12-05 22:53:32,328 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5066328173459962, 'Total loss': 0.5066328173459962} | train loss {'Reaction outcome loss': 0.5328420663919345, 'Total loss': 0.5328420663919345}
2022-12-05 22:53:32,328 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:32,328 INFO:     Epoch: 42
2022-12-05 22:53:33,021 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5204295016998468, 'Total loss': 0.5204295016998468} | train loss {'Reaction outcome loss': 0.533942265091119, 'Total loss': 0.533942265091119}
2022-12-05 22:53:33,021 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:33,021 INFO:     Epoch: 43
2022-12-05 22:53:33,709 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5074184367129969, 'Total loss': 0.5074184367129969} | train loss {'Reaction outcome loss': 0.527621433016204, 'Total loss': 0.527621433016204}
2022-12-05 22:53:33,710 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:33,710 INFO:     Epoch: 44
2022-12-05 22:53:34,399 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5177161506442136, 'Total loss': 0.5177161506442136} | train loss {'Reaction outcome loss': 0.5198938923853414, 'Total loss': 0.5198938923853414}
2022-12-05 22:53:34,400 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:34,400 INFO:     Epoch: 45
2022-12-05 22:53:35,089 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4958647160336029, 'Total loss': 0.4958647160336029} | train loss {'Reaction outcome loss': 0.5298508817766919, 'Total loss': 0.5298508817766919}
2022-12-05 22:53:35,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:35,090 INFO:     Epoch: 46
2022-12-05 22:53:35,780 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5445602161939754, 'Total loss': 0.5445602161939754} | train loss {'Reaction outcome loss': 0.5265575603202537, 'Total loss': 0.5265575603202537}
2022-12-05 22:53:35,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:35,780 INFO:     Epoch: 47
2022-12-05 22:53:36,475 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49318343920763147, 'Total loss': 0.49318343920763147} | train loss {'Reaction outcome loss': 0.5252680699705097, 'Total loss': 0.5252680699705097}
2022-12-05 22:53:36,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:36,475 INFO:     Epoch: 48
2022-12-05 22:53:37,164 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5247637667628222, 'Total loss': 0.5247637667628222} | train loss {'Reaction outcome loss': 0.5284940510252376, 'Total loss': 0.5284940510252376}
2022-12-05 22:53:37,164 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:37,164 INFO:     Epoch: 49
2022-12-05 22:53:37,856 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5332133402658064, 'Total loss': 0.5332133402658064} | train loss {'Reaction outcome loss': 0.5377981000476413, 'Total loss': 0.5377981000476413}
2022-12-05 22:53:37,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:37,857 INFO:     Epoch: 50
2022-12-05 22:53:38,551 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49237505745056065, 'Total loss': 0.49237505745056065} | train loss {'Reaction outcome loss': 0.5271911708170495, 'Total loss': 0.5271911708170495}
2022-12-05 22:53:38,551 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:38,551 INFO:     Epoch: 51
2022-12-05 22:53:39,240 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5337638321310975, 'Total loss': 0.5337638321310975} | train loss {'Reaction outcome loss': 0.5316693447376966, 'Total loss': 0.5316693447376966}
2022-12-05 22:53:39,240 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:39,240 INFO:     Epoch: 52
2022-12-05 22:53:39,933 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47993954045827997, 'Total loss': 0.47993954045827997} | train loss {'Reaction outcome loss': 0.5312808318515864, 'Total loss': 0.5312808318515864}
2022-12-05 22:53:39,933 INFO:     Found new best model at epoch 52
2022-12-05 22:53:39,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:39,933 INFO:     Epoch: 53
2022-12-05 22:53:40,624 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5127410095098407, 'Total loss': 0.5127410095098407} | train loss {'Reaction outcome loss': 0.5233183574590663, 'Total loss': 0.5233183574590663}
2022-12-05 22:53:40,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:40,624 INFO:     Epoch: 54
2022-12-05 22:53:41,317 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5258933329998061, 'Total loss': 0.5258933329998061} | train loss {'Reaction outcome loss': 0.5347563117251966, 'Total loss': 0.5347563117251966}
2022-12-05 22:53:41,317 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:41,317 INFO:     Epoch: 55
2022-12-05 22:53:42,007 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48972275021464323, 'Total loss': 0.48972275021464323} | train loss {'Reaction outcome loss': 0.5332003330252298, 'Total loss': 0.5332003330252298}
2022-12-05 22:53:42,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:42,008 INFO:     Epoch: 56
2022-12-05 22:53:42,700 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4950690477393394, 'Total loss': 0.4950690477393394} | train loss {'Reaction outcome loss': 0.5281774279021432, 'Total loss': 0.5281774279021432}
2022-12-05 22:53:42,701 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:42,701 INFO:     Epoch: 57
2022-12-05 22:53:43,394 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5271808463473653, 'Total loss': 0.5271808463473653} | train loss {'Reaction outcome loss': 0.5300993464365908, 'Total loss': 0.5300993464365908}
2022-12-05 22:53:43,394 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:43,394 INFO:     Epoch: 58
2022-12-05 22:53:44,085 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5363574540892313, 'Total loss': 0.5363574540892313} | train loss {'Reaction outcome loss': 0.5327503317545471, 'Total loss': 0.5327503317545471}
2022-12-05 22:53:44,085 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:44,085 INFO:     Epoch: 59
2022-12-05 22:53:44,777 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5143166849779528, 'Total loss': 0.5143166849779528} | train loss {'Reaction outcome loss': 0.5361927024130959, 'Total loss': 0.5361927024130959}
2022-12-05 22:53:44,777 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:44,777 INFO:     Epoch: 60
2022-12-05 22:53:45,470 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5265403078045956, 'Total loss': 0.5265403078045956} | train loss {'Reaction outcome loss': 0.5345950571229919, 'Total loss': 0.5345950571229919}
2022-12-05 22:53:45,470 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:45,470 INFO:     Epoch: 61
2022-12-05 22:53:46,163 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5176694258007892, 'Total loss': 0.5176694258007892} | train loss {'Reaction outcome loss': 0.5263012934000895, 'Total loss': 0.5263012934000895}
2022-12-05 22:53:46,163 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:46,163 INFO:     Epoch: 62
2022-12-05 22:53:46,857 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5232860931130343, 'Total loss': 0.5232860931130343} | train loss {'Reaction outcome loss': 0.5253981996342969, 'Total loss': 0.5253981996342969}
2022-12-05 22:53:46,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:46,857 INFO:     Epoch: 63
2022-12-05 22:53:47,550 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5361386717751969, 'Total loss': 0.5361386717751969} | train loss {'Reaction outcome loss': 0.5233858648396323, 'Total loss': 0.5233858648396323}
2022-12-05 22:53:47,550 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:47,550 INFO:     Epoch: 64
2022-12-05 22:53:48,241 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5121800095535988, 'Total loss': 0.5121800095535988} | train loss {'Reaction outcome loss': 0.5326784840581839, 'Total loss': 0.5326784840581839}
2022-12-05 22:53:48,241 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:48,241 INFO:     Epoch: 65
2022-12-05 22:53:48,933 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5010998481234838, 'Total loss': 0.5010998481234838} | train loss {'Reaction outcome loss': 0.5321575286089147, 'Total loss': 0.5321575286089147}
2022-12-05 22:53:48,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:48,933 INFO:     Epoch: 66
2022-12-05 22:53:49,627 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5008787904367891, 'Total loss': 0.5008787904367891} | train loss {'Reaction outcome loss': 0.5282422873218364, 'Total loss': 0.5282422873218364}
2022-12-05 22:53:49,627 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:49,627 INFO:     Epoch: 67
2022-12-05 22:53:50,322 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5510209618612777, 'Total loss': 0.5510209618612777} | train loss {'Reaction outcome loss': 0.5260987255431007, 'Total loss': 0.5260987255431007}
2022-12-05 22:53:50,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:50,322 INFO:     Epoch: 68
2022-12-05 22:53:51,012 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5028778328451999, 'Total loss': 0.5028778328451999} | train loss {'Reaction outcome loss': 0.5282396156601454, 'Total loss': 0.5282396156601454}
2022-12-05 22:53:51,012 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:51,012 INFO:     Epoch: 69
2022-12-05 22:53:51,702 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49823801739271295, 'Total loss': 0.49823801739271295} | train loss {'Reaction outcome loss': 0.5327616924488986, 'Total loss': 0.5327616924488986}
2022-12-05 22:53:51,702 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:51,702 INFO:     Epoch: 70
2022-12-05 22:53:52,399 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4949822758519372, 'Total loss': 0.4949822758519372} | train loss {'Reaction outcome loss': 0.5297436776720448, 'Total loss': 0.5297436776720448}
2022-12-05 22:53:52,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:52,399 INFO:     Epoch: 71
2022-12-05 22:53:53,091 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5043115456436955, 'Total loss': 0.5043115456436955} | train loss {'Reaction outcome loss': 0.5279370862760662, 'Total loss': 0.5279370862760662}
2022-12-05 22:53:53,092 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:53,092 INFO:     Epoch: 72
2022-12-05 22:53:53,781 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5035588717044786, 'Total loss': 0.5035588717044786} | train loss {'Reaction outcome loss': 0.5272588477826413, 'Total loss': 0.5272588477826413}
2022-12-05 22:53:53,782 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:53,782 INFO:     Epoch: 73
2022-12-05 22:53:54,471 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49587803004786024, 'Total loss': 0.49587803004786024} | train loss {'Reaction outcome loss': 0.5253755384021335, 'Total loss': 0.5253755384021335}
2022-12-05 22:53:54,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:54,471 INFO:     Epoch: 74
2022-12-05 22:53:55,164 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4946824693402579, 'Total loss': 0.4946824693402579} | train loss {'Reaction outcome loss': 0.5215415842371223, 'Total loss': 0.5215415842371223}
2022-12-05 22:53:55,164 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:55,164 INFO:     Epoch: 75
2022-12-05 22:53:55,857 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.50196086875228, 'Total loss': 0.50196086875228} | train loss {'Reaction outcome loss': 0.530053511077975, 'Total loss': 0.530053511077975}
2022-12-05 22:53:55,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:55,857 INFO:     Epoch: 76
2022-12-05 22:53:56,553 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5043513719425645, 'Total loss': 0.5043513719425645} | train loss {'Reaction outcome loss': 0.5324434164620231, 'Total loss': 0.5324434164620231}
2022-12-05 22:53:56,553 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:56,553 INFO:     Epoch: 77
2022-12-05 22:53:57,249 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.515814603761185, 'Total loss': 0.515814603761185} | train loss {'Reaction outcome loss': 0.5273258911116133, 'Total loss': 0.5273258911116133}
2022-12-05 22:53:57,250 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:57,250 INFO:     Epoch: 78
2022-12-05 22:53:57,941 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5230271483576575, 'Total loss': 0.5230271483576575} | train loss {'Reaction outcome loss': 0.5295325323878002, 'Total loss': 0.5295325323878002}
2022-12-05 22:53:57,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:57,941 INFO:     Epoch: 79
2022-12-05 22:53:58,635 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4891823190589284, 'Total loss': 0.4891823190589284} | train loss {'Reaction outcome loss': 0.5230984311290239, 'Total loss': 0.5230984311290239}
2022-12-05 22:53:58,636 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:58,636 INFO:     Epoch: 80
2022-12-05 22:53:59,327 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5183027906473293, 'Total loss': 0.5183027906473293} | train loss {'Reaction outcome loss': 0.5225411551724736, 'Total loss': 0.5225411551724736}
2022-12-05 22:53:59,327 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:53:59,327 INFO:     Epoch: 81
2022-12-05 22:54:00,016 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4871787581332894, 'Total loss': 0.4871787581332894} | train loss {'Reaction outcome loss': 0.5300524264206121, 'Total loss': 0.5300524264206121}
2022-12-05 22:54:00,016 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:00,016 INFO:     Epoch: 82
2022-12-05 22:54:00,706 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5137626272301341, 'Total loss': 0.5137626272301341} | train loss {'Reaction outcome loss': 0.5284833333497185, 'Total loss': 0.5284833333497185}
2022-12-05 22:54:00,706 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:00,706 INFO:     Epoch: 83
2022-12-05 22:54:01,396 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5153176895407743, 'Total loss': 0.5153176895407743} | train loss {'Reaction outcome loss': 0.5328414229821766, 'Total loss': 0.5328414229821766}
2022-12-05 22:54:01,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:01,396 INFO:     Epoch: 84
2022-12-05 22:54:02,086 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5068498042433761, 'Total loss': 0.5068498042433761} | train loss {'Reaction outcome loss': 0.5291136936763677, 'Total loss': 0.5291136936763677}
2022-12-05 22:54:02,086 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:02,086 INFO:     Epoch: 85
2022-12-05 22:54:02,776 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5127093719188557, 'Total loss': 0.5127093719188557} | train loss {'Reaction outcome loss': 0.5241719029322573, 'Total loss': 0.5241719029322573}
2022-12-05 22:54:02,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:02,776 INFO:     Epoch: 86
2022-12-05 22:54:03,470 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49801692817100257, 'Total loss': 0.49801692817100257} | train loss {'Reaction outcome loss': 0.5320644180593177, 'Total loss': 0.5320644180593177}
2022-12-05 22:54:03,470 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:03,470 INFO:     Epoch: 87
2022-12-05 22:54:04,159 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5150645052970841, 'Total loss': 0.5150645052970841} | train loss {'Reaction outcome loss': 0.5361762115494214, 'Total loss': 0.5361762115494214}
2022-12-05 22:54:04,159 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:04,159 INFO:     Epoch: 88
2022-12-05 22:54:04,849 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5148510579452958, 'Total loss': 0.5148510579452958} | train loss {'Reaction outcome loss': 0.5257849777922218, 'Total loss': 0.5257849777922218}
2022-12-05 22:54:04,850 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:04,850 INFO:     Epoch: 89
2022-12-05 22:54:05,540 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.520311999806138, 'Total loss': 0.520311999806138} | train loss {'Reaction outcome loss': 0.5266624259850616, 'Total loss': 0.5266624259850616}
2022-12-05 22:54:05,540 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:05,540 INFO:     Epoch: 90
2022-12-05 22:54:06,233 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5001138847234637, 'Total loss': 0.5001138847234637} | train loss {'Reaction outcome loss': 0.5240243285158535, 'Total loss': 0.5240243285158535}
2022-12-05 22:54:06,233 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:06,234 INFO:     Epoch: 91
2022-12-05 22:54:06,928 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5119102039309436, 'Total loss': 0.5119102039309436} | train loss {'Reaction outcome loss': 0.5283384156938443, 'Total loss': 0.5283384156938443}
2022-12-05 22:54:06,928 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:06,928 INFO:     Epoch: 92
2022-12-05 22:54:07,618 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.49019545074119125, 'Total loss': 0.49019545074119125} | train loss {'Reaction outcome loss': 0.5252046670320103, 'Total loss': 0.5252046670320103}
2022-12-05 22:54:07,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:07,618 INFO:     Epoch: 93
2022-12-05 22:54:08,314 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5019284774397694, 'Total loss': 0.5019284774397694} | train loss {'Reaction outcome loss': 0.5297884920251713, 'Total loss': 0.5297884920251713}
2022-12-05 22:54:08,314 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:08,314 INFO:     Epoch: 94
2022-12-05 22:54:09,009 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49825178121411523, 'Total loss': 0.49825178121411523} | train loss {'Reaction outcome loss': 0.5239303930674071, 'Total loss': 0.5239303930674071}
2022-12-05 22:54:09,009 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:09,009 INFO:     Epoch: 95
2022-12-05 22:54:09,702 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5180303281129792, 'Total loss': 0.5180303281129792} | train loss {'Reaction outcome loss': 0.5256185216422925, 'Total loss': 0.5256185216422925}
2022-12-05 22:54:09,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:09,703 INFO:     Epoch: 96
2022-12-05 22:54:10,396 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4998066903546799, 'Total loss': 0.4998066903546799} | train loss {'Reaction outcome loss': 0.530871245596144, 'Total loss': 0.530871245596144}
2022-12-05 22:54:10,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:10,396 INFO:     Epoch: 97
2022-12-05 22:54:11,090 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5534338119418122, 'Total loss': 0.5534338119418122} | train loss {'Reaction outcome loss': 0.5250711159880269, 'Total loss': 0.5250711159880269}
2022-12-05 22:54:11,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:11,091 INFO:     Epoch: 98
2022-12-05 22:54:11,781 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47912743410398795, 'Total loss': 0.47912743410398795} | train loss {'Reaction outcome loss': 0.5217816332976023, 'Total loss': 0.5217816332976023}
2022-12-05 22:54:11,781 INFO:     Found new best model at epoch 98
2022-12-05 22:54:11,782 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:11,782 INFO:     Epoch: 99
2022-12-05 22:54:12,471 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.500022021490474, 'Total loss': 0.500022021490474} | train loss {'Reaction outcome loss': 0.5321324831296387, 'Total loss': 0.5321324831296387}
2022-12-05 22:54:12,471 INFO:     Best model found after epoch 99 of 100.
2022-12-05 22:54:12,471 INFO:   Done with stage: TRAINING
2022-12-05 22:54:12,471 INFO:   Starting stage: EVALUATION
2022-12-05 22:54:12,612 INFO:   Done with stage: EVALUATION
2022-12-05 22:54:12,612 INFO:   Leaving out SEQ value Fold_1
2022-12-05 22:54:12,625 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:54:12,625 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:54:13,258 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:54:13,258 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:54:13,329 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:54:13,329 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:54:13,329 INFO:     No hyperparam tuning for this model
2022-12-05 22:54:13,329 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:54:13,329 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:54:13,330 INFO:     None feature selector for col prot
2022-12-05 22:54:13,330 INFO:     None feature selector for col prot
2022-12-05 22:54:13,330 INFO:     None feature selector for col prot
2022-12-05 22:54:13,330 INFO:     None feature selector for col chem
2022-12-05 22:54:13,330 INFO:     None feature selector for col chem
2022-12-05 22:54:13,331 INFO:     None feature selector for col chem
2022-12-05 22:54:13,331 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:54:13,331 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:54:13,332 INFO:     Number of params in model 215731
2022-12-05 22:54:13,335 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:54:13,335 INFO:   Starting stage: TRAINING
2022-12-05 22:54:13,393 INFO:     Val loss before train {'Reaction outcome loss': 1.0288275195793672, 'Total loss': 1.0288275195793672}
2022-12-05 22:54:13,393 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:13,393 INFO:     Epoch: 0
2022-12-05 22:54:14,096 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7029066702181642, 'Total loss': 0.7029066702181642} | train loss {'Reaction outcome loss': 0.8178496699222186, 'Total loss': 0.8178496699222186}
2022-12-05 22:54:14,096 INFO:     Found new best model at epoch 0
2022-12-05 22:54:14,097 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:14,097 INFO:     Epoch: 1
2022-12-05 22:54:14,797 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6530193408781831, 'Total loss': 0.6530193408781831} | train loss {'Reaction outcome loss': 0.6839039732328793, 'Total loss': 0.6839039732328793}
2022-12-05 22:54:14,797 INFO:     Found new best model at epoch 1
2022-12-05 22:54:14,798 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:14,798 INFO:     Epoch: 2
2022-12-05 22:54:15,498 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5454396246509119, 'Total loss': 0.5454396246509119} | train loss {'Reaction outcome loss': 0.6360339957934159, 'Total loss': 0.6360339957934159}
2022-12-05 22:54:15,499 INFO:     Found new best model at epoch 2
2022-12-05 22:54:15,499 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:15,499 INFO:     Epoch: 3
2022-12-05 22:54:16,199 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5827538255940784, 'Total loss': 0.5827538255940784} | train loss {'Reaction outcome loss': 0.6017501690247764, 'Total loss': 0.6017501690247764}
2022-12-05 22:54:16,199 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:16,199 INFO:     Epoch: 4
2022-12-05 22:54:16,904 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5949066904458132, 'Total loss': 0.5949066904458132} | train loss {'Reaction outcome loss': 0.5918848450608581, 'Total loss': 0.5918848450608581}
2022-12-05 22:54:16,904 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:16,904 INFO:     Epoch: 5
2022-12-05 22:54:17,607 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5431565378199924, 'Total loss': 0.5431565378199924} | train loss {'Reaction outcome loss': 0.6004905319406919, 'Total loss': 0.6004905319406919}
2022-12-05 22:54:17,607 INFO:     Found new best model at epoch 5
2022-12-05 22:54:17,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:17,608 INFO:     Epoch: 6
2022-12-05 22:54:18,309 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5572111240842126, 'Total loss': 0.5572111240842126} | train loss {'Reaction outcome loss': 0.5678889352059074, 'Total loss': 0.5678889352059074}
2022-12-05 22:54:18,309 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:18,310 INFO:     Epoch: 7
2022-12-05 22:54:19,013 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5641798383810304, 'Total loss': 0.5641798383810304} | train loss {'Reaction outcome loss': 0.5689285833102006, 'Total loss': 0.5689285833102006}
2022-12-05 22:54:19,013 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:19,013 INFO:     Epoch: 8
2022-12-05 22:54:19,715 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5666671598499472, 'Total loss': 0.5666671598499472} | train loss {'Reaction outcome loss': 0.5767068378476479, 'Total loss': 0.5767068378476479}
2022-12-05 22:54:19,715 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:19,715 INFO:     Epoch: 9
2022-12-05 22:54:20,416 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5558248040351, 'Total loss': 0.5558248040351} | train loss {'Reaction outcome loss': 0.5986043036225354, 'Total loss': 0.5986043036225354}
2022-12-05 22:54:20,417 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:20,417 INFO:     Epoch: 10
2022-12-05 22:54:21,121 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5616538395935838, 'Total loss': 0.5616538395935838} | train loss {'Reaction outcome loss': 0.5806034061952159, 'Total loss': 0.5806034061952159}
2022-12-05 22:54:21,121 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:21,121 INFO:     Epoch: 11
2022-12-05 22:54:21,826 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5292016945101998, 'Total loss': 0.5292016945101998} | train loss {'Reaction outcome loss': 0.5497494487597151, 'Total loss': 0.5497494487597151}
2022-12-05 22:54:21,826 INFO:     Found new best model at epoch 11
2022-12-05 22:54:21,826 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:21,827 INFO:     Epoch: 12
2022-12-05 22:54:22,532 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5253290158103813, 'Total loss': 0.5253290158103813} | train loss {'Reaction outcome loss': 0.5469115949744879, 'Total loss': 0.5469115949744879}
2022-12-05 22:54:22,532 INFO:     Found new best model at epoch 12
2022-12-05 22:54:22,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:22,533 INFO:     Epoch: 13
2022-12-05 22:54:23,233 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5196255394680933, 'Total loss': 0.5196255394680933} | train loss {'Reaction outcome loss': 0.5415045414610129, 'Total loss': 0.5415045414610129}
2022-12-05 22:54:23,234 INFO:     Found new best model at epoch 13
2022-12-05 22:54:23,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:23,235 INFO:     Epoch: 14
2022-12-05 22:54:23,936 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5326381020925262, 'Total loss': 0.5326381020925262} | train loss {'Reaction outcome loss': 0.5502796437938203, 'Total loss': 0.5502796437938203}
2022-12-05 22:54:23,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:23,937 INFO:     Epoch: 15
2022-12-05 22:54:24,645 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.528996245766228, 'Total loss': 0.528996245766228} | train loss {'Reaction outcome loss': 0.5445856695112429, 'Total loss': 0.5445856695112429}
2022-12-05 22:54:24,645 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:24,645 INFO:     Epoch: 16
2022-12-05 22:54:25,350 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.6104346175085414, 'Total loss': 0.6104346175085414} | train loss {'Reaction outcome loss': 0.5492048895793405, 'Total loss': 0.5492048895793405}
2022-12-05 22:54:25,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:25,351 INFO:     Epoch: 17
2022-12-05 22:54:26,054 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5412855801934545, 'Total loss': 0.5412855801934545} | train loss {'Reaction outcome loss': 0.5599295515642475, 'Total loss': 0.5599295515642475}
2022-12-05 22:54:26,054 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:26,054 INFO:     Epoch: 18
2022-12-05 22:54:26,755 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4791701740839265, 'Total loss': 0.4791701740839265} | train loss {'Reaction outcome loss': 0.5421165078293969, 'Total loss': 0.5421165078293969}
2022-12-05 22:54:26,755 INFO:     Found new best model at epoch 18
2022-12-05 22:54:26,756 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:26,756 INFO:     Epoch: 19
2022-12-05 22:54:27,458 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5149762654169039, 'Total loss': 0.5149762654169039} | train loss {'Reaction outcome loss': 0.539268300842177, 'Total loss': 0.539268300842177}
2022-12-05 22:54:27,458 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:27,458 INFO:     Epoch: 20
2022-12-05 22:54:28,160 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5451226098970934, 'Total loss': 0.5451226098970934} | train loss {'Reaction outcome loss': 0.5541891010425352, 'Total loss': 0.5541891010425352}
2022-12-05 22:54:28,160 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:28,160 INFO:     Epoch: 21
2022-12-05 22:54:28,861 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5090309449217536, 'Total loss': 0.5090309449217536} | train loss {'Reaction outcome loss': 0.5407421991289386, 'Total loss': 0.5407421991289386}
2022-12-05 22:54:28,861 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:28,861 INFO:     Epoch: 22
2022-12-05 22:54:29,563 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5248703617941249, 'Total loss': 0.5248703617941249} | train loss {'Reaction outcome loss': 0.541778446631393, 'Total loss': 0.541778446631393}
2022-12-05 22:54:29,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:29,563 INFO:     Epoch: 23
2022-12-05 22:54:30,265 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5116690945896235, 'Total loss': 0.5116690945896235} | train loss {'Reaction outcome loss': 0.5396165958179636, 'Total loss': 0.5396165958179636}
2022-12-05 22:54:30,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:30,266 INFO:     Epoch: 24
2022-12-05 22:54:30,966 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5723694901574742, 'Total loss': 0.5723694901574742} | train loss {'Reaction outcome loss': 0.5337361669250829, 'Total loss': 0.5337361669250829}
2022-12-05 22:54:30,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:30,966 INFO:     Epoch: 25
2022-12-05 22:54:31,667 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49069172550331464, 'Total loss': 0.49069172550331464} | train loss {'Reaction outcome loss': 0.5366583046642875, 'Total loss': 0.5366583046642875}
2022-12-05 22:54:31,667 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:31,668 INFO:     Epoch: 26
2022-12-05 22:54:32,368 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5508683364499699, 'Total loss': 0.5508683364499699} | train loss {'Reaction outcome loss': 0.5385258362481469, 'Total loss': 0.5385258362481469}
2022-12-05 22:54:32,368 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:32,368 INFO:     Epoch: 27
2022-12-05 22:54:33,073 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49092199924317276, 'Total loss': 0.49092199924317276} | train loss {'Reaction outcome loss': 0.5316634124431473, 'Total loss': 0.5316634124431473}
2022-12-05 22:54:33,073 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:33,073 INFO:     Epoch: 28
2022-12-05 22:54:33,774 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.527166196229783, 'Total loss': 0.527166196229783} | train loss {'Reaction outcome loss': 0.532308666239142, 'Total loss': 0.532308666239142}
2022-12-05 22:54:33,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:33,774 INFO:     Epoch: 29
2022-12-05 22:54:34,474 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5643139000643383, 'Total loss': 0.5643139000643383} | train loss {'Reaction outcome loss': 0.5309433238467707, 'Total loss': 0.5309433238467707}
2022-12-05 22:54:34,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:34,475 INFO:     Epoch: 30
2022-12-05 22:54:35,180 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5873255032030019, 'Total loss': 0.5873255032030019} | train loss {'Reaction outcome loss': 0.5323415089715348, 'Total loss': 0.5323415089715348}
2022-12-05 22:54:35,180 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:35,180 INFO:     Epoch: 31
2022-12-05 22:54:35,882 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.503179298544472, 'Total loss': 0.503179298544472} | train loss {'Reaction outcome loss': 0.5457211300911691, 'Total loss': 0.5457211300911691}
2022-12-05 22:54:35,884 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:35,884 INFO:     Epoch: 32
2022-12-05 22:54:36,588 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5488787564364347, 'Total loss': 0.5488787564364347} | train loss {'Reaction outcome loss': 0.5311524513882664, 'Total loss': 0.5311524513882664}
2022-12-05 22:54:36,588 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:36,589 INFO:     Epoch: 33
2022-12-05 22:54:37,292 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.506352790038694, 'Total loss': 0.506352790038694} | train loss {'Reaction outcome loss': 0.5425000095415694, 'Total loss': 0.5425000095415694}
2022-12-05 22:54:37,292 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:37,292 INFO:     Epoch: 34
2022-12-05 22:54:37,993 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5665166547352617, 'Total loss': 0.5665166547352617} | train loss {'Reaction outcome loss': 0.5335873588617996, 'Total loss': 0.5335873588617996}
2022-12-05 22:54:37,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:37,993 INFO:     Epoch: 35
2022-12-05 22:54:38,694 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4914009354331277, 'Total loss': 0.4914009354331277} | train loss {'Reaction outcome loss': 0.5361812553304409, 'Total loss': 0.5361812553304409}
2022-12-05 22:54:38,694 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:38,695 INFO:     Epoch: 36
2022-12-05 22:54:39,399 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.528804211453958, 'Total loss': 0.528804211453958} | train loss {'Reaction outcome loss': 0.5283906598564102, 'Total loss': 0.5283906598564102}
2022-12-05 22:54:39,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:39,399 INFO:     Epoch: 37
2022-12-05 22:54:40,101 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5045288022268902, 'Total loss': 0.5045288022268902} | train loss {'Reaction outcome loss': 0.5370826388780887, 'Total loss': 0.5370826388780887}
2022-12-05 22:54:40,101 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:40,101 INFO:     Epoch: 38
2022-12-05 22:54:40,808 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.53554071824659, 'Total loss': 0.53554071824659} | train loss {'Reaction outcome loss': 0.5333832907773223, 'Total loss': 0.5333832907773223}
2022-12-05 22:54:40,808 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:40,808 INFO:     Epoch: 39
2022-12-05 22:54:41,511 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5192520814863119, 'Total loss': 0.5192520814863119} | train loss {'Reaction outcome loss': 0.5409911477614028, 'Total loss': 0.5409911477614028}
2022-12-05 22:54:41,512 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:41,512 INFO:     Epoch: 40
2022-12-05 22:54:42,214 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5172541967847131, 'Total loss': 0.5172541967847131} | train loss {'Reaction outcome loss': 0.5332115424065454, 'Total loss': 0.5332115424065454}
2022-12-05 22:54:42,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:42,215 INFO:     Epoch: 41
2022-12-05 22:54:42,923 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5238604806363583, 'Total loss': 0.5238604806363583} | train loss {'Reaction outcome loss': 0.5273004963632054, 'Total loss': 0.5273004963632054}
2022-12-05 22:54:42,923 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:42,923 INFO:     Epoch: 42
2022-12-05 22:54:43,634 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5130311508070339, 'Total loss': 0.5130311508070339} | train loss {'Reaction outcome loss': 0.5221105920158418, 'Total loss': 0.5221105920158418}
2022-12-05 22:54:43,634 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:43,634 INFO:     Epoch: 43
2022-12-05 22:54:44,340 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48475674099542876, 'Total loss': 0.48475674099542876} | train loss {'Reaction outcome loss': 0.5269467895209548, 'Total loss': 0.5269467895209548}
2022-12-05 22:54:44,340 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:44,340 INFO:     Epoch: 44
2022-12-05 22:54:45,048 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4979947608980266, 'Total loss': 0.4979947608980266} | train loss {'Reaction outcome loss': 0.5207985503229535, 'Total loss': 0.5207985503229535}
2022-12-05 22:54:45,049 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:45,049 INFO:     Epoch: 45
2022-12-05 22:54:45,753 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5212059197100726, 'Total loss': 0.5212059197100726} | train loss {'Reaction outcome loss': 0.5141567737316555, 'Total loss': 0.5141567737316555}
2022-12-05 22:54:45,753 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:45,753 INFO:     Epoch: 46
2022-12-05 22:54:46,465 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5512722947380759, 'Total loss': 0.5512722947380759} | train loss {'Reaction outcome loss': 0.5261983192763348, 'Total loss': 0.5261983192763348}
2022-12-05 22:54:46,465 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:46,465 INFO:     Epoch: 47
2022-12-05 22:54:47,171 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5769200880419124, 'Total loss': 0.5769200880419124} | train loss {'Reaction outcome loss': 0.5248561372399813, 'Total loss': 0.5248561372399813}
2022-12-05 22:54:47,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:47,171 INFO:     Epoch: 48
2022-12-05 22:54:47,876 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5796733464707028, 'Total loss': 0.5796733464707028} | train loss {'Reaction outcome loss': 0.5199954021073546, 'Total loss': 0.5199954021073546}
2022-12-05 22:54:47,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:47,876 INFO:     Epoch: 49
2022-12-05 22:54:48,580 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5008148781277917, 'Total loss': 0.5008148781277917} | train loss {'Reaction outcome loss': 0.5337873284369405, 'Total loss': 0.5337873284369405}
2022-12-05 22:54:48,581 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:48,581 INFO:     Epoch: 50
2022-12-05 22:54:49,285 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.50212764096531, 'Total loss': 0.50212764096531} | train loss {'Reaction outcome loss': 0.5179623877591932, 'Total loss': 0.5179623877591932}
2022-12-05 22:54:49,285 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:49,286 INFO:     Epoch: 51
2022-12-05 22:54:49,991 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4956915757872842, 'Total loss': 0.4956915757872842} | train loss {'Reaction outcome loss': 0.5142614944623067, 'Total loss': 0.5142614944623067}
2022-12-05 22:54:49,991 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:49,991 INFO:     Epoch: 52
2022-12-05 22:54:50,699 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4828246953812512, 'Total loss': 0.4828246953812512} | train loss {'Reaction outcome loss': 0.5178008305761013, 'Total loss': 0.5178008305761013}
2022-12-05 22:54:50,699 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:50,699 INFO:     Epoch: 53
2022-12-05 22:54:51,405 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5474167527122931, 'Total loss': 0.5474167527122931} | train loss {'Reaction outcome loss': 0.5264354178056061, 'Total loss': 0.5264354178056061}
2022-12-05 22:54:51,405 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:51,405 INFO:     Epoch: 54
2022-12-05 22:54:52,111 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49212945388122037, 'Total loss': 0.49212945388122037} | train loss {'Reaction outcome loss': 0.5706844428169583, 'Total loss': 0.5706844428169583}
2022-12-05 22:54:52,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:52,111 INFO:     Epoch: 55
2022-12-05 22:54:52,819 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49380924146283756, 'Total loss': 0.49380924146283756} | train loss {'Reaction outcome loss': 0.5179466364399986, 'Total loss': 0.5179466364399986}
2022-12-05 22:54:52,819 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:52,819 INFO:     Epoch: 56
2022-12-05 22:54:53,525 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4922648722475225, 'Total loss': 0.4922648722475225} | train loss {'Reaction outcome loss': 0.5202447975333403, 'Total loss': 0.5202447975333403}
2022-12-05 22:54:53,525 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:53,525 INFO:     Epoch: 57
2022-12-05 22:54:54,233 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5032962354069407, 'Total loss': 0.5032962354069407} | train loss {'Reaction outcome loss': 0.5189375868783548, 'Total loss': 0.5189375868783548}
2022-12-05 22:54:54,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:54,234 INFO:     Epoch: 58
2022-12-05 22:54:54,939 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47902386500076816, 'Total loss': 0.47902386500076816} | train loss {'Reaction outcome loss': 0.5131727731541583, 'Total loss': 0.5131727731541583}
2022-12-05 22:54:54,940 INFO:     Found new best model at epoch 58
2022-12-05 22:54:54,940 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:54,940 INFO:     Epoch: 59
2022-12-05 22:54:55,651 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5307614674622362, 'Total loss': 0.5307614674622362} | train loss {'Reaction outcome loss': 0.5081787322334915, 'Total loss': 0.5081787322334915}
2022-12-05 22:54:55,651 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:55,651 INFO:     Epoch: 60
2022-12-05 22:54:56,361 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47194914147257805, 'Total loss': 0.47194914147257805} | train loss {'Reaction outcome loss': 0.5144753164125357, 'Total loss': 0.5144753164125357}
2022-12-05 22:54:56,361 INFO:     Found new best model at epoch 60
2022-12-05 22:54:56,362 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:56,362 INFO:     Epoch: 61
2022-12-05 22:54:57,071 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.49155054783279245, 'Total loss': 0.49155054783279245} | train loss {'Reaction outcome loss': 0.5138489574736912, 'Total loss': 0.5138489574736912}
2022-12-05 22:54:57,071 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:57,071 INFO:     Epoch: 62
2022-12-05 22:54:57,780 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4836108176545663, 'Total loss': 0.4836108176545663} | train loss {'Reaction outcome loss': 0.5150335273038038, 'Total loss': 0.5150335273038038}
2022-12-05 22:54:57,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:57,780 INFO:     Epoch: 63
2022-12-05 22:54:58,485 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5241455452686007, 'Total loss': 0.5241455452686007} | train loss {'Reaction outcome loss': 0.5120102936319011, 'Total loss': 0.5120102936319011}
2022-12-05 22:54:58,485 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:58,486 INFO:     Epoch: 64
2022-12-05 22:54:59,190 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47483794221823866, 'Total loss': 0.47483794221823866} | train loss {'Reaction outcome loss': 0.5182995749147314, 'Total loss': 0.5182995749147314}
2022-12-05 22:54:59,190 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:59,190 INFO:     Epoch: 65
2022-12-05 22:54:59,894 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.47565573487769475, 'Total loss': 0.47565573487769475} | train loss {'Reaction outcome loss': 0.5102477638948302, 'Total loss': 0.5102477638948302}
2022-12-05 22:54:59,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:54:59,894 INFO:     Epoch: 66
2022-12-05 22:55:00,598 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5359590608965267, 'Total loss': 0.5359590608965267} | train loss {'Reaction outcome loss': 0.5152478685625169, 'Total loss': 0.5152478685625169}
2022-12-05 22:55:00,599 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:00,599 INFO:     Epoch: 67
2022-12-05 22:55:01,303 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48810659078034485, 'Total loss': 0.48810659078034485} | train loss {'Reaction outcome loss': 0.5106197838256276, 'Total loss': 0.5106197838256276}
2022-12-05 22:55:01,303 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:01,303 INFO:     Epoch: 68
2022-12-05 22:55:02,009 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47250222380865703, 'Total loss': 0.47250222380865703} | train loss {'Reaction outcome loss': 0.5149795743014648, 'Total loss': 0.5149795743014648}
2022-12-05 22:55:02,009 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:02,010 INFO:     Epoch: 69
2022-12-05 22:55:02,716 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5844808363101699, 'Total loss': 0.5844808363101699} | train loss {'Reaction outcome loss': 0.5147285405923481, 'Total loss': 0.5147285405923481}
2022-12-05 22:55:02,716 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:02,717 INFO:     Epoch: 70
2022-12-05 22:55:03,421 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5265238711779768, 'Total loss': 0.5265238711779768} | train loss {'Reaction outcome loss': 0.5157938303976406, 'Total loss': 0.5157938303976406}
2022-12-05 22:55:03,421 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:03,421 INFO:     Epoch: 71
2022-12-05 22:55:04,129 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5622647479176521, 'Total loss': 0.5622647479176521} | train loss {'Reaction outcome loss': 0.5160753950175003, 'Total loss': 0.5160753950175003}
2022-12-05 22:55:04,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:04,129 INFO:     Epoch: 72
2022-12-05 22:55:04,836 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48348833891478454, 'Total loss': 0.48348833891478454} | train loss {'Reaction outcome loss': 0.5291574561161551, 'Total loss': 0.5291574561161551}
2022-12-05 22:55:04,836 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:04,836 INFO:     Epoch: 73
2022-12-05 22:55:05,542 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49329079348932614, 'Total loss': 0.49329079348932614} | train loss {'Reaction outcome loss': 0.5170185629293503, 'Total loss': 0.5170185629293503}
2022-12-05 22:55:05,542 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:05,542 INFO:     Epoch: 74
2022-12-05 22:55:06,246 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.500809792090546, 'Total loss': 0.500809792090546} | train loss {'Reaction outcome loss': 0.5266928247473983, 'Total loss': 0.5266928247473983}
2022-12-05 22:55:06,247 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:06,247 INFO:     Epoch: 75
2022-12-05 22:55:06,956 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5137278722091154, 'Total loss': 0.5137278722091154} | train loss {'Reaction outcome loss': 0.5416997090766305, 'Total loss': 0.5416997090766305}
2022-12-05 22:55:06,957 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:06,957 INFO:     Epoch: 76
2022-12-05 22:55:07,667 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49843486804853787, 'Total loss': 0.49843486804853787} | train loss {'Reaction outcome loss': 0.5086888234274318, 'Total loss': 0.5086888234274318}
2022-12-05 22:55:07,668 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:07,668 INFO:     Epoch: 77
2022-12-05 22:55:08,381 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48597240244800394, 'Total loss': 0.48597240244800394} | train loss {'Reaction outcome loss': 0.5108007070144661, 'Total loss': 0.5108007070144661}
2022-12-05 22:55:08,381 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:08,381 INFO:     Epoch: 78
2022-12-05 22:55:09,088 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5027528882703998, 'Total loss': 0.5027528882703998} | train loss {'Reaction outcome loss': 0.5222825834976306, 'Total loss': 0.5222825834976306}
2022-12-05 22:55:09,089 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:09,089 INFO:     Epoch: 79
2022-12-05 22:55:09,796 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4846297478811307, 'Total loss': 0.4846297478811307} | train loss {'Reaction outcome loss': 0.5083970344259672, 'Total loss': 0.5083970344259672}
2022-12-05 22:55:09,796 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:09,797 INFO:     Epoch: 80
2022-12-05 22:55:10,511 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5221111239357428, 'Total loss': 0.5221111239357428} | train loss {'Reaction outcome loss': 0.5036678833845505, 'Total loss': 0.5036678833845505}
2022-12-05 22:55:10,511 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:10,511 INFO:     Epoch: 81
2022-12-05 22:55:11,221 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.551768997176127, 'Total loss': 0.551768997176127} | train loss {'Reaction outcome loss': 0.508586010288613, 'Total loss': 0.508586010288613}
2022-12-05 22:55:11,221 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:11,221 INFO:     Epoch: 82
2022-12-05 22:55:11,928 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.493098722262816, 'Total loss': 0.493098722262816} | train loss {'Reaction outcome loss': 0.523659951954718, 'Total loss': 0.523659951954718}
2022-12-05 22:55:11,929 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:11,929 INFO:     Epoch: 83
2022-12-05 22:55:12,637 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5556466653943062, 'Total loss': 0.5556466653943062} | train loss {'Reaction outcome loss': 0.5179765881435109, 'Total loss': 0.5179765881435109}
2022-12-05 22:55:12,637 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:12,638 INFO:     Epoch: 84
2022-12-05 22:55:13,344 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5391426767137918, 'Total loss': 0.5391426767137918} | train loss {'Reaction outcome loss': 0.5289713405525154, 'Total loss': 0.5289713405525154}
2022-12-05 22:55:13,344 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:13,345 INFO:     Epoch: 85
2022-12-05 22:55:14,051 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47347715801813384, 'Total loss': 0.47347715801813384} | train loss {'Reaction outcome loss': 0.5200765681290916, 'Total loss': 0.5200765681290916}
2022-12-05 22:55:14,051 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:14,051 INFO:     Epoch: 86
2022-12-05 22:55:14,757 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.47324333814057434, 'Total loss': 0.47324333814057434} | train loss {'Reaction outcome loss': 0.5205798918600024, 'Total loss': 0.5205798918600024}
2022-12-05 22:55:14,757 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:14,757 INFO:     Epoch: 87
2022-12-05 22:55:15,464 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5061784210530195, 'Total loss': 0.5061784210530195} | train loss {'Reaction outcome loss': 0.5099453135781925, 'Total loss': 0.5099453135781925}
2022-12-05 22:55:15,464 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:15,464 INFO:     Epoch: 88
2022-12-05 22:55:16,170 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4765349335291169, 'Total loss': 0.4765349335291169} | train loss {'Reaction outcome loss': 0.5118122322235995, 'Total loss': 0.5118122322235995}
2022-12-05 22:55:16,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:16,171 INFO:     Epoch: 89
2022-12-05 22:55:16,877 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47276255454529414, 'Total loss': 0.47276255454529414} | train loss {'Reaction outcome loss': 0.5135567921255282, 'Total loss': 0.5135567921255282}
2022-12-05 22:55:16,877 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:16,877 INFO:     Epoch: 90
2022-12-05 22:55:17,586 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4901494268666614, 'Total loss': 0.4901494268666614} | train loss {'Reaction outcome loss': 0.5146543839682451, 'Total loss': 0.5146543839682451}
2022-12-05 22:55:17,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:17,586 INFO:     Epoch: 91
2022-12-05 22:55:18,295 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4982924176888032, 'Total loss': 0.4982924176888032} | train loss {'Reaction outcome loss': 0.504035478299446, 'Total loss': 0.504035478299446}
2022-12-05 22:55:18,295 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:18,295 INFO:     Epoch: 92
2022-12-05 22:55:19,001 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47243019904602657, 'Total loss': 0.47243019904602657} | train loss {'Reaction outcome loss': 0.5175892206112503, 'Total loss': 0.5175892206112503}
2022-12-05 22:55:19,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:19,002 INFO:     Epoch: 93
2022-12-05 22:55:19,707 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4965796643360095, 'Total loss': 0.4965796643360095} | train loss {'Reaction outcome loss': 0.5064672509562752, 'Total loss': 0.5064672509562752}
2022-12-05 22:55:19,707 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:19,707 INFO:     Epoch: 94
2022-12-05 22:55:20,414 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4736945019526915, 'Total loss': 0.4736945019526915} | train loss {'Reaction outcome loss': 0.5060439044044085, 'Total loss': 0.5060439044044085}
2022-12-05 22:55:20,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:20,414 INFO:     Epoch: 95
2022-12-05 22:55:21,120 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5639752874320204, 'Total loss': 0.5639752874320204} | train loss {'Reaction outcome loss': 0.5046838566902195, 'Total loss': 0.5046838566902195}
2022-12-05 22:55:21,120 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:21,120 INFO:     Epoch: 96
2022-12-05 22:55:21,830 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5780361829833551, 'Total loss': 0.5780361829833551} | train loss {'Reaction outcome loss': 0.5057571192502011, 'Total loss': 0.5057571192502011}
2022-12-05 22:55:21,830 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:21,830 INFO:     Epoch: 97
2022-12-05 22:55:22,537 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5299406999891455, 'Total loss': 0.5299406999891455} | train loss {'Reaction outcome loss': 0.5320424898433299, 'Total loss': 0.5320424898433299}
2022-12-05 22:55:22,537 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:22,537 INFO:     Epoch: 98
2022-12-05 22:55:23,244 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4980622408064929, 'Total loss': 0.4980622408064929} | train loss {'Reaction outcome loss': 0.5314495280566003, 'Total loss': 0.5314495280566003}
2022-12-05 22:55:23,244 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:23,244 INFO:     Epoch: 99
2022-12-05 22:55:23,952 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5117896327918227, 'Total loss': 0.5117896327918227} | train loss {'Reaction outcome loss': 0.5163550462558685, 'Total loss': 0.5163550462558685}
2022-12-05 22:55:23,952 INFO:     Best model found after epoch 61 of 100.
2022-12-05 22:55:23,952 INFO:   Done with stage: TRAINING
2022-12-05 22:55:23,952 INFO:   Starting stage: EVALUATION
2022-12-05 22:55:24,075 INFO:   Done with stage: EVALUATION
2022-12-05 22:55:24,075 INFO:   Leaving out SEQ value Fold_2
2022-12-05 22:55:24,088 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:55:24,088 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:55:24,712 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:55:24,713 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:55:24,783 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:55:24,783 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:55:24,783 INFO:     No hyperparam tuning for this model
2022-12-05 22:55:24,783 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:55:24,783 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:55:24,784 INFO:     None feature selector for col prot
2022-12-05 22:55:24,784 INFO:     None feature selector for col prot
2022-12-05 22:55:24,784 INFO:     None feature selector for col prot
2022-12-05 22:55:24,784 INFO:     None feature selector for col chem
2022-12-05 22:55:24,784 INFO:     None feature selector for col chem
2022-12-05 22:55:24,784 INFO:     None feature selector for col chem
2022-12-05 22:55:24,785 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:55:24,785 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:55:24,786 INFO:     Number of params in model 215731
2022-12-05 22:55:24,789 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:55:24,789 INFO:   Starting stage: TRAINING
2022-12-05 22:55:24,848 INFO:     Val loss before train {'Reaction outcome loss': 1.0369418100877241, 'Total loss': 1.0369418100877241}
2022-12-05 22:55:24,848 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:24,848 INFO:     Epoch: 0
2022-12-05 22:55:25,554 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7677209661765532, 'Total loss': 0.7677209661765532} | train loss {'Reaction outcome loss': 0.8097885421344212, 'Total loss': 0.8097885421344212}
2022-12-05 22:55:25,555 INFO:     Found new best model at epoch 0
2022-12-05 22:55:25,556 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:25,556 INFO:     Epoch: 1
2022-12-05 22:55:26,260 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6926453039050102, 'Total loss': 0.6926453039050102} | train loss {'Reaction outcome loss': 0.6651870478172691, 'Total loss': 0.6651870478172691}
2022-12-05 22:55:26,260 INFO:     Found new best model at epoch 1
2022-12-05 22:55:26,261 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:26,261 INFO:     Epoch: 2
2022-12-05 22:55:26,965 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6339971795678139, 'Total loss': 0.6339971795678139} | train loss {'Reaction outcome loss': 0.6113827693219087, 'Total loss': 0.6113827693219087}
2022-12-05 22:55:26,966 INFO:     Found new best model at epoch 2
2022-12-05 22:55:26,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:26,966 INFO:     Epoch: 3
2022-12-05 22:55:27,671 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6480775258757852, 'Total loss': 0.6480775258757852} | train loss {'Reaction outcome loss': 0.5915894194525115, 'Total loss': 0.5915894194525115}
2022-12-05 22:55:27,671 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:27,671 INFO:     Epoch: 4
2022-12-05 22:55:28,378 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6358338689262216, 'Total loss': 0.6358338689262216} | train loss {'Reaction outcome loss': 0.5819698147019562, 'Total loss': 0.5819698147019562}
2022-12-05 22:55:28,378 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:28,378 INFO:     Epoch: 5
2022-12-05 22:55:29,079 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6266009882092476, 'Total loss': 0.6266009882092476} | train loss {'Reaction outcome loss': 0.5757557021720069, 'Total loss': 0.5757557021720069}
2022-12-05 22:55:29,079 INFO:     Found new best model at epoch 5
2022-12-05 22:55:29,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:29,080 INFO:     Epoch: 6
2022-12-05 22:55:29,782 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5868154168128967, 'Total loss': 0.5868154168128967} | train loss {'Reaction outcome loss': 0.5702276452463501, 'Total loss': 0.5702276452463501}
2022-12-05 22:55:29,782 INFO:     Found new best model at epoch 6
2022-12-05 22:55:29,783 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:29,783 INFO:     Epoch: 7
2022-12-05 22:55:30,490 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5899016884240237, 'Total loss': 0.5899016884240237} | train loss {'Reaction outcome loss': 0.5607117130440109, 'Total loss': 0.5607117130440109}
2022-12-05 22:55:30,490 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:30,490 INFO:     Epoch: 8
2022-12-05 22:55:31,193 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6116209829395468, 'Total loss': 0.6116209829395468} | train loss {'Reaction outcome loss': 0.5575792391081246, 'Total loss': 0.5575792391081246}
2022-12-05 22:55:31,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:31,193 INFO:     Epoch: 9
2022-12-05 22:55:31,895 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5966556590389122, 'Total loss': 0.5966556590389122} | train loss {'Reaction outcome loss': 0.5595491385581542, 'Total loss': 0.5595491385581542}
2022-12-05 22:55:31,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:31,895 INFO:     Epoch: 10
2022-12-05 22:55:32,598 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6335467438806187, 'Total loss': 0.6335467438806187} | train loss {'Reaction outcome loss': 0.5486991601330894, 'Total loss': 0.5486991601330894}
2022-12-05 22:55:32,599 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:32,599 INFO:     Epoch: 11
2022-12-05 22:55:33,302 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5958062423901125, 'Total loss': 0.5958062423901125} | train loss {'Reaction outcome loss': 0.5606495070214175, 'Total loss': 0.5606495070214175}
2022-12-05 22:55:33,302 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:33,302 INFO:     Epoch: 12
2022-12-05 22:55:34,008 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5868831441145052, 'Total loss': 0.5868831441145052} | train loss {'Reaction outcome loss': 0.5510908279491931, 'Total loss': 0.5510908279491931}
2022-12-05 22:55:34,009 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:34,009 INFO:     Epoch: 13
2022-12-05 22:55:34,710 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5662017491730776, 'Total loss': 0.5662017491730776} | train loss {'Reaction outcome loss': 0.544214506781831, 'Total loss': 0.544214506781831}
2022-12-05 22:55:34,710 INFO:     Found new best model at epoch 13
2022-12-05 22:55:34,711 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:34,711 INFO:     Epoch: 14
2022-12-05 22:55:35,414 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.6214974204247649, 'Total loss': 0.6214974204247649} | train loss {'Reaction outcome loss': 0.5435798343955254, 'Total loss': 0.5435798343955254}
2022-12-05 22:55:35,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:35,415 INFO:     Epoch: 15
2022-12-05 22:55:36,120 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5969980779019269, 'Total loss': 0.5969980779019269} | train loss {'Reaction outcome loss': 0.5433225240634412, 'Total loss': 0.5433225240634412}
2022-12-05 22:55:36,120 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:36,120 INFO:     Epoch: 16
2022-12-05 22:55:36,823 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5792237730188803, 'Total loss': 0.5792237730188803} | train loss {'Reaction outcome loss': 0.5470322115080697, 'Total loss': 0.5470322115080697}
2022-12-05 22:55:36,823 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:36,823 INFO:     Epoch: 17
2022-12-05 22:55:37,528 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5656677736816081, 'Total loss': 0.5656677736816081} | train loss {'Reaction outcome loss': 0.5411707282674556, 'Total loss': 0.5411707282674556}
2022-12-05 22:55:37,528 INFO:     Found new best model at epoch 17
2022-12-05 22:55:37,529 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:37,529 INFO:     Epoch: 18
2022-12-05 22:55:38,230 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.61085571822795, 'Total loss': 0.61085571822795} | train loss {'Reaction outcome loss': 0.5423913888177093, 'Total loss': 0.5423913888177093}
2022-12-05 22:55:38,231 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:38,231 INFO:     Epoch: 19
2022-12-05 22:55:38,939 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5853604037653316, 'Total loss': 0.5853604037653316} | train loss {'Reaction outcome loss': 0.5458920878415205, 'Total loss': 0.5458920878415205}
2022-12-05 22:55:38,939 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:38,939 INFO:     Epoch: 20
2022-12-05 22:55:39,647 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5720275315371427, 'Total loss': 0.5720275315371427} | train loss {'Reaction outcome loss': 0.546199033576615, 'Total loss': 0.546199033576615}
2022-12-05 22:55:39,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:39,647 INFO:     Epoch: 21
2022-12-05 22:55:40,352 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.6403774910352447, 'Total loss': 0.6403774910352447} | train loss {'Reaction outcome loss': 0.530343868598646, 'Total loss': 0.530343868598646}
2022-12-05 22:55:40,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:40,352 INFO:     Epoch: 22
2022-12-05 22:55:41,055 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5889862823215398, 'Total loss': 0.5889862823215398} | train loss {'Reaction outcome loss': 0.5302568137645721, 'Total loss': 0.5302568137645721}
2022-12-05 22:55:41,055 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:41,055 INFO:     Epoch: 23
2022-12-05 22:55:41,758 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5501719540493055, 'Total loss': 0.5501719540493055} | train loss {'Reaction outcome loss': 0.5319444972641614, 'Total loss': 0.5319444972641614}
2022-12-05 22:55:41,758 INFO:     Found new best model at epoch 23
2022-12-05 22:55:41,758 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:41,759 INFO:     Epoch: 24
2022-12-05 22:55:42,461 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5617541081526063, 'Total loss': 0.5617541081526063} | train loss {'Reaction outcome loss': 0.5396460320876569, 'Total loss': 0.5396460320876569}
2022-12-05 22:55:42,461 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:42,461 INFO:     Epoch: 25
2022-12-05 22:55:43,167 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.6131811426444487, 'Total loss': 0.6131811426444487} | train loss {'Reaction outcome loss': 0.5401861721155595, 'Total loss': 0.5401861721155595}
2022-12-05 22:55:43,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:43,168 INFO:     Epoch: 26
2022-12-05 22:55:43,872 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.578530282120813, 'Total loss': 0.578530282120813} | train loss {'Reaction outcome loss': 0.5328838803330246, 'Total loss': 0.5328838803330246}
2022-12-05 22:55:43,872 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:43,872 INFO:     Epoch: 27
2022-12-05 22:55:44,574 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5869948982515119, 'Total loss': 0.5869948982515119} | train loss {'Reaction outcome loss': 0.5401227719929753, 'Total loss': 0.5401227719929753}
2022-12-05 22:55:44,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:44,575 INFO:     Epoch: 28
2022-12-05 22:55:45,279 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5532018579542637, 'Total loss': 0.5532018579542637} | train loss {'Reaction outcome loss': 0.5280968486046305, 'Total loss': 0.5280968486046305}
2022-12-05 22:55:45,279 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:45,279 INFO:     Epoch: 29
2022-12-05 22:55:45,988 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5729182582687248, 'Total loss': 0.5729182582687248} | train loss {'Reaction outcome loss': 0.536930357862492, 'Total loss': 0.536930357862492}
2022-12-05 22:55:45,988 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:45,988 INFO:     Epoch: 30
2022-12-05 22:55:46,692 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.577157898382707, 'Total loss': 0.577157898382707} | train loss {'Reaction outcome loss': 0.5329061729567391, 'Total loss': 0.5329061729567391}
2022-12-05 22:55:46,693 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:46,693 INFO:     Epoch: 31
2022-12-05 22:55:47,396 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5721761008555238, 'Total loss': 0.5721761008555238} | train loss {'Reaction outcome loss': 0.5315253479140145, 'Total loss': 0.5315253479140145}
2022-12-05 22:55:47,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:47,397 INFO:     Epoch: 32
2022-12-05 22:55:48,104 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5443997396664186, 'Total loss': 0.5443997396664186} | train loss {'Reaction outcome loss': 0.5313972188501942, 'Total loss': 0.5313972188501942}
2022-12-05 22:55:48,104 INFO:     Found new best model at epoch 32
2022-12-05 22:55:48,104 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:48,105 INFO:     Epoch: 33
2022-12-05 22:55:48,806 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.6028227555480871, 'Total loss': 0.6028227555480871} | train loss {'Reaction outcome loss': 0.532348052153782, 'Total loss': 0.532348052153782}
2022-12-05 22:55:48,806 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:48,806 INFO:     Epoch: 34
2022-12-05 22:55:49,507 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5579565333371813, 'Total loss': 0.5579565333371813} | train loss {'Reaction outcome loss': 0.5270580986932832, 'Total loss': 0.5270580986932832}
2022-12-05 22:55:49,507 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:49,507 INFO:     Epoch: 35
2022-12-05 22:55:50,210 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5673582980578596, 'Total loss': 0.5673582980578596} | train loss {'Reaction outcome loss': 0.5284570088800119, 'Total loss': 0.5284570088800119}
2022-12-05 22:55:50,210 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:50,210 INFO:     Epoch: 36
2022-12-05 22:55:50,911 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5628060071983121, 'Total loss': 0.5628060071983121} | train loss {'Reaction outcome loss': 0.5298509584397686, 'Total loss': 0.5298509584397686}
2022-12-05 22:55:50,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:50,911 INFO:     Epoch: 37
2022-12-05 22:55:51,615 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.6324900700287386, 'Total loss': 0.6324900700287386} | train loss {'Reaction outcome loss': 0.5277071469900559, 'Total loss': 0.5277071469900559}
2022-12-05 22:55:51,615 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:51,615 INFO:     Epoch: 38
2022-12-05 22:55:52,323 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5895878462628885, 'Total loss': 0.5895878462628885} | train loss {'Reaction outcome loss': 0.5290002955465901, 'Total loss': 0.5290002955465901}
2022-12-05 22:55:52,323 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:52,323 INFO:     Epoch: 39
2022-12-05 22:55:53,026 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5569258032535965, 'Total loss': 0.5569258032535965} | train loss {'Reaction outcome loss': 0.5251302880292036, 'Total loss': 0.5251302880292036}
2022-12-05 22:55:53,027 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:53,027 INFO:     Epoch: 40
2022-12-05 22:55:53,746 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5576295344667002, 'Total loss': 0.5576295344667002} | train loss {'Reaction outcome loss': 0.5270927724181389, 'Total loss': 0.5270927724181389}
2022-12-05 22:55:53,746 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:53,746 INFO:     Epoch: 41
2022-12-05 22:55:54,453 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5943836915222082, 'Total loss': 0.5943836915222082} | train loss {'Reaction outcome loss': 0.5393956631422043, 'Total loss': 0.5393956631422043}
2022-12-05 22:55:54,453 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:54,453 INFO:     Epoch: 42
2022-12-05 22:55:55,153 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.6052920432253317, 'Total loss': 0.6052920432253317} | train loss {'Reaction outcome loss': 0.527716542932452, 'Total loss': 0.527716542932452}
2022-12-05 22:55:55,153 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:55,153 INFO:     Epoch: 43
2022-12-05 22:55:55,854 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5500846308740702, 'Total loss': 0.5500846308740702} | train loss {'Reaction outcome loss': 0.5228579133749008, 'Total loss': 0.5228579133749008}
2022-12-05 22:55:55,854 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:55,854 INFO:     Epoch: 44
2022-12-05 22:55:56,553 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.592610012401234, 'Total loss': 0.592610012401234} | train loss {'Reaction outcome loss': 0.5315279520896017, 'Total loss': 0.5315279520896017}
2022-12-05 22:55:56,553 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:56,553 INFO:     Epoch: 45
2022-12-05 22:55:57,256 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5479891723529859, 'Total loss': 0.5479891723529859} | train loss {'Reaction outcome loss': 0.5222770089397625, 'Total loss': 0.5222770089397625}
2022-12-05 22:55:57,257 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:57,257 INFO:     Epoch: 46
2022-12-05 22:55:57,962 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.557835806499828, 'Total loss': 0.557835806499828} | train loss {'Reaction outcome loss': 0.5328241929715993, 'Total loss': 0.5328241929715993}
2022-12-05 22:55:57,963 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:57,963 INFO:     Epoch: 47
2022-12-05 22:55:58,660 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5586911345070059, 'Total loss': 0.5586911345070059} | train loss {'Reaction outcome loss': 0.5288326678227405, 'Total loss': 0.5288326678227405}
2022-12-05 22:55:58,660 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:58,661 INFO:     Epoch: 48
2022-12-05 22:55:59,358 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5506092679094184, 'Total loss': 0.5506092679094184} | train loss {'Reaction outcome loss': 0.5242751062524562, 'Total loss': 0.5242751062524562}
2022-12-05 22:55:59,358 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:55:59,359 INFO:     Epoch: 49
2022-12-05 22:56:00,060 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5642854232679714, 'Total loss': 0.5642854232679714} | train loss {'Reaction outcome loss': 0.5265644550323486, 'Total loss': 0.5265644550323486}
2022-12-05 22:56:00,060 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:00,060 INFO:     Epoch: 50
2022-12-05 22:56:00,768 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5695496526631442, 'Total loss': 0.5695496526631442} | train loss {'Reaction outcome loss': 0.5241965386332298, 'Total loss': 0.5241965386332298}
2022-12-05 22:56:00,768 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:00,768 INFO:     Epoch: 51
2022-12-05 22:56:01,468 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5859826704995199, 'Total loss': 0.5859826704995199} | train loss {'Reaction outcome loss': 0.527205509433941, 'Total loss': 0.527205509433941}
2022-12-05 22:56:01,468 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:01,468 INFO:     Epoch: 52
2022-12-05 22:56:02,167 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5499332479455254, 'Total loss': 0.5499332479455254} | train loss {'Reaction outcome loss': 0.5249378420868699, 'Total loss': 0.5249378420868699}
2022-12-05 22:56:02,167 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:02,167 INFO:     Epoch: 53
2022-12-05 22:56:02,865 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5673487572507425, 'Total loss': 0.5673487572507425} | train loss {'Reaction outcome loss': 0.5327577534987002, 'Total loss': 0.5327577534987002}
2022-12-05 22:56:02,865 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:02,865 INFO:     Epoch: 54
2022-12-05 22:56:03,562 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5682200027460401, 'Total loss': 0.5682200027460401} | train loss {'Reaction outcome loss': 0.5254128800362957, 'Total loss': 0.5254128800362957}
2022-12-05 22:56:03,562 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:03,563 INFO:     Epoch: 55
2022-12-05 22:56:04,265 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5444293770600449, 'Total loss': 0.5444293770600449} | train loss {'Reaction outcome loss': 0.5315696513166233, 'Total loss': 0.5315696513166233}
2022-12-05 22:56:04,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:04,266 INFO:     Epoch: 56
2022-12-05 22:56:04,966 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5668334534222429, 'Total loss': 0.5668334534222429} | train loss {'Reaction outcome loss': 0.5175172765036018, 'Total loss': 0.5175172765036018}
2022-12-05 22:56:04,967 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:04,967 INFO:     Epoch: 57
2022-12-05 22:56:05,665 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5433686778626658, 'Total loss': 0.5433686778626658} | train loss {'Reaction outcome loss': 0.5263180272919791, 'Total loss': 0.5263180272919791}
2022-12-05 22:56:05,665 INFO:     Found new best model at epoch 57
2022-12-05 22:56:05,666 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:05,666 INFO:     Epoch: 58
2022-12-05 22:56:06,369 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5526876158334992, 'Total loss': 0.5526876158334992} | train loss {'Reaction outcome loss': 0.523277550692461, 'Total loss': 0.523277550692461}
2022-12-05 22:56:06,369 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:06,369 INFO:     Epoch: 59
2022-12-05 22:56:07,069 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5657208582217043, 'Total loss': 0.5657208582217043} | train loss {'Reaction outcome loss': 0.5313021745000567, 'Total loss': 0.5313021745000567}
2022-12-05 22:56:07,069 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:07,069 INFO:     Epoch: 60
2022-12-05 22:56:07,768 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5455398170954802, 'Total loss': 0.5455398170954802} | train loss {'Reaction outcome loss': 0.5294312399869062, 'Total loss': 0.5294312399869062}
2022-12-05 22:56:07,768 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:07,768 INFO:     Epoch: 61
2022-12-05 22:56:08,470 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.6270260560241613, 'Total loss': 0.6270260560241613} | train loss {'Reaction outcome loss': 0.5295364254591416, 'Total loss': 0.5295364254591416}
2022-12-05 22:56:08,470 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:08,470 INFO:     Epoch: 62
2022-12-05 22:56:09,172 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5542020584371957, 'Total loss': 0.5542020584371957} | train loss {'Reaction outcome loss': 0.5274226560884593, 'Total loss': 0.5274226560884593}
2022-12-05 22:56:09,172 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:09,172 INFO:     Epoch: 63
2022-12-05 22:56:09,871 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5958751714365049, 'Total loss': 0.5958751714365049} | train loss {'Reaction outcome loss': 0.5270038657042445, 'Total loss': 0.5270038657042445}
2022-12-05 22:56:09,872 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:09,872 INFO:     Epoch: 64
2022-12-05 22:56:10,572 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.578333278271285, 'Total loss': 0.578333278271285} | train loss {'Reaction outcome loss': 0.5246253417462718, 'Total loss': 0.5246253417462718}
2022-12-05 22:56:10,572 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:10,572 INFO:     Epoch: 65
2022-12-05 22:56:11,272 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5787507031451572, 'Total loss': 0.5787507031451572} | train loss {'Reaction outcome loss': 0.5204035854461242, 'Total loss': 0.5204035854461242}
2022-12-05 22:56:11,272 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:11,273 INFO:     Epoch: 66
2022-12-05 22:56:11,971 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.6452028165486726, 'Total loss': 0.6452028165486726} | train loss {'Reaction outcome loss': 0.5257469824990447, 'Total loss': 0.5257469824990447}
2022-12-05 22:56:11,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:11,971 INFO:     Epoch: 67
2022-12-05 22:56:12,671 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5416012213311412, 'Total loss': 0.5416012213311412} | train loss {'Reaction outcome loss': 0.5259616233864609, 'Total loss': 0.5259616233864609}
2022-12-05 22:56:12,671 INFO:     Found new best model at epoch 67
2022-12-05 22:56:12,672 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:12,672 INFO:     Epoch: 68
2022-12-05 22:56:13,370 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5659352505410259, 'Total loss': 0.5659352505410259} | train loss {'Reaction outcome loss': 0.5223917675869806, 'Total loss': 0.5223917675869806}
2022-12-05 22:56:13,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:13,370 INFO:     Epoch: 69
2022-12-05 22:56:14,068 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5300112225284631, 'Total loss': 0.5300112225284631} | train loss {'Reaction outcome loss': 0.5201341724517394, 'Total loss': 0.5201341724517394}
2022-12-05 22:56:14,068 INFO:     Found new best model at epoch 69
2022-12-05 22:56:14,069 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:14,069 INFO:     Epoch: 70
2022-12-05 22:56:14,768 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5714101886207407, 'Total loss': 0.5714101886207407} | train loss {'Reaction outcome loss': 0.5247222662884362, 'Total loss': 0.5247222662884362}
2022-12-05 22:56:14,769 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:14,769 INFO:     Epoch: 71
2022-12-05 22:56:15,469 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.537542459639636, 'Total loss': 0.537542459639636} | train loss {'Reaction outcome loss': 0.5246377332478154, 'Total loss': 0.5246377332478154}
2022-12-05 22:56:15,469 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:15,469 INFO:     Epoch: 72
2022-12-05 22:56:16,168 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5786995721811597, 'Total loss': 0.5786995721811597} | train loss {'Reaction outcome loss': 0.5265470948754525, 'Total loss': 0.5265470948754525}
2022-12-05 22:56:16,169 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:16,169 INFO:     Epoch: 73
2022-12-05 22:56:16,868 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5546074259010229, 'Total loss': 0.5546074259010229} | train loss {'Reaction outcome loss': 0.524482350902898, 'Total loss': 0.524482350902898}
2022-12-05 22:56:16,868 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:16,868 INFO:     Epoch: 74
2022-12-05 22:56:17,567 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5737550390714948, 'Total loss': 0.5737550390714948} | train loss {'Reaction outcome loss': 0.5205063733519341, 'Total loss': 0.5205063733519341}
2022-12-05 22:56:17,568 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:17,568 INFO:     Epoch: 75
2022-12-05 22:56:18,270 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5718735083937645, 'Total loss': 0.5718735083937645} | train loss {'Reaction outcome loss': 0.5271289403341255, 'Total loss': 0.5271289403341255}
2022-12-05 22:56:18,270 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:18,270 INFO:     Epoch: 76
2022-12-05 22:56:18,972 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5428941762921485, 'Total loss': 0.5428941762921485} | train loss {'Reaction outcome loss': 0.526295329630375, 'Total loss': 0.526295329630375}
2022-12-05 22:56:18,972 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:18,972 INFO:     Epoch: 77
2022-12-05 22:56:19,671 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5410614125430584, 'Total loss': 0.5410614125430584} | train loss {'Reaction outcome loss': 0.5273137912458303, 'Total loss': 0.5273137912458303}
2022-12-05 22:56:19,671 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:19,671 INFO:     Epoch: 78
2022-12-05 22:56:20,373 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5449734265831384, 'Total loss': 0.5449734265831384} | train loss {'Reaction outcome loss': 0.5292322131443997, 'Total loss': 0.5292322131443997}
2022-12-05 22:56:20,373 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:20,373 INFO:     Epoch: 79
2022-12-05 22:56:21,076 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5585253502834927, 'Total loss': 0.5585253502834927} | train loss {'Reaction outcome loss': 0.5268276898228392, 'Total loss': 0.5268276898228392}
2022-12-05 22:56:21,077 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:21,077 INFO:     Epoch: 80
2022-12-05 22:56:21,780 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6148593730547212, 'Total loss': 0.6148593730547212} | train loss {'Reaction outcome loss': 0.5248078444782569, 'Total loss': 0.5248078444782569}
2022-12-05 22:56:21,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:21,780 INFO:     Epoch: 81
2022-12-05 22:56:22,484 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5639807649634101, 'Total loss': 0.5639807649634101} | train loss {'Reaction outcome loss': 0.5329130167863807, 'Total loss': 0.5329130167863807}
2022-12-05 22:56:22,484 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:22,484 INFO:     Epoch: 82
2022-12-05 22:56:23,185 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5745223943482746, 'Total loss': 0.5745223943482746} | train loss {'Reaction outcome loss': 0.5204731141426125, 'Total loss': 0.5204731141426125}
2022-12-05 22:56:23,185 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:23,185 INFO:     Epoch: 83
2022-12-05 22:56:23,884 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5681919157505035, 'Total loss': 0.5681919157505035} | train loss {'Reaction outcome loss': 0.5280758542673928, 'Total loss': 0.5280758542673928}
2022-12-05 22:56:23,884 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:23,884 INFO:     Epoch: 84
2022-12-05 22:56:24,586 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5498418658971786, 'Total loss': 0.5498418658971786} | train loss {'Reaction outcome loss': 0.5203910586785297, 'Total loss': 0.5203910586785297}
2022-12-05 22:56:24,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:24,586 INFO:     Epoch: 85
2022-12-05 22:56:25,288 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5591044773093679, 'Total loss': 0.5591044773093679} | train loss {'Reaction outcome loss': 0.5199322792340298, 'Total loss': 0.5199322792340298}
2022-12-05 22:56:25,289 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:25,289 INFO:     Epoch: 86
2022-12-05 22:56:25,989 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6043813452124596, 'Total loss': 0.6043813452124596} | train loss {'Reaction outcome loss': 0.529687387724312, 'Total loss': 0.529687387724312}
2022-12-05 22:56:25,989 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:25,989 INFO:     Epoch: 87
2022-12-05 22:56:26,693 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5558138994330709, 'Total loss': 0.5558138994330709} | train loss {'Reaction outcome loss': 0.5192979606438656, 'Total loss': 0.5192979606438656}
2022-12-05 22:56:26,693 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:26,693 INFO:     Epoch: 88
2022-12-05 22:56:27,394 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5653273402289911, 'Total loss': 0.5653273402289911} | train loss {'Reaction outcome loss': 0.5276974411643282, 'Total loss': 0.5276974411643282}
2022-12-05 22:56:27,394 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:27,394 INFO:     Epoch: 89
2022-12-05 22:56:28,093 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5806325992399995, 'Total loss': 0.5806325992399995} | train loss {'Reaction outcome loss': 0.525035629162983, 'Total loss': 0.525035629162983}
2022-12-05 22:56:28,094 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:28,094 INFO:     Epoch: 90
2022-12-05 22:56:28,793 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5649255077269945, 'Total loss': 0.5649255077269945} | train loss {'Reaction outcome loss': 0.5253084707625059, 'Total loss': 0.5253084707625059}
2022-12-05 22:56:28,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:28,794 INFO:     Epoch: 91
2022-12-05 22:56:29,495 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5582803162661466, 'Total loss': 0.5582803162661466} | train loss {'Reaction outcome loss': 0.5233670434781483, 'Total loss': 0.5233670434781483}
2022-12-05 22:56:29,495 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:29,495 INFO:     Epoch: 92
2022-12-05 22:56:30,197 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5558220066807487, 'Total loss': 0.5558220066807487} | train loss {'Reaction outcome loss': 0.520045288728208, 'Total loss': 0.520045288728208}
2022-12-05 22:56:30,197 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:30,197 INFO:     Epoch: 93
2022-12-05 22:56:30,896 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5581954751502384, 'Total loss': 0.5581954751502384} | train loss {'Reaction outcome loss': 0.5229133491613427, 'Total loss': 0.5229133491613427}
2022-12-05 22:56:30,896 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:30,896 INFO:     Epoch: 94
2022-12-05 22:56:31,597 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5713850415565751, 'Total loss': 0.5713850415565751} | train loss {'Reaction outcome loss': 0.5280814035206425, 'Total loss': 0.5280814035206425}
2022-12-05 22:56:31,597 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:31,597 INFO:     Epoch: 95
2022-12-05 22:56:32,303 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5683252242478457, 'Total loss': 0.5683252242478457} | train loss {'Reaction outcome loss': 0.5149525268345463, 'Total loss': 0.5149525268345463}
2022-12-05 22:56:32,303 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:32,303 INFO:     Epoch: 96
2022-12-05 22:56:33,007 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5467541339722547, 'Total loss': 0.5467541339722547} | train loss {'Reaction outcome loss': 0.5237060495785304, 'Total loss': 0.5237060495785304}
2022-12-05 22:56:33,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:33,007 INFO:     Epoch: 97
2022-12-05 22:56:33,706 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5680251615968618, 'Total loss': 0.5680251615968618} | train loss {'Reaction outcome loss': 0.5234363933607024, 'Total loss': 0.5234363933607024}
2022-12-05 22:56:33,707 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:33,707 INFO:     Epoch: 98
2022-12-05 22:56:34,407 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5785720521076159, 'Total loss': 0.5785720521076159} | train loss {'Reaction outcome loss': 0.5327997671706336, 'Total loss': 0.5327997671706336}
2022-12-05 22:56:34,407 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:34,407 INFO:     Epoch: 99
2022-12-05 22:56:35,112 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.562061595307155, 'Total loss': 0.562061595307155} | train loss {'Reaction outcome loss': 0.5234527209583594, 'Total loss': 0.5234527209583594}
2022-12-05 22:56:35,112 INFO:     Best model found after epoch 70 of 100.
2022-12-05 22:56:35,113 INFO:   Done with stage: TRAINING
2022-12-05 22:56:35,113 INFO:   Starting stage: EVALUATION
2022-12-05 22:56:35,242 INFO:   Done with stage: EVALUATION
2022-12-05 22:56:35,242 INFO:   Leaving out SEQ value Fold_3
2022-12-05 22:56:35,255 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 22:56:35,255 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:56:35,887 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:56:35,887 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:56:35,957 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:56:35,957 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:56:35,957 INFO:     No hyperparam tuning for this model
2022-12-05 22:56:35,957 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:56:35,957 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:56:35,958 INFO:     None feature selector for col prot
2022-12-05 22:56:35,958 INFO:     None feature selector for col prot
2022-12-05 22:56:35,958 INFO:     None feature selector for col prot
2022-12-05 22:56:35,959 INFO:     None feature selector for col chem
2022-12-05 22:56:35,959 INFO:     None feature selector for col chem
2022-12-05 22:56:35,959 INFO:     None feature selector for col chem
2022-12-05 22:56:35,959 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:56:35,959 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:56:35,961 INFO:     Number of params in model 215731
2022-12-05 22:56:35,964 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:56:35,964 INFO:   Starting stage: TRAINING
2022-12-05 22:56:36,021 INFO:     Val loss before train {'Reaction outcome loss': 1.0202992780264033, 'Total loss': 1.0202992780264033}
2022-12-05 22:56:36,021 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:36,021 INFO:     Epoch: 0
2022-12-05 22:56:36,723 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7197373883668766, 'Total loss': 0.7197373883668766} | train loss {'Reaction outcome loss': 0.8077950396987258, 'Total loss': 0.8077950396987258}
2022-12-05 22:56:36,723 INFO:     Found new best model at epoch 0
2022-12-05 22:56:36,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:36,724 INFO:     Epoch: 1
2022-12-05 22:56:37,424 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6691450622192648, 'Total loss': 0.6691450622192648} | train loss {'Reaction outcome loss': 0.6674121613385248, 'Total loss': 0.6674121613385248}
2022-12-05 22:56:37,425 INFO:     Found new best model at epoch 1
2022-12-05 22:56:37,425 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:37,425 INFO:     Epoch: 2
2022-12-05 22:56:38,127 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6334527391333913, 'Total loss': 0.6334527391333913} | train loss {'Reaction outcome loss': 0.6258230838375013, 'Total loss': 0.6258230838375013}
2022-12-05 22:56:38,127 INFO:     Found new best model at epoch 2
2022-12-05 22:56:38,128 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:38,128 INFO:     Epoch: 3
2022-12-05 22:56:38,823 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.657088331704916, 'Total loss': 0.657088331704916} | train loss {'Reaction outcome loss': 0.5909481621423706, 'Total loss': 0.5909481621423706}
2022-12-05 22:56:38,823 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:38,823 INFO:     Epoch: 4
2022-12-05 22:56:39,517 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6135967533255733, 'Total loss': 0.6135967533255733} | train loss {'Reaction outcome loss': 0.5879674130043046, 'Total loss': 0.5879674130043046}
2022-12-05 22:56:39,517 INFO:     Found new best model at epoch 4
2022-12-05 22:56:39,518 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:39,518 INFO:     Epoch: 5
2022-12-05 22:56:40,214 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5689913526523945, 'Total loss': 0.5689913526523945} | train loss {'Reaction outcome loss': 0.5672543466579719, 'Total loss': 0.5672543466579719}
2022-12-05 22:56:40,215 INFO:     Found new best model at epoch 5
2022-12-05 22:56:40,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:40,216 INFO:     Epoch: 6
2022-12-05 22:56:40,910 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6039853033631347, 'Total loss': 0.6039853033631347} | train loss {'Reaction outcome loss': 0.5670605359568459, 'Total loss': 0.5670605359568459}
2022-12-05 22:56:40,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:40,911 INFO:     Epoch: 7
2022-12-05 22:56:41,607 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5880459838135298, 'Total loss': 0.5880459838135298} | train loss {'Reaction outcome loss': 0.5661293356145014, 'Total loss': 0.5661293356145014}
2022-12-05 22:56:41,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:41,607 INFO:     Epoch: 8
2022-12-05 22:56:42,304 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5948296833870023, 'Total loss': 0.5948296833870023} | train loss {'Reaction outcome loss': 0.5576238776328134, 'Total loss': 0.5576238776328134}
2022-12-05 22:56:42,304 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:42,304 INFO:     Epoch: 9
2022-12-05 22:56:42,998 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5780240148305893, 'Total loss': 0.5780240148305893} | train loss {'Reaction outcome loss': 0.5564516919558166, 'Total loss': 0.5564516919558166}
2022-12-05 22:56:42,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:42,998 INFO:     Epoch: 10
2022-12-05 22:56:43,696 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6108954493389573, 'Total loss': 0.6108954493389573} | train loss {'Reaction outcome loss': 0.553625475432052, 'Total loss': 0.553625475432052}
2022-12-05 22:56:43,696 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:43,697 INFO:     Epoch: 11
2022-12-05 22:56:44,394 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.602734099293864, 'Total loss': 0.602734099293864} | train loss {'Reaction outcome loss': 0.5512887361596842, 'Total loss': 0.5512887361596842}
2022-12-05 22:56:44,395 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:44,395 INFO:     Epoch: 12
2022-12-05 22:56:45,090 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.620689062878143, 'Total loss': 0.620689062878143} | train loss {'Reaction outcome loss': 0.5398281626403332, 'Total loss': 0.5398281626403332}
2022-12-05 22:56:45,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:45,090 INFO:     Epoch: 13
2022-12-05 22:56:45,789 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5844868698785471, 'Total loss': 0.5844868698785471} | train loss {'Reaction outcome loss': 0.5389665004293449, 'Total loss': 0.5389665004293449}
2022-12-05 22:56:45,789 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:45,790 INFO:     Epoch: 14
2022-12-05 22:56:46,492 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5944837886233663, 'Total loss': 0.5944837886233663} | train loss {'Reaction outcome loss': 0.5394060478591528, 'Total loss': 0.5394060478591528}
2022-12-05 22:56:46,493 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:46,493 INFO:     Epoch: 15
2022-12-05 22:56:47,189 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5423119511715201, 'Total loss': 0.5423119511715201} | train loss {'Reaction outcome loss': 0.5363272415687803, 'Total loss': 0.5363272415687803}
2022-12-05 22:56:47,189 INFO:     Found new best model at epoch 15
2022-12-05 22:56:47,189 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:47,190 INFO:     Epoch: 16
2022-12-05 22:56:47,885 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5514776956203372, 'Total loss': 0.5514776956203372} | train loss {'Reaction outcome loss': 0.5362092893509591, 'Total loss': 0.5362092893509591}
2022-12-05 22:56:47,885 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:47,885 INFO:     Epoch: 17
2022-12-05 22:56:48,583 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5559073818284411, 'Total loss': 0.5559073818284411} | train loss {'Reaction outcome loss': 0.5277413381416289, 'Total loss': 0.5277413381416289}
2022-12-05 22:56:48,583 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:48,583 INFO:     Epoch: 18
2022-12-05 22:56:49,277 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5465146753677103, 'Total loss': 0.5465146753677103} | train loss {'Reaction outcome loss': 0.5273630243466526, 'Total loss': 0.5273630243466526}
2022-12-05 22:56:49,277 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:49,277 INFO:     Epoch: 19
2022-12-05 22:56:49,972 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5289214516794959, 'Total loss': 0.5289214516794959} | train loss {'Reaction outcome loss': 0.5272681431570014, 'Total loss': 0.5272681431570014}
2022-12-05 22:56:49,972 INFO:     Found new best model at epoch 19
2022-12-05 22:56:49,972 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:49,973 INFO:     Epoch: 20
2022-12-05 22:56:50,668 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.547381118979565, 'Total loss': 0.547381118979565} | train loss {'Reaction outcome loss': 0.529700112452761, 'Total loss': 0.529700112452761}
2022-12-05 22:56:50,668 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:50,668 INFO:     Epoch: 21
2022-12-05 22:56:51,362 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5959126845348713, 'Total loss': 0.5959126845348713} | train loss {'Reaction outcome loss': 0.5290221995750412, 'Total loss': 0.5290221995750412}
2022-12-05 22:56:51,363 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:51,363 INFO:     Epoch: 22
2022-12-05 22:56:52,063 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5491417275611744, 'Total loss': 0.5491417275611744} | train loss {'Reaction outcome loss': 0.5300565591601075, 'Total loss': 0.5300565591601075}
2022-12-05 22:56:52,063 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:52,063 INFO:     Epoch: 23
2022-12-05 22:56:52,758 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5590299298596937, 'Total loss': 0.5590299298596937} | train loss {'Reaction outcome loss': 0.5267255318457963, 'Total loss': 0.5267255318457963}
2022-12-05 22:56:52,759 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:52,759 INFO:     Epoch: 24
2022-12-05 22:56:53,453 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.6019761118777963, 'Total loss': 0.6019761118777963} | train loss {'Reaction outcome loss': 0.5297406447104743, 'Total loss': 0.5297406447104743}
2022-12-05 22:56:53,454 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:53,454 INFO:     Epoch: 25
2022-12-05 22:56:54,150 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5512511674747911, 'Total loss': 0.5512511674747911} | train loss {'Reaction outcome loss': 0.5225887012164123, 'Total loss': 0.5225887012164123}
2022-12-05 22:56:54,150 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:54,150 INFO:     Epoch: 26
2022-12-05 22:56:54,844 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.532464335824168, 'Total loss': 0.532464335824168} | train loss {'Reaction outcome loss': 0.5304439517318226, 'Total loss': 0.5304439517318226}
2022-12-05 22:56:54,844 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:54,844 INFO:     Epoch: 27
2022-12-05 22:56:55,542 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5389339421377626, 'Total loss': 0.5389339421377626} | train loss {'Reaction outcome loss': 0.529722872388656, 'Total loss': 0.529722872388656}
2022-12-05 22:56:55,542 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:55,542 INFO:     Epoch: 28
2022-12-05 22:56:56,240 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5412678091331969, 'Total loss': 0.5412678091331969} | train loss {'Reaction outcome loss': 0.5243181635732533, 'Total loss': 0.5243181635732533}
2022-12-05 22:56:56,240 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:56,240 INFO:     Epoch: 29
2022-12-05 22:56:56,938 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5503042187801627, 'Total loss': 0.5503042187801627} | train loss {'Reaction outcome loss': 0.5273354457782917, 'Total loss': 0.5273354457782917}
2022-12-05 22:56:56,938 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:56,938 INFO:     Epoch: 30
2022-12-05 22:56:57,636 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5608923230753389, 'Total loss': 0.5608923230753389} | train loss {'Reaction outcome loss': 0.5273339191421134, 'Total loss': 0.5273339191421134}
2022-12-05 22:56:57,636 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:57,637 INFO:     Epoch: 31
2022-12-05 22:56:58,339 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5644358867822692, 'Total loss': 0.5644358867822692} | train loss {'Reaction outcome loss': 0.5240600468804602, 'Total loss': 0.5240600468804602}
2022-12-05 22:56:58,340 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:58,340 INFO:     Epoch: 32
2022-12-05 22:56:59,036 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5471489990866462, 'Total loss': 0.5471489990866462} | train loss {'Reaction outcome loss': 0.5335787037601236, 'Total loss': 0.5335787037601236}
2022-12-05 22:56:59,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:59,037 INFO:     Epoch: 33
2022-12-05 22:56:59,735 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5711017632207205, 'Total loss': 0.5711017632207205} | train loss {'Reaction outcome loss': 0.5232597159557655, 'Total loss': 0.5232597159557655}
2022-12-05 22:56:59,735 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:56:59,735 INFO:     Epoch: 34
2022-12-05 22:57:00,432 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.572187788264696, 'Total loss': 0.572187788264696} | train loss {'Reaction outcome loss': 0.5257051598097457, 'Total loss': 0.5257051598097457}
2022-12-05 22:57:00,432 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:00,432 INFO:     Epoch: 35
2022-12-05 22:57:01,132 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.551787292194921, 'Total loss': 0.551787292194921} | train loss {'Reaction outcome loss': 0.5304314279776128, 'Total loss': 0.5304314279776128}
2022-12-05 22:57:01,133 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:01,133 INFO:     Epoch: 36
2022-12-05 22:57:01,831 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5728977204755296, 'Total loss': 0.5728977204755296} | train loss {'Reaction outcome loss': 0.5206440013573795, 'Total loss': 0.5206440013573795}
2022-12-05 22:57:01,831 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:01,831 INFO:     Epoch: 37
2022-12-05 22:57:02,526 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5421925769295803, 'Total loss': 0.5421925769295803} | train loss {'Reaction outcome loss': 0.5251735073865437, 'Total loss': 0.5251735073865437}
2022-12-05 22:57:02,526 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:02,526 INFO:     Epoch: 38
2022-12-05 22:57:03,221 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5528680398020633, 'Total loss': 0.5528680398020633} | train loss {'Reaction outcome loss': 0.5255695004321512, 'Total loss': 0.5255695004321512}
2022-12-05 22:57:03,221 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:03,222 INFO:     Epoch: 39
2022-12-05 22:57:03,920 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5385839842086615, 'Total loss': 0.5385839842086615} | train loss {'Reaction outcome loss': 0.521621859281278, 'Total loss': 0.521621859281278}
2022-12-05 22:57:03,920 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:03,920 INFO:     Epoch: 40
2022-12-05 22:57:04,615 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.573270454656246, 'Total loss': 0.573270454656246} | train loss {'Reaction outcome loss': 0.522390460687094, 'Total loss': 0.522390460687094}
2022-12-05 22:57:04,616 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:04,616 INFO:     Epoch: 41
2022-12-05 22:57:05,310 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5438769567151402, 'Total loss': 0.5438769567151402} | train loss {'Reaction outcome loss': 0.5270919247118176, 'Total loss': 0.5270919247118176}
2022-12-05 22:57:05,310 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:05,311 INFO:     Epoch: 42
2022-12-05 22:57:06,011 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5682052699632423, 'Total loss': 0.5682052699632423} | train loss {'Reaction outcome loss': 0.5304413045161083, 'Total loss': 0.5304413045161083}
2022-12-05 22:57:06,011 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:06,011 INFO:     Epoch: 43
2022-12-05 22:57:06,714 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5471698142761408, 'Total loss': 0.5471698142761408} | train loss {'Reaction outcome loss': 0.5294931610343886, 'Total loss': 0.5294931610343886}
2022-12-05 22:57:06,714 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:06,714 INFO:     Epoch: 44
2022-12-05 22:57:07,411 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5665511315645173, 'Total loss': 0.5665511315645173} | train loss {'Reaction outcome loss': 0.5290831628515095, 'Total loss': 0.5290831628515095}
2022-12-05 22:57:07,411 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:07,411 INFO:     Epoch: 45
2022-12-05 22:57:08,105 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5476428984209548, 'Total loss': 0.5476428984209548} | train loss {'Reaction outcome loss': 0.5234870377500527, 'Total loss': 0.5234870377500527}
2022-12-05 22:57:08,105 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:08,105 INFO:     Epoch: 46
2022-12-05 22:57:08,799 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.563710822268974, 'Total loss': 0.563710822268974} | train loss {'Reaction outcome loss': 0.5224710302885438, 'Total loss': 0.5224710302885438}
2022-12-05 22:57:08,800 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:08,800 INFO:     Epoch: 47
2022-12-05 22:57:09,501 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5523797876613085, 'Total loss': 0.5523797876613085} | train loss {'Reaction outcome loss': 0.5231998945723791, 'Total loss': 0.5231998945723791}
2022-12-05 22:57:09,501 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:09,501 INFO:     Epoch: 48
2022-12-05 22:57:10,198 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5482358745364255, 'Total loss': 0.5482358745364255} | train loss {'Reaction outcome loss': 0.5285110625087238, 'Total loss': 0.5285110625087238}
2022-12-05 22:57:10,198 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:10,198 INFO:     Epoch: 49
2022-12-05 22:57:10,893 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5548291552898496, 'Total loss': 0.5548291552898496} | train loss {'Reaction outcome loss': 0.5246260170443137, 'Total loss': 0.5246260170443137}
2022-12-05 22:57:10,893 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:10,893 INFO:     Epoch: 50
2022-12-05 22:57:11,591 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5451458924731543, 'Total loss': 0.5451458924731543} | train loss {'Reaction outcome loss': 0.5226000798408126, 'Total loss': 0.5226000798408126}
2022-12-05 22:57:11,592 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:11,592 INFO:     Epoch: 51
2022-12-05 22:57:12,287 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5561466168525607, 'Total loss': 0.5561466168525607} | train loss {'Reaction outcome loss': 0.5211552511595312, 'Total loss': 0.5211552511595312}
2022-12-05 22:57:12,287 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:12,287 INFO:     Epoch: 52
2022-12-05 22:57:12,982 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5640840343264646, 'Total loss': 0.5640840343264646} | train loss {'Reaction outcome loss': 0.5258030132314221, 'Total loss': 0.5258030132314221}
2022-12-05 22:57:12,982 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:12,982 INFO:     Epoch: 53
2022-12-05 22:57:13,679 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5452963238538697, 'Total loss': 0.5452963238538697} | train loss {'Reaction outcome loss': 0.5279211729887079, 'Total loss': 0.5279211729887079}
2022-12-05 22:57:13,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:13,680 INFO:     Epoch: 54
2022-12-05 22:57:14,377 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5560743483000024, 'Total loss': 0.5560743483000024} | train loss {'Reaction outcome loss': 0.5305043229924851, 'Total loss': 0.5305043229924851}
2022-12-05 22:57:14,377 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:14,377 INFO:     Epoch: 55
2022-12-05 22:57:15,075 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5581718052542487, 'Total loss': 0.5581718052542487} | train loss {'Reaction outcome loss': 0.5261506297182842, 'Total loss': 0.5261506297182842}
2022-12-05 22:57:15,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:15,075 INFO:     Epoch: 56
2022-12-05 22:57:15,776 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.535030996037084, 'Total loss': 0.535030996037084} | train loss {'Reaction outcome loss': 0.5229637908642409, 'Total loss': 0.5229637908642409}
2022-12-05 22:57:15,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:15,776 INFO:     Epoch: 57
2022-12-05 22:57:16,474 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.55804954711781, 'Total loss': 0.55804954711781} | train loss {'Reaction outcome loss': 0.5276713163637724, 'Total loss': 0.5276713163637724}
2022-12-05 22:57:16,474 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:16,474 INFO:     Epoch: 58
2022-12-05 22:57:17,171 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5465522734231727, 'Total loss': 0.5465522734231727} | train loss {'Reaction outcome loss': 0.5306386217230656, 'Total loss': 0.5306386217230656}
2022-12-05 22:57:17,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:17,171 INFO:     Epoch: 59
2022-12-05 22:57:17,869 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5437295090320499, 'Total loss': 0.5437295090320499} | train loss {'Reaction outcome loss': 0.5280952100626758, 'Total loss': 0.5280952100626758}
2022-12-05 22:57:17,870 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:17,870 INFO:     Epoch: 60
2022-12-05 22:57:18,565 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5610914538766063, 'Total loss': 0.5610914538766063} | train loss {'Reaction outcome loss': 0.5236687500823717, 'Total loss': 0.5236687500823717}
2022-12-05 22:57:18,565 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:18,565 INFO:     Epoch: 61
2022-12-05 22:57:19,266 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5724519525849542, 'Total loss': 0.5724519525849542} | train loss {'Reaction outcome loss': 0.5284314859108846, 'Total loss': 0.5284314859108846}
2022-12-05 22:57:19,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:19,266 INFO:     Epoch: 62
2022-12-05 22:57:19,961 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.543533168213312, 'Total loss': 0.543533168213312} | train loss {'Reaction outcome loss': 0.5261453194085692, 'Total loss': 0.5261453194085692}
2022-12-05 22:57:19,961 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:19,961 INFO:     Epoch: 63
2022-12-05 22:57:20,656 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5817511788634366, 'Total loss': 0.5817511788634366} | train loss {'Reaction outcome loss': 0.51962387543477, 'Total loss': 0.51962387543477}
2022-12-05 22:57:20,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:20,656 INFO:     Epoch: 64
2022-12-05 22:57:21,352 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5442143820746, 'Total loss': 0.5442143820746} | train loss {'Reaction outcome loss': 0.5203411290880109, 'Total loss': 0.5203411290880109}
2022-12-05 22:57:21,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:21,352 INFO:     Epoch: 65
2022-12-05 22:57:22,051 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5480803438397341, 'Total loss': 0.5480803438397341} | train loss {'Reaction outcome loss': 0.5271906889364367, 'Total loss': 0.5271906889364367}
2022-12-05 22:57:22,052 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:22,052 INFO:     Epoch: 66
2022-12-05 22:57:22,750 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5480525521344917, 'Total loss': 0.5480525521344917} | train loss {'Reaction outcome loss': 0.5202256551042932, 'Total loss': 0.5202256551042932}
2022-12-05 22:57:22,751 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:22,751 INFO:     Epoch: 67
2022-12-05 22:57:23,454 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5509711490120999, 'Total loss': 0.5509711490120999} | train loss {'Reaction outcome loss': 0.5237036559608628, 'Total loss': 0.5237036559608628}
2022-12-05 22:57:23,454 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:23,455 INFO:     Epoch: 68
2022-12-05 22:57:24,149 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.579897674363713, 'Total loss': 0.579897674363713} | train loss {'Reaction outcome loss': 0.5188440555309664, 'Total loss': 0.5188440555309664}
2022-12-05 22:57:24,150 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:24,150 INFO:     Epoch: 69
2022-12-05 22:57:24,844 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5324700228696646, 'Total loss': 0.5324700228696646} | train loss {'Reaction outcome loss': 0.5274702531636738, 'Total loss': 0.5274702531636738}
2022-12-05 22:57:24,845 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:24,845 INFO:     Epoch: 70
2022-12-05 22:57:25,540 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5531720442827358, 'Total loss': 0.5531720442827358} | train loss {'Reaction outcome loss': 0.5314296176199054, 'Total loss': 0.5314296176199054}
2022-12-05 22:57:25,540 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:25,540 INFO:     Epoch: 71
2022-12-05 22:57:26,234 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5385200682767602, 'Total loss': 0.5385200682767602} | train loss {'Reaction outcome loss': 0.5188439534213699, 'Total loss': 0.5188439534213699}
2022-12-05 22:57:26,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:26,234 INFO:     Epoch: 72
2022-12-05 22:57:26,931 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5924095386682555, 'Total loss': 0.5924095386682555} | train loss {'Reaction outcome loss': 0.5243286023863026, 'Total loss': 0.5243286023863026}
2022-12-05 22:57:26,932 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:26,932 INFO:     Epoch: 73
2022-12-05 22:57:27,628 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5850625356962514, 'Total loss': 0.5850625356962514} | train loss {'Reaction outcome loss': 0.5210202979992647, 'Total loss': 0.5210202979992647}
2022-12-05 22:57:27,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:27,628 INFO:     Epoch: 74
2022-12-05 22:57:28,324 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5405413951984671, 'Total loss': 0.5405413951984671} | train loss {'Reaction outcome loss': 0.5310648787217062, 'Total loss': 0.5310648787217062}
2022-12-05 22:57:28,324 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:28,324 INFO:     Epoch: 75
2022-12-05 22:57:29,022 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5813351231952046, 'Total loss': 0.5813351231952046} | train loss {'Reaction outcome loss': 0.5166356129968752, 'Total loss': 0.5166356129968752}
2022-12-05 22:57:29,022 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:29,022 INFO:     Epoch: 76
2022-12-05 22:57:29,722 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5705768919961397, 'Total loss': 0.5705768919961397} | train loss {'Reaction outcome loss': 0.5296013566558478, 'Total loss': 0.5296013566558478}
2022-12-05 22:57:29,722 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:29,722 INFO:     Epoch: 77
2022-12-05 22:57:30,417 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5375984813584838, 'Total loss': 0.5375984813584838} | train loss {'Reaction outcome loss': 0.532514964215091, 'Total loss': 0.532514964215091}
2022-12-05 22:57:30,418 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:30,418 INFO:     Epoch: 78
2022-12-05 22:57:31,118 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5499618510867275, 'Total loss': 0.5499618510867275} | train loss {'Reaction outcome loss': 0.5233597982003063, 'Total loss': 0.5233597982003063}
2022-12-05 22:57:31,118 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:31,118 INFO:     Epoch: 79
2022-12-05 22:57:31,813 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5470010201598323, 'Total loss': 0.5470010201598323} | train loss {'Reaction outcome loss': 0.519906077839312, 'Total loss': 0.519906077839312}
2022-12-05 22:57:31,813 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:31,813 INFO:     Epoch: 80
2022-12-05 22:57:32,512 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.537204947582511, 'Total loss': 0.537204947582511} | train loss {'Reaction outcome loss': 0.5269748967934827, 'Total loss': 0.5269748967934827}
2022-12-05 22:57:32,512 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:32,512 INFO:     Epoch: 81
2022-12-05 22:57:33,206 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5312215949213782, 'Total loss': 0.5312215949213782} | train loss {'Reaction outcome loss': 0.5293129599485241, 'Total loss': 0.5293129599485241}
2022-12-05 22:57:33,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:33,206 INFO:     Epoch: 82
2022-12-05 22:57:33,900 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5423841552678929, 'Total loss': 0.5423841552678929} | train loss {'Reaction outcome loss': 0.5215701739319035, 'Total loss': 0.5215701739319035}
2022-12-05 22:57:33,900 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:33,900 INFO:     Epoch: 83
2022-12-05 22:57:34,598 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5467434844305349, 'Total loss': 0.5467434844305349} | train loss {'Reaction outcome loss': 0.5236268292685025, 'Total loss': 0.5236268292685025}
2022-12-05 22:57:34,598 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:34,598 INFO:     Epoch: 84
2022-12-05 22:57:35,294 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6090443737285082, 'Total loss': 0.6090443737285082} | train loss {'Reaction outcome loss': 0.5269833301789448, 'Total loss': 0.5269833301789448}
2022-12-05 22:57:35,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:35,294 INFO:     Epoch: 85
2022-12-05 22:57:35,988 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5507380504940831, 'Total loss': 0.5507380504940831} | train loss {'Reaction outcome loss': 0.528097178603782, 'Total loss': 0.528097178603782}
2022-12-05 22:57:35,988 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:35,988 INFO:     Epoch: 86
2022-12-05 22:57:36,684 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.552502170551655, 'Total loss': 0.552502170551655} | train loss {'Reaction outcome loss': 0.5302619576820584, 'Total loss': 0.5302619576820584}
2022-12-05 22:57:36,684 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:36,684 INFO:     Epoch: 87
2022-12-05 22:57:37,379 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5387678132500759, 'Total loss': 0.5387678132500759} | train loss {'Reaction outcome loss': 0.528065346608885, 'Total loss': 0.528065346608885}
2022-12-05 22:57:37,379 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:37,379 INFO:     Epoch: 88
2022-12-05 22:57:38,073 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5422370589749758, 'Total loss': 0.5422370589749758} | train loss {'Reaction outcome loss': 0.5244827353258114, 'Total loss': 0.5244827353258114}
2022-12-05 22:57:38,073 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:38,073 INFO:     Epoch: 89
2022-12-05 22:57:38,771 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5528853175251983, 'Total loss': 0.5528853175251983} | train loss {'Reaction outcome loss': 0.523681920510335, 'Total loss': 0.523681920510335}
2022-12-05 22:57:38,772 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:38,772 INFO:     Epoch: 90
2022-12-05 22:57:39,466 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5973120082256406, 'Total loss': 0.5973120082256406} | train loss {'Reaction outcome loss': 0.5249837453736633, 'Total loss': 0.5249837453736633}
2022-12-05 22:57:39,466 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:39,466 INFO:     Epoch: 91
2022-12-05 22:57:40,165 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5716640540333682, 'Total loss': 0.5716640540333682} | train loss {'Reaction outcome loss': 0.5276846893009592, 'Total loss': 0.5276846893009592}
2022-12-05 22:57:40,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:40,166 INFO:     Epoch: 92
2022-12-05 22:57:40,866 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5437739325124163, 'Total loss': 0.5437739325124163} | train loss {'Reaction outcome loss': 0.5344505282576943, 'Total loss': 0.5344505282576943}
2022-12-05 22:57:40,867 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:40,867 INFO:     Epoch: 93
2022-12-05 22:57:41,565 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5490210160266521, 'Total loss': 0.5490210160266521} | train loss {'Reaction outcome loss': 0.5305983066314557, 'Total loss': 0.5305983066314557}
2022-12-05 22:57:41,565 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:41,565 INFO:     Epoch: 94
2022-12-05 22:57:42,266 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5663114931694296, 'Total loss': 0.5663114931694296} | train loss {'Reaction outcome loss': 0.521376235929669, 'Total loss': 0.521376235929669}
2022-12-05 22:57:42,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:42,266 INFO:     Epoch: 95
2022-12-05 22:57:42,961 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5683747398298841, 'Total loss': 0.5683747398298841} | train loss {'Reaction outcome loss': 0.525120345722945, 'Total loss': 0.525120345722945}
2022-12-05 22:57:42,962 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:42,962 INFO:     Epoch: 96
2022-12-05 22:57:43,656 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5557453597700873, 'Total loss': 0.5557453597700873} | train loss {'Reaction outcome loss': 0.5304709227725131, 'Total loss': 0.5304709227725131}
2022-12-05 22:57:43,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:43,657 INFO:     Epoch: 97
2022-12-05 22:57:44,354 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6066981692646825, 'Total loss': 0.6066981692646825} | train loss {'Reaction outcome loss': 0.5241511403048624, 'Total loss': 0.5241511403048624}
2022-12-05 22:57:44,354 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:44,355 INFO:     Epoch: 98
2022-12-05 22:57:45,050 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.563423368126847, 'Total loss': 0.563423368126847} | train loss {'Reaction outcome loss': 0.5248647504409806, 'Total loss': 0.5248647504409806}
2022-12-05 22:57:45,050 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:45,050 INFO:     Epoch: 99
2022-12-05 22:57:45,745 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.537252937985021, 'Total loss': 0.537252937985021} | train loss {'Reaction outcome loss': 0.5227909753190689, 'Total loss': 0.5227909753190689}
2022-12-05 22:57:45,745 INFO:     Best model found after epoch 20 of 100.
2022-12-05 22:57:45,745 INFO:   Done with stage: TRAINING
2022-12-05 22:57:45,746 INFO:   Starting stage: EVALUATION
2022-12-05 22:57:45,880 INFO:   Done with stage: EVALUATION
2022-12-05 22:57:45,880 INFO:   Leaving out SEQ value Fold_4
2022-12-05 22:57:45,893 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 22:57:45,893 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:57:46,539 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:57:46,539 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:57:46,610 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:57:46,610 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:57:46,610 INFO:     No hyperparam tuning for this model
2022-12-05 22:57:46,610 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:57:46,610 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:57:46,611 INFO:     None feature selector for col prot
2022-12-05 22:57:46,611 INFO:     None feature selector for col prot
2022-12-05 22:57:46,611 INFO:     None feature selector for col prot
2022-12-05 22:57:46,611 INFO:     None feature selector for col chem
2022-12-05 22:57:46,612 INFO:     None feature selector for col chem
2022-12-05 22:57:46,612 INFO:     None feature selector for col chem
2022-12-05 22:57:46,612 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:57:46,612 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:57:46,613 INFO:     Number of params in model 215731
2022-12-05 22:57:46,616 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:57:46,616 INFO:   Starting stage: TRAINING
2022-12-05 22:57:46,674 INFO:     Val loss before train {'Reaction outcome loss': 1.0024026767774061, 'Total loss': 1.0024026767774061}
2022-12-05 22:57:46,674 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:46,674 INFO:     Epoch: 0
2022-12-05 22:57:47,375 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7398041425780817, 'Total loss': 0.7398041425780817} | train loss {'Reaction outcome loss': 0.8217063687285598, 'Total loss': 0.8217063687285598}
2022-12-05 22:57:47,375 INFO:     Found new best model at epoch 0
2022-12-05 22:57:47,376 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:47,376 INFO:     Epoch: 1
2022-12-05 22:57:48,073 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6724194315346804, 'Total loss': 0.6724194315346804} | train loss {'Reaction outcome loss': 0.7024159701503053, 'Total loss': 0.7024159701503053}
2022-12-05 22:57:48,073 INFO:     Found new best model at epoch 1
2022-12-05 22:57:48,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:48,074 INFO:     Epoch: 2
2022-12-05 22:57:48,778 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6071473278782584, 'Total loss': 0.6071473278782584} | train loss {'Reaction outcome loss': 0.6648728250240793, 'Total loss': 0.6648728250240793}
2022-12-05 22:57:48,779 INFO:     Found new best model at epoch 2
2022-12-05 22:57:48,779 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:48,779 INFO:     Epoch: 3
2022-12-05 22:57:49,482 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5724499848755923, 'Total loss': 0.5724499848755923} | train loss {'Reaction outcome loss': 0.6293635745437778, 'Total loss': 0.6293635745437778}
2022-12-05 22:57:49,483 INFO:     Found new best model at epoch 3
2022-12-05 22:57:49,484 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:49,484 INFO:     Epoch: 4
2022-12-05 22:57:50,189 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5602807185866616, 'Total loss': 0.5602807185866616} | train loss {'Reaction outcome loss': 0.601631646496909, 'Total loss': 0.601631646496909}
2022-12-05 22:57:50,189 INFO:     Found new best model at epoch 4
2022-12-05 22:57:50,190 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:50,190 INFO:     Epoch: 5
2022-12-05 22:57:50,894 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.597095634449612, 'Total loss': 0.597095634449612} | train loss {'Reaction outcome loss': 0.5952592970765367, 'Total loss': 0.5952592970765367}
2022-12-05 22:57:50,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:50,894 INFO:     Epoch: 6
2022-12-05 22:57:51,599 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5792531140825965, 'Total loss': 0.5792531140825965} | train loss {'Reaction outcome loss': 0.5818671646775032, 'Total loss': 0.5818671646775032}
2022-12-05 22:57:51,599 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:51,599 INFO:     Epoch: 7
2022-12-05 22:57:52,299 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5954886133020575, 'Total loss': 0.5954886133020575} | train loss {'Reaction outcome loss': 0.5786679985571881, 'Total loss': 0.5786679985571881}
2022-12-05 22:57:52,299 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:52,299 INFO:     Epoch: 8
2022-12-05 22:57:53,000 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5450751104138114, 'Total loss': 0.5450751104138114} | train loss {'Reaction outcome loss': 0.5752225536472944, 'Total loss': 0.5752225536472944}
2022-12-05 22:57:53,000 INFO:     Found new best model at epoch 8
2022-12-05 22:57:53,000 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:53,001 INFO:     Epoch: 9
2022-12-05 22:57:53,700 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.53889080949805, 'Total loss': 0.53889080949805} | train loss {'Reaction outcome loss': 0.5688650409786069, 'Total loss': 0.5688650409786069}
2022-12-05 22:57:53,700 INFO:     Found new best model at epoch 9
2022-12-05 22:57:53,701 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:53,701 INFO:     Epoch: 10
2022-12-05 22:57:54,403 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5493707633153959, 'Total loss': 0.5493707633153959} | train loss {'Reaction outcome loss': 0.5598374999299341, 'Total loss': 0.5598374999299341}
2022-12-05 22:57:54,404 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:54,404 INFO:     Epoch: 11
2022-12-05 22:57:55,104 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5156090384857221, 'Total loss': 0.5156090384857221} | train loss {'Reaction outcome loss': 0.5612129386590452, 'Total loss': 0.5612129386590452}
2022-12-05 22:57:55,104 INFO:     Found new best model at epoch 11
2022-12-05 22:57:55,105 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:55,105 INFO:     Epoch: 12
2022-12-05 22:57:55,805 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.553970780223608, 'Total loss': 0.553970780223608} | train loss {'Reaction outcome loss': 0.5618727588531922, 'Total loss': 0.5618727588531922}
2022-12-05 22:57:55,805 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:55,805 INFO:     Epoch: 13
2022-12-05 22:57:56,506 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.553904729810628, 'Total loss': 0.553904729810628} | train loss {'Reaction outcome loss': 0.5618262526332115, 'Total loss': 0.5618262526332115}
2022-12-05 22:57:56,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:56,506 INFO:     Epoch: 14
2022-12-05 22:57:57,204 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5610663206739859, 'Total loss': 0.5610663206739859} | train loss {'Reaction outcome loss': 0.5648020977268413, 'Total loss': 0.5648020977268413}
2022-12-05 22:57:57,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:57,205 INFO:     Epoch: 15
2022-12-05 22:57:57,905 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5555414279753511, 'Total loss': 0.5555414279753511} | train loss {'Reaction outcome loss': 0.5541445986348755, 'Total loss': 0.5541445986348755}
2022-12-05 22:57:57,905 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:57,905 INFO:     Epoch: 16
2022-12-05 22:57:58,604 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5338180776346814, 'Total loss': 0.5338180776346814} | train loss {'Reaction outcome loss': 0.5590380255056887, 'Total loss': 0.5590380255056887}
2022-12-05 22:57:58,604 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:58,604 INFO:     Epoch: 17
2022-12-05 22:57:59,301 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5462569025429812, 'Total loss': 0.5462569025429812} | train loss {'Reaction outcome loss': 0.5478698906849842, 'Total loss': 0.5478698906849842}
2022-12-05 22:57:59,301 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:57:59,301 INFO:     Epoch: 18
2022-12-05 22:58:00,002 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5144433314827356, 'Total loss': 0.5144433314827356} | train loss {'Reaction outcome loss': 0.5610822543197749, 'Total loss': 0.5610822543197749}
2022-12-05 22:58:00,002 INFO:     Found new best model at epoch 18
2022-12-05 22:58:00,003 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:00,003 INFO:     Epoch: 19
2022-12-05 22:58:00,702 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5250563523308798, 'Total loss': 0.5250563523308798} | train loss {'Reaction outcome loss': 0.5504847406124582, 'Total loss': 0.5504847406124582}
2022-12-05 22:58:00,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:00,703 INFO:     Epoch: 20
2022-12-05 22:58:01,400 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5579256831922315, 'Total loss': 0.5579256831922315} | train loss {'Reaction outcome loss': 0.5541208966654174, 'Total loss': 0.5541208966654174}
2022-12-05 22:58:01,400 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:01,400 INFO:     Epoch: 21
2022-12-05 22:58:02,098 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5564250173893842, 'Total loss': 0.5564250173893842} | train loss {'Reaction outcome loss': 0.5469333801342516, 'Total loss': 0.5469333801342516}
2022-12-05 22:58:02,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:02,099 INFO:     Epoch: 22
2022-12-05 22:58:02,797 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5399842658503489, 'Total loss': 0.5399842658503489} | train loss {'Reaction outcome loss': 0.5435210951736995, 'Total loss': 0.5435210951736995}
2022-12-05 22:58:02,797 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:02,797 INFO:     Epoch: 23
2022-12-05 22:58:03,494 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5439907122742046, 'Total loss': 0.5439907122742046} | train loss {'Reaction outcome loss': 0.5486815993883172, 'Total loss': 0.5486815993883172}
2022-12-05 22:58:03,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:03,495 INFO:     Epoch: 24
2022-12-05 22:58:04,192 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49825235388495703, 'Total loss': 0.49825235388495703} | train loss {'Reaction outcome loss': 0.546219189069709, 'Total loss': 0.546219189069709}
2022-12-05 22:58:04,192 INFO:     Found new best model at epoch 24
2022-12-05 22:58:04,192 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:04,193 INFO:     Epoch: 25
2022-12-05 22:58:04,894 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5002889697524634, 'Total loss': 0.5002889697524634} | train loss {'Reaction outcome loss': 0.5411457856698912, 'Total loss': 0.5411457856698912}
2022-12-05 22:58:04,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:04,894 INFO:     Epoch: 26
2022-12-05 22:58:05,595 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5326058173721487, 'Total loss': 0.5326058173721487} | train loss {'Reaction outcome loss': 0.5425137090439699, 'Total loss': 0.5425137090439699}
2022-12-05 22:58:05,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:05,596 INFO:     Epoch: 27
2022-12-05 22:58:06,296 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5676662996411324, 'Total loss': 0.5676662996411324} | train loss {'Reaction outcome loss': 0.5396530420196299, 'Total loss': 0.5396530420196299}
2022-12-05 22:58:06,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:06,296 INFO:     Epoch: 28
2022-12-05 22:58:06,995 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5408997549252077, 'Total loss': 0.5408997549252077} | train loss {'Reaction outcome loss': 0.5309886698211942, 'Total loss': 0.5309886698211942}
2022-12-05 22:58:06,995 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:06,995 INFO:     Epoch: 29
2022-12-05 22:58:07,693 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5055330355059017, 'Total loss': 0.5055330355059017} | train loss {'Reaction outcome loss': 0.5418408071508213, 'Total loss': 0.5418408071508213}
2022-12-05 22:58:07,693 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:07,693 INFO:     Epoch: 30
2022-12-05 22:58:08,391 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5028631931001489, 'Total loss': 0.5028631931001489} | train loss {'Reaction outcome loss': 0.5304093750155702, 'Total loss': 0.5304093750155702}
2022-12-05 22:58:08,391 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:08,392 INFO:     Epoch: 31
2022-12-05 22:58:09,089 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5599549839442427, 'Total loss': 0.5599549839442427} | train loss {'Reaction outcome loss': 0.5340850333170015, 'Total loss': 0.5340850333170015}
2022-12-05 22:58:09,089 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:09,089 INFO:     Epoch: 32
2022-12-05 22:58:09,788 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5010269971733744, 'Total loss': 0.5010269971733744} | train loss {'Reaction outcome loss': 0.5314232765411844, 'Total loss': 0.5314232765411844}
2022-12-05 22:58:09,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:09,788 INFO:     Epoch: 33
2022-12-05 22:58:10,491 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5320467535745014, 'Total loss': 0.5320467535745014} | train loss {'Reaction outcome loss': 0.532497955037623, 'Total loss': 0.532497955037623}
2022-12-05 22:58:10,492 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:10,492 INFO:     Epoch: 34
2022-12-05 22:58:11,196 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5016259415583177, 'Total loss': 0.5016259415583177} | train loss {'Reaction outcome loss': 0.5314347152807275, 'Total loss': 0.5314347152807275}
2022-12-05 22:58:11,196 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:11,196 INFO:     Epoch: 35
2022-12-05 22:58:11,894 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5539115274494345, 'Total loss': 0.5539115274494345} | train loss {'Reaction outcome loss': 0.5272305945352632, 'Total loss': 0.5272305945352632}
2022-12-05 22:58:11,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:11,894 INFO:     Epoch: 36
2022-12-05 22:58:12,594 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4785545432770794, 'Total loss': 0.4785545432770794} | train loss {'Reaction outcome loss': 0.5299082503635056, 'Total loss': 0.5299082503635056}
2022-12-05 22:58:12,595 INFO:     Found new best model at epoch 36
2022-12-05 22:58:12,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:12,595 INFO:     Epoch: 37
2022-12-05 22:58:13,297 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5282408496872946, 'Total loss': 0.5282408496872946} | train loss {'Reaction outcome loss': 0.5223773368767329, 'Total loss': 0.5223773368767329}
2022-12-05 22:58:13,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:13,297 INFO:     Epoch: 38
2022-12-05 22:58:13,997 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5386023209853605, 'Total loss': 0.5386023209853605} | train loss {'Reaction outcome loss': 0.5352732812871739, 'Total loss': 0.5352732812871739}
2022-12-05 22:58:13,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:13,998 INFO:     Epoch: 39
2022-12-05 22:58:14,700 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49946070462465286, 'Total loss': 0.49946070462465286} | train loss {'Reaction outcome loss': 0.5256074287453476, 'Total loss': 0.5256074287453476}
2022-12-05 22:58:14,700 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:14,700 INFO:     Epoch: 40
2022-12-05 22:58:15,398 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49989585849371826, 'Total loss': 0.49989585849371826} | train loss {'Reaction outcome loss': 0.5257388674483008, 'Total loss': 0.5257388674483008}
2022-12-05 22:58:15,398 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:15,398 INFO:     Epoch: 41
2022-12-05 22:58:16,096 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5194992007349025, 'Total loss': 0.5194992007349025} | train loss {'Reaction outcome loss': 0.5232054199491228, 'Total loss': 0.5232054199491228}
2022-12-05 22:58:16,096 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:16,097 INFO:     Epoch: 42
2022-12-05 22:58:16,799 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49194608425552194, 'Total loss': 0.49194608425552194} | train loss {'Reaction outcome loss': 0.5227690707664101, 'Total loss': 0.5227690707664101}
2022-12-05 22:58:16,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:16,799 INFO:     Epoch: 43
2022-12-05 22:58:17,500 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4988039420409636, 'Total loss': 0.4988039420409636} | train loss {'Reaction outcome loss': 0.5150331083305028, 'Total loss': 0.5150331083305028}
2022-12-05 22:58:17,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:17,500 INFO:     Epoch: 44
2022-12-05 22:58:18,202 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5590647465803407, 'Total loss': 0.5590647465803407} | train loss {'Reaction outcome loss': 0.5227903310741697, 'Total loss': 0.5227903310741697}
2022-12-05 22:58:18,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:18,202 INFO:     Epoch: 45
2022-12-05 22:58:18,906 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.48662937635725195, 'Total loss': 0.48662937635725195} | train loss {'Reaction outcome loss': 0.5218564924536919, 'Total loss': 0.5218564924536919}
2022-12-05 22:58:18,907 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:18,907 INFO:     Epoch: 46
2022-12-05 22:58:19,605 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5028028745542873, 'Total loss': 0.5028028745542873} | train loss {'Reaction outcome loss': 0.5225607925531816, 'Total loss': 0.5225607925531816}
2022-12-05 22:58:19,605 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:19,605 INFO:     Epoch: 47
2022-12-05 22:58:20,304 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47738810256123543, 'Total loss': 0.47738810256123543} | train loss {'Reaction outcome loss': 0.5122426706309221, 'Total loss': 0.5122426706309221}
2022-12-05 22:58:20,305 INFO:     Found new best model at epoch 47
2022-12-05 22:58:20,306 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:20,306 INFO:     Epoch: 48
2022-12-05 22:58:21,004 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4859256426465105, 'Total loss': 0.4859256426465105} | train loss {'Reaction outcome loss': 0.5178140271683128, 'Total loss': 0.5178140271683128}
2022-12-05 22:58:21,004 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:21,004 INFO:     Epoch: 49
2022-12-05 22:58:21,706 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5087711682373827, 'Total loss': 0.5087711682373827} | train loss {'Reaction outcome loss': 0.5221225393061735, 'Total loss': 0.5221225393061735}
2022-12-05 22:58:21,706 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:21,707 INFO:     Epoch: 50
2022-12-05 22:58:22,411 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4929469792934304, 'Total loss': 0.4929469792934304} | train loss {'Reaction outcome loss': 0.5155017554151768, 'Total loss': 0.5155017554151768}
2022-12-05 22:58:22,411 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:22,411 INFO:     Epoch: 51
2022-12-05 22:58:23,113 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5069409554654901, 'Total loss': 0.5069409554654901} | train loss {'Reaction outcome loss': 0.5159681455821407, 'Total loss': 0.5159681455821407}
2022-12-05 22:58:23,113 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:23,113 INFO:     Epoch: 52
2022-12-05 22:58:23,810 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4946985447948629, 'Total loss': 0.4946985447948629} | train loss {'Reaction outcome loss': 0.5139740314410657, 'Total loss': 0.5139740314410657}
2022-12-05 22:58:23,810 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:23,810 INFO:     Epoch: 53
2022-12-05 22:58:24,507 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5013854310593822, 'Total loss': 0.5013854310593822} | train loss {'Reaction outcome loss': 0.521807330360218, 'Total loss': 0.521807330360218}
2022-12-05 22:58:24,508 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:24,508 INFO:     Epoch: 54
2022-12-05 22:58:25,205 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.485000496560877, 'Total loss': 0.485000496560877} | train loss {'Reaction outcome loss': 0.5201954730311219, 'Total loss': 0.5201954730311219}
2022-12-05 22:58:25,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:25,205 INFO:     Epoch: 55
2022-12-05 22:58:25,901 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.503405989909714, 'Total loss': 0.503405989909714} | train loss {'Reaction outcome loss': 0.522234219495131, 'Total loss': 0.522234219495131}
2022-12-05 22:58:25,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:25,902 INFO:     Epoch: 56
2022-12-05 22:58:26,603 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48906474289568985, 'Total loss': 0.48906474289568985} | train loss {'Reaction outcome loss': 0.513014422387493, 'Total loss': 0.513014422387493}
2022-12-05 22:58:26,603 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:26,603 INFO:     Epoch: 57
2022-12-05 22:58:27,302 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5049219199202277, 'Total loss': 0.5049219199202277} | train loss {'Reaction outcome loss': 0.5214724208019218, 'Total loss': 0.5214724208019218}
2022-12-05 22:58:27,302 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:27,302 INFO:     Epoch: 58
2022-12-05 22:58:28,005 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5079145936126058, 'Total loss': 0.5079145936126058} | train loss {'Reaction outcome loss': 0.5203752882626592, 'Total loss': 0.5203752882626592}
2022-12-05 22:58:28,006 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:28,006 INFO:     Epoch: 59
2022-12-05 22:58:28,703 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5019531314345923, 'Total loss': 0.5019531314345923} | train loss {'Reaction outcome loss': 0.5109043607906419, 'Total loss': 0.5109043607906419}
2022-12-05 22:58:28,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:28,704 INFO:     Epoch: 60
2022-12-05 22:58:29,401 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5096783976663243, 'Total loss': 0.5096783976663243} | train loss {'Reaction outcome loss': 0.5278629165522907, 'Total loss': 0.5278629165522907}
2022-12-05 22:58:29,401 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:29,401 INFO:     Epoch: 61
2022-12-05 22:58:30,100 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4857141599059105, 'Total loss': 0.4857141599059105} | train loss {'Reaction outcome loss': 0.5194569764088611, 'Total loss': 0.5194569764088611}
2022-12-05 22:58:30,100 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:30,100 INFO:     Epoch: 62
2022-12-05 22:58:30,799 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5095187049697746, 'Total loss': 0.5095187049697746} | train loss {'Reaction outcome loss': 0.5213102819360033, 'Total loss': 0.5213102819360033}
2022-12-05 22:58:30,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:30,799 INFO:     Epoch: 63
2022-12-05 22:58:31,497 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5034044506874952, 'Total loss': 0.5034044506874952} | train loss {'Reaction outcome loss': 0.5197419195759053, 'Total loss': 0.5197419195759053}
2022-12-05 22:58:31,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:31,497 INFO:     Epoch: 64
2022-12-05 22:58:32,195 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49513212422078307, 'Total loss': 0.49513212422078307} | train loss {'Reaction outcome loss': 0.5218472782446414, 'Total loss': 0.5218472782446414}
2022-12-05 22:58:32,195 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:32,195 INFO:     Epoch: 65
2022-12-05 22:58:32,894 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4868851378560066, 'Total loss': 0.4868851378560066} | train loss {'Reaction outcome loss': 0.5146552838233053, 'Total loss': 0.5146552838233053}
2022-12-05 22:58:32,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:32,895 INFO:     Epoch: 66
2022-12-05 22:58:33,594 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.502885523844849, 'Total loss': 0.502885523844849} | train loss {'Reaction outcome loss': 0.5197847200899708, 'Total loss': 0.5197847200899708}
2022-12-05 22:58:33,594 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:33,594 INFO:     Epoch: 67
2022-12-05 22:58:34,295 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4673527946526354, 'Total loss': 0.4673527946526354} | train loss {'Reaction outcome loss': 0.5184118572546511, 'Total loss': 0.5184118572546511}
2022-12-05 22:58:34,295 INFO:     Found new best model at epoch 67
2022-12-05 22:58:34,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:34,296 INFO:     Epoch: 68
2022-12-05 22:58:34,997 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4771394370631738, 'Total loss': 0.4771394370631738} | train loss {'Reaction outcome loss': 0.5166391772883279, 'Total loss': 0.5166391772883279}
2022-12-05 22:58:34,997 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:34,997 INFO:     Epoch: 69
2022-12-05 22:58:35,695 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4736898026683114, 'Total loss': 0.4736898026683114} | train loss {'Reaction outcome loss': 0.518287456887109, 'Total loss': 0.518287456887109}
2022-12-05 22:58:35,696 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:35,696 INFO:     Epoch: 70
2022-12-05 22:58:36,393 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48338780856945296, 'Total loss': 0.48338780856945296} | train loss {'Reaction outcome loss': 0.5137853480115229, 'Total loss': 0.5137853480115229}
2022-12-05 22:58:36,393 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:36,393 INFO:     Epoch: 71
2022-12-05 22:58:37,093 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5330300070345402, 'Total loss': 0.5330300070345402} | train loss {'Reaction outcome loss': 0.5171605942808852, 'Total loss': 0.5171605942808852}
2022-12-05 22:58:37,094 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:37,094 INFO:     Epoch: 72
2022-12-05 22:58:37,795 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49537956985560333, 'Total loss': 0.49537956985560333} | train loss {'Reaction outcome loss': 0.5234560367404198, 'Total loss': 0.5234560367404198}
2022-12-05 22:58:37,795 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:37,795 INFO:     Epoch: 73
2022-12-05 22:58:38,494 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48492862995375285, 'Total loss': 0.48492862995375285} | train loss {'Reaction outcome loss': 0.5135078404022723, 'Total loss': 0.5135078404022723}
2022-12-05 22:58:38,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:38,494 INFO:     Epoch: 74
2022-12-05 22:58:39,196 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4965096539394422, 'Total loss': 0.4965096539394422} | train loss {'Reaction outcome loss': 0.518251299614809, 'Total loss': 0.518251299614809}
2022-12-05 22:58:39,196 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:39,196 INFO:     Epoch: 75
2022-12-05 22:58:39,898 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.510456981645389, 'Total loss': 0.510456981645389} | train loss {'Reaction outcome loss': 0.5267012628973747, 'Total loss': 0.5267012628973747}
2022-12-05 22:58:39,898 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:39,898 INFO:     Epoch: 76
2022-12-05 22:58:40,598 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.511366069316864, 'Total loss': 0.511366069316864} | train loss {'Reaction outcome loss': 0.515697888877927, 'Total loss': 0.515697888877927}
2022-12-05 22:58:40,598 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:40,598 INFO:     Epoch: 77
2022-12-05 22:58:41,296 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4813780324025588, 'Total loss': 0.4813780324025588} | train loss {'Reaction outcome loss': 0.5190571739965556, 'Total loss': 0.5190571739965556}
2022-12-05 22:58:41,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:41,297 INFO:     Epoch: 78
2022-12-05 22:58:41,995 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5186270759864287, 'Total loss': 0.5186270759864287} | train loss {'Reaction outcome loss': 0.5209694932309948, 'Total loss': 0.5209694932309948}
2022-12-05 22:58:41,995 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:41,995 INFO:     Epoch: 79
2022-12-05 22:58:42,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5160636448047378, 'Total loss': 0.5160636448047378} | train loss {'Reaction outcome loss': 0.5175290122932318, 'Total loss': 0.5175290122932318}
2022-12-05 22:58:42,695 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:42,695 INFO:     Epoch: 80
2022-12-05 22:58:43,394 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47888080606406386, 'Total loss': 0.47888080606406386} | train loss {'Reaction outcome loss': 0.5096421334816486, 'Total loss': 0.5096421334816486}
2022-12-05 22:58:43,394 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:43,394 INFO:     Epoch: 81
2022-12-05 22:58:44,095 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5151950656013056, 'Total loss': 0.5151950656013056} | train loss {'Reaction outcome loss': 0.5155898918910903, 'Total loss': 0.5155898918910903}
2022-12-05 22:58:44,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:44,095 INFO:     Epoch: 82
2022-12-05 22:58:44,795 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5480442954735323, 'Total loss': 0.5480442954735323} | train loss {'Reaction outcome loss': 0.5219765691428768, 'Total loss': 0.5219765691428768}
2022-12-05 22:58:44,795 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:44,795 INFO:     Epoch: 83
2022-12-05 22:58:45,494 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48926715095612133, 'Total loss': 0.48926715095612133} | train loss {'Reaction outcome loss': 0.5114549933039412, 'Total loss': 0.5114549933039412}
2022-12-05 22:58:45,495 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:45,495 INFO:     Epoch: 84
2022-12-05 22:58:46,205 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5168534524061463, 'Total loss': 0.5168534524061463} | train loss {'Reaction outcome loss': 0.5158671164390992, 'Total loss': 0.5158671164390992}
2022-12-05 22:58:46,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:46,205 INFO:     Epoch: 85
2022-12-05 22:58:46,904 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5569588995792649, 'Total loss': 0.5569588995792649} | train loss {'Reaction outcome loss': 0.5175770892780654, 'Total loss': 0.5175770892780654}
2022-12-05 22:58:46,905 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:46,905 INFO:     Epoch: 86
2022-12-05 22:58:47,606 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5436026812954382, 'Total loss': 0.5436026812954382} | train loss {'Reaction outcome loss': 0.5230847432905313, 'Total loss': 0.5230847432905313}
2022-12-05 22:58:47,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:47,607 INFO:     Epoch: 87
2022-12-05 22:58:48,308 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5057239227674224, 'Total loss': 0.5057239227674224} | train loss {'Reaction outcome loss': 0.5215477987211578, 'Total loss': 0.5215477987211578}
2022-12-05 22:58:48,308 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:48,308 INFO:     Epoch: 88
2022-12-05 22:58:49,013 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47316177866675635, 'Total loss': 0.47316177866675635} | train loss {'Reaction outcome loss': 0.5212688172350124, 'Total loss': 0.5212688172350124}
2022-12-05 22:58:49,014 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:49,014 INFO:     Epoch: 89
2022-12-05 22:58:49,718 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4853644824840806, 'Total loss': 0.4853644824840806} | train loss {'Reaction outcome loss': 0.5139957573949074, 'Total loss': 0.5139957573949074}
2022-12-05 22:58:49,718 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:49,718 INFO:     Epoch: 90
2022-12-05 22:58:50,417 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5178063660860062, 'Total loss': 0.5178063660860062} | train loss {'Reaction outcome loss': 0.5175897004652996, 'Total loss': 0.5175897004652996}
2022-12-05 22:58:50,417 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:50,417 INFO:     Epoch: 91
2022-12-05 22:58:51,119 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.501640322194858, 'Total loss': 0.501640322194858} | train loss {'Reaction outcome loss': 0.5180877546266633, 'Total loss': 0.5180877546266633}
2022-12-05 22:58:51,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:51,120 INFO:     Epoch: 92
2022-12-05 22:58:51,817 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5260768549686129, 'Total loss': 0.5260768549686129} | train loss {'Reaction outcome loss': 0.5252535043930521, 'Total loss': 0.5252535043930521}
2022-12-05 22:58:51,818 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:51,818 INFO:     Epoch: 93
2022-12-05 22:58:52,515 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48451844399625604, 'Total loss': 0.48451844399625604} | train loss {'Reaction outcome loss': 0.5185792097631766, 'Total loss': 0.5185792097631766}
2022-12-05 22:58:52,515 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:52,515 INFO:     Epoch: 94
2022-12-05 22:58:53,213 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5279647094959562, 'Total loss': 0.5279647094959562} | train loss {'Reaction outcome loss': 0.5182766652837092, 'Total loss': 0.5182766652837092}
2022-12-05 22:58:53,213 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:53,213 INFO:     Epoch: 95
2022-12-05 22:58:53,910 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45868365398862143, 'Total loss': 0.45868365398862143} | train loss {'Reaction outcome loss': 0.5213412663766316, 'Total loss': 0.5213412663766316}
2022-12-05 22:58:53,910 INFO:     Found new best model at epoch 95
2022-12-05 22:58:53,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:53,911 INFO:     Epoch: 96
2022-12-05 22:58:54,609 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5200342573225498, 'Total loss': 0.5200342573225498} | train loss {'Reaction outcome loss': 0.5174402851231245, 'Total loss': 0.5174402851231245}
2022-12-05 22:58:54,609 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:54,609 INFO:     Epoch: 97
2022-12-05 22:58:55,307 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4934623431075703, 'Total loss': 0.4934623431075703} | train loss {'Reaction outcome loss': 0.514084959638362, 'Total loss': 0.514084959638362}
2022-12-05 22:58:55,307 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:55,307 INFO:     Epoch: 98
2022-12-05 22:58:56,005 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48242391645908356, 'Total loss': 0.48242391645908356} | train loss {'Reaction outcome loss': 0.5220180690288544, 'Total loss': 0.5220180690288544}
2022-12-05 22:58:56,005 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:56,005 INFO:     Epoch: 99
2022-12-05 22:58:56,703 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5231606035747312, 'Total loss': 0.5231606035747312} | train loss {'Reaction outcome loss': 0.5213513141992141, 'Total loss': 0.5213513141992141}
2022-12-05 22:58:56,703 INFO:     Best model found after epoch 96 of 100.
2022-12-05 22:58:56,703 INFO:   Done with stage: TRAINING
2022-12-05 22:58:56,703 INFO:   Starting stage: EVALUATION
2022-12-05 22:58:56,834 INFO:   Done with stage: EVALUATION
2022-12-05 22:58:56,834 INFO:   Leaving out SEQ value Fold_5
2022-12-05 22:58:56,846 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 22:58:56,846 INFO:   Starting stage: FEATURE SCALING
2022-12-05 22:58:57,493 INFO:   Done with stage: FEATURE SCALING
2022-12-05 22:58:57,494 INFO:   Starting stage: SCALING TARGETS
2022-12-05 22:58:57,566 INFO:   Done with stage: SCALING TARGETS
2022-12-05 22:58:57,566 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:58:57,566 INFO:     No hyperparam tuning for this model
2022-12-05 22:58:57,566 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 22:58:57,566 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 22:58:57,567 INFO:     None feature selector for col prot
2022-12-05 22:58:57,567 INFO:     None feature selector for col prot
2022-12-05 22:58:57,567 INFO:     None feature selector for col prot
2022-12-05 22:58:57,568 INFO:     None feature selector for col chem
2022-12-05 22:58:57,568 INFO:     None feature selector for col chem
2022-12-05 22:58:57,568 INFO:     None feature selector for col chem
2022-12-05 22:58:57,568 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 22:58:57,568 INFO:   Starting stage: BUILD MODEL
2022-12-05 22:58:57,570 INFO:     Number of params in model 215731
2022-12-05 22:58:57,573 INFO:   Done with stage: BUILD MODEL
2022-12-05 22:58:57,573 INFO:   Starting stage: TRAINING
2022-12-05 22:58:57,631 INFO:     Val loss before train {'Reaction outcome loss': 1.0590270784768192, 'Total loss': 1.0590270784768192}
2022-12-05 22:58:57,631 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:57,631 INFO:     Epoch: 0
2022-12-05 22:58:58,336 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7968758662993257, 'Total loss': 0.7968758662993257} | train loss {'Reaction outcome loss': 0.8147864158336933, 'Total loss': 0.8147864158336933}
2022-12-05 22:58:58,337 INFO:     Found new best model at epoch 0
2022-12-05 22:58:58,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:58,337 INFO:     Epoch: 1
2022-12-05 22:58:59,041 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6252879740839655, 'Total loss': 0.6252879740839655} | train loss {'Reaction outcome loss': 0.6996996044388667, 'Total loss': 0.6996996044388667}
2022-12-05 22:58:59,041 INFO:     Found new best model at epoch 1
2022-12-05 22:58:59,042 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:59,042 INFO:     Epoch: 2
2022-12-05 22:58:59,748 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7360377365892584, 'Total loss': 0.7360377365892584} | train loss {'Reaction outcome loss': 0.6118317654786202, 'Total loss': 0.6118317654786202}
2022-12-05 22:58:59,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:58:59,749 INFO:     Epoch: 3
2022-12-05 22:59:00,454 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5712589526718314, 'Total loss': 0.5712589526718314} | train loss {'Reaction outcome loss': 0.58928207413629, 'Total loss': 0.58928207413629}
2022-12-05 22:59:00,455 INFO:     Found new best model at epoch 3
2022-12-05 22:59:00,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:00,455 INFO:     Epoch: 4
2022-12-05 22:59:01,159 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.579619134014303, 'Total loss': 0.579619134014303} | train loss {'Reaction outcome loss': 0.5744189318375066, 'Total loss': 0.5744189318375066}
2022-12-05 22:59:01,159 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:01,159 INFO:     Epoch: 5
2022-12-05 22:59:01,863 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5685557567260482, 'Total loss': 0.5685557567260482} | train loss {'Reaction outcome loss': 0.5603733494998473, 'Total loss': 0.5603733494998473}
2022-12-05 22:59:01,863 INFO:     Found new best model at epoch 5
2022-12-05 22:59:01,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:01,864 INFO:     Epoch: 6
2022-12-05 22:59:02,568 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5860538547011939, 'Total loss': 0.5860538547011939} | train loss {'Reaction outcome loss': 0.5477440116723419, 'Total loss': 0.5477440116723419}
2022-12-05 22:59:02,568 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:02,568 INFO:     Epoch: 7
2022-12-05 22:59:03,271 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5563740649006583, 'Total loss': 0.5563740649006583} | train loss {'Reaction outcome loss': 0.5617957192997218, 'Total loss': 0.5617957192997218}
2022-12-05 22:59:03,271 INFO:     Found new best model at epoch 7
2022-12-05 22:59:03,272 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:03,272 INFO:     Epoch: 8
2022-12-05 22:59:03,978 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5560487850823186, 'Total loss': 0.5560487850823186} | train loss {'Reaction outcome loss': 0.5531356773275112, 'Total loss': 0.5531356773275112}
2022-12-05 22:59:03,979 INFO:     Found new best model at epoch 8
2022-12-05 22:59:03,979 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:03,979 INFO:     Epoch: 9
2022-12-05 22:59:04,683 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.556752313267101, 'Total loss': 0.556752313267101} | train loss {'Reaction outcome loss': 0.5431957448783674, 'Total loss': 0.5431957448783674}
2022-12-05 22:59:04,683 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:04,683 INFO:     Epoch: 10
2022-12-05 22:59:05,389 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5508472513068806, 'Total loss': 0.5508472513068806} | train loss {'Reaction outcome loss': 0.5389225553977586, 'Total loss': 0.5389225553977586}
2022-12-05 22:59:05,389 INFO:     Found new best model at epoch 10
2022-12-05 22:59:05,390 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:05,390 INFO:     Epoch: 11
2022-12-05 22:59:06,093 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.6022716808048162, 'Total loss': 0.6022716808048162} | train loss {'Reaction outcome loss': 0.5470788191083954, 'Total loss': 0.5470788191083954}
2022-12-05 22:59:06,093 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:06,093 INFO:     Epoch: 12
2022-12-05 22:59:06,799 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5438846200704575, 'Total loss': 0.5438846200704575} | train loss {'Reaction outcome loss': 0.5520930746909578, 'Total loss': 0.5520930746909578}
2022-12-05 22:59:06,799 INFO:     Found new best model at epoch 12
2022-12-05 22:59:06,800 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:06,800 INFO:     Epoch: 13
2022-12-05 22:59:07,504 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.531247312372381, 'Total loss': 0.531247312372381} | train loss {'Reaction outcome loss': 0.5364006163650438, 'Total loss': 0.5364006163650438}
2022-12-05 22:59:07,505 INFO:     Found new best model at epoch 13
2022-12-05 22:59:07,505 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:07,505 INFO:     Epoch: 14
2022-12-05 22:59:08,210 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5366716354408048, 'Total loss': 0.5366716354408048} | train loss {'Reaction outcome loss': 0.5436590243930276, 'Total loss': 0.5436590243930276}
2022-12-05 22:59:08,210 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:08,210 INFO:     Epoch: 15
2022-12-05 22:59:08,916 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6175757050514221, 'Total loss': 0.6175757050514221} | train loss {'Reaction outcome loss': 0.5398109638497897, 'Total loss': 0.5398109638497897}
2022-12-05 22:59:08,916 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:08,917 INFO:     Epoch: 16
2022-12-05 22:59:09,624 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5362956381656907, 'Total loss': 0.5362956381656907} | train loss {'Reaction outcome loss': 0.5359608136449265, 'Total loss': 0.5359608136449265}
2022-12-05 22:59:09,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:09,624 INFO:     Epoch: 17
2022-12-05 22:59:10,330 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5812194320288572, 'Total loss': 0.5812194320288572} | train loss {'Reaction outcome loss': 0.5443893450233135, 'Total loss': 0.5443893450233135}
2022-12-05 22:59:10,330 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:10,331 INFO:     Epoch: 18
2022-12-05 22:59:11,037 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.6087113310667601, 'Total loss': 0.6087113310667601} | train loss {'Reaction outcome loss': 0.5341312619838637, 'Total loss': 0.5341312619838637}
2022-12-05 22:59:11,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:11,037 INFO:     Epoch: 19
2022-12-05 22:59:11,741 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.51871418106285, 'Total loss': 0.51871418106285} | train loss {'Reaction outcome loss': 0.5374272998199923, 'Total loss': 0.5374272998199923}
2022-12-05 22:59:11,741 INFO:     Found new best model at epoch 19
2022-12-05 22:59:11,742 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:11,742 INFO:     Epoch: 20
2022-12-05 22:59:12,449 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5642090453342958, 'Total loss': 0.5642090453342958} | train loss {'Reaction outcome loss': 0.5313556362018894, 'Total loss': 0.5313556362018894}
2022-12-05 22:59:12,449 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:12,449 INFO:     Epoch: 21
2022-12-05 22:59:13,154 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5412207516756925, 'Total loss': 0.5412207516756925} | train loss {'Reaction outcome loss': 0.5373721126361415, 'Total loss': 0.5373721126361415}
2022-12-05 22:59:13,155 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:13,155 INFO:     Epoch: 22
2022-12-05 22:59:13,858 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5295148979533802, 'Total loss': 0.5295148979533802} | train loss {'Reaction outcome loss': 0.5350394826910274, 'Total loss': 0.5350394826910274}
2022-12-05 22:59:13,859 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:13,859 INFO:     Epoch: 23
2022-12-05 22:59:14,562 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5487669442187656, 'Total loss': 0.5487669442187656} | train loss {'Reaction outcome loss': 0.5262845822794717, 'Total loss': 0.5262845822794717}
2022-12-05 22:59:14,562 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:14,562 INFO:     Epoch: 24
2022-12-05 22:59:15,269 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5622441714460199, 'Total loss': 0.5622441714460199} | train loss {'Reaction outcome loss': 0.5374919270214281, 'Total loss': 0.5374919270214281}
2022-12-05 22:59:15,269 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:15,269 INFO:     Epoch: 25
2022-12-05 22:59:15,976 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5914668495004828, 'Total loss': 0.5914668495004828} | train loss {'Reaction outcome loss': 0.5382309980419001, 'Total loss': 0.5382309980419001}
2022-12-05 22:59:15,977 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:15,977 INFO:     Epoch: 26
2022-12-05 22:59:16,690 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5443710291927512, 'Total loss': 0.5443710291927512} | train loss {'Reaction outcome loss': 0.5410515724225082, 'Total loss': 0.5410515724225082}
2022-12-05 22:59:16,690 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:16,690 INFO:     Epoch: 27
2022-12-05 22:59:17,403 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5437126308679581, 'Total loss': 0.5437126308679581} | train loss {'Reaction outcome loss': 0.5267780574589123, 'Total loss': 0.5267780574589123}
2022-12-05 22:59:17,403 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:17,403 INFO:     Epoch: 28
2022-12-05 22:59:18,116 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5646656182679263, 'Total loss': 0.5646656182679263} | train loss {'Reaction outcome loss': 0.5347302188636803, 'Total loss': 0.5347302188636803}
2022-12-05 22:59:18,116 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:18,116 INFO:     Epoch: 29
2022-12-05 22:59:18,829 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5393867120146751, 'Total loss': 0.5393867120146751} | train loss {'Reaction outcome loss': 0.534846600491991, 'Total loss': 0.534846600491991}
2022-12-05 22:59:18,830 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:18,830 INFO:     Epoch: 30
2022-12-05 22:59:19,545 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.6150539375164292, 'Total loss': 0.6150539375164292} | train loss {'Reaction outcome loss': 0.5319840786375316, 'Total loss': 0.5319840786375316}
2022-12-05 22:59:19,545 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:19,545 INFO:     Epoch: 31
2022-12-05 22:59:20,262 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5509150692007758, 'Total loss': 0.5509150692007758} | train loss {'Reaction outcome loss': 0.524862079756704, 'Total loss': 0.524862079756704}
2022-12-05 22:59:20,262 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:20,262 INFO:     Epoch: 32
2022-12-05 22:59:20,974 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5655572400851683, 'Total loss': 0.5655572400851683} | train loss {'Reaction outcome loss': 0.5233994047166892, 'Total loss': 0.5233994047166892}
2022-12-05 22:59:20,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:20,974 INFO:     Epoch: 33
2022-12-05 22:59:21,685 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5386156744577668, 'Total loss': 0.5386156744577668} | train loss {'Reaction outcome loss': 0.5249670067658792, 'Total loss': 0.5249670067658792}
2022-12-05 22:59:21,685 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:21,685 INFO:     Epoch: 34
2022-12-05 22:59:22,397 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5386017015711828, 'Total loss': 0.5386017015711828} | train loss {'Reaction outcome loss': 0.5356281878132569, 'Total loss': 0.5356281878132569}
2022-12-05 22:59:22,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:22,397 INFO:     Epoch: 35
2022-12-05 22:59:23,109 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5712525986812331, 'Total loss': 0.5712525986812331} | train loss {'Reaction outcome loss': 0.5211055939376112, 'Total loss': 0.5211055939376112}
2022-12-05 22:59:23,109 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:23,109 INFO:     Epoch: 36
2022-12-05 22:59:23,822 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5545928783037446, 'Total loss': 0.5545928783037446} | train loss {'Reaction outcome loss': 0.5329354027746177, 'Total loss': 0.5329354027746177}
2022-12-05 22:59:23,822 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:23,822 INFO:     Epoch: 37
2022-12-05 22:59:24,533 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5617289888587865, 'Total loss': 0.5617289888587865} | train loss {'Reaction outcome loss': 0.5249509800033199, 'Total loss': 0.5249509800033199}
2022-12-05 22:59:24,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:24,533 INFO:     Epoch: 38
2022-12-05 22:59:25,247 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5219080448150635, 'Total loss': 0.5219080448150635} | train loss {'Reaction outcome loss': 0.5290582377297676, 'Total loss': 0.5290582377297676}
2022-12-05 22:59:25,247 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:25,247 INFO:     Epoch: 39
2022-12-05 22:59:25,957 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5403289002451029, 'Total loss': 0.5403289002451029} | train loss {'Reaction outcome loss': 0.5156441123379387, 'Total loss': 0.5156441123379387}
2022-12-05 22:59:25,957 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:25,958 INFO:     Epoch: 40
2022-12-05 22:59:26,668 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5306109846992926, 'Total loss': 0.5306109846992926} | train loss {'Reaction outcome loss': 0.5143877964481892, 'Total loss': 0.5143877964481892}
2022-12-05 22:59:26,669 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:26,669 INFO:     Epoch: 41
2022-12-05 22:59:27,379 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5366024943915281, 'Total loss': 0.5366024943915281} | train loss {'Reaction outcome loss': 0.5241666110043945, 'Total loss': 0.5241666110043945}
2022-12-05 22:59:27,379 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:27,379 INFO:     Epoch: 42
2022-12-05 22:59:28,091 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5522265021096576, 'Total loss': 0.5522265021096576} | train loss {'Reaction outcome loss': 0.5256141069748623, 'Total loss': 0.5256141069748623}
2022-12-05 22:59:28,091 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:28,091 INFO:     Epoch: 43
2022-12-05 22:59:28,804 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5479239347306165, 'Total loss': 0.5479239347306165} | train loss {'Reaction outcome loss': 0.52354783073128, 'Total loss': 0.52354783073128}
2022-12-05 22:59:28,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:28,804 INFO:     Epoch: 44
2022-12-05 22:59:29,517 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5597832643172957, 'Total loss': 0.5597832643172957} | train loss {'Reaction outcome loss': 0.521398234524225, 'Total loss': 0.521398234524225}
2022-12-05 22:59:29,517 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:29,517 INFO:     Epoch: 45
2022-12-05 22:59:30,229 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.575153337283568, 'Total loss': 0.575153337283568} | train loss {'Reaction outcome loss': 0.5319948702567985, 'Total loss': 0.5319948702567985}
2022-12-05 22:59:30,229 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:30,229 INFO:     Epoch: 46
2022-12-05 22:59:30,941 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5320157246156172, 'Total loss': 0.5320157246156172} | train loss {'Reaction outcome loss': 0.5207369971929895, 'Total loss': 0.5207369971929895}
2022-12-05 22:59:30,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:30,941 INFO:     Epoch: 47
2022-12-05 22:59:31,652 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5921467491848902, 'Total loss': 0.5921467491848902} | train loss {'Reaction outcome loss': 0.5307912278754509, 'Total loss': 0.5307912278754509}
2022-12-05 22:59:31,653 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:31,653 INFO:     Epoch: 48
2022-12-05 22:59:32,368 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5136015892706134, 'Total loss': 0.5136015892706134} | train loss {'Reaction outcome loss': 0.5205433419358875, 'Total loss': 0.5205433419358875}
2022-12-05 22:59:32,368 INFO:     Found new best model at epoch 48
2022-12-05 22:59:32,369 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:32,369 INFO:     Epoch: 49
2022-12-05 22:59:33,083 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5406527810476043, 'Total loss': 0.5406527810476043} | train loss {'Reaction outcome loss': 0.5264744770973318, 'Total loss': 0.5264744770973318}
2022-12-05 22:59:33,084 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:33,084 INFO:     Epoch: 50
2022-12-05 22:59:33,797 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5785425623709505, 'Total loss': 0.5785425623709505} | train loss {'Reaction outcome loss': 0.5227501171505312, 'Total loss': 0.5227501171505312}
2022-12-05 22:59:33,797 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:33,797 INFO:     Epoch: 51
2022-12-05 22:59:34,508 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5747344747863032, 'Total loss': 0.5747344747863032} | train loss {'Reaction outcome loss': 0.5173707519231839, 'Total loss': 0.5173707519231839}
2022-12-05 22:59:34,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:34,509 INFO:     Epoch: 52
2022-12-05 22:59:35,225 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5444501425054941, 'Total loss': 0.5444501425054941} | train loss {'Reaction outcome loss': 0.5241135663185825, 'Total loss': 0.5241135663185825}
2022-12-05 22:59:35,226 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:35,226 INFO:     Epoch: 53
2022-12-05 22:59:35,939 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5438393212177537, 'Total loss': 0.5438393212177537} | train loss {'Reaction outcome loss': 0.5183780864182754, 'Total loss': 0.5183780864182754}
2022-12-05 22:59:35,939 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:35,939 INFO:     Epoch: 54
2022-12-05 22:59:36,651 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5449622849171812, 'Total loss': 0.5449622849171812} | train loss {'Reaction outcome loss': 0.5298543650249721, 'Total loss': 0.5298543650249721}
2022-12-05 22:59:36,651 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:36,651 INFO:     Epoch: 55
2022-12-05 22:59:37,363 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5370104370469396, 'Total loss': 0.5370104370469396} | train loss {'Reaction outcome loss': 0.5312279741928313, 'Total loss': 0.5312279741928313}
2022-12-05 22:59:37,363 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:37,364 INFO:     Epoch: 56
2022-12-05 22:59:38,073 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5353368276899512, 'Total loss': 0.5353368276899512} | train loss {'Reaction outcome loss': 0.5319606938101502, 'Total loss': 0.5319606938101502}
2022-12-05 22:59:38,073 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:38,073 INFO:     Epoch: 57
2022-12-05 22:59:38,787 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5288499421016737, 'Total loss': 0.5288499421016737} | train loss {'Reaction outcome loss': 0.5319864877748496, 'Total loss': 0.5319864877748496}
2022-12-05 22:59:38,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:38,788 INFO:     Epoch: 58
2022-12-05 22:59:39,504 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5479723174463619, 'Total loss': 0.5479723174463619} | train loss {'Reaction outcome loss': 0.5179501653682848, 'Total loss': 0.5179501653682848}
2022-12-05 22:59:39,504 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:39,504 INFO:     Epoch: 59
2022-12-05 22:59:40,215 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5624624700708822, 'Total loss': 0.5624624700708822} | train loss {'Reaction outcome loss': 0.5228203043401966, 'Total loss': 0.5228203043401966}
2022-12-05 22:59:40,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:40,215 INFO:     Epoch: 60
2022-12-05 22:59:40,927 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5675772638483481, 'Total loss': 0.5675772638483481} | train loss {'Reaction outcome loss': 0.525492622845086, 'Total loss': 0.525492622845086}
2022-12-05 22:59:40,927 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:40,927 INFO:     Epoch: 61
2022-12-05 22:59:41,640 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5211908993395892, 'Total loss': 0.5211908993395892} | train loss {'Reaction outcome loss': 0.5221081202329412, 'Total loss': 0.5221081202329412}
2022-12-05 22:59:41,640 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:41,640 INFO:     Epoch: 62
2022-12-05 22:59:42,351 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5246976089071144, 'Total loss': 0.5246976089071144} | train loss {'Reaction outcome loss': 0.524354147645626, 'Total loss': 0.524354147645626}
2022-12-05 22:59:42,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:42,352 INFO:     Epoch: 63
2022-12-05 22:59:43,067 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5516178099946543, 'Total loss': 0.5516178099946543} | train loss {'Reaction outcome loss': 0.5364098649034615, 'Total loss': 0.5364098649034615}
2022-12-05 22:59:43,067 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:43,067 INFO:     Epoch: 64
2022-12-05 22:59:43,778 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5279806202108209, 'Total loss': 0.5279806202108209} | train loss {'Reaction outcome loss': 0.5235777838148086, 'Total loss': 0.5235777838148086}
2022-12-05 22:59:43,784 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:43,784 INFO:     Epoch: 65
2022-12-05 22:59:44,494 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5876919891346585, 'Total loss': 0.5876919891346585} | train loss {'Reaction outcome loss': 0.5290758427579393, 'Total loss': 0.5290758427579393}
2022-12-05 22:59:44,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:44,494 INFO:     Epoch: 66
2022-12-05 22:59:45,205 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5642093508081003, 'Total loss': 0.5642093508081003} | train loss {'Reaction outcome loss': 0.533075018357938, 'Total loss': 0.533075018357938}
2022-12-05 22:59:45,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:45,205 INFO:     Epoch: 67
2022-12-05 22:59:45,917 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5241907028989359, 'Total loss': 0.5241907028989359} | train loss {'Reaction outcome loss': 0.5247743033204484, 'Total loss': 0.5247743033204484}
2022-12-05 22:59:45,918 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:45,918 INFO:     Epoch: 68
2022-12-05 22:59:46,639 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5488461628556252, 'Total loss': 0.5488461628556252} | train loss {'Reaction outcome loss': 0.5276399705905904, 'Total loss': 0.5276399705905904}
2022-12-05 22:59:46,639 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:46,639 INFO:     Epoch: 69
2022-12-05 22:59:47,349 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.539810526100072, 'Total loss': 0.539810526100072} | train loss {'Reaction outcome loss': 0.52274719580465, 'Total loss': 0.52274719580465}
2022-12-05 22:59:47,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:47,350 INFO:     Epoch: 70
2022-12-05 22:59:48,060 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5322126644578847, 'Total loss': 0.5322126644578847} | train loss {'Reaction outcome loss': 0.5272096078164181, 'Total loss': 0.5272096078164181}
2022-12-05 22:59:48,060 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:48,060 INFO:     Epoch: 71
2022-12-05 22:59:48,772 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5430061119523916, 'Total loss': 0.5430061119523916} | train loss {'Reaction outcome loss': 0.528066346037243, 'Total loss': 0.528066346037243}
2022-12-05 22:59:48,772 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:48,772 INFO:     Epoch: 72
2022-12-05 22:59:49,483 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5430975966155529, 'Total loss': 0.5430975966155529} | train loss {'Reaction outcome loss': 0.5199796555541184, 'Total loss': 0.5199796555541184}
2022-12-05 22:59:49,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:49,484 INFO:     Epoch: 73
2022-12-05 22:59:50,194 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5371057567271319, 'Total loss': 0.5371057567271319} | train loss {'Reaction outcome loss': 0.5259502728371636, 'Total loss': 0.5259502728371636}
2022-12-05 22:59:50,194 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:50,194 INFO:     Epoch: 74
2022-12-05 22:59:50,908 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5456184175881472, 'Total loss': 0.5456184175881472} | train loss {'Reaction outcome loss': 0.5169892937910219, 'Total loss': 0.5169892937910219}
2022-12-05 22:59:50,908 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:50,909 INFO:     Epoch: 75
2022-12-05 22:59:51,619 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5793162325227802, 'Total loss': 0.5793162325227802} | train loss {'Reaction outcome loss': 0.5127657837411652, 'Total loss': 0.5127657837411652}
2022-12-05 22:59:51,619 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:51,619 INFO:     Epoch: 76
2022-12-05 22:59:52,330 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5717333142052997, 'Total loss': 0.5717333142052997} | train loss {'Reaction outcome loss': 0.5180474655657463, 'Total loss': 0.5180474655657463}
2022-12-05 22:59:52,330 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:52,330 INFO:     Epoch: 77
2022-12-05 22:59:53,043 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5516162582419135, 'Total loss': 0.5516162582419135} | train loss {'Reaction outcome loss': 0.526937783784365, 'Total loss': 0.526937783784365}
2022-12-05 22:59:53,043 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:53,043 INFO:     Epoch: 78
2022-12-05 22:59:53,753 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5292486517944119, 'Total loss': 0.5292486517944119} | train loss {'Reaction outcome loss': 0.5231046534260275, 'Total loss': 0.5231046534260275}
2022-12-05 22:59:53,754 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:53,754 INFO:     Epoch: 79
2022-12-05 22:59:54,463 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5297952341762456, 'Total loss': 0.5297952341762456} | train loss {'Reaction outcome loss': 0.5302414283578695, 'Total loss': 0.5302414283578695}
2022-12-05 22:59:54,463 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:54,463 INFO:     Epoch: 80
2022-12-05 22:59:55,177 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5651399703188376, 'Total loss': 0.5651399703188376} | train loss {'Reaction outcome loss': 0.5337360284106452, 'Total loss': 0.5337360284106452}
2022-12-05 22:59:55,177 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:55,177 INFO:     Epoch: 81
2022-12-05 22:59:55,890 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5066103889522228, 'Total loss': 0.5066103889522228} | train loss {'Reaction outcome loss': 0.5428333263467198, 'Total loss': 0.5428333263467198}
2022-12-05 22:59:55,890 INFO:     Found new best model at epoch 81
2022-12-05 22:59:55,891 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:55,891 INFO:     Epoch: 82
2022-12-05 22:59:56,607 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5560625361447985, 'Total loss': 0.5560625361447985} | train loss {'Reaction outcome loss': 0.5189996175317146, 'Total loss': 0.5189996175317146}
2022-12-05 22:59:56,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:56,607 INFO:     Epoch: 83
2022-12-05 22:59:57,316 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5504784658551216, 'Total loss': 0.5504784658551216} | train loss {'Reaction outcome loss': 0.5330492240576609, 'Total loss': 0.5330492240576609}
2022-12-05 22:59:57,316 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:57,316 INFO:     Epoch: 84
2022-12-05 22:59:58,028 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5237381241538308, 'Total loss': 0.5237381241538308} | train loss {'Reaction outcome loss': 0.5215604395760216, 'Total loss': 0.5215604395760216}
2022-12-05 22:59:58,028 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:58,028 INFO:     Epoch: 85
2022-12-05 22:59:58,739 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5176653692668135, 'Total loss': 0.5176653692668135} | train loss {'Reaction outcome loss': 0.5164320739777947, 'Total loss': 0.5164320739777947}
2022-12-05 22:59:58,739 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:58,739 INFO:     Epoch: 86
2022-12-05 22:59:59,451 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5881079225377603, 'Total loss': 0.5881079225377603} | train loss {'Reaction outcome loss': 0.5184452142189389, 'Total loss': 0.5184452142189389}
2022-12-05 22:59:59,451 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 22:59:59,451 INFO:     Epoch: 87
2022-12-05 23:00:00,161 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5327449400316585, 'Total loss': 0.5327449400316585} | train loss {'Reaction outcome loss': 0.5161527912867697, 'Total loss': 0.5161527912867697}
2022-12-05 23:00:00,161 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:00,161 INFO:     Epoch: 88
2022-12-05 23:00:00,875 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5299070179462433, 'Total loss': 0.5299070179462433} | train loss {'Reaction outcome loss': 0.5173467093633737, 'Total loss': 0.5173467093633737}
2022-12-05 23:00:00,875 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:00,875 INFO:     Epoch: 89
2022-12-05 23:00:01,589 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5395142828876321, 'Total loss': 0.5395142828876321} | train loss {'Reaction outcome loss': 0.5207883819922624, 'Total loss': 0.5207883819922624}
2022-12-05 23:00:01,590 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:01,590 INFO:     Epoch: 90
2022-12-05 23:00:02,299 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5977811454371973, 'Total loss': 0.5977811454371973} | train loss {'Reaction outcome loss': 0.5206322167521185, 'Total loss': 0.5206322167521185}
2022-12-05 23:00:02,299 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:02,299 INFO:     Epoch: 91
2022-12-05 23:00:03,009 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5151483694260771, 'Total loss': 0.5151483694260771} | train loss {'Reaction outcome loss': 0.5306784887666162, 'Total loss': 0.5306784887666162}
2022-12-05 23:00:03,009 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:03,009 INFO:     Epoch: 92
2022-12-05 23:00:03,717 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5348668938333337, 'Total loss': 0.5348668938333337} | train loss {'Reaction outcome loss': 0.5176409412908787, 'Total loss': 0.5176409412908787}
2022-12-05 23:00:03,717 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:03,717 INFO:     Epoch: 93
2022-12-05 23:00:04,425 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5365784215656194, 'Total loss': 0.5365784215656194} | train loss {'Reaction outcome loss': 0.5215941415986551, 'Total loss': 0.5215941415986551}
2022-12-05 23:00:04,426 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:04,426 INFO:     Epoch: 94
2022-12-05 23:00:05,138 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5418178290128708, 'Total loss': 0.5418178290128708} | train loss {'Reaction outcome loss': 0.5206699911278752, 'Total loss': 0.5206699911278752}
2022-12-05 23:00:05,138 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:05,138 INFO:     Epoch: 95
2022-12-05 23:00:05,851 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5104089006781578, 'Total loss': 0.5104089006781578} | train loss {'Reaction outcome loss': 0.5185561409287969, 'Total loss': 0.5185561409287969}
2022-12-05 23:00:05,852 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:05,852 INFO:     Epoch: 96
2022-12-05 23:00:06,566 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5261197618462823, 'Total loss': 0.5261197618462823} | train loss {'Reaction outcome loss': 0.5268114175391101, 'Total loss': 0.5268114175391101}
2022-12-05 23:00:06,566 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:06,566 INFO:     Epoch: 97
2022-12-05 23:00:07,278 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5114788006652485, 'Total loss': 0.5114788006652485} | train loss {'Reaction outcome loss': 0.5206165421708875, 'Total loss': 0.5206165421708875}
2022-12-05 23:00:07,278 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:07,278 INFO:     Epoch: 98
2022-12-05 23:00:07,989 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5318578813563694, 'Total loss': 0.5318578813563694} | train loss {'Reaction outcome loss': 0.5319596300663253, 'Total loss': 0.5319596300663253}
2022-12-05 23:00:07,989 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:07,989 INFO:     Epoch: 99
2022-12-05 23:00:08,701 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5775369592010975, 'Total loss': 0.5775369592010975} | train loss {'Reaction outcome loss': 0.5215062453498241, 'Total loss': 0.5215062453498241}
2022-12-05 23:00:08,701 INFO:     Best model found after epoch 82 of 100.
2022-12-05 23:00:08,701 INFO:   Done with stage: TRAINING
2022-12-05 23:00:08,701 INFO:   Starting stage: EVALUATION
2022-12-05 23:00:08,824 INFO:   Done with stage: EVALUATION
2022-12-05 23:00:08,825 INFO:   Leaving out SEQ value Fold_6
2022-12-05 23:00:08,837 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:00:08,838 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:00:09,489 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:00:09,490 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:00:09,561 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:00:09,561 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:00:09,561 INFO:     No hyperparam tuning for this model
2022-12-05 23:00:09,561 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:00:09,561 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:00:09,562 INFO:     None feature selector for col prot
2022-12-05 23:00:09,562 INFO:     None feature selector for col prot
2022-12-05 23:00:09,562 INFO:     None feature selector for col prot
2022-12-05 23:00:09,562 INFO:     None feature selector for col chem
2022-12-05 23:00:09,563 INFO:     None feature selector for col chem
2022-12-05 23:00:09,563 INFO:     None feature selector for col chem
2022-12-05 23:00:09,563 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:00:09,563 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:00:09,564 INFO:     Number of params in model 215731
2022-12-05 23:00:09,568 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:00:09,568 INFO:   Starting stage: TRAINING
2022-12-05 23:00:09,627 INFO:     Val loss before train {'Reaction outcome loss': 0.9711588661779057, 'Total loss': 0.9711588661779057}
2022-12-05 23:00:09,627 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:09,627 INFO:     Epoch: 0
2022-12-05 23:00:10,340 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6860239830884066, 'Total loss': 0.6860239830884066} | train loss {'Reaction outcome loss': 0.8058160166105917, 'Total loss': 0.8058160166105917}
2022-12-05 23:00:10,340 INFO:     Found new best model at epoch 0
2022-12-05 23:00:10,341 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:10,341 INFO:     Epoch: 1
2022-12-05 23:00:11,055 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6183776537125761, 'Total loss': 0.6183776537125761} | train loss {'Reaction outcome loss': 0.6632403101051046, 'Total loss': 0.6632403101051046}
2022-12-05 23:00:11,055 INFO:     Found new best model at epoch 1
2022-12-05 23:00:11,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:11,056 INFO:     Epoch: 2
2022-12-05 23:00:11,772 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5707031705162742, 'Total loss': 0.5707031705162742} | train loss {'Reaction outcome loss': 0.608884037442265, 'Total loss': 0.608884037442265}
2022-12-05 23:00:11,772 INFO:     Found new best model at epoch 2
2022-12-05 23:00:11,773 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:11,773 INFO:     Epoch: 3
2022-12-05 23:00:12,492 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5604189681735906, 'Total loss': 0.5604189681735906} | train loss {'Reaction outcome loss': 0.5851241115841174, 'Total loss': 0.5851241115841174}
2022-12-05 23:00:12,492 INFO:     Found new best model at epoch 3
2022-12-05 23:00:12,493 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:12,493 INFO:     Epoch: 4
2022-12-05 23:00:13,207 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5266644771803509, 'Total loss': 0.5266644771803509} | train loss {'Reaction outcome loss': 0.5730915201166945, 'Total loss': 0.5730915201166945}
2022-12-05 23:00:13,207 INFO:     Found new best model at epoch 4
2022-12-05 23:00:13,208 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:13,208 INFO:     Epoch: 5
2022-12-05 23:00:13,926 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5636301894079555, 'Total loss': 0.5636301894079555} | train loss {'Reaction outcome loss': 0.5765794952430071, 'Total loss': 0.5765794952430071}
2022-12-05 23:00:13,927 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:13,927 INFO:     Epoch: 6
2022-12-05 23:00:14,643 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.584680937230587, 'Total loss': 0.584680937230587} | train loss {'Reaction outcome loss': 0.5630854014908114, 'Total loss': 0.5630854014908114}
2022-12-05 23:00:14,643 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:14,644 INFO:     Epoch: 7
2022-12-05 23:00:15,356 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5463149486617609, 'Total loss': 0.5463149486617609} | train loss {'Reaction outcome loss': 0.5499321426895838, 'Total loss': 0.5499321426895838}
2022-12-05 23:00:15,356 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:15,356 INFO:     Epoch: 8
2022-12-05 23:00:16,070 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5588600256226279, 'Total loss': 0.5588600256226279} | train loss {'Reaction outcome loss': 0.5555918533955851, 'Total loss': 0.5555918533955851}
2022-12-05 23:00:16,070 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:16,071 INFO:     Epoch: 9
2022-12-05 23:00:16,787 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5212595483118837, 'Total loss': 0.5212595483118837} | train loss {'Reaction outcome loss': 0.5502385629881774, 'Total loss': 0.5502385629881774}
2022-12-05 23:00:16,787 INFO:     Found new best model at epoch 9
2022-12-05 23:00:16,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:16,788 INFO:     Epoch: 10
2022-12-05 23:00:17,507 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5509523237970743, 'Total loss': 0.5509523237970743} | train loss {'Reaction outcome loss': 0.5515667858022836, 'Total loss': 0.5515667858022836}
2022-12-05 23:00:17,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:17,509 INFO:     Epoch: 11
2022-12-05 23:00:18,226 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5402983542193066, 'Total loss': 0.5402983542193066} | train loss {'Reaction outcome loss': 0.5469775103753612, 'Total loss': 0.5469775103753612}
2022-12-05 23:00:18,226 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:18,226 INFO:     Epoch: 12
2022-12-05 23:00:18,945 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5444201982834123, 'Total loss': 0.5444201982834123} | train loss {'Reaction outcome loss': 0.5521076143148446, 'Total loss': 0.5521076143148446}
2022-12-05 23:00:18,946 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:18,946 INFO:     Epoch: 13
2022-12-05 23:00:19,661 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.545609230006283, 'Total loss': 0.545609230006283} | train loss {'Reaction outcome loss': 0.5351229737242383, 'Total loss': 0.5351229737242383}
2022-12-05 23:00:19,662 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:19,662 INFO:     Epoch: 14
2022-12-05 23:00:20,376 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5462107285857201, 'Total loss': 0.5462107285857201} | train loss {'Reaction outcome loss': 0.5415066507674994, 'Total loss': 0.5415066507674994}
2022-12-05 23:00:20,376 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:20,376 INFO:     Epoch: 15
2022-12-05 23:00:21,097 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5172230418432843, 'Total loss': 0.5172230418432843} | train loss {'Reaction outcome loss': 0.5397237675084222, 'Total loss': 0.5397237675084222}
2022-12-05 23:00:21,097 INFO:     Found new best model at epoch 15
2022-12-05 23:00:21,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:21,098 INFO:     Epoch: 16
2022-12-05 23:00:21,816 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.54730585352941, 'Total loss': 0.54730585352941} | train loss {'Reaction outcome loss': 0.535358589322817, 'Total loss': 0.535358589322817}
2022-12-05 23:00:21,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:21,816 INFO:     Epoch: 17
2022-12-05 23:00:22,530 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5483234985308214, 'Total loss': 0.5483234985308214} | train loss {'Reaction outcome loss': 0.5371855053930513, 'Total loss': 0.5371855053930513}
2022-12-05 23:00:22,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:22,530 INFO:     Epoch: 18
2022-12-05 23:00:23,243 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5642968118190765, 'Total loss': 0.5642968118190765} | train loss {'Reaction outcome loss': 0.5324913913444165, 'Total loss': 0.5324913913444165}
2022-12-05 23:00:23,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:23,243 INFO:     Epoch: 19
2022-12-05 23:00:23,956 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5671533664519136, 'Total loss': 0.5671533664519136} | train loss {'Reaction outcome loss': 0.531377008244876, 'Total loss': 0.531377008244876}
2022-12-05 23:00:23,957 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:23,957 INFO:     Epoch: 20
2022-12-05 23:00:24,669 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.516055285253308, 'Total loss': 0.516055285253308} | train loss {'Reaction outcome loss': 0.5408157762140036, 'Total loss': 0.5408157762140036}
2022-12-05 23:00:24,669 INFO:     Found new best model at epoch 20
2022-12-05 23:00:24,669 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:24,669 INFO:     Epoch: 21
2022-12-05 23:00:25,383 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5173230885782025, 'Total loss': 0.5173230885782025} | train loss {'Reaction outcome loss': 0.5303519052423297, 'Total loss': 0.5303519052423297}
2022-12-05 23:00:25,383 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:25,383 INFO:     Epoch: 22
2022-12-05 23:00:26,096 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5443634099581025, 'Total loss': 0.5443634099581025} | train loss {'Reaction outcome loss': 0.5215148369991972, 'Total loss': 0.5215148369991972}
2022-12-05 23:00:26,096 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:26,096 INFO:     Epoch: 23
2022-12-05 23:00:26,809 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5263633518056436, 'Total loss': 0.5263633518056436} | train loss {'Reaction outcome loss': 0.5238836788001561, 'Total loss': 0.5238836788001561}
2022-12-05 23:00:26,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:26,809 INFO:     Epoch: 24
2022-12-05 23:00:27,521 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5188966498456218, 'Total loss': 0.5188966498456218} | train loss {'Reaction outcome loss': 0.5266764181996545, 'Total loss': 0.5266764181996545}
2022-12-05 23:00:27,521 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:27,521 INFO:     Epoch: 25
2022-12-05 23:00:28,235 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5310253473845395, 'Total loss': 0.5310253473845395} | train loss {'Reaction outcome loss': 0.5261515588048966, 'Total loss': 0.5261515588048966}
2022-12-05 23:00:28,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:28,235 INFO:     Epoch: 26
2022-12-05 23:00:28,947 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5600917813452807, 'Total loss': 0.5600917813452807} | train loss {'Reaction outcome loss': 0.5228547148646847, 'Total loss': 0.5228547148646847}
2022-12-05 23:00:28,947 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:28,947 INFO:     Epoch: 27
2022-12-05 23:00:29,659 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5129011964256113, 'Total loss': 0.5129011964256113} | train loss {'Reaction outcome loss': 0.5251793087490143, 'Total loss': 0.5251793087490143}
2022-12-05 23:00:29,659 INFO:     Found new best model at epoch 27
2022-12-05 23:00:29,659 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:29,660 INFO:     Epoch: 28
2022-12-05 23:00:30,370 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5186267505315217, 'Total loss': 0.5186267505315217} | train loss {'Reaction outcome loss': 0.5209212294749676, 'Total loss': 0.5209212294749676}
2022-12-05 23:00:30,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:30,370 INFO:     Epoch: 29
2022-12-05 23:00:31,084 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5090693682432175, 'Total loss': 0.5090693682432175} | train loss {'Reaction outcome loss': 0.5208372591483977, 'Total loss': 0.5208372591483977}
2022-12-05 23:00:31,084 INFO:     Found new best model at epoch 29
2022-12-05 23:00:31,084 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:31,085 INFO:     Epoch: 30
2022-12-05 23:00:31,795 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5205598869784311, 'Total loss': 0.5205598869784311} | train loss {'Reaction outcome loss': 0.5175322165051776, 'Total loss': 0.5175322165051776}
2022-12-05 23:00:31,795 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:31,795 INFO:     Epoch: 31
2022-12-05 23:00:32,506 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5110557136887853, 'Total loss': 0.5110557136887853} | train loss {'Reaction outcome loss': 0.5224769751150762, 'Total loss': 0.5224769751150762}
2022-12-05 23:00:32,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:32,506 INFO:     Epoch: 32
2022-12-05 23:00:33,225 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5098042999478903, 'Total loss': 0.5098042999478903} | train loss {'Reaction outcome loss': 0.5218576698774292, 'Total loss': 0.5218576698774292}
2022-12-05 23:00:33,225 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:33,225 INFO:     Epoch: 33
2022-12-05 23:00:33,936 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.527071054008874, 'Total loss': 0.527071054008874} | train loss {'Reaction outcome loss': 0.519364356093349, 'Total loss': 0.519364356093349}
2022-12-05 23:00:33,937 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:33,937 INFO:     Epoch: 34
2022-12-05 23:00:34,647 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5558008795434778, 'Total loss': 0.5558008795434778} | train loss {'Reaction outcome loss': 0.5143597154848037, 'Total loss': 0.5143597154848037}
2022-12-05 23:00:34,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:34,647 INFO:     Epoch: 35
2022-12-05 23:00:35,359 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5129115595058962, 'Total loss': 0.5129115595058962} | train loss {'Reaction outcome loss': 0.5211065616458654, 'Total loss': 0.5211065616458654}
2022-12-05 23:00:35,359 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:35,359 INFO:     Epoch: 36
2022-12-05 23:00:36,075 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4979241635989059, 'Total loss': 0.4979241635989059} | train loss {'Reaction outcome loss': 0.5289853016335156, 'Total loss': 0.5289853016335156}
2022-12-05 23:00:36,075 INFO:     Found new best model at epoch 36
2022-12-05 23:00:36,076 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:36,076 INFO:     Epoch: 37
2022-12-05 23:00:36,789 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.522710326381705, 'Total loss': 0.522710326381705} | train loss {'Reaction outcome loss': 0.5207022735548597, 'Total loss': 0.5207022735548597}
2022-12-05 23:00:36,789 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:36,789 INFO:     Epoch: 38
2022-12-05 23:00:37,501 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5010999241335825, 'Total loss': 0.5010999241335825} | train loss {'Reaction outcome loss': 0.519211716649513, 'Total loss': 0.519211716649513}
2022-12-05 23:00:37,502 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:37,502 INFO:     Epoch: 39
2022-12-05 23:00:38,218 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4922424580224536, 'Total loss': 0.4922424580224536} | train loss {'Reaction outcome loss': 0.5155796749337066, 'Total loss': 0.5155796749337066}
2022-12-05 23:00:38,218 INFO:     Found new best model at epoch 39
2022-12-05 23:00:38,219 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:38,219 INFO:     Epoch: 40
2022-12-05 23:00:38,931 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5264494530856609, 'Total loss': 0.5264494530856609} | train loss {'Reaction outcome loss': 0.5240164505498063, 'Total loss': 0.5240164505498063}
2022-12-05 23:00:38,931 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:38,931 INFO:     Epoch: 41
2022-12-05 23:00:39,644 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49877620285207575, 'Total loss': 0.49877620285207575} | train loss {'Reaction outcome loss': 0.5192495783971202, 'Total loss': 0.5192495783971202}
2022-12-05 23:00:39,644 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:39,644 INFO:     Epoch: 42
2022-12-05 23:00:40,357 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.496406554159793, 'Total loss': 0.496406554159793} | train loss {'Reaction outcome loss': 0.517345751485517, 'Total loss': 0.517345751485517}
2022-12-05 23:00:40,357 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:40,357 INFO:     Epoch: 43
2022-12-05 23:00:41,069 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5052823288874193, 'Total loss': 0.5052823288874193} | train loss {'Reaction outcome loss': 0.5262042110966098, 'Total loss': 0.5262042110966098}
2022-12-05 23:00:41,069 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:41,069 INFO:     Epoch: 44
2022-12-05 23:00:41,784 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5024341449818828, 'Total loss': 0.5024341449818828} | train loss {'Reaction outcome loss': 0.5163857017553621, 'Total loss': 0.5163857017553621}
2022-12-05 23:00:41,784 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:41,784 INFO:     Epoch: 45
2022-12-05 23:00:42,495 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5058200901204889, 'Total loss': 0.5058200901204889} | train loss {'Reaction outcome loss': 0.5190679151564837, 'Total loss': 0.5190679151564837}
2022-12-05 23:00:42,495 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:42,495 INFO:     Epoch: 46
2022-12-05 23:00:43,208 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4951308007267388, 'Total loss': 0.4951308007267388} | train loss {'Reaction outcome loss': 0.5131951755573673, 'Total loss': 0.5131951755573673}
2022-12-05 23:00:43,208 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:43,208 INFO:     Epoch: 47
2022-12-05 23:00:43,919 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5296942219138145, 'Total loss': 0.5296942219138145} | train loss {'Reaction outcome loss': 0.5157320989115585, 'Total loss': 0.5157320989115585}
2022-12-05 23:00:43,919 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:43,919 INFO:     Epoch: 48
2022-12-05 23:00:44,630 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48899107528003777, 'Total loss': 0.48899107528003777} | train loss {'Reaction outcome loss': 0.5155738479788264, 'Total loss': 0.5155738479788264}
2022-12-05 23:00:44,630 INFO:     Found new best model at epoch 48
2022-12-05 23:00:44,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:44,631 INFO:     Epoch: 49
2022-12-05 23:00:45,342 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5041084184565328, 'Total loss': 0.5041084184565328} | train loss {'Reaction outcome loss': 0.511841949916655, 'Total loss': 0.511841949916655}
2022-12-05 23:00:45,342 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:45,342 INFO:     Epoch: 50
2022-12-05 23:00:46,057 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.520457545464689, 'Total loss': 0.520457545464689} | train loss {'Reaction outcome loss': 0.5147280730907956, 'Total loss': 0.5147280730907956}
2022-12-05 23:00:46,058 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:46,058 INFO:     Epoch: 51
2022-12-05 23:00:46,769 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49829849363728, 'Total loss': 0.49829849363728} | train loss {'Reaction outcome loss': 0.5175308699929907, 'Total loss': 0.5175308699929907}
2022-12-05 23:00:46,769 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:46,769 INFO:     Epoch: 52
2022-12-05 23:00:47,480 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4818707216869701, 'Total loss': 0.4818707216869701} | train loss {'Reaction outcome loss': 0.5235015057748363, 'Total loss': 0.5235015057748363}
2022-12-05 23:00:47,481 INFO:     Found new best model at epoch 52
2022-12-05 23:00:47,481 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:47,481 INFO:     Epoch: 53
2022-12-05 23:00:48,193 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5405101952227679, 'Total loss': 0.5405101952227679} | train loss {'Reaction outcome loss': 0.5211921616066848, 'Total loss': 0.5211921616066848}
2022-12-05 23:00:48,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:48,193 INFO:     Epoch: 54
2022-12-05 23:00:48,907 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5092562501403418, 'Total loss': 0.5092562501403418} | train loss {'Reaction outcome loss': 0.5119992873721546, 'Total loss': 0.5119992873721546}
2022-12-05 23:00:48,909 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:48,909 INFO:     Epoch: 55
2022-12-05 23:00:49,623 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5171648578887637, 'Total loss': 0.5171648578887637} | train loss {'Reaction outcome loss': 0.5149991220283893, 'Total loss': 0.5149991220283893}
2022-12-05 23:00:49,623 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:49,623 INFO:     Epoch: 56
2022-12-05 23:00:50,336 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5067745467478578, 'Total loss': 0.5067745467478578} | train loss {'Reaction outcome loss': 0.5233705272116969, 'Total loss': 0.5233705272116969}
2022-12-05 23:00:50,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:50,337 INFO:     Epoch: 57
2022-12-05 23:00:51,048 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5180922719565305, 'Total loss': 0.5180922719565305} | train loss {'Reaction outcome loss': 0.5176471650840775, 'Total loss': 0.5176471650840775}
2022-12-05 23:00:51,048 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:51,048 INFO:     Epoch: 58
2022-12-05 23:00:51,760 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4974241354926066, 'Total loss': 0.4974241354926066} | train loss {'Reaction outcome loss': 0.5102835013981788, 'Total loss': 0.5102835013981788}
2022-12-05 23:00:51,760 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:51,760 INFO:     Epoch: 59
2022-12-05 23:00:52,472 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5529161000793631, 'Total loss': 0.5529161000793631} | train loss {'Reaction outcome loss': 0.5222116672704297, 'Total loss': 0.5222116672704297}
2022-12-05 23:00:52,473 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:52,473 INFO:     Epoch: 60
2022-12-05 23:00:53,190 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5152127092534845, 'Total loss': 0.5152127092534845} | train loss {'Reaction outcome loss': 0.5177602093786963, 'Total loss': 0.5177602093786963}
2022-12-05 23:00:53,191 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:53,191 INFO:     Epoch: 61
2022-12-05 23:00:53,907 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5130591538142074, 'Total loss': 0.5130591538142074} | train loss {'Reaction outcome loss': 0.512826640579489, 'Total loss': 0.512826640579489}
2022-12-05 23:00:53,907 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:53,907 INFO:     Epoch: 62
2022-12-05 23:00:54,618 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5072410479187965, 'Total loss': 0.5072410479187965} | train loss {'Reaction outcome loss': 0.5158963586173712, 'Total loss': 0.5158963586173712}
2022-12-05 23:00:54,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:54,618 INFO:     Epoch: 63
2022-12-05 23:00:55,330 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5179731700230729, 'Total loss': 0.5179731700230729} | train loss {'Reaction outcome loss': 0.5166820414484509, 'Total loss': 0.5166820414484509}
2022-12-05 23:00:55,331 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:55,331 INFO:     Epoch: 64
2022-12-05 23:00:56,046 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5032281530174342, 'Total loss': 0.5032281530174342} | train loss {'Reaction outcome loss': 0.5132655847457147, 'Total loss': 0.5132655847457147}
2022-12-05 23:00:56,046 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:56,046 INFO:     Epoch: 65
2022-12-05 23:00:56,759 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4824264794588089, 'Total loss': 0.4824264794588089} | train loss {'Reaction outcome loss': 0.5198766315476068, 'Total loss': 0.5198766315476068}
2022-12-05 23:00:56,759 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:56,760 INFO:     Epoch: 66
2022-12-05 23:00:57,471 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49112406508489087, 'Total loss': 0.49112406508489087} | train loss {'Reaction outcome loss': 0.5142421591426095, 'Total loss': 0.5142421591426095}
2022-12-05 23:00:57,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:57,471 INFO:     Epoch: 67
2022-12-05 23:00:58,179 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5186387148093093, 'Total loss': 0.5186387148093093} | train loss {'Reaction outcome loss': 0.5092072853998791, 'Total loss': 0.5092072853998791}
2022-12-05 23:00:58,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:58,179 INFO:     Epoch: 68
2022-12-05 23:00:58,890 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5748770352114331, 'Total loss': 0.5748770352114331} | train loss {'Reaction outcome loss': 0.5168902616226866, 'Total loss': 0.5168902616226866}
2022-12-05 23:00:58,890 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:58,890 INFO:     Epoch: 69
2022-12-05 23:00:59,597 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5493185865608129, 'Total loss': 0.5493185865608129} | train loss {'Reaction outcome loss': 0.5138018260439557, 'Total loss': 0.5138018260439557}
2022-12-05 23:00:59,597 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:00:59,598 INFO:     Epoch: 70
2022-12-05 23:01:00,307 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5327608361840248, 'Total loss': 0.5327608361840248} | train loss {'Reaction outcome loss': 0.5119838147394119, 'Total loss': 0.5119838147394119}
2022-12-05 23:01:00,308 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:00,308 INFO:     Epoch: 71
2022-12-05 23:01:01,016 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4831657392734831, 'Total loss': 0.4831657392734831} | train loss {'Reaction outcome loss': 0.5174784077511679, 'Total loss': 0.5174784077511679}
2022-12-05 23:01:01,016 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:01,016 INFO:     Epoch: 72
2022-12-05 23:01:01,727 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5355065627531572, 'Total loss': 0.5355065627531572} | train loss {'Reaction outcome loss': 0.5096278040399475, 'Total loss': 0.5096278040399475}
2022-12-05 23:01:01,727 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:01,727 INFO:     Epoch: 73
2022-12-05 23:01:02,437 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5455779548395764, 'Total loss': 0.5455779548395764} | train loss {'Reaction outcome loss': 0.5137271356558607, 'Total loss': 0.5137271356558607}
2022-12-05 23:01:02,437 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:02,437 INFO:     Epoch: 74
2022-12-05 23:01:03,145 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5306429619138892, 'Total loss': 0.5306429619138892} | train loss {'Reaction outcome loss': 0.5150521822393902, 'Total loss': 0.5150521822393902}
2022-12-05 23:01:03,145 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:03,145 INFO:     Epoch: 75
2022-12-05 23:01:03,854 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5011046088554643, 'Total loss': 0.5011046088554643} | train loss {'Reaction outcome loss': 0.5098750572050771, 'Total loss': 0.5098750572050771}
2022-12-05 23:01:03,854 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:03,854 INFO:     Epoch: 76
2022-12-05 23:01:04,564 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5247433734211054, 'Total loss': 0.5247433734211054} | train loss {'Reaction outcome loss': 0.5123232133806713, 'Total loss': 0.5123232133806713}
2022-12-05 23:01:04,564 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:04,565 INFO:     Epoch: 77
2022-12-05 23:01:05,271 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.512027380141345, 'Total loss': 0.512027380141345} | train loss {'Reaction outcome loss': 0.5129330011625444, 'Total loss': 0.5129330011625444}
2022-12-05 23:01:05,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:05,272 INFO:     Epoch: 78
2022-12-05 23:01:05,978 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5152535570616071, 'Total loss': 0.5152535570616071} | train loss {'Reaction outcome loss': 0.5190361904941739, 'Total loss': 0.5190361904941739}
2022-12-05 23:01:05,978 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:05,978 INFO:     Epoch: 79
2022-12-05 23:01:06,685 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5319290973923423, 'Total loss': 0.5319290973923423} | train loss {'Reaction outcome loss': 0.5146604320935665, 'Total loss': 0.5146604320935665}
2022-12-05 23:01:06,685 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:06,686 INFO:     Epoch: 80
2022-12-05 23:01:07,396 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5088228312405673, 'Total loss': 0.5088228312405673} | train loss {'Reaction outcome loss': 0.5163283436408928, 'Total loss': 0.5163283436408928}
2022-12-05 23:01:07,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:07,397 INFO:     Epoch: 81
2022-12-05 23:01:08,108 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5035234246064316, 'Total loss': 0.5035234246064316} | train loss {'Reaction outcome loss': 0.5157221840514291, 'Total loss': 0.5157221840514291}
2022-12-05 23:01:08,108 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:08,108 INFO:     Epoch: 82
2022-12-05 23:01:08,816 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5174605677073653, 'Total loss': 0.5174605677073653} | train loss {'Reaction outcome loss': 0.5191788085165524, 'Total loss': 0.5191788085165524}
2022-12-05 23:01:08,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:08,816 INFO:     Epoch: 83
2022-12-05 23:01:09,525 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5392012579197233, 'Total loss': 0.5392012579197233} | train loss {'Reaction outcome loss': 0.5104106968689349, 'Total loss': 0.5104106968689349}
2022-12-05 23:01:09,525 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:09,525 INFO:     Epoch: 84
2022-12-05 23:01:10,233 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5101268880746581, 'Total loss': 0.5101268880746581} | train loss {'Reaction outcome loss': 0.5164374827497429, 'Total loss': 0.5164374827497429}
2022-12-05 23:01:10,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:10,234 INFO:     Epoch: 85
2022-12-05 23:01:10,941 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5133910036899827, 'Total loss': 0.5133910036899827} | train loss {'Reaction outcome loss': 0.5112334911771599, 'Total loss': 0.5112334911771599}
2022-12-05 23:01:10,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:10,941 INFO:     Epoch: 86
2022-12-05 23:01:11,648 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5767278393561189, 'Total loss': 0.5767278393561189} | train loss {'Reaction outcome loss': 0.5158444008519573, 'Total loss': 0.5158444008519573}
2022-12-05 23:01:11,648 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:11,648 INFO:     Epoch: 87
2022-12-05 23:01:12,356 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.49888755211775954, 'Total loss': 0.49888755211775954} | train loss {'Reaction outcome loss': 0.518461233065013, 'Total loss': 0.518461233065013}
2022-12-05 23:01:12,356 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:12,356 INFO:     Epoch: 88
2022-12-05 23:01:13,068 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5034286664290861, 'Total loss': 0.5034286664290861} | train loss {'Reaction outcome loss': 0.5121866856972056, 'Total loss': 0.5121866856972056}
2022-12-05 23:01:13,068 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:13,068 INFO:     Epoch: 89
2022-12-05 23:01:13,778 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49910018322142685, 'Total loss': 0.49910018322142685} | train loss {'Reaction outcome loss': 0.5127128685313848, 'Total loss': 0.5127128685313848}
2022-12-05 23:01:13,778 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:13,779 INFO:     Epoch: 90
2022-12-05 23:01:14,490 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5055956512012265, 'Total loss': 0.5055956512012265} | train loss {'Reaction outcome loss': 0.516484294507292, 'Total loss': 0.516484294507292}
2022-12-05 23:01:14,490 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:14,490 INFO:     Epoch: 91
2022-12-05 23:01:15,196 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5841236046769402, 'Total loss': 0.5841236046769402} | train loss {'Reaction outcome loss': 0.5173787915658566, 'Total loss': 0.5173787915658566}
2022-12-05 23:01:15,196 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:15,196 INFO:     Epoch: 92
2022-12-05 23:01:15,903 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5025797384706411, 'Total loss': 0.5025797384706411} | train loss {'Reaction outcome loss': 0.5188887954479263, 'Total loss': 0.5188887954479263}
2022-12-05 23:01:15,903 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:15,903 INFO:     Epoch: 93
2022-12-05 23:01:16,612 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4934452822939916, 'Total loss': 0.4934452822939916} | train loss {'Reaction outcome loss': 0.5137713022169567, 'Total loss': 0.5137713022169567}
2022-12-05 23:01:16,612 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:16,612 INFO:     Epoch: 94
2022-12-05 23:01:17,322 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5061201862990856, 'Total loss': 0.5061201862990856} | train loss {'Reaction outcome loss': 0.5149433720376222, 'Total loss': 0.5149433720376222}
2022-12-05 23:01:17,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:17,322 INFO:     Epoch: 95
2022-12-05 23:01:18,028 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49753725427118217, 'Total loss': 0.49753725427118217} | train loss {'Reaction outcome loss': 0.5050111727248277, 'Total loss': 0.5050111727248277}
2022-12-05 23:01:18,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:18,029 INFO:     Epoch: 96
2022-12-05 23:01:18,742 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5275267802856185, 'Total loss': 0.5275267802856185} | train loss {'Reaction outcome loss': 0.5143831215438343, 'Total loss': 0.5143831215438343}
2022-12-05 23:01:18,742 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:18,742 INFO:     Epoch: 97
2022-12-05 23:01:19,449 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5005083324557001, 'Total loss': 0.5005083324557001} | train loss {'Reaction outcome loss': 0.5136620900443485, 'Total loss': 0.5136620900443485}
2022-12-05 23:01:19,449 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:19,450 INFO:     Epoch: 98
2022-12-05 23:01:20,156 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5174624588001858, 'Total loss': 0.5174624588001858} | train loss {'Reaction outcome loss': 0.5141077073170773, 'Total loss': 0.5141077073170773}
2022-12-05 23:01:20,157 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:20,157 INFO:     Epoch: 99
2022-12-05 23:01:20,863 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.517838595265692, 'Total loss': 0.517838595265692} | train loss {'Reaction outcome loss': 0.5068723218094918, 'Total loss': 0.5068723218094918}
2022-12-05 23:01:20,863 INFO:     Best model found after epoch 53 of 100.
2022-12-05 23:01:20,863 INFO:   Done with stage: TRAINING
2022-12-05 23:01:20,863 INFO:   Starting stage: EVALUATION
2022-12-05 23:01:20,981 INFO:   Done with stage: EVALUATION
2022-12-05 23:01:20,981 INFO:   Leaving out SEQ value Fold_7
2022-12-05 23:01:20,993 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:01:20,994 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:01:21,630 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:01:21,630 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:01:21,701 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:01:21,701 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:01:21,701 INFO:     No hyperparam tuning for this model
2022-12-05 23:01:21,701 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:01:21,701 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:01:21,702 INFO:     None feature selector for col prot
2022-12-05 23:01:21,702 INFO:     None feature selector for col prot
2022-12-05 23:01:21,702 INFO:     None feature selector for col prot
2022-12-05 23:01:21,703 INFO:     None feature selector for col chem
2022-12-05 23:01:21,703 INFO:     None feature selector for col chem
2022-12-05 23:01:21,703 INFO:     None feature selector for col chem
2022-12-05 23:01:21,703 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:01:21,703 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:01:21,705 INFO:     Number of params in model 215731
2022-12-05 23:01:21,708 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:01:21,708 INFO:   Starting stage: TRAINING
2022-12-05 23:01:21,765 INFO:     Val loss before train {'Reaction outcome loss': 1.0072044676000422, 'Total loss': 1.0072044676000422}
2022-12-05 23:01:21,766 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:21,766 INFO:     Epoch: 0
2022-12-05 23:01:22,474 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6846575079993769, 'Total loss': 0.6846575079993769} | train loss {'Reaction outcome loss': 0.7857505531320649, 'Total loss': 0.7857505531320649}
2022-12-05 23:01:22,474 INFO:     Found new best model at epoch 0
2022-12-05 23:01:22,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:22,475 INFO:     Epoch: 1
2022-12-05 23:01:23,178 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6546496884389357, 'Total loss': 0.6546496884389357} | train loss {'Reaction outcome loss': 0.6514045239215897, 'Total loss': 0.6514045239215897}
2022-12-05 23:01:23,178 INFO:     Found new best model at epoch 1
2022-12-05 23:01:23,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:23,179 INFO:     Epoch: 2
2022-12-05 23:01:23,887 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6052720560268923, 'Total loss': 0.6052720560268923} | train loss {'Reaction outcome loss': 0.6251694472326387, 'Total loss': 0.6251694472326387}
2022-12-05 23:01:23,887 INFO:     Found new best model at epoch 2
2022-12-05 23:01:23,888 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:23,888 INFO:     Epoch: 3
2022-12-05 23:01:24,592 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6082742668010972, 'Total loss': 0.6082742668010972} | train loss {'Reaction outcome loss': 0.5897585633060625, 'Total loss': 0.5897585633060625}
2022-12-05 23:01:24,592 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:24,593 INFO:     Epoch: 4
2022-12-05 23:01:25,296 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5987070236693729, 'Total loss': 0.5987070236693729} | train loss {'Reaction outcome loss': 0.5697743625890824, 'Total loss': 0.5697743625890824}
2022-12-05 23:01:25,296 INFO:     Found new best model at epoch 4
2022-12-05 23:01:25,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:25,297 INFO:     Epoch: 5
2022-12-05 23:01:26,002 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5589375373992053, 'Total loss': 0.5589375373992053} | train loss {'Reaction outcome loss': 0.5723179048828541, 'Total loss': 0.5723179048828541}
2022-12-05 23:01:26,002 INFO:     Found new best model at epoch 5
2022-12-05 23:01:26,003 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:26,003 INFO:     Epoch: 6
2022-12-05 23:01:26,707 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5572488849813287, 'Total loss': 0.5572488849813287} | train loss {'Reaction outcome loss': 0.5428375122287581, 'Total loss': 0.5428375122287581}
2022-12-05 23:01:26,708 INFO:     Found new best model at epoch 6
2022-12-05 23:01:26,709 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:26,709 INFO:     Epoch: 7
2022-12-05 23:01:27,414 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5608105496926741, 'Total loss': 0.5608105496926741} | train loss {'Reaction outcome loss': 0.5500441803446701, 'Total loss': 0.5500441803446701}
2022-12-05 23:01:27,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:27,415 INFO:     Epoch: 8
2022-12-05 23:01:28,120 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5481887358156118, 'Total loss': 0.5481887358156118} | train loss {'Reaction outcome loss': 0.5438962170794126, 'Total loss': 0.5438962170794126}
2022-12-05 23:01:28,120 INFO:     Found new best model at epoch 8
2022-12-05 23:01:28,120 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:28,121 INFO:     Epoch: 9
2022-12-05 23:01:28,825 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5599353916265748, 'Total loss': 0.5599353916265748} | train loss {'Reaction outcome loss': 0.5402845313412047, 'Total loss': 0.5402845313412047}
2022-12-05 23:01:28,825 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:28,825 INFO:     Epoch: 10
2022-12-05 23:01:29,529 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5411107492717829, 'Total loss': 0.5411107492717829} | train loss {'Reaction outcome loss': 0.5281828378717746, 'Total loss': 0.5281828378717746}
2022-12-05 23:01:29,529 INFO:     Found new best model at epoch 10
2022-12-05 23:01:29,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:29,530 INFO:     Epoch: 11
2022-12-05 23:01:30,235 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5760118764909831, 'Total loss': 0.5760118764909831} | train loss {'Reaction outcome loss': 0.5320370188283343, 'Total loss': 0.5320370188283343}
2022-12-05 23:01:30,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:30,235 INFO:     Epoch: 12
2022-12-05 23:01:30,944 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5383135168389841, 'Total loss': 0.5383135168389841} | train loss {'Reaction outcome loss': 0.5334633178408107, 'Total loss': 0.5334633178408107}
2022-12-05 23:01:30,944 INFO:     Found new best model at epoch 12
2022-12-05 23:01:30,944 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:30,945 INFO:     Epoch: 13
2022-12-05 23:01:31,652 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5548797168514945, 'Total loss': 0.5548797168514945} | train loss {'Reaction outcome loss': 0.5261287383975521, 'Total loss': 0.5261287383975521}
2022-12-05 23:01:31,652 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:31,652 INFO:     Epoch: 14
2022-12-05 23:01:32,359 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5881217765537176, 'Total loss': 0.5881217765537176} | train loss {'Reaction outcome loss': 0.5232446273608554, 'Total loss': 0.5232446273608554}
2022-12-05 23:01:32,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:32,360 INFO:     Epoch: 15
2022-12-05 23:01:33,063 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5487317432734099, 'Total loss': 0.5487317432734099} | train loss {'Reaction outcome loss': 0.524812976619409, 'Total loss': 0.524812976619409}
2022-12-05 23:01:33,064 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:33,064 INFO:     Epoch: 16
2022-12-05 23:01:33,767 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5344950211319056, 'Total loss': 0.5344950211319056} | train loss {'Reaction outcome loss': 0.5294262074655102, 'Total loss': 0.5294262074655102}
2022-12-05 23:01:33,767 INFO:     Found new best model at epoch 16
2022-12-05 23:01:33,768 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:33,768 INFO:     Epoch: 17
2022-12-05 23:01:34,473 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5461325923150236, 'Total loss': 0.5461325923150236} | train loss {'Reaction outcome loss': 0.5299253108640832, 'Total loss': 0.5299253108640832}
2022-12-05 23:01:34,473 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:34,473 INFO:     Epoch: 18
2022-12-05 23:01:35,179 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.552859911864454, 'Total loss': 0.552859911864454} | train loss {'Reaction outcome loss': 0.5172896882699382, 'Total loss': 0.5172896882699382}
2022-12-05 23:01:35,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:35,179 INFO:     Epoch: 19
2022-12-05 23:01:35,883 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5709816840561953, 'Total loss': 0.5709816840561953} | train loss {'Reaction outcome loss': 0.5250147737923169, 'Total loss': 0.5250147737923169}
2022-12-05 23:01:35,884 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:35,884 INFO:     Epoch: 20
2022-12-05 23:01:36,590 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5164182260632515, 'Total loss': 0.5164182260632515} | train loss {'Reaction outcome loss': 0.5159496073761294, 'Total loss': 0.5159496073761294}
2022-12-05 23:01:36,590 INFO:     Found new best model at epoch 20
2022-12-05 23:01:36,591 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:36,591 INFO:     Epoch: 21
2022-12-05 23:01:37,296 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5623003860766237, 'Total loss': 0.5623003860766237} | train loss {'Reaction outcome loss': 0.5224930425925601, 'Total loss': 0.5224930425925601}
2022-12-05 23:01:37,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:37,296 INFO:     Epoch: 22
2022-12-05 23:01:38,000 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5660942054607652, 'Total loss': 0.5660942054607652} | train loss {'Reaction outcome loss': 0.5201624523728124, 'Total loss': 0.5201624523728124}
2022-12-05 23:01:38,001 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:38,001 INFO:     Epoch: 23
2022-12-05 23:01:38,705 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5550852688876066, 'Total loss': 0.5550852688876066} | train loss {'Reaction outcome loss': 0.5168142277867563, 'Total loss': 0.5168142277867563}
2022-12-05 23:01:38,705 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:38,705 INFO:     Epoch: 24
2022-12-05 23:01:39,409 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5411355922167952, 'Total loss': 0.5411355922167952} | train loss {'Reaction outcome loss': 0.5151845830222291, 'Total loss': 0.5151845830222291}
2022-12-05 23:01:39,410 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:39,410 INFO:     Epoch: 25
2022-12-05 23:01:40,114 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5298262563618746, 'Total loss': 0.5298262563618746} | train loss {'Reaction outcome loss': 0.5150236671850565, 'Total loss': 0.5150236671850565}
2022-12-05 23:01:40,114 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:40,114 INFO:     Epoch: 26
2022-12-05 23:01:40,818 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5162999413230203, 'Total loss': 0.5162999413230203} | train loss {'Reaction outcome loss': 0.5180350808847335, 'Total loss': 0.5180350808847335}
2022-12-05 23:01:40,818 INFO:     Found new best model at epoch 26
2022-12-05 23:01:40,819 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:40,819 INFO:     Epoch: 27
2022-12-05 23:01:41,524 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5363535782830282, 'Total loss': 0.5363535782830282} | train loss {'Reaction outcome loss': 0.511833961211866, 'Total loss': 0.511833961211866}
2022-12-05 23:01:41,525 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:41,525 INFO:     Epoch: 28
2022-12-05 23:01:42,230 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5358947610313242, 'Total loss': 0.5358947610313242} | train loss {'Reaction outcome loss': 0.5170237246540285, 'Total loss': 0.5170237246540285}
2022-12-05 23:01:42,230 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:42,230 INFO:     Epoch: 29
2022-12-05 23:01:42,936 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5412944345311685, 'Total loss': 0.5412944345311685} | train loss {'Reaction outcome loss': 0.5169264072732579, 'Total loss': 0.5169264072732579}
2022-12-05 23:01:42,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:42,936 INFO:     Epoch: 30
2022-12-05 23:01:43,642 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5287775380367582, 'Total loss': 0.5287775380367582} | train loss {'Reaction outcome loss': 0.5096991482761598, 'Total loss': 0.5096991482761598}
2022-12-05 23:01:43,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:43,642 INFO:     Epoch: 31
2022-12-05 23:01:44,347 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5368896580555222, 'Total loss': 0.5368896580555222} | train loss {'Reaction outcome loss': 0.515177154793374, 'Total loss': 0.515177154793374}
2022-12-05 23:01:44,347 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:44,347 INFO:     Epoch: 32
2022-12-05 23:01:45,059 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5399352677843787, 'Total loss': 0.5399352677843787} | train loss {'Reaction outcome loss': 0.5150177288920649, 'Total loss': 0.5150177288920649}
2022-12-05 23:01:45,059 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:45,059 INFO:     Epoch: 33
2022-12-05 23:01:45,764 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5458843003619801, 'Total loss': 0.5458843003619801} | train loss {'Reaction outcome loss': 0.5094132642712323, 'Total loss': 0.5094132642712323}
2022-12-05 23:01:45,764 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:45,765 INFO:     Epoch: 34
2022-12-05 23:01:46,473 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5152605887163769, 'Total loss': 0.5152605887163769} | train loss {'Reaction outcome loss': 0.5123529716004287, 'Total loss': 0.5123529716004287}
2022-12-05 23:01:46,474 INFO:     Found new best model at epoch 34
2022-12-05 23:01:46,474 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:46,474 INFO:     Epoch: 35
2022-12-05 23:01:47,181 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.516174374317581, 'Total loss': 0.516174374317581} | train loss {'Reaction outcome loss': 0.5040952724915359, 'Total loss': 0.5040952724915359}
2022-12-05 23:01:47,181 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:47,181 INFO:     Epoch: 36
2022-12-05 23:01:47,886 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5648938146504489, 'Total loss': 0.5648938146504489} | train loss {'Reaction outcome loss': 0.5114096657282883, 'Total loss': 0.5114096657282883}
2022-12-05 23:01:47,886 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:47,887 INFO:     Epoch: 37
2022-12-05 23:01:48,595 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.562694960358468, 'Total loss': 0.562694960358468} | train loss {'Reaction outcome loss': 0.5073977362124189, 'Total loss': 0.5073977362124189}
2022-12-05 23:01:48,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:48,595 INFO:     Epoch: 38
2022-12-05 23:01:49,302 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5310650969093497, 'Total loss': 0.5310650969093497} | train loss {'Reaction outcome loss': 0.515206592878507, 'Total loss': 0.515206592878507}
2022-12-05 23:01:49,302 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:49,302 INFO:     Epoch: 39
2022-12-05 23:01:50,008 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5203063139183954, 'Total loss': 0.5203063139183954} | train loss {'Reaction outcome loss': 0.5049118156875333, 'Total loss': 0.5049118156875333}
2022-12-05 23:01:50,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:50,008 INFO:     Epoch: 40
2022-12-05 23:01:50,714 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5319704609838399, 'Total loss': 0.5319704609838399} | train loss {'Reaction outcome loss': 0.5051840069673715, 'Total loss': 0.5051840069673715}
2022-12-05 23:01:50,715 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:50,715 INFO:     Epoch: 41
2022-12-05 23:01:51,425 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5532965351912108, 'Total loss': 0.5532965351912108} | train loss {'Reaction outcome loss': 0.5061160167979617, 'Total loss': 0.5061160167979617}
2022-12-05 23:01:51,426 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:51,426 INFO:     Epoch: 42
2022-12-05 23:01:52,132 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5228954282673922, 'Total loss': 0.5228954282673922} | train loss {'Reaction outcome loss': 0.5107641023613753, 'Total loss': 0.5107641023613753}
2022-12-05 23:01:52,133 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:52,133 INFO:     Epoch: 43
2022-12-05 23:01:52,838 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5259245166724379, 'Total loss': 0.5259245166724379} | train loss {'Reaction outcome loss': 0.5020735743906228, 'Total loss': 0.5020735743906228}
2022-12-05 23:01:52,839 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:52,839 INFO:     Epoch: 44
2022-12-05 23:01:53,544 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5506191636351022, 'Total loss': 0.5506191636351022} | train loss {'Reaction outcome loss': 0.5050390469691446, 'Total loss': 0.5050390469691446}
2022-12-05 23:01:53,544 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:53,544 INFO:     Epoch: 45
2022-12-05 23:01:54,252 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5048389143564485, 'Total loss': 0.5048389143564485} | train loss {'Reaction outcome loss': 0.5086836258490239, 'Total loss': 0.5086836258490239}
2022-12-05 23:01:54,252 INFO:     Found new best model at epoch 45
2022-12-05 23:01:54,252 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:54,253 INFO:     Epoch: 46
2022-12-05 23:01:54,958 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5213516699996862, 'Total loss': 0.5213516699996862} | train loss {'Reaction outcome loss': 0.5097821011778808, 'Total loss': 0.5097821011778808}
2022-12-05 23:01:54,958 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:54,958 INFO:     Epoch: 47
2022-12-05 23:01:55,667 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5505433837798509, 'Total loss': 0.5505433837798509} | train loss {'Reaction outcome loss': 0.5007431838781603, 'Total loss': 0.5007431838781603}
2022-12-05 23:01:55,667 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:55,667 INFO:     Epoch: 48
2022-12-05 23:01:56,373 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5394932885061611, 'Total loss': 0.5394932885061611} | train loss {'Reaction outcome loss': 0.5082904090804439, 'Total loss': 0.5082904090804439}
2022-12-05 23:01:56,374 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:56,374 INFO:     Epoch: 49
2022-12-05 23:01:57,081 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5344462245702744, 'Total loss': 0.5344462245702744} | train loss {'Reaction outcome loss': 0.5030462869833554, 'Total loss': 0.5030462869833554}
2022-12-05 23:01:57,081 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:57,081 INFO:     Epoch: 50
2022-12-05 23:01:57,786 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5283092836087401, 'Total loss': 0.5283092836087401} | train loss {'Reaction outcome loss': 0.5058660029523796, 'Total loss': 0.5058660029523796}
2022-12-05 23:01:57,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:57,787 INFO:     Epoch: 51
2022-12-05 23:01:58,492 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4939030828801068, 'Total loss': 0.4939030828801068} | train loss {'Reaction outcome loss': 0.49656774992904357, 'Total loss': 0.49656774992904357}
2022-12-05 23:01:58,492 INFO:     Found new best model at epoch 51
2022-12-05 23:01:58,493 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:58,493 INFO:     Epoch: 52
2022-12-05 23:01:59,197 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5035316530953754, 'Total loss': 0.5035316530953754} | train loss {'Reaction outcome loss': 0.5080558739963078, 'Total loss': 0.5080558739963078}
2022-12-05 23:01:59,197 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:59,197 INFO:     Epoch: 53
2022-12-05 23:01:59,902 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5423062751916322, 'Total loss': 0.5423062751916322} | train loss {'Reaction outcome loss': 0.506136946500309, 'Total loss': 0.506136946500309}
2022-12-05 23:01:59,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:01:59,903 INFO:     Epoch: 54
2022-12-05 23:02:00,607 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5330061733045361, 'Total loss': 0.5330061733045361} | train loss {'Reaction outcome loss': 0.5035075718356717, 'Total loss': 0.5035075718356717}
2022-12-05 23:02:00,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:00,607 INFO:     Epoch: 55
2022-12-05 23:02:01,315 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5436617830260233, 'Total loss': 0.5436617830260233} | train loss {'Reaction outcome loss': 0.509017008627134, 'Total loss': 0.509017008627134}
2022-12-05 23:02:01,315 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:01,316 INFO:     Epoch: 56
2022-12-05 23:02:02,021 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5355129736390981, 'Total loss': 0.5355129736390981} | train loss {'Reaction outcome loss': 0.5029151770736902, 'Total loss': 0.5029151770736902}
2022-12-05 23:02:02,021 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:02,021 INFO:     Epoch: 57
2022-12-05 23:02:02,729 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5215113427151333, 'Total loss': 0.5215113427151333} | train loss {'Reaction outcome loss': 0.4988879117994539, 'Total loss': 0.4988879117994539}
2022-12-05 23:02:02,729 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:02,729 INFO:     Epoch: 58
2022-12-05 23:02:03,434 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.523631754246625, 'Total loss': 0.523631754246625} | train loss {'Reaction outcome loss': 0.5109169584729017, 'Total loss': 0.5109169584729017}
2022-12-05 23:02:03,435 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:03,435 INFO:     Epoch: 59
2022-12-05 23:02:04,140 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5153004696423357, 'Total loss': 0.5153004696423357} | train loss {'Reaction outcome loss': 0.5005467540073779, 'Total loss': 0.5005467540073779}
2022-12-05 23:02:04,140 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:04,140 INFO:     Epoch: 60
2022-12-05 23:02:04,847 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5244029452177611, 'Total loss': 0.5244029452177611} | train loss {'Reaction outcome loss': 0.4965829893105453, 'Total loss': 0.4965829893105453}
2022-12-05 23:02:04,847 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:04,847 INFO:     Epoch: 61
2022-12-05 23:02:05,551 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5362792353738438, 'Total loss': 0.5362792353738438} | train loss {'Reaction outcome loss': 0.5092025081657113, 'Total loss': 0.5092025081657113}
2022-12-05 23:02:05,551 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:05,551 INFO:     Epoch: 62
2022-12-05 23:02:06,256 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5410340170968663, 'Total loss': 0.5410340170968663} | train loss {'Reaction outcome loss': 0.4972287614138857, 'Total loss': 0.4972287614138857}
2022-12-05 23:02:06,257 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:06,257 INFO:     Epoch: 63
2022-12-05 23:02:06,966 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5138306719335642, 'Total loss': 0.5138306719335642} | train loss {'Reaction outcome loss': 0.5014203310974182, 'Total loss': 0.5014203310974182}
2022-12-05 23:02:06,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:06,966 INFO:     Epoch: 64
2022-12-05 23:02:07,671 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.548909030854702, 'Total loss': 0.548909030854702} | train loss {'Reaction outcome loss': 0.5027681972771403, 'Total loss': 0.5027681972771403}
2022-12-05 23:02:07,671 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:07,671 INFO:     Epoch: 65
2022-12-05 23:02:08,375 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5315456414087252, 'Total loss': 0.5315456414087252} | train loss {'Reaction outcome loss': 0.5041971912066783, 'Total loss': 0.5041971912066783}
2022-12-05 23:02:08,375 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:08,375 INFO:     Epoch: 66
2022-12-05 23:02:09,082 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.529335202818567, 'Total loss': 0.529335202818567} | train loss {'Reaction outcome loss': 0.5008095610406129, 'Total loss': 0.5008095610406129}
2022-12-05 23:02:09,082 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:09,082 INFO:     Epoch: 67
2022-12-05 23:02:09,792 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5318548733537848, 'Total loss': 0.5318548733537848} | train loss {'Reaction outcome loss': 0.5028439861752333, 'Total loss': 0.5028439861752333}
2022-12-05 23:02:09,793 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:09,793 INFO:     Epoch: 68
2022-12-05 23:02:10,497 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5404539480805397, 'Total loss': 0.5404539480805397} | train loss {'Reaction outcome loss': 0.5086040942058447, 'Total loss': 0.5086040942058447}
2022-12-05 23:02:10,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:10,497 INFO:     Epoch: 69
2022-12-05 23:02:11,201 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5982414914125745, 'Total loss': 0.5982414914125745} | train loss {'Reaction outcome loss': 0.5010268470092166, 'Total loss': 0.5010268470092166}
2022-12-05 23:02:11,201 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:11,202 INFO:     Epoch: 70
2022-12-05 23:02:11,906 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5428724580190398, 'Total loss': 0.5428724580190398} | train loss {'Reaction outcome loss': 0.5038968880450533, 'Total loss': 0.5038968880450533}
2022-12-05 23:02:11,906 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:11,906 INFO:     Epoch: 71
2022-12-05 23:02:12,614 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5790104588324373, 'Total loss': 0.5790104588324373} | train loss {'Reaction outcome loss': 0.49985998682677746, 'Total loss': 0.49985998682677746}
2022-12-05 23:02:12,614 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:12,614 INFO:     Epoch: 72
2022-12-05 23:02:13,318 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5414704429832372, 'Total loss': 0.5414704429832372} | train loss {'Reaction outcome loss': 0.49627592630924716, 'Total loss': 0.49627592630924716}
2022-12-05 23:02:13,318 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:13,318 INFO:     Epoch: 73
2022-12-05 23:02:14,022 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5267785110256888, 'Total loss': 0.5267785110256888} | train loss {'Reaction outcome loss': 0.49615529810468995, 'Total loss': 0.49615529810468995}
2022-12-05 23:02:14,022 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:14,022 INFO:     Epoch: 74
2022-12-05 23:02:14,726 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5407386889511888, 'Total loss': 0.5407386889511888} | train loss {'Reaction outcome loss': 0.5097206488492028, 'Total loss': 0.5097206488492028}
2022-12-05 23:02:14,726 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:14,727 INFO:     Epoch: 75
2022-12-05 23:02:15,430 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5196215029467236, 'Total loss': 0.5196215029467236} | train loss {'Reaction outcome loss': 0.5068741715963809, 'Total loss': 0.5068741715963809}
2022-12-05 23:02:15,430 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:15,431 INFO:     Epoch: 76
2022-12-05 23:02:16,135 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5674605599858544, 'Total loss': 0.5674605599858544} | train loss {'Reaction outcome loss': 0.5012162798234532, 'Total loss': 0.5012162798234532}
2022-12-05 23:02:16,135 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:16,135 INFO:     Epoch: 77
2022-12-05 23:02:16,843 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5596257400783625, 'Total loss': 0.5596257400783625} | train loss {'Reaction outcome loss': 0.5119763149489318, 'Total loss': 0.5119763149489318}
2022-12-05 23:02:16,843 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:16,844 INFO:     Epoch: 78
2022-12-05 23:02:17,547 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.597973361950029, 'Total loss': 0.597973361950029} | train loss {'Reaction outcome loss': 0.4957320843372614, 'Total loss': 0.4957320843372614}
2022-12-05 23:02:17,547 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:17,547 INFO:     Epoch: 79
2022-12-05 23:02:18,252 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5194364203648134, 'Total loss': 0.5194364203648134} | train loss {'Reaction outcome loss': 0.5022986670355162, 'Total loss': 0.5022986670355162}
2022-12-05 23:02:18,252 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:18,252 INFO:     Epoch: 80
2022-12-05 23:02:18,957 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5319196791811422, 'Total loss': 0.5319196791811422} | train loss {'Reaction outcome loss': 0.5050638622694439, 'Total loss': 0.5050638622694439}
2022-12-05 23:02:18,957 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:18,957 INFO:     Epoch: 81
2022-12-05 23:02:19,662 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5174610374326055, 'Total loss': 0.5174610374326055} | train loss {'Reaction outcome loss': 0.49947619534307913, 'Total loss': 0.49947619534307913}
2022-12-05 23:02:19,662 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:19,662 INFO:     Epoch: 82
2022-12-05 23:02:20,368 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5565528879788789, 'Total loss': 0.5565528879788789} | train loss {'Reaction outcome loss': 0.5002668751103263, 'Total loss': 0.5002668751103263}
2022-12-05 23:02:20,368 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:20,368 INFO:     Epoch: 83
2022-12-05 23:02:21,076 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.531435186212713, 'Total loss': 0.531435186212713} | train loss {'Reaction outcome loss': 0.5036042852988166, 'Total loss': 0.5036042852988166}
2022-12-05 23:02:21,076 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:21,076 INFO:     Epoch: 84
2022-12-05 23:02:21,781 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5477179326117039, 'Total loss': 0.5477179326117039} | train loss {'Reaction outcome loss': 0.499217999378039, 'Total loss': 0.499217999378039}
2022-12-05 23:02:21,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:21,782 INFO:     Epoch: 85
2022-12-05 23:02:22,487 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5345737236467275, 'Total loss': 0.5345737236467275} | train loss {'Reaction outcome loss': 0.5063451726830774, 'Total loss': 0.5063451726830774}
2022-12-05 23:02:22,488 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:22,488 INFO:     Epoch: 86
2022-12-05 23:02:23,192 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.540846149013801, 'Total loss': 0.540846149013801} | train loss {'Reaction outcome loss': 0.5088107152090918, 'Total loss': 0.5088107152090918}
2022-12-05 23:02:23,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:23,193 INFO:     Epoch: 87
2022-12-05 23:02:23,898 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5298060605471785, 'Total loss': 0.5298060605471785} | train loss {'Reaction outcome loss': 0.5017700370761656, 'Total loss': 0.5017700370761656}
2022-12-05 23:02:23,898 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:23,898 INFO:     Epoch: 88
2022-12-05 23:02:24,606 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5547879399223761, 'Total loss': 0.5547879399223761} | train loss {'Reaction outcome loss': 0.5014510630599914, 'Total loss': 0.5014510630599914}
2022-12-05 23:02:24,606 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:24,606 INFO:     Epoch: 89
2022-12-05 23:02:25,312 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.6110604439269413, 'Total loss': 0.6110604439269413} | train loss {'Reaction outcome loss': 0.5047686414252366, 'Total loss': 0.5047686414252366}
2022-12-05 23:02:25,312 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:25,312 INFO:     Epoch: 90
2022-12-05 23:02:26,017 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5154279128394343, 'Total loss': 0.5154279128394343} | train loss {'Reaction outcome loss': 0.4995953404615002, 'Total loss': 0.4995953404615002}
2022-12-05 23:02:26,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:26,017 INFO:     Epoch: 91
2022-12-05 23:02:26,722 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5678942250934514, 'Total loss': 0.5678942250934514} | train loss {'Reaction outcome loss': 0.5010247893270946, 'Total loss': 0.5010247893270946}
2022-12-05 23:02:26,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:26,723 INFO:     Epoch: 92
2022-12-05 23:02:27,428 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5503015497868712, 'Total loss': 0.5503015497868712} | train loss {'Reaction outcome loss': 0.5011721551418304, 'Total loss': 0.5011721551418304}
2022-12-05 23:02:27,428 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:27,429 INFO:     Epoch: 93
2022-12-05 23:02:28,134 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5304558588699861, 'Total loss': 0.5304558588699861} | train loss {'Reaction outcome loss': 0.5059290055425898, 'Total loss': 0.5059290055425898}
2022-12-05 23:02:28,135 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:28,135 INFO:     Epoch: 94
2022-12-05 23:02:28,843 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5274987281723456, 'Total loss': 0.5274987281723456} | train loss {'Reaction outcome loss': 0.4993844237178564, 'Total loss': 0.4993844237178564}
2022-12-05 23:02:28,844 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:28,844 INFO:     Epoch: 95
2022-12-05 23:02:29,548 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5033542449501428, 'Total loss': 0.5033542449501428} | train loss {'Reaction outcome loss': 0.49830597627066797, 'Total loss': 0.49830597627066797}
2022-12-05 23:02:29,548 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:29,548 INFO:     Epoch: 96
2022-12-05 23:02:30,254 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.49530015885829926, 'Total loss': 0.49530015885829926} | train loss {'Reaction outcome loss': 0.5005480171211304, 'Total loss': 0.5005480171211304}
2022-12-05 23:02:30,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:30,254 INFO:     Epoch: 97
2022-12-05 23:02:30,959 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5222876627336849, 'Total loss': 0.5222876627336849} | train loss {'Reaction outcome loss': 0.5068113653049353, 'Total loss': 0.5068113653049353}
2022-12-05 23:02:30,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:30,959 INFO:     Epoch: 98
2022-12-05 23:02:31,665 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.517472501505505, 'Total loss': 0.517472501505505} | train loss {'Reaction outcome loss': 0.5111571951138396, 'Total loss': 0.5111571951138396}
2022-12-05 23:02:31,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:31,665 INFO:     Epoch: 99
2022-12-05 23:02:32,376 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.514891994947737, 'Total loss': 0.514891994947737} | train loss {'Reaction outcome loss': 0.5031235995552232, 'Total loss': 0.5031235995552232}
2022-12-05 23:02:32,377 INFO:     Best model found after epoch 52 of 100.
2022-12-05 23:02:32,377 INFO:   Done with stage: TRAINING
2022-12-05 23:02:32,377 INFO:   Starting stage: EVALUATION
2022-12-05 23:02:32,495 INFO:   Done with stage: EVALUATION
2022-12-05 23:02:32,495 INFO:   Leaving out SEQ value Fold_8
2022-12-05 23:02:32,508 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:02:32,508 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:02:33,143 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:02:33,143 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:02:33,214 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:02:33,214 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:02:33,214 INFO:     No hyperparam tuning for this model
2022-12-05 23:02:33,214 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:02:33,215 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:02:33,215 INFO:     None feature selector for col prot
2022-12-05 23:02:33,215 INFO:     None feature selector for col prot
2022-12-05 23:02:33,215 INFO:     None feature selector for col prot
2022-12-05 23:02:33,216 INFO:     None feature selector for col chem
2022-12-05 23:02:33,216 INFO:     None feature selector for col chem
2022-12-05 23:02:33,216 INFO:     None feature selector for col chem
2022-12-05 23:02:33,216 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:02:33,216 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:02:33,218 INFO:     Number of params in model 215731
2022-12-05 23:02:33,221 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:02:33,221 INFO:   Starting stage: TRAINING
2022-12-05 23:02:33,279 INFO:     Val loss before train {'Reaction outcome loss': 1.0103996924378655, 'Total loss': 1.0103996924378655}
2022-12-05 23:02:33,280 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:33,280 INFO:     Epoch: 0
2022-12-05 23:02:33,987 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7541436207565394, 'Total loss': 0.7541436207565394} | train loss {'Reaction outcome loss': 0.8093879432813359, 'Total loss': 0.8093879432813359}
2022-12-05 23:02:33,987 INFO:     Found new best model at epoch 0
2022-12-05 23:02:33,987 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:33,987 INFO:     Epoch: 1
2022-12-05 23:02:34,692 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6355528099970384, 'Total loss': 0.6355528099970384} | train loss {'Reaction outcome loss': 0.6771063857112336, 'Total loss': 0.6771063857112336}
2022-12-05 23:02:34,693 INFO:     Found new best model at epoch 1
2022-12-05 23:02:34,693 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:34,693 INFO:     Epoch: 2
2022-12-05 23:02:35,399 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5967217439954932, 'Total loss': 0.5967217439954932} | train loss {'Reaction outcome loss': 0.6181666907752573, 'Total loss': 0.6181666907752573}
2022-12-05 23:02:35,399 INFO:     Found new best model at epoch 2
2022-12-05 23:02:35,400 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:35,400 INFO:     Epoch: 3
2022-12-05 23:02:36,102 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6054367673667994, 'Total loss': 0.6054367673667994} | train loss {'Reaction outcome loss': 0.6067776931562887, 'Total loss': 0.6067776931562887}
2022-12-05 23:02:36,102 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:36,102 INFO:     Epoch: 4
2022-12-05 23:02:36,813 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5623146668076515, 'Total loss': 0.5623146668076515} | train loss {'Reaction outcome loss': 0.5939090153587009, 'Total loss': 0.5939090153587009}
2022-12-05 23:02:36,813 INFO:     Found new best model at epoch 4
2022-12-05 23:02:36,813 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:36,814 INFO:     Epoch: 5
2022-12-05 23:02:37,528 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5734983506527814, 'Total loss': 0.5734983506527814} | train loss {'Reaction outcome loss': 0.5792619557674175, 'Total loss': 0.5792619557674175}
2022-12-05 23:02:37,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:37,528 INFO:     Epoch: 6
2022-12-05 23:02:38,241 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5800751633942127, 'Total loss': 0.5800751633942127} | train loss {'Reaction outcome loss': 0.5750385311089063, 'Total loss': 0.5750385311089063}
2022-12-05 23:02:38,241 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:38,241 INFO:     Epoch: 7
2022-12-05 23:02:38,954 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6111368225379423, 'Total loss': 0.6111368225379423} | train loss {'Reaction outcome loss': 0.5686603206764107, 'Total loss': 0.5686603206764107}
2022-12-05 23:02:38,954 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:38,954 INFO:     Epoch: 8
2022-12-05 23:02:39,669 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6348904886028983, 'Total loss': 0.6348904886028983} | train loss {'Reaction outcome loss': 0.5476612956055745, 'Total loss': 0.5476612956055745}
2022-12-05 23:02:39,669 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:39,669 INFO:     Epoch: 9
2022-12-05 23:02:40,386 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5684672302820466, 'Total loss': 0.5684672302820466} | train loss {'Reaction outcome loss': 0.5582796676076858, 'Total loss': 0.5582796676076858}
2022-12-05 23:02:40,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:40,386 INFO:     Epoch: 10
2022-12-05 23:02:41,102 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.574816533787684, 'Total loss': 0.574816533787684} | train loss {'Reaction outcome loss': 0.5509120429213713, 'Total loss': 0.5509120429213713}
2022-12-05 23:02:41,103 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:41,103 INFO:     Epoch: 11
2022-12-05 23:02:41,816 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.6098368140784177, 'Total loss': 0.6098368140784177} | train loss {'Reaction outcome loss': 0.5500146729140146, 'Total loss': 0.5500146729140146}
2022-12-05 23:02:41,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:41,816 INFO:     Epoch: 12
2022-12-05 23:02:42,532 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5844009701501239, 'Total loss': 0.5844009701501239} | train loss {'Reaction outcome loss': 0.5639778577123093, 'Total loss': 0.5639778577123093}
2022-12-05 23:02:42,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:42,532 INFO:     Epoch: 13
2022-12-05 23:02:43,243 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5969409441406076, 'Total loss': 0.5969409441406076} | train loss {'Reaction outcome loss': 0.5459505420947365, 'Total loss': 0.5459505420947365}
2022-12-05 23:02:43,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:43,243 INFO:     Epoch: 14
2022-12-05 23:02:43,959 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5474103228612379, 'Total loss': 0.5474103228612379} | train loss {'Reaction outcome loss': 0.5535312566438667, 'Total loss': 0.5535312566438667}
2022-12-05 23:02:43,959 INFO:     Found new best model at epoch 14
2022-12-05 23:02:43,960 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:43,960 INFO:     Epoch: 15
2022-12-05 23:02:44,671 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.519447038796815, 'Total loss': 0.519447038796815} | train loss {'Reaction outcome loss': 0.5388473555867971, 'Total loss': 0.5388473555867971}
2022-12-05 23:02:44,672 INFO:     Found new best model at epoch 15
2022-12-05 23:02:44,672 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:44,672 INFO:     Epoch: 16
2022-12-05 23:02:45,384 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5422634543343023, 'Total loss': 0.5422634543343023} | train loss {'Reaction outcome loss': 0.5307124652843244, 'Total loss': 0.5307124652843244}
2022-12-05 23:02:45,384 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:45,384 INFO:     Epoch: 17
2022-12-05 23:02:46,098 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5441067144274712, 'Total loss': 0.5441067144274712} | train loss {'Reaction outcome loss': 0.5307794879473414, 'Total loss': 0.5307794879473414}
2022-12-05 23:02:46,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:46,099 INFO:     Epoch: 18
2022-12-05 23:02:46,811 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5711254260756753, 'Total loss': 0.5711254260756753} | train loss {'Reaction outcome loss': 0.534174023067903, 'Total loss': 0.534174023067903}
2022-12-05 23:02:46,811 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:46,811 INFO:     Epoch: 19
2022-12-05 23:02:47,528 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5332718843763525, 'Total loss': 0.5332718843763525} | train loss {'Reaction outcome loss': 0.5481092737391893, 'Total loss': 0.5481092737391893}
2022-12-05 23:02:47,529 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:47,529 INFO:     Epoch: 20
2022-12-05 23:02:48,243 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5639890879392624, 'Total loss': 0.5639890879392624} | train loss {'Reaction outcome loss': 0.5300689635851122, 'Total loss': 0.5300689635851122}
2022-12-05 23:02:48,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:48,243 INFO:     Epoch: 21
2022-12-05 23:02:48,958 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5671314346519384, 'Total loss': 0.5671314346519384} | train loss {'Reaction outcome loss': 0.5282135905041868, 'Total loss': 0.5282135905041868}
2022-12-05 23:02:48,958 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:48,958 INFO:     Epoch: 22
2022-12-05 23:02:49,672 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5382973318072882, 'Total loss': 0.5382973318072882} | train loss {'Reaction outcome loss': 0.531260016114123, 'Total loss': 0.531260016114123}
2022-12-05 23:02:49,672 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:49,672 INFO:     Epoch: 23
2022-12-05 23:02:50,385 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5789819861000235, 'Total loss': 0.5789819861000235} | train loss {'Reaction outcome loss': 0.5272495628368516, 'Total loss': 0.5272495628368516}
2022-12-05 23:02:50,385 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:50,385 INFO:     Epoch: 24
2022-12-05 23:02:51,098 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5568964762443845, 'Total loss': 0.5568964762443845} | train loss {'Reaction outcome loss': 0.5533021678808729, 'Total loss': 0.5533021678808729}
2022-12-05 23:02:51,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:51,098 INFO:     Epoch: 25
2022-12-05 23:02:51,813 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5274983021346006, 'Total loss': 0.5274983021346006} | train loss {'Reaction outcome loss': 0.5225842931469985, 'Total loss': 0.5225842931469985}
2022-12-05 23:02:51,813 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:51,813 INFO:     Epoch: 26
2022-12-05 23:02:52,525 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.539323681796139, 'Total loss': 0.539323681796139} | train loss {'Reaction outcome loss': 0.5218726040885938, 'Total loss': 0.5218726040885938}
2022-12-05 23:02:52,526 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:52,526 INFO:     Epoch: 27
2022-12-05 23:02:53,238 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.523773689838973, 'Total loss': 0.523773689838973} | train loss {'Reaction outcome loss': 0.518747051476467, 'Total loss': 0.518747051476467}
2022-12-05 23:02:53,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:53,238 INFO:     Epoch: 28
2022-12-05 23:02:53,951 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5607841908931732, 'Total loss': 0.5607841908931732} | train loss {'Reaction outcome loss': 0.5274437445438342, 'Total loss': 0.5274437445438342}
2022-12-05 23:02:53,952 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:53,952 INFO:     Epoch: 29
2022-12-05 23:02:54,667 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5319616205312989, 'Total loss': 0.5319616205312989} | train loss {'Reaction outcome loss': 0.5332679420347638, 'Total loss': 0.5332679420347638}
2022-12-05 23:02:54,667 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:54,667 INFO:     Epoch: 30
2022-12-05 23:02:55,383 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5222509818320925, 'Total loss': 0.5222509818320925} | train loss {'Reaction outcome loss': 0.5285785782795686, 'Total loss': 0.5285785782795686}
2022-12-05 23:02:55,383 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:55,383 INFO:     Epoch: 31
2022-12-05 23:02:56,095 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5369815941561352, 'Total loss': 0.5369815941561352} | train loss {'Reaction outcome loss': 0.5171669802443701, 'Total loss': 0.5171669802443701}
2022-12-05 23:02:56,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:56,095 INFO:     Epoch: 32
2022-12-05 23:02:56,803 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5829720822247592, 'Total loss': 0.5829720822247592} | train loss {'Reaction outcome loss': 0.5228106045891882, 'Total loss': 0.5228106045891882}
2022-12-05 23:02:56,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:56,804 INFO:     Epoch: 33
2022-12-05 23:02:57,510 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5436589731411501, 'Total loss': 0.5436589731411501} | train loss {'Reaction outcome loss': 0.5363708091409582, 'Total loss': 0.5363708091409582}
2022-12-05 23:02:57,510 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:57,510 INFO:     Epoch: 34
2022-12-05 23:02:58,216 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.537996883419427, 'Total loss': 0.537996883419427} | train loss {'Reaction outcome loss': 0.5179927173515533, 'Total loss': 0.5179927173515533}
2022-12-05 23:02:58,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:58,216 INFO:     Epoch: 35
2022-12-05 23:02:58,923 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5647189928726717, 'Total loss': 0.5647189928726717} | train loss {'Reaction outcome loss': 0.5210980011625328, 'Total loss': 0.5210980011625328}
2022-12-05 23:02:58,923 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:58,923 INFO:     Epoch: 36
2022-12-05 23:02:59,629 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.517567017538981, 'Total loss': 0.517567017538981} | train loss {'Reaction outcome loss': 0.5145982028313192, 'Total loss': 0.5145982028313192}
2022-12-05 23:02:59,629 INFO:     Found new best model at epoch 36
2022-12-05 23:02:59,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:02:59,630 INFO:     Epoch: 37
2022-12-05 23:03:00,335 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.51459505002607, 'Total loss': 0.51459505002607} | train loss {'Reaction outcome loss': 0.5200196931719298, 'Total loss': 0.5200196931719298}
2022-12-05 23:03:00,336 INFO:     Found new best model at epoch 37
2022-12-05 23:03:00,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:00,337 INFO:     Epoch: 38
2022-12-05 23:03:01,045 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5460416386750612, 'Total loss': 0.5460416386750612} | train loss {'Reaction outcome loss': 0.5188167705978286, 'Total loss': 0.5188167705978286}
2022-12-05 23:03:01,045 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:01,046 INFO:     Epoch: 39
2022-12-05 23:03:01,752 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.565799206495285, 'Total loss': 0.565799206495285} | train loss {'Reaction outcome loss': 0.5154709495030917, 'Total loss': 0.5154709495030917}
2022-12-05 23:03:01,752 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:01,753 INFO:     Epoch: 40
2022-12-05 23:03:02,461 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5135703513568098, 'Total loss': 0.5135703513568098} | train loss {'Reaction outcome loss': 0.5311131995578526, 'Total loss': 0.5311131995578526}
2022-12-05 23:03:02,461 INFO:     Found new best model at epoch 40
2022-12-05 23:03:02,462 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:02,462 INFO:     Epoch: 41
2022-12-05 23:03:03,165 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5065096914768219, 'Total loss': 0.5065096914768219} | train loss {'Reaction outcome loss': 0.5219242395418375, 'Total loss': 0.5219242395418375}
2022-12-05 23:03:03,165 INFO:     Found new best model at epoch 41
2022-12-05 23:03:03,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:03,166 INFO:     Epoch: 42
2022-12-05 23:03:03,872 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5424321646040137, 'Total loss': 0.5424321646040137} | train loss {'Reaction outcome loss': 0.5132684664205018, 'Total loss': 0.5132684664205018}
2022-12-05 23:03:03,872 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:03,872 INFO:     Epoch: 43
2022-12-05 23:03:04,575 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5349651581861756, 'Total loss': 0.5349651581861756} | train loss {'Reaction outcome loss': 0.5288698836135478, 'Total loss': 0.5288698836135478}
2022-12-05 23:03:04,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:04,575 INFO:     Epoch: 44
2022-12-05 23:03:05,277 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5302447280423208, 'Total loss': 0.5302447280423208} | train loss {'Reaction outcome loss': 0.535277974147063, 'Total loss': 0.535277974147063}
2022-12-05 23:03:05,277 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:05,277 INFO:     Epoch: 45
2022-12-05 23:03:05,981 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5309625464406881, 'Total loss': 0.5309625464406881} | train loss {'Reaction outcome loss': 0.5106854326495154, 'Total loss': 0.5106854326495154}
2022-12-05 23:03:05,981 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:05,981 INFO:     Epoch: 46
2022-12-05 23:03:06,685 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5175814405083656, 'Total loss': 0.5175814405083656} | train loss {'Reaction outcome loss': 0.5232086355386958, 'Total loss': 0.5232086355386958}
2022-12-05 23:03:06,685 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:06,685 INFO:     Epoch: 47
2022-12-05 23:03:07,387 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5200060978531837, 'Total loss': 0.5200060978531837} | train loss {'Reaction outcome loss': 0.5190097067640861, 'Total loss': 0.5190097067640861}
2022-12-05 23:03:07,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:07,387 INFO:     Epoch: 48
2022-12-05 23:03:08,089 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5434030504389242, 'Total loss': 0.5434030504389242} | train loss {'Reaction outcome loss': 0.5155038346163174, 'Total loss': 0.5155038346163174}
2022-12-05 23:03:08,089 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:08,090 INFO:     Epoch: 49
2022-12-05 23:03:08,792 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5416598428379406, 'Total loss': 0.5416598428379406} | train loss {'Reaction outcome loss': 0.5204384512143579, 'Total loss': 0.5204384512143579}
2022-12-05 23:03:08,792 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:08,792 INFO:     Epoch: 50
2022-12-05 23:03:09,499 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.534732903607867, 'Total loss': 0.534732903607867} | train loss {'Reaction outcome loss': 0.5221483943916043, 'Total loss': 0.5221483943916043}
2022-12-05 23:03:09,499 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:09,499 INFO:     Epoch: 51
2022-12-05 23:03:10,206 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.540942816233093, 'Total loss': 0.540942816233093} | train loss {'Reaction outcome loss': 0.5174000374228139, 'Total loss': 0.5174000374228139}
2022-12-05 23:03:10,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:10,207 INFO:     Epoch: 52
2022-12-05 23:03:10,909 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5313087315721945, 'Total loss': 0.5313087315721945} | train loss {'Reaction outcome loss': 0.51964998341765, 'Total loss': 0.51964998341765}
2022-12-05 23:03:10,909 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:10,910 INFO:     Epoch: 53
2022-12-05 23:03:11,619 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5198080417784777, 'Total loss': 0.5198080417784777} | train loss {'Reaction outcome loss': 0.5093075330859345, 'Total loss': 0.5093075330859345}
2022-12-05 23:03:11,619 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:11,619 INFO:     Epoch: 54
2022-12-05 23:03:12,324 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5682935599576343, 'Total loss': 0.5682935599576343} | train loss {'Reaction outcome loss': 0.5210431240666809, 'Total loss': 0.5210431240666809}
2022-12-05 23:03:12,324 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:12,324 INFO:     Epoch: 55
2022-12-05 23:03:13,027 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5470787903124635, 'Total loss': 0.5470787903124635} | train loss {'Reaction outcome loss': 0.5154451274799432, 'Total loss': 0.5154451274799432}
2022-12-05 23:03:13,028 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:13,028 INFO:     Epoch: 56
2022-12-05 23:03:13,730 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5401946746490218, 'Total loss': 0.5401946746490218} | train loss {'Reaction outcome loss': 0.5225698324108896, 'Total loss': 0.5225698324108896}
2022-12-05 23:03:13,731 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:13,731 INFO:     Epoch: 57
2022-12-05 23:03:14,434 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5457614192908461, 'Total loss': 0.5457614192908461} | train loss {'Reaction outcome loss': 0.509036935654729, 'Total loss': 0.509036935654729}
2022-12-05 23:03:14,434 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:14,434 INFO:     Epoch: 58
2022-12-05 23:03:15,138 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.563100163909522, 'Total loss': 0.563100163909522} | train loss {'Reaction outcome loss': 0.5134078067565254, 'Total loss': 0.5134078067565254}
2022-12-05 23:03:15,139 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:15,139 INFO:     Epoch: 59
2022-12-05 23:03:15,845 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5108826702291315, 'Total loss': 0.5108826702291315} | train loss {'Reaction outcome loss': 0.5274222758391246, 'Total loss': 0.5274222758391246}
2022-12-05 23:03:15,845 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:15,845 INFO:     Epoch: 60
2022-12-05 23:03:16,553 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5461586124517701, 'Total loss': 0.5461586124517701} | train loss {'Reaction outcome loss': 0.5114493477139396, 'Total loss': 0.5114493477139396}
2022-12-05 23:03:16,553 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:16,553 INFO:     Epoch: 61
2022-12-05 23:03:17,255 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5707631029865958, 'Total loss': 0.5707631029865958} | train loss {'Reaction outcome loss': 0.5171605377544758, 'Total loss': 0.5171605377544758}
2022-12-05 23:03:17,255 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:17,255 INFO:     Epoch: 62
2022-12-05 23:03:17,960 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5160016024654562, 'Total loss': 0.5160016024654562} | train loss {'Reaction outcome loss': 0.5157878007588961, 'Total loss': 0.5157878007588961}
2022-12-05 23:03:17,960 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:17,960 INFO:     Epoch: 63
2022-12-05 23:03:18,664 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5319925763390281, 'Total loss': 0.5319925763390281} | train loss {'Reaction outcome loss': 0.5150931285136202, 'Total loss': 0.5150931285136202}
2022-12-05 23:03:18,664 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:18,664 INFO:     Epoch: 64
2022-12-05 23:03:19,367 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5454408892176368, 'Total loss': 0.5454408892176368} | train loss {'Reaction outcome loss': 0.5170289378779137, 'Total loss': 0.5170289378779137}
2022-12-05 23:03:19,367 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:19,367 INFO:     Epoch: 65
2022-12-05 23:03:20,070 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5468238057060675, 'Total loss': 0.5468238057060675} | train loss {'Reaction outcome loss': 0.5153627555802284, 'Total loss': 0.5153627555802284}
2022-12-05 23:03:20,070 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:20,071 INFO:     Epoch: 66
2022-12-05 23:03:20,776 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5437926453622904, 'Total loss': 0.5437926453622904} | train loss {'Reaction outcome loss': 0.5153279124121917, 'Total loss': 0.5153279124121917}
2022-12-05 23:03:20,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:20,776 INFO:     Epoch: 67
2022-12-05 23:03:21,481 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5323793231086298, 'Total loss': 0.5323793231086298} | train loss {'Reaction outcome loss': 0.5214506142173219, 'Total loss': 0.5214506142173219}
2022-12-05 23:03:21,481 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:21,481 INFO:     Epoch: 68
2022-12-05 23:03:22,188 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.563876597718759, 'Total loss': 0.563876597718759} | train loss {'Reaction outcome loss': 0.518640758688392, 'Total loss': 0.518640758688392}
2022-12-05 23:03:22,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:22,188 INFO:     Epoch: 69
2022-12-05 23:03:22,892 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5348079075867479, 'Total loss': 0.5348079075867479} | train loss {'Reaction outcome loss': 0.5192310484918022, 'Total loss': 0.5192310484918022}
2022-12-05 23:03:22,892 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:22,892 INFO:     Epoch: 70
2022-12-05 23:03:23,599 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.538221055472439, 'Total loss': 0.538221055472439} | train loss {'Reaction outcome loss': 0.5194610609458044, 'Total loss': 0.5194610609458044}
2022-12-05 23:03:23,599 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:23,599 INFO:     Epoch: 71
2022-12-05 23:03:24,308 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5465096086263657, 'Total loss': 0.5465096086263657} | train loss {'Reaction outcome loss': 0.5223560089524458, 'Total loss': 0.5223560089524458}
2022-12-05 23:03:24,308 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:24,308 INFO:     Epoch: 72
2022-12-05 23:03:25,016 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5468354130333121, 'Total loss': 0.5468354130333121} | train loss {'Reaction outcome loss': 0.5188787318313652, 'Total loss': 0.5188787318313652}
2022-12-05 23:03:25,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:25,017 INFO:     Epoch: 73
2022-12-05 23:03:25,721 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5830086293545637, 'Total loss': 0.5830086293545637} | train loss {'Reaction outcome loss': 0.5224695837932077, 'Total loss': 0.5224695837932077}
2022-12-05 23:03:25,721 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:25,721 INFO:     Epoch: 74
2022-12-05 23:03:26,424 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5581082444299351, 'Total loss': 0.5581082444299351} | train loss {'Reaction outcome loss': 0.5188735600236637, 'Total loss': 0.5188735600236637}
2022-12-05 23:03:26,424 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:26,424 INFO:     Epoch: 75
2022-12-05 23:03:27,127 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5314856584776532, 'Total loss': 0.5314856584776532} | train loss {'Reaction outcome loss': 0.5112532102747968, 'Total loss': 0.5112532102747968}
2022-12-05 23:03:27,127 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:27,127 INFO:     Epoch: 76
2022-12-05 23:03:27,831 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5227750837802887, 'Total loss': 0.5227750837802887} | train loss {'Reaction outcome loss': 0.5168768217568456, 'Total loss': 0.5168768217568456}
2022-12-05 23:03:27,832 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:27,832 INFO:     Epoch: 77
2022-12-05 23:03:28,535 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5826005041599274, 'Total loss': 0.5826005041599274} | train loss {'Reaction outcome loss': 0.5199085091832678, 'Total loss': 0.5199085091832678}
2022-12-05 23:03:28,535 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:28,535 INFO:     Epoch: 78
2022-12-05 23:03:29,238 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5369152629917319, 'Total loss': 0.5369152629917319} | train loss {'Reaction outcome loss': 0.5128145048975462, 'Total loss': 0.5128145048975462}
2022-12-05 23:03:29,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:29,238 INFO:     Epoch: 79
2022-12-05 23:03:29,941 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5488757972012867, 'Total loss': 0.5488757972012867} | train loss {'Reaction outcome loss': 0.5181051290288627, 'Total loss': 0.5181051290288627}
2022-12-05 23:03:29,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:29,941 INFO:     Epoch: 80
2022-12-05 23:03:30,646 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5389207364483313, 'Total loss': 0.5389207364483313} | train loss {'Reaction outcome loss': 0.5134271089485299, 'Total loss': 0.5134271089485299}
2022-12-05 23:03:30,646 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:30,646 INFO:     Epoch: 81
2022-12-05 23:03:31,355 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.52707943523472, 'Total loss': 0.52707943523472} | train loss {'Reaction outcome loss': 0.5211964915638511, 'Total loss': 0.5211964915638511}
2022-12-05 23:03:31,356 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:31,356 INFO:     Epoch: 82
2022-12-05 23:03:32,059 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5291188887574456, 'Total loss': 0.5291188887574456} | train loss {'Reaction outcome loss': 0.5148862947819204, 'Total loss': 0.5148862947819204}
2022-12-05 23:03:32,059 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:32,060 INFO:     Epoch: 83
2022-12-05 23:03:32,766 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.520084032958204, 'Total loss': 0.520084032958204} | train loss {'Reaction outcome loss': 0.5180313701360573, 'Total loss': 0.5180313701360573}
2022-12-05 23:03:32,766 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:32,766 INFO:     Epoch: 84
2022-12-05 23:03:33,470 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5854803936725314, 'Total loss': 0.5854803936725314} | train loss {'Reaction outcome loss': 0.5145985359243053, 'Total loss': 0.5145985359243053}
2022-12-05 23:03:33,470 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:33,470 INFO:     Epoch: 85
2022-12-05 23:03:34,176 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5231423218819228, 'Total loss': 0.5231423218819228} | train loss {'Reaction outcome loss': 0.5167647333738398, 'Total loss': 0.5167647333738398}
2022-12-05 23:03:34,176 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:34,176 INFO:     Epoch: 86
2022-12-05 23:03:34,880 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5233389796181158, 'Total loss': 0.5233389796181158} | train loss {'Reaction outcome loss': 0.5128235777138699, 'Total loss': 0.5128235777138699}
2022-12-05 23:03:34,880 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:34,880 INFO:     Epoch: 87
2022-12-05 23:03:35,586 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5321974002502181, 'Total loss': 0.5321974002502181} | train loss {'Reaction outcome loss': 0.5109926431405882, 'Total loss': 0.5109926431405882}
2022-12-05 23:03:35,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:35,586 INFO:     Epoch: 88
2022-12-05 23:03:36,292 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5554090270941908, 'Total loss': 0.5554090270941908} | train loss {'Reaction outcome loss': 0.5243993819001233, 'Total loss': 0.5243993819001233}
2022-12-05 23:03:36,292 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:36,292 INFO:     Epoch: 89
2022-12-05 23:03:36,996 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5044118240475655, 'Total loss': 0.5044118240475655} | train loss {'Reaction outcome loss': 0.5179867603880192, 'Total loss': 0.5179867603880192}
2022-12-05 23:03:36,996 INFO:     Found new best model at epoch 89
2022-12-05 23:03:36,997 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:36,997 INFO:     Epoch: 90
2022-12-05 23:03:37,701 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5143677301027558, 'Total loss': 0.5143677301027558} | train loss {'Reaction outcome loss': 0.5157437565838278, 'Total loss': 0.5157437565838278}
2022-12-05 23:03:37,702 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:37,702 INFO:     Epoch: 91
2022-12-05 23:03:38,405 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5429986427453432, 'Total loss': 0.5429986427453432} | train loss {'Reaction outcome loss': 0.5143213410322603, 'Total loss': 0.5143213410322603}
2022-12-05 23:03:38,405 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:38,405 INFO:     Epoch: 92
2022-12-05 23:03:39,111 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5951016822999174, 'Total loss': 0.5951016822999174} | train loss {'Reaction outcome loss': 0.5195049660408545, 'Total loss': 0.5195049660408545}
2022-12-05 23:03:39,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:39,112 INFO:     Epoch: 93
2022-12-05 23:03:39,815 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.538336262784221, 'Total loss': 0.538336262784221} | train loss {'Reaction outcome loss': 0.5170238193488389, 'Total loss': 0.5170238193488389}
2022-12-05 23:03:39,815 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:39,815 INFO:     Epoch: 94
2022-12-05 23:03:40,522 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5735428333282471, 'Total loss': 0.5735428333282471} | train loss {'Reaction outcome loss': 0.5130608758101096, 'Total loss': 0.5130608758101096}
2022-12-05 23:03:40,522 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:40,522 INFO:     Epoch: 95
2022-12-05 23:03:41,230 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5513807934793559, 'Total loss': 0.5513807934793559} | train loss {'Reaction outcome loss': 0.5103406058511271, 'Total loss': 0.5103406058511271}
2022-12-05 23:03:41,230 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:41,230 INFO:     Epoch: 96
2022-12-05 23:03:41,934 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5534337389875542, 'Total loss': 0.5534337389875542} | train loss {'Reaction outcome loss': 0.5116862647446544, 'Total loss': 0.5116862647446544}
2022-12-05 23:03:41,934 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:41,934 INFO:     Epoch: 97
2022-12-05 23:03:42,642 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5436420332301747, 'Total loss': 0.5436420332301747} | train loss {'Reaction outcome loss': 0.5231173383618747, 'Total loss': 0.5231173383618747}
2022-12-05 23:03:42,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:42,642 INFO:     Epoch: 98
2022-12-05 23:03:43,356 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.54269699041139, 'Total loss': 0.54269699041139} | train loss {'Reaction outcome loss': 0.5069775741833907, 'Total loss': 0.5069775741833907}
2022-12-05 23:03:43,357 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:43,357 INFO:     Epoch: 99
2022-12-05 23:03:44,070 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5270401564511386, 'Total loss': 0.5270401564511386} | train loss {'Reaction outcome loss': 0.5172409421466442, 'Total loss': 0.5172409421466442}
2022-12-05 23:03:44,070 INFO:     Best model found after epoch 90 of 100.
2022-12-05 23:03:44,070 INFO:   Done with stage: TRAINING
2022-12-05 23:03:44,071 INFO:   Starting stage: EVALUATION
2022-12-05 23:03:44,194 INFO:   Done with stage: EVALUATION
2022-12-05 23:03:44,194 INFO:   Leaving out SEQ value Fold_9
2022-12-05 23:03:44,207 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:03:44,207 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:03:44,856 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:03:44,857 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:03:44,928 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:03:44,928 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:03:44,928 INFO:     No hyperparam tuning for this model
2022-12-05 23:03:44,929 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:03:44,929 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:03:44,929 INFO:     None feature selector for col prot
2022-12-05 23:03:44,929 INFO:     None feature selector for col prot
2022-12-05 23:03:44,930 INFO:     None feature selector for col prot
2022-12-05 23:03:44,930 INFO:     None feature selector for col chem
2022-12-05 23:03:44,930 INFO:     None feature selector for col chem
2022-12-05 23:03:44,930 INFO:     None feature selector for col chem
2022-12-05 23:03:44,930 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:03:44,930 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:03:44,932 INFO:     Number of params in model 215731
2022-12-05 23:03:44,935 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:03:44,935 INFO:   Starting stage: TRAINING
2022-12-05 23:03:44,994 INFO:     Val loss before train {'Reaction outcome loss': 1.0241861167279156, 'Total loss': 1.0241861167279156}
2022-12-05 23:03:44,994 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:44,994 INFO:     Epoch: 0
2022-12-05 23:03:45,709 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7328447076407346, 'Total loss': 0.7328447076407346} | train loss {'Reaction outcome loss': 0.8215989706016356, 'Total loss': 0.8215989706016356}
2022-12-05 23:03:45,709 INFO:     Found new best model at epoch 0
2022-12-05 23:03:45,710 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:45,710 INFO:     Epoch: 1
2022-12-05 23:03:46,427 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6278884783387184, 'Total loss': 0.6278884783387184} | train loss {'Reaction outcome loss': 0.6860759879552549, 'Total loss': 0.6860759879552549}
2022-12-05 23:03:46,427 INFO:     Found new best model at epoch 1
2022-12-05 23:03:46,428 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:46,428 INFO:     Epoch: 2
2022-12-05 23:03:47,140 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6776072003624656, 'Total loss': 0.6776072003624656} | train loss {'Reaction outcome loss': 0.6400457936669549, 'Total loss': 0.6400457936669549}
2022-12-05 23:03:47,140 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:47,140 INFO:     Epoch: 3
2022-12-05 23:03:47,852 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.645190910182216, 'Total loss': 0.645190910182216} | train loss {'Reaction outcome loss': 0.61489976353703, 'Total loss': 0.61489976353703}
2022-12-05 23:03:47,852 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:47,852 INFO:     Epoch: 4
2022-12-05 23:03:48,564 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6023108850825917, 'Total loss': 0.6023108850825917} | train loss {'Reaction outcome loss': 0.6028068772847613, 'Total loss': 0.6028068772847613}
2022-12-05 23:03:48,565 INFO:     Found new best model at epoch 4
2022-12-05 23:03:48,565 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:48,565 INFO:     Epoch: 5
2022-12-05 23:03:49,279 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5888997878540646, 'Total loss': 0.5888997878540646} | train loss {'Reaction outcome loss': 0.5833396048795793, 'Total loss': 0.5833396048795793}
2022-12-05 23:03:49,279 INFO:     Found new best model at epoch 5
2022-12-05 23:03:49,280 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:49,280 INFO:     Epoch: 6
2022-12-05 23:03:49,995 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5989747971973636, 'Total loss': 0.5989747971973636} | train loss {'Reaction outcome loss': 0.5806468724002761, 'Total loss': 0.5806468724002761}
2022-12-05 23:03:49,996 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:49,996 INFO:     Epoch: 7
2022-12-05 23:03:50,708 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5729873397133567, 'Total loss': 0.5729873397133567} | train loss {'Reaction outcome loss': 0.573197812623074, 'Total loss': 0.573197812623074}
2022-12-05 23:03:50,708 INFO:     Found new best model at epoch 7
2022-12-05 23:03:50,709 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:50,709 INFO:     Epoch: 8
2022-12-05 23:03:51,425 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5690133734182878, 'Total loss': 0.5690133734182878} | train loss {'Reaction outcome loss': 0.5690908116558867, 'Total loss': 0.5690908116558867}
2022-12-05 23:03:51,425 INFO:     Found new best model at epoch 8
2022-12-05 23:03:51,425 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:51,426 INFO:     Epoch: 9
2022-12-05 23:03:52,140 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5516313551501795, 'Total loss': 0.5516313551501795} | train loss {'Reaction outcome loss': 0.572734176872238, 'Total loss': 0.572734176872238}
2022-12-05 23:03:52,140 INFO:     Found new best model at epoch 9
2022-12-05 23:03:52,141 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:52,141 INFO:     Epoch: 10
2022-12-05 23:03:52,856 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5349558009342714, 'Total loss': 0.5349558009342714} | train loss {'Reaction outcome loss': 0.5647637418982002, 'Total loss': 0.5647637418982002}
2022-12-05 23:03:52,856 INFO:     Found new best model at epoch 10
2022-12-05 23:03:52,856 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:52,857 INFO:     Epoch: 11
2022-12-05 23:03:53,574 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5614087791605429, 'Total loss': 0.5614087791605429} | train loss {'Reaction outcome loss': 0.5597233214685994, 'Total loss': 0.5597233214685994}
2022-12-05 23:03:53,574 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:53,574 INFO:     Epoch: 12
2022-12-05 23:03:54,292 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5608690817925063, 'Total loss': 0.5608690817925063} | train loss {'Reaction outcome loss': 0.5593065417281562, 'Total loss': 0.5593065417281562}
2022-12-05 23:03:54,292 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:54,292 INFO:     Epoch: 13
2022-12-05 23:03:55,008 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5401198985901746, 'Total loss': 0.5401198985901746} | train loss {'Reaction outcome loss': 0.5578440198855054, 'Total loss': 0.5578440198855054}
2022-12-05 23:03:55,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:55,008 INFO:     Epoch: 14
2022-12-05 23:03:55,723 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.543739188123833, 'Total loss': 0.543739188123833} | train loss {'Reaction outcome loss': 0.565591971600248, 'Total loss': 0.565591971600248}
2022-12-05 23:03:55,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:55,724 INFO:     Epoch: 15
2022-12-05 23:03:56,440 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5458419153636153, 'Total loss': 0.5458419153636153} | train loss {'Reaction outcome loss': 0.5524593057531503, 'Total loss': 0.5524593057531503}
2022-12-05 23:03:56,441 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:56,441 INFO:     Epoch: 16
2022-12-05 23:03:57,153 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.553151720288125, 'Total loss': 0.553151720288125} | train loss {'Reaction outcome loss': 0.5564241039776995, 'Total loss': 0.5564241039776995}
2022-12-05 23:03:57,153 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:57,153 INFO:     Epoch: 17
2022-12-05 23:03:57,864 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5563959357413378, 'Total loss': 0.5563959357413378} | train loss {'Reaction outcome loss': 0.5541720960529581, 'Total loss': 0.5541720960529581}
2022-12-05 23:03:57,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:57,864 INFO:     Epoch: 18
2022-12-05 23:03:58,575 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5281164517456834, 'Total loss': 0.5281164517456834} | train loss {'Reaction outcome loss': 0.552560897664197, 'Total loss': 0.552560897664197}
2022-12-05 23:03:58,575 INFO:     Found new best model at epoch 18
2022-12-05 23:03:58,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:58,575 INFO:     Epoch: 19
2022-12-05 23:03:59,283 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.532539850608869, 'Total loss': 0.532539850608869} | train loss {'Reaction outcome loss': 0.5505033816781736, 'Total loss': 0.5505033816781736}
2022-12-05 23:03:59,283 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:59,284 INFO:     Epoch: 20
2022-12-05 23:03:59,993 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5628716539252888, 'Total loss': 0.5628716539252888} | train loss {'Reaction outcome loss': 0.5536668789122374, 'Total loss': 0.5536668789122374}
2022-12-05 23:03:59,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:03:59,994 INFO:     Epoch: 21
2022-12-05 23:04:00,701 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5356798456473784, 'Total loss': 0.5356798456473784} | train loss {'Reaction outcome loss': 0.5470933058569508, 'Total loss': 0.5470933058569508}
2022-12-05 23:04:00,701 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:00,701 INFO:     Epoch: 22
2022-12-05 23:04:01,411 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5389055846766992, 'Total loss': 0.5389055846766992} | train loss {'Reaction outcome loss': 0.5447752956421145, 'Total loss': 0.5447752956421145}
2022-12-05 23:04:01,412 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:01,412 INFO:     Epoch: 23
2022-12-05 23:04:02,119 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5496685095131397, 'Total loss': 0.5496685095131397} | train loss {'Reaction outcome loss': 0.5439720644104865, 'Total loss': 0.5439720644104865}
2022-12-05 23:04:02,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:02,120 INFO:     Epoch: 24
2022-12-05 23:04:02,827 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.526016270572489, 'Total loss': 0.526016270572489} | train loss {'Reaction outcome loss': 0.5488516696758808, 'Total loss': 0.5488516696758808}
2022-12-05 23:04:02,828 INFO:     Found new best model at epoch 24
2022-12-05 23:04:02,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:02,829 INFO:     Epoch: 25
2022-12-05 23:04:03,540 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.565742895684459, 'Total loss': 0.565742895684459} | train loss {'Reaction outcome loss': 0.5479703623681299, 'Total loss': 0.5479703623681299}
2022-12-05 23:04:03,540 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:03,541 INFO:     Epoch: 26
2022-12-05 23:04:04,249 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5465172864496708, 'Total loss': 0.5465172864496708} | train loss {'Reaction outcome loss': 0.542233079912201, 'Total loss': 0.542233079912201}
2022-12-05 23:04:04,250 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:04,250 INFO:     Epoch: 27
2022-12-05 23:04:04,957 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5315368524329229, 'Total loss': 0.5315368524329229} | train loss {'Reaction outcome loss': 0.5515288497892118, 'Total loss': 0.5515288497892118}
2022-12-05 23:04:04,957 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:04,957 INFO:     Epoch: 28
2022-12-05 23:04:05,666 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5092687444253401, 'Total loss': 0.5092687444253401} | train loss {'Reaction outcome loss': 0.5453942460759033, 'Total loss': 0.5453942460759033}
2022-12-05 23:04:05,666 INFO:     Found new best model at epoch 28
2022-12-05 23:04:05,667 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:05,667 INFO:     Epoch: 29
2022-12-05 23:04:06,375 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5551856322722002, 'Total loss': 0.5551856322722002} | train loss {'Reaction outcome loss': 0.5438691023136338, 'Total loss': 0.5438691023136338}
2022-12-05 23:04:06,375 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:06,375 INFO:     Epoch: 30
2022-12-05 23:04:07,084 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5280588221820918, 'Total loss': 0.5280588221820918} | train loss {'Reaction outcome loss': 0.5515671442112615, 'Total loss': 0.5515671442112615}
2022-12-05 23:04:07,084 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:07,084 INFO:     Epoch: 31
2022-12-05 23:04:07,794 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5613214644518766, 'Total loss': 0.5613214644518766} | train loss {'Reaction outcome loss': 0.5467746465076362, 'Total loss': 0.5467746465076362}
2022-12-05 23:04:07,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:07,794 INFO:     Epoch: 32
2022-12-05 23:04:08,504 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5398970845748078, 'Total loss': 0.5398970845748078} | train loss {'Reaction outcome loss': 0.5464777830507486, 'Total loss': 0.5464777830507486}
2022-12-05 23:04:08,504 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:08,504 INFO:     Epoch: 33
2022-12-05 23:04:09,216 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5345474247905341, 'Total loss': 0.5345474247905341} | train loss {'Reaction outcome loss': 0.5442568536006636, 'Total loss': 0.5442568536006636}
2022-12-05 23:04:09,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:09,216 INFO:     Epoch: 34
2022-12-05 23:04:09,929 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5157402174716647, 'Total loss': 0.5157402174716647} | train loss {'Reaction outcome loss': 0.5442059168051328, 'Total loss': 0.5442059168051328}
2022-12-05 23:04:09,930 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:09,930 INFO:     Epoch: 35
2022-12-05 23:04:10,643 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5164870436895977, 'Total loss': 0.5164870436895977} | train loss {'Reaction outcome loss': 0.5464801856226498, 'Total loss': 0.5464801856226498}
2022-12-05 23:04:10,643 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:10,643 INFO:     Epoch: 36
2022-12-05 23:04:11,355 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5504315898499705, 'Total loss': 0.5504315898499705} | train loss {'Reaction outcome loss': 0.5431152147451236, 'Total loss': 0.5431152147451236}
2022-12-05 23:04:11,355 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:11,355 INFO:     Epoch: 37
2022-12-05 23:04:12,063 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5189520164646886, 'Total loss': 0.5189520164646886} | train loss {'Reaction outcome loss': 0.5417289945987924, 'Total loss': 0.5417289945987924}
2022-12-05 23:04:12,063 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:12,063 INFO:     Epoch: 38
2022-12-05 23:04:12,773 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5341832868077538, 'Total loss': 0.5341832868077538} | train loss {'Reaction outcome loss': 0.539479629136622, 'Total loss': 0.539479629136622}
2022-12-05 23:04:12,773 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:12,773 INFO:     Epoch: 39
2022-12-05 23:04:13,481 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5741297504441305, 'Total loss': 0.5741297504441305} | train loss {'Reaction outcome loss': 0.5431608555297698, 'Total loss': 0.5431608555297698}
2022-12-05 23:04:13,481 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:13,482 INFO:     Epoch: 40
2022-12-05 23:04:14,193 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5248469859361649, 'Total loss': 0.5248469859361649} | train loss {'Reaction outcome loss': 0.5473267902890521, 'Total loss': 0.5473267902890521}
2022-12-05 23:04:14,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:14,194 INFO:     Epoch: 41
2022-12-05 23:04:14,906 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5293447991663759, 'Total loss': 0.5293447991663759} | train loss {'Reaction outcome loss': 0.5434862737573923, 'Total loss': 0.5434862737573923}
2022-12-05 23:04:14,907 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:14,907 INFO:     Epoch: 42
2022-12-05 23:04:15,617 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5526117882267996, 'Total loss': 0.5526117882267996} | train loss {'Reaction outcome loss': 0.541768773729282, 'Total loss': 0.541768773729282}
2022-12-05 23:04:15,617 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:15,617 INFO:     Epoch: 43
2022-12-05 23:04:16,326 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5343621603467248, 'Total loss': 0.5343621603467248} | train loss {'Reaction outcome loss': 0.540265122368451, 'Total loss': 0.540265122368451}
2022-12-05 23:04:16,326 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:16,326 INFO:     Epoch: 44
2022-12-05 23:04:17,034 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5204123990102247, 'Total loss': 0.5204123990102247} | train loss {'Reaction outcome loss': 0.5422355877836386, 'Total loss': 0.5422355877836386}
2022-12-05 23:04:17,035 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:17,035 INFO:     Epoch: 45
2022-12-05 23:04:17,745 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5257116678086194, 'Total loss': 0.5257116678086194} | train loss {'Reaction outcome loss': 0.54668869108202, 'Total loss': 0.54668869108202}
2022-12-05 23:04:17,745 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:17,745 INFO:     Epoch: 46
2022-12-05 23:04:18,454 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.530370122668418, 'Total loss': 0.530370122668418} | train loss {'Reaction outcome loss': 0.5379539065423512, 'Total loss': 0.5379539065423512}
2022-12-05 23:04:18,454 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:18,454 INFO:     Epoch: 47
2022-12-05 23:04:19,165 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5888829549605196, 'Total loss': 0.5888829549605196} | train loss {'Reaction outcome loss': 0.5437726530456736, 'Total loss': 0.5437726530456736}
2022-12-05 23:04:19,165 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:19,165 INFO:     Epoch: 48
2022-12-05 23:04:19,878 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5322071063247594, 'Total loss': 0.5322071063247594} | train loss {'Reaction outcome loss': 0.5453659752684255, 'Total loss': 0.5453659752684255}
2022-12-05 23:04:19,878 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:19,878 INFO:     Epoch: 49
2022-12-05 23:04:20,586 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5391602892089974, 'Total loss': 0.5391602892089974} | train loss {'Reaction outcome loss': 0.540380286593591, 'Total loss': 0.540380286593591}
2022-12-05 23:04:20,587 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:20,587 INFO:     Epoch: 50
2022-12-05 23:04:21,295 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5428924699398604, 'Total loss': 0.5428924699398604} | train loss {'Reaction outcome loss': 0.5401494337185737, 'Total loss': 0.5401494337185737}
2022-12-05 23:04:21,295 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:21,295 INFO:     Epoch: 51
2022-12-05 23:04:22,004 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5203941955485127, 'Total loss': 0.5203941955485127} | train loss {'Reaction outcome loss': 0.5359432090434336, 'Total loss': 0.5359432090434336}
2022-12-05 23:04:22,004 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:22,004 INFO:     Epoch: 52
2022-12-05 23:04:22,717 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5376985763961618, 'Total loss': 0.5376985763961618} | train loss {'Reaction outcome loss': 0.5395633054356421, 'Total loss': 0.5395633054356421}
2022-12-05 23:04:22,717 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:22,718 INFO:     Epoch: 53
2022-12-05 23:04:23,430 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5569769205017523, 'Total loss': 0.5569769205017523} | train loss {'Reaction outcome loss': 0.5410548411910573, 'Total loss': 0.5410548411910573}
2022-12-05 23:04:23,430 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:23,430 INFO:     Epoch: 54
2022-12-05 23:04:24,142 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.533242478966713, 'Total loss': 0.533242478966713} | train loss {'Reaction outcome loss': 0.5473676812985251, 'Total loss': 0.5473676812985251}
2022-12-05 23:04:24,142 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:24,142 INFO:     Epoch: 55
2022-12-05 23:04:24,854 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5680332637645982, 'Total loss': 0.5680332637645982} | train loss {'Reaction outcome loss': 0.5410328234636015, 'Total loss': 0.5410328234636015}
2022-12-05 23:04:24,854 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:24,854 INFO:     Epoch: 56
2022-12-05 23:04:25,567 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5826581350781701, 'Total loss': 0.5826581350781701} | train loss {'Reaction outcome loss': 0.5395938475285808, 'Total loss': 0.5395938475285808}
2022-12-05 23:04:25,568 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:25,568 INFO:     Epoch: 57
2022-12-05 23:04:26,280 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5352072852917693, 'Total loss': 0.5352072852917693} | train loss {'Reaction outcome loss': 0.5453452911948965, 'Total loss': 0.5453452911948965}
2022-12-05 23:04:26,280 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:26,280 INFO:     Epoch: 58
2022-12-05 23:04:26,996 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5496608289805326, 'Total loss': 0.5496608289805326} | train loss {'Reaction outcome loss': 0.5364594667428925, 'Total loss': 0.5364594667428925}
2022-12-05 23:04:26,996 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:26,996 INFO:     Epoch: 59
2022-12-05 23:04:27,709 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5564110997048292, 'Total loss': 0.5564110997048292} | train loss {'Reaction outcome loss': 0.54079157768959, 'Total loss': 0.54079157768959}
2022-12-05 23:04:27,710 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:27,710 INFO:     Epoch: 60
2022-12-05 23:04:28,425 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5383612249385227, 'Total loss': 0.5383612249385227} | train loss {'Reaction outcome loss': 0.5387543135833356, 'Total loss': 0.5387543135833356}
2022-12-05 23:04:28,425 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:28,425 INFO:     Epoch: 61
2022-12-05 23:04:29,138 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5111962956461039, 'Total loss': 0.5111962956461039} | train loss {'Reaction outcome loss': 0.5411845612670144, 'Total loss': 0.5411845612670144}
2022-12-05 23:04:29,138 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:29,138 INFO:     Epoch: 62
2022-12-05 23:04:29,851 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5366476266221567, 'Total loss': 0.5366476266221567} | train loss {'Reaction outcome loss': 0.5374559423015002, 'Total loss': 0.5374559423015002}
2022-12-05 23:04:29,851 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:29,851 INFO:     Epoch: 63
2022-12-05 23:04:30,563 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5677725452591073, 'Total loss': 0.5677725452591073} | train loss {'Reaction outcome loss': 0.5437855735541351, 'Total loss': 0.5437855735541351}
2022-12-05 23:04:30,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:30,563 INFO:     Epoch: 64
2022-12-05 23:04:31,279 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.552671758288687, 'Total loss': 0.552671758288687} | train loss {'Reaction outcome loss': 0.5428091695592288, 'Total loss': 0.5428091695592288}
2022-12-05 23:04:31,279 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:31,279 INFO:     Epoch: 65
2022-12-05 23:04:31,994 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5245553600517187, 'Total loss': 0.5245553600517187} | train loss {'Reaction outcome loss': 0.541590754663752, 'Total loss': 0.541590754663752}
2022-12-05 23:04:31,994 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:31,994 INFO:     Epoch: 66
2022-12-05 23:04:32,711 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5814696265892549, 'Total loss': 0.5814696265892549} | train loss {'Reaction outcome loss': 0.5410276010872856, 'Total loss': 0.5410276010872856}
2022-12-05 23:04:32,711 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:32,711 INFO:     Epoch: 67
2022-12-05 23:04:33,429 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.522788786075332, 'Total loss': 0.522788786075332} | train loss {'Reaction outcome loss': 0.5383360087871552, 'Total loss': 0.5383360087871552}
2022-12-05 23:04:33,429 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:33,429 INFO:     Epoch: 68
2022-12-05 23:04:34,142 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5143018405545842, 'Total loss': 0.5143018405545842} | train loss {'Reaction outcome loss': 0.5455966921703469, 'Total loss': 0.5455966921703469}
2022-12-05 23:04:34,143 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:34,143 INFO:     Epoch: 69
2022-12-05 23:04:34,857 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5336152084849097, 'Total loss': 0.5336152084849097} | train loss {'Reaction outcome loss': 0.5369714091742231, 'Total loss': 0.5369714091742231}
2022-12-05 23:04:34,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:34,857 INFO:     Epoch: 70
2022-12-05 23:04:35,577 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5703166201710701, 'Total loss': 0.5703166201710701} | train loss {'Reaction outcome loss': 0.5437820091723434, 'Total loss': 0.5437820091723434}
2022-12-05 23:04:35,577 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:35,577 INFO:     Epoch: 71
2022-12-05 23:04:36,294 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5377374372699044, 'Total loss': 0.5377374372699044} | train loss {'Reaction outcome loss': 0.5419617083764845, 'Total loss': 0.5419617083764845}
2022-12-05 23:04:36,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:36,294 INFO:     Epoch: 72
2022-12-05 23:04:37,007 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5472844297235663, 'Total loss': 0.5472844297235663} | train loss {'Reaction outcome loss': 0.5396411231448573, 'Total loss': 0.5396411231448573}
2022-12-05 23:04:37,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:37,008 INFO:     Epoch: 73
2022-12-05 23:04:37,723 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5508123900402676, 'Total loss': 0.5508123900402676} | train loss {'Reaction outcome loss': 0.5394173320983687, 'Total loss': 0.5394173320983687}
2022-12-05 23:04:37,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:37,723 INFO:     Epoch: 74
2022-12-05 23:04:38,436 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.535299829122695, 'Total loss': 0.535299829122695} | train loss {'Reaction outcome loss': 0.5402564455064074, 'Total loss': 0.5402564455064074}
2022-12-05 23:04:38,436 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:38,436 INFO:     Epoch: 75
2022-12-05 23:04:39,149 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5422151400284334, 'Total loss': 0.5422151400284334} | train loss {'Reaction outcome loss': 0.5407689521990476, 'Total loss': 0.5407689521990476}
2022-12-05 23:04:39,149 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:39,149 INFO:     Epoch: 76
2022-12-05 23:04:39,861 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5299754759127443, 'Total loss': 0.5299754759127443} | train loss {'Reaction outcome loss': 0.5459062769528358, 'Total loss': 0.5459062769528358}
2022-12-05 23:04:39,861 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:39,861 INFO:     Epoch: 77
2022-12-05 23:04:40,578 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5239067666909911, 'Total loss': 0.5239067666909911} | train loss {'Reaction outcome loss': 0.5389500079496253, 'Total loss': 0.5389500079496253}
2022-12-05 23:04:40,578 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:40,578 INFO:     Epoch: 78
2022-12-05 23:04:41,287 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5713490809906613, 'Total loss': 0.5713490809906613} | train loss {'Reaction outcome loss': 0.5384895430216866, 'Total loss': 0.5384895430216866}
2022-12-05 23:04:41,288 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:41,288 INFO:     Epoch: 79
2022-12-05 23:04:41,998 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5170596580613743, 'Total loss': 0.5170596580613743} | train loss {'Reaction outcome loss': 0.5357833330429369, 'Total loss': 0.5357833330429369}
2022-12-05 23:04:41,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:41,998 INFO:     Epoch: 80
2022-12-05 23:04:42,708 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.56329038197344, 'Total loss': 0.56329038197344} | train loss {'Reaction outcome loss': 0.5426349619463566, 'Total loss': 0.5426349619463566}
2022-12-05 23:04:42,708 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:42,708 INFO:     Epoch: 81
2022-12-05 23:04:43,417 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5390853912315585, 'Total loss': 0.5390853912315585} | train loss {'Reaction outcome loss': 0.5416554482653737, 'Total loss': 0.5416554482653737}
2022-12-05 23:04:43,417 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:43,417 INFO:     Epoch: 82
2022-12-05 23:04:44,127 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5859218754551627, 'Total loss': 0.5859218754551627} | train loss {'Reaction outcome loss': 0.5390239887300038, 'Total loss': 0.5390239887300038}
2022-12-05 23:04:44,127 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:44,128 INFO:     Epoch: 83
2022-12-05 23:04:44,840 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5279825759882276, 'Total loss': 0.5279825759882276} | train loss {'Reaction outcome loss': 0.5375537921584421, 'Total loss': 0.5375537921584421}
2022-12-05 23:04:44,840 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:44,840 INFO:     Epoch: 84
2022-12-05 23:04:45,549 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5843627635728229, 'Total loss': 0.5843627635728229} | train loss {'Reaction outcome loss': 0.5368898670759893, 'Total loss': 0.5368898670759893}
2022-12-05 23:04:45,549 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:45,549 INFO:     Epoch: 85
2022-12-05 23:04:46,258 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5504619215022434, 'Total loss': 0.5504619215022434} | train loss {'Reaction outcome loss': 0.5450576898311416, 'Total loss': 0.5450576898311416}
2022-12-05 23:04:46,259 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:46,259 INFO:     Epoch: 86
2022-12-05 23:04:46,968 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5615903572602705, 'Total loss': 0.5615903572602705} | train loss {'Reaction outcome loss': 0.5366730899099381, 'Total loss': 0.5366730899099381}
2022-12-05 23:04:46,969 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:46,969 INFO:     Epoch: 87
2022-12-05 23:04:47,679 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5255582739006389, 'Total loss': 0.5255582739006389} | train loss {'Reaction outcome loss': 0.5396361180971707, 'Total loss': 0.5396361180971707}
2022-12-05 23:04:47,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:47,679 INFO:     Epoch: 88
2022-12-05 23:04:48,391 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5880759334699674, 'Total loss': 0.5880759334699674} | train loss {'Reaction outcome loss': 0.5462000829077536, 'Total loss': 0.5462000829077536}
2022-12-05 23:04:48,391 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:48,391 INFO:     Epoch: 89
2022-12-05 23:04:49,102 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5255126431584358, 'Total loss': 0.5255126431584358} | train loss {'Reaction outcome loss': 0.5445056594307384, 'Total loss': 0.5445056594307384}
2022-12-05 23:04:49,102 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:49,102 INFO:     Epoch: 90
2022-12-05 23:04:49,815 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5155361572449858, 'Total loss': 0.5155361572449858} | train loss {'Reaction outcome loss': 0.5425127765103694, 'Total loss': 0.5425127765103694}
2022-12-05 23:04:49,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:49,816 INFO:     Epoch: 91
2022-12-05 23:04:50,527 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5124144252728332, 'Total loss': 0.5124144252728332} | train loss {'Reaction outcome loss': 0.5446536005023987, 'Total loss': 0.5446536005023987}
2022-12-05 23:04:50,527 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:50,527 INFO:     Epoch: 92
2022-12-05 23:04:51,240 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.515339922498573, 'Total loss': 0.515339922498573} | train loss {'Reaction outcome loss': 0.5345688108354807, 'Total loss': 0.5345688108354807}
2022-12-05 23:04:51,240 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:51,240 INFO:     Epoch: 93
2022-12-05 23:04:51,951 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5132326632738113, 'Total loss': 0.5132326632738113} | train loss {'Reaction outcome loss': 0.5352074257548778, 'Total loss': 0.5352074257548778}
2022-12-05 23:04:51,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:51,951 INFO:     Epoch: 94
2022-12-05 23:04:52,662 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5518121827732433, 'Total loss': 0.5518121827732433} | train loss {'Reaction outcome loss': 0.5424435961270525, 'Total loss': 0.5424435961270525}
2022-12-05 23:04:52,662 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:52,662 INFO:     Epoch: 95
2022-12-05 23:04:53,372 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5277785943313078, 'Total loss': 0.5277785943313078} | train loss {'Reaction outcome loss': 0.5437815081808837, 'Total loss': 0.5437815081808837}
2022-12-05 23:04:53,372 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:53,372 INFO:     Epoch: 96
2022-12-05 23:04:54,081 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.526096811010079, 'Total loss': 0.526096811010079} | train loss {'Reaction outcome loss': 0.544723454682577, 'Total loss': 0.544723454682577}
2022-12-05 23:04:54,081 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:54,082 INFO:     Epoch: 97
2022-12-05 23:04:54,791 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5557975945147601, 'Total loss': 0.5557975945147601} | train loss {'Reaction outcome loss': 0.5416333468090142, 'Total loss': 0.5416333468090142}
2022-12-05 23:04:54,791 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:54,791 INFO:     Epoch: 98
2022-12-05 23:04:55,501 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5297809812155637, 'Total loss': 0.5297809812155637} | train loss {'Reaction outcome loss': 0.5404565601098922, 'Total loss': 0.5404565601098922}
2022-12-05 23:04:55,501 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:55,502 INFO:     Epoch: 99
2022-12-05 23:04:56,211 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5476040616631508, 'Total loss': 0.5476040616631508} | train loss {'Reaction outcome loss': 0.5395494134676072, 'Total loss': 0.5395494134676072}
2022-12-05 23:04:56,211 INFO:     Best model found after epoch 29 of 100.
2022-12-05 23:04:56,211 INFO:   Done with stage: TRAINING
2022-12-05 23:04:56,211 INFO:   Starting stage: EVALUATION
2022-12-05 23:04:56,329 INFO:   Done with stage: EVALUATION
2022-12-05 23:04:56,338 INFO:   Leaving out SEQ value Fold_0
2022-12-05 23:04:56,351 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 23:04:56,351 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:04:56,987 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:04:56,987 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:04:57,057 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:04:57,057 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:04:57,057 INFO:     No hyperparam tuning for this model
2022-12-05 23:04:57,057 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:04:57,057 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:04:57,058 INFO:     None feature selector for col prot
2022-12-05 23:04:57,058 INFO:     None feature selector for col prot
2022-12-05 23:04:57,058 INFO:     None feature selector for col prot
2022-12-05 23:04:57,059 INFO:     None feature selector for col chem
2022-12-05 23:04:57,059 INFO:     None feature selector for col chem
2022-12-05 23:04:57,059 INFO:     None feature selector for col chem
2022-12-05 23:04:57,059 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:04:57,059 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:04:57,061 INFO:     Number of params in model 215731
2022-12-05 23:04:57,064 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:04:57,064 INFO:   Starting stage: TRAINING
2022-12-05 23:04:57,123 INFO:     Val loss before train {'Reaction outcome loss': 1.0067796192385934, 'Total loss': 1.0067796192385934}
2022-12-05 23:04:57,123 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:57,123 INFO:     Epoch: 0
2022-12-05 23:04:57,832 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7213827009228143, 'Total loss': 0.7213827009228143} | train loss {'Reaction outcome loss': 0.7961123451894644, 'Total loss': 0.7961123451894644}
2022-12-05 23:04:57,833 INFO:     Found new best model at epoch 0
2022-12-05 23:04:57,833 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:57,833 INFO:     Epoch: 1
2022-12-05 23:04:58,537 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5919311933896758, 'Total loss': 0.5919311933896758} | train loss {'Reaction outcome loss': 0.6497607435498919, 'Total loss': 0.6497607435498919}
2022-12-05 23:04:58,538 INFO:     Found new best model at epoch 1
2022-12-05 23:04:58,538 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:58,538 INFO:     Epoch: 2
2022-12-05 23:04:59,241 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5879491703076796, 'Total loss': 0.5879491703076796} | train loss {'Reaction outcome loss': 0.6132178504248055, 'Total loss': 0.6132178504248055}
2022-12-05 23:04:59,242 INFO:     Found new best model at epoch 2
2022-12-05 23:04:59,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:59,243 INFO:     Epoch: 3
2022-12-05 23:04:59,948 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5426111471923915, 'Total loss': 0.5426111471923915} | train loss {'Reaction outcome loss': 0.5897292874297317, 'Total loss': 0.5897292874297317}
2022-12-05 23:04:59,948 INFO:     Found new best model at epoch 3
2022-12-05 23:04:59,949 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:04:59,949 INFO:     Epoch: 4
2022-12-05 23:05:00,657 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5699142068624496, 'Total loss': 0.5699142068624496} | train loss {'Reaction outcome loss': 0.5940491424531352, 'Total loss': 0.5940491424531352}
2022-12-05 23:05:00,658 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:00,658 INFO:     Epoch: 5
2022-12-05 23:05:01,360 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6160652095621283, 'Total loss': 0.6160652095621283} | train loss {'Reaction outcome loss': 0.5796829972340136, 'Total loss': 0.5796829972340136}
2022-12-05 23:05:01,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:01,360 INFO:     Epoch: 6
2022-12-05 23:05:02,062 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5479212708093903, 'Total loss': 0.5479212708093903} | train loss {'Reaction outcome loss': 0.5727868702338667, 'Total loss': 0.5727868702338667}
2022-12-05 23:05:02,063 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:02,063 INFO:     Epoch: 7
2022-12-05 23:05:02,768 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5475112240422856, 'Total loss': 0.5475112240422856} | train loss {'Reaction outcome loss': 0.5753190606832504, 'Total loss': 0.5753190606832504}
2022-12-05 23:05:02,768 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:02,768 INFO:     Epoch: 8
2022-12-05 23:05:03,470 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5405003828081217, 'Total loss': 0.5405003828081217} | train loss {'Reaction outcome loss': 0.5682519283829903, 'Total loss': 0.5682519283829903}
2022-12-05 23:05:03,471 INFO:     Found new best model at epoch 8
2022-12-05 23:05:03,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:03,471 INFO:     Epoch: 9
2022-12-05 23:05:04,176 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5108304931358858, 'Total loss': 0.5108304931358858} | train loss {'Reaction outcome loss': 0.5733689864071048, 'Total loss': 0.5733689864071048}
2022-12-05 23:05:04,176 INFO:     Found new best model at epoch 9
2022-12-05 23:05:04,176 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:04,177 INFO:     Epoch: 10
2022-12-05 23:05:04,884 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5810251188549128, 'Total loss': 0.5810251188549128} | train loss {'Reaction outcome loss': 0.5589068313034213, 'Total loss': 0.5589068313034213}
2022-12-05 23:05:04,884 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:04,885 INFO:     Epoch: 11
2022-12-05 23:05:05,593 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5984369760209863, 'Total loss': 0.5984369760209863} | train loss {'Reaction outcome loss': 0.5594513019128722, 'Total loss': 0.5594513019128722}
2022-12-05 23:05:05,593 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:05,593 INFO:     Epoch: 12
2022-12-05 23:05:06,295 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5219647315415469, 'Total loss': 0.5219647315415469} | train loss {'Reaction outcome loss': 0.5568954661792639, 'Total loss': 0.5568954661792639}
2022-12-05 23:05:06,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:06,296 INFO:     Epoch: 13
2022-12-05 23:05:06,997 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.555640428581021, 'Total loss': 0.555640428581021} | train loss {'Reaction outcome loss': 0.5538825632966294, 'Total loss': 0.5538825632966294}
2022-12-05 23:05:06,997 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:06,997 INFO:     Epoch: 14
2022-12-05 23:05:07,699 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5214752548120238, 'Total loss': 0.5214752548120238} | train loss {'Reaction outcome loss': 0.5606556208766237, 'Total loss': 0.5606556208766237}
2022-12-05 23:05:07,700 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:07,700 INFO:     Epoch: 15
2022-12-05 23:05:08,402 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5285431139848449, 'Total loss': 0.5285431139848449} | train loss {'Reaction outcome loss': 0.5509704945038776, 'Total loss': 0.5509704945038776}
2022-12-05 23:05:08,402 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:08,402 INFO:     Epoch: 16
2022-12-05 23:05:09,104 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5300902195952155, 'Total loss': 0.5300902195952155} | train loss {'Reaction outcome loss': 0.5537447190406372, 'Total loss': 0.5537447190406372}
2022-12-05 23:05:09,104 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:09,104 INFO:     Epoch: 17
2022-12-05 23:05:09,809 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5420387075705961, 'Total loss': 0.5420387075705961} | train loss {'Reaction outcome loss': 0.5438148588550334, 'Total loss': 0.5438148588550334}
2022-12-05 23:05:09,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:09,809 INFO:     Epoch: 18
2022-12-05 23:05:10,515 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5401019548827951, 'Total loss': 0.5401019548827951} | train loss {'Reaction outcome loss': 0.542977672936965, 'Total loss': 0.542977672936965}
2022-12-05 23:05:10,516 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:10,516 INFO:     Epoch: 19
2022-12-05 23:05:11,219 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.565958322449164, 'Total loss': 0.565958322449164} | train loss {'Reaction outcome loss': 0.5347465218938127, 'Total loss': 0.5347465218938127}
2022-12-05 23:05:11,219 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:11,219 INFO:     Epoch: 20
2022-12-05 23:05:11,921 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5092411857437004, 'Total loss': 0.5092411857437004} | train loss {'Reaction outcome loss': 0.5400110323818362, 'Total loss': 0.5400110323818362}
2022-12-05 23:05:11,921 INFO:     Found new best model at epoch 20
2022-12-05 23:05:11,922 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:11,922 INFO:     Epoch: 21
2022-12-05 23:05:12,630 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5424703217365525, 'Total loss': 0.5424703217365525} | train loss {'Reaction outcome loss': 0.5367703820369681, 'Total loss': 0.5367703820369681}
2022-12-05 23:05:12,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:12,630 INFO:     Epoch: 22
2022-12-05 23:05:13,336 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5200559070164507, 'Total loss': 0.5200559070164507} | train loss {'Reaction outcome loss': 0.5365850139637383, 'Total loss': 0.5365850139637383}
2022-12-05 23:05:13,336 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:13,336 INFO:     Epoch: 23
2022-12-05 23:05:14,038 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5085651762783527, 'Total loss': 0.5085651762783527} | train loss {'Reaction outcome loss': 0.5395853532212121, 'Total loss': 0.5395853532212121}
2022-12-05 23:05:14,038 INFO:     Found new best model at epoch 23
2022-12-05 23:05:14,038 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:14,039 INFO:     Epoch: 24
2022-12-05 23:05:14,743 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5489043485034596, 'Total loss': 0.5489043485034596} | train loss {'Reaction outcome loss': 0.5295431050719047, 'Total loss': 0.5295431050719047}
2022-12-05 23:05:14,743 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:14,744 INFO:     Epoch: 25
2022-12-05 23:05:15,448 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5046115646308119, 'Total loss': 0.5046115646308119} | train loss {'Reaction outcome loss': 0.5279402201881214, 'Total loss': 0.5279402201881214}
2022-12-05 23:05:15,448 INFO:     Found new best model at epoch 25
2022-12-05 23:05:15,449 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:15,449 INFO:     Epoch: 26
2022-12-05 23:05:16,152 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5224017568609931, 'Total loss': 0.5224017568609931} | train loss {'Reaction outcome loss': 0.5291306330841414, 'Total loss': 0.5291306330841414}
2022-12-05 23:05:16,153 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:16,153 INFO:     Epoch: 27
2022-12-05 23:05:16,855 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5476766865361821, 'Total loss': 0.5476766865361821} | train loss {'Reaction outcome loss': 0.5210560130221503, 'Total loss': 0.5210560130221503}
2022-12-05 23:05:16,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:16,855 INFO:     Epoch: 28
2022-12-05 23:05:17,560 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5157960731197487, 'Total loss': 0.5157960731197487} | train loss {'Reaction outcome loss': 0.5248917895920423, 'Total loss': 0.5248917895920423}
2022-12-05 23:05:17,561 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:17,561 INFO:     Epoch: 29
2022-12-05 23:05:18,264 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5133485089648854, 'Total loss': 0.5133485089648854} | train loss {'Reaction outcome loss': 0.5319762211673114, 'Total loss': 0.5319762211673114}
2022-12-05 23:05:18,264 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:18,265 INFO:     Epoch: 30
2022-12-05 23:05:18,967 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4910445982082324, 'Total loss': 0.4910445982082324} | train loss {'Reaction outcome loss': 0.5231549216168268, 'Total loss': 0.5231549216168268}
2022-12-05 23:05:18,967 INFO:     Found new best model at epoch 30
2022-12-05 23:05:18,967 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:18,968 INFO:     Epoch: 31
2022-12-05 23:05:19,670 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5763770931146361, 'Total loss': 0.5763770931146361} | train loss {'Reaction outcome loss': 0.5246087276813935, 'Total loss': 0.5246087276813935}
2022-12-05 23:05:19,670 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:19,671 INFO:     Epoch: 32
2022-12-05 23:05:20,373 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47887874936515634, 'Total loss': 0.47887874936515634} | train loss {'Reaction outcome loss': 0.5288406747944501, 'Total loss': 0.5288406747944501}
2022-12-05 23:05:20,373 INFO:     Found new best model at epoch 32
2022-12-05 23:05:20,374 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:20,374 INFO:     Epoch: 33
2022-12-05 23:05:21,076 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5485832962122831, 'Total loss': 0.5485832962122831} | train loss {'Reaction outcome loss': 0.513709310366183, 'Total loss': 0.513709310366183}
2022-12-05 23:05:21,076 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:21,076 INFO:     Epoch: 34
2022-12-05 23:05:21,779 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5363790470768105, 'Total loss': 0.5363790470768105} | train loss {'Reaction outcome loss': 0.5276929770805397, 'Total loss': 0.5276929770805397}
2022-12-05 23:05:21,779 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:21,779 INFO:     Epoch: 35
2022-12-05 23:05:22,486 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5250156968832016, 'Total loss': 0.5250156968832016} | train loss {'Reaction outcome loss': 0.5167223323972858, 'Total loss': 0.5167223323972858}
2022-12-05 23:05:22,487 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:22,487 INFO:     Epoch: 36
2022-12-05 23:05:23,188 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5279436145316471, 'Total loss': 0.5279436145316471} | train loss {'Reaction outcome loss': 0.5183524244293874, 'Total loss': 0.5183524244293874}
2022-12-05 23:05:23,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:23,189 INFO:     Epoch: 37
2022-12-05 23:05:23,894 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47526204653761606, 'Total loss': 0.47526204653761606} | train loss {'Reaction outcome loss': 0.5259774304166132, 'Total loss': 0.5259774304166132}
2022-12-05 23:05:23,894 INFO:     Found new best model at epoch 37
2022-12-05 23:05:23,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:23,895 INFO:     Epoch: 38
2022-12-05 23:05:24,598 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5311527086252515, 'Total loss': 0.5311527086252515} | train loss {'Reaction outcome loss': 0.5158489285074934, 'Total loss': 0.5158489285074934}
2022-12-05 23:05:24,598 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:24,598 INFO:     Epoch: 39
2022-12-05 23:05:25,306 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5022406767715107, 'Total loss': 0.5022406767715107} | train loss {'Reaction outcome loss': 0.5224308490144963, 'Total loss': 0.5224308490144963}
2022-12-05 23:05:25,307 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:25,307 INFO:     Epoch: 40
2022-12-05 23:05:26,010 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5220973234285008, 'Total loss': 0.5220973234285008} | train loss {'Reaction outcome loss': 0.5087227555562038, 'Total loss': 0.5087227555562038}
2022-12-05 23:05:26,011 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:26,011 INFO:     Epoch: 41
2022-12-05 23:05:26,713 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5233933526006612, 'Total loss': 0.5233933526006612} | train loss {'Reaction outcome loss': 0.518267249878572, 'Total loss': 0.518267249878572}
2022-12-05 23:05:26,714 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:26,714 INFO:     Epoch: 42
2022-12-05 23:05:27,419 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5037810565395788, 'Total loss': 0.5037810565395788} | train loss {'Reaction outcome loss': 0.5195240301745279, 'Total loss': 0.5195240301745279}
2022-12-05 23:05:27,419 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:27,419 INFO:     Epoch: 43
2022-12-05 23:05:28,122 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4923488206484101, 'Total loss': 0.4923488206484101} | train loss {'Reaction outcome loss': 0.513628210036122, 'Total loss': 0.513628210036122}
2022-12-05 23:05:28,122 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:28,122 INFO:     Epoch: 44
2022-12-05 23:05:28,824 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49201035736636684, 'Total loss': 0.49201035736636684} | train loss {'Reaction outcome loss': 0.5198174750318333, 'Total loss': 0.5198174750318333}
2022-12-05 23:05:28,824 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:28,824 INFO:     Epoch: 45
2022-12-05 23:05:29,528 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4972044602036476, 'Total loss': 0.4972044602036476} | train loss {'Reaction outcome loss': 0.5166054414851325, 'Total loss': 0.5166054414851325}
2022-12-05 23:05:29,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:29,528 INFO:     Epoch: 46
2022-12-05 23:05:30,232 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5451997044411573, 'Total loss': 0.5451997044411573} | train loss {'Reaction outcome loss': 0.5187019247181561, 'Total loss': 0.5187019247181561}
2022-12-05 23:05:30,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:30,234 INFO:     Epoch: 47
2022-12-05 23:05:30,936 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5060902092267167, 'Total loss': 0.5060902092267167} | train loss {'Reaction outcome loss': 0.512199092823632, 'Total loss': 0.512199092823632}
2022-12-05 23:05:30,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:30,936 INFO:     Epoch: 48
2022-12-05 23:05:31,639 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5106022425673225, 'Total loss': 0.5106022425673225} | train loss {'Reaction outcome loss': 0.5144453232993885, 'Total loss': 0.5144453232993885}
2022-12-05 23:05:31,639 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:31,639 INFO:     Epoch: 49
2022-12-05 23:05:32,344 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47367785464633594, 'Total loss': 0.47367785464633594} | train loss {'Reaction outcome loss': 0.5206781712721805, 'Total loss': 0.5206781712721805}
2022-12-05 23:05:32,344 INFO:     Found new best model at epoch 49
2022-12-05 23:05:32,345 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:32,345 INFO:     Epoch: 50
2022-12-05 23:05:33,049 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4942537307400595, 'Total loss': 0.4942537307400595} | train loss {'Reaction outcome loss': 0.5099462327908496, 'Total loss': 0.5099462327908496}
2022-12-05 23:05:33,049 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:33,050 INFO:     Epoch: 51
2022-12-05 23:05:33,751 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5336067222736098, 'Total loss': 0.5336067222736098} | train loss {'Reaction outcome loss': 0.5149741108320197, 'Total loss': 0.5149741108320197}
2022-12-05 23:05:33,751 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:33,751 INFO:     Epoch: 52
2022-12-05 23:05:34,453 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49975440346381883, 'Total loss': 0.49975440346381883} | train loss {'Reaction outcome loss': 0.5198773437616776, 'Total loss': 0.5198773437616776}
2022-12-05 23:05:34,453 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:34,453 INFO:     Epoch: 53
2022-12-05 23:05:35,155 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49468233140016143, 'Total loss': 0.49468233140016143} | train loss {'Reaction outcome loss': 0.507629528884985, 'Total loss': 0.507629528884985}
2022-12-05 23:05:35,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:35,156 INFO:     Epoch: 54
2022-12-05 23:05:35,859 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.46996505897153507, 'Total loss': 0.46996505897153507} | train loss {'Reaction outcome loss': 0.5089578618808669, 'Total loss': 0.5089578618808669}
2022-12-05 23:05:35,859 INFO:     Found new best model at epoch 54
2022-12-05 23:05:35,860 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:35,860 INFO:     Epoch: 55
2022-12-05 23:05:36,564 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48587008531798015, 'Total loss': 0.48587008531798015} | train loss {'Reaction outcome loss': 0.5140286645110772, 'Total loss': 0.5140286645110772}
2022-12-05 23:05:36,564 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:36,564 INFO:     Epoch: 56
2022-12-05 23:05:37,267 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5212834924459457, 'Total loss': 0.5212834924459457} | train loss {'Reaction outcome loss': 0.5031924918598059, 'Total loss': 0.5031924918598059}
2022-12-05 23:05:37,267 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:37,267 INFO:     Epoch: 57
2022-12-05 23:05:37,970 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48654529215259984, 'Total loss': 0.48654529215259984} | train loss {'Reaction outcome loss': 0.5253110749989139, 'Total loss': 0.5253110749989139}
2022-12-05 23:05:37,970 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:37,970 INFO:     Epoch: 58
2022-12-05 23:05:38,673 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4821995496749878, 'Total loss': 0.4821995496749878} | train loss {'Reaction outcome loss': 0.5074863764096279, 'Total loss': 0.5074863764096279}
2022-12-05 23:05:38,673 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:38,673 INFO:     Epoch: 59
2022-12-05 23:05:39,377 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49519343267787586, 'Total loss': 0.49519343267787586} | train loss {'Reaction outcome loss': 0.5089969576013331, 'Total loss': 0.5089969576013331}
2022-12-05 23:05:39,377 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:39,377 INFO:     Epoch: 60
2022-12-05 23:05:40,081 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5206650908697735, 'Total loss': 0.5206650908697735} | train loss {'Reaction outcome loss': 0.5123780413549773, 'Total loss': 0.5123780413549773}
2022-12-05 23:05:40,082 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:40,082 INFO:     Epoch: 61
2022-12-05 23:05:40,786 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5008641217242588, 'Total loss': 0.5008641217242588} | train loss {'Reaction outcome loss': 0.5013563297232803, 'Total loss': 0.5013563297232803}
2022-12-05 23:05:40,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:40,787 INFO:     Epoch: 62
2022-12-05 23:05:41,494 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5062615139917894, 'Total loss': 0.5062615139917894} | train loss {'Reaction outcome loss': 0.506601780774642, 'Total loss': 0.506601780774642}
2022-12-05 23:05:41,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:41,494 INFO:     Epoch: 63
2022-12-05 23:05:42,202 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5096951201558113, 'Total loss': 0.5096951201558113} | train loss {'Reaction outcome loss': 0.5189657455196186, 'Total loss': 0.5189657455196186}
2022-12-05 23:05:42,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:42,203 INFO:     Epoch: 64
2022-12-05 23:05:42,909 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49220927906307305, 'Total loss': 0.49220927906307305} | train loss {'Reaction outcome loss': 0.5101254607949938, 'Total loss': 0.5101254607949938}
2022-12-05 23:05:42,910 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:42,910 INFO:     Epoch: 65
2022-12-05 23:05:43,613 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4788735425946387, 'Total loss': 0.4788735425946387} | train loss {'Reaction outcome loss': 0.5125653085659961, 'Total loss': 0.5125653085659961}
2022-12-05 23:05:43,614 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:43,614 INFO:     Epoch: 66
2022-12-05 23:05:44,320 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.484928102994507, 'Total loss': 0.484928102994507} | train loss {'Reaction outcome loss': 0.50226614803684, 'Total loss': 0.50226614803684}
2022-12-05 23:05:44,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:44,320 INFO:     Epoch: 67
2022-12-05 23:05:45,029 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4983111653815616, 'Total loss': 0.4983111653815616} | train loss {'Reaction outcome loss': 0.5051666045675473, 'Total loss': 0.5051666045675473}
2022-12-05 23:05:45,030 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:45,030 INFO:     Epoch: 68
2022-12-05 23:05:45,750 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4826632998883724, 'Total loss': 0.4826632998883724} | train loss {'Reaction outcome loss': 0.5194498132686226, 'Total loss': 0.5194498132686226}
2022-12-05 23:05:45,750 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:45,750 INFO:     Epoch: 69
2022-12-05 23:05:46,470 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4852715696800839, 'Total loss': 0.4852715696800839} | train loss {'Reaction outcome loss': 0.504598060980135, 'Total loss': 0.504598060980135}
2022-12-05 23:05:46,470 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:46,470 INFO:     Epoch: 70
2022-12-05 23:05:47,196 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4766703593459996, 'Total loss': 0.4766703593459996} | train loss {'Reaction outcome loss': 0.5099046404568517, 'Total loss': 0.5099046404568517}
2022-12-05 23:05:47,197 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:47,197 INFO:     Epoch: 71
2022-12-05 23:05:47,918 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5281327976421877, 'Total loss': 0.5281327976421877} | train loss {'Reaction outcome loss': 0.5142298376073643, 'Total loss': 0.5142298376073643}
2022-12-05 23:05:47,918 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:47,919 INFO:     Epoch: 72
2022-12-05 23:05:48,641 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47056401863863523, 'Total loss': 0.47056401863863523} | train loss {'Reaction outcome loss': 0.5029886003051486, 'Total loss': 0.5029886003051486}
2022-12-05 23:05:48,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:48,642 INFO:     Epoch: 73
2022-12-05 23:05:49,361 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5109112316911871, 'Total loss': 0.5109112316911871} | train loss {'Reaction outcome loss': 0.5023617497512273, 'Total loss': 0.5023617497512273}
2022-12-05 23:05:49,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:49,361 INFO:     Epoch: 74
2022-12-05 23:05:50,080 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.505802103064277, 'Total loss': 0.505802103064277} | train loss {'Reaction outcome loss': 0.5121834820630599, 'Total loss': 0.5121834820630599}
2022-12-05 23:05:50,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:50,080 INFO:     Epoch: 75
2022-12-05 23:05:50,791 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5322532846846364, 'Total loss': 0.5322532846846364} | train loss {'Reaction outcome loss': 0.5059392101302439, 'Total loss': 0.5059392101302439}
2022-12-05 23:05:50,791 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:50,791 INFO:     Epoch: 76
2022-12-05 23:05:51,494 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5587090572172945, 'Total loss': 0.5587090572172945} | train loss {'Reaction outcome loss': 0.5020516054058561, 'Total loss': 0.5020516054058561}
2022-12-05 23:05:51,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:51,494 INFO:     Epoch: 77
2022-12-05 23:05:52,201 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4786899330263788, 'Total loss': 0.4786899330263788} | train loss {'Reaction outcome loss': 0.5090297559086158, 'Total loss': 0.5090297559086158}
2022-12-05 23:05:52,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:52,202 INFO:     Epoch: 78
2022-12-05 23:05:52,905 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5523119226775386, 'Total loss': 0.5523119226775386} | train loss {'Reaction outcome loss': 0.5051123744979197, 'Total loss': 0.5051123744979197}
2022-12-05 23:05:52,905 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:52,905 INFO:     Epoch: 79
2022-12-05 23:05:53,614 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49522621353918855, 'Total loss': 0.49522621353918855} | train loss {'Reaction outcome loss': 0.5117106631094096, 'Total loss': 0.5117106631094096}
2022-12-05 23:05:53,614 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:53,614 INFO:     Epoch: 80
2022-12-05 23:05:54,320 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5004938766360283, 'Total loss': 0.5004938766360283} | train loss {'Reaction outcome loss': 0.5060123832858339, 'Total loss': 0.5060123832858339}
2022-12-05 23:05:54,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:54,321 INFO:     Epoch: 81
2022-12-05 23:05:55,019 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5400677275928584, 'Total loss': 0.5400677275928584} | train loss {'Reaction outcome loss': 0.49676245134703967, 'Total loss': 0.49676245134703967}
2022-12-05 23:05:55,019 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:55,020 INFO:     Epoch: 82
2022-12-05 23:05:55,718 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47867961261760106, 'Total loss': 0.47867961261760106} | train loss {'Reaction outcome loss': 0.5078070062763836, 'Total loss': 0.5078070062763836}
2022-12-05 23:05:55,719 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:55,719 INFO:     Epoch: 83
2022-12-05 23:05:56,419 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4707973777231845, 'Total loss': 0.4707973777231845} | train loss {'Reaction outcome loss': 0.5074959318248593, 'Total loss': 0.5074959318248593}
2022-12-05 23:05:56,420 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:56,420 INFO:     Epoch: 84
2022-12-05 23:05:57,120 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5000014924867586, 'Total loss': 0.5000014924867586} | train loss {'Reaction outcome loss': 0.508378814799445, 'Total loss': 0.508378814799445}
2022-12-05 23:05:57,120 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:57,120 INFO:     Epoch: 85
2022-12-05 23:05:57,823 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5012556882575154, 'Total loss': 0.5012556882575154} | train loss {'Reaction outcome loss': 0.5098645679804743, 'Total loss': 0.5098645679804743}
2022-12-05 23:05:57,823 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:57,823 INFO:     Epoch: 86
2022-12-05 23:05:58,523 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49160857837308536, 'Total loss': 0.49160857837308536} | train loss {'Reaction outcome loss': 0.5044325691096637, 'Total loss': 0.5044325691096637}
2022-12-05 23:05:58,523 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:58,523 INFO:     Epoch: 87
2022-12-05 23:05:59,222 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47777377983385866, 'Total loss': 0.47777377983385866} | train loss {'Reaction outcome loss': 0.5168452303020321, 'Total loss': 0.5168452303020321}
2022-12-05 23:05:59,222 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:59,222 INFO:     Epoch: 88
2022-12-05 23:05:59,924 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5275134274905379, 'Total loss': 0.5275134274905379} | train loss {'Reaction outcome loss': 0.5009249645836499, 'Total loss': 0.5009249645836499}
2022-12-05 23:05:59,924 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:05:59,924 INFO:     Epoch: 89
2022-12-05 23:06:00,628 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48861815136941994, 'Total loss': 0.48861815136941994} | train loss {'Reaction outcome loss': 0.507538849358656, 'Total loss': 0.507538849358656}
2022-12-05 23:06:00,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:00,628 INFO:     Epoch: 90
2022-12-05 23:06:01,328 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5247196622870185, 'Total loss': 0.5247196622870185} | train loss {'Reaction outcome loss': 0.5112759637589357, 'Total loss': 0.5112759637589357}
2022-12-05 23:06:01,329 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:01,329 INFO:     Epoch: 91
2022-12-05 23:06:02,027 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5116061839190397, 'Total loss': 0.5116061839190397} | train loss {'Reaction outcome loss': 0.5019024779601973, 'Total loss': 0.5019024779601973}
2022-12-05 23:06:02,028 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:02,028 INFO:     Epoch: 92
2022-12-05 23:06:02,730 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4885148155418309, 'Total loss': 0.4885148155418309} | train loss {'Reaction outcome loss': 0.5040565665583221, 'Total loss': 0.5040565665583221}
2022-12-05 23:06:02,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:02,730 INFO:     Epoch: 93
2022-12-05 23:06:03,429 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5304229398342696, 'Total loss': 0.5304229398342696} | train loss {'Reaction outcome loss': 0.5029397874462361, 'Total loss': 0.5029397874462361}
2022-12-05 23:06:03,429 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:03,429 INFO:     Epoch: 94
2022-12-05 23:06:04,128 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5199782563881441, 'Total loss': 0.5199782563881441} | train loss {'Reaction outcome loss': 0.49785607426750417, 'Total loss': 0.49785607426750417}
2022-12-05 23:06:04,128 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:04,128 INFO:     Epoch: 95
2022-12-05 23:06:04,833 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49731011485511606, 'Total loss': 0.49731011485511606} | train loss {'Reaction outcome loss': 0.5039456074031032, 'Total loss': 0.5039456074031032}
2022-12-05 23:06:04,833 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:04,833 INFO:     Epoch: 96
2022-12-05 23:06:05,533 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5081890586086295, 'Total loss': 0.5081890586086295} | train loss {'Reaction outcome loss': 0.4973633510725839, 'Total loss': 0.4973633510725839}
2022-12-05 23:06:05,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:05,533 INFO:     Epoch: 97
2022-12-05 23:06:06,232 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5235004333609884, 'Total loss': 0.5235004333609884} | train loss {'Reaction outcome loss': 0.5128165650732663, 'Total loss': 0.5128165650732663}
2022-12-05 23:06:06,232 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:06,232 INFO:     Epoch: 98
2022-12-05 23:06:06,934 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49273615127260034, 'Total loss': 0.49273615127260034} | train loss {'Reaction outcome loss': 0.5076433442685069, 'Total loss': 0.5076433442685069}
2022-12-05 23:06:06,934 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:06,934 INFO:     Epoch: 99
2022-12-05 23:06:07,636 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4894247774712064, 'Total loss': 0.4894247774712064} | train loss {'Reaction outcome loss': 0.5043453307784334, 'Total loss': 0.5043453307784334}
2022-12-05 23:06:07,637 INFO:     Best model found after epoch 55 of 100.
2022-12-05 23:06:07,637 INFO:   Done with stage: TRAINING
2022-12-05 23:06:07,637 INFO:   Starting stage: EVALUATION
2022-12-05 23:06:07,766 INFO:   Done with stage: EVALUATION
2022-12-05 23:06:07,766 INFO:   Leaving out SEQ value Fold_1
2022-12-05 23:06:07,779 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-12-05 23:06:07,779 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:06:08,405 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:06:08,405 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:06:08,474 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:06:08,474 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:06:08,474 INFO:     No hyperparam tuning for this model
2022-12-05 23:06:08,474 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:06:08,475 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:06:08,475 INFO:     None feature selector for col prot
2022-12-05 23:06:08,475 INFO:     None feature selector for col prot
2022-12-05 23:06:08,475 INFO:     None feature selector for col prot
2022-12-05 23:06:08,476 INFO:     None feature selector for col chem
2022-12-05 23:06:08,476 INFO:     None feature selector for col chem
2022-12-05 23:06:08,476 INFO:     None feature selector for col chem
2022-12-05 23:06:08,476 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:06:08,476 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:06:08,478 INFO:     Number of params in model 215731
2022-12-05 23:06:08,481 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:06:08,481 INFO:   Starting stage: TRAINING
2022-12-05 23:06:08,538 INFO:     Val loss before train {'Reaction outcome loss': 0.9907549522643866, 'Total loss': 0.9907549522643866}
2022-12-05 23:06:08,538 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:08,538 INFO:     Epoch: 0
2022-12-05 23:06:09,234 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7689523786999458, 'Total loss': 0.7689523786999458} | train loss {'Reaction outcome loss': 0.8163707181504725, 'Total loss': 0.8163707181504725}
2022-12-05 23:06:09,234 INFO:     Found new best model at epoch 0
2022-12-05 23:06:09,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:09,235 INFO:     Epoch: 1
2022-12-05 23:06:09,931 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6274521066698917, 'Total loss': 0.6274521066698917} | train loss {'Reaction outcome loss': 0.6982389733869843, 'Total loss': 0.6982389733869843}
2022-12-05 23:06:09,931 INFO:     Found new best model at epoch 1
2022-12-05 23:06:09,932 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:09,932 INFO:     Epoch: 2
2022-12-05 23:06:10,624 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6080675166706706, 'Total loss': 0.6080675166706706} | train loss {'Reaction outcome loss': 0.6190218223956386, 'Total loss': 0.6190218223956386}
2022-12-05 23:06:10,624 INFO:     Found new best model at epoch 2
2022-12-05 23:06:10,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:10,625 INFO:     Epoch: 3
2022-12-05 23:06:11,320 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5703092803095662, 'Total loss': 0.5703092803095662} | train loss {'Reaction outcome loss': 0.5820556104551127, 'Total loss': 0.5820556104551127}
2022-12-05 23:06:11,320 INFO:     Found new best model at epoch 3
2022-12-05 23:06:11,321 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:11,321 INFO:     Epoch: 4
2022-12-05 23:06:12,014 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5920515303001848, 'Total loss': 0.5920515303001848} | train loss {'Reaction outcome loss': 0.5774879633399194, 'Total loss': 0.5774879633399194}
2022-12-05 23:06:12,014 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:12,014 INFO:     Epoch: 5
2022-12-05 23:06:12,706 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5497727172319279, 'Total loss': 0.5497727172319279} | train loss {'Reaction outcome loss': 0.5726120821487757, 'Total loss': 0.5726120821487757}
2022-12-05 23:06:12,706 INFO:     Found new best model at epoch 5
2022-12-05 23:06:12,707 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:12,707 INFO:     Epoch: 6
2022-12-05 23:06:13,402 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5613518741934799, 'Total loss': 0.5613518741934799} | train loss {'Reaction outcome loss': 0.5518057458562615, 'Total loss': 0.5518057458562615}
2022-12-05 23:06:13,403 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:13,403 INFO:     Epoch: 7
2022-12-05 23:06:14,093 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.574568783474523, 'Total loss': 0.574568783474523} | train loss {'Reaction outcome loss': 0.5493847374562864, 'Total loss': 0.5493847374562864}
2022-12-05 23:06:14,093 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:14,093 INFO:     Epoch: 8
2022-12-05 23:06:14,784 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5514293777388196, 'Total loss': 0.5514293777388196} | train loss {'Reaction outcome loss': 0.5495709096208031, 'Total loss': 0.5495709096208031}
2022-12-05 23:06:14,784 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:14,784 INFO:     Epoch: 9
2022-12-05 23:06:15,477 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.6024553858956625, 'Total loss': 0.6024553858956625} | train loss {'Reaction outcome loss': 0.5421226396850107, 'Total loss': 0.5421226396850107}
2022-12-05 23:06:15,478 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:15,478 INFO:     Epoch: 10
2022-12-05 23:06:16,167 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5289398126823958, 'Total loss': 0.5289398126823958} | train loss {'Reaction outcome loss': 0.5368553569900646, 'Total loss': 0.5368553569900646}
2022-12-05 23:06:16,167 INFO:     Found new best model at epoch 10
2022-12-05 23:06:16,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:16,168 INFO:     Epoch: 11
2022-12-05 23:06:16,859 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5455100411592528, 'Total loss': 0.5455100411592528} | train loss {'Reaction outcome loss': 0.5305460184321973, 'Total loss': 0.5305460184321973}
2022-12-05 23:06:16,859 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:16,859 INFO:     Epoch: 12
2022-12-05 23:06:17,551 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5964498845643775, 'Total loss': 0.5964498845643775} | train loss {'Reaction outcome loss': 0.5362628308956515, 'Total loss': 0.5362628308956515}
2022-12-05 23:06:17,551 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:17,551 INFO:     Epoch: 13
2022-12-05 23:06:18,243 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.557004970173503, 'Total loss': 0.557004970173503} | train loss {'Reaction outcome loss': 0.526583726084772, 'Total loss': 0.526583726084772}
2022-12-05 23:06:18,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:18,243 INFO:     Epoch: 14
2022-12-05 23:06:18,935 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5313559784445652, 'Total loss': 0.5313559784445652} | train loss {'Reaction outcome loss': 0.5318164122080116, 'Total loss': 0.5318164122080116}
2022-12-05 23:06:18,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:18,936 INFO:     Epoch: 15
2022-12-05 23:06:19,626 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6070718959320424, 'Total loss': 0.6070718959320424} | train loss {'Reaction outcome loss': 0.5336049917180843, 'Total loss': 0.5336049917180843}
2022-12-05 23:06:19,626 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:19,626 INFO:     Epoch: 16
2022-12-05 23:06:20,320 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5611780285835266, 'Total loss': 0.5611780285835266} | train loss {'Reaction outcome loss': 0.529974653458399, 'Total loss': 0.529974653458399}
2022-12-05 23:06:20,321 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:20,321 INFO:     Epoch: 17
2022-12-05 23:06:21,015 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5575144381024116, 'Total loss': 0.5575144381024116} | train loss {'Reaction outcome loss': 0.5264060722947611, 'Total loss': 0.5264060722947611}
2022-12-05 23:06:21,015 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:21,015 INFO:     Epoch: 18
2022-12-05 23:06:21,706 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5457526784996654, 'Total loss': 0.5457526784996654} | train loss {'Reaction outcome loss': 0.5350512287008419, 'Total loss': 0.5350512287008419}
2022-12-05 23:06:21,706 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:21,706 INFO:     Epoch: 19
2022-12-05 23:06:22,401 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5649154650610547, 'Total loss': 0.5649154650610547} | train loss {'Reaction outcome loss': 0.5274040435935244, 'Total loss': 0.5274040435935244}
2022-12-05 23:06:22,401 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:22,401 INFO:     Epoch: 20
2022-12-05 23:06:23,092 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.516544217287108, 'Total loss': 0.516544217287108} | train loss {'Reaction outcome loss': 0.5310138747280027, 'Total loss': 0.5310138747280027}
2022-12-05 23:06:23,092 INFO:     Found new best model at epoch 20
2022-12-05 23:06:23,092 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:23,092 INFO:     Epoch: 21
2022-12-05 23:06:23,782 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5529000828432482, 'Total loss': 0.5529000828432482} | train loss {'Reaction outcome loss': 0.5227912177519544, 'Total loss': 0.5227912177519544}
2022-12-05 23:06:23,783 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:23,783 INFO:     Epoch: 22
2022-12-05 23:06:24,472 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5135724350463512, 'Total loss': 0.5135724350463512} | train loss {'Reaction outcome loss': 0.5351121985495336, 'Total loss': 0.5351121985495336}
2022-12-05 23:06:24,472 INFO:     Found new best model at epoch 22
2022-12-05 23:06:24,473 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:24,473 INFO:     Epoch: 23
2022-12-05 23:06:25,166 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5211753862541776, 'Total loss': 0.5211753862541776} | train loss {'Reaction outcome loss': 0.5281150570990126, 'Total loss': 0.5281150570990126}
2022-12-05 23:06:25,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:25,166 INFO:     Epoch: 24
2022-12-05 23:06:25,859 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5724200329115224, 'Total loss': 0.5724200329115224} | train loss {'Reaction outcome loss': 0.5269819347210872, 'Total loss': 0.5269819347210872}
2022-12-05 23:06:25,859 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:25,859 INFO:     Epoch: 25
2022-12-05 23:06:26,552 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5302161813475365, 'Total loss': 0.5302161813475365} | train loss {'Reaction outcome loss': 0.5227010276459862, 'Total loss': 0.5227010276459862}
2022-12-05 23:06:26,552 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:26,552 INFO:     Epoch: 26
2022-12-05 23:06:27,243 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.521604330733765, 'Total loss': 0.521604330733765} | train loss {'Reaction outcome loss': 0.52461617541166, 'Total loss': 0.52461617541166}
2022-12-05 23:06:27,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:27,243 INFO:     Epoch: 27
2022-12-05 23:06:27,934 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5257524023222369, 'Total loss': 0.5257524023222369} | train loss {'Reaction outcome loss': 0.5270552672599078, 'Total loss': 0.5270552672599078}
2022-12-05 23:06:27,934 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:27,934 INFO:     Epoch: 28
2022-12-05 23:06:28,625 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5737034175978151, 'Total loss': 0.5737034175978151} | train loss {'Reaction outcome loss': 0.5194147386178067, 'Total loss': 0.5194147386178067}
2022-12-05 23:06:28,625 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:28,625 INFO:     Epoch: 29
2022-12-05 23:06:29,315 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.6626242322977199, 'Total loss': 0.6626242322977199} | train loss {'Reaction outcome loss': 0.5818132345445852, 'Total loss': 0.5818132345445852}
2022-12-05 23:06:29,315 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:29,316 INFO:     Epoch: 30
2022-12-05 23:06:30,007 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5118844827940298, 'Total loss': 0.5118844827940298} | train loss {'Reaction outcome loss': 0.5381082379155688, 'Total loss': 0.5381082379155688}
2022-12-05 23:06:30,007 INFO:     Found new best model at epoch 30
2022-12-05 23:06:30,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:30,008 INFO:     Epoch: 31
2022-12-05 23:06:30,704 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5683329327161922, 'Total loss': 0.5683329327161922} | train loss {'Reaction outcome loss': 0.5214602892045621, 'Total loss': 0.5214602892045621}
2022-12-05 23:06:30,704 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:30,704 INFO:     Epoch: 32
2022-12-05 23:06:31,399 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5051966240239698, 'Total loss': 0.5051966240239698} | train loss {'Reaction outcome loss': 0.5326658847278037, 'Total loss': 0.5326658847278037}
2022-12-05 23:06:31,400 INFO:     Found new best model at epoch 32
2022-12-05 23:06:31,400 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:31,400 INFO:     Epoch: 33
2022-12-05 23:06:32,093 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5737372636795044, 'Total loss': 0.5737372636795044} | train loss {'Reaction outcome loss': 0.5161827499115909, 'Total loss': 0.5161827499115909}
2022-12-05 23:06:32,093 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:32,094 INFO:     Epoch: 34
2022-12-05 23:06:32,787 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5438049723242604, 'Total loss': 0.5438049723242604} | train loss {'Reaction outcome loss': 0.534062320558132, 'Total loss': 0.534062320558132}
2022-12-05 23:06:32,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:32,788 INFO:     Epoch: 35
2022-12-05 23:06:33,479 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5269779088192208, 'Total loss': 0.5269779088192208} | train loss {'Reaction outcome loss': 0.5222236330739756, 'Total loss': 0.5222236330739756}
2022-12-05 23:06:33,479 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:33,479 INFO:     Epoch: 36
2022-12-05 23:06:34,169 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5267347790474115, 'Total loss': 0.5267347790474115} | train loss {'Reaction outcome loss': 0.5170821989637343, 'Total loss': 0.5170821989637343}
2022-12-05 23:06:34,169 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:34,169 INFO:     Epoch: 37
2022-12-05 23:06:34,860 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5450235743855321, 'Total loss': 0.5450235743855321} | train loss {'Reaction outcome loss': 0.5232078062040816, 'Total loss': 0.5232078062040816}
2022-12-05 23:06:34,860 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:34,860 INFO:     Epoch: 38
2022-12-05 23:06:35,554 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5300381277189699, 'Total loss': 0.5300381277189699} | train loss {'Reaction outcome loss': 0.5233131372388989, 'Total loss': 0.5233131372388989}
2022-12-05 23:06:35,554 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:35,554 INFO:     Epoch: 39
2022-12-05 23:06:36,245 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5242475288551908, 'Total loss': 0.5242475288551908} | train loss {'Reaction outcome loss': 0.5199474629796581, 'Total loss': 0.5199474629796581}
2022-12-05 23:06:36,245 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:36,245 INFO:     Epoch: 40
2022-12-05 23:06:36,938 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.55249573810156, 'Total loss': 0.55249573810156} | train loss {'Reaction outcome loss': 0.5227203888535009, 'Total loss': 0.5227203888535009}
2022-12-05 23:06:36,938 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:36,938 INFO:     Epoch: 41
2022-12-05 23:06:37,633 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5164058780254319, 'Total loss': 0.5164058780254319} | train loss {'Reaction outcome loss': 0.526005912035581, 'Total loss': 0.526005912035581}
2022-12-05 23:06:37,633 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:37,633 INFO:     Epoch: 42
2022-12-05 23:06:38,324 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5458663979242014, 'Total loss': 0.5458663979242014} | train loss {'Reaction outcome loss': 0.5243248827295539, 'Total loss': 0.5243248827295539}
2022-12-05 23:06:38,324 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:38,324 INFO:     Epoch: 43
2022-12-05 23:06:39,018 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5180576998133992, 'Total loss': 0.5180576998133992} | train loss {'Reaction outcome loss': 0.5286139361407041, 'Total loss': 0.5286139361407041}
2022-12-05 23:06:39,018 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:39,019 INFO:     Epoch: 44
2022-12-05 23:06:39,710 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5466244456379913, 'Total loss': 0.5466244456379913} | train loss {'Reaction outcome loss': 0.5232358597862867, 'Total loss': 0.5232358597862867}
2022-12-05 23:06:39,710 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:39,710 INFO:     Epoch: 45
2022-12-05 23:06:40,401 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5130435138247734, 'Total loss': 0.5130435138247734} | train loss {'Reaction outcome loss': 0.5184411621449415, 'Total loss': 0.5184411621449415}
2022-12-05 23:06:40,401 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:40,401 INFO:     Epoch: 46
2022-12-05 23:06:41,094 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5114887949339179, 'Total loss': 0.5114887949339179} | train loss {'Reaction outcome loss': 0.5252894393087905, 'Total loss': 0.5252894393087905}
2022-12-05 23:06:41,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:41,095 INFO:     Epoch: 47
2022-12-05 23:06:41,785 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5089121623787769, 'Total loss': 0.5089121623787769} | train loss {'Reaction outcome loss': 0.5199074820603853, 'Total loss': 0.5199074820603853}
2022-12-05 23:06:41,785 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:41,786 INFO:     Epoch: 48
2022-12-05 23:06:42,477 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5295172624809797, 'Total loss': 0.5295172624809797} | train loss {'Reaction outcome loss': 0.5196505480219797, 'Total loss': 0.5196505480219797}
2022-12-05 23:06:42,477 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:42,477 INFO:     Epoch: 49
2022-12-05 23:06:43,167 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5406475330508033, 'Total loss': 0.5406475330508033} | train loss {'Reaction outcome loss': 0.5223527676406711, 'Total loss': 0.5223527676406711}
2022-12-05 23:06:43,167 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:43,168 INFO:     Epoch: 50
2022-12-05 23:06:43,863 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5495422295359678, 'Total loss': 0.5495422295359678} | train loss {'Reaction outcome loss': 0.525094958919066, 'Total loss': 0.525094958919066}
2022-12-05 23:06:43,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:43,864 INFO:     Epoch: 51
2022-12-05 23:06:44,555 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5652944397094638, 'Total loss': 0.5652944397094638} | train loss {'Reaction outcome loss': 0.5188603840247104, 'Total loss': 0.5188603840247104}
2022-12-05 23:06:44,555 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:44,555 INFO:     Epoch: 52
2022-12-05 23:06:45,249 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5178340316511864, 'Total loss': 0.5178340316511864} | train loss {'Reaction outcome loss': 0.5198723261739001, 'Total loss': 0.5198723261739001}
2022-12-05 23:06:45,249 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:45,249 INFO:     Epoch: 53
2022-12-05 23:06:45,948 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5469680650289669, 'Total loss': 0.5469680650289669} | train loss {'Reaction outcome loss': 0.5180831988161974, 'Total loss': 0.5180831988161974}
2022-12-05 23:06:45,948 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:45,949 INFO:     Epoch: 54
2022-12-05 23:06:46,647 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5466939068810884, 'Total loss': 0.5466939068810884} | train loss {'Reaction outcome loss': 0.5205234478039996, 'Total loss': 0.5205234478039996}
2022-12-05 23:06:46,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:46,647 INFO:     Epoch: 55
2022-12-05 23:06:47,342 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5205960557904354, 'Total loss': 0.5205960557904354} | train loss {'Reaction outcome loss': 0.5256887210739983, 'Total loss': 0.5256887210739983}
2022-12-05 23:06:47,342 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:47,342 INFO:     Epoch: 56
2022-12-05 23:06:48,035 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5200605482556099, 'Total loss': 0.5200605482556099} | train loss {'Reaction outcome loss': 0.5272979855292128, 'Total loss': 0.5272979855292128}
2022-12-05 23:06:48,035 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:48,035 INFO:     Epoch: 57
2022-12-05 23:06:48,726 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5009374937345815, 'Total loss': 0.5009374937345815} | train loss {'Reaction outcome loss': 0.5228071109134964, 'Total loss': 0.5228071109134964}
2022-12-05 23:06:48,726 INFO:     Found new best model at epoch 57
2022-12-05 23:06:48,726 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:48,727 INFO:     Epoch: 58
2022-12-05 23:06:49,416 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5143080734929373, 'Total loss': 0.5143080734929373} | train loss {'Reaction outcome loss': 0.522412636643084, 'Total loss': 0.522412636643084}
2022-12-05 23:06:49,416 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:49,416 INFO:     Epoch: 59
2022-12-05 23:06:50,110 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5100974884144095, 'Total loss': 0.5100974884144095} | train loss {'Reaction outcome loss': 0.5181920188076702, 'Total loss': 0.5181920188076702}
2022-12-05 23:06:50,110 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:50,110 INFO:     Epoch: 60
2022-12-05 23:06:50,801 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5475915188706199, 'Total loss': 0.5475915188706199} | train loss {'Reaction outcome loss': 0.5277967418662806, 'Total loss': 0.5277967418662806}
2022-12-05 23:06:50,801 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:50,801 INFO:     Epoch: 61
2022-12-05 23:06:51,493 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5225327167400095, 'Total loss': 0.5225327167400095} | train loss {'Reaction outcome loss': 0.5184641029731727, 'Total loss': 0.5184641029731727}
2022-12-05 23:06:51,493 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:51,493 INFO:     Epoch: 62
2022-12-05 23:06:52,187 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5173615948405377, 'Total loss': 0.5173615948405377} | train loss {'Reaction outcome loss': 0.5220476683888415, 'Total loss': 0.5220476683888415}
2022-12-05 23:06:52,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:52,188 INFO:     Epoch: 63
2022-12-05 23:06:52,880 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5597595378409984, 'Total loss': 0.5597595378409984} | train loss {'Reaction outcome loss': 0.5232750665503765, 'Total loss': 0.5232750665503765}
2022-12-05 23:06:52,881 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:52,881 INFO:     Epoch: 64
2022-12-05 23:06:53,571 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5379146555828493, 'Total loss': 0.5379146555828493} | train loss {'Reaction outcome loss': 0.5165546924611668, 'Total loss': 0.5165546924611668}
2022-12-05 23:06:53,571 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:53,571 INFO:     Epoch: 65
2022-12-05 23:06:54,260 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5202662840832112, 'Total loss': 0.5202662840832112} | train loss {'Reaction outcome loss': 0.5220751285307692, 'Total loss': 0.5220751285307692}
2022-12-05 23:06:54,261 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:54,261 INFO:     Epoch: 66
2022-12-05 23:06:54,951 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4967466426450153, 'Total loss': 0.4967466426450153} | train loss {'Reaction outcome loss': 0.5175592487241015, 'Total loss': 0.5175592487241015}
2022-12-05 23:06:54,951 INFO:     Found new best model at epoch 66
2022-12-05 23:06:54,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:54,951 INFO:     Epoch: 67
2022-12-05 23:06:55,641 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5339503011038137, 'Total loss': 0.5339503011038137} | train loss {'Reaction outcome loss': 0.5187626375582973, 'Total loss': 0.5187626375582973}
2022-12-05 23:06:55,641 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:55,641 INFO:     Epoch: 68
2022-12-05 23:06:56,336 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5655932124964026, 'Total loss': 0.5655932124964026} | train loss {'Reaction outcome loss': 0.5251014491412865, 'Total loss': 0.5251014491412865}
2022-12-05 23:06:56,336 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:56,336 INFO:     Epoch: 69
2022-12-05 23:06:57,029 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5048392352669738, 'Total loss': 0.5048392352669738} | train loss {'Reaction outcome loss': 0.5229915151748147, 'Total loss': 0.5229915151748147}
2022-12-05 23:06:57,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:57,029 INFO:     Epoch: 70
2022-12-05 23:06:57,720 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5301135064557542, 'Total loss': 0.5301135064557542} | train loss {'Reaction outcome loss': 0.5205306941221771, 'Total loss': 0.5205306941221771}
2022-12-05 23:06:57,720 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:57,720 INFO:     Epoch: 71
2022-12-05 23:06:58,414 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5638111448565195, 'Total loss': 0.5638111448565195} | train loss {'Reaction outcome loss': 0.52134523531537, 'Total loss': 0.52134523531537}
2022-12-05 23:06:58,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:58,414 INFO:     Epoch: 72
2022-12-05 23:06:59,107 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5423171166763749, 'Total loss': 0.5423171166763749} | train loss {'Reaction outcome loss': 0.5277378560952198, 'Total loss': 0.5277378560952198}
2022-12-05 23:06:59,107 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:59,107 INFO:     Epoch: 73
2022-12-05 23:06:59,798 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5096202118452205, 'Total loss': 0.5096202118452205} | train loss {'Reaction outcome loss': 0.518756923054962, 'Total loss': 0.518756923054962}
2022-12-05 23:06:59,798 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:06:59,798 INFO:     Epoch: 74
2022-12-05 23:07:00,488 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5228268712065941, 'Total loss': 0.5228268712065941} | train loss {'Reaction outcome loss': 0.5231800328924823, 'Total loss': 0.5231800328924823}
2022-12-05 23:07:00,488 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:00,488 INFO:     Epoch: 75
2022-12-05 23:07:01,178 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5244084139202916, 'Total loss': 0.5244084139202916} | train loss {'Reaction outcome loss': 0.5231230590691782, 'Total loss': 0.5231230590691782}
2022-12-05 23:07:01,178 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:01,178 INFO:     Epoch: 76
2022-12-05 23:07:01,869 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5263369506181672, 'Total loss': 0.5263369506181672} | train loss {'Reaction outcome loss': 0.5258932723184672, 'Total loss': 0.5258932723184672}
2022-12-05 23:07:01,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:01,869 INFO:     Epoch: 77
2022-12-05 23:07:02,560 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5726499411948892, 'Total loss': 0.5726499411948892} | train loss {'Reaction outcome loss': 0.5190187924438052, 'Total loss': 0.5190187924438052}
2022-12-05 23:07:02,560 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:02,560 INFO:     Epoch: 78
2022-12-05 23:07:03,251 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5014214779055396, 'Total loss': 0.5014214779055396} | train loss {'Reaction outcome loss': 0.5213768724428773, 'Total loss': 0.5213768724428773}
2022-12-05 23:07:03,252 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:03,252 INFO:     Epoch: 79
2022-12-05 23:07:03,944 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5455998695173929, 'Total loss': 0.5455998695173929} | train loss {'Reaction outcome loss': 0.5196847875177124, 'Total loss': 0.5196847875177124}
2022-12-05 23:07:03,944 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:03,944 INFO:     Epoch: 80
2022-12-05 23:07:04,637 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5031322039837061, 'Total loss': 0.5031322039837061} | train loss {'Reaction outcome loss': 0.5187462816635767, 'Total loss': 0.5187462816635767}
2022-12-05 23:07:04,637 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:04,637 INFO:     Epoch: 81
2022-12-05 23:07:05,336 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5230963805387187, 'Total loss': 0.5230963805387187} | train loss {'Reaction outcome loss': 0.5213685491325434, 'Total loss': 0.5213685491325434}
2022-12-05 23:07:05,336 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:05,336 INFO:     Epoch: 82
2022-12-05 23:07:06,031 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.512733681257381, 'Total loss': 0.512733681257381} | train loss {'Reaction outcome loss': 0.5235463622420904, 'Total loss': 0.5235463622420904}
2022-12-05 23:07:06,031 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:06,031 INFO:     Epoch: 83
2022-12-05 23:07:06,722 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5385700453852498, 'Total loss': 0.5385700453852498} | train loss {'Reaction outcome loss': 0.5190817962090174, 'Total loss': 0.5190817962090174}
2022-12-05 23:07:06,722 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:06,722 INFO:     Epoch: 84
2022-12-05 23:07:07,413 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5712986893432085, 'Total loss': 0.5712986893432085} | train loss {'Reaction outcome loss': 0.5161565858027573, 'Total loss': 0.5161565858027573}
2022-12-05 23:07:07,413 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:07,413 INFO:     Epoch: 85
2022-12-05 23:07:08,105 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5395608378011126, 'Total loss': 0.5395608378011126} | train loss {'Reaction outcome loss': 0.5185766234196754, 'Total loss': 0.5185766234196754}
2022-12-05 23:07:08,105 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:08,105 INFO:     Epoch: 86
2022-12-05 23:07:08,801 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49647207974001417, 'Total loss': 0.49647207974001417} | train loss {'Reaction outcome loss': 0.5189715387767234, 'Total loss': 0.5189715387767234}
2022-12-05 23:07:08,801 INFO:     Found new best model at epoch 86
2022-12-05 23:07:08,802 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:08,802 INFO:     Epoch: 87
2022-12-05 23:07:09,495 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5328179445377615, 'Total loss': 0.5328179445377615} | train loss {'Reaction outcome loss': 0.5197671085228155, 'Total loss': 0.5197671085228155}
2022-12-05 23:07:09,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:09,496 INFO:     Epoch: 88
2022-12-05 23:07:10,188 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5470888448315997, 'Total loss': 0.5470888448315997} | train loss {'Reaction outcome loss': 0.5192644566052245, 'Total loss': 0.5192644566052245}
2022-12-05 23:07:10,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:10,188 INFO:     Epoch: 89
2022-12-05 23:07:10,881 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5392070863136026, 'Total loss': 0.5392070863136026} | train loss {'Reaction outcome loss': 0.5150705019755618, 'Total loss': 0.5150705019755618}
2022-12-05 23:07:10,881 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:10,881 INFO:     Epoch: 90
2022-12-05 23:07:11,576 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5544557654580404, 'Total loss': 0.5544557654580404} | train loss {'Reaction outcome loss': 0.5172592061169353, 'Total loss': 0.5172592061169353}
2022-12-05 23:07:11,576 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:11,576 INFO:     Epoch: 91
2022-12-05 23:07:12,269 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5526464151781659, 'Total loss': 0.5526464151781659} | train loss {'Reaction outcome loss': 0.5201460713589633, 'Total loss': 0.5201460713589633}
2022-12-05 23:07:12,270 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:12,270 INFO:     Epoch: 92
2022-12-05 23:07:12,959 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5360937271007272, 'Total loss': 0.5360937271007272} | train loss {'Reaction outcome loss': 0.5233134107334624, 'Total loss': 0.5233134107334624}
2022-12-05 23:07:12,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:12,960 INFO:     Epoch: 93
2022-12-05 23:07:13,649 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5221593515124432, 'Total loss': 0.5221593515124432} | train loss {'Reaction outcome loss': 0.5192661257805647, 'Total loss': 0.5192661257805647}
2022-12-05 23:07:13,649 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:13,649 INFO:     Epoch: 94
2022-12-05 23:07:14,339 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5750568100186282, 'Total loss': 0.5750568100186282} | train loss {'Reaction outcome loss': 0.516205042723275, 'Total loss': 0.516205042723275}
2022-12-05 23:07:14,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:14,339 INFO:     Epoch: 95
2022-12-05 23:07:15,032 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5139049929241801, 'Total loss': 0.5139049929241801} | train loss {'Reaction outcome loss': 0.5166681177699517, 'Total loss': 0.5166681177699517}
2022-12-05 23:07:15,032 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:15,032 INFO:     Epoch: 96
2022-12-05 23:07:15,722 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5196999910958978, 'Total loss': 0.5196999910958978} | train loss {'Reaction outcome loss': 0.5180542204115126, 'Total loss': 0.5180542204115126}
2022-12-05 23:07:15,722 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:15,722 INFO:     Epoch: 97
2022-12-05 23:07:16,411 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5513531194869862, 'Total loss': 0.5513531194869862} | train loss {'Reaction outcome loss': 0.5214810032750108, 'Total loss': 0.5214810032750108}
2022-12-05 23:07:16,411 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:16,412 INFO:     Epoch: 98
2022-12-05 23:07:17,102 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5205555592858514, 'Total loss': 0.5205555592858514} | train loss {'Reaction outcome loss': 0.517897542305444, 'Total loss': 0.517897542305444}
2022-12-05 23:07:17,102 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:17,102 INFO:     Epoch: 99
2022-12-05 23:07:17,792 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5311227704203406, 'Total loss': 0.5311227704203406} | train loss {'Reaction outcome loss': 0.5256171467495553, 'Total loss': 0.5256171467495553}
2022-12-05 23:07:17,792 INFO:     Best model found after epoch 87 of 100.
2022-12-05 23:07:17,792 INFO:   Done with stage: TRAINING
2022-12-05 23:07:17,792 INFO:   Starting stage: EVALUATION
2022-12-05 23:07:17,933 INFO:   Done with stage: EVALUATION
2022-12-05 23:07:17,933 INFO:   Leaving out SEQ value Fold_2
2022-12-05 23:07:17,945 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:07:17,946 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:07:18,581 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:07:18,581 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:07:18,652 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:07:18,653 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:07:18,653 INFO:     No hyperparam tuning for this model
2022-12-05 23:07:18,653 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:07:18,653 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:07:18,653 INFO:     None feature selector for col prot
2022-12-05 23:07:18,654 INFO:     None feature selector for col prot
2022-12-05 23:07:18,654 INFO:     None feature selector for col prot
2022-12-05 23:07:18,654 INFO:     None feature selector for col chem
2022-12-05 23:07:18,654 INFO:     None feature selector for col chem
2022-12-05 23:07:18,654 INFO:     None feature selector for col chem
2022-12-05 23:07:18,654 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:07:18,654 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:07:18,656 INFO:     Number of params in model 215731
2022-12-05 23:07:18,659 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:07:18,659 INFO:   Starting stage: TRAINING
2022-12-05 23:07:18,717 INFO:     Val loss before train {'Reaction outcome loss': 0.9554863016713749, 'Total loss': 0.9554863016713749}
2022-12-05 23:07:18,717 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:18,717 INFO:     Epoch: 0
2022-12-05 23:07:19,425 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7033906978639689, 'Total loss': 0.7033906978639689} | train loss {'Reaction outcome loss': 0.8132820311586867, 'Total loss': 0.8132820311586867}
2022-12-05 23:07:19,425 INFO:     Found new best model at epoch 0
2022-12-05 23:07:19,426 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:19,426 INFO:     Epoch: 1
2022-12-05 23:07:20,135 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6894020438194275, 'Total loss': 0.6894020438194275} | train loss {'Reaction outcome loss': 0.6648932853449694, 'Total loss': 0.6648932853449694}
2022-12-05 23:07:20,135 INFO:     Found new best model at epoch 1
2022-12-05 23:07:20,136 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:20,136 INFO:     Epoch: 2
2022-12-05 23:07:20,837 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7554583298889074, 'Total loss': 0.7554583298889074} | train loss {'Reaction outcome loss': 0.6322031640692761, 'Total loss': 0.6322031640692761}
2022-12-05 23:07:20,837 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:20,837 INFO:     Epoch: 3
2022-12-05 23:07:21,539 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5802250897342508, 'Total loss': 0.5802250897342508} | train loss {'Reaction outcome loss': 0.5995735601985804, 'Total loss': 0.5995735601985804}
2022-12-05 23:07:21,540 INFO:     Found new best model at epoch 3
2022-12-05 23:07:21,540 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:21,540 INFO:     Epoch: 4
2022-12-05 23:07:22,245 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6040597849271514, 'Total loss': 0.6040597849271514} | train loss {'Reaction outcome loss': 0.5801088774373174, 'Total loss': 0.5801088774373174}
2022-12-05 23:07:22,245 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:22,245 INFO:     Epoch: 5
2022-12-05 23:07:22,948 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.562951082533056, 'Total loss': 0.562951082533056} | train loss {'Reaction outcome loss': 0.5682550653634284, 'Total loss': 0.5682550653634284}
2022-12-05 23:07:22,948 INFO:     Found new best model at epoch 5
2022-12-05 23:07:22,949 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:22,949 INFO:     Epoch: 6
2022-12-05 23:07:23,650 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5774720602414825, 'Total loss': 0.5774720602414825} | train loss {'Reaction outcome loss': 0.5536500794383196, 'Total loss': 0.5536500794383196}
2022-12-05 23:07:23,650 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:23,650 INFO:     Epoch: 7
2022-12-05 23:07:24,351 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5111983086575161, 'Total loss': 0.5111983086575161} | train loss {'Reaction outcome loss': 0.5597722419360389, 'Total loss': 0.5597722419360389}
2022-12-05 23:07:24,351 INFO:     Found new best model at epoch 7
2022-12-05 23:07:24,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:24,352 INFO:     Epoch: 8
2022-12-05 23:07:25,052 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5308518348769709, 'Total loss': 0.5308518348769709} | train loss {'Reaction outcome loss': 0.5380930540412061, 'Total loss': 0.5380930540412061}
2022-12-05 23:07:25,053 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:25,053 INFO:     Epoch: 9
2022-12-05 23:07:25,753 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5141701677983458, 'Total loss': 0.5141701677983458} | train loss {'Reaction outcome loss': 0.5375950029383787, 'Total loss': 0.5375950029383787}
2022-12-05 23:07:25,753 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:25,753 INFO:     Epoch: 10
2022-12-05 23:07:26,454 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4902515099807219, 'Total loss': 0.4902515099807219} | train loss {'Reaction outcome loss': 0.5270755789827118, 'Total loss': 0.5270755789827118}
2022-12-05 23:07:26,454 INFO:     Found new best model at epoch 10
2022-12-05 23:07:26,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:26,455 INFO:     Epoch: 11
2022-12-05 23:07:27,155 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5287789045409723, 'Total loss': 0.5287789045409723} | train loss {'Reaction outcome loss': 0.5296702286009847, 'Total loss': 0.5296702286009847}
2022-12-05 23:07:27,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:27,156 INFO:     Epoch: 12
2022-12-05 23:07:27,859 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4961748648096215, 'Total loss': 0.4961748648096215} | train loss {'Reaction outcome loss': 0.5350917689502239, 'Total loss': 0.5350917689502239}
2022-12-05 23:07:27,859 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:27,859 INFO:     Epoch: 13
2022-12-05 23:07:28,564 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5183283872902393, 'Total loss': 0.5183283872902393} | train loss {'Reaction outcome loss': 0.5254467511587297, 'Total loss': 0.5254467511587297}
2022-12-05 23:07:28,564 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:28,564 INFO:     Epoch: 14
2022-12-05 23:07:29,275 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5144775565713644, 'Total loss': 0.5144775565713644} | train loss {'Reaction outcome loss': 0.5244661745754814, 'Total loss': 0.5244661745754814}
2022-12-05 23:07:29,275 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:29,275 INFO:     Epoch: 15
2022-12-05 23:07:29,979 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4968042177232829, 'Total loss': 0.4968042177232829} | train loss {'Reaction outcome loss': 0.5254287107391395, 'Total loss': 0.5254287107391395}
2022-12-05 23:07:29,980 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:29,980 INFO:     Epoch: 16
2022-12-05 23:07:30,683 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5041365325450897, 'Total loss': 0.5041365325450897} | train loss {'Reaction outcome loss': 0.5201423939181725, 'Total loss': 0.5201423939181725}
2022-12-05 23:07:30,684 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:30,684 INFO:     Epoch: 17
2022-12-05 23:07:31,385 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5052786760709502, 'Total loss': 0.5052786760709502} | train loss {'Reaction outcome loss': 0.51683707711728, 'Total loss': 0.51683707711728}
2022-12-05 23:07:31,385 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:31,386 INFO:     Epoch: 18
2022-12-05 23:07:32,089 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5243304195729169, 'Total loss': 0.5243304195729169} | train loss {'Reaction outcome loss': 0.5204416285400931, 'Total loss': 0.5204416285400931}
2022-12-05 23:07:32,089 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:32,089 INFO:     Epoch: 19
2022-12-05 23:07:32,792 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5195311802354726, 'Total loss': 0.5195311802354726} | train loss {'Reaction outcome loss': 0.518273035712872, 'Total loss': 0.518273035712872}
2022-12-05 23:07:32,792 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:32,792 INFO:     Epoch: 20
2022-12-05 23:07:33,496 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5145376480438493, 'Total loss': 0.5145376480438493} | train loss {'Reaction outcome loss': 0.5146963849120777, 'Total loss': 0.5146963849120777}
2022-12-05 23:07:33,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:33,496 INFO:     Epoch: 21
2022-12-05 23:07:34,201 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5894565368917856, 'Total loss': 0.5894565368917856} | train loss {'Reaction outcome loss': 0.5147732209700805, 'Total loss': 0.5147732209700805}
2022-12-05 23:07:34,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:34,202 INFO:     Epoch: 22
2022-12-05 23:07:34,904 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5102823224257339, 'Total loss': 0.5102823224257339} | train loss {'Reaction outcome loss': 0.5141334716150036, 'Total loss': 0.5141334716150036}
2022-12-05 23:07:34,905 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:34,906 INFO:     Epoch: 23
2022-12-05 23:07:35,608 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5162790265272964, 'Total loss': 0.5162790265272964} | train loss {'Reaction outcome loss': 0.5082557298514524, 'Total loss': 0.5082557298514524}
2022-12-05 23:07:35,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:35,608 INFO:     Epoch: 24
2022-12-05 23:07:36,312 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5129548954692754, 'Total loss': 0.5129548954692754} | train loss {'Reaction outcome loss': 0.5214060393542896, 'Total loss': 0.5214060393542896}
2022-12-05 23:07:36,312 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:36,312 INFO:     Epoch: 25
2022-12-05 23:07:37,015 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.515427477657795, 'Total loss': 0.515427477657795} | train loss {'Reaction outcome loss': 0.5074103766758191, 'Total loss': 0.5074103766758191}
2022-12-05 23:07:37,015 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:37,015 INFO:     Epoch: 26
2022-12-05 23:07:37,722 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4974794743413275, 'Total loss': 0.4974794743413275} | train loss {'Reaction outcome loss': 0.5152085364347527, 'Total loss': 0.5152085364347527}
2022-12-05 23:07:37,722 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:37,722 INFO:     Epoch: 27
2022-12-05 23:07:38,429 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4886435361748392, 'Total loss': 0.4886435361748392} | train loss {'Reaction outcome loss': 0.5134717068118364, 'Total loss': 0.5134717068118364}
2022-12-05 23:07:38,429 INFO:     Found new best model at epoch 27
2022-12-05 23:07:38,429 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:38,429 INFO:     Epoch: 28
2022-12-05 23:07:39,136 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5159341601485555, 'Total loss': 0.5159341601485555} | train loss {'Reaction outcome loss': 0.5100185130289209, 'Total loss': 0.5100185130289209}
2022-12-05 23:07:39,136 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:39,136 INFO:     Epoch: 29
2022-12-05 23:07:39,839 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5082582289522345, 'Total loss': 0.5082582289522345} | train loss {'Reaction outcome loss': 0.5171625576762535, 'Total loss': 0.5171625576762535}
2022-12-05 23:07:39,839 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:39,839 INFO:     Epoch: 30
2022-12-05 23:07:40,544 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5326174658469178, 'Total loss': 0.5326174658469178} | train loss {'Reaction outcome loss': 0.5081642921033659, 'Total loss': 0.5081642921033659}
2022-12-05 23:07:40,544 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:40,544 INFO:     Epoch: 31
2022-12-05 23:07:41,246 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49670846218412573, 'Total loss': 0.49670846218412573} | train loss {'Reaction outcome loss': 0.5116541044190828, 'Total loss': 0.5116541044190828}
2022-12-05 23:07:41,247 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:41,247 INFO:     Epoch: 32
2022-12-05 23:07:41,953 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.509151220660318, 'Total loss': 0.509151220660318} | train loss {'Reaction outcome loss': 0.5110450638571249, 'Total loss': 0.5110450638571249}
2022-12-05 23:07:41,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:41,953 INFO:     Epoch: 33
2022-12-05 23:07:42,656 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5375650538639589, 'Total loss': 0.5375650538639589} | train loss {'Reaction outcome loss': 0.5141353074476304, 'Total loss': 0.5141353074476304}
2022-12-05 23:07:42,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:42,656 INFO:     Epoch: 34
2022-12-05 23:07:43,358 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5372373373671011, 'Total loss': 0.5372373373671011} | train loss {'Reaction outcome loss': 0.5055731916837847, 'Total loss': 0.5055731916837847}
2022-12-05 23:07:43,358 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:43,358 INFO:     Epoch: 35
2022-12-05 23:07:44,061 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5039126425981522, 'Total loss': 0.5039126425981522} | train loss {'Reaction outcome loss': 0.5158325523017389, 'Total loss': 0.5158325523017389}
2022-12-05 23:07:44,061 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:44,061 INFO:     Epoch: 36
2022-12-05 23:07:44,764 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5044587755745108, 'Total loss': 0.5044587755745108} | train loss {'Reaction outcome loss': 0.532691276025193, 'Total loss': 0.532691276025193}
2022-12-05 23:07:44,764 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:44,764 INFO:     Epoch: 37
2022-12-05 23:07:45,466 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.563279049640352, 'Total loss': 0.563279049640352} | train loss {'Reaction outcome loss': 0.5090904481377196, 'Total loss': 0.5090904481377196}
2022-12-05 23:07:45,466 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:45,467 INFO:     Epoch: 38
2022-12-05 23:07:46,173 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5035305070606145, 'Total loss': 0.5035305070606145} | train loss {'Reaction outcome loss': 0.517606011467424, 'Total loss': 0.517606011467424}
2022-12-05 23:07:46,173 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:46,173 INFO:     Epoch: 39
2022-12-05 23:07:46,875 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5244840322570368, 'Total loss': 0.5244840322570368} | train loss {'Reaction outcome loss': 0.5037305092642664, 'Total loss': 0.5037305092642664}
2022-12-05 23:07:46,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:46,876 INFO:     Epoch: 40
2022-12-05 23:07:47,578 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5230611017481848, 'Total loss': 0.5230611017481848} | train loss {'Reaction outcome loss': 0.49901960005885676, 'Total loss': 0.49901960005885676}
2022-12-05 23:07:47,579 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:47,579 INFO:     Epoch: 41
2022-12-05 23:07:48,280 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5138742171905257, 'Total loss': 0.5138742171905257} | train loss {'Reaction outcome loss': 0.5081677390978887, 'Total loss': 0.5081677390978887}
2022-12-05 23:07:48,281 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:48,281 INFO:     Epoch: 42
2022-12-05 23:07:48,983 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4980795904994011, 'Total loss': 0.4980795904994011} | train loss {'Reaction outcome loss': 0.5009886687583769, 'Total loss': 0.5009886687583769}
2022-12-05 23:07:48,983 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:48,983 INFO:     Epoch: 43
2022-12-05 23:07:49,686 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49598231505263934, 'Total loss': 0.49598231505263934} | train loss {'Reaction outcome loss': 0.5145896778777543, 'Total loss': 0.5145896778777543}
2022-12-05 23:07:49,686 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:49,686 INFO:     Epoch: 44
2022-12-05 23:07:50,392 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5290661251003091, 'Total loss': 0.5290661251003091} | train loss {'Reaction outcome loss': 0.5083610570201507, 'Total loss': 0.5083610570201507}
2022-12-05 23:07:50,393 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:50,393 INFO:     Epoch: 45
2022-12-05 23:07:51,098 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5172619044103406, 'Total loss': 0.5172619044103406} | train loss {'Reaction outcome loss': 0.5023253405625038, 'Total loss': 0.5023253405625038}
2022-12-05 23:07:51,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:51,099 INFO:     Epoch: 46
2022-12-05 23:07:51,802 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4796884703365239, 'Total loss': 0.4796884703365239} | train loss {'Reaction outcome loss': 0.5190244292320028, 'Total loss': 0.5190244292320028}
2022-12-05 23:07:51,802 INFO:     Found new best model at epoch 46
2022-12-05 23:07:51,802 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:51,803 INFO:     Epoch: 47
2022-12-05 23:07:52,506 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5035148310390386, 'Total loss': 0.5035148310390386} | train loss {'Reaction outcome loss': 0.5173068624216053, 'Total loss': 0.5173068624216053}
2022-12-05 23:07:52,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:52,506 INFO:     Epoch: 48
2022-12-05 23:07:53,216 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5061059302904389, 'Total loss': 0.5061059302904389} | train loss {'Reaction outcome loss': 0.49902523152138056, 'Total loss': 0.49902523152138056}
2022-12-05 23:07:53,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:53,217 INFO:     Epoch: 49
2022-12-05 23:07:53,925 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5164098800583319, 'Total loss': 0.5164098800583319} | train loss {'Reaction outcome loss': 0.5130233444303636, 'Total loss': 0.5130233444303636}
2022-12-05 23:07:53,926 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:53,926 INFO:     Epoch: 50
2022-12-05 23:07:54,630 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5198858871378682, 'Total loss': 0.5198858871378682} | train loss {'Reaction outcome loss': 0.5729584473407703, 'Total loss': 0.5729584473407703}
2022-12-05 23:07:54,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:54,630 INFO:     Epoch: 51
2022-12-05 23:07:55,333 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4990318471735174, 'Total loss': 0.4990318471735174} | train loss {'Reaction outcome loss': 0.515800838336077, 'Total loss': 0.515800838336077}
2022-12-05 23:07:55,333 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:55,334 INFO:     Epoch: 52
2022-12-05 23:07:56,037 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5277912779287859, 'Total loss': 0.5277912779287859} | train loss {'Reaction outcome loss': 0.5000439750762121, 'Total loss': 0.5000439750762121}
2022-12-05 23:07:56,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:56,037 INFO:     Epoch: 53
2022-12-05 23:07:56,740 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5171062824400988, 'Total loss': 0.5171062824400988} | train loss {'Reaction outcome loss': 0.5308361014856501, 'Total loss': 0.5308361014856501}
2022-12-05 23:07:56,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:56,741 INFO:     Epoch: 54
2022-12-05 23:07:57,444 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5191680365665392, 'Total loss': 0.5191680365665392} | train loss {'Reaction outcome loss': 0.5021645241541418, 'Total loss': 0.5021645241541418}
2022-12-05 23:07:57,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:57,444 INFO:     Epoch: 55
2022-12-05 23:07:58,148 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48831087486310437, 'Total loss': 0.48831087486310437} | train loss {'Reaction outcome loss': 0.5080731508127877, 'Total loss': 0.5080731508127877}
2022-12-05 23:07:58,148 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:58,148 INFO:     Epoch: 56
2022-12-05 23:07:58,855 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5438699451359835, 'Total loss': 0.5438699451359835} | train loss {'Reaction outcome loss': 0.49654683410397427, 'Total loss': 0.49654683410397427}
2022-12-05 23:07:58,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:58,855 INFO:     Epoch: 57
2022-12-05 23:07:59,561 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5010111135515299, 'Total loss': 0.5010111135515299} | train loss {'Reaction outcome loss': 0.516713652047159, 'Total loss': 0.516713652047159}
2022-12-05 23:07:59,562 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:07:59,562 INFO:     Epoch: 58
2022-12-05 23:08:00,266 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49509696002033626, 'Total loss': 0.49509696002033626} | train loss {'Reaction outcome loss': 0.5031966467332358, 'Total loss': 0.5031966467332358}
2022-12-05 23:08:00,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:00,266 INFO:     Epoch: 59
2022-12-05 23:08:00,969 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49784301492300903, 'Total loss': 0.49784301492300903} | train loss {'Reaction outcome loss': 0.4937818349011031, 'Total loss': 0.4937818349011031}
2022-12-05 23:08:00,969 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:00,969 INFO:     Epoch: 60
2022-12-05 23:08:01,675 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5519780574197118, 'Total loss': 0.5519780574197118} | train loss {'Reaction outcome loss': 0.4975637125628077, 'Total loss': 0.4975637125628077}
2022-12-05 23:08:01,675 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:01,675 INFO:     Epoch: 61
2022-12-05 23:08:02,380 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4904873526909135, 'Total loss': 0.4904873526909135} | train loss {'Reaction outcome loss': 0.512423644302345, 'Total loss': 0.512423644302345}
2022-12-05 23:08:02,380 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:02,380 INFO:     Epoch: 62
2022-12-05 23:08:03,084 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47221859476783057, 'Total loss': 0.47221859476783057} | train loss {'Reaction outcome loss': 0.4906443734408209, 'Total loss': 0.4906443734408209}
2022-12-05 23:08:03,085 INFO:     Found new best model at epoch 62
2022-12-05 23:08:03,085 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:03,085 INFO:     Epoch: 63
2022-12-05 23:08:03,788 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5342165096239611, 'Total loss': 0.5342165096239611} | train loss {'Reaction outcome loss': 0.494435419196542, 'Total loss': 0.494435419196542}
2022-12-05 23:08:03,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:03,788 INFO:     Epoch: 64
2022-12-05 23:08:04,491 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5149237967350266, 'Total loss': 0.5149237967350266} | train loss {'Reaction outcome loss': 0.5016117029133355, 'Total loss': 0.5016117029133355}
2022-12-05 23:08:04,491 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:04,491 INFO:     Epoch: 65
2022-12-05 23:08:05,195 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5440543703734875, 'Total loss': 0.5440543703734875} | train loss {'Reaction outcome loss': 0.5035533177466528, 'Total loss': 0.5035533177466528}
2022-12-05 23:08:05,195 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:05,195 INFO:     Epoch: 66
2022-12-05 23:08:05,897 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49264623123136436, 'Total loss': 0.49264623123136436} | train loss {'Reaction outcome loss': 0.5017886905655687, 'Total loss': 0.5017886905655687}
2022-12-05 23:08:05,899 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:05,899 INFO:     Epoch: 67
2022-12-05 23:08:06,605 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4805607944726944, 'Total loss': 0.4805607944726944} | train loss {'Reaction outcome loss': 0.5152872292652937, 'Total loss': 0.5152872292652937}
2022-12-05 23:08:06,605 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:06,605 INFO:     Epoch: 68
2022-12-05 23:08:07,309 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5052445906807076, 'Total loss': 0.5052445906807076} | train loss {'Reaction outcome loss': 0.498737921719609, 'Total loss': 0.498737921719609}
2022-12-05 23:08:07,309 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:07,310 INFO:     Epoch: 69
2022-12-05 23:08:08,013 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4902496649460359, 'Total loss': 0.4902496649460359} | train loss {'Reaction outcome loss': 0.49880181239759513, 'Total loss': 0.49880181239759513}
2022-12-05 23:08:08,013 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:08,013 INFO:     Epoch: 70
2022-12-05 23:08:08,716 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4930995526638898, 'Total loss': 0.4930995526638898} | train loss {'Reaction outcome loss': 0.49510922997827955, 'Total loss': 0.49510922997827955}
2022-12-05 23:08:08,716 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:08,716 INFO:     Epoch: 71
2022-12-05 23:08:09,418 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4937722025947137, 'Total loss': 0.4937722025947137} | train loss {'Reaction outcome loss': 0.5009475201971618, 'Total loss': 0.5009475201971618}
2022-12-05 23:08:09,418 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:09,418 INFO:     Epoch: 72
2022-12-05 23:08:10,121 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4963451993059028, 'Total loss': 0.4963451993059028} | train loss {'Reaction outcome loss': 0.5005362464071662, 'Total loss': 0.5005362464071662}
2022-12-05 23:08:10,122 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:10,122 INFO:     Epoch: 73
2022-12-05 23:08:10,825 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5718122544613752, 'Total loss': 0.5718122544613752} | train loss {'Reaction outcome loss': 0.5070908420119691, 'Total loss': 0.5070908420119691}
2022-12-05 23:08:10,825 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:10,825 INFO:     Epoch: 74
2022-12-05 23:08:11,530 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5365852483294227, 'Total loss': 0.5365852483294227} | train loss {'Reaction outcome loss': 0.5040929775971633, 'Total loss': 0.5040929775971633}
2022-12-05 23:08:11,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:11,531 INFO:     Epoch: 75
2022-12-05 23:08:12,233 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.491023371165449, 'Total loss': 0.491023371165449} | train loss {'Reaction outcome loss': 0.5072146146765605, 'Total loss': 0.5072146146765605}
2022-12-05 23:08:12,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:12,234 INFO:     Epoch: 76
2022-12-05 23:08:12,940 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5000730285590346, 'Total loss': 0.5000730285590346} | train loss {'Reaction outcome loss': 0.5086408729857279, 'Total loss': 0.5086408729857279}
2022-12-05 23:08:12,940 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:12,940 INFO:     Epoch: 77
2022-12-05 23:08:13,642 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4833700755103068, 'Total loss': 0.4833700755103068} | train loss {'Reaction outcome loss': 0.5083074880198779, 'Total loss': 0.5083074880198779}
2022-12-05 23:08:13,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:13,642 INFO:     Epoch: 78
2022-12-05 23:08:14,345 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5120993100784041, 'Total loss': 0.5120993100784041} | train loss {'Reaction outcome loss': 0.49316141950833775, 'Total loss': 0.49316141950833775}
2022-12-05 23:08:14,345 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:14,345 INFO:     Epoch: 79
2022-12-05 23:08:15,047 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5065032721243121, 'Total loss': 0.5065032721243121} | train loss {'Reaction outcome loss': 0.5054071341690264, 'Total loss': 0.5054071341690264}
2022-12-05 23:08:15,048 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:15,048 INFO:     Epoch: 80
2022-12-05 23:08:15,752 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5245933065360243, 'Total loss': 0.5245933065360243} | train loss {'Reaction outcome loss': 0.5099123624108188, 'Total loss': 0.5099123624108188}
2022-12-05 23:08:15,753 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:15,753 INFO:     Epoch: 81
2022-12-05 23:08:16,456 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4734365130690011, 'Total loss': 0.4734365130690011} | train loss {'Reaction outcome loss': 0.49812634307363257, 'Total loss': 0.49812634307363257}
2022-12-05 23:08:16,456 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:16,456 INFO:     Epoch: 82
2022-12-05 23:08:17,161 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5285282707349821, 'Total loss': 0.5285282707349821} | train loss {'Reaction outcome loss': 0.4998571370475688, 'Total loss': 0.4998571370475688}
2022-12-05 23:08:17,161 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:17,161 INFO:     Epoch: 83
2022-12-05 23:08:17,869 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5780293013561856, 'Total loss': 0.5780293013561856} | train loss {'Reaction outcome loss': 0.5009146224752612, 'Total loss': 0.5009146224752612}
2022-12-05 23:08:17,870 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:17,870 INFO:     Epoch: 84
2022-12-05 23:08:18,575 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5055774484168399, 'Total loss': 0.5055774484168399} | train loss {'Reaction outcome loss': 0.504129730195169, 'Total loss': 0.504129730195169}
2022-12-05 23:08:18,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:18,575 INFO:     Epoch: 85
2022-12-05 23:08:19,284 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5428050241687081, 'Total loss': 0.5428050241687081} | train loss {'Reaction outcome loss': 0.5109031101470052, 'Total loss': 0.5109031101470052}
2022-12-05 23:08:19,284 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:19,284 INFO:     Epoch: 86
2022-12-05 23:08:19,987 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5323716222562573, 'Total loss': 0.5323716222562573} | train loss {'Reaction outcome loss': 0.513037491423881, 'Total loss': 0.513037491423881}
2022-12-05 23:08:19,987 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:19,987 INFO:     Epoch: 87
2022-12-05 23:08:20,692 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.512984303588217, 'Total loss': 0.512984303588217} | train loss {'Reaction outcome loss': 0.5007520396458475, 'Total loss': 0.5007520396458475}
2022-12-05 23:08:20,693 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:20,693 INFO:     Epoch: 88
2022-12-05 23:08:21,397 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5340199660171162, 'Total loss': 0.5340199660171162} | train loss {'Reaction outcome loss': 0.5123644130915282, 'Total loss': 0.5123644130915282}
2022-12-05 23:08:21,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:21,397 INFO:     Epoch: 89
2022-12-05 23:08:22,099 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5380775813351978, 'Total loss': 0.5380775813351978} | train loss {'Reaction outcome loss': 0.5038008286659172, 'Total loss': 0.5038008286659172}
2022-12-05 23:08:22,100 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:22,100 INFO:     Epoch: 90
2022-12-05 23:08:22,803 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5027836764400656, 'Total loss': 0.5027836764400656} | train loss {'Reaction outcome loss': 0.5032923128154234, 'Total loss': 0.5032923128154234}
2022-12-05 23:08:22,803 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:22,803 INFO:     Epoch: 91
2022-12-05 23:08:23,509 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4848230037499558, 'Total loss': 0.4848230037499558} | train loss {'Reaction outcome loss': 0.4978308810999519, 'Total loss': 0.4978308810999519}
2022-12-05 23:08:23,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:23,509 INFO:     Epoch: 92
2022-12-05 23:08:24,212 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5099979750812054, 'Total loss': 0.5099979750812054} | train loss {'Reaction outcome loss': 0.5100616357225155, 'Total loss': 0.5100616357225155}
2022-12-05 23:08:24,212 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:24,212 INFO:     Epoch: 93
2022-12-05 23:08:24,914 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5677432898770679, 'Total loss': 0.5677432898770679} | train loss {'Reaction outcome loss': 0.4952325623195905, 'Total loss': 0.4952325623195905}
2022-12-05 23:08:24,915 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:24,915 INFO:     Epoch: 94
2022-12-05 23:08:25,618 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5161495537243106, 'Total loss': 0.5161495537243106} | train loss {'Reaction outcome loss': 0.5068785879414092, 'Total loss': 0.5068785879414092}
2022-12-05 23:08:25,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:25,618 INFO:     Epoch: 95
2022-12-05 23:08:26,320 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4933892779729583, 'Total loss': 0.4933892779729583} | train loss {'Reaction outcome loss': 0.5064651176393756, 'Total loss': 0.5064651176393756}
2022-12-05 23:08:26,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:26,320 INFO:     Epoch: 96
2022-12-05 23:08:27,027 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4755768007175489, 'Total loss': 0.4755768007175489} | train loss {'Reaction outcome loss': 0.5047267376499907, 'Total loss': 0.5047267376499907}
2022-12-05 23:08:27,027 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:27,027 INFO:     Epoch: 97
2022-12-05 23:08:27,730 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49140962518074294, 'Total loss': 0.49140962518074294} | train loss {'Reaction outcome loss': 0.4980583391812166, 'Total loss': 0.4980583391812166}
2022-12-05 23:08:27,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:27,731 INFO:     Epoch: 98
2022-12-05 23:08:28,434 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5996018702333624, 'Total loss': 0.5996018702333624} | train loss {'Reaction outcome loss': 0.5115097890257353, 'Total loss': 0.5115097890257353}
2022-12-05 23:08:28,434 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:28,434 INFO:     Epoch: 99
2022-12-05 23:08:29,136 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5075658986514265, 'Total loss': 0.5075658986514265} | train loss {'Reaction outcome loss': 0.524570193066288, 'Total loss': 0.524570193066288}
2022-12-05 23:08:29,136 INFO:     Best model found after epoch 63 of 100.
2022-12-05 23:08:29,136 INFO:   Done with stage: TRAINING
2022-12-05 23:08:29,137 INFO:   Starting stage: EVALUATION
2022-12-05 23:08:29,259 INFO:   Done with stage: EVALUATION
2022-12-05 23:08:29,260 INFO:   Leaving out SEQ value Fold_3
2022-12-05 23:08:29,272 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 23:08:29,272 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:08:29,903 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:08:29,904 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:08:29,975 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:08:29,975 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:08:29,975 INFO:     No hyperparam tuning for this model
2022-12-05 23:08:29,975 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:08:29,975 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:08:29,976 INFO:     None feature selector for col prot
2022-12-05 23:08:29,976 INFO:     None feature selector for col prot
2022-12-05 23:08:29,976 INFO:     None feature selector for col prot
2022-12-05 23:08:29,977 INFO:     None feature selector for col chem
2022-12-05 23:08:29,977 INFO:     None feature selector for col chem
2022-12-05 23:08:29,977 INFO:     None feature selector for col chem
2022-12-05 23:08:29,977 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:08:29,977 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:08:29,979 INFO:     Number of params in model 215731
2022-12-05 23:08:29,982 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:08:29,982 INFO:   Starting stage: TRAINING
2022-12-05 23:08:30,039 INFO:     Val loss before train {'Reaction outcome loss': 1.023589132830154, 'Total loss': 1.023589132830154}
2022-12-05 23:08:30,040 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:30,040 INFO:     Epoch: 0
2022-12-05 23:08:30,741 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7333024026349534, 'Total loss': 0.7333024026349534} | train loss {'Reaction outcome loss': 0.8052245998968843, 'Total loss': 0.8052245998968843}
2022-12-05 23:08:30,741 INFO:     Found new best model at epoch 0
2022-12-05 23:08:30,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:30,742 INFO:     Epoch: 1
2022-12-05 23:08:31,434 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6211381748665211, 'Total loss': 0.6211381748665211} | train loss {'Reaction outcome loss': 0.6746345896457062, 'Total loss': 0.6746345896457062}
2022-12-05 23:08:31,434 INFO:     Found new best model at epoch 1
2022-12-05 23:08:31,435 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:31,435 INFO:     Epoch: 2
2022-12-05 23:08:32,128 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6180126847222794, 'Total loss': 0.6180126847222794} | train loss {'Reaction outcome loss': 0.6168162837380269, 'Total loss': 0.6168162837380269}
2022-12-05 23:08:32,128 INFO:     Found new best model at epoch 2
2022-12-05 23:08:32,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:32,129 INFO:     Epoch: 3
2022-12-05 23:08:32,823 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5962353993293851, 'Total loss': 0.5962353993293851} | train loss {'Reaction outcome loss': 0.601679544101973, 'Total loss': 0.601679544101973}
2022-12-05 23:08:32,823 INFO:     Found new best model at epoch 3
2022-12-05 23:08:32,823 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:32,824 INFO:     Epoch: 4
2022-12-05 23:08:33,519 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5580341334259787, 'Total loss': 0.5580341334259787} | train loss {'Reaction outcome loss': 0.5916918128973148, 'Total loss': 0.5916918128973148}
2022-12-05 23:08:33,519 INFO:     Found new best model at epoch 4
2022-12-05 23:08:33,520 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:33,520 INFO:     Epoch: 5
2022-12-05 23:08:34,217 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5522836110619611, 'Total loss': 0.5522836110619611} | train loss {'Reaction outcome loss': 0.5822200933318646, 'Total loss': 0.5822200933318646}
2022-12-05 23:08:34,217 INFO:     Found new best model at epoch 5
2022-12-05 23:08:34,218 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:34,218 INFO:     Epoch: 6
2022-12-05 23:08:34,912 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6056476789851521, 'Total loss': 0.6056476789851521} | train loss {'Reaction outcome loss': 0.57451003472336, 'Total loss': 0.57451003472336}
2022-12-05 23:08:34,912 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:34,912 INFO:     Epoch: 7
2022-12-05 23:08:35,606 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5827431041140889, 'Total loss': 0.5827431041140889} | train loss {'Reaction outcome loss': 0.5674397171032234, 'Total loss': 0.5674397171032234}
2022-12-05 23:08:35,606 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:35,606 INFO:     Epoch: 8
2022-12-05 23:08:36,302 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5975198378396589, 'Total loss': 0.5975198378396589} | train loss {'Reaction outcome loss': 0.5786423192161029, 'Total loss': 0.5786423192161029}
2022-12-05 23:08:36,303 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:36,303 INFO:     Epoch: 9
2022-12-05 23:08:36,997 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5623795501021451, 'Total loss': 0.5623795501021451} | train loss {'Reaction outcome loss': 0.5596372770969985, 'Total loss': 0.5596372770969985}
2022-12-05 23:08:36,997 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:36,997 INFO:     Epoch: 10
2022-12-05 23:08:37,691 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5474696055401204, 'Total loss': 0.5474696055401204} | train loss {'Reaction outcome loss': 0.5619559886514164, 'Total loss': 0.5619559886514164}
2022-12-05 23:08:37,691 INFO:     Found new best model at epoch 10
2022-12-05 23:08:37,691 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:37,692 INFO:     Epoch: 11
2022-12-05 23:08:38,388 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5518082314452459, 'Total loss': 0.5518082314452459} | train loss {'Reaction outcome loss': 0.5545198928381576, 'Total loss': 0.5545198928381576}
2022-12-05 23:08:38,388 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:38,388 INFO:     Epoch: 12
2022-12-05 23:08:39,086 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5449981370637583, 'Total loss': 0.5449981370637583} | train loss {'Reaction outcome loss': 0.5481119830710967, 'Total loss': 0.5481119830710967}
2022-12-05 23:08:39,086 INFO:     Found new best model at epoch 12
2022-12-05 23:08:39,086 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:39,086 INFO:     Epoch: 13
2022-12-05 23:08:39,781 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5772609828516494, 'Total loss': 0.5772609828516494} | train loss {'Reaction outcome loss': 0.5525768668558754, 'Total loss': 0.5525768668558754}
2022-12-05 23:08:39,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:39,781 INFO:     Epoch: 14
2022-12-05 23:08:40,476 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5207266197648159, 'Total loss': 0.5207266197648159} | train loss {'Reaction outcome loss': 0.5484517482338381, 'Total loss': 0.5484517482338381}
2022-12-05 23:08:40,476 INFO:     Found new best model at epoch 14
2022-12-05 23:08:40,477 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:40,477 INFO:     Epoch: 15
2022-12-05 23:08:41,170 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5402884621952855, 'Total loss': 0.5402884621952855} | train loss {'Reaction outcome loss': 0.5419963667871522, 'Total loss': 0.5419963667871522}
2022-12-05 23:08:41,170 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:41,171 INFO:     Epoch: 16
2022-12-05 23:08:41,863 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5288472868675409, 'Total loss': 0.5288472868675409} | train loss {'Reaction outcome loss': 0.5371132893640487, 'Total loss': 0.5371132893640487}
2022-12-05 23:08:41,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:41,864 INFO:     Epoch: 17
2022-12-05 23:08:42,562 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5182551994573238, 'Total loss': 0.5182551994573238} | train loss {'Reaction outcome loss': 0.5474296632970943, 'Total loss': 0.5474296632970943}
2022-12-05 23:08:42,563 INFO:     Found new best model at epoch 17
2022-12-05 23:08:42,564 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:42,564 INFO:     Epoch: 18
2022-12-05 23:08:43,264 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5126902869967527, 'Total loss': 0.5126902869967527} | train loss {'Reaction outcome loss': 0.5333048124171671, 'Total loss': 0.5333048124171671}
2022-12-05 23:08:43,264 INFO:     Found new best model at epoch 18
2022-12-05 23:08:43,265 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:43,265 INFO:     Epoch: 19
2022-12-05 23:08:43,960 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5235377477352009, 'Total loss': 0.5235377477352009} | train loss {'Reaction outcome loss': 0.5339870367993097, 'Total loss': 0.5339870367993097}
2022-12-05 23:08:43,960 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:43,960 INFO:     Epoch: 20
2022-12-05 23:08:44,655 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5620298988597338, 'Total loss': 0.5620298988597338} | train loss {'Reaction outcome loss': 0.5308806303827489, 'Total loss': 0.5308806303827489}
2022-12-05 23:08:44,655 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:44,655 INFO:     Epoch: 21
2022-12-05 23:08:45,352 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.529059753168461, 'Total loss': 0.529059753168461} | train loss {'Reaction outcome loss': 0.5361306559233392, 'Total loss': 0.5361306559233392}
2022-12-05 23:08:45,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:45,352 INFO:     Epoch: 22
2022-12-05 23:08:46,053 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5006634502909905, 'Total loss': 0.5006634502909905} | train loss {'Reaction outcome loss': 0.5327624061801395, 'Total loss': 0.5327624061801395}
2022-12-05 23:08:46,053 INFO:     Found new best model at epoch 22
2022-12-05 23:08:46,054 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:46,054 INFO:     Epoch: 23
2022-12-05 23:08:46,750 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5362481315468632, 'Total loss': 0.5362481315468632} | train loss {'Reaction outcome loss': 0.5332767935317071, 'Total loss': 0.5332767935317071}
2022-12-05 23:08:46,750 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:46,750 INFO:     Epoch: 24
2022-12-05 23:08:47,444 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5312618613243103, 'Total loss': 0.5312618613243103} | train loss {'Reaction outcome loss': 0.522704863768132, 'Total loss': 0.522704863768132}
2022-12-05 23:08:47,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:47,444 INFO:     Epoch: 25
2022-12-05 23:08:48,141 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5168261673561362, 'Total loss': 0.5168261673561362} | train loss {'Reaction outcome loss': 0.5323742422901216, 'Total loss': 0.5323742422901216}
2022-12-05 23:08:48,141 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:48,141 INFO:     Epoch: 26
2022-12-05 23:08:48,836 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5298141518304514, 'Total loss': 0.5298141518304514} | train loss {'Reaction outcome loss': 0.5208398286924988, 'Total loss': 0.5208398286924988}
2022-12-05 23:08:48,836 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:48,837 INFO:     Epoch: 27
2022-12-05 23:08:49,534 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5256420782832212, 'Total loss': 0.5256420782832212} | train loss {'Reaction outcome loss': 0.5318475531750038, 'Total loss': 0.5318475531750038}
2022-12-05 23:08:49,534 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:49,534 INFO:     Epoch: 28
2022-12-05 23:08:50,235 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5319649199413699, 'Total loss': 0.5319649199413699} | train loss {'Reaction outcome loss': 0.5289823781760012, 'Total loss': 0.5289823781760012}
2022-12-05 23:08:50,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:50,235 INFO:     Epoch: 29
2022-12-05 23:08:50,937 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5032572853703832, 'Total loss': 0.5032572853703832} | train loss {'Reaction outcome loss': 0.5224027713669128, 'Total loss': 0.5224027713669128}
2022-12-05 23:08:50,937 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:50,937 INFO:     Epoch: 30
2022-12-05 23:08:51,647 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.48764257306276365, 'Total loss': 0.48764257306276365} | train loss {'Reaction outcome loss': 0.5216058516477953, 'Total loss': 0.5216058516477953}
2022-12-05 23:08:51,647 INFO:     Found new best model at epoch 30
2022-12-05 23:08:51,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:51,648 INFO:     Epoch: 31
2022-12-05 23:08:52,359 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4974915641684865, 'Total loss': 0.4974915641684865} | train loss {'Reaction outcome loss': 0.5108098941015415, 'Total loss': 0.5108098941015415}
2022-12-05 23:08:52,359 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:52,359 INFO:     Epoch: 32
2022-12-05 23:08:53,063 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5018220970103907, 'Total loss': 0.5018220970103907} | train loss {'Reaction outcome loss': 0.5259641344185735, 'Total loss': 0.5259641344185735}
2022-12-05 23:08:53,063 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:53,063 INFO:     Epoch: 33
2022-12-05 23:08:53,767 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5012444333974705, 'Total loss': 0.5012444333974705} | train loss {'Reaction outcome loss': 0.5176465269483503, 'Total loss': 0.5176465269483503}
2022-12-05 23:08:53,767 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:53,767 INFO:     Epoch: 34
2022-12-05 23:08:54,474 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.50324315941611, 'Total loss': 0.50324315941611} | train loss {'Reaction outcome loss': 0.5231777231102107, 'Total loss': 0.5231777231102107}
2022-12-05 23:08:54,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:54,475 INFO:     Epoch: 35
2022-12-05 23:08:55,181 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5060316452453303, 'Total loss': 0.5060316452453303} | train loss {'Reaction outcome loss': 0.5129077376522979, 'Total loss': 0.5129077376522979}
2022-12-05 23:08:55,182 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:55,182 INFO:     Epoch: 36
2022-12-05 23:08:55,886 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4948732139066208, 'Total loss': 0.4948732139066208} | train loss {'Reaction outcome loss': 0.5016908067904535, 'Total loss': 0.5016908067904535}
2022-12-05 23:08:55,886 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:55,886 INFO:     Epoch: 37
2022-12-05 23:08:56,593 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5039571967235831, 'Total loss': 0.5039571967235831} | train loss {'Reaction outcome loss': 0.512869158729178, 'Total loss': 0.512869158729178}
2022-12-05 23:08:56,593 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:56,593 INFO:     Epoch: 38
2022-12-05 23:08:57,297 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5041698917400005, 'Total loss': 0.5041698917400005} | train loss {'Reaction outcome loss': 0.5054127107389638, 'Total loss': 0.5054127107389638}
2022-12-05 23:08:57,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:57,297 INFO:     Epoch: 39
2022-12-05 23:08:58,002 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5140462670215341, 'Total loss': 0.5140462670215341} | train loss {'Reaction outcome loss': 0.5123929728250034, 'Total loss': 0.5123929728250034}
2022-12-05 23:08:58,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:58,002 INFO:     Epoch: 40
2022-12-05 23:08:58,709 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5154693299947783, 'Total loss': 0.5154693299947783} | train loss {'Reaction outcome loss': 0.5095648114554218, 'Total loss': 0.5095648114554218}
2022-12-05 23:08:58,709 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:58,709 INFO:     Epoch: 41
2022-12-05 23:08:59,419 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4956916536009589, 'Total loss': 0.4956916536009589} | train loss {'Reaction outcome loss': 0.5083433765856946, 'Total loss': 0.5083433765856946}
2022-12-05 23:08:59,419 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:08:59,419 INFO:     Epoch: 42
2022-12-05 23:09:00,126 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49507068166899126, 'Total loss': 0.49507068166899126} | train loss {'Reaction outcome loss': 0.5102491091753616, 'Total loss': 0.5102491091753616}
2022-12-05 23:09:00,126 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:00,126 INFO:     Epoch: 43
2022-12-05 23:09:00,832 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.49593488941358965, 'Total loss': 0.49593488941358965} | train loss {'Reaction outcome loss': 0.5114228029842259, 'Total loss': 0.5114228029842259}
2022-12-05 23:09:00,832 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:00,832 INFO:     Epoch: 44
2022-12-05 23:09:01,543 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5223270654678345, 'Total loss': 0.5223270654678345} | train loss {'Reaction outcome loss': 0.5058011137193343, 'Total loss': 0.5058011137193343}
2022-12-05 23:09:01,543 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:01,543 INFO:     Epoch: 45
2022-12-05 23:09:02,254 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5062813343003739, 'Total loss': 0.5062813343003739} | train loss {'Reaction outcome loss': 0.5097142273529631, 'Total loss': 0.5097142273529631}
2022-12-05 23:09:02,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:02,254 INFO:     Epoch: 46
2022-12-05 23:09:02,961 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5280438793259997, 'Total loss': 0.5280438793259997} | train loss {'Reaction outcome loss': 0.5199974645845226, 'Total loss': 0.5199974645845226}
2022-12-05 23:09:02,961 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:02,961 INFO:     Epoch: 47
2022-12-05 23:09:03,665 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5077938291915628, 'Total loss': 0.5077938291915628} | train loss {'Reaction outcome loss': 0.5071647827376108, 'Total loss': 0.5071647827376108}
2022-12-05 23:09:03,666 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:03,666 INFO:     Epoch: 48
2022-12-05 23:09:04,372 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4925442892451619, 'Total loss': 0.4925442892451619} | train loss {'Reaction outcome loss': 0.5079678599340994, 'Total loss': 0.5079678599340994}
2022-12-05 23:09:04,372 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:04,373 INFO:     Epoch: 49
2022-12-05 23:09:05,077 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.603323278732078, 'Total loss': 0.603323278732078} | train loss {'Reaction outcome loss': 0.5064545243245656, 'Total loss': 0.5064545243245656}
2022-12-05 23:09:05,077 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:05,077 INFO:     Epoch: 50
2022-12-05 23:09:05,781 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5440295491107675, 'Total loss': 0.5440295491107675} | train loss {'Reaction outcome loss': 0.5114797654821247, 'Total loss': 0.5114797654821247}
2022-12-05 23:09:05,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:05,781 INFO:     Epoch: 51
2022-12-05 23:09:06,488 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49990442360556403, 'Total loss': 0.49990442360556403} | train loss {'Reaction outcome loss': 0.5033006231437941, 'Total loss': 0.5033006231437941}
2022-12-05 23:09:06,488 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:06,488 INFO:     Epoch: 52
2022-12-05 23:09:07,192 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48107315149418145, 'Total loss': 0.48107315149418145} | train loss {'Reaction outcome loss': 0.5097039700409428, 'Total loss': 0.5097039700409428}
2022-12-05 23:09:07,193 INFO:     Found new best model at epoch 52
2022-12-05 23:09:07,194 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:07,194 INFO:     Epoch: 53
2022-12-05 23:09:07,899 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.49591551028018777, 'Total loss': 0.49591551028018777} | train loss {'Reaction outcome loss': 0.5041599657814033, 'Total loss': 0.5041599657814033}
2022-12-05 23:09:07,899 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:07,899 INFO:     Epoch: 54
2022-12-05 23:09:08,603 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5277688073557477, 'Total loss': 0.5277688073557477} | train loss {'Reaction outcome loss': 0.5021503342956793, 'Total loss': 0.5021503342956793}
2022-12-05 23:09:08,603 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:08,603 INFO:     Epoch: 55
2022-12-05 23:09:09,311 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5014695712300234, 'Total loss': 0.5014695712300234} | train loss {'Reaction outcome loss': 0.5123829012889354, 'Total loss': 0.5123829012889354}
2022-12-05 23:09:09,311 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:09,312 INFO:     Epoch: 56
2022-12-05 23:09:10,016 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49848477057246277, 'Total loss': 0.49848477057246277} | train loss {'Reaction outcome loss': 0.5035283430555805, 'Total loss': 0.5035283430555805}
2022-12-05 23:09:10,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:10,017 INFO:     Epoch: 57
2022-12-05 23:09:10,725 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5244635797517244, 'Total loss': 0.5244635797517244} | train loss {'Reaction outcome loss': 0.5069957543469843, 'Total loss': 0.5069957543469843}
2022-12-05 23:09:10,725 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:10,725 INFO:     Epoch: 58
2022-12-05 23:09:11,427 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.532932952392933, 'Total loss': 0.532932952392933} | train loss {'Reaction outcome loss': 0.5073785125354274, 'Total loss': 0.5073785125354274}
2022-12-05 23:09:11,427 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:11,427 INFO:     Epoch: 59
2022-12-05 23:09:12,129 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47789577342743095, 'Total loss': 0.47789577342743095} | train loss {'Reaction outcome loss': 0.5074872839279839, 'Total loss': 0.5074872839279839}
2022-12-05 23:09:12,129 INFO:     Found new best model at epoch 59
2022-12-05 23:09:12,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:12,130 INFO:     Epoch: 60
2022-12-05 23:09:12,830 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5062244856773421, 'Total loss': 0.5062244856773421} | train loss {'Reaction outcome loss': 0.5075376096685402, 'Total loss': 0.5075376096685402}
2022-12-05 23:09:12,830 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:12,830 INFO:     Epoch: 61
2022-12-05 23:09:13,531 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.54414150326751, 'Total loss': 0.54414150326751} | train loss {'Reaction outcome loss': 0.5142351152589086, 'Total loss': 0.5142351152589086}
2022-12-05 23:09:13,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:13,532 INFO:     Epoch: 62
2022-12-05 23:09:14,238 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49180905416954396, 'Total loss': 0.49180905416954396} | train loss {'Reaction outcome loss': 0.5071347450501607, 'Total loss': 0.5071347450501607}
2022-12-05 23:09:14,239 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:14,239 INFO:     Epoch: 63
2022-12-05 23:09:14,940 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5186201174591862, 'Total loss': 0.5186201174591862} | train loss {'Reaction outcome loss': 0.4993251753879375, 'Total loss': 0.4993251753879375}
2022-12-05 23:09:14,940 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:14,940 INFO:     Epoch: 64
2022-12-05 23:09:15,648 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5005611822355626, 'Total loss': 0.5005611822355626} | train loss {'Reaction outcome loss': 0.5119887371776534, 'Total loss': 0.5119887371776534}
2022-12-05 23:09:15,648 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:15,648 INFO:     Epoch: 65
2022-12-05 23:09:16,349 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.49253989340260973, 'Total loss': 0.49253989340260973} | train loss {'Reaction outcome loss': 0.5125847874117679, 'Total loss': 0.5125847874117679}
2022-12-05 23:09:16,349 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:16,349 INFO:     Epoch: 66
2022-12-05 23:09:17,056 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5230511617521907, 'Total loss': 0.5230511617521907} | train loss {'Reaction outcome loss': 0.5115199573948735, 'Total loss': 0.5115199573948735}
2022-12-05 23:09:17,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:17,056 INFO:     Epoch: 67
2022-12-05 23:09:17,763 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49623992727246397, 'Total loss': 0.49623992727246397} | train loss {'Reaction outcome loss': 0.5124623908615503, 'Total loss': 0.5124623908615503}
2022-12-05 23:09:17,763 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:17,763 INFO:     Epoch: 68
2022-12-05 23:09:18,465 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5210729560186697, 'Total loss': 0.5210729560186697} | train loss {'Reaction outcome loss': 0.49747835582152744, 'Total loss': 0.49747835582152744}
2022-12-05 23:09:18,466 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:18,466 INFO:     Epoch: 69
2022-12-05 23:09:19,171 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5113951536112054, 'Total loss': 0.5113951536112054} | train loss {'Reaction outcome loss': 0.5058534437882118, 'Total loss': 0.5058534437882118}
2022-12-05 23:09:19,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:19,171 INFO:     Epoch: 70
2022-12-05 23:09:19,874 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4933968567570975, 'Total loss': 0.4933968567570975} | train loss {'Reaction outcome loss': 0.5037880950897443, 'Total loss': 0.5037880950897443}
2022-12-05 23:09:19,874 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:19,874 INFO:     Epoch: 71
2022-12-05 23:09:20,577 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5357891965744107, 'Total loss': 0.5357891965744107} | train loss {'Reaction outcome loss': 0.5091993882030738, 'Total loss': 0.5091993882030738}
2022-12-05 23:09:20,577 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:20,578 INFO:     Epoch: 72
2022-12-05 23:09:21,282 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.502049848783848, 'Total loss': 0.502049848783848} | train loss {'Reaction outcome loss': 0.5006646079118134, 'Total loss': 0.5006646079118134}
2022-12-05 23:09:21,282 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:21,282 INFO:     Epoch: 73
2022-12-05 23:09:21,983 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5591953968585923, 'Total loss': 0.5591953968585923} | train loss {'Reaction outcome loss': 0.5070903658500461, 'Total loss': 0.5070903658500461}
2022-12-05 23:09:21,983 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:21,983 INFO:     Epoch: 74
2022-12-05 23:09:22,684 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5238752871058708, 'Total loss': 0.5238752871058708} | train loss {'Reaction outcome loss': 0.5074150087769891, 'Total loss': 0.5074150087769891}
2022-12-05 23:09:22,685 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:22,685 INFO:     Epoch: 75
2022-12-05 23:09:23,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4833191757978395, 'Total loss': 0.4833191757978395} | train loss {'Reaction outcome loss': 0.5071695489106608, 'Total loss': 0.5071695489106608}
2022-12-05 23:09:23,385 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:23,385 INFO:     Epoch: 76
2022-12-05 23:09:24,082 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5265882386024608, 'Total loss': 0.5265882386024608} | train loss {'Reaction outcome loss': 0.5080385819443913, 'Total loss': 0.5080385819443913}
2022-12-05 23:09:24,083 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:24,083 INFO:     Epoch: 77
2022-12-05 23:09:24,780 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5391445367835289, 'Total loss': 0.5391445367835289} | train loss {'Reaction outcome loss': 0.5035688925961979, 'Total loss': 0.5035688925961979}
2022-12-05 23:09:24,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:24,780 INFO:     Epoch: 78
2022-12-05 23:09:25,483 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5134799934403841, 'Total loss': 0.5134799934403841} | train loss {'Reaction outcome loss': 0.507930438599137, 'Total loss': 0.507930438599137}
2022-12-05 23:09:25,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:25,483 INFO:     Epoch: 79
2022-12-05 23:09:26,187 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5278692488060441, 'Total loss': 0.5278692488060441} | train loss {'Reaction outcome loss': 0.5125745293669036, 'Total loss': 0.5125745293669036}
2022-12-05 23:09:26,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:26,188 INFO:     Epoch: 80
2022-12-05 23:09:26,893 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.47081070116092993, 'Total loss': 0.47081070116092993} | train loss {'Reaction outcome loss': 0.5089219740179719, 'Total loss': 0.5089219740179719}
2022-12-05 23:09:26,893 INFO:     Found new best model at epoch 80
2022-12-05 23:09:26,893 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:26,893 INFO:     Epoch: 81
2022-12-05 23:09:27,593 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49287188538285187, 'Total loss': 0.49287188538285187} | train loss {'Reaction outcome loss': 0.5035559599761104, 'Total loss': 0.5035559599761104}
2022-12-05 23:09:27,593 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:27,594 INFO:     Epoch: 82
2022-12-05 23:09:28,295 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5648064440072968, 'Total loss': 0.5648064440072968} | train loss {'Reaction outcome loss': 0.5009780122486295, 'Total loss': 0.5009780122486295}
2022-12-05 23:09:28,295 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:28,295 INFO:     Epoch: 83
2022-12-05 23:09:28,994 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5144141482752423, 'Total loss': 0.5144141482752423} | train loss {'Reaction outcome loss': 0.5093524851759926, 'Total loss': 0.5093524851759926}
2022-12-05 23:09:28,995 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:28,995 INFO:     Epoch: 84
2022-12-05 23:09:29,696 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4943050658980081, 'Total loss': 0.4943050658980081} | train loss {'Reaction outcome loss': 0.503998227051047, 'Total loss': 0.503998227051047}
2022-12-05 23:09:29,696 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:29,696 INFO:     Epoch: 85
2022-12-05 23:09:30,397 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.49016217922055444, 'Total loss': 0.49016217922055444} | train loss {'Reaction outcome loss': 0.507941017385389, 'Total loss': 0.507941017385389}
2022-12-05 23:09:30,398 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:30,398 INFO:     Epoch: 86
2022-12-05 23:09:31,095 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4883729021909625, 'Total loss': 0.4883729021909625} | train loss {'Reaction outcome loss': 0.503554403629215, 'Total loss': 0.503554403629215}
2022-12-05 23:09:31,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:31,095 INFO:     Epoch: 87
2022-12-05 23:09:31,793 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4866949357958727, 'Total loss': 0.4866949357958727} | train loss {'Reaction outcome loss': 0.5111372708419307, 'Total loss': 0.5111372708419307}
2022-12-05 23:09:31,793 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:31,793 INFO:     Epoch: 88
2022-12-05 23:09:32,491 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48055264457713726, 'Total loss': 0.48055264457713726} | train loss {'Reaction outcome loss': 0.504945521777282, 'Total loss': 0.504945521777282}
2022-12-05 23:09:32,491 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:32,491 INFO:     Epoch: 89
2022-12-05 23:09:33,195 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5282994626566421, 'Total loss': 0.5282994626566421} | train loss {'Reaction outcome loss': 0.4938886938158606, 'Total loss': 0.4938886938158606}
2022-12-05 23:09:33,195 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:33,195 INFO:     Epoch: 90
2022-12-05 23:09:33,893 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5206476720266564, 'Total loss': 0.5206476720266564} | train loss {'Reaction outcome loss': 0.5142564570195363, 'Total loss': 0.5142564570195363}
2022-12-05 23:09:33,893 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:33,893 INFO:     Epoch: 91
2022-12-05 23:09:34,592 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.48214545326177466, 'Total loss': 0.48214545326177466} | train loss {'Reaction outcome loss': 0.509342799482287, 'Total loss': 0.509342799482287}
2022-12-05 23:09:34,592 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:34,592 INFO:     Epoch: 92
2022-12-05 23:09:35,290 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.48392469453257186, 'Total loss': 0.48392469453257186} | train loss {'Reaction outcome loss': 0.5002949041177015, 'Total loss': 0.5002949041177015}
2022-12-05 23:09:35,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:35,290 INFO:     Epoch: 93
2022-12-05 23:09:35,988 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5134754468535268, 'Total loss': 0.5134754468535268} | train loss {'Reaction outcome loss': 0.506915307985466, 'Total loss': 0.506915307985466}
2022-12-05 23:09:35,988 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:35,988 INFO:     Epoch: 94
2022-12-05 23:09:36,686 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49274507476839907, 'Total loss': 0.49274507476839907} | train loss {'Reaction outcome loss': 0.4995173333121128, 'Total loss': 0.4995173333121128}
2022-12-05 23:09:36,686 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:36,686 INFO:     Epoch: 95
2022-12-05 23:09:37,385 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4968439098014388, 'Total loss': 0.4968439098014388} | train loss {'Reaction outcome loss': 0.5029606234709747, 'Total loss': 0.5029606234709747}
2022-12-05 23:09:37,385 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:37,385 INFO:     Epoch: 96
2022-12-05 23:09:38,085 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.506022087016771, 'Total loss': 0.506022087016771} | train loss {'Reaction outcome loss': 0.505984115063167, 'Total loss': 0.505984115063167}
2022-12-05 23:09:38,085 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:38,086 INFO:     Epoch: 97
2022-12-05 23:09:38,785 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5304122749109601, 'Total loss': 0.5304122749109601} | train loss {'Reaction outcome loss': 0.5029067520479686, 'Total loss': 0.5029067520479686}
2022-12-05 23:09:38,786 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:38,786 INFO:     Epoch: 98
2022-12-05 23:09:39,493 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.507401434141536, 'Total loss': 0.507401434141536} | train loss {'Reaction outcome loss': 0.5104268599362647, 'Total loss': 0.5104268599362647}
2022-12-05 23:09:39,493 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:39,493 INFO:     Epoch: 99
2022-12-05 23:09:40,196 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5162688694721045, 'Total loss': 0.5162688694721045} | train loss {'Reaction outcome loss': 0.4986887302432881, 'Total loss': 0.4986887302432881}
2022-12-05 23:09:40,196 INFO:     Best model found after epoch 81 of 100.
2022-12-05 23:09:40,196 INFO:   Done with stage: TRAINING
2022-12-05 23:09:40,196 INFO:   Starting stage: EVALUATION
2022-12-05 23:09:40,332 INFO:   Done with stage: EVALUATION
2022-12-05 23:09:40,332 INFO:   Leaving out SEQ value Fold_4
2022-12-05 23:09:40,345 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:09:40,345 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:09:40,981 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:09:40,981 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:09:41,052 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:09:41,052 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:09:41,052 INFO:     No hyperparam tuning for this model
2022-12-05 23:09:41,052 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:09:41,052 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:09:41,053 INFO:     None feature selector for col prot
2022-12-05 23:09:41,053 INFO:     None feature selector for col prot
2022-12-05 23:09:41,053 INFO:     None feature selector for col prot
2022-12-05 23:09:41,054 INFO:     None feature selector for col chem
2022-12-05 23:09:41,054 INFO:     None feature selector for col chem
2022-12-05 23:09:41,054 INFO:     None feature selector for col chem
2022-12-05 23:09:41,054 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:09:41,054 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:09:41,056 INFO:     Number of params in model 215731
2022-12-05 23:09:41,059 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:09:41,059 INFO:   Starting stage: TRAINING
2022-12-05 23:09:41,117 INFO:     Val loss before train {'Reaction outcome loss': 1.0002946230498226, 'Total loss': 1.0002946230498226}
2022-12-05 23:09:41,117 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:41,117 INFO:     Epoch: 0
2022-12-05 23:09:41,825 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6779776608402078, 'Total loss': 0.6779776608402078} | train loss {'Reaction outcome loss': 0.8219405317739132, 'Total loss': 0.8219405317739132}
2022-12-05 23:09:41,826 INFO:     Found new best model at epoch 0
2022-12-05 23:09:41,826 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:41,826 INFO:     Epoch: 1
2022-12-05 23:09:42,535 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6017113920639862, 'Total loss': 0.6017113920639862} | train loss {'Reaction outcome loss': 0.6810418274854461, 'Total loss': 0.6810418274854461}
2022-12-05 23:09:42,535 INFO:     Found new best model at epoch 1
2022-12-05 23:09:42,535 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:42,535 INFO:     Epoch: 2
2022-12-05 23:09:43,249 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6042380854487419, 'Total loss': 0.6042380854487419} | train loss {'Reaction outcome loss': 0.6349788877752519, 'Total loss': 0.6349788877752519}
2022-12-05 23:09:43,249 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:43,249 INFO:     Epoch: 3
2022-12-05 23:09:43,964 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5609764090993188, 'Total loss': 0.5609764090993188} | train loss {'Reaction outcome loss': 0.6105132842015836, 'Total loss': 0.6105132842015836}
2022-12-05 23:09:43,964 INFO:     Found new best model at epoch 3
2022-12-05 23:09:43,964 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:43,965 INFO:     Epoch: 4
2022-12-05 23:09:44,676 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5514035489071499, 'Total loss': 0.5514035489071499} | train loss {'Reaction outcome loss': 0.5969939021573912, 'Total loss': 0.5969939021573912}
2022-12-05 23:09:44,676 INFO:     Found new best model at epoch 4
2022-12-05 23:09:44,676 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:44,676 INFO:     Epoch: 5
2022-12-05 23:09:45,392 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5853950564156879, 'Total loss': 0.5853950564156879} | train loss {'Reaction outcome loss': 0.5964443248005644, 'Total loss': 0.5964443248005644}
2022-12-05 23:09:45,392 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:45,393 INFO:     Epoch: 6
2022-12-05 23:09:46,111 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5476648946377364, 'Total loss': 0.5476648946377364} | train loss {'Reaction outcome loss': 0.5903927198340816, 'Total loss': 0.5903927198340816}
2022-12-05 23:09:46,111 INFO:     Found new best model at epoch 6
2022-12-05 23:09:46,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:46,112 INFO:     Epoch: 7
2022-12-05 23:09:46,827 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5760195052081888, 'Total loss': 0.5760195052081888} | train loss {'Reaction outcome loss': 0.5853391689879279, 'Total loss': 0.5853391689879279}
2022-12-05 23:09:46,827 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:46,827 INFO:     Epoch: 8
2022-12-05 23:09:47,542 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6021698916500265, 'Total loss': 0.6021698916500265} | train loss {'Reaction outcome loss': 0.5729142662678515, 'Total loss': 0.5729142662678515}
2022-12-05 23:09:47,542 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:47,542 INFO:     Epoch: 9
2022-12-05 23:09:48,256 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5438423908569596, 'Total loss': 0.5438423908569596} | train loss {'Reaction outcome loss': 0.5687233268493607, 'Total loss': 0.5687233268493607}
2022-12-05 23:09:48,257 INFO:     Found new best model at epoch 9
2022-12-05 23:09:48,257 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:48,257 INFO:     Epoch: 10
2022-12-05 23:09:48,974 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5464402132413604, 'Total loss': 0.5464402132413604} | train loss {'Reaction outcome loss': 0.5584460753466813, 'Total loss': 0.5584460753466813}
2022-12-05 23:09:48,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:48,974 INFO:     Epoch: 11
2022-12-05 23:09:49,689 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5194888616150076, 'Total loss': 0.5194888616150076} | train loss {'Reaction outcome loss': 0.5663810610290496, 'Total loss': 0.5663810610290496}
2022-12-05 23:09:49,689 INFO:     Found new best model at epoch 11
2022-12-05 23:09:49,690 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:49,690 INFO:     Epoch: 12
2022-12-05 23:09:50,405 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.6343975432894446, 'Total loss': 0.6343975432894446} | train loss {'Reaction outcome loss': 0.5553484208160832, 'Total loss': 0.5553484208160832}
2022-12-05 23:09:50,405 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:50,405 INFO:     Epoch: 13
2022-12-05 23:09:51,122 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5405371981588277, 'Total loss': 0.5405371981588277} | train loss {'Reaction outcome loss': 0.5554814179457964, 'Total loss': 0.5554814179457964}
2022-12-05 23:09:51,122 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:51,122 INFO:     Epoch: 14
2022-12-05 23:09:51,834 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5468422750180418, 'Total loss': 0.5468422750180418} | train loss {'Reaction outcome loss': 0.5683900268688318, 'Total loss': 0.5683900268688318}
2022-12-05 23:09:51,834 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:51,835 INFO:     Epoch: 15
2022-12-05 23:09:52,546 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5622499798509207, 'Total loss': 0.5622499798509207} | train loss {'Reaction outcome loss': 0.5437026381973298, 'Total loss': 0.5437026381973298}
2022-12-05 23:09:52,546 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:52,546 INFO:     Epoch: 16
2022-12-05 23:09:53,256 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5412971577183767, 'Total loss': 0.5412971577183767} | train loss {'Reaction outcome loss': 0.5518518540287211, 'Total loss': 0.5518518540287211}
2022-12-05 23:09:53,256 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:53,256 INFO:     Epoch: 17
2022-12-05 23:09:53,966 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5188293511217291, 'Total loss': 0.5188293511217291} | train loss {'Reaction outcome loss': 0.5516113394931439, 'Total loss': 0.5516113394931439}
2022-12-05 23:09:53,966 INFO:     Found new best model at epoch 17
2022-12-05 23:09:53,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:53,967 INFO:     Epoch: 18
2022-12-05 23:09:54,677 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5443461561067537, 'Total loss': 0.5443461561067537} | train loss {'Reaction outcome loss': 0.5451482854062512, 'Total loss': 0.5451482854062512}
2022-12-05 23:09:54,677 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:54,677 INFO:     Epoch: 19
2022-12-05 23:09:55,388 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5256101905622266, 'Total loss': 0.5256101905622266} | train loss {'Reaction outcome loss': 0.545280251952429, 'Total loss': 0.545280251952429}
2022-12-05 23:09:55,388 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:55,388 INFO:     Epoch: 20
2022-12-05 23:09:56,102 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5241077095270157, 'Total loss': 0.5241077095270157} | train loss {'Reaction outcome loss': 0.5488896077919391, 'Total loss': 0.5488896077919391}
2022-12-05 23:09:56,102 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:56,102 INFO:     Epoch: 21
2022-12-05 23:09:56,815 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5296505472876809, 'Total loss': 0.5296505472876809} | train loss {'Reaction outcome loss': 0.5421259968030837, 'Total loss': 0.5421259968030837}
2022-12-05 23:09:56,815 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:56,815 INFO:     Epoch: 22
2022-12-05 23:09:57,530 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5173668864775788, 'Total loss': 0.5173668864775788} | train loss {'Reaction outcome loss': 0.5404206293244516, 'Total loss': 0.5404206293244516}
2022-12-05 23:09:57,531 INFO:     Found new best model at epoch 22
2022-12-05 23:09:57,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:57,532 INFO:     Epoch: 23
2022-12-05 23:09:58,248 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5393762574954466, 'Total loss': 0.5393762574954466} | train loss {'Reaction outcome loss': 0.5331006810790108, 'Total loss': 0.5331006810790108}
2022-12-05 23:09:58,248 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:58,248 INFO:     Epoch: 24
2022-12-05 23:09:58,962 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5287897390398112, 'Total loss': 0.5287897390398112} | train loss {'Reaction outcome loss': 0.538123574768824, 'Total loss': 0.538123574768824}
2022-12-05 23:09:58,962 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:58,963 INFO:     Epoch: 25
2022-12-05 23:09:59,679 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5633146085522391, 'Total loss': 0.5633146085522391} | train loss {'Reaction outcome loss': 0.5310422975509879, 'Total loss': 0.5310422975509879}
2022-12-05 23:09:59,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:09:59,679 INFO:     Epoch: 26
2022-12-05 23:10:00,397 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.517935174094005, 'Total loss': 0.517935174094005} | train loss {'Reaction outcome loss': 0.5308664951233133, 'Total loss': 0.5308664951233133}
2022-12-05 23:10:00,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:00,397 INFO:     Epoch: 27
2022-12-05 23:10:01,114 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5214217247610743, 'Total loss': 0.5214217247610743} | train loss {'Reaction outcome loss': 0.5276397335673532, 'Total loss': 0.5276397335673532}
2022-12-05 23:10:01,114 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:01,114 INFO:     Epoch: 28
2022-12-05 23:10:01,834 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5620412122119557, 'Total loss': 0.5620412122119557} | train loss {'Reaction outcome loss': 0.5330083789303899, 'Total loss': 0.5330083789303899}
2022-12-05 23:10:01,834 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:01,834 INFO:     Epoch: 29
2022-12-05 23:10:02,552 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.529535764658993, 'Total loss': 0.529535764658993} | train loss {'Reaction outcome loss': 0.5347840859885177, 'Total loss': 0.5347840859885177}
2022-12-05 23:10:02,552 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:02,552 INFO:     Epoch: 30
2022-12-05 23:10:03,266 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5331226058981635, 'Total loss': 0.5331226058981635} | train loss {'Reaction outcome loss': 0.532872304981274, 'Total loss': 0.532872304981274}
2022-12-05 23:10:03,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:03,267 INFO:     Epoch: 31
2022-12-05 23:10:03,984 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.532960058613257, 'Total loss': 0.532960058613257} | train loss {'Reaction outcome loss': 0.5238135553175404, 'Total loss': 0.5238135553175404}
2022-12-05 23:10:03,984 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:03,984 INFO:     Epoch: 32
2022-12-05 23:10:04,701 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5480316111987288, 'Total loss': 0.5480316111987288} | train loss {'Reaction outcome loss': 0.5341218476814609, 'Total loss': 0.5341218476814609}
2022-12-05 23:10:04,701 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:04,701 INFO:     Epoch: 33
2022-12-05 23:10:05,416 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5443862602114677, 'Total loss': 0.5443862602114677} | train loss {'Reaction outcome loss': 0.5300136332910869, 'Total loss': 0.5300136332910869}
2022-12-05 23:10:05,416 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:05,416 INFO:     Epoch: 34
2022-12-05 23:10:06,131 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5063582814552567, 'Total loss': 0.5063582814552567} | train loss {'Reaction outcome loss': 0.5304161025992324, 'Total loss': 0.5304161025992324}
2022-12-05 23:10:06,131 INFO:     Found new best model at epoch 34
2022-12-05 23:10:06,132 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:06,132 INFO:     Epoch: 35
2022-12-05 23:10:06,848 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5178445516662165, 'Total loss': 0.5178445516662165} | train loss {'Reaction outcome loss': 0.528818009721656, 'Total loss': 0.528818009721656}
2022-12-05 23:10:06,848 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:06,848 INFO:     Epoch: 36
2022-12-05 23:10:07,569 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5214803703129292, 'Total loss': 0.5214803703129292} | train loss {'Reaction outcome loss': 0.5281628066253278, 'Total loss': 0.5281628066253278}
2022-12-05 23:10:07,569 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:07,569 INFO:     Epoch: 37
2022-12-05 23:10:08,285 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.498893121088093, 'Total loss': 0.498893121088093} | train loss {'Reaction outcome loss': 0.5225765514037302, 'Total loss': 0.5225765514037302}
2022-12-05 23:10:08,285 INFO:     Found new best model at epoch 37
2022-12-05 23:10:08,286 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:08,286 INFO:     Epoch: 38
2022-12-05 23:10:09,002 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5528202436187051, 'Total loss': 0.5528202436187051} | train loss {'Reaction outcome loss': 0.535031289342911, 'Total loss': 0.535031289342911}
2022-12-05 23:10:09,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:09,002 INFO:     Epoch: 39
2022-12-05 23:10:09,718 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5345795632086017, 'Total loss': 0.5345795632086017} | train loss {'Reaction outcome loss': 0.5307098928718798, 'Total loss': 0.5307098928718798}
2022-12-05 23:10:09,720 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:09,720 INFO:     Epoch: 40
2022-12-05 23:10:10,435 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5100468766282905, 'Total loss': 0.5100468766282905} | train loss {'Reaction outcome loss': 0.5220889741134259, 'Total loss': 0.5220889741134259}
2022-12-05 23:10:10,435 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:10,435 INFO:     Epoch: 41
2022-12-05 23:10:11,151 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5310276191342961, 'Total loss': 0.5310276191342961} | train loss {'Reaction outcome loss': 0.5282167743651136, 'Total loss': 0.5282167743651136}
2022-12-05 23:10:11,151 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:11,151 INFO:     Epoch: 42
2022-12-05 23:10:11,865 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5251720920205116, 'Total loss': 0.5251720920205116} | train loss {'Reaction outcome loss': 0.5361927790387023, 'Total loss': 0.5361927790387023}
2022-12-05 23:10:11,865 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:11,866 INFO:     Epoch: 43
2022-12-05 23:10:12,580 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.505783920260993, 'Total loss': 0.505783920260993} | train loss {'Reaction outcome loss': 0.522384288330232, 'Total loss': 0.522384288330232}
2022-12-05 23:10:12,581 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:12,581 INFO:     Epoch: 44
2022-12-05 23:10:13,297 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48940076577392494, 'Total loss': 0.48940076577392494} | train loss {'Reaction outcome loss': 0.5300152196639007, 'Total loss': 0.5300152196639007}
2022-12-05 23:10:13,298 INFO:     Found new best model at epoch 44
2022-12-05 23:10:13,298 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:13,298 INFO:     Epoch: 45
2022-12-05 23:10:14,013 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5354346632957458, 'Total loss': 0.5354346632957458} | train loss {'Reaction outcome loss': 0.5212336806880851, 'Total loss': 0.5212336806880851}
2022-12-05 23:10:14,013 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:14,014 INFO:     Epoch: 46
2022-12-05 23:10:14,734 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5006245151162148, 'Total loss': 0.5006245151162148} | train loss {'Reaction outcome loss': 0.5290865547534439, 'Total loss': 0.5290865547534439}
2022-12-05 23:10:14,734 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:14,734 INFO:     Epoch: 47
2022-12-05 23:10:15,454 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5240537805313413, 'Total loss': 0.5240537805313413} | train loss {'Reaction outcome loss': 0.5170795097947121, 'Total loss': 0.5170795097947121}
2022-12-05 23:10:15,454 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:15,454 INFO:     Epoch: 48
2022-12-05 23:10:16,172 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5555709522556175, 'Total loss': 0.5555709522556175} | train loss {'Reaction outcome loss': 0.5194635792605339, 'Total loss': 0.5194635792605339}
2022-12-05 23:10:16,172 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:16,172 INFO:     Epoch: 49
2022-12-05 23:10:16,888 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5662786933508787, 'Total loss': 0.5662786933508787} | train loss {'Reaction outcome loss': 0.5182783503325716, 'Total loss': 0.5182783503325716}
2022-12-05 23:10:16,888 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:16,888 INFO:     Epoch: 50
2022-12-05 23:10:17,608 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5200236768207767, 'Total loss': 0.5200236768207767} | train loss {'Reaction outcome loss': 0.5265764630429687, 'Total loss': 0.5265764630429687}
2022-12-05 23:10:17,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:17,608 INFO:     Epoch: 51
2022-12-05 23:10:18,323 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5038152384487066, 'Total loss': 0.5038152384487066} | train loss {'Reaction outcome loss': 0.5210430148027597, 'Total loss': 0.5210430148027597}
2022-12-05 23:10:18,323 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:18,323 INFO:     Epoch: 52
2022-12-05 23:10:19,038 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5060466135090048, 'Total loss': 0.5060466135090048} | train loss {'Reaction outcome loss': 0.5201238241467264, 'Total loss': 0.5201238241467264}
2022-12-05 23:10:19,038 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:19,038 INFO:     Epoch: 53
2022-12-05 23:10:19,754 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5347137728875334, 'Total loss': 0.5347137728875334} | train loss {'Reaction outcome loss': 0.5194344682799231, 'Total loss': 0.5194344682799231}
2022-12-05 23:10:19,754 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:19,754 INFO:     Epoch: 54
2022-12-05 23:10:20,469 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49996541711417114, 'Total loss': 0.49996541711417114} | train loss {'Reaction outcome loss': 0.5230268653962882, 'Total loss': 0.5230268653962882}
2022-12-05 23:10:20,469 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:20,469 INFO:     Epoch: 55
2022-12-05 23:10:21,185 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5300419256091118, 'Total loss': 0.5300419256091118} | train loss {'Reaction outcome loss': 0.5235450303842945, 'Total loss': 0.5235450303842945}
2022-12-05 23:10:21,185 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:21,186 INFO:     Epoch: 56
2022-12-05 23:10:21,899 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49261375787583267, 'Total loss': 0.49261375787583267} | train loss {'Reaction outcome loss': 0.5226203094446852, 'Total loss': 0.5226203094446852}
2022-12-05 23:10:21,900 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:21,900 INFO:     Epoch: 57
2022-12-05 23:10:22,616 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5133332799781453, 'Total loss': 0.5133332799781453} | train loss {'Reaction outcome loss': 0.5217337560269141, 'Total loss': 0.5217337560269141}
2022-12-05 23:10:22,616 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:22,616 INFO:     Epoch: 58
2022-12-05 23:10:23,333 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5161929367618128, 'Total loss': 0.5161929367618128} | train loss {'Reaction outcome loss': 0.5108438397367154, 'Total loss': 0.5108438397367154}
2022-12-05 23:10:23,334 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:23,334 INFO:     Epoch: 59
2022-12-05 23:10:24,047 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5093820084902373, 'Total loss': 0.5093820084902373} | train loss {'Reaction outcome loss': 0.5205593077886489, 'Total loss': 0.5205593077886489}
2022-12-05 23:10:24,047 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:24,048 INFO:     Epoch: 60
2022-12-05 23:10:24,761 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5273900673809376, 'Total loss': 0.5273900673809376} | train loss {'Reaction outcome loss': 0.5210766067668315, 'Total loss': 0.5210766067668315}
2022-12-05 23:10:24,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:24,761 INFO:     Epoch: 61
2022-12-05 23:10:25,476 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5057943537831306, 'Total loss': 0.5057943537831306} | train loss {'Reaction outcome loss': 0.5220678288249239, 'Total loss': 0.5220678288249239}
2022-12-05 23:10:25,476 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:25,476 INFO:     Epoch: 62
2022-12-05 23:10:26,193 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5241691507399082, 'Total loss': 0.5241691507399082} | train loss {'Reaction outcome loss': 0.521908329018662, 'Total loss': 0.521908329018662}
2022-12-05 23:10:26,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:26,193 INFO:     Epoch: 63
2022-12-05 23:10:26,907 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.510503816333684, 'Total loss': 0.510503816333684} | train loss {'Reaction outcome loss': 0.5238345295431153, 'Total loss': 0.5238345295431153}
2022-12-05 23:10:26,908 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:26,908 INFO:     Epoch: 64
2022-12-05 23:10:27,622 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.500298911197619, 'Total loss': 0.500298911197619} | train loss {'Reaction outcome loss': 0.5266583108253056, 'Total loss': 0.5266583108253056}
2022-12-05 23:10:27,622 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:27,622 INFO:     Epoch: 65
2022-12-05 23:10:28,336 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5311370962722735, 'Total loss': 0.5311370962722735} | train loss {'Reaction outcome loss': 0.5241238397335813, 'Total loss': 0.5241238397335813}
2022-12-05 23:10:28,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:28,337 INFO:     Epoch: 66
2022-12-05 23:10:29,051 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5227890454910018, 'Total loss': 0.5227890454910018} | train loss {'Reaction outcome loss': 0.5160503073805763, 'Total loss': 0.5160503073805763}
2022-12-05 23:10:29,051 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:29,051 INFO:     Epoch: 67
2022-12-05 23:10:29,765 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5163799348202619, 'Total loss': 0.5163799348202619} | train loss {'Reaction outcome loss': 0.5197619381811349, 'Total loss': 0.5197619381811349}
2022-12-05 23:10:29,765 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:29,765 INFO:     Epoch: 68
2022-12-05 23:10:30,479 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49990560385313904, 'Total loss': 0.49990560385313904} | train loss {'Reaction outcome loss': 0.5227286837874882, 'Total loss': 0.5227286837874882}
2022-12-05 23:10:30,480 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:30,480 INFO:     Epoch: 69
2022-12-05 23:10:31,194 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5046664523807439, 'Total loss': 0.5046664523807439} | train loss {'Reaction outcome loss': 0.5158211102168406, 'Total loss': 0.5158211102168406}
2022-12-05 23:10:31,194 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:31,194 INFO:     Epoch: 70
2022-12-05 23:10:31,910 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5155660855499181, 'Total loss': 0.5155660855499181} | train loss {'Reaction outcome loss': 0.5190018414850196, 'Total loss': 0.5190018414850196}
2022-12-05 23:10:31,910 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:31,910 INFO:     Epoch: 71
2022-12-05 23:10:32,624 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4995909570292993, 'Total loss': 0.4995909570292993} | train loss {'Reaction outcome loss': 0.5206923040771677, 'Total loss': 0.5206923040771677}
2022-12-05 23:10:32,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:32,624 INFO:     Epoch: 72
2022-12-05 23:10:33,341 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.511746537278999, 'Total loss': 0.511746537278999} | train loss {'Reaction outcome loss': 0.5193405577372159, 'Total loss': 0.5193405577372159}
2022-12-05 23:10:33,341 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:33,341 INFO:     Epoch: 73
2022-12-05 23:10:34,057 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4952135289257223, 'Total loss': 0.4952135289257223} | train loss {'Reaction outcome loss': 0.5290526830621304, 'Total loss': 0.5290526830621304}
2022-12-05 23:10:34,057 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:34,057 INFO:     Epoch: 74
2022-12-05 23:10:34,772 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.499585898085074, 'Total loss': 0.499585898085074} | train loss {'Reaction outcome loss': 0.5146698365288396, 'Total loss': 0.5146698365288396}
2022-12-05 23:10:34,772 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:34,772 INFO:     Epoch: 75
2022-12-05 23:10:35,486 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48990530825474043, 'Total loss': 0.48990530825474043} | train loss {'Reaction outcome loss': 0.5155004937081568, 'Total loss': 0.5155004937081568}
2022-12-05 23:10:35,486 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:35,486 INFO:     Epoch: 76
2022-12-05 23:10:36,199 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5093400041488084, 'Total loss': 0.5093400041488084} | train loss {'Reaction outcome loss': 0.5171524455710765, 'Total loss': 0.5171524455710765}
2022-12-05 23:10:36,200 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:36,200 INFO:     Epoch: 77
2022-12-05 23:10:36,916 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5070565055039796, 'Total loss': 0.5070565055039796} | train loss {'Reaction outcome loss': 0.5150373457300086, 'Total loss': 0.5150373457300086}
2022-12-05 23:10:36,916 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:36,916 INFO:     Epoch: 78
2022-12-05 23:10:37,635 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5128328654576432, 'Total loss': 0.5128328654576432} | train loss {'Reaction outcome loss': 0.5148150253920786, 'Total loss': 0.5148150253920786}
2022-12-05 23:10:37,635 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:37,635 INFO:     Epoch: 79
2022-12-05 23:10:38,350 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5000958212397315, 'Total loss': 0.5000958212397315} | train loss {'Reaction outcome loss': 0.5161978464813963, 'Total loss': 0.5161978464813963}
2022-12-05 23:10:38,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:38,351 INFO:     Epoch: 80
2022-12-05 23:10:39,070 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5353615849532865, 'Total loss': 0.5353615849532865} | train loss {'Reaction outcome loss': 0.5176867681645578, 'Total loss': 0.5176867681645578}
2022-12-05 23:10:39,070 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:39,070 INFO:     Epoch: 81
2022-12-05 23:10:39,787 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5159290778366002, 'Total loss': 0.5159290778366002} | train loss {'Reaction outcome loss': 0.5243586875017612, 'Total loss': 0.5243586875017612}
2022-12-05 23:10:39,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:39,787 INFO:     Epoch: 82
2022-12-05 23:10:40,508 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5342910100113262, 'Total loss': 0.5342910100113262} | train loss {'Reaction outcome loss': 0.5262590527173973, 'Total loss': 0.5262590527173973}
2022-12-05 23:10:40,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:40,509 INFO:     Epoch: 83
2022-12-05 23:10:41,225 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5317330048842863, 'Total loss': 0.5317330048842863} | train loss {'Reaction outcome loss': 0.5156852322961053, 'Total loss': 0.5156852322961053}
2022-12-05 23:10:41,225 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:41,225 INFO:     Epoch: 84
2022-12-05 23:10:41,942 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5385285456749526, 'Total loss': 0.5385285456749526} | train loss {'Reaction outcome loss': 0.513352275555653, 'Total loss': 0.513352275555653}
2022-12-05 23:10:41,942 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:41,942 INFO:     Epoch: 85
2022-12-05 23:10:42,660 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5071143507957458, 'Total loss': 0.5071143507957458} | train loss {'Reaction outcome loss': 0.5210366021361081, 'Total loss': 0.5210366021361081}
2022-12-05 23:10:42,660 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:42,660 INFO:     Epoch: 86
2022-12-05 23:10:43,378 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5228057347915389, 'Total loss': 0.5228057347915389} | train loss {'Reaction outcome loss': 0.5267139922587141, 'Total loss': 0.5267139922587141}
2022-12-05 23:10:43,378 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:43,378 INFO:     Epoch: 87
2022-12-05 23:10:44,093 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4996254735372283, 'Total loss': 0.4996254735372283} | train loss {'Reaction outcome loss': 0.5313600948260676, 'Total loss': 0.5313600948260676}
2022-12-05 23:10:44,093 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:44,093 INFO:     Epoch: 88
2022-12-05 23:10:44,811 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5020115534690294, 'Total loss': 0.5020115534690294} | train loss {'Reaction outcome loss': 0.5197299333709863, 'Total loss': 0.5197299333709863}
2022-12-05 23:10:44,811 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:44,812 INFO:     Epoch: 89
2022-12-05 23:10:45,527 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49795780872756784, 'Total loss': 0.49795780872756784} | train loss {'Reaction outcome loss': 0.5127191145213381, 'Total loss': 0.5127191145213381}
2022-12-05 23:10:45,527 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:45,527 INFO:     Epoch: 90
2022-12-05 23:10:46,243 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5341180048205636, 'Total loss': 0.5341180048205636} | train loss {'Reaction outcome loss': 0.5201755454463344, 'Total loss': 0.5201755454463344}
2022-12-05 23:10:46,244 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:46,244 INFO:     Epoch: 91
2022-12-05 23:10:46,959 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5196748887273398, 'Total loss': 0.5196748887273398} | train loss {'Reaction outcome loss': 0.5187763930448601, 'Total loss': 0.5187763930448601}
2022-12-05 23:10:46,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:46,960 INFO:     Epoch: 92
2022-12-05 23:10:47,679 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5218118537556041, 'Total loss': 0.5218118537556041} | train loss {'Reaction outcome loss': 0.5176804756685611, 'Total loss': 0.5176804756685611}
2022-12-05 23:10:47,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:47,679 INFO:     Epoch: 93
2022-12-05 23:10:48,396 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5253655256872828, 'Total loss': 0.5253655256872828} | train loss {'Reaction outcome loss': 0.5202003664547398, 'Total loss': 0.5202003664547398}
2022-12-05 23:10:48,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:48,396 INFO:     Epoch: 94
2022-12-05 23:10:49,111 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5067077414555983, 'Total loss': 0.5067077414555983} | train loss {'Reaction outcome loss': 0.5188603991221997, 'Total loss': 0.5188603991221997}
2022-12-05 23:10:49,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:49,111 INFO:     Epoch: 95
2022-12-05 23:10:49,829 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5202170847491785, 'Total loss': 0.5202170847491785} | train loss {'Reaction outcome loss': 0.521835315491884, 'Total loss': 0.521835315491884}
2022-12-05 23:10:49,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:49,829 INFO:     Epoch: 96
2022-12-05 23:10:50,549 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.498537423258478, 'Total loss': 0.498537423258478} | train loss {'Reaction outcome loss': 0.5190063327430717, 'Total loss': 0.5190063327430717}
2022-12-05 23:10:50,549 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:50,549 INFO:     Epoch: 97
2022-12-05 23:10:51,271 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5330709774385799, 'Total loss': 0.5330709774385799} | train loss {'Reaction outcome loss': 0.510089507566825, 'Total loss': 0.510089507566825}
2022-12-05 23:10:51,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:51,271 INFO:     Epoch: 98
2022-12-05 23:10:51,990 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4959672045978633, 'Total loss': 0.4959672045978633} | train loss {'Reaction outcome loss': 0.5177180748432875, 'Total loss': 0.5177180748432875}
2022-12-05 23:10:51,990 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:51,990 INFO:     Epoch: 99
2022-12-05 23:10:52,712 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5229051898826252, 'Total loss': 0.5229051898826252} | train loss {'Reaction outcome loss': 0.5120887111632093, 'Total loss': 0.5120887111632093}
2022-12-05 23:10:52,712 INFO:     Best model found after epoch 45 of 100.
2022-12-05 23:10:52,712 INFO:   Done with stage: TRAINING
2022-12-05 23:10:52,712 INFO:   Starting stage: EVALUATION
2022-12-05 23:10:52,830 INFO:   Done with stage: EVALUATION
2022-12-05 23:10:52,831 INFO:   Leaving out SEQ value Fold_5
2022-12-05 23:10:52,843 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:10:52,843 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:10:53,487 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:10:53,487 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:10:53,559 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:10:53,560 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:10:53,560 INFO:     No hyperparam tuning for this model
2022-12-05 23:10:53,560 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:10:53,560 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:10:53,560 INFO:     None feature selector for col prot
2022-12-05 23:10:53,561 INFO:     None feature selector for col prot
2022-12-05 23:10:53,561 INFO:     None feature selector for col prot
2022-12-05 23:10:53,561 INFO:     None feature selector for col chem
2022-12-05 23:10:53,561 INFO:     None feature selector for col chem
2022-12-05 23:10:53,561 INFO:     None feature selector for col chem
2022-12-05 23:10:53,561 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:10:53,562 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:10:53,563 INFO:     Number of params in model 215731
2022-12-05 23:10:53,566 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:10:53,567 INFO:   Starting stage: TRAINING
2022-12-05 23:10:53,626 INFO:     Val loss before train {'Reaction outcome loss': 1.020085090940649, 'Total loss': 1.020085090940649}
2022-12-05 23:10:53,626 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:53,626 INFO:     Epoch: 0
2022-12-05 23:10:54,342 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7395566539330916, 'Total loss': 0.7395566539330916} | train loss {'Reaction outcome loss': 0.8115235380074273, 'Total loss': 0.8115235380074273}
2022-12-05 23:10:54,342 INFO:     Found new best model at epoch 0
2022-12-05 23:10:54,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:54,343 INFO:     Epoch: 1
2022-12-05 23:10:55,058 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7011032768271186, 'Total loss': 0.7011032768271186} | train loss {'Reaction outcome loss': 0.6772458403699311, 'Total loss': 0.6772458403699311}
2022-12-05 23:10:55,058 INFO:     Found new best model at epoch 1
2022-12-05 23:10:55,059 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:55,059 INFO:     Epoch: 2
2022-12-05 23:10:55,773 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6382624385031787, 'Total loss': 0.6382624385031787} | train loss {'Reaction outcome loss': 0.6452302687805191, 'Total loss': 0.6452302687805191}
2022-12-05 23:10:55,773 INFO:     Found new best model at epoch 2
2022-12-05 23:10:55,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:55,774 INFO:     Epoch: 3
2022-12-05 23:10:56,490 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6280749663710594, 'Total loss': 0.6280749663710594} | train loss {'Reaction outcome loss': 0.6333497538257707, 'Total loss': 0.6333497538257707}
2022-12-05 23:10:56,490 INFO:     Found new best model at epoch 3
2022-12-05 23:10:56,491 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:56,491 INFO:     Epoch: 4
2022-12-05 23:10:57,212 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.676558909768408, 'Total loss': 0.676558909768408} | train loss {'Reaction outcome loss': 0.58518327861602, 'Total loss': 0.58518327861602}
2022-12-05 23:10:57,212 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:57,212 INFO:     Epoch: 5
2022-12-05 23:10:57,928 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6198707575147803, 'Total loss': 0.6198707575147803} | train loss {'Reaction outcome loss': 0.5843859141775471, 'Total loss': 0.5843859141775471}
2022-12-05 23:10:57,928 INFO:     Found new best model at epoch 5
2022-12-05 23:10:57,929 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:57,929 INFO:     Epoch: 6
2022-12-05 23:10:58,647 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6179456216367808, 'Total loss': 0.6179456216367808} | train loss {'Reaction outcome loss': 0.5790612944948529, 'Total loss': 0.5790612944948529}
2022-12-05 23:10:58,647 INFO:     Found new best model at epoch 6
2022-12-05 23:10:58,648 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:58,648 INFO:     Epoch: 7
2022-12-05 23:10:59,360 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5803610069507902, 'Total loss': 0.5803610069507902} | train loss {'Reaction outcome loss': 0.5623132439277433, 'Total loss': 0.5623132439277433}
2022-12-05 23:10:59,361 INFO:     Found new best model at epoch 7
2022-12-05 23:10:59,362 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:10:59,362 INFO:     Epoch: 8
2022-12-05 23:11:00,078 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6156144480813633, 'Total loss': 0.6156144480813633} | train loss {'Reaction outcome loss': 0.5614328074310473, 'Total loss': 0.5614328074310473}
2022-12-05 23:11:00,078 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:00,078 INFO:     Epoch: 9
2022-12-05 23:11:00,786 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.6337380057031458, 'Total loss': 0.6337380057031458} | train loss {'Reaction outcome loss': 0.5541882533655476, 'Total loss': 0.5541882533655476}
2022-12-05 23:11:00,786 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:00,786 INFO:     Epoch: 10
2022-12-05 23:11:01,497 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6211161078377203, 'Total loss': 0.6211161078377203} | train loss {'Reaction outcome loss': 0.5554465884983781, 'Total loss': 0.5554465884983781}
2022-12-05 23:11:01,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:01,497 INFO:     Epoch: 11
2022-12-05 23:11:02,213 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.6233284635977312, 'Total loss': 0.6233284635977312} | train loss {'Reaction outcome loss': 0.5672747274400735, 'Total loss': 0.5672747274400735}
2022-12-05 23:11:02,213 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:02,213 INFO:     Epoch: 12
2022-12-05 23:11:02,922 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5916746780276299, 'Total loss': 0.5916746780276299} | train loss {'Reaction outcome loss': 0.5578526471013784, 'Total loss': 0.5578526471013784}
2022-12-05 23:11:02,922 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:02,922 INFO:     Epoch: 13
2022-12-05 23:11:03,637 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.560326377776536, 'Total loss': 0.560326377776536} | train loss {'Reaction outcome loss': 0.5419914060638018, 'Total loss': 0.5419914060638018}
2022-12-05 23:11:03,638 INFO:     Found new best model at epoch 13
2022-12-05 23:11:03,638 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:03,638 INFO:     Epoch: 14
2022-12-05 23:11:04,349 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5974720635197379, 'Total loss': 0.5974720635197379} | train loss {'Reaction outcome loss': 0.538312676886798, 'Total loss': 0.538312676886798}
2022-12-05 23:11:04,349 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:04,350 INFO:     Epoch: 15
2022-12-05 23:11:05,061 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6028232757340778, 'Total loss': 0.6028232757340778} | train loss {'Reaction outcome loss': 0.5520832042703744, 'Total loss': 0.5520832042703744}
2022-12-05 23:11:05,061 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:05,061 INFO:     Epoch: 16
2022-12-05 23:11:05,775 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5810019556771625, 'Total loss': 0.5810019556771625} | train loss {'Reaction outcome loss': 0.5438524141666378, 'Total loss': 0.5438524141666378}
2022-12-05 23:11:05,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:05,776 INFO:     Epoch: 17
2022-12-05 23:11:06,482 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5679759681224823, 'Total loss': 0.5679759681224823} | train loss {'Reaction outcome loss': 0.5381291364941762, 'Total loss': 0.5381291364941762}
2022-12-05 23:11:06,482 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:06,482 INFO:     Epoch: 18
2022-12-05 23:11:07,188 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5724867182699117, 'Total loss': 0.5724867182699117} | train loss {'Reaction outcome loss': 0.543172176610603, 'Total loss': 0.543172176610603}
2022-12-05 23:11:07,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:07,188 INFO:     Epoch: 19
2022-12-05 23:11:07,894 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5866830904375423, 'Total loss': 0.5866830904375423} | train loss {'Reaction outcome loss': 0.539665803901459, 'Total loss': 0.539665803901459}
2022-12-05 23:11:07,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:07,894 INFO:     Epoch: 20
2022-12-05 23:11:08,607 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.6420041878115047, 'Total loss': 0.6420041878115047} | train loss {'Reaction outcome loss': 0.5345748397201179, 'Total loss': 0.5345748397201179}
2022-12-05 23:11:08,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:08,607 INFO:     Epoch: 21
2022-12-05 23:11:09,314 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.6159396801482547, 'Total loss': 0.6159396801482547} | train loss {'Reaction outcome loss': 0.5343597699032139, 'Total loss': 0.5343597699032139}
2022-12-05 23:11:09,314 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:09,314 INFO:     Epoch: 22
2022-12-05 23:11:10,021 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.6003594540736892, 'Total loss': 0.6003594540736892} | train loss {'Reaction outcome loss': 0.5338379073179202, 'Total loss': 0.5338379073179202}
2022-12-05 23:11:10,021 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:10,021 INFO:     Epoch: 23
2022-12-05 23:11:10,729 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5875901844013821, 'Total loss': 0.5875901844013821} | train loss {'Reaction outcome loss': 0.5352731424002994, 'Total loss': 0.5352731424002994}
2022-12-05 23:11:10,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:10,730 INFO:     Epoch: 24
2022-12-05 23:11:11,441 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5936783721501177, 'Total loss': 0.5936783721501177} | train loss {'Reaction outcome loss': 0.5320229582820344, 'Total loss': 0.5320229582820344}
2022-12-05 23:11:11,442 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:11,442 INFO:     Epoch: 25
2022-12-05 23:11:12,150 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5685068321498957, 'Total loss': 0.5685068321498957} | train loss {'Reaction outcome loss': 0.5335666519186275, 'Total loss': 0.5335666519186275}
2022-12-05 23:11:12,151 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:12,151 INFO:     Epoch: 26
2022-12-05 23:11:12,859 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5496764393015341, 'Total loss': 0.5496764393015341} | train loss {'Reaction outcome loss': 0.5251941964527976, 'Total loss': 0.5251941964527976}
2022-12-05 23:11:12,859 INFO:     Found new best model at epoch 26
2022-12-05 23:11:12,859 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:12,859 INFO:     Epoch: 27
2022-12-05 23:11:13,562 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5579255379059098, 'Total loss': 0.5579255379059098} | train loss {'Reaction outcome loss': 0.5299875630661544, 'Total loss': 0.5299875630661544}
2022-12-05 23:11:13,562 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:13,562 INFO:     Epoch: 28
2022-12-05 23:11:14,263 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5770824521102689, 'Total loss': 0.5770824521102689} | train loss {'Reaction outcome loss': 0.527246009121057, 'Total loss': 0.527246009121057}
2022-12-05 23:11:14,263 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:14,263 INFO:     Epoch: 29
2022-12-05 23:11:14,968 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.6077673777260564, 'Total loss': 0.6077673777260564} | train loss {'Reaction outcome loss': 0.5270098839388776, 'Total loss': 0.5270098839388776}
2022-12-05 23:11:14,969 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:14,969 INFO:     Epoch: 30
2022-12-05 23:11:15,671 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5857388201085004, 'Total loss': 0.5857388201085004} | train loss {'Reaction outcome loss': 0.523125459851041, 'Total loss': 0.523125459851041}
2022-12-05 23:11:15,671 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:15,671 INFO:     Epoch: 31
2022-12-05 23:11:16,379 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.588771911507303, 'Total loss': 0.588771911507303} | train loss {'Reaction outcome loss': 0.5398043526208353, 'Total loss': 0.5398043526208353}
2022-12-05 23:11:16,379 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:16,379 INFO:     Epoch: 32
2022-12-05 23:11:17,089 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.546856535767967, 'Total loss': 0.546856535767967} | train loss {'Reaction outcome loss': 0.5342684363124341, 'Total loss': 0.5342684363124341}
2022-12-05 23:11:17,090 INFO:     Found new best model at epoch 32
2022-12-05 23:11:17,091 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:17,091 INFO:     Epoch: 33
2022-12-05 23:11:17,792 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5657034624706615, 'Total loss': 0.5657034624706615} | train loss {'Reaction outcome loss': 0.5250662425118178, 'Total loss': 0.5250662425118178}
2022-12-05 23:11:17,793 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:17,793 INFO:     Epoch: 34
2022-12-05 23:11:18,494 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5789956118572842, 'Total loss': 0.5789956118572842} | train loss {'Reaction outcome loss': 0.5239121053624249, 'Total loss': 0.5239121053624249}
2022-12-05 23:11:18,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:18,494 INFO:     Epoch: 35
2022-12-05 23:11:19,195 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5601246367123994, 'Total loss': 0.5601246367123994} | train loss {'Reaction outcome loss': 0.5329425920117722, 'Total loss': 0.5329425920117722}
2022-12-05 23:11:19,195 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:19,195 INFO:     Epoch: 36
2022-12-05 23:11:19,901 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.6033300381492485, 'Total loss': 0.6033300381492485} | train loss {'Reaction outcome loss': 0.5288012735696457, 'Total loss': 0.5288012735696457}
2022-12-05 23:11:19,901 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:19,901 INFO:     Epoch: 37
2022-12-05 23:11:20,607 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5711166709661484, 'Total loss': 0.5711166709661484} | train loss {'Reaction outcome loss': 0.5159578683525927, 'Total loss': 0.5159578683525927}
2022-12-05 23:11:20,607 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:20,607 INFO:     Epoch: 38
2022-12-05 23:11:21,312 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5666204555468126, 'Total loss': 0.5666204555468126} | train loss {'Reaction outcome loss': 0.5273391821003153, 'Total loss': 0.5273391821003153}
2022-12-05 23:11:21,313 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:21,313 INFO:     Epoch: 39
2022-12-05 23:11:22,017 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5577978363091295, 'Total loss': 0.5577978363091295} | train loss {'Reaction outcome loss': 0.5308114113474665, 'Total loss': 0.5308114113474665}
2022-12-05 23:11:22,018 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:22,018 INFO:     Epoch: 40
2022-12-05 23:11:22,723 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5737748413600705, 'Total loss': 0.5737748413600705} | train loss {'Reaction outcome loss': 0.5250595589017548, 'Total loss': 0.5250595589017548}
2022-12-05 23:11:22,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:22,723 INFO:     Epoch: 41
2022-12-05 23:11:23,427 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5365222516384992, 'Total loss': 0.5365222516384992} | train loss {'Reaction outcome loss': 0.526274078499209, 'Total loss': 0.526274078499209}
2022-12-05 23:11:23,427 INFO:     Found new best model at epoch 41
2022-12-05 23:11:23,427 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:23,427 INFO:     Epoch: 42
2022-12-05 23:11:24,129 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5510579323904081, 'Total loss': 0.5510579323904081} | train loss {'Reaction outcome loss': 0.5206220386519667, 'Total loss': 0.5206220386519667}
2022-12-05 23:11:24,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:24,129 INFO:     Epoch: 43
2022-12-05 23:11:24,830 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5767603994093158, 'Total loss': 0.5767603994093158} | train loss {'Reaction outcome loss': 0.5159130723819868, 'Total loss': 0.5159130723819868}
2022-12-05 23:11:24,830 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:24,831 INFO:     Epoch: 44
2022-12-05 23:11:25,533 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5375674346631224, 'Total loss': 0.5375674346631224} | train loss {'Reaction outcome loss': 0.5228777459629591, 'Total loss': 0.5228777459629591}
2022-12-05 23:11:25,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:25,533 INFO:     Epoch: 45
2022-12-05 23:11:26,238 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5630008798431266, 'Total loss': 0.5630008798431266} | train loss {'Reaction outcome loss': 0.5195589326100559, 'Total loss': 0.5195589326100559}
2022-12-05 23:11:26,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:26,238 INFO:     Epoch: 46
2022-12-05 23:11:26,941 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5416243069551208, 'Total loss': 0.5416243069551208} | train loss {'Reaction outcome loss': 0.5147501309788767, 'Total loss': 0.5147501309788767}
2022-12-05 23:11:26,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:26,941 INFO:     Epoch: 47
2022-12-05 23:11:27,646 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.6262157586487856, 'Total loss': 0.6262157586487856} | train loss {'Reaction outcome loss': 0.5229418680735445, 'Total loss': 0.5229418680735445}
2022-12-05 23:11:27,646 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:27,646 INFO:     Epoch: 48
2022-12-05 23:11:28,353 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.53209864822301, 'Total loss': 0.53209864822301} | train loss {'Reaction outcome loss': 0.5320375128253269, 'Total loss': 0.5320375128253269}
2022-12-05 23:11:28,353 INFO:     Found new best model at epoch 48
2022-12-05 23:11:28,353 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:28,354 INFO:     Epoch: 49
2022-12-05 23:11:29,055 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5742695307867094, 'Total loss': 0.5742695307867094} | train loss {'Reaction outcome loss': 0.5209339142509317, 'Total loss': 0.5209339142509317}
2022-12-05 23:11:29,055 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:29,055 INFO:     Epoch: 50
2022-12-05 23:11:29,761 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5540018393234774, 'Total loss': 0.5540018393234774} | train loss {'Reaction outcome loss': 0.5181703329810247, 'Total loss': 0.5181703329810247}
2022-12-05 23:11:29,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:29,761 INFO:     Epoch: 51
2022-12-05 23:11:30,464 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5680445398796689, 'Total loss': 0.5680445398796689} | train loss {'Reaction outcome loss': 0.5220416089301168, 'Total loss': 0.5220416089301168}
2022-12-05 23:11:30,464 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:30,465 INFO:     Epoch: 52
2022-12-05 23:11:31,167 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5623227953910828, 'Total loss': 0.5623227953910828} | train loss {'Reaction outcome loss': 0.5158813900431158, 'Total loss': 0.5158813900431158}
2022-12-05 23:11:31,167 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:31,167 INFO:     Epoch: 53
2022-12-05 23:11:31,869 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5997807437723334, 'Total loss': 0.5997807437723334} | train loss {'Reaction outcome loss': 0.5172874572788656, 'Total loss': 0.5172874572788656}
2022-12-05 23:11:31,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:31,869 INFO:     Epoch: 54
2022-12-05 23:11:32,570 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.6052988320589066, 'Total loss': 0.6052988320589066} | train loss {'Reaction outcome loss': 0.5322570827929115, 'Total loss': 0.5322570827929115}
2022-12-05 23:11:32,571 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:32,571 INFO:     Epoch: 55
2022-12-05 23:11:33,274 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5531597239049998, 'Total loss': 0.5531597239049998} | train loss {'Reaction outcome loss': 0.5312495726322838, 'Total loss': 0.5312495726322838}
2022-12-05 23:11:33,274 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:33,274 INFO:     Epoch: 56
2022-12-05 23:11:33,981 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5393078966404904, 'Total loss': 0.5393078966404904} | train loss {'Reaction outcome loss': 0.5173428419389223, 'Total loss': 0.5173428419389223}
2022-12-05 23:11:33,981 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:33,981 INFO:     Epoch: 57
2022-12-05 23:11:34,686 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5448808588764884, 'Total loss': 0.5448808588764884} | train loss {'Reaction outcome loss': 0.5109305805168473, 'Total loss': 0.5109305805168473}
2022-12-05 23:11:34,687 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:34,687 INFO:     Epoch: 58
2022-12-05 23:11:35,392 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.547033755955371, 'Total loss': 0.547033755955371} | train loss {'Reaction outcome loss': 0.5182471050153136, 'Total loss': 0.5182471050153136}
2022-12-05 23:11:35,392 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:35,392 INFO:     Epoch: 59
2022-12-05 23:11:36,096 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.605413178151304, 'Total loss': 0.605413178151304} | train loss {'Reaction outcome loss': 0.5165214942775758, 'Total loss': 0.5165214942775758}
2022-12-05 23:11:36,096 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:36,096 INFO:     Epoch: 60
2022-12-05 23:11:36,802 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.579654449089007, 'Total loss': 0.579654449089007} | train loss {'Reaction outcome loss': 0.5179995437056535, 'Total loss': 0.5179995437056535}
2022-12-05 23:11:36,802 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:36,803 INFO:     Epoch: 61
2022-12-05 23:11:37,506 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5475232384421609, 'Total loss': 0.5475232384421609} | train loss {'Reaction outcome loss': 0.5113473302394393, 'Total loss': 0.5113473302394393}
2022-12-05 23:11:37,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:37,506 INFO:     Epoch: 62
2022-12-05 23:11:38,208 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5358735871585932, 'Total loss': 0.5358735871585932} | train loss {'Reaction outcome loss': 0.5167583825617184, 'Total loss': 0.5167583825617184}
2022-12-05 23:11:38,208 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:38,208 INFO:     Epoch: 63
2022-12-05 23:11:38,909 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5542120313779875, 'Total loss': 0.5542120313779875} | train loss {'Reaction outcome loss': 0.5200306032953957, 'Total loss': 0.5200306032953957}
2022-12-05 23:11:38,910 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:38,910 INFO:     Epoch: 64
2022-12-05 23:11:39,613 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.539329320192337, 'Total loss': 0.539329320192337} | train loss {'Reaction outcome loss': 0.5251536490282549, 'Total loss': 0.5251536490282549}
2022-12-05 23:11:39,613 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:39,613 INFO:     Epoch: 65
2022-12-05 23:11:40,318 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.551997937600721, 'Total loss': 0.551997937600721} | train loss {'Reaction outcome loss': 0.51470927314961, 'Total loss': 0.51470927314961}
2022-12-05 23:11:40,318 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:40,318 INFO:     Epoch: 66
2022-12-05 23:11:41,031 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5774514363570646, 'Total loss': 0.5774514363570646} | train loss {'Reaction outcome loss': 0.5250812438938782, 'Total loss': 0.5250812438938782}
2022-12-05 23:11:41,031 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:41,031 INFO:     Epoch: 67
2022-12-05 23:11:41,738 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5575058345090259, 'Total loss': 0.5575058345090259} | train loss {'Reaction outcome loss': 0.5156090091235241, 'Total loss': 0.5156090091235241}
2022-12-05 23:11:41,739 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:41,740 INFO:     Epoch: 68
2022-12-05 23:11:42,442 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5589700124480508, 'Total loss': 0.5589700124480508} | train loss {'Reaction outcome loss': 0.5149132838238951, 'Total loss': 0.5149132838238951}
2022-12-05 23:11:42,442 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:42,442 INFO:     Epoch: 69
2022-12-05 23:11:43,144 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5435511469841003, 'Total loss': 0.5435511469841003} | train loss {'Reaction outcome loss': 0.5178496477001833, 'Total loss': 0.5178496477001833}
2022-12-05 23:11:43,144 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:43,145 INFO:     Epoch: 70
2022-12-05 23:11:43,847 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5387877886268225, 'Total loss': 0.5387877886268225} | train loss {'Reaction outcome loss': 0.5137816159590053, 'Total loss': 0.5137816159590053}
2022-12-05 23:11:43,847 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:43,848 INFO:     Epoch: 71
2022-12-05 23:11:44,549 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5541864433749155, 'Total loss': 0.5541864433749155} | train loss {'Reaction outcome loss': 0.5245782857843739, 'Total loss': 0.5245782857843739}
2022-12-05 23:11:44,549 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:44,549 INFO:     Epoch: 72
2022-12-05 23:11:45,260 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5605429990047758, 'Total loss': 0.5605429990047758} | train loss {'Reaction outcome loss': 0.5171840541396546, 'Total loss': 0.5171840541396546}
2022-12-05 23:11:45,260 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:45,260 INFO:     Epoch: 73
2022-12-05 23:11:45,970 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5439114299687472, 'Total loss': 0.5439114299687472} | train loss {'Reaction outcome loss': 0.5332805208469692, 'Total loss': 0.5332805208469692}
2022-12-05 23:11:45,970 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:45,970 INFO:     Epoch: 74
2022-12-05 23:11:46,680 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5447854487733408, 'Total loss': 0.5447854487733408} | train loss {'Reaction outcome loss': 0.5209789616376282, 'Total loss': 0.5209789616376282}
2022-12-05 23:11:46,680 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:46,681 INFO:     Epoch: 75
2022-12-05 23:11:47,391 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.529506113041531, 'Total loss': 0.529506113041531} | train loss {'Reaction outcome loss': 0.514577896911123, 'Total loss': 0.514577896911123}
2022-12-05 23:11:47,391 INFO:     Found new best model at epoch 75
2022-12-05 23:11:47,391 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:47,391 INFO:     Epoch: 76
2022-12-05 23:11:48,105 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5289857387542725, 'Total loss': 0.5289857387542725} | train loss {'Reaction outcome loss': 0.5135332269043575, 'Total loss': 0.5135332269043575}
2022-12-05 23:11:48,106 INFO:     Found new best model at epoch 76
2022-12-05 23:11:48,107 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:48,107 INFO:     Epoch: 77
2022-12-05 23:11:48,816 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5923815064809539, 'Total loss': 0.5923815064809539} | train loss {'Reaction outcome loss': 0.5148527335662109, 'Total loss': 0.5148527335662109}
2022-12-05 23:11:48,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:48,816 INFO:     Epoch: 78
2022-12-05 23:11:49,524 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5706156471913512, 'Total loss': 0.5706156471913512} | train loss {'Reaction outcome loss': 0.5097369423158739, 'Total loss': 0.5097369423158739}
2022-12-05 23:11:49,525 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:49,525 INFO:     Epoch: 79
2022-12-05 23:11:50,234 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.54944404756481, 'Total loss': 0.54944404756481} | train loss {'Reaction outcome loss': 0.5161919198734196, 'Total loss': 0.5161919198734196}
2022-12-05 23:11:50,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:50,234 INFO:     Epoch: 80
2022-12-05 23:11:50,944 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5557624751871283, 'Total loss': 0.5557624751871283} | train loss {'Reaction outcome loss': 0.5186481098776404, 'Total loss': 0.5186481098776404}
2022-12-05 23:11:50,944 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:50,944 INFO:     Epoch: 81
2022-12-05 23:11:51,656 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5531005368314006, 'Total loss': 0.5531005368314006} | train loss {'Reaction outcome loss': 0.5307765061918058, 'Total loss': 0.5307765061918058}
2022-12-05 23:11:51,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:51,656 INFO:     Epoch: 82
2022-12-05 23:11:52,365 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5407015972516753, 'Total loss': 0.5407015972516753} | train loss {'Reaction outcome loss': 0.5467623119894792, 'Total loss': 0.5467623119894792}
2022-12-05 23:11:52,365 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:52,365 INFO:     Epoch: 83
2022-12-05 23:11:53,072 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5322228856384754, 'Total loss': 0.5322228856384754} | train loss {'Reaction outcome loss': 0.5172103709761131, 'Total loss': 0.5172103709761131}
2022-12-05 23:11:53,072 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:53,072 INFO:     Epoch: 84
2022-12-05 23:11:53,781 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5389977612278678, 'Total loss': 0.5389977612278678} | train loss {'Reaction outcome loss': 0.5163729856854026, 'Total loss': 0.5163729856854026}
2022-12-05 23:11:53,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:53,781 INFO:     Epoch: 85
2022-12-05 23:11:54,492 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5559458959509026, 'Total loss': 0.5559458959509026} | train loss {'Reaction outcome loss': 0.5203277214094695, 'Total loss': 0.5203277214094695}
2022-12-05 23:11:54,493 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:54,493 INFO:     Epoch: 86
2022-12-05 23:11:55,204 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5462312871082262, 'Total loss': 0.5462312871082262} | train loss {'Reaction outcome loss': 0.5174724792058651, 'Total loss': 0.5174724792058651}
2022-12-05 23:11:55,204 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:55,204 INFO:     Epoch: 87
2022-12-05 23:11:55,916 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5459602620791305, 'Total loss': 0.5459602620791305} | train loss {'Reaction outcome loss': 0.5173518317431091, 'Total loss': 0.5173518317431091}
2022-12-05 23:11:55,916 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:55,916 INFO:     Epoch: 88
2022-12-05 23:11:56,628 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5739967199889097, 'Total loss': 0.5739967199889097} | train loss {'Reaction outcome loss': 0.515583998519882, 'Total loss': 0.515583998519882}
2022-12-05 23:11:56,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:56,628 INFO:     Epoch: 89
2022-12-05 23:11:57,339 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5718355023048141, 'Total loss': 0.5718355023048141} | train loss {'Reaction outcome loss': 0.525702809032641, 'Total loss': 0.525702809032641}
2022-12-05 23:11:57,340 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:57,340 INFO:     Epoch: 90
2022-12-05 23:11:58,049 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.624196933074431, 'Total loss': 0.624196933074431} | train loss {'Reaction outcome loss': 0.5197724462218153, 'Total loss': 0.5197724462218153}
2022-12-05 23:11:58,049 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:58,049 INFO:     Epoch: 91
2022-12-05 23:11:58,756 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5715169628912752, 'Total loss': 0.5715169628912752} | train loss {'Reaction outcome loss': 0.5151504421161737, 'Total loss': 0.5151504421161737}
2022-12-05 23:11:58,756 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:58,757 INFO:     Epoch: 92
2022-12-05 23:11:59,464 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5911558046936989, 'Total loss': 0.5911558046936989} | train loss {'Reaction outcome loss': 0.5158308060040419, 'Total loss': 0.5158308060040419}
2022-12-05 23:11:59,464 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:11:59,464 INFO:     Epoch: 93
2022-12-05 23:12:00,175 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5572597670622847, 'Total loss': 0.5572597670622847} | train loss {'Reaction outcome loss': 0.5166905578452083, 'Total loss': 0.5166905578452083}
2022-12-05 23:12:00,176 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:00,176 INFO:     Epoch: 94
2022-12-05 23:12:00,886 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5532780580899932, 'Total loss': 0.5532780580899932} | train loss {'Reaction outcome loss': 0.5230134675988121, 'Total loss': 0.5230134675988121}
2022-12-05 23:12:00,887 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:00,887 INFO:     Epoch: 95
2022-12-05 23:12:01,596 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5514780255881223, 'Total loss': 0.5514780255881223} | train loss {'Reaction outcome loss': 0.5104774574519169, 'Total loss': 0.5104774574519169}
2022-12-05 23:12:01,596 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:01,596 INFO:     Epoch: 96
2022-12-05 23:12:02,308 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5650457753376528, 'Total loss': 0.5650457753376528} | train loss {'Reaction outcome loss': 0.522576020312258, 'Total loss': 0.522576020312258}
2022-12-05 23:12:02,308 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:02,308 INFO:     Epoch: 97
2022-12-05 23:12:03,017 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5459842180663889, 'Total loss': 0.5459842180663889} | train loss {'Reaction outcome loss': 0.523093305739314, 'Total loss': 0.523093305739314}
2022-12-05 23:12:03,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:03,017 INFO:     Epoch: 98
2022-12-05 23:12:03,725 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5385808026926084, 'Total loss': 0.5385808026926084} | train loss {'Reaction outcome loss': 0.5260252019895716, 'Total loss': 0.5260252019895716}
2022-12-05 23:12:03,725 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:03,726 INFO:     Epoch: 99
2022-12-05 23:12:04,440 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5368758236820047, 'Total loss': 0.5368758236820047} | train loss {'Reaction outcome loss': 0.5166836552291747, 'Total loss': 0.5166836552291747}
2022-12-05 23:12:04,440 INFO:     Best model found after epoch 77 of 100.
2022-12-05 23:12:04,440 INFO:   Done with stage: TRAINING
2022-12-05 23:12:04,440 INFO:   Starting stage: EVALUATION
2022-12-05 23:12:04,564 INFO:   Done with stage: EVALUATION
2022-12-05 23:12:04,565 INFO:   Leaving out SEQ value Fold_6
2022-12-05 23:12:04,578 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:12:04,579 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:12:05,230 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:12:05,230 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:12:05,301 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:12:05,302 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:12:05,302 INFO:     No hyperparam tuning for this model
2022-12-05 23:12:05,302 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:12:05,302 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:12:05,302 INFO:     None feature selector for col prot
2022-12-05 23:12:05,303 INFO:     None feature selector for col prot
2022-12-05 23:12:05,303 INFO:     None feature selector for col prot
2022-12-05 23:12:05,303 INFO:     None feature selector for col chem
2022-12-05 23:12:05,303 INFO:     None feature selector for col chem
2022-12-05 23:12:05,303 INFO:     None feature selector for col chem
2022-12-05 23:12:05,303 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:12:05,303 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:12:05,305 INFO:     Number of params in model 215731
2022-12-05 23:12:05,308 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:12:05,308 INFO:   Starting stage: TRAINING
2022-12-05 23:12:05,367 INFO:     Val loss before train {'Reaction outcome loss': 0.9627926261587576, 'Total loss': 0.9627926261587576}
2022-12-05 23:12:05,367 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:05,367 INFO:     Epoch: 0
2022-12-05 23:12:06,080 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7184930436990478, 'Total loss': 0.7184930436990478} | train loss {'Reaction outcome loss': 0.823690120250948, 'Total loss': 0.823690120250948}
2022-12-05 23:12:06,080 INFO:     Found new best model at epoch 0
2022-12-05 23:12:06,081 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:06,081 INFO:     Epoch: 1
2022-12-05 23:12:06,795 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6019758846272122, 'Total loss': 0.6019758846272122} | train loss {'Reaction outcome loss': 0.669026970623001, 'Total loss': 0.669026970623001}
2022-12-05 23:12:06,795 INFO:     Found new best model at epoch 1
2022-12-05 23:12:06,795 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:06,796 INFO:     Epoch: 2
2022-12-05 23:12:07,509 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5747617672790181, 'Total loss': 0.5747617672790181} | train loss {'Reaction outcome loss': 0.6219563993715471, 'Total loss': 0.6219563993715471}
2022-12-05 23:12:07,509 INFO:     Found new best model at epoch 2
2022-12-05 23:12:07,510 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:07,510 INFO:     Epoch: 3
2022-12-05 23:12:08,221 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5896166068586436, 'Total loss': 0.5896166068586436} | train loss {'Reaction outcome loss': 0.5961255627053399, 'Total loss': 0.5961255627053399}
2022-12-05 23:12:08,222 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:08,222 INFO:     Epoch: 4
2022-12-05 23:12:08,937 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5371689180081541, 'Total loss': 0.5371689180081541} | train loss {'Reaction outcome loss': 0.5798598355463436, 'Total loss': 0.5798598355463436}
2022-12-05 23:12:08,937 INFO:     Found new best model at epoch 4
2022-12-05 23:12:08,938 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:08,938 INFO:     Epoch: 5
2022-12-05 23:12:09,650 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.524279120970856, 'Total loss': 0.524279120970856} | train loss {'Reaction outcome loss': 0.5770824310039321, 'Total loss': 0.5770824310039321}
2022-12-05 23:12:09,650 INFO:     Found new best model at epoch 5
2022-12-05 23:12:09,651 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:09,651 INFO:     Epoch: 6
2022-12-05 23:12:10,362 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5340429415757005, 'Total loss': 0.5340429415757005} | train loss {'Reaction outcome loss': 0.5724116841391209, 'Total loss': 0.5724116841391209}
2022-12-05 23:12:10,363 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:10,363 INFO:     Epoch: 7
2022-12-05 23:12:11,073 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5183826170184396, 'Total loss': 0.5183826170184396} | train loss {'Reaction outcome loss': 0.5693530693890587, 'Total loss': 0.5693530693890587}
2022-12-05 23:12:11,074 INFO:     Found new best model at epoch 7
2022-12-05 23:12:11,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:11,074 INFO:     Epoch: 8
2022-12-05 23:12:11,787 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.580382032150572, 'Total loss': 0.580382032150572} | train loss {'Reaction outcome loss': 0.5538035908173169, 'Total loss': 0.5538035908173169}
2022-12-05 23:12:11,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:11,788 INFO:     Epoch: 9
2022-12-05 23:12:12,503 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5396821302446452, 'Total loss': 0.5396821302446452} | train loss {'Reaction outcome loss': 0.5580090300570573, 'Total loss': 0.5580090300570573}
2022-12-05 23:12:12,503 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:12,503 INFO:     Epoch: 10
2022-12-05 23:12:13,215 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5358418510718779, 'Total loss': 0.5358418510718779} | train loss {'Reaction outcome loss': 0.5552468857457561, 'Total loss': 0.5552468857457561}
2022-12-05 23:12:13,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:13,216 INFO:     Epoch: 11
2022-12-05 23:12:13,929 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5546593049710448, 'Total loss': 0.5546593049710448} | train loss {'Reaction outcome loss': 0.5513457653503264, 'Total loss': 0.5513457653503264}
2022-12-05 23:12:13,929 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:13,930 INFO:     Epoch: 12
2022-12-05 23:12:14,641 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5429707277904857, 'Total loss': 0.5429707277904857} | train loss {'Reaction outcome loss': 0.5559488935095649, 'Total loss': 0.5559488935095649}
2022-12-05 23:12:14,641 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:14,641 INFO:     Epoch: 13
2022-12-05 23:12:15,354 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5409032434902408, 'Total loss': 0.5409032434902408} | train loss {'Reaction outcome loss': 0.544398523446533, 'Total loss': 0.544398523446533}
2022-12-05 23:12:15,354 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:15,354 INFO:     Epoch: 14
2022-12-05 23:12:16,074 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5446124042976986, 'Total loss': 0.5446124042976986} | train loss {'Reaction outcome loss': 0.5455157708136305, 'Total loss': 0.5455157708136305}
2022-12-05 23:12:16,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:16,074 INFO:     Epoch: 15
2022-12-05 23:12:16,793 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5246568809856068, 'Total loss': 0.5246568809856068} | train loss {'Reaction outcome loss': 0.5444574402945657, 'Total loss': 0.5444574402945657}
2022-12-05 23:12:16,793 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:16,793 INFO:     Epoch: 16
2022-12-05 23:12:17,509 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5119691775603727, 'Total loss': 0.5119691775603727} | train loss {'Reaction outcome loss': 0.5470892651787689, 'Total loss': 0.5470892651787689}
2022-12-05 23:12:17,509 INFO:     Found new best model at epoch 16
2022-12-05 23:12:17,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:17,509 INFO:     Epoch: 17
2022-12-05 23:12:18,228 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.529844775118611, 'Total loss': 0.529844775118611} | train loss {'Reaction outcome loss': 0.5464606202778316, 'Total loss': 0.5464606202778316}
2022-12-05 23:12:18,228 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:18,229 INFO:     Epoch: 18
2022-12-05 23:12:18,943 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5233687528155067, 'Total loss': 0.5233687528155067} | train loss {'Reaction outcome loss': 0.5488094335361835, 'Total loss': 0.5488094335361835}
2022-12-05 23:12:18,943 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:18,943 INFO:     Epoch: 19
2022-12-05 23:12:19,657 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5333545092831958, 'Total loss': 0.5333545092831958} | train loss {'Reaction outcome loss': 0.5433712683978581, 'Total loss': 0.5433712683978581}
2022-12-05 23:12:19,658 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:19,658 INFO:     Epoch: 20
2022-12-05 23:12:20,375 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5365664586424828, 'Total loss': 0.5365664586424828} | train loss {'Reaction outcome loss': 0.5481106975987073, 'Total loss': 0.5481106975987073}
2022-12-05 23:12:20,375 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:20,375 INFO:     Epoch: 21
2022-12-05 23:12:21,090 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5315894674171101, 'Total loss': 0.5315894674171101} | train loss {'Reaction outcome loss': 0.5345834356041685, 'Total loss': 0.5345834356041685}
2022-12-05 23:12:21,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:21,090 INFO:     Epoch: 22
2022-12-05 23:12:21,803 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5270406068726019, 'Total loss': 0.5270406068726019} | train loss {'Reaction outcome loss': 0.5379234313844673, 'Total loss': 0.5379234313844673}
2022-12-05 23:12:21,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:21,804 INFO:     Epoch: 23
2022-12-05 23:12:22,521 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.534263127906756, 'Total loss': 0.534263127906756} | train loss {'Reaction outcome loss': 0.5448863094131793, 'Total loss': 0.5448863094131793}
2022-12-05 23:12:22,522 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:22,522 INFO:     Epoch: 24
2022-12-05 23:12:23,240 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5252042121507905, 'Total loss': 0.5252042121507905} | train loss {'Reaction outcome loss': 0.5393350037235406, 'Total loss': 0.5393350037235406}
2022-12-05 23:12:23,240 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:23,240 INFO:     Epoch: 25
2022-12-05 23:12:23,956 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5082712295380506, 'Total loss': 0.5082712295380506} | train loss {'Reaction outcome loss': 0.5329788796483509, 'Total loss': 0.5329788796483509}
2022-12-05 23:12:23,956 INFO:     Found new best model at epoch 25
2022-12-05 23:12:23,956 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:23,956 INFO:     Epoch: 26
2022-12-05 23:12:24,671 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5497331111268564, 'Total loss': 0.5497331111268564} | train loss {'Reaction outcome loss': 0.5407104914587352, 'Total loss': 0.5407104914587352}
2022-12-05 23:12:24,672 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:24,672 INFO:     Epoch: 27
2022-12-05 23:12:25,386 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5255157822235064, 'Total loss': 0.5255157822235064} | train loss {'Reaction outcome loss': 0.5435673953184197, 'Total loss': 0.5435673953184197}
2022-12-05 23:12:25,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:25,387 INFO:     Epoch: 28
2022-12-05 23:12:26,102 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5428533493117853, 'Total loss': 0.5428533493117853} | train loss {'Reaction outcome loss': 0.534432411974957, 'Total loss': 0.534432411974957}
2022-12-05 23:12:26,102 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:26,102 INFO:     Epoch: 29
2022-12-05 23:12:26,817 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.58233830942349, 'Total loss': 0.58233830942349} | train loss {'Reaction outcome loss': 0.5409443897585715, 'Total loss': 0.5409443897585715}
2022-12-05 23:12:26,817 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:26,817 INFO:     Epoch: 30
2022-12-05 23:12:27,533 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5218984708189964, 'Total loss': 0.5218984708189964} | train loss {'Reaction outcome loss': 0.5418571905202924, 'Total loss': 0.5418571905202924}
2022-12-05 23:12:27,534 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:27,534 INFO:     Epoch: 31
2022-12-05 23:12:28,253 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5353861674666405, 'Total loss': 0.5353861674666405} | train loss {'Reaction outcome loss': 0.5341935347645513, 'Total loss': 0.5341935347645513}
2022-12-05 23:12:28,253 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:28,253 INFO:     Epoch: 32
2022-12-05 23:12:28,970 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5024050758643583, 'Total loss': 0.5024050758643583} | train loss {'Reaction outcome loss': 0.5442543724972394, 'Total loss': 0.5442543724972394}
2022-12-05 23:12:28,970 INFO:     Found new best model at epoch 32
2022-12-05 23:12:28,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:28,971 INFO:     Epoch: 33
2022-12-05 23:12:29,686 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5188276645812121, 'Total loss': 0.5188276645812121} | train loss {'Reaction outcome loss': 0.5364082787906931, 'Total loss': 0.5364082787906931}
2022-12-05 23:12:29,686 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:29,686 INFO:     Epoch: 34
2022-12-05 23:12:30,401 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5046840106899088, 'Total loss': 0.5046840106899088} | train loss {'Reaction outcome loss': 0.5374139300397327, 'Total loss': 0.5374139300397327}
2022-12-05 23:12:30,401 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:30,401 INFO:     Epoch: 35
2022-12-05 23:12:31,119 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5212272893298756, 'Total loss': 0.5212272893298756} | train loss {'Reaction outcome loss': 0.5382805717808585, 'Total loss': 0.5382805717808585}
2022-12-05 23:12:31,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:31,120 INFO:     Epoch: 36
2022-12-05 23:12:31,837 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5272665223614736, 'Total loss': 0.5272665223614736} | train loss {'Reaction outcome loss': 0.5471850871559112, 'Total loss': 0.5471850871559112}
2022-12-05 23:12:31,838 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:31,838 INFO:     Epoch: 37
2022-12-05 23:12:32,553 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5357328138568185, 'Total loss': 0.5357328138568185} | train loss {'Reaction outcome loss': 0.538708855247786, 'Total loss': 0.538708855247786}
2022-12-05 23:12:32,553 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:32,554 INFO:     Epoch: 38
2022-12-05 23:12:33,268 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5663057264279235, 'Total loss': 0.5663057264279235} | train loss {'Reaction outcome loss': 0.5384489973526327, 'Total loss': 0.5384489973526327}
2022-12-05 23:12:33,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:33,268 INFO:     Epoch: 39
2022-12-05 23:12:33,987 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5169397230175409, 'Total loss': 0.5169397230175409} | train loss {'Reaction outcome loss': 0.53283098526299, 'Total loss': 0.53283098526299}
2022-12-05 23:12:33,988 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:33,988 INFO:     Epoch: 40
2022-12-05 23:12:34,706 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.542334381152283, 'Total loss': 0.542334381152283} | train loss {'Reaction outcome loss': 0.5391859192281, 'Total loss': 0.5391859192281}
2022-12-05 23:12:34,707 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:34,707 INFO:     Epoch: 41
2022-12-05 23:12:35,423 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5238248380747709, 'Total loss': 0.5238248380747709} | train loss {'Reaction outcome loss': 0.5382451681840804, 'Total loss': 0.5382451681840804}
2022-12-05 23:12:35,423 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:35,423 INFO:     Epoch: 42
2022-12-05 23:12:36,139 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5083919638259844, 'Total loss': 0.5083919638259844} | train loss {'Reaction outcome loss': 0.5427782428601096, 'Total loss': 0.5427782428601096}
2022-12-05 23:12:36,139 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:36,140 INFO:     Epoch: 43
2022-12-05 23:12:36,854 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5206734165549278, 'Total loss': 0.5206734165549278} | train loss {'Reaction outcome loss': 0.5345109636865316, 'Total loss': 0.5345109636865316}
2022-12-05 23:12:36,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:36,855 INFO:     Epoch: 44
2022-12-05 23:12:37,569 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5371725298464298, 'Total loss': 0.5371725298464298} | train loss {'Reaction outcome loss': 0.5386185591980335, 'Total loss': 0.5386185591980335}
2022-12-05 23:12:37,569 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:37,569 INFO:     Epoch: 45
2022-12-05 23:12:38,285 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5382248054851185, 'Total loss': 0.5382248054851185} | train loss {'Reaction outcome loss': 0.5378107372070512, 'Total loss': 0.5378107372070512}
2022-12-05 23:12:38,285 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:38,285 INFO:     Epoch: 46
2022-12-05 23:12:39,001 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5275003463029861, 'Total loss': 0.5275003463029861} | train loss {'Reaction outcome loss': 0.5318398215477506, 'Total loss': 0.5318398215477506}
2022-12-05 23:12:39,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:39,002 INFO:     Epoch: 47
2022-12-05 23:12:39,717 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5337330875071612, 'Total loss': 0.5337330875071612} | train loss {'Reaction outcome loss': 0.5388091864184507, 'Total loss': 0.5388091864184507}
2022-12-05 23:12:39,717 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:39,717 INFO:     Epoch: 48
2022-12-05 23:12:40,436 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.51019506088712, 'Total loss': 0.51019506088712} | train loss {'Reaction outcome loss': 0.5360848635675446, 'Total loss': 0.5360848635675446}
2022-12-05 23:12:40,437 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:40,437 INFO:     Epoch: 49
2022-12-05 23:12:41,156 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5229045183143832, 'Total loss': 0.5229045183143832} | train loss {'Reaction outcome loss': 0.5324479812575925, 'Total loss': 0.5324479812575925}
2022-12-05 23:12:41,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:41,156 INFO:     Epoch: 50
2022-12-05 23:12:41,877 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5232857337052171, 'Total loss': 0.5232857337052171} | train loss {'Reaction outcome loss': 0.53918780218209, 'Total loss': 0.53918780218209}
2022-12-05 23:12:41,878 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:41,878 INFO:     Epoch: 51
2022-12-05 23:12:42,599 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5364079607481306, 'Total loss': 0.5364079607481306} | train loss {'Reaction outcome loss': 0.5362668191232989, 'Total loss': 0.5362668191232989}
2022-12-05 23:12:42,599 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:42,599 INFO:     Epoch: 52
2022-12-05 23:12:43,319 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5089214579625563, 'Total loss': 0.5089214579625563} | train loss {'Reaction outcome loss': 0.5383965980501906, 'Total loss': 0.5383965980501906}
2022-12-05 23:12:43,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:43,320 INFO:     Epoch: 53
2022-12-05 23:12:44,036 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5513734079220078, 'Total loss': 0.5513734079220078} | train loss {'Reaction outcome loss': 0.5369164860176463, 'Total loss': 0.5369164860176463}
2022-12-05 23:12:44,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:44,037 INFO:     Epoch: 54
2022-12-05 23:12:44,753 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5163225135342642, 'Total loss': 0.5163225135342642} | train loss {'Reaction outcome loss': 0.5390781098676305, 'Total loss': 0.5390781098676305}
2022-12-05 23:12:44,753 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:44,753 INFO:     Epoch: 55
2022-12-05 23:12:45,471 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5192139771851626, 'Total loss': 0.5192139771851626} | train loss {'Reaction outcome loss': 0.5332135091265363, 'Total loss': 0.5332135091265363}
2022-12-05 23:12:45,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:45,471 INFO:     Epoch: 56
2022-12-05 23:12:46,196 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.506839198822325, 'Total loss': 0.506839198822325} | train loss {'Reaction outcome loss': 0.534655038087118, 'Total loss': 0.534655038087118}
2022-12-05 23:12:46,196 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:46,196 INFO:     Epoch: 57
2022-12-05 23:12:46,912 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5001405927945267, 'Total loss': 0.5001405927945267} | train loss {'Reaction outcome loss': 0.5389189401701573, 'Total loss': 0.5389189401701573}
2022-12-05 23:12:46,912 INFO:     Found new best model at epoch 57
2022-12-05 23:12:46,913 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:46,913 INFO:     Epoch: 58
2022-12-05 23:12:47,628 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5197660699486732, 'Total loss': 0.5197660699486732} | train loss {'Reaction outcome loss': 0.5367259874699577, 'Total loss': 0.5367259874699577}
2022-12-05 23:12:47,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:47,628 INFO:     Epoch: 59
2022-12-05 23:12:48,343 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5326300757852468, 'Total loss': 0.5326300757852468} | train loss {'Reaction outcome loss': 0.5344655171877915, 'Total loss': 0.5344655171877915}
2022-12-05 23:12:48,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:48,343 INFO:     Epoch: 60
2022-12-05 23:12:49,059 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5112554187124426, 'Total loss': 0.5112554187124426} | train loss {'Reaction outcome loss': 0.531019045881206, 'Total loss': 0.531019045881206}
2022-12-05 23:12:49,059 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:49,059 INFO:     Epoch: 61
2022-12-05 23:12:49,777 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5216141492128372, 'Total loss': 0.5216141492128372} | train loss {'Reaction outcome loss': 0.5363159899509722, 'Total loss': 0.5363159899509722}
2022-12-05 23:12:49,777 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:49,778 INFO:     Epoch: 62
2022-12-05 23:12:50,494 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5137169682844118, 'Total loss': 0.5137169682844118} | train loss {'Reaction outcome loss': 0.5422127868138975, 'Total loss': 0.5422127868138975}
2022-12-05 23:12:50,495 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:50,495 INFO:     Epoch: 63
2022-12-05 23:12:51,216 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5185138061642647, 'Total loss': 0.5185138061642647} | train loss {'Reaction outcome loss': 0.5373729592970302, 'Total loss': 0.5373729592970302}
2022-12-05 23:12:51,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:51,216 INFO:     Epoch: 64
2022-12-05 23:12:51,934 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5440556488253854, 'Total loss': 0.5440556488253854} | train loss {'Reaction outcome loss': 0.5361283185981935, 'Total loss': 0.5361283185981935}
2022-12-05 23:12:51,934 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:51,934 INFO:     Epoch: 65
2022-12-05 23:12:52,653 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5195669531822205, 'Total loss': 0.5195669531822205} | train loss {'Reaction outcome loss': 0.5362206321930693, 'Total loss': 0.5362206321930693}
2022-12-05 23:12:52,653 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:52,654 INFO:     Epoch: 66
2022-12-05 23:12:53,369 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5292163707993247, 'Total loss': 0.5292163707993247} | train loss {'Reaction outcome loss': 0.5335576819376119, 'Total loss': 0.5335576819376119}
2022-12-05 23:12:53,369 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:53,369 INFO:     Epoch: 67
2022-12-05 23:12:54,085 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5383041277527809, 'Total loss': 0.5383041277527809} | train loss {'Reaction outcome loss': 0.536511670016954, 'Total loss': 0.536511670016954}
2022-12-05 23:12:54,085 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:54,085 INFO:     Epoch: 68
2022-12-05 23:12:54,800 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.51526605066928, 'Total loss': 0.51526605066928} | train loss {'Reaction outcome loss': 0.5310567596386517, 'Total loss': 0.5310567596386517}
2022-12-05 23:12:54,801 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:54,801 INFO:     Epoch: 69
2022-12-05 23:12:55,520 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5560629757290537, 'Total loss': 0.5560629757290537} | train loss {'Reaction outcome loss': 0.5332633067042597, 'Total loss': 0.5332633067042597}
2022-12-05 23:12:55,520 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:55,520 INFO:     Epoch: 70
2022-12-05 23:12:56,235 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5156536000696096, 'Total loss': 0.5156536000696096} | train loss {'Reaction outcome loss': 0.5426580244975705, 'Total loss': 0.5426580244975705}
2022-12-05 23:12:56,236 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:56,236 INFO:     Epoch: 71
2022-12-05 23:12:56,951 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5369303487241268, 'Total loss': 0.5369303487241268} | train loss {'Reaction outcome loss': 0.5407511540838787, 'Total loss': 0.5407511540838787}
2022-12-05 23:12:56,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:56,951 INFO:     Epoch: 72
2022-12-05 23:12:57,667 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5395650179548697, 'Total loss': 0.5395650179548697} | train loss {'Reaction outcome loss': 0.5353489244176496, 'Total loss': 0.5353489244176496}
2022-12-05 23:12:57,667 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:57,667 INFO:     Epoch: 73
2022-12-05 23:12:58,386 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5240756876089356, 'Total loss': 0.5240756876089356} | train loss {'Reaction outcome loss': 0.5367672960724561, 'Total loss': 0.5367672960724561}
2022-12-05 23:12:58,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:58,386 INFO:     Epoch: 74
2022-12-05 23:12:59,102 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5407683903520758, 'Total loss': 0.5407683903520758} | train loss {'Reaction outcome loss': 0.5400123197224832, 'Total loss': 0.5400123197224832}
2022-12-05 23:12:59,102 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:59,103 INFO:     Epoch: 75
2022-12-05 23:12:59,824 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5386588641188361, 'Total loss': 0.5386588641188361} | train loss {'Reaction outcome loss': 0.544730288517331, 'Total loss': 0.544730288517331}
2022-12-05 23:12:59,824 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:12:59,824 INFO:     Epoch: 76
2022-12-05 23:13:00,540 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5121453130109743, 'Total loss': 0.5121453130109743} | train loss {'Reaction outcome loss': 0.5332447489302966, 'Total loss': 0.5332447489302966}
2022-12-05 23:13:00,540 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:00,540 INFO:     Epoch: 77
2022-12-05 23:13:01,255 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5154207524928179, 'Total loss': 0.5154207524928179} | train loss {'Reaction outcome loss': 0.5414081763836646, 'Total loss': 0.5414081763836646}
2022-12-05 23:13:01,256 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:01,256 INFO:     Epoch: 78
2022-12-05 23:13:01,973 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5105198818174276, 'Total loss': 0.5105198818174276} | train loss {'Reaction outcome loss': 0.5258641768727572, 'Total loss': 0.5258641768727572}
2022-12-05 23:13:01,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:01,974 INFO:     Epoch: 79
2022-12-05 23:13:02,691 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5281296230175279, 'Total loss': 0.5281296230175279} | train loss {'Reaction outcome loss': 0.5396708298714892, 'Total loss': 0.5396708298714892}
2022-12-05 23:13:02,692 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:02,692 INFO:     Epoch: 80
2022-12-05 23:13:03,414 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5305161513388157, 'Total loss': 0.5305161513388157} | train loss {'Reaction outcome loss': 0.5362105767933592, 'Total loss': 0.5362105767933592}
2022-12-05 23:13:03,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:03,414 INFO:     Epoch: 81
2022-12-05 23:13:04,134 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5362940660931848, 'Total loss': 0.5362940660931848} | train loss {'Reaction outcome loss': 0.5373510088651411, 'Total loss': 0.5373510088651411}
2022-12-05 23:13:04,134 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:04,134 INFO:     Epoch: 82
2022-12-05 23:13:04,851 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5235298841514371, 'Total loss': 0.5235298841514371} | train loss {'Reaction outcome loss': 0.533164179733684, 'Total loss': 0.533164179733684}
2022-12-05 23:13:04,851 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:04,851 INFO:     Epoch: 83
2022-12-05 23:13:05,574 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5111905871467157, 'Total loss': 0.5111905871467157} | train loss {'Reaction outcome loss': 0.5403450795359188, 'Total loss': 0.5403450795359188}
2022-12-05 23:13:05,574 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:05,574 INFO:     Epoch: 84
2022-12-05 23:13:06,299 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5431779115037485, 'Total loss': 0.5431779115037485} | train loss {'Reaction outcome loss': 0.5379697450346523, 'Total loss': 0.5379697450346523}
2022-12-05 23:13:06,299 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:06,299 INFO:     Epoch: 85
2022-12-05 23:13:07,018 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5080919882113283, 'Total loss': 0.5080919882113283} | train loss {'Reaction outcome loss': 0.5407209020829008, 'Total loss': 0.5407209020829008}
2022-12-05 23:13:07,018 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:07,018 INFO:     Epoch: 86
2022-12-05 23:13:07,735 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5513442212885077, 'Total loss': 0.5513442212885077} | train loss {'Reaction outcome loss': 0.5347286169567416, 'Total loss': 0.5347286169567416}
2022-12-05 23:13:07,735 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:07,735 INFO:     Epoch: 87
2022-12-05 23:13:08,455 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5405486497012052, 'Total loss': 0.5405486497012052} | train loss {'Reaction outcome loss': 0.5329227654203292, 'Total loss': 0.5329227654203292}
2022-12-05 23:13:08,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:08,455 INFO:     Epoch: 88
2022-12-05 23:13:09,172 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5243953761052002, 'Total loss': 0.5243953761052002} | train loss {'Reaction outcome loss': 0.5385134576429282, 'Total loss': 0.5385134576429282}
2022-12-05 23:13:09,172 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:09,172 INFO:     Epoch: 89
2022-12-05 23:13:09,889 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5126349329948425, 'Total loss': 0.5126349329948425} | train loss {'Reaction outcome loss': 0.5394711604702377, 'Total loss': 0.5394711604702377}
2022-12-05 23:13:09,889 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:09,889 INFO:     Epoch: 90
2022-12-05 23:13:10,606 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5064536035060883, 'Total loss': 0.5064536035060883} | train loss {'Reaction outcome loss': 0.537462901834759, 'Total loss': 0.537462901834759}
2022-12-05 23:13:10,606 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:10,606 INFO:     Epoch: 91
2022-12-05 23:13:11,328 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5865828516808423, 'Total loss': 0.5865828516808423} | train loss {'Reaction outcome loss': 0.5363327408990552, 'Total loss': 0.5363327408990552}
2022-12-05 23:13:11,328 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:11,328 INFO:     Epoch: 92
2022-12-05 23:13:12,048 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5234329693696715, 'Total loss': 0.5234329693696715} | train loss {'Reaction outcome loss': 0.532820513832473, 'Total loss': 0.532820513832473}
2022-12-05 23:13:12,048 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:12,048 INFO:     Epoch: 93
2022-12-05 23:13:12,764 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.519190483472564, 'Total loss': 0.519190483472564} | train loss {'Reaction outcome loss': 0.536249874940803, 'Total loss': 0.536249874940803}
2022-12-05 23:13:12,765 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:12,765 INFO:     Epoch: 94
2022-12-05 23:13:13,482 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.514438985762271, 'Total loss': 0.514438985762271} | train loss {'Reaction outcome loss': 0.5360585390439918, 'Total loss': 0.5360585390439918}
2022-12-05 23:13:13,482 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:13,482 INFO:     Epoch: 95
2022-12-05 23:13:14,202 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5202294825152918, 'Total loss': 0.5202294825152918} | train loss {'Reaction outcome loss': 0.5365294078064542, 'Total loss': 0.5365294078064542}
2022-12-05 23:13:14,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:14,202 INFO:     Epoch: 96
2022-12-05 23:13:14,924 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5401333204724572, 'Total loss': 0.5401333204724572} | train loss {'Reaction outcome loss': 0.5363351785607876, 'Total loss': 0.5363351785607876}
2022-12-05 23:13:14,924 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:14,924 INFO:     Epoch: 97
2022-12-05 23:13:15,641 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.557322545485063, 'Total loss': 0.557322545485063} | train loss {'Reaction outcome loss': 0.5337832412051577, 'Total loss': 0.5337832412051577}
2022-12-05 23:13:15,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:15,642 INFO:     Epoch: 98
2022-12-05 23:13:16,365 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5343121909959749, 'Total loss': 0.5343121909959749} | train loss {'Reaction outcome loss': 0.537182837965027, 'Total loss': 0.537182837965027}
2022-12-05 23:13:16,365 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:16,365 INFO:     Epoch: 99
2022-12-05 23:13:17,080 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5245371599766341, 'Total loss': 0.5245371599766341} | train loss {'Reaction outcome loss': 0.5394353104695198, 'Total loss': 0.5394353104695198}
2022-12-05 23:13:17,080 INFO:     Best model found after epoch 58 of 100.
2022-12-05 23:13:17,080 INFO:   Done with stage: TRAINING
2022-12-05 23:13:17,080 INFO:   Starting stage: EVALUATION
2022-12-05 23:13:17,198 INFO:   Done with stage: EVALUATION
2022-12-05 23:13:17,199 INFO:   Leaving out SEQ value Fold_7
2022-12-05 23:13:17,211 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 23:13:17,211 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:13:17,846 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:13:17,847 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:13:17,918 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:13:17,918 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:13:17,918 INFO:     No hyperparam tuning for this model
2022-12-05 23:13:17,918 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:13:17,918 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:13:17,919 INFO:     None feature selector for col prot
2022-12-05 23:13:17,919 INFO:     None feature selector for col prot
2022-12-05 23:13:17,919 INFO:     None feature selector for col prot
2022-12-05 23:13:17,919 INFO:     None feature selector for col chem
2022-12-05 23:13:17,920 INFO:     None feature selector for col chem
2022-12-05 23:13:17,920 INFO:     None feature selector for col chem
2022-12-05 23:13:17,920 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:13:17,920 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:13:17,921 INFO:     Number of params in model 215731
2022-12-05 23:13:17,925 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:13:17,925 INFO:   Starting stage: TRAINING
2022-12-05 23:13:17,983 INFO:     Val loss before train {'Reaction outcome loss': 1.0332310457121243, 'Total loss': 1.0332310457121243}
2022-12-05 23:13:17,983 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:17,983 INFO:     Epoch: 0
2022-12-05 23:13:18,691 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6924459582025354, 'Total loss': 0.6924459582025354} | train loss {'Reaction outcome loss': 0.8073107038225447, 'Total loss': 0.8073107038225447}
2022-12-05 23:13:18,691 INFO:     Found new best model at epoch 0
2022-12-05 23:13:18,692 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:18,692 INFO:     Epoch: 1
2022-12-05 23:13:19,400 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6345445303754373, 'Total loss': 0.6345445303754373} | train loss {'Reaction outcome loss': 0.6627138205936977, 'Total loss': 0.6627138205936977}
2022-12-05 23:13:19,400 INFO:     Found new best model at epoch 1
2022-12-05 23:13:19,401 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:19,401 INFO:     Epoch: 2
2022-12-05 23:13:20,114 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.601814944635738, 'Total loss': 0.601814944635738} | train loss {'Reaction outcome loss': 0.6222114179815564, 'Total loss': 0.6222114179815564}
2022-12-05 23:13:20,114 INFO:     Found new best model at epoch 2
2022-12-05 23:13:20,115 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:20,115 INFO:     Epoch: 3
2022-12-05 23:13:20,820 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5926818028092384, 'Total loss': 0.5926818028092384} | train loss {'Reaction outcome loss': 0.6017777387584958, 'Total loss': 0.6017777387584958}
2022-12-05 23:13:20,820 INFO:     Found new best model at epoch 3
2022-12-05 23:13:20,821 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:20,821 INFO:     Epoch: 4
2022-12-05 23:13:21,528 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.580953564833511, 'Total loss': 0.580953564833511} | train loss {'Reaction outcome loss': 0.5800225269429538, 'Total loss': 0.5800225269429538}
2022-12-05 23:13:21,528 INFO:     Found new best model at epoch 4
2022-12-05 23:13:21,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:21,528 INFO:     Epoch: 5
2022-12-05 23:13:22,231 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5647341273725033, 'Total loss': 0.5647341273725033} | train loss {'Reaction outcome loss': 0.5831606836951508, 'Total loss': 0.5831606836951508}
2022-12-05 23:13:22,232 INFO:     Found new best model at epoch 5
2022-12-05 23:13:22,232 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:22,232 INFO:     Epoch: 6
2022-12-05 23:13:22,937 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5847341269254684, 'Total loss': 0.5847341269254684} | train loss {'Reaction outcome loss': 0.5749148152312454, 'Total loss': 0.5749148152312454}
2022-12-05 23:13:22,937 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:22,937 INFO:     Epoch: 7
2022-12-05 23:13:23,641 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5504911203276027, 'Total loss': 0.5504911203276027} | train loss {'Reaction outcome loss': 0.5676042976428052, 'Total loss': 0.5676042976428052}
2022-12-05 23:13:23,641 INFO:     Found new best model at epoch 7
2022-12-05 23:13:23,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:23,642 INFO:     Epoch: 8
2022-12-05 23:13:24,344 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5577445995401252, 'Total loss': 0.5577445995401252} | train loss {'Reaction outcome loss': 0.5576929998032901, 'Total loss': 0.5576929998032901}
2022-12-05 23:13:24,344 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:24,344 INFO:     Epoch: 9
2022-12-05 23:13:25,048 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5430283422835849, 'Total loss': 0.5430283422835849} | train loss {'Reaction outcome loss': 0.5597822731246753, 'Total loss': 0.5597822731246753}
2022-12-05 23:13:25,048 INFO:     Found new best model at epoch 9
2022-12-05 23:13:25,048 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:25,049 INFO:     Epoch: 10
2022-12-05 23:13:25,754 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5453222224658186, 'Total loss': 0.5453222224658186} | train loss {'Reaction outcome loss': 0.5574158304808091, 'Total loss': 0.5574158304808091}
2022-12-05 23:13:25,754 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:25,754 INFO:     Epoch: 11
2022-12-05 23:13:26,466 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5567399791695855, 'Total loss': 0.5567399791695855} | train loss {'Reaction outcome loss': 0.553949027037134, 'Total loss': 0.553949027037134}
2022-12-05 23:13:26,467 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:26,467 INFO:     Epoch: 12
2022-12-05 23:13:27,172 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.616617965427312, 'Total loss': 0.616617965427312} | train loss {'Reaction outcome loss': 0.5443447659818493, 'Total loss': 0.5443447659818493}
2022-12-05 23:13:27,172 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:27,172 INFO:     Epoch: 13
2022-12-05 23:13:27,876 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5615270611914721, 'Total loss': 0.5615270611914721} | train loss {'Reaction outcome loss': 0.5507706513210219, 'Total loss': 0.5507706513210219}
2022-12-05 23:13:27,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:27,876 INFO:     Epoch: 14
2022-12-05 23:13:28,580 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5791858813979409, 'Total loss': 0.5791858813979409} | train loss {'Reaction outcome loss': 0.549103195448311, 'Total loss': 0.549103195448311}
2022-12-05 23:13:28,580 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:28,580 INFO:     Epoch: 15
2022-12-05 23:13:29,287 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5499724820256233, 'Total loss': 0.5499724820256233} | train loss {'Reaction outcome loss': 0.5467072447343748, 'Total loss': 0.5467072447343748}
2022-12-05 23:13:29,288 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:29,288 INFO:     Epoch: 16
2022-12-05 23:13:29,995 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5568235557187687, 'Total loss': 0.5568235557187687} | train loss {'Reaction outcome loss': 0.5411408526556832, 'Total loss': 0.5411408526556832}
2022-12-05 23:13:29,995 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:29,995 INFO:     Epoch: 17
2022-12-05 23:13:30,703 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5298082493245602, 'Total loss': 0.5298082493245602} | train loss {'Reaction outcome loss': 0.5468855726475619, 'Total loss': 0.5468855726475619}
2022-12-05 23:13:30,703 INFO:     Found new best model at epoch 17
2022-12-05 23:13:30,704 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:30,704 INFO:     Epoch: 18
2022-12-05 23:13:31,408 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5518877245485783, 'Total loss': 0.5518877245485783} | train loss {'Reaction outcome loss': 0.5341699100878774, 'Total loss': 0.5341699100878774}
2022-12-05 23:13:31,408 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:31,408 INFO:     Epoch: 19
2022-12-05 23:13:32,113 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5506874305958097, 'Total loss': 0.5506874305958097} | train loss {'Reaction outcome loss': 0.5503345400703197, 'Total loss': 0.5503345400703197}
2022-12-05 23:13:32,113 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:32,114 INFO:     Epoch: 20
2022-12-05 23:13:32,818 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5426360284062949, 'Total loss': 0.5426360284062949} | train loss {'Reaction outcome loss': 0.5446692902214673, 'Total loss': 0.5446692902214673}
2022-12-05 23:13:32,818 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:32,819 INFO:     Epoch: 21
2022-12-05 23:13:33,524 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5628229305148125, 'Total loss': 0.5628229305148125} | train loss {'Reaction outcome loss': 0.5443165173335951, 'Total loss': 0.5443165173335951}
2022-12-05 23:13:33,524 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:33,524 INFO:     Epoch: 22
2022-12-05 23:13:34,226 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5432986688207496, 'Total loss': 0.5432986688207496} | train loss {'Reaction outcome loss': 0.5385060554256245, 'Total loss': 0.5385060554256245}
2022-12-05 23:13:34,226 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:34,226 INFO:     Epoch: 23
2022-12-05 23:13:34,929 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5433831661939621, 'Total loss': 0.5433831661939621} | train loss {'Reaction outcome loss': 0.5398892390484713, 'Total loss': 0.5398892390484713}
2022-12-05 23:13:34,930 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:34,930 INFO:     Epoch: 24
2022-12-05 23:13:35,634 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5244793241674249, 'Total loss': 0.5244793241674249} | train loss {'Reaction outcome loss': 0.5390287789155026, 'Total loss': 0.5390287789155026}
2022-12-05 23:13:35,635 INFO:     Found new best model at epoch 24
2022-12-05 23:13:35,635 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:35,635 INFO:     Epoch: 25
2022-12-05 23:13:36,346 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5620187263597142, 'Total loss': 0.5620187263597142} | train loss {'Reaction outcome loss': 0.5449310628127079, 'Total loss': 0.5449310628127079}
2022-12-05 23:13:36,346 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:36,346 INFO:     Epoch: 26
2022-12-05 23:13:37,052 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5419855554672804, 'Total loss': 0.5419855554672804} | train loss {'Reaction outcome loss': 0.5338113054937246, 'Total loss': 0.5338113054937246}
2022-12-05 23:13:37,052 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:37,053 INFO:     Epoch: 27
2022-12-05 23:13:37,761 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.6014847565780986, 'Total loss': 0.6014847565780986} | train loss {'Reaction outcome loss': 0.5355606967697338, 'Total loss': 0.5355606967697338}
2022-12-05 23:13:37,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:37,761 INFO:     Epoch: 28
2022-12-05 23:13:38,469 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5344453203407201, 'Total loss': 0.5344453203407201} | train loss {'Reaction outcome loss': 0.5408568806794225, 'Total loss': 0.5408568806794225}
2022-12-05 23:13:38,469 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:38,469 INFO:     Epoch: 29
2022-12-05 23:13:39,177 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.57530122555115, 'Total loss': 0.57530122555115} | train loss {'Reaction outcome loss': 0.5393758207559586, 'Total loss': 0.5393758207559586}
2022-12-05 23:13:39,177 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:39,177 INFO:     Epoch: 30
2022-12-05 23:13:39,882 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5359436981379986, 'Total loss': 0.5359436981379986} | train loss {'Reaction outcome loss': 0.5347689546492636, 'Total loss': 0.5347689546492636}
2022-12-05 23:13:39,882 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:39,882 INFO:     Epoch: 31
2022-12-05 23:13:40,588 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5486888113346967, 'Total loss': 0.5486888113346967} | train loss {'Reaction outcome loss': 0.5377500658740803, 'Total loss': 0.5377500658740803}
2022-12-05 23:13:40,588 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:40,588 INFO:     Epoch: 32
2022-12-05 23:13:41,295 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5827632790262048, 'Total loss': 0.5827632790262048} | train loss {'Reaction outcome loss': 0.5350772945248351, 'Total loss': 0.5350772945248351}
2022-12-05 23:13:41,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:41,296 INFO:     Epoch: 33
2022-12-05 23:13:42,001 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.552866016599265, 'Total loss': 0.552866016599265} | train loss {'Reaction outcome loss': 0.5274931869944748, 'Total loss': 0.5274931869944748}
2022-12-05 23:13:42,001 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:42,001 INFO:     Epoch: 34
2022-12-05 23:13:42,710 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.54491852698001, 'Total loss': 0.54491852698001} | train loss {'Reaction outcome loss': 0.5361997752165307, 'Total loss': 0.5361997752165307}
2022-12-05 23:13:42,711 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:42,711 INFO:     Epoch: 35
2022-12-05 23:13:43,421 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5776284489442002, 'Total loss': 0.5776284489442002} | train loss {'Reaction outcome loss': 0.5353804483097426, 'Total loss': 0.5353804483097426}
2022-12-05 23:13:43,421 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:43,421 INFO:     Epoch: 36
2022-12-05 23:13:44,134 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5660114156251604, 'Total loss': 0.5660114156251604} | train loss {'Reaction outcome loss': 0.5358087154067293, 'Total loss': 0.5358087154067293}
2022-12-05 23:13:44,134 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:44,134 INFO:     Epoch: 37
2022-12-05 23:13:44,843 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5525760857219045, 'Total loss': 0.5525760857219045} | train loss {'Reaction outcome loss': 0.5353590151485131, 'Total loss': 0.5353590151485131}
2022-12-05 23:13:44,843 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:44,843 INFO:     Epoch: 38
2022-12-05 23:13:45,554 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5280899554491043, 'Total loss': 0.5280899554491043} | train loss {'Reaction outcome loss': 0.5301660264024929, 'Total loss': 0.5301660264024929}
2022-12-05 23:13:45,554 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:45,554 INFO:     Epoch: 39
2022-12-05 23:13:46,265 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.563738463954492, 'Total loss': 0.563738463954492} | train loss {'Reaction outcome loss': 0.530938194357619, 'Total loss': 0.530938194357619}
2022-12-05 23:13:46,267 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:46,267 INFO:     Epoch: 40
2022-12-05 23:13:46,971 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5343981588428671, 'Total loss': 0.5343981588428671} | train loss {'Reaction outcome loss': 0.5286303580415492, 'Total loss': 0.5286303580415492}
2022-12-05 23:13:46,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:46,971 INFO:     Epoch: 41
2022-12-05 23:13:47,681 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5573524924164469, 'Total loss': 0.5573524924164469} | train loss {'Reaction outcome loss': 0.5231502792056726, 'Total loss': 0.5231502792056726}
2022-12-05 23:13:47,681 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:47,681 INFO:     Epoch: 42
2022-12-05 23:13:48,393 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5405644185163758, 'Total loss': 0.5405644185163758} | train loss {'Reaction outcome loss': 0.5340112407596744, 'Total loss': 0.5340112407596744}
2022-12-05 23:13:48,393 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:48,393 INFO:     Epoch: 43
2022-12-05 23:13:49,098 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5337563766674562, 'Total loss': 0.5337563766674562} | train loss {'Reaction outcome loss': 0.5279353726883323, 'Total loss': 0.5279353726883323}
2022-12-05 23:13:49,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:49,098 INFO:     Epoch: 44
2022-12-05 23:13:49,809 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5320247117091309, 'Total loss': 0.5320247117091309} | train loss {'Reaction outcome loss': 0.5259745036460916, 'Total loss': 0.5259745036460916}
2022-12-05 23:13:49,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:49,809 INFO:     Epoch: 45
2022-12-05 23:13:50,522 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5243056839839979, 'Total loss': 0.5243056839839979} | train loss {'Reaction outcome loss': 0.5319651821438147, 'Total loss': 0.5319651821438147}
2022-12-05 23:13:50,523 INFO:     Found new best model at epoch 45
2022-12-05 23:13:50,523 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:50,523 INFO:     Epoch: 46
2022-12-05 23:13:51,228 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5292085602202199, 'Total loss': 0.5292085602202199} | train loss {'Reaction outcome loss': 0.5281383862300795, 'Total loss': 0.5281383862300795}
2022-12-05 23:13:51,228 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:51,228 INFO:     Epoch: 47
2022-12-05 23:13:51,932 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5385623269460418, 'Total loss': 0.5385623269460418} | train loss {'Reaction outcome loss': 0.5321556310872643, 'Total loss': 0.5321556310872643}
2022-12-05 23:13:51,932 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:51,932 INFO:     Epoch: 48
2022-12-05 23:13:52,639 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5469547794623808, 'Total loss': 0.5469547794623808} | train loss {'Reaction outcome loss': 0.5270792079215147, 'Total loss': 0.5270792079215147}
2022-12-05 23:13:52,640 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:52,640 INFO:     Epoch: 49
2022-12-05 23:13:53,346 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5505413609472188, 'Total loss': 0.5505413609472188} | train loss {'Reaction outcome loss': 0.5201358628516295, 'Total loss': 0.5201358628516295}
2022-12-05 23:13:53,346 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:53,346 INFO:     Epoch: 50
2022-12-05 23:13:54,054 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5167229883372784, 'Total loss': 0.5167229883372784} | train loss {'Reaction outcome loss': 0.5264965845614064, 'Total loss': 0.5264965845614064}
2022-12-05 23:13:54,054 INFO:     Found new best model at epoch 50
2022-12-05 23:13:54,055 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:54,055 INFO:     Epoch: 51
2022-12-05 23:13:54,760 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.554433020001108, 'Total loss': 0.554433020001108} | train loss {'Reaction outcome loss': 0.5247451857036474, 'Total loss': 0.5247451857036474}
2022-12-05 23:13:54,760 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:54,760 INFO:     Epoch: 52
2022-12-05 23:13:55,464 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5308604264123873, 'Total loss': 0.5308604264123873} | train loss {'Reaction outcome loss': 0.5303921026842935, 'Total loss': 0.5303921026842935}
2022-12-05 23:13:55,464 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:55,464 INFO:     Epoch: 53
2022-12-05 23:13:56,168 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.507470306347717, 'Total loss': 0.507470306347717} | train loss {'Reaction outcome loss': 0.5249746590244527, 'Total loss': 0.5249746590244527}
2022-12-05 23:13:56,168 INFO:     Found new best model at epoch 53
2022-12-05 23:13:56,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:56,168 INFO:     Epoch: 54
2022-12-05 23:13:56,870 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5584948060568422, 'Total loss': 0.5584948060568422} | train loss {'Reaction outcome loss': 0.525067953005129, 'Total loss': 0.525067953005129}
2022-12-05 23:13:56,871 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:56,871 INFO:     Epoch: 55
2022-12-05 23:13:57,577 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5481774854389104, 'Total loss': 0.5481774854389104} | train loss {'Reaction outcome loss': 0.5229933492991389, 'Total loss': 0.5229933492991389}
2022-12-05 23:13:57,577 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:57,577 INFO:     Epoch: 56
2022-12-05 23:13:58,286 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5961731387810274, 'Total loss': 0.5961731387810274} | train loss {'Reaction outcome loss': 0.5260510276774971, 'Total loss': 0.5260510276774971}
2022-12-05 23:13:58,286 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:58,286 INFO:     Epoch: 57
2022-12-05 23:13:58,993 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5484092834998261, 'Total loss': 0.5484092834998261} | train loss {'Reaction outcome loss': 0.5319324869890603, 'Total loss': 0.5319324869890603}
2022-12-05 23:13:58,994 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:58,994 INFO:     Epoch: 58
2022-12-05 23:13:59,697 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5355456004088576, 'Total loss': 0.5355456004088576} | train loss {'Reaction outcome loss': 0.5283253326707956, 'Total loss': 0.5283253326707956}
2022-12-05 23:13:59,698 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:13:59,698 INFO:     Epoch: 59
2022-12-05 23:14:00,402 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5651657768440518, 'Total loss': 0.5651657768440518} | train loss {'Reaction outcome loss': 0.5282467728974868, 'Total loss': 0.5282467728974868}
2022-12-05 23:14:00,402 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:00,402 INFO:     Epoch: 60
2022-12-05 23:14:01,108 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5166873793033037, 'Total loss': 0.5166873793033037} | train loss {'Reaction outcome loss': 0.5338630448798745, 'Total loss': 0.5338630448798745}
2022-12-05 23:14:01,108 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:01,108 INFO:     Epoch: 61
2022-12-05 23:14:01,812 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5384084622968327, 'Total loss': 0.5384084622968327} | train loss {'Reaction outcome loss': 0.5260847696844413, 'Total loss': 0.5260847696844413}
2022-12-05 23:14:01,812 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:01,812 INFO:     Epoch: 62
2022-12-05 23:14:02,520 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5422232753851197, 'Total loss': 0.5422232753851197} | train loss {'Reaction outcome loss': 0.5278429051443022, 'Total loss': 0.5278429051443022}
2022-12-05 23:14:02,521 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:02,521 INFO:     Epoch: 63
2022-12-05 23:14:03,225 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5499669062820348, 'Total loss': 0.5499669062820348} | train loss {'Reaction outcome loss': 0.5270288913833852, 'Total loss': 0.5270288913833852}
2022-12-05 23:14:03,225 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:03,226 INFO:     Epoch: 64
2022-12-05 23:14:03,934 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5225442824038592, 'Total loss': 0.5225442824038592} | train loss {'Reaction outcome loss': 0.5176963678428105, 'Total loss': 0.5176963678428105}
2022-12-05 23:14:03,934 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:03,934 INFO:     Epoch: 65
2022-12-05 23:14:04,641 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.522376839410175, 'Total loss': 0.522376839410175} | train loss {'Reaction outcome loss': 0.5334520277320122, 'Total loss': 0.5334520277320122}
2022-12-05 23:14:04,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:04,642 INFO:     Epoch: 66
2022-12-05 23:14:05,347 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.545021996579387, 'Total loss': 0.545021996579387} | train loss {'Reaction outcome loss': 0.5251678173031126, 'Total loss': 0.5251678173031126}
2022-12-05 23:14:05,347 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:05,347 INFO:     Epoch: 67
2022-12-05 23:14:06,055 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5267254012552175, 'Total loss': 0.5267254012552175} | train loss {'Reaction outcome loss': 0.520413710815566, 'Total loss': 0.520413710815566}
2022-12-05 23:14:06,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:06,056 INFO:     Epoch: 68
2022-12-05 23:14:06,762 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5246839259158481, 'Total loss': 0.5246839259158481} | train loss {'Reaction outcome loss': 0.528424013390833, 'Total loss': 0.528424013390833}
2022-12-05 23:14:06,762 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:06,762 INFO:     Epoch: 69
2022-12-05 23:14:07,469 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.528152924369682, 'Total loss': 0.528152924369682} | train loss {'Reaction outcome loss': 0.5258060844577088, 'Total loss': 0.5258060844577088}
2022-12-05 23:14:07,469 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:07,469 INFO:     Epoch: 70
2022-12-05 23:14:08,176 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.606394574046135, 'Total loss': 0.606394574046135} | train loss {'Reaction outcome loss': 0.5254012452704566, 'Total loss': 0.5254012452704566}
2022-12-05 23:14:08,177 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:08,177 INFO:     Epoch: 71
2022-12-05 23:14:08,880 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5552714849737558, 'Total loss': 0.5552714849737558} | train loss {'Reaction outcome loss': 0.530485964612085, 'Total loss': 0.530485964612085}
2022-12-05 23:14:08,881 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:08,881 INFO:     Epoch: 72
2022-12-05 23:14:09,587 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5151247605681419, 'Total loss': 0.5151247605681419} | train loss {'Reaction outcome loss': 0.5304591107125185, 'Total loss': 0.5304591107125185}
2022-12-05 23:14:09,587 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:09,588 INFO:     Epoch: 73
2022-12-05 23:14:10,296 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5777124857360666, 'Total loss': 0.5777124857360666} | train loss {'Reaction outcome loss': 0.5254243177418806, 'Total loss': 0.5254243177418806}
2022-12-05 23:14:10,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:10,296 INFO:     Epoch: 74
2022-12-05 23:14:11,002 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.529594576832923, 'Total loss': 0.529594576832923} | train loss {'Reaction outcome loss': 0.5274468218793674, 'Total loss': 0.5274468218793674}
2022-12-05 23:14:11,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:11,002 INFO:     Epoch: 75
2022-12-05 23:14:11,707 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5236813216046854, 'Total loss': 0.5236813216046854} | train loss {'Reaction outcome loss': 0.5251414210212474, 'Total loss': 0.5251414210212474}
2022-12-05 23:14:11,707 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:11,707 INFO:     Epoch: 76
2022-12-05 23:14:12,414 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5148443139412187, 'Total loss': 0.5148443139412187} | train loss {'Reaction outcome loss': 0.5238763171191119, 'Total loss': 0.5238763171191119}
2022-12-05 23:14:12,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:12,414 INFO:     Epoch: 77
2022-12-05 23:14:13,118 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5448778854175047, 'Total loss': 0.5448778854175047} | train loss {'Reaction outcome loss': 0.5186338017181474, 'Total loss': 0.5186338017181474}
2022-12-05 23:14:13,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:13,119 INFO:     Epoch: 78
2022-12-05 23:14:13,825 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5200032165104692, 'Total loss': 0.5200032165104692} | train loss {'Reaction outcome loss': 0.5283268254022209, 'Total loss': 0.5283268254022209}
2022-12-05 23:14:13,825 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:13,825 INFO:     Epoch: 79
2022-12-05 23:14:14,530 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5558723319660533, 'Total loss': 0.5558723319660533} | train loss {'Reaction outcome loss': 0.5216761750226118, 'Total loss': 0.5216761750226118}
2022-12-05 23:14:14,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:14,530 INFO:     Epoch: 80
2022-12-05 23:14:15,235 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.555390826003118, 'Total loss': 0.555390826003118} | train loss {'Reaction outcome loss': 0.5243999205681742, 'Total loss': 0.5243999205681742}
2022-12-05 23:14:15,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:15,235 INFO:     Epoch: 81
2022-12-05 23:14:15,941 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5885336744514379, 'Total loss': 0.5885336744514379} | train loss {'Reaction outcome loss': 0.5252750795106499, 'Total loss': 0.5252750795106499}
2022-12-05 23:14:15,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:15,941 INFO:     Epoch: 82
2022-12-05 23:14:16,646 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.637378794903105, 'Total loss': 0.637378794903105} | train loss {'Reaction outcome loss': 0.5195971807046812, 'Total loss': 0.5195971807046812}
2022-12-05 23:14:16,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:16,647 INFO:     Epoch: 83
2022-12-05 23:14:17,350 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5368504063649611, 'Total loss': 0.5368504063649611} | train loss {'Reaction outcome loss': 0.5282217047044209, 'Total loss': 0.5282217047044209}
2022-12-05 23:14:17,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:17,350 INFO:     Epoch: 84
2022-12-05 23:14:18,053 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5094286735084924, 'Total loss': 0.5094286735084924} | train loss {'Reaction outcome loss': 0.5281003465457839, 'Total loss': 0.5281003465457839}
2022-12-05 23:14:18,054 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:18,054 INFO:     Epoch: 85
2022-12-05 23:14:18,759 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5212159844284708, 'Total loss': 0.5212159844284708} | train loss {'Reaction outcome loss': 0.525255232380361, 'Total loss': 0.525255232380361}
2022-12-05 23:14:18,759 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:18,759 INFO:     Epoch: 86
2022-12-05 23:14:19,466 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5136401470411908, 'Total loss': 0.5136401470411908} | train loss {'Reaction outcome loss': 0.5338925890168366, 'Total loss': 0.5338925890168366}
2022-12-05 23:14:19,466 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:19,466 INFO:     Epoch: 87
2022-12-05 23:14:20,176 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5785560662096197, 'Total loss': 0.5785560662096197} | train loss {'Reaction outcome loss': 0.5230860009485362, 'Total loss': 0.5230860009485362}
2022-12-05 23:14:20,176 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:20,176 INFO:     Epoch: 88
2022-12-05 23:14:20,884 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5280717597766356, 'Total loss': 0.5280717597766356} | train loss {'Reaction outcome loss': 0.5302815891650259, 'Total loss': 0.5302815891650259}
2022-12-05 23:14:20,884 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:20,884 INFO:     Epoch: 89
2022-12-05 23:14:21,592 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5265115946531296, 'Total loss': 0.5265115946531296} | train loss {'Reaction outcome loss': 0.5326171665775533, 'Total loss': 0.5326171665775533}
2022-12-05 23:14:21,592 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:21,592 INFO:     Epoch: 90
2022-12-05 23:14:22,301 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5512174340811643, 'Total loss': 0.5512174340811643} | train loss {'Reaction outcome loss': 0.5291425659340255, 'Total loss': 0.5291425659340255}
2022-12-05 23:14:22,302 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:22,302 INFO:     Epoch: 91
2022-12-05 23:14:23,007 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5447832285003229, 'Total loss': 0.5447832285003229} | train loss {'Reaction outcome loss': 0.5319784377910652, 'Total loss': 0.5319784377910652}
2022-12-05 23:14:23,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:23,008 INFO:     Epoch: 92
2022-12-05 23:14:23,715 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5410005775364962, 'Total loss': 0.5410005775364962} | train loss {'Reaction outcome loss': 0.5271941836391176, 'Total loss': 0.5271941836391176}
2022-12-05 23:14:23,716 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:23,716 INFO:     Epoch: 93
2022-12-05 23:14:24,428 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5042803023349155, 'Total loss': 0.5042803023349155} | train loss {'Reaction outcome loss': 0.5297138666011849, 'Total loss': 0.5297138666011849}
2022-12-05 23:14:24,428 INFO:     Found new best model at epoch 93
2022-12-05 23:14:24,429 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:24,429 INFO:     Epoch: 94
2022-12-05 23:14:25,140 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.54982413622466, 'Total loss': 0.54982413622466} | train loss {'Reaction outcome loss': 0.5264154575308975, 'Total loss': 0.5264154575308975}
2022-12-05 23:14:25,140 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:25,140 INFO:     Epoch: 95
2022-12-05 23:14:25,852 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5414214100350033, 'Total loss': 0.5414214100350033} | train loss {'Reaction outcome loss': 0.5264553046956354, 'Total loss': 0.5264553046956354}
2022-12-05 23:14:25,853 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:25,853 INFO:     Epoch: 96
2022-12-05 23:14:26,563 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5450651737099345, 'Total loss': 0.5450651737099345} | train loss {'Reaction outcome loss': 0.5211085934420021, 'Total loss': 0.5211085934420021}
2022-12-05 23:14:26,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:26,563 INFO:     Epoch: 97
2022-12-05 23:14:27,275 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5243003781546246, 'Total loss': 0.5243003781546246} | train loss {'Reaction outcome loss': 0.5303038353214459, 'Total loss': 0.5303038353214459}
2022-12-05 23:14:27,275 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:27,275 INFO:     Epoch: 98
2022-12-05 23:14:27,987 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.516132847151973, 'Total loss': 0.516132847151973} | train loss {'Reaction outcome loss': 0.5271214940110032, 'Total loss': 0.5271214940110032}
2022-12-05 23:14:27,987 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:27,987 INFO:     Epoch: 99
2022-12-05 23:14:28,697 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5611685527996584, 'Total loss': 0.5611685527996584} | train loss {'Reaction outcome loss': 0.5214463569984145, 'Total loss': 0.5214463569984145}
2022-12-05 23:14:28,697 INFO:     Best model found after epoch 94 of 100.
2022-12-05 23:14:28,698 INFO:   Done with stage: TRAINING
2022-12-05 23:14:28,698 INFO:   Starting stage: EVALUATION
2022-12-05 23:14:28,827 INFO:   Done with stage: EVALUATION
2022-12-05 23:14:28,827 INFO:   Leaving out SEQ value Fold_8
2022-12-05 23:14:28,840 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:14:28,840 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:14:29,477 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:14:29,478 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:14:29,548 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:14:29,548 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:14:29,548 INFO:     No hyperparam tuning for this model
2022-12-05 23:14:29,548 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:14:29,548 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:14:29,549 INFO:     None feature selector for col prot
2022-12-05 23:14:29,549 INFO:     None feature selector for col prot
2022-12-05 23:14:29,549 INFO:     None feature selector for col prot
2022-12-05 23:14:29,550 INFO:     None feature selector for col chem
2022-12-05 23:14:29,550 INFO:     None feature selector for col chem
2022-12-05 23:14:29,550 INFO:     None feature selector for col chem
2022-12-05 23:14:29,550 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:14:29,550 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:14:29,551 INFO:     Number of params in model 215731
2022-12-05 23:14:29,555 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:14:29,555 INFO:   Starting stage: TRAINING
2022-12-05 23:14:29,613 INFO:     Val loss before train {'Reaction outcome loss': 0.9801084494048898, 'Total loss': 0.9801084494048898}
2022-12-05 23:14:29,613 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:29,613 INFO:     Epoch: 0
2022-12-05 23:14:30,326 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6792571341449564, 'Total loss': 0.6792571341449564} | train loss {'Reaction outcome loss': 0.8248545710117586, 'Total loss': 0.8248545710117586}
2022-12-05 23:14:30,326 INFO:     Found new best model at epoch 0
2022-12-05 23:14:30,327 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:30,327 INFO:     Epoch: 1
2022-12-05 23:14:31,036 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6610111736438491, 'Total loss': 0.6610111736438491} | train loss {'Reaction outcome loss': 0.7011892782343973, 'Total loss': 0.7011892782343973}
2022-12-05 23:14:31,036 INFO:     Found new best model at epoch 1
2022-12-05 23:14:31,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:31,037 INFO:     Epoch: 2
2022-12-05 23:14:31,747 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5822150456634435, 'Total loss': 0.5822150456634435} | train loss {'Reaction outcome loss': 0.6393725256766042, 'Total loss': 0.6393725256766042}
2022-12-05 23:14:31,747 INFO:     Found new best model at epoch 2
2022-12-05 23:14:31,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:31,748 INFO:     Epoch: 3
2022-12-05 23:14:32,462 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5561471236023036, 'Total loss': 0.5561471236023036} | train loss {'Reaction outcome loss': 0.606769341134256, 'Total loss': 0.606769341134256}
2022-12-05 23:14:32,463 INFO:     Found new best model at epoch 3
2022-12-05 23:14:32,463 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:32,463 INFO:     Epoch: 4
2022-12-05 23:14:33,172 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5761810161850669, 'Total loss': 0.5761810161850669} | train loss {'Reaction outcome loss': 0.5821699502487336, 'Total loss': 0.5821699502487336}
2022-12-05 23:14:33,173 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:33,173 INFO:     Epoch: 5
2022-12-05 23:14:33,882 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5440770556980913, 'Total loss': 0.5440770556980913} | train loss {'Reaction outcome loss': 0.5740943364799023, 'Total loss': 0.5740943364799023}
2022-12-05 23:14:33,882 INFO:     Found new best model at epoch 5
2022-12-05 23:14:33,882 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:33,883 INFO:     Epoch: 6
2022-12-05 23:14:34,593 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.543334889140996, 'Total loss': 0.543334889140996} | train loss {'Reaction outcome loss': 0.5694994165772392, 'Total loss': 0.5694994165772392}
2022-12-05 23:14:34,594 INFO:     Found new best model at epoch 6
2022-12-05 23:14:34,594 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:34,594 INFO:     Epoch: 7
2022-12-05 23:14:35,305 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5351311950521036, 'Total loss': 0.5351311950521036} | train loss {'Reaction outcome loss': 0.5609324636358407, 'Total loss': 0.5609324636358407}
2022-12-05 23:14:35,306 INFO:     Found new best model at epoch 7
2022-12-05 23:14:35,307 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:35,307 INFO:     Epoch: 8
2022-12-05 23:14:36,019 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5330728468569842, 'Total loss': 0.5330728468569842} | train loss {'Reaction outcome loss': 0.5553527880580195, 'Total loss': 0.5553527880580195}
2022-12-05 23:14:36,019 INFO:     Found new best model at epoch 8
2022-12-05 23:14:36,019 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:36,019 INFO:     Epoch: 9
2022-12-05 23:14:36,731 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5298192477361723, 'Total loss': 0.5298192477361723} | train loss {'Reaction outcome loss': 0.5459569853640371, 'Total loss': 0.5459569853640371}
2022-12-05 23:14:36,732 INFO:     Found new best model at epoch 9
2022-12-05 23:14:36,732 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:36,732 INFO:     Epoch: 10
2022-12-05 23:14:37,444 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.537086813964627, 'Total loss': 0.537086813964627} | train loss {'Reaction outcome loss': 0.5435375743094952, 'Total loss': 0.5435375743094952}
2022-12-05 23:14:37,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:37,444 INFO:     Epoch: 11
2022-12-05 23:14:38,158 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.530893241817301, 'Total loss': 0.530893241817301} | train loss {'Reaction outcome loss': 0.5466022390511728, 'Total loss': 0.5466022390511728}
2022-12-05 23:14:38,158 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:38,158 INFO:     Epoch: 12
2022-12-05 23:14:38,868 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5284074704078111, 'Total loss': 0.5284074704078111} | train loss {'Reaction outcome loss': 0.5412292469653391, 'Total loss': 0.5412292469653391}
2022-12-05 23:14:38,868 INFO:     Found new best model at epoch 12
2022-12-05 23:14:38,868 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:38,869 INFO:     Epoch: 13
2022-12-05 23:14:39,578 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5224834727970037, 'Total loss': 0.5224834727970037} | train loss {'Reaction outcome loss': 0.5373555736075486, 'Total loss': 0.5373555736075486}
2022-12-05 23:14:39,578 INFO:     Found new best model at epoch 13
2022-12-05 23:14:39,579 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:39,579 INFO:     Epoch: 14
2022-12-05 23:14:40,290 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5367307957600463, 'Total loss': 0.5367307957600463} | train loss {'Reaction outcome loss': 0.5357451398646639, 'Total loss': 0.5357451398646639}
2022-12-05 23:14:40,291 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:40,291 INFO:     Epoch: 15
2022-12-05 23:14:41,004 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5546780506318266, 'Total loss': 0.5546780506318266} | train loss {'Reaction outcome loss': 0.5455438768070552, 'Total loss': 0.5455438768070552}
2022-12-05 23:14:41,004 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:41,004 INFO:     Epoch: 16
2022-12-05 23:14:41,718 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5122830982912671, 'Total loss': 0.5122830982912671} | train loss {'Reaction outcome loss': 0.5286745454875692, 'Total loss': 0.5286745454875692}
2022-12-05 23:14:41,719 INFO:     Found new best model at epoch 16
2022-12-05 23:14:41,719 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:41,719 INFO:     Epoch: 17
2022-12-05 23:14:42,429 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5077080858702009, 'Total loss': 0.5077080858702009} | train loss {'Reaction outcome loss': 0.5318861535239604, 'Total loss': 0.5318861535239604}
2022-12-05 23:14:42,429 INFO:     Found new best model at epoch 17
2022-12-05 23:14:42,429 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:42,429 INFO:     Epoch: 18
2022-12-05 23:14:43,138 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4909247803417119, 'Total loss': 0.4909247803417119} | train loss {'Reaction outcome loss': 0.5382669436474962, 'Total loss': 0.5382669436474962}
2022-12-05 23:14:43,138 INFO:     Found new best model at epoch 18
2022-12-05 23:14:43,139 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:43,139 INFO:     Epoch: 19
2022-12-05 23:14:43,850 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.520713480358774, 'Total loss': 0.520713480358774} | train loss {'Reaction outcome loss': 0.527537162085214, 'Total loss': 0.527537162085214}
2022-12-05 23:14:43,850 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:43,850 INFO:     Epoch: 20
2022-12-05 23:14:44,559 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5238095975734971, 'Total loss': 0.5238095975734971} | train loss {'Reaction outcome loss': 0.5273388539470972, 'Total loss': 0.5273388539470972}
2022-12-05 23:14:44,559 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:44,559 INFO:     Epoch: 21
2022-12-05 23:14:45,272 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49887615882537584, 'Total loss': 0.49887615882537584} | train loss {'Reaction outcome loss': 0.5220607076320918, 'Total loss': 0.5220607076320918}
2022-12-05 23:14:45,272 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:45,272 INFO:     Epoch: 22
2022-12-05 23:14:45,983 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.505701635371555, 'Total loss': 0.505701635371555} | train loss {'Reaction outcome loss': 0.5222303885966539, 'Total loss': 0.5222303885966539}
2022-12-05 23:14:45,984 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:45,984 INFO:     Epoch: 23
2022-12-05 23:14:46,693 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5832034200429916, 'Total loss': 0.5832034200429916} | train loss {'Reaction outcome loss': 0.5243184133883445, 'Total loss': 0.5243184133883445}
2022-12-05 23:14:46,693 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:46,694 INFO:     Epoch: 24
2022-12-05 23:14:47,405 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.49625938131727954, 'Total loss': 0.49625938131727954} | train loss {'Reaction outcome loss': 0.5255900403304447, 'Total loss': 0.5255900403304447}
2022-12-05 23:14:47,405 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:47,405 INFO:     Epoch: 25
2022-12-05 23:14:48,114 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4944021115926179, 'Total loss': 0.4944021115926179} | train loss {'Reaction outcome loss': 0.5206731789775433, 'Total loss': 0.5206731789775433}
2022-12-05 23:14:48,115 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:48,115 INFO:     Epoch: 26
2022-12-05 23:14:48,830 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5236922001296823, 'Total loss': 0.5236922001296823} | train loss {'Reaction outcome loss': 0.5150000882004538, 'Total loss': 0.5150000882004538}
2022-12-05 23:14:48,830 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:48,830 INFO:     Epoch: 27
2022-12-05 23:14:49,540 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5513470582664013, 'Total loss': 0.5513470582664013} | train loss {'Reaction outcome loss': 0.5217379983514547, 'Total loss': 0.5217379983514547}
2022-12-05 23:14:49,540 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:49,540 INFO:     Epoch: 28
2022-12-05 23:14:50,250 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5021726624532179, 'Total loss': 0.5021726624532179} | train loss {'Reaction outcome loss': 0.5278915425221766, 'Total loss': 0.5278915425221766}
2022-12-05 23:14:50,250 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:50,250 INFO:     Epoch: 29
2022-12-05 23:14:50,966 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5380585451017726, 'Total loss': 0.5380585451017726} | train loss {'Reaction outcome loss': 0.5149951463024462, 'Total loss': 0.5149951463024462}
2022-12-05 23:14:50,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:50,966 INFO:     Epoch: 30
2022-12-05 23:14:51,683 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5097034126520157, 'Total loss': 0.5097034126520157} | train loss {'Reaction outcome loss': 0.5309619418075008, 'Total loss': 0.5309619418075008}
2022-12-05 23:14:51,683 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:51,683 INFO:     Epoch: 31
2022-12-05 23:14:52,397 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4973632286895405, 'Total loss': 0.4973632286895405} | train loss {'Reaction outcome loss': 0.5112859827856864, 'Total loss': 0.5112859827856864}
2022-12-05 23:14:52,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:52,397 INFO:     Epoch: 32
2022-12-05 23:14:53,111 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5013028857382861, 'Total loss': 0.5013028857382861} | train loss {'Reaction outcome loss': 0.5185240296827208, 'Total loss': 0.5185240296827208}
2022-12-05 23:14:53,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:53,111 INFO:     Epoch: 33
2022-12-05 23:14:53,820 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5176375826651399, 'Total loss': 0.5176375826651399} | train loss {'Reaction outcome loss': 0.5170196098305525, 'Total loss': 0.5170196098305525}
2022-12-05 23:14:53,820 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:53,820 INFO:     Epoch: 34
2022-12-05 23:14:54,530 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47952681068669667, 'Total loss': 0.47952681068669667} | train loss {'Reaction outcome loss': 0.5061273330882672, 'Total loss': 0.5061273330882672}
2022-12-05 23:14:54,530 INFO:     Found new best model at epoch 34
2022-12-05 23:14:54,531 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:54,531 INFO:     Epoch: 35
2022-12-05 23:14:55,243 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5319912359118462, 'Total loss': 0.5319912359118462} | train loss {'Reaction outcome loss': 0.5151584397160238, 'Total loss': 0.5151584397160238}
2022-12-05 23:14:55,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:55,243 INFO:     Epoch: 36
2022-12-05 23:14:55,954 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5048824396323074, 'Total loss': 0.5048824396323074} | train loss {'Reaction outcome loss': 0.5128076694785587, 'Total loss': 0.5128076694785587}
2022-12-05 23:14:55,954 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:55,954 INFO:     Epoch: 37
2022-12-05 23:14:56,663 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5040754709731449, 'Total loss': 0.5040754709731449} | train loss {'Reaction outcome loss': 0.5119181908066234, 'Total loss': 0.5119181908066234}
2022-12-05 23:14:56,663 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:56,663 INFO:     Epoch: 38
2022-12-05 23:14:57,373 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5003844814544375, 'Total loss': 0.5003844814544375} | train loss {'Reaction outcome loss': 0.5120156120148397, 'Total loss': 0.5120156120148397}
2022-12-05 23:14:57,373 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:57,373 INFO:     Epoch: 39
2022-12-05 23:14:58,083 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5539477386257865, 'Total loss': 0.5539477386257865} | train loss {'Reaction outcome loss': 0.5226220429063805, 'Total loss': 0.5226220429063805}
2022-12-05 23:14:58,083 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:58,083 INFO:     Epoch: 40
2022-12-05 23:14:58,792 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5195090608163313, 'Total loss': 0.5195090608163313} | train loss {'Reaction outcome loss': 0.5111824709080881, 'Total loss': 0.5111824709080881}
2022-12-05 23:14:58,792 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:58,792 INFO:     Epoch: 41
2022-12-05 23:14:59,501 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5345053354447539, 'Total loss': 0.5345053354447539} | train loss {'Reaction outcome loss': 0.5138805988094499, 'Total loss': 0.5138805988094499}
2022-12-05 23:14:59,501 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:14:59,501 INFO:     Epoch: 42
2022-12-05 23:15:00,212 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5147345814515244, 'Total loss': 0.5147345814515244} | train loss {'Reaction outcome loss': 0.5100054094988492, 'Total loss': 0.5100054094988492}
2022-12-05 23:15:00,212 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:00,212 INFO:     Epoch: 43
2022-12-05 23:15:00,923 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5098857104100964, 'Total loss': 0.5098857104100964} | train loss {'Reaction outcome loss': 0.5157155734637091, 'Total loss': 0.5157155734637091}
2022-12-05 23:15:00,923 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:00,923 INFO:     Epoch: 44
2022-12-05 23:15:01,634 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48991063135591423, 'Total loss': 0.48991063135591423} | train loss {'Reaction outcome loss': 0.507631562890545, 'Total loss': 0.507631562890545}
2022-12-05 23:15:01,634 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:01,634 INFO:     Epoch: 45
2022-12-05 23:15:02,344 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5372695797546343, 'Total loss': 0.5372695797546343} | train loss {'Reaction outcome loss': 0.5078050917194735, 'Total loss': 0.5078050917194735}
2022-12-05 23:15:02,344 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:02,344 INFO:     Epoch: 46
2022-12-05 23:15:03,056 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49399256841702893, 'Total loss': 0.49399256841702893} | train loss {'Reaction outcome loss': 0.5169365430070508, 'Total loss': 0.5169365430070508}
2022-12-05 23:15:03,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:03,056 INFO:     Epoch: 47
2022-12-05 23:15:03,764 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4897540347142653, 'Total loss': 0.4897540347142653} | train loss {'Reaction outcome loss': 0.5162350778137484, 'Total loss': 0.5162350778137484}
2022-12-05 23:15:03,764 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:03,764 INFO:     Epoch: 48
2022-12-05 23:15:04,476 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5340016121891412, 'Total loss': 0.5340016121891412} | train loss {'Reaction outcome loss': 0.5063795721939495, 'Total loss': 0.5063795721939495}
2022-12-05 23:15:04,476 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:04,476 INFO:     Epoch: 49
2022-12-05 23:15:05,184 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5347303423014554, 'Total loss': 0.5347303423014554} | train loss {'Reaction outcome loss': 0.5172089171866255, 'Total loss': 0.5172089171866255}
2022-12-05 23:15:05,184 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:05,184 INFO:     Epoch: 50
2022-12-05 23:15:05,895 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5075243962081996, 'Total loss': 0.5075243962081996} | train loss {'Reaction outcome loss': 0.511255802827016, 'Total loss': 0.511255802827016}
2022-12-05 23:15:05,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:05,896 INFO:     Epoch: 51
2022-12-05 23:15:06,610 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5217713889750567, 'Total loss': 0.5217713889750567} | train loss {'Reaction outcome loss': 0.5105997792655422, 'Total loss': 0.5105997792655422}
2022-12-05 23:15:06,610 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:06,611 INFO:     Epoch: 52
2022-12-05 23:15:07,319 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5118316452611577, 'Total loss': 0.5118316452611577} | train loss {'Reaction outcome loss': 0.5041095917263338, 'Total loss': 0.5041095917263338}
2022-12-05 23:15:07,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:07,320 INFO:     Epoch: 53
2022-12-05 23:15:08,028 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.48716716129671445, 'Total loss': 0.48716716129671445} | train loss {'Reaction outcome loss': 0.5097453879613069, 'Total loss': 0.5097453879613069}
2022-12-05 23:15:08,028 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:08,028 INFO:     Epoch: 54
2022-12-05 23:15:08,742 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.49682957475835626, 'Total loss': 0.49682957475835626} | train loss {'Reaction outcome loss': 0.500681459903717, 'Total loss': 0.500681459903717}
2022-12-05 23:15:08,742 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:08,742 INFO:     Epoch: 55
2022-12-05 23:15:09,452 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49856786971742456, 'Total loss': 0.49856786971742456} | train loss {'Reaction outcome loss': 0.5125089416340474, 'Total loss': 0.5125089416340474}
2022-12-05 23:15:09,452 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:09,452 INFO:     Epoch: 56
2022-12-05 23:15:10,165 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49318421056324785, 'Total loss': 0.49318421056324785} | train loss {'Reaction outcome loss': 0.5127584773205942, 'Total loss': 0.5127584773205942}
2022-12-05 23:15:10,165 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:10,166 INFO:     Epoch: 57
2022-12-05 23:15:10,879 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5019221888347105, 'Total loss': 0.5019221888347105} | train loss {'Reaction outcome loss': 0.5076369480980981, 'Total loss': 0.5076369480980981}
2022-12-05 23:15:10,879 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:10,879 INFO:     Epoch: 58
2022-12-05 23:15:11,589 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4988222254270857, 'Total loss': 0.4988222254270857} | train loss {'Reaction outcome loss': 0.5156208586788946, 'Total loss': 0.5156208586788946}
2022-12-05 23:15:11,589 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:11,589 INFO:     Epoch: 59
2022-12-05 23:15:12,294 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.48471284860914404, 'Total loss': 0.48471284860914404} | train loss {'Reaction outcome loss': 0.499525451792344, 'Total loss': 0.499525451792344}
2022-12-05 23:15:12,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:12,294 INFO:     Epoch: 60
2022-12-05 23:15:13,000 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5115428722717545, 'Total loss': 0.5115428722717545} | train loss {'Reaction outcome loss': 0.5049185996815082, 'Total loss': 0.5049185996815082}
2022-12-05 23:15:13,000 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:13,000 INFO:     Epoch: 61
2022-12-05 23:15:13,704 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5265464091842825, 'Total loss': 0.5265464091842825} | train loss {'Reaction outcome loss': 0.5129849448079064, 'Total loss': 0.5129849448079064}
2022-12-05 23:15:13,704 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:13,704 INFO:     Epoch: 62
2022-12-05 23:15:14,414 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4882876578379761, 'Total loss': 0.4882876578379761} | train loss {'Reaction outcome loss': 0.5084088799814063, 'Total loss': 0.5084088799814063}
2022-12-05 23:15:14,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:14,414 INFO:     Epoch: 63
2022-12-05 23:15:15,120 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4930985722352158, 'Total loss': 0.4930985722352158} | train loss {'Reaction outcome loss': 0.5086781770111092, 'Total loss': 0.5086781770111092}
2022-12-05 23:15:15,120 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:15,120 INFO:     Epoch: 64
2022-12-05 23:15:15,824 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5412661578844894, 'Total loss': 0.5412661578844894} | train loss {'Reaction outcome loss': 0.5037877357775166, 'Total loss': 0.5037877357775166}
2022-12-05 23:15:15,825 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:15,825 INFO:     Epoch: 65
2022-12-05 23:15:16,529 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5134535042399709, 'Total loss': 0.5134535042399709} | train loss {'Reaction outcome loss': 0.512505667824899, 'Total loss': 0.512505667824899}
2022-12-05 23:15:16,529 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:16,529 INFO:     Epoch: 66
2022-12-05 23:15:17,241 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4991912692785263, 'Total loss': 0.4991912692785263} | train loss {'Reaction outcome loss': 0.5084638576954603, 'Total loss': 0.5084638576954603}
2022-12-05 23:15:17,241 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:17,241 INFO:     Epoch: 67
2022-12-05 23:15:17,948 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48999632454731246, 'Total loss': 0.48999632454731246} | train loss {'Reaction outcome loss': 0.5075765406532634, 'Total loss': 0.5075765406532634}
2022-12-05 23:15:17,948 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:17,948 INFO:     Epoch: 68
2022-12-05 23:15:18,653 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5404286669059233, 'Total loss': 0.5404286669059233} | train loss {'Reaction outcome loss': 0.5029669825828844, 'Total loss': 0.5029669825828844}
2022-12-05 23:15:18,653 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:18,653 INFO:     Epoch: 69
2022-12-05 23:15:19,362 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49233061888001184, 'Total loss': 0.49233061888001184} | train loss {'Reaction outcome loss': 0.5149081843875108, 'Total loss': 0.5149081843875108}
2022-12-05 23:15:19,363 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:19,363 INFO:     Epoch: 70
2022-12-05 23:15:20,074 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48521146313710645, 'Total loss': 0.48521146313710645} | train loss {'Reaction outcome loss': 0.5028037518383034, 'Total loss': 0.5028037518383034}
2022-12-05 23:15:20,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:20,074 INFO:     Epoch: 71
2022-12-05 23:15:20,780 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5175173817710443, 'Total loss': 0.5175173817710443} | train loss {'Reaction outcome loss': 0.5142364142642867, 'Total loss': 0.5142364142642867}
2022-12-05 23:15:20,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:20,780 INFO:     Epoch: 72
2022-12-05 23:15:21,489 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4884627949107777, 'Total loss': 0.4884627949107777} | train loss {'Reaction outcome loss': 0.5091010684808416, 'Total loss': 0.5091010684808416}
2022-12-05 23:15:21,489 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:21,489 INFO:     Epoch: 73
2022-12-05 23:15:22,197 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5262090729718859, 'Total loss': 0.5262090729718859} | train loss {'Reaction outcome loss': 0.5093865734074385, 'Total loss': 0.5093865734074385}
2022-12-05 23:15:22,197 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:22,197 INFO:     Epoch: 74
2022-12-05 23:15:22,901 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49735634469173173, 'Total loss': 0.49735634469173173} | train loss {'Reaction outcome loss': 0.5051195822776325, 'Total loss': 0.5051195822776325}
2022-12-05 23:15:22,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:22,902 INFO:     Epoch: 75
2022-12-05 23:15:23,606 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5259198465130546, 'Total loss': 0.5259198465130546} | train loss {'Reaction outcome loss': 0.5108403780407482, 'Total loss': 0.5108403780407482}
2022-12-05 23:15:23,606 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:23,606 INFO:     Epoch: 76
2022-12-05 23:15:24,312 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5020557872273705, 'Total loss': 0.5020557872273705} | train loss {'Reaction outcome loss': 0.49910211869545523, 'Total loss': 0.49910211869545523}
2022-12-05 23:15:24,312 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:24,312 INFO:     Epoch: 77
2022-12-05 23:15:25,018 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5312270447611809, 'Total loss': 0.5312270447611809} | train loss {'Reaction outcome loss': 0.512209162356392, 'Total loss': 0.512209162356392}
2022-12-05 23:15:25,018 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:25,018 INFO:     Epoch: 78
2022-12-05 23:15:25,730 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48780762268738315, 'Total loss': 0.48780762268738315} | train loss {'Reaction outcome loss': 0.5005065437045789, 'Total loss': 0.5005065437045789}
2022-12-05 23:15:25,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:25,730 INFO:     Epoch: 79
2022-12-05 23:15:26,446 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5002670365978371, 'Total loss': 0.5002670365978371} | train loss {'Reaction outcome loss': 0.503693436302485, 'Total loss': 0.503693436302485}
2022-12-05 23:15:26,446 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:26,446 INFO:     Epoch: 80
2022-12-05 23:15:27,154 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4727103381671689, 'Total loss': 0.4727103381671689} | train loss {'Reaction outcome loss': 0.5086861417418526, 'Total loss': 0.5086861417418526}
2022-12-05 23:15:27,154 INFO:     Found new best model at epoch 80
2022-12-05 23:15:27,155 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:27,155 INFO:     Epoch: 81
2022-12-05 23:15:27,861 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5051876347173344, 'Total loss': 0.5051876347173344} | train loss {'Reaction outcome loss': 0.5078394239347789, 'Total loss': 0.5078394239347789}
2022-12-05 23:15:27,861 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:27,861 INFO:     Epoch: 82
2022-12-05 23:15:28,566 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49074609916318546, 'Total loss': 0.49074609916318546} | train loss {'Reaction outcome loss': 0.5118539321326441, 'Total loss': 0.5118539321326441}
2022-12-05 23:15:28,566 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:28,566 INFO:     Epoch: 83
2022-12-05 23:15:29,276 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49229867079041223, 'Total loss': 0.49229867079041223} | train loss {'Reaction outcome loss': 0.517458512838329, 'Total loss': 0.517458512838329}
2022-12-05 23:15:29,276 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:29,276 INFO:     Epoch: 84
2022-12-05 23:15:29,989 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5034825957634232, 'Total loss': 0.5034825957634232} | train loss {'Reaction outcome loss': 0.5146652757520637, 'Total loss': 0.5146652757520637}
2022-12-05 23:15:29,990 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:29,990 INFO:     Epoch: 85
2022-12-05 23:15:30,697 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5377019196748734, 'Total loss': 0.5377019196748734} | train loss {'Reaction outcome loss': 0.5133886391357068, 'Total loss': 0.5133886391357068}
2022-12-05 23:15:30,697 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:30,698 INFO:     Epoch: 86
2022-12-05 23:15:31,405 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5218379890376871, 'Total loss': 0.5218379890376871} | train loss {'Reaction outcome loss': 0.5063945721654642, 'Total loss': 0.5063945721654642}
2022-12-05 23:15:31,405 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:31,405 INFO:     Epoch: 87
2022-12-05 23:15:32,110 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4921045296571471, 'Total loss': 0.4921045296571471} | train loss {'Reaction outcome loss': 0.5062649658610744, 'Total loss': 0.5062649658610744}
2022-12-05 23:15:32,110 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:32,110 INFO:     Epoch: 88
2022-12-05 23:15:32,819 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4843856357038021, 'Total loss': 0.4843856357038021} | train loss {'Reaction outcome loss': 0.5064966760936284, 'Total loss': 0.5064966760936284}
2022-12-05 23:15:32,819 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:32,819 INFO:     Epoch: 89
2022-12-05 23:15:33,524 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4946007335727865, 'Total loss': 0.4946007335727865} | train loss {'Reaction outcome loss': 0.5071953281519874, 'Total loss': 0.5071953281519874}
2022-12-05 23:15:33,525 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:33,525 INFO:     Epoch: 90
2022-12-05 23:15:34,231 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.49607712640003726, 'Total loss': 0.49607712640003726} | train loss {'Reaction outcome loss': 0.5089405457819661, 'Total loss': 0.5089405457819661}
2022-12-05 23:15:34,231 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:34,231 INFO:     Epoch: 91
2022-12-05 23:15:34,936 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5081665566699072, 'Total loss': 0.5081665566699072} | train loss {'Reaction outcome loss': 0.5033270677611712, 'Total loss': 0.5033270677611712}
2022-12-05 23:15:34,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:34,936 INFO:     Epoch: 92
2022-12-05 23:15:35,642 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.553330062803897, 'Total loss': 0.553330062803897} | train loss {'Reaction outcome loss': 0.5100615981125063, 'Total loss': 0.5100615981125063}
2022-12-05 23:15:35,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:35,642 INFO:     Epoch: 93
2022-12-05 23:15:36,347 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4955298880284483, 'Total loss': 0.4955298880284483} | train loss {'Reaction outcome loss': 0.5108821194979453, 'Total loss': 0.5108821194979453}
2022-12-05 23:15:36,347 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:36,347 INFO:     Epoch: 94
2022-12-05 23:15:37,052 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5522606836801226, 'Total loss': 0.5522606836801226} | train loss {'Reaction outcome loss': 0.49959496835306766, 'Total loss': 0.49959496835306766}
2022-12-05 23:15:37,052 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:37,052 INFO:     Epoch: 95
2022-12-05 23:15:37,760 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4991180358285254, 'Total loss': 0.4991180358285254} | train loss {'Reaction outcome loss': 0.5118799112256496, 'Total loss': 0.5118799112256496}
2022-12-05 23:15:37,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:37,761 INFO:     Epoch: 96
2022-12-05 23:15:38,470 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.525856030935591, 'Total loss': 0.525856030935591} | train loss {'Reaction outcome loss': 0.5127536280140761, 'Total loss': 0.5127536280140761}
2022-12-05 23:15:38,470 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:38,470 INFO:     Epoch: 97
2022-12-05 23:15:39,181 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5101873282004487, 'Total loss': 0.5101873282004487} | train loss {'Reaction outcome loss': 0.5037899089436377, 'Total loss': 0.5037899089436377}
2022-12-05 23:15:39,181 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:39,181 INFO:     Epoch: 98
2022-12-05 23:15:39,889 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5210338106209581, 'Total loss': 0.5210338106209581} | train loss {'Reaction outcome loss': 0.506371803281288, 'Total loss': 0.506371803281288}
2022-12-05 23:15:39,889 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:39,889 INFO:     Epoch: 99
2022-12-05 23:15:40,595 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.546735633503307, 'Total loss': 0.546735633503307} | train loss {'Reaction outcome loss': 0.5030075586250713, 'Total loss': 0.5030075586250713}
2022-12-05 23:15:40,595 INFO:     Best model found after epoch 81 of 100.
2022-12-05 23:15:40,595 INFO:   Done with stage: TRAINING
2022-12-05 23:15:40,596 INFO:   Starting stage: EVALUATION
2022-12-05 23:15:40,713 INFO:   Done with stage: EVALUATION
2022-12-05 23:15:40,713 INFO:   Leaving out SEQ value Fold_9
2022-12-05 23:15:40,726 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:15:40,726 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:15:41,358 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:15:41,359 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:15:41,430 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:15:41,430 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:15:41,430 INFO:     No hyperparam tuning for this model
2022-12-05 23:15:41,430 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:15:41,430 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:15:41,431 INFO:     None feature selector for col prot
2022-12-05 23:15:41,431 INFO:     None feature selector for col prot
2022-12-05 23:15:41,431 INFO:     None feature selector for col prot
2022-12-05 23:15:41,431 INFO:     None feature selector for col chem
2022-12-05 23:15:41,432 INFO:     None feature selector for col chem
2022-12-05 23:15:41,432 INFO:     None feature selector for col chem
2022-12-05 23:15:41,432 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:15:41,432 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:15:41,433 INFO:     Number of params in model 215731
2022-12-05 23:15:41,436 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:15:41,436 INFO:   Starting stage: TRAINING
2022-12-05 23:15:41,494 INFO:     Val loss before train {'Reaction outcome loss': 1.0452578663825989, 'Total loss': 1.0452578663825989}
2022-12-05 23:15:41,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:41,494 INFO:     Epoch: 0
2022-12-05 23:15:42,195 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7616214488040317, 'Total loss': 0.7616214488040317} | train loss {'Reaction outcome loss': 0.8174495156477337, 'Total loss': 0.8174495156477337}
2022-12-05 23:15:42,195 INFO:     Found new best model at epoch 0
2022-12-05 23:15:42,196 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:42,196 INFO:     Epoch: 1
2022-12-05 23:15:42,896 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6967437849803404, 'Total loss': 0.6967437849803404} | train loss {'Reaction outcome loss': 0.6919302202550023, 'Total loss': 0.6919302202550023}
2022-12-05 23:15:42,896 INFO:     Found new best model at epoch 1
2022-12-05 23:15:42,896 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:42,897 INFO:     Epoch: 2
2022-12-05 23:15:43,598 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6856958818706599, 'Total loss': 0.6856958818706599} | train loss {'Reaction outcome loss': 0.6451670093092359, 'Total loss': 0.6451670093092359}
2022-12-05 23:15:43,598 INFO:     Found new best model at epoch 2
2022-12-05 23:15:43,598 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:43,598 INFO:     Epoch: 3
2022-12-05 23:15:44,304 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6268319020217116, 'Total loss': 0.6268319020217116} | train loss {'Reaction outcome loss': 0.624596821634393, 'Total loss': 0.624596821634393}
2022-12-05 23:15:44,304 INFO:     Found new best model at epoch 3
2022-12-05 23:15:44,305 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:44,305 INFO:     Epoch: 4
2022-12-05 23:15:45,011 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5845899107781324, 'Total loss': 0.5845899107781324} | train loss {'Reaction outcome loss': 0.6198639708009326, 'Total loss': 0.6198639708009326}
2022-12-05 23:15:45,011 INFO:     Found new best model at epoch 4
2022-12-05 23:15:45,012 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:45,012 INFO:     Epoch: 5
2022-12-05 23:15:45,714 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6031665260141547, 'Total loss': 0.6031665260141547} | train loss {'Reaction outcome loss': 0.5973666550418143, 'Total loss': 0.5973666550418143}
2022-12-05 23:15:45,714 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:45,714 INFO:     Epoch: 6
2022-12-05 23:15:46,416 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.58270563185215, 'Total loss': 0.58270563185215} | train loss {'Reaction outcome loss': 0.5774920204511056, 'Total loss': 0.5774920204511056}
2022-12-05 23:15:46,416 INFO:     Found new best model at epoch 6
2022-12-05 23:15:46,417 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:46,417 INFO:     Epoch: 7
2022-12-05 23:15:47,116 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5700349286198616, 'Total loss': 0.5700349286198616} | train loss {'Reaction outcome loss': 0.5877707003340548, 'Total loss': 0.5877707003340548}
2022-12-05 23:15:47,116 INFO:     Found new best model at epoch 7
2022-12-05 23:15:47,117 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:47,117 INFO:     Epoch: 8
2022-12-05 23:15:47,817 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5729190436276522, 'Total loss': 0.5729190436276522} | train loss {'Reaction outcome loss': 0.5622970676615171, 'Total loss': 0.5622970676615171}
2022-12-05 23:15:47,817 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:47,817 INFO:     Epoch: 9
2022-12-05 23:15:48,515 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5414675067771565, 'Total loss': 0.5414675067771565} | train loss {'Reaction outcome loss': 0.5634539985825658, 'Total loss': 0.5634539985825658}
2022-12-05 23:15:48,515 INFO:     Found new best model at epoch 9
2022-12-05 23:15:48,516 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:48,516 INFO:     Epoch: 10
2022-12-05 23:15:49,215 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.541108678010377, 'Total loss': 0.541108678010377} | train loss {'Reaction outcome loss': 0.5615004374068758, 'Total loss': 0.5615004374068758}
2022-12-05 23:15:49,216 INFO:     Found new best model at epoch 10
2022-12-05 23:15:49,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:49,216 INFO:     Epoch: 11
2022-12-05 23:15:49,921 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5368250642310489, 'Total loss': 0.5368250642310489} | train loss {'Reaction outcome loss': 0.5518574515425483, 'Total loss': 0.5518574515425483}
2022-12-05 23:15:49,922 INFO:     Found new best model at epoch 11
2022-12-05 23:15:49,922 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:49,922 INFO:     Epoch: 12
2022-12-05 23:15:50,626 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5753098922696981, 'Total loss': 0.5753098922696981} | train loss {'Reaction outcome loss': 0.5474922133360797, 'Total loss': 0.5474922133360797}
2022-12-05 23:15:50,627 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:50,628 INFO:     Epoch: 13
2022-12-05 23:15:51,330 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5415328205986456, 'Total loss': 0.5415328205986456} | train loss {'Reaction outcome loss': 0.5600963435343161, 'Total loss': 0.5600963435343161}
2022-12-05 23:15:51,330 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:51,330 INFO:     Epoch: 14
2022-12-05 23:15:52,031 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5204113552516157, 'Total loss': 0.5204113552516157} | train loss {'Reaction outcome loss': 0.5391656301561215, 'Total loss': 0.5391656301561215}
2022-12-05 23:15:52,031 INFO:     Found new best model at epoch 14
2022-12-05 23:15:52,032 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:52,032 INFO:     Epoch: 15
2022-12-05 23:15:52,733 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5459797192703594, 'Total loss': 0.5459797192703594} | train loss {'Reaction outcome loss': 0.5365499182781468, 'Total loss': 0.5365499182781468}
2022-12-05 23:15:52,733 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:52,733 INFO:     Epoch: 16
2022-12-05 23:15:53,431 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.6109299449758097, 'Total loss': 0.6109299449758097} | train loss {'Reaction outcome loss': 0.5409426162479377, 'Total loss': 0.5409426162479377}
2022-12-05 23:15:53,431 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:53,431 INFO:     Epoch: 17
2022-12-05 23:15:54,130 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5730691812932491, 'Total loss': 0.5730691812932491} | train loss {'Reaction outcome loss': 0.5547532571954765, 'Total loss': 0.5547532571954765}
2022-12-05 23:15:54,130 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:54,130 INFO:     Epoch: 18
2022-12-05 23:15:54,829 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5474070161581039, 'Total loss': 0.5474070161581039} | train loss {'Reaction outcome loss': 0.5481659286553681, 'Total loss': 0.5481659286553681}
2022-12-05 23:15:54,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:54,829 INFO:     Epoch: 19
2022-12-05 23:15:55,528 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5785329511219804, 'Total loss': 0.5785329511219804} | train loss {'Reaction outcome loss': 0.5420741570381983, 'Total loss': 0.5420741570381983}
2022-12-05 23:15:55,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:55,529 INFO:     Epoch: 20
2022-12-05 23:15:56,227 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5293227891353044, 'Total loss': 0.5293227891353044} | train loss {'Reaction outcome loss': 0.5405082706256434, 'Total loss': 0.5405082706256434}
2022-12-05 23:15:56,227 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:56,227 INFO:     Epoch: 21
2022-12-05 23:15:56,925 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5545823072845285, 'Total loss': 0.5545823072845285} | train loss {'Reaction outcome loss': 0.541339089452979, 'Total loss': 0.541339089452979}
2022-12-05 23:15:56,926 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:56,926 INFO:     Epoch: 22
2022-12-05 23:15:57,625 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5324405902488665, 'Total loss': 0.5324405902488665} | train loss {'Reaction outcome loss': 0.5369303474534559, 'Total loss': 0.5369303474534559}
2022-12-05 23:15:57,625 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:57,625 INFO:     Epoch: 23
2022-12-05 23:15:58,327 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5274064185267145, 'Total loss': 0.5274064185267145} | train loss {'Reaction outcome loss': 0.5401222621381041, 'Total loss': 0.5401222621381041}
2022-12-05 23:15:58,327 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:58,327 INFO:     Epoch: 24
2022-12-05 23:15:59,025 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.6147767593237486, 'Total loss': 0.6147767593237486} | train loss {'Reaction outcome loss': 0.5415001148998979, 'Total loss': 0.5415001148998979}
2022-12-05 23:15:59,025 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:59,025 INFO:     Epoch: 25
2022-12-05 23:15:59,724 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.537436957386407, 'Total loss': 0.537436957386407} | train loss {'Reaction outcome loss': 0.5367410273596585, 'Total loss': 0.5367410273596585}
2022-12-05 23:15:59,724 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:15:59,724 INFO:     Epoch: 26
2022-12-05 23:16:00,425 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5366777764125303, 'Total loss': 0.5366777764125303} | train loss {'Reaction outcome loss': 0.540471596575459, 'Total loss': 0.540471596575459}
2022-12-05 23:16:00,425 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:00,425 INFO:     Epoch: 27
2022-12-05 23:16:01,129 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5433804704384371, 'Total loss': 0.5433804704384371} | train loss {'Reaction outcome loss': 0.5321706370997284, 'Total loss': 0.5321706370997284}
2022-12-05 23:16:01,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:01,129 INFO:     Epoch: 28
2022-12-05 23:16:01,831 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.6024066216566346, 'Total loss': 0.6024066216566346} | train loss {'Reaction outcome loss': 0.5349136193995534, 'Total loss': 0.5349136193995534}
2022-12-05 23:16:01,831 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:01,831 INFO:     Epoch: 29
2022-12-05 23:16:02,534 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.542895771055059, 'Total loss': 0.542895771055059} | train loss {'Reaction outcome loss': 0.5383534402876851, 'Total loss': 0.5383534402876851}
2022-12-05 23:16:02,534 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:02,534 INFO:     Epoch: 30
2022-12-05 23:16:03,236 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5305242545225404, 'Total loss': 0.5305242545225404} | train loss {'Reaction outcome loss': 0.5334376995546012, 'Total loss': 0.5334376995546012}
2022-12-05 23:16:03,236 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:03,236 INFO:     Epoch: 31
2022-12-05 23:16:03,939 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.518172141503204, 'Total loss': 0.518172141503204} | train loss {'Reaction outcome loss': 0.5414553011959864, 'Total loss': 0.5414553011959864}
2022-12-05 23:16:03,939 INFO:     Found new best model at epoch 31
2022-12-05 23:16:03,939 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:03,940 INFO:     Epoch: 32
2022-12-05 23:16:04,638 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.558659778399901, 'Total loss': 0.558659778399901} | train loss {'Reaction outcome loss': 0.531686598412421, 'Total loss': 0.531686598412421}
2022-12-05 23:16:04,639 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:04,639 INFO:     Epoch: 33
2022-12-05 23:16:05,343 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.6386752968484705, 'Total loss': 0.6386752968484705} | train loss {'Reaction outcome loss': 0.5382198358957584, 'Total loss': 0.5382198358957584}
2022-12-05 23:16:05,344 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:05,344 INFO:     Epoch: 34
2022-12-05 23:16:06,044 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.594691130247983, 'Total loss': 0.594691130247983} | train loss {'Reaction outcome loss': 0.551447083230926, 'Total loss': 0.551447083230926}
2022-12-05 23:16:06,044 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:06,044 INFO:     Epoch: 35
2022-12-05 23:16:06,749 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5339719626036558, 'Total loss': 0.5339719626036558} | train loss {'Reaction outcome loss': 0.5291283965744229, 'Total loss': 0.5291283965744229}
2022-12-05 23:16:06,749 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:06,749 INFO:     Epoch: 36
2022-12-05 23:16:07,454 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5126669948751276, 'Total loss': 0.5126669948751276} | train loss {'Reaction outcome loss': 0.533774553017638, 'Total loss': 0.533774553017638}
2022-12-05 23:16:07,454 INFO:     Found new best model at epoch 36
2022-12-05 23:16:07,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:07,455 INFO:     Epoch: 37
2022-12-05 23:16:08,160 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5311459665271369, 'Total loss': 0.5311459665271369} | train loss {'Reaction outcome loss': 0.5322384936244864, 'Total loss': 0.5322384936244864}
2022-12-05 23:16:08,161 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:08,161 INFO:     Epoch: 38
2022-12-05 23:16:08,863 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5319639532403513, 'Total loss': 0.5319639532403513} | train loss {'Reaction outcome loss': 0.5469384350878025, 'Total loss': 0.5469384350878025}
2022-12-05 23:16:08,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:08,864 INFO:     Epoch: 39
2022-12-05 23:16:09,569 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5281135961413383, 'Total loss': 0.5281135961413383} | train loss {'Reaction outcome loss': 0.5343822767479187, 'Total loss': 0.5343822767479187}
2022-12-05 23:16:09,570 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:09,570 INFO:     Epoch: 40
2022-12-05 23:16:10,273 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.6351042356003415, 'Total loss': 0.6351042356003415} | train loss {'Reaction outcome loss': 0.5294204815799891, 'Total loss': 0.5294204815799891}
2022-12-05 23:16:10,274 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:10,274 INFO:     Epoch: 41
2022-12-05 23:16:10,983 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5281692062589255, 'Total loss': 0.5281692062589255} | train loss {'Reaction outcome loss': 0.5316511297877501, 'Total loss': 0.5316511297877501}
2022-12-05 23:16:10,983 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:10,983 INFO:     Epoch: 42
2022-12-05 23:16:11,687 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5233596766536887, 'Total loss': 0.5233596766536887} | train loss {'Reaction outcome loss': 0.5393060654522437, 'Total loss': 0.5393060654522437}
2022-12-05 23:16:11,687 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:11,687 INFO:     Epoch: 43
2022-12-05 23:16:12,393 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5430478633127429, 'Total loss': 0.5430478633127429} | train loss {'Reaction outcome loss': 0.5372206469779073, 'Total loss': 0.5372206469779073}
2022-12-05 23:16:12,393 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:12,393 INFO:     Epoch: 44
2022-12-05 23:16:13,098 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.6607402681627057, 'Total loss': 0.6607402681627057} | train loss {'Reaction outcome loss': 0.5408703622065092, 'Total loss': 0.5408703622065092}
2022-12-05 23:16:13,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:13,099 INFO:     Epoch: 45
2022-12-05 23:16:13,805 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.524644002657045, 'Total loss': 0.524644002657045} | train loss {'Reaction outcome loss': 0.535623165759963, 'Total loss': 0.535623165759963}
2022-12-05 23:16:13,805 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:13,805 INFO:     Epoch: 46
2022-12-05 23:16:14,509 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5234742780978029, 'Total loss': 0.5234742780978029} | train loss {'Reaction outcome loss': 0.5285306369606783, 'Total loss': 0.5285306369606783}
2022-12-05 23:16:14,510 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:14,510 INFO:     Epoch: 47
2022-12-05 23:16:15,212 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.6480937606909059, 'Total loss': 0.6480937606909059} | train loss {'Reaction outcome loss': 0.5258123937773665, 'Total loss': 0.5258123937773665}
2022-12-05 23:16:15,212 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:15,213 INFO:     Epoch: 48
2022-12-05 23:16:15,919 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5211161266673695, 'Total loss': 0.5211161266673695} | train loss {'Reaction outcome loss': 0.5251650488388683, 'Total loss': 0.5251650488388683}
2022-12-05 23:16:15,919 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:15,919 INFO:     Epoch: 49
2022-12-05 23:16:16,628 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5484844527461312, 'Total loss': 0.5484844527461312} | train loss {'Reaction outcome loss': 0.5348629185303986, 'Total loss': 0.5348629185303986}
2022-12-05 23:16:16,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:16,628 INFO:     Epoch: 50
2022-12-05 23:16:17,338 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5673926569182765, 'Total loss': 0.5673926569182765} | train loss {'Reaction outcome loss': 0.527887263218401, 'Total loss': 0.527887263218401}
2022-12-05 23:16:17,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:17,339 INFO:     Epoch: 51
2022-12-05 23:16:18,042 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5219345570287921, 'Total loss': 0.5219345570287921} | train loss {'Reaction outcome loss': 0.5328005648817611, 'Total loss': 0.5328005648817611}
2022-12-05 23:16:18,042 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:18,042 INFO:     Epoch: 52
2022-12-05 23:16:18,744 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5243888267061927, 'Total loss': 0.5243888267061927} | train loss {'Reaction outcome loss': 0.526597793044349, 'Total loss': 0.526597793044349}
2022-12-05 23:16:18,744 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:18,744 INFO:     Epoch: 53
2022-12-05 23:16:19,446 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5422833087769422, 'Total loss': 0.5422833087769422} | train loss {'Reaction outcome loss': 0.5281800815933629, 'Total loss': 0.5281800815933629}
2022-12-05 23:16:19,446 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:19,446 INFO:     Epoch: 54
2022-12-05 23:16:20,152 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5012361021204428, 'Total loss': 0.5012361021204428} | train loss {'Reaction outcome loss': 0.5355518507330042, 'Total loss': 0.5355518507330042}
2022-12-05 23:16:20,152 INFO:     Found new best model at epoch 54
2022-12-05 23:16:20,153 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:20,153 INFO:     Epoch: 55
2022-12-05 23:16:20,855 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5087571611458604, 'Total loss': 0.5087571611458604} | train loss {'Reaction outcome loss': 0.5297498074379045, 'Total loss': 0.5297498074379045}
2022-12-05 23:16:20,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:20,855 INFO:     Epoch: 56
2022-12-05 23:16:21,557 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5280466337095607, 'Total loss': 0.5280466337095607} | train loss {'Reaction outcome loss': 0.5376091066762986, 'Total loss': 0.5376091066762986}
2022-12-05 23:16:21,557 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:21,557 INFO:     Epoch: 57
2022-12-05 23:16:22,260 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5458800724961541, 'Total loss': 0.5458800724961541} | train loss {'Reaction outcome loss': 0.5356291133141228, 'Total loss': 0.5356291133141228}
2022-12-05 23:16:22,261 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:22,261 INFO:     Epoch: 58
2022-12-05 23:16:22,967 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5483391711657698, 'Total loss': 0.5483391711657698} | train loss {'Reaction outcome loss': 0.5381981214538578, 'Total loss': 0.5381981214538578}
2022-12-05 23:16:22,967 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:22,967 INFO:     Epoch: 59
2022-12-05 23:16:23,669 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5593259717253122, 'Total loss': 0.5593259717253122} | train loss {'Reaction outcome loss': 0.5304711386259751, 'Total loss': 0.5304711386259751}
2022-12-05 23:16:23,670 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:23,670 INFO:     Epoch: 60
2022-12-05 23:16:24,373 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5736030015078458, 'Total loss': 0.5736030015078458} | train loss {'Reaction outcome loss': 0.5435191018861315, 'Total loss': 0.5435191018861315}
2022-12-05 23:16:24,373 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:24,373 INFO:     Epoch: 61
2022-12-05 23:16:25,078 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5282750576734543, 'Total loss': 0.5282750576734543} | train loss {'Reaction outcome loss': 0.5689731192311295, 'Total loss': 0.5689731192311295}
2022-12-05 23:16:25,078 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:25,078 INFO:     Epoch: 62
2022-12-05 23:16:25,781 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.521137076345357, 'Total loss': 0.521137076345357} | train loss {'Reaction outcome loss': 0.5237907851152575, 'Total loss': 0.5237907851152575}
2022-12-05 23:16:25,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:25,781 INFO:     Epoch: 63
2022-12-05 23:16:26,487 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5605674602768638, 'Total loss': 0.5605674602768638} | train loss {'Reaction outcome loss': 0.5282155652398522, 'Total loss': 0.5282155652398522}
2022-12-05 23:16:26,487 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:26,487 INFO:     Epoch: 64
2022-12-05 23:16:27,193 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5232686054977503, 'Total loss': 0.5232686054977503} | train loss {'Reaction outcome loss': 0.5443623834233052, 'Total loss': 0.5443623834233052}
2022-12-05 23:16:27,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:27,193 INFO:     Epoch: 65
2022-12-05 23:16:27,904 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5315713089975443, 'Total loss': 0.5315713089975443} | train loss {'Reaction outcome loss': 0.529693542764737, 'Total loss': 0.529693542764737}
2022-12-05 23:16:27,904 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:27,905 INFO:     Epoch: 66
2022-12-05 23:16:28,613 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5198181576349519, 'Total loss': 0.5198181576349519} | train loss {'Reaction outcome loss': 0.5203836762350098, 'Total loss': 0.5203836762350098}
2022-12-05 23:16:28,614 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:28,614 INFO:     Epoch: 67
2022-12-05 23:16:29,320 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5955558724024079, 'Total loss': 0.5955558724024079} | train loss {'Reaction outcome loss': 0.5240597754777202, 'Total loss': 0.5240597754777202}
2022-12-05 23:16:29,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:29,320 INFO:     Epoch: 68
2022-12-05 23:16:30,023 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5119663199240511, 'Total loss': 0.5119663199240511} | train loss {'Reaction outcome loss': 0.5258428998864614, 'Total loss': 0.5258428998864614}
2022-12-05 23:16:30,023 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:30,023 INFO:     Epoch: 69
2022-12-05 23:16:30,731 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4952696284109896, 'Total loss': 0.4952696284109896} | train loss {'Reaction outcome loss': 0.532390229856437, 'Total loss': 0.532390229856437}
2022-12-05 23:16:30,732 INFO:     Found new best model at epoch 69
2022-12-05 23:16:30,732 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:30,732 INFO:     Epoch: 70
2022-12-05 23:16:31,435 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5199951549822633, 'Total loss': 0.5199951549822633} | train loss {'Reaction outcome loss': 0.5250352103308387, 'Total loss': 0.5250352103308387}
2022-12-05 23:16:31,435 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:31,435 INFO:     Epoch: 71
2022-12-05 23:16:32,138 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5608857724476944, 'Total loss': 0.5608857724476944} | train loss {'Reaction outcome loss': 0.5247279405593872, 'Total loss': 0.5247279405593872}
2022-12-05 23:16:32,139 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:32,139 INFO:     Epoch: 72
2022-12-05 23:16:32,841 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5278501070358537, 'Total loss': 0.5278501070358537} | train loss {'Reaction outcome loss': 0.533804922813346, 'Total loss': 0.533804922813346}
2022-12-05 23:16:32,841 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:32,841 INFO:     Epoch: 73
2022-12-05 23:16:33,548 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5168650739572265, 'Total loss': 0.5168650739572265} | train loss {'Reaction outcome loss': 0.5396568937460903, 'Total loss': 0.5396568937460903}
2022-12-05 23:16:33,548 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:33,548 INFO:     Epoch: 74
2022-12-05 23:16:34,251 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.530425331809304, 'Total loss': 0.530425331809304} | train loss {'Reaction outcome loss': 0.5203073678711648, 'Total loss': 0.5203073678711648}
2022-12-05 23:16:34,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:34,252 INFO:     Epoch: 75
2022-12-05 23:16:34,954 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5060119354589419, 'Total loss': 0.5060119354589419} | train loss {'Reaction outcome loss': 0.5303916512471945, 'Total loss': 0.5303916512471945}
2022-12-05 23:16:34,954 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:34,955 INFO:     Epoch: 76
2022-12-05 23:16:35,657 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.511558208275925, 'Total loss': 0.511558208275925} | train loss {'Reaction outcome loss': 0.5594152026330894, 'Total loss': 0.5594152026330894}
2022-12-05 23:16:35,657 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:35,657 INFO:     Epoch: 77
2022-12-05 23:16:36,360 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5258633697574789, 'Total loss': 0.5258633697574789} | train loss {'Reaction outcome loss': 0.5297433685375611, 'Total loss': 0.5297433685375611}
2022-12-05 23:16:36,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:36,360 INFO:     Epoch: 78
2022-12-05 23:16:37,067 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5647403797642752, 'Total loss': 0.5647403797642752} | train loss {'Reaction outcome loss': 0.5325432417967059, 'Total loss': 0.5325432417967059}
2022-12-05 23:16:37,067 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:37,067 INFO:     Epoch: 79
2022-12-05 23:16:37,775 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5153825733472001, 'Total loss': 0.5153825733472001} | train loss {'Reaction outcome loss': 0.5333421341622406, 'Total loss': 0.5333421341622406}
2022-12-05 23:16:37,775 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:37,775 INFO:     Epoch: 80
2022-12-05 23:16:38,478 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5375048558820378, 'Total loss': 0.5375048558820378} | train loss {'Reaction outcome loss': 0.5308880028333741, 'Total loss': 0.5308880028333741}
2022-12-05 23:16:38,478 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:38,478 INFO:     Epoch: 81
2022-12-05 23:16:39,179 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.540129001845013, 'Total loss': 0.540129001845013} | train loss {'Reaction outcome loss': 0.5471439208940938, 'Total loss': 0.5471439208940938}
2022-12-05 23:16:39,180 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:39,180 INFO:     Epoch: 82
2022-12-05 23:16:39,886 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.6065027429298921, 'Total loss': 0.6065027429298921} | train loss {'Reaction outcome loss': 0.5276269592374925, 'Total loss': 0.5276269592374925}
2022-12-05 23:16:39,886 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:39,886 INFO:     Epoch: 83
2022-12-05 23:16:40,589 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5303456343033097, 'Total loss': 0.5303456343033097} | train loss {'Reaction outcome loss': 0.550798302599293, 'Total loss': 0.550798302599293}
2022-12-05 23:16:40,590 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:40,590 INFO:     Epoch: 84
2022-12-05 23:16:41,293 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5196190070022236, 'Total loss': 0.5196190070022236} | train loss {'Reaction outcome loss': 0.5292214148560999, 'Total loss': 0.5292214148560999}
2022-12-05 23:16:41,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:41,294 INFO:     Epoch: 85
2022-12-05 23:16:42,001 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5457432100718672, 'Total loss': 0.5457432100718672} | train loss {'Reaction outcome loss': 0.5419174391127791, 'Total loss': 0.5419174391127791}
2022-12-05 23:16:42,001 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:42,001 INFO:     Epoch: 86
2022-12-05 23:16:42,708 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5329323526133191, 'Total loss': 0.5329323526133191} | train loss {'Reaction outcome loss': 0.5451946268800781, 'Total loss': 0.5451946268800781}
2022-12-05 23:16:42,708 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:42,708 INFO:     Epoch: 87
2022-12-05 23:16:43,416 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5484994751485911, 'Total loss': 0.5484994751485911} | train loss {'Reaction outcome loss': 0.5265363620722342, 'Total loss': 0.5265363620722342}
2022-12-05 23:16:43,416 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:43,416 INFO:     Epoch: 88
2022-12-05 23:16:44,126 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.547265945171768, 'Total loss': 0.547265945171768} | train loss {'Reaction outcome loss': 0.5264349645569257, 'Total loss': 0.5264349645569257}
2022-12-05 23:16:44,126 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:44,127 INFO:     Epoch: 89
2022-12-05 23:16:44,831 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5695190761576999, 'Total loss': 0.5695190761576999} | train loss {'Reaction outcome loss': 0.5318421932309206, 'Total loss': 0.5318421932309206}
2022-12-05 23:16:44,832 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:44,832 INFO:     Epoch: 90
2022-12-05 23:16:45,537 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5179647004062479, 'Total loss': 0.5179647004062479} | train loss {'Reaction outcome loss': 0.5300754801585124, 'Total loss': 0.5300754801585124}
2022-12-05 23:16:45,537 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:45,537 INFO:     Epoch: 91
2022-12-05 23:16:46,244 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5415924895893444, 'Total loss': 0.5415924895893444} | train loss {'Reaction outcome loss': 0.5271182539250686, 'Total loss': 0.5271182539250686}
2022-12-05 23:16:46,244 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:46,244 INFO:     Epoch: 92
2022-12-05 23:16:46,947 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5287829542701895, 'Total loss': 0.5287829542701895} | train loss {'Reaction outcome loss': 0.5268262571048158, 'Total loss': 0.5268262571048158}
2022-12-05 23:16:46,947 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:46,947 INFO:     Epoch: 93
2022-12-05 23:16:47,655 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5228363627737219, 'Total loss': 0.5228363627737219} | train loss {'Reaction outcome loss': 0.5289057385975774, 'Total loss': 0.5289057385975774}
2022-12-05 23:16:47,655 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:47,655 INFO:     Epoch: 94
2022-12-05 23:16:48,361 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5174159028313376, 'Total loss': 0.5174159028313376} | train loss {'Reaction outcome loss': 0.5279872530867696, 'Total loss': 0.5279872530867696}
2022-12-05 23:16:48,362 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:48,362 INFO:     Epoch: 95
2022-12-05 23:16:49,067 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5024914372373711, 'Total loss': 0.5024914372373711} | train loss {'Reaction outcome loss': 0.5338124886818743, 'Total loss': 0.5338124886818743}
2022-12-05 23:16:49,068 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:49,068 INFO:     Epoch: 96
2022-12-05 23:16:49,775 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5367671671238813, 'Total loss': 0.5367671671238813} | train loss {'Reaction outcome loss': 0.5245638417932186, 'Total loss': 0.5245638417932186}
2022-12-05 23:16:49,775 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:49,775 INFO:     Epoch: 97
2022-12-05 23:16:50,477 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5077813640236855, 'Total loss': 0.5077813640236855} | train loss {'Reaction outcome loss': 0.526853165280089, 'Total loss': 0.526853165280089}
2022-12-05 23:16:50,477 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:50,477 INFO:     Epoch: 98
2022-12-05 23:16:51,176 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5193028869954023, 'Total loss': 0.5193028869954023} | train loss {'Reaction outcome loss': 0.5229871795524047, 'Total loss': 0.5229871795524047}
2022-12-05 23:16:51,176 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:51,176 INFO:     Epoch: 99
2022-12-05 23:16:51,874 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5326880663633347, 'Total loss': 0.5326880663633347} | train loss {'Reaction outcome loss': 0.530181196114795, 'Total loss': 0.530181196114795}
2022-12-05 23:16:51,874 INFO:     Best model found after epoch 70 of 100.
2022-12-05 23:16:51,874 INFO:   Done with stage: TRAINING
2022-12-05 23:16:51,874 INFO:   Starting stage: EVALUATION
2022-12-05 23:16:51,998 INFO:   Done with stage: EVALUATION
2022-12-05 23:16:52,007 INFO:   Leaving out SEQ value Fold_0
2022-12-05 23:16:52,020 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 23:16:52,020 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:16:52,649 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:16:52,651 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:16:52,721 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:16:52,721 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:16:52,721 INFO:     No hyperparam tuning for this model
2022-12-05 23:16:52,721 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:16:52,721 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:16:52,722 INFO:     None feature selector for col prot
2022-12-05 23:16:52,722 INFO:     None feature selector for col prot
2022-12-05 23:16:52,722 INFO:     None feature selector for col prot
2022-12-05 23:16:52,723 INFO:     None feature selector for col chem
2022-12-05 23:16:52,723 INFO:     None feature selector for col chem
2022-12-05 23:16:52,723 INFO:     None feature selector for col chem
2022-12-05 23:16:52,723 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:16:52,723 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:16:52,724 INFO:     Number of params in model 215731
2022-12-05 23:16:52,728 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:16:52,728 INFO:   Starting stage: TRAINING
2022-12-05 23:16:52,785 INFO:     Val loss before train {'Reaction outcome loss': 1.1316927712072025, 'Total loss': 1.1316927712072025}
2022-12-05 23:16:52,785 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:52,785 INFO:     Epoch: 0
2022-12-05 23:16:53,478 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7289538735693152, 'Total loss': 0.7289538735693152} | train loss {'Reaction outcome loss': 0.8083866968446848, 'Total loss': 0.8083866968446848}
2022-12-05 23:16:53,478 INFO:     Found new best model at epoch 0
2022-12-05 23:16:53,479 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:53,479 INFO:     Epoch: 1
2022-12-05 23:16:54,172 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6666796153241937, 'Total loss': 0.6666796153241937} | train loss {'Reaction outcome loss': 0.6797520930669746, 'Total loss': 0.6797520930669746}
2022-12-05 23:16:54,172 INFO:     Found new best model at epoch 1
2022-12-05 23:16:54,173 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:54,173 INFO:     Epoch: 2
2022-12-05 23:16:54,868 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.633358512412418, 'Total loss': 0.633358512412418} | train loss {'Reaction outcome loss': 0.6111153769249819, 'Total loss': 0.6111153769249819}
2022-12-05 23:16:54,868 INFO:     Found new best model at epoch 2
2022-12-05 23:16:54,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:54,869 INFO:     Epoch: 3
2022-12-05 23:16:55,563 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.636370374397798, 'Total loss': 0.636370374397798} | train loss {'Reaction outcome loss': 0.5901336984974997, 'Total loss': 0.5901336984974997}
2022-12-05 23:16:55,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:55,563 INFO:     Epoch: 4
2022-12-05 23:16:56,256 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5868449360132217, 'Total loss': 0.5868449360132217} | train loss {'Reaction outcome loss': 0.5755890548837428, 'Total loss': 0.5755890548837428}
2022-12-05 23:16:56,257 INFO:     Found new best model at epoch 4
2022-12-05 23:16:56,257 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:56,257 INFO:     Epoch: 5
2022-12-05 23:16:56,952 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5852111252871427, 'Total loss': 0.5852111252871427} | train loss {'Reaction outcome loss': 0.5624037033441115, 'Total loss': 0.5624037033441115}
2022-12-05 23:16:56,952 INFO:     Found new best model at epoch 5
2022-12-05 23:16:56,952 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:56,953 INFO:     Epoch: 6
2022-12-05 23:16:57,646 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5798749226060781, 'Total loss': 0.5798749226060781} | train loss {'Reaction outcome loss': 0.5569161998982333, 'Total loss': 0.5569161998982333}
2022-12-05 23:16:57,646 INFO:     Found new best model at epoch 6
2022-12-05 23:16:57,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:57,647 INFO:     Epoch: 7
2022-12-05 23:16:58,343 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6162767159667882, 'Total loss': 0.6162767159667882} | train loss {'Reaction outcome loss': 0.5513435770662464, 'Total loss': 0.5513435770662464}
2022-12-05 23:16:58,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:58,344 INFO:     Epoch: 8
2022-12-05 23:16:59,042 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5370140739462592, 'Total loss': 0.5370140739462592} | train loss {'Reaction outcome loss': 0.5526898769091587, 'Total loss': 0.5526898769091587}
2022-12-05 23:16:59,042 INFO:     Found new best model at epoch 8
2022-12-05 23:16:59,043 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:59,043 INFO:     Epoch: 9
2022-12-05 23:16:59,736 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5699714378199794, 'Total loss': 0.5699714378199794} | train loss {'Reaction outcome loss': 0.5428237051379924, 'Total loss': 0.5428237051379924}
2022-12-05 23:16:59,737 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:16:59,737 INFO:     Epoch: 10
2022-12-05 23:17:00,430 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5537544387308034, 'Total loss': 0.5537544387308034} | train loss {'Reaction outcome loss': 0.5380780223072792, 'Total loss': 0.5380780223072792}
2022-12-05 23:17:00,430 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:00,430 INFO:     Epoch: 11
2022-12-05 23:17:01,131 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.565573634749109, 'Total loss': 0.565573634749109} | train loss {'Reaction outcome loss': 0.5334465688588668, 'Total loss': 0.5334465688588668}
2022-12-05 23:17:01,131 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:01,132 INFO:     Epoch: 12
2022-12-05 23:17:01,827 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5662618448788469, 'Total loss': 0.5662618448788469} | train loss {'Reaction outcome loss': 0.5443596354552678, 'Total loss': 0.5443596354552678}
2022-12-05 23:17:01,827 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:01,827 INFO:     Epoch: 13
2022-12-05 23:17:02,525 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5798691189424559, 'Total loss': 0.5798691189424559} | train loss {'Reaction outcome loss': 0.5361620470577356, 'Total loss': 0.5361620470577356}
2022-12-05 23:17:02,525 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:02,525 INFO:     Epoch: 14
2022-12-05 23:17:03,218 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.565748969939622, 'Total loss': 0.565748969939622} | train loss {'Reaction outcome loss': 0.5363429622990744, 'Total loss': 0.5363429622990744}
2022-12-05 23:17:03,218 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:03,218 INFO:     Epoch: 15
2022-12-05 23:17:03,914 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6052182892506773, 'Total loss': 0.6052182892506773} | train loss {'Reaction outcome loss': 0.5331189108138181, 'Total loss': 0.5331189108138181}
2022-12-05 23:17:03,914 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:03,915 INFO:     Epoch: 16
2022-12-05 23:17:04,611 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5758246061476794, 'Total loss': 0.5758246061476794} | train loss {'Reaction outcome loss': 0.539498469355155, 'Total loss': 0.539498469355155}
2022-12-05 23:17:04,611 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:04,611 INFO:     Epoch: 17
2022-12-05 23:17:05,307 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.6023309217257933, 'Total loss': 0.6023309217257933} | train loss {'Reaction outcome loss': 0.5316435788358961, 'Total loss': 0.5316435788358961}
2022-12-05 23:17:05,308 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:05,308 INFO:     Epoch: 18
2022-12-05 23:17:06,007 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5721232254396785, 'Total loss': 0.5721232254396785} | train loss {'Reaction outcome loss': 0.5326692023447581, 'Total loss': 0.5326692023447581}
2022-12-05 23:17:06,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:06,007 INFO:     Epoch: 19
2022-12-05 23:17:06,702 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.571604115719145, 'Total loss': 0.571604115719145} | train loss {'Reaction outcome loss': 0.5333919882166143, 'Total loss': 0.5333919882166143}
2022-12-05 23:17:06,702 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:06,702 INFO:     Epoch: 20
2022-12-05 23:17:07,396 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5671623349189758, 'Total loss': 0.5671623349189758} | train loss {'Reaction outcome loss': 0.5325208826332676, 'Total loss': 0.5325208826332676}
2022-12-05 23:17:07,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:07,396 INFO:     Epoch: 21
2022-12-05 23:17:08,096 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.569636537947438, 'Total loss': 0.569636537947438} | train loss {'Reaction outcome loss': 0.5382653469942054, 'Total loss': 0.5382653469942054}
2022-12-05 23:17:08,096 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:08,096 INFO:     Epoch: 22
2022-12-05 23:17:08,790 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5669293850660324, 'Total loss': 0.5669293850660324} | train loss {'Reaction outcome loss': 0.535290599173429, 'Total loss': 0.535290599173429}
2022-12-05 23:17:08,790 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:08,790 INFO:     Epoch: 23
2022-12-05 23:17:09,483 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5927656079557809, 'Total loss': 0.5927656079557809} | train loss {'Reaction outcome loss': 0.5312948995098776, 'Total loss': 0.5312948995098776}
2022-12-05 23:17:09,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:09,483 INFO:     Epoch: 24
2022-12-05 23:17:10,179 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5654331982474435, 'Total loss': 0.5654331982474435} | train loss {'Reaction outcome loss': 0.5380825298781298, 'Total loss': 0.5380825298781298}
2022-12-05 23:17:10,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:10,179 INFO:     Epoch: 25
2022-12-05 23:17:10,874 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.6047167757695372, 'Total loss': 0.6047167757695372} | train loss {'Reaction outcome loss': 0.5325504743323034, 'Total loss': 0.5325504743323034}
2022-12-05 23:17:10,874 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:10,874 INFO:     Epoch: 26
2022-12-05 23:17:11,571 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5691774040460587, 'Total loss': 0.5691774040460587} | train loss {'Reaction outcome loss': 0.5296784100483874, 'Total loss': 0.5296784100483874}
2022-12-05 23:17:11,572 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:11,572 INFO:     Epoch: 27
2022-12-05 23:17:12,268 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5799012776802887, 'Total loss': 0.5799012776802887} | train loss {'Reaction outcome loss': 0.5267733660279488, 'Total loss': 0.5267733660279488}
2022-12-05 23:17:12,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:12,269 INFO:     Epoch: 28
2022-12-05 23:17:12,962 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5821813162077557, 'Total loss': 0.5821813162077557} | train loss {'Reaction outcome loss': 0.5248886225174885, 'Total loss': 0.5248886225174885}
2022-12-05 23:17:12,962 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:12,962 INFO:     Epoch: 29
2022-12-05 23:17:13,656 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5797823836857622, 'Total loss': 0.5797823836857622} | train loss {'Reaction outcome loss': 0.5316965903554643, 'Total loss': 0.5316965903554643}
2022-12-05 23:17:13,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:13,656 INFO:     Epoch: 30
2022-12-05 23:17:14,349 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5727644688026472, 'Total loss': 0.5727644688026472} | train loss {'Reaction outcome loss': 0.5215468887163668, 'Total loss': 0.5215468887163668}
2022-12-05 23:17:14,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:14,350 INFO:     Epoch: 31
2022-12-05 23:17:15,045 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.6161066381768747, 'Total loss': 0.6161066381768747} | train loss {'Reaction outcome loss': 0.5262536744682156, 'Total loss': 0.5262536744682156}
2022-12-05 23:17:15,045 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:15,045 INFO:     Epoch: 32
2022-12-05 23:17:15,744 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.6635937829586592, 'Total loss': 0.6635937829586592} | train loss {'Reaction outcome loss': 0.527391687461308, 'Total loss': 0.527391687461308}
2022-12-05 23:17:15,744 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:15,744 INFO:     Epoch: 33
2022-12-05 23:17:16,439 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5802293545143171, 'Total loss': 0.5802293545143171} | train loss {'Reaction outcome loss': 0.530378754224096, 'Total loss': 0.530378754224096}
2022-12-05 23:17:16,439 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:16,439 INFO:     Epoch: 34
2022-12-05 23:17:17,133 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.57951439849355, 'Total loss': 0.57951439849355} | train loss {'Reaction outcome loss': 0.5269605228487326, 'Total loss': 0.5269605228487326}
2022-12-05 23:17:17,133 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:17,133 INFO:     Epoch: 35
2022-12-05 23:17:17,827 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5591449737548828, 'Total loss': 0.5591449737548828} | train loss {'Reaction outcome loss': 0.5259290951855329, 'Total loss': 0.5259290951855329}
2022-12-05 23:17:17,827 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:17,827 INFO:     Epoch: 36
2022-12-05 23:17:18,521 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5674634142355486, 'Total loss': 0.5674634142355486} | train loss {'Reaction outcome loss': 0.5266836376214514, 'Total loss': 0.5266836376214514}
2022-12-05 23:17:18,521 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:18,521 INFO:     Epoch: 37
2022-12-05 23:17:19,215 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.6403945657339963, 'Total loss': 0.6403945657339963} | train loss {'Reaction outcome loss': 0.5294502202953612, 'Total loss': 0.5294502202953612}
2022-12-05 23:17:19,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:19,215 INFO:     Epoch: 38
2022-12-05 23:17:19,908 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.6178702898323536, 'Total loss': 0.6178702898323536} | train loss {'Reaction outcome loss': 0.5245207945303041, 'Total loss': 0.5245207945303041}
2022-12-05 23:17:19,908 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:19,908 INFO:     Epoch: 39
2022-12-05 23:17:20,606 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5616070160811598, 'Total loss': 0.5616070160811598} | train loss {'Reaction outcome loss': 0.5357745447937323, 'Total loss': 0.5357745447937323}
2022-12-05 23:17:20,606 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:20,606 INFO:     Epoch: 40
2022-12-05 23:17:21,305 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5771091397513043, 'Total loss': 0.5771091397513043} | train loss {'Reaction outcome loss': 0.5274520595462955, 'Total loss': 0.5274520595462955}
2022-12-05 23:17:21,306 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:21,306 INFO:     Epoch: 41
2022-12-05 23:17:22,003 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5725591148842465, 'Total loss': 0.5725591148842465} | train loss {'Reaction outcome loss': 0.5300993444968243, 'Total loss': 0.5300993444968243}
2022-12-05 23:17:22,003 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:22,003 INFO:     Epoch: 42
2022-12-05 23:17:22,701 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5489263222976164, 'Total loss': 0.5489263222976164} | train loss {'Reaction outcome loss': 0.5309864683418858, 'Total loss': 0.5309864683418858}
2022-12-05 23:17:22,701 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:22,701 INFO:     Epoch: 43
2022-12-05 23:17:23,397 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5873637409372763, 'Total loss': 0.5873637409372763} | train loss {'Reaction outcome loss': 0.5278924414697959, 'Total loss': 0.5278924414697959}
2022-12-05 23:17:23,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:23,398 INFO:     Epoch: 44
2022-12-05 23:17:24,096 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5637816241519018, 'Total loss': 0.5637816241519018} | train loss {'Reaction outcome loss': 0.5339366536967608, 'Total loss': 0.5339366536967608}
2022-12-05 23:17:24,097 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:24,098 INFO:     Epoch: 45
2022-12-05 23:17:24,801 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5799307999285784, 'Total loss': 0.5799307999285784} | train loss {'Reaction outcome loss': 0.5283752159804714, 'Total loss': 0.5283752159804714}
2022-12-05 23:17:24,801 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:24,801 INFO:     Epoch: 46
2022-12-05 23:17:25,498 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.6138578849759969, 'Total loss': 0.6138578849759969} | train loss {'Reaction outcome loss': 0.5353884144096959, 'Total loss': 0.5353884144096959}
2022-12-05 23:17:25,498 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:25,498 INFO:     Epoch: 47
2022-12-05 23:17:26,197 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5704520947553895, 'Total loss': 0.5704520947553895} | train loss {'Reaction outcome loss': 0.5332469220064124, 'Total loss': 0.5332469220064124}
2022-12-05 23:17:26,197 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:26,197 INFO:     Epoch: 48
2022-12-05 23:17:26,895 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.6074809174646031, 'Total loss': 0.6074809174646031} | train loss {'Reaction outcome loss': 0.5307725379661637, 'Total loss': 0.5307725379661637}
2022-12-05 23:17:26,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:26,895 INFO:     Epoch: 49
2022-12-05 23:17:27,596 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5624906346201897, 'Total loss': 0.5624906346201897} | train loss {'Reaction outcome loss': 0.5286672806861449, 'Total loss': 0.5286672806861449}
2022-12-05 23:17:27,596 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:27,596 INFO:     Epoch: 50
2022-12-05 23:17:28,293 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5514745089140806, 'Total loss': 0.5514745089140806} | train loss {'Reaction outcome loss': 0.5334850263838865, 'Total loss': 0.5334850263838865}
2022-12-05 23:17:28,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:28,293 INFO:     Epoch: 51
2022-12-05 23:17:28,990 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5860780734907497, 'Total loss': 0.5860780734907497} | train loss {'Reaction outcome loss': 0.5322280676997437, 'Total loss': 0.5322280676997437}
2022-12-05 23:17:28,990 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:28,991 INFO:     Epoch: 52
2022-12-05 23:17:29,687 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5556104223836552, 'Total loss': 0.5556104223836552} | train loss {'Reaction outcome loss': 0.5246617299561598, 'Total loss': 0.5246617299561598}
2022-12-05 23:17:29,687 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:29,688 INFO:     Epoch: 53
2022-12-05 23:17:30,386 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5766463665799662, 'Total loss': 0.5766463665799662} | train loss {'Reaction outcome loss': 0.5245467966916609, 'Total loss': 0.5245467966916609}
2022-12-05 23:17:30,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:30,387 INFO:     Epoch: 54
2022-12-05 23:17:31,085 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5909201055765152, 'Total loss': 0.5909201055765152} | train loss {'Reaction outcome loss': 0.5356046063559395, 'Total loss': 0.5356046063559395}
2022-12-05 23:17:31,085 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:31,085 INFO:     Epoch: 55
2022-12-05 23:17:31,786 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5762855705212463, 'Total loss': 0.5762855705212463} | train loss {'Reaction outcome loss': 0.5262375517767303, 'Total loss': 0.5262375517767303}
2022-12-05 23:17:31,786 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:31,787 INFO:     Epoch: 56
2022-12-05 23:17:32,481 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.6351412995295092, 'Total loss': 0.6351412995295092} | train loss {'Reaction outcome loss': 0.5247810330926156, 'Total loss': 0.5247810330926156}
2022-12-05 23:17:32,482 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:32,482 INFO:     Epoch: 57
2022-12-05 23:17:33,180 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5797132551670074, 'Total loss': 0.5797132551670074} | train loss {'Reaction outcome loss': 0.5285892981047533, 'Total loss': 0.5285892981047533}
2022-12-05 23:17:33,181 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:33,181 INFO:     Epoch: 58
2022-12-05 23:17:33,878 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5643486627800898, 'Total loss': 0.5643486627800898} | train loss {'Reaction outcome loss': 0.5297308631089269, 'Total loss': 0.5297308631089269}
2022-12-05 23:17:33,878 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:33,878 INFO:     Epoch: 59
2022-12-05 23:17:34,575 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5850151343779131, 'Total loss': 0.5850151343779131} | train loss {'Reaction outcome loss': 0.5311873973632345, 'Total loss': 0.5311873973632345}
2022-12-05 23:17:34,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:34,575 INFO:     Epoch: 60
2022-12-05 23:17:35,271 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5940673933787779, 'Total loss': 0.5940673933787779} | train loss {'Reaction outcome loss': 0.53199505678245, 'Total loss': 0.53199505678245}
2022-12-05 23:17:35,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:35,271 INFO:     Epoch: 61
2022-12-05 23:17:35,968 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5711155181581323, 'Total loss': 0.5711155181581323} | train loss {'Reaction outcome loss': 0.5307293861496205, 'Total loss': 0.5307293861496205}
2022-12-05 23:17:35,968 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:35,968 INFO:     Epoch: 62
2022-12-05 23:17:36,670 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.591827620159496, 'Total loss': 0.591827620159496} | train loss {'Reaction outcome loss': 0.5298526182466624, 'Total loss': 0.5298526182466624}
2022-12-05 23:17:36,670 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:36,670 INFO:     Epoch: 63
2022-12-05 23:17:37,369 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.550262755968354, 'Total loss': 0.550262755968354} | train loss {'Reaction outcome loss': 0.5320769030220655, 'Total loss': 0.5320769030220655}
2022-12-05 23:17:37,369 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:37,369 INFO:     Epoch: 64
2022-12-05 23:17:38,066 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5756188275461848, 'Total loss': 0.5756188275461848} | train loss {'Reaction outcome loss': 0.5333982545502332, 'Total loss': 0.5333982545502332}
2022-12-05 23:17:38,066 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:38,066 INFO:     Epoch: 65
2022-12-05 23:17:38,760 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5904469977725636, 'Total loss': 0.5904469977725636} | train loss {'Reaction outcome loss': 0.5237047345662603, 'Total loss': 0.5237047345662603}
2022-12-05 23:17:38,760 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:38,760 INFO:     Epoch: 66
2022-12-05 23:17:39,460 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5674901503053579, 'Total loss': 0.5674901503053579} | train loss {'Reaction outcome loss': 0.5279041983643357, 'Total loss': 0.5279041983643357}
2022-12-05 23:17:39,460 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:39,460 INFO:     Epoch: 67
2022-12-05 23:17:40,161 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5864983248439702, 'Total loss': 0.5864983248439702} | train loss {'Reaction outcome loss': 0.5300959483701355, 'Total loss': 0.5300959483701355}
2022-12-05 23:17:40,161 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:40,161 INFO:     Epoch: 68
2022-12-05 23:17:40,857 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5770370784130964, 'Total loss': 0.5770370784130964} | train loss {'Reaction outcome loss': 0.5354404428175518, 'Total loss': 0.5354404428175518}
2022-12-05 23:17:40,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:40,858 INFO:     Epoch: 69
2022-12-05 23:17:41,556 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6001125357367776, 'Total loss': 0.6001125357367776} | train loss {'Reaction outcome loss': 0.5256736878837858, 'Total loss': 0.5256736878837858}
2022-12-05 23:17:41,556 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:41,556 INFO:     Epoch: 70
2022-12-05 23:17:42,254 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.6029365596954118, 'Total loss': 0.6029365596954118} | train loss {'Reaction outcome loss': 0.5289419731923513, 'Total loss': 0.5289419731923513}
2022-12-05 23:17:42,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:42,254 INFO:     Epoch: 71
2022-12-05 23:17:42,952 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6068213974887674, 'Total loss': 0.6068213974887674} | train loss {'Reaction outcome loss': 0.5257297361079527, 'Total loss': 0.5257297361079527}
2022-12-05 23:17:42,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:42,953 INFO:     Epoch: 72
2022-12-05 23:17:43,651 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.581579134545543, 'Total loss': 0.581579134545543} | train loss {'Reaction outcome loss': 0.5338383627485256, 'Total loss': 0.5338383627485256}
2022-12-05 23:17:43,651 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:43,651 INFO:     Epoch: 73
2022-12-05 23:17:44,346 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5610496361147274, 'Total loss': 0.5610496361147274} | train loss {'Reaction outcome loss': 0.5292682036453363, 'Total loss': 0.5292682036453363}
2022-12-05 23:17:44,346 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:44,346 INFO:     Epoch: 74
2022-12-05 23:17:45,042 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5728086903691292, 'Total loss': 0.5728086903691292} | train loss {'Reaction outcome loss': 0.5240377934611573, 'Total loss': 0.5240377934611573}
2022-12-05 23:17:45,042 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:45,042 INFO:     Epoch: 75
2022-12-05 23:17:45,739 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5649763711474158, 'Total loss': 0.5649763711474158} | train loss {'Reaction outcome loss': 0.5276971692333416, 'Total loss': 0.5276971692333416}
2022-12-05 23:17:45,739 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:45,739 INFO:     Epoch: 76
2022-12-05 23:17:46,434 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5755572285164486, 'Total loss': 0.5755572285164486} | train loss {'Reaction outcome loss': 0.5319269916232752, 'Total loss': 0.5319269916232752}
2022-12-05 23:17:46,434 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:46,434 INFO:     Epoch: 77
2022-12-05 23:17:47,129 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5925925407897342, 'Total loss': 0.5925925407897342} | train loss {'Reaction outcome loss': 0.5277967593499593, 'Total loss': 0.5277967593499593}
2022-12-05 23:17:47,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:47,129 INFO:     Epoch: 78
2022-12-05 23:17:47,831 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5652973123572089, 'Total loss': 0.5652973123572089} | train loss {'Reaction outcome loss': 0.5342915343994997, 'Total loss': 0.5342915343994997}
2022-12-05 23:17:47,832 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:47,832 INFO:     Epoch: 79
2022-12-05 23:17:48,528 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5883290110663935, 'Total loss': 0.5883290110663935} | train loss {'Reaction outcome loss': 0.5287634069822272, 'Total loss': 0.5287634069822272}
2022-12-05 23:17:48,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:48,528 INFO:     Epoch: 80
2022-12-05 23:17:49,224 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5553725849498402, 'Total loss': 0.5553725849498402} | train loss {'Reaction outcome loss': 0.5307134790079934, 'Total loss': 0.5307134790079934}
2022-12-05 23:17:49,224 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:49,224 INFO:     Epoch: 81
2022-12-05 23:17:49,923 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5492855036123232, 'Total loss': 0.5492855036123232} | train loss {'Reaction outcome loss': 0.5264527841490142, 'Total loss': 0.5264527841490142}
2022-12-05 23:17:49,923 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:49,923 INFO:     Epoch: 82
2022-12-05 23:17:50,618 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5722170824354346, 'Total loss': 0.5722170824354346} | train loss {'Reaction outcome loss': 0.5305419883557728, 'Total loss': 0.5305419883557728}
2022-12-05 23:17:50,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:50,618 INFO:     Epoch: 83
2022-12-05 23:17:51,313 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.57489367777651, 'Total loss': 0.57489367777651} | train loss {'Reaction outcome loss': 0.5282209036605698, 'Total loss': 0.5282209036605698}
2022-12-05 23:17:51,313 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:51,313 INFO:     Epoch: 84
2022-12-05 23:17:52,007 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5863475640389052, 'Total loss': 0.5863475640389052} | train loss {'Reaction outcome loss': 0.5317969491287153, 'Total loss': 0.5317969491287153}
2022-12-05 23:17:52,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:52,008 INFO:     Epoch: 85
2022-12-05 23:17:52,705 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5622425722804937, 'Total loss': 0.5622425722804937} | train loss {'Reaction outcome loss': 0.5281970961361515, 'Total loss': 0.5281970961361515}
2022-12-05 23:17:52,706 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:52,706 INFO:     Epoch: 86
2022-12-05 23:17:53,403 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5802702250128443, 'Total loss': 0.5802702250128443} | train loss {'Reaction outcome loss': 0.5358202266449831, 'Total loss': 0.5358202266449831}
2022-12-05 23:17:53,403 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:53,403 INFO:     Epoch: 87
2022-12-05 23:17:54,100 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6183529868721962, 'Total loss': 0.6183529868721962} | train loss {'Reaction outcome loss': 0.5226883180895631, 'Total loss': 0.5226883180895631}
2022-12-05 23:17:54,100 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:54,100 INFO:     Epoch: 88
2022-12-05 23:17:54,799 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5588294701142744, 'Total loss': 0.5588294701142744} | train loss {'Reaction outcome loss': 0.5310968583943892, 'Total loss': 0.5310968583943892}
2022-12-05 23:17:54,800 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:54,800 INFO:     Epoch: 89
2022-12-05 23:17:55,497 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.563575838777152, 'Total loss': 0.563575838777152} | train loss {'Reaction outcome loss': 0.5280305323552112, 'Total loss': 0.5280305323552112}
2022-12-05 23:17:55,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:55,497 INFO:     Epoch: 90
2022-12-05 23:17:56,192 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.559176852079955, 'Total loss': 0.559176852079955} | train loss {'Reaction outcome loss': 0.5302079482954376, 'Total loss': 0.5302079482954376}
2022-12-05 23:17:56,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:56,193 INFO:     Epoch: 91
2022-12-05 23:17:56,895 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5933968472209844, 'Total loss': 0.5933968472209844} | train loss {'Reaction outcome loss': 0.5312583357095718, 'Total loss': 0.5312583357095718}
2022-12-05 23:17:56,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:56,895 INFO:     Epoch: 92
2022-12-05 23:17:57,595 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5897396325387738, 'Total loss': 0.5897396325387738} | train loss {'Reaction outcome loss': 0.5294409507999615, 'Total loss': 0.5294409507999615}
2022-12-05 23:17:57,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:57,595 INFO:     Epoch: 93
2022-12-05 23:17:58,292 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5930680605498228, 'Total loss': 0.5930680605498228} | train loss {'Reaction outcome loss': 0.5271467493504894, 'Total loss': 0.5271467493504894}
2022-12-05 23:17:58,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:58,293 INFO:     Epoch: 94
2022-12-05 23:17:58,991 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5708189078352668, 'Total loss': 0.5708189078352668} | train loss {'Reaction outcome loss': 0.5309502285353992, 'Total loss': 0.5309502285353992}
2022-12-05 23:17:58,991 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:58,991 INFO:     Epoch: 95
2022-12-05 23:17:59,690 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5923092656514861, 'Total loss': 0.5923092656514861} | train loss {'Reaction outcome loss': 0.5259729727798579, 'Total loss': 0.5259729727798579}
2022-12-05 23:17:59,690 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:17:59,691 INFO:     Epoch: 96
2022-12-05 23:18:00,388 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5804306458343159, 'Total loss': 0.5804306458343159} | train loss {'Reaction outcome loss': 0.5278054873554074, 'Total loss': 0.5278054873554074}
2022-12-05 23:18:00,388 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:00,388 INFO:     Epoch: 97
2022-12-05 23:18:01,086 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5806941823525862, 'Total loss': 0.5806941823525862} | train loss {'Reaction outcome loss': 0.5266298179723778, 'Total loss': 0.5266298179723778}
2022-12-05 23:18:01,087 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:01,087 INFO:     Epoch: 98
2022-12-05 23:18:01,786 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5653717761689966, 'Total loss': 0.5653717761689966} | train loss {'Reaction outcome loss': 0.5321981001873406, 'Total loss': 0.5321981001873406}
2022-12-05 23:18:01,786 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:01,786 INFO:     Epoch: 99
2022-12-05 23:18:02,489 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5594868490641768, 'Total loss': 0.5594868490641768} | train loss {'Reaction outcome loss': 0.5289693354343882, 'Total loss': 0.5289693354343882}
2022-12-05 23:18:02,489 INFO:     Best model found after epoch 9 of 100.
2022-12-05 23:18:02,489 INFO:   Done with stage: TRAINING
2022-12-05 23:18:02,489 INFO:   Starting stage: EVALUATION
2022-12-05 23:18:02,619 INFO:   Done with stage: EVALUATION
2022-12-05 23:18:02,619 INFO:   Leaving out SEQ value Fold_1
2022-12-05 23:18:02,632 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 23:18:02,632 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:18:03,272 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:18:03,273 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:18:03,343 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:18:03,343 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:18:03,343 INFO:     No hyperparam tuning for this model
2022-12-05 23:18:03,343 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:18:03,343 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:18:03,344 INFO:     None feature selector for col prot
2022-12-05 23:18:03,344 INFO:     None feature selector for col prot
2022-12-05 23:18:03,344 INFO:     None feature selector for col prot
2022-12-05 23:18:03,345 INFO:     None feature selector for col chem
2022-12-05 23:18:03,345 INFO:     None feature selector for col chem
2022-12-05 23:18:03,345 INFO:     None feature selector for col chem
2022-12-05 23:18:03,345 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:18:03,345 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:18:03,346 INFO:     Number of params in model 215731
2022-12-05 23:18:03,349 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:18:03,350 INFO:   Starting stage: TRAINING
2022-12-05 23:18:03,407 INFO:     Val loss before train {'Reaction outcome loss': 0.9733037799596786, 'Total loss': 0.9733037799596786}
2022-12-05 23:18:03,407 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:03,407 INFO:     Epoch: 0
2022-12-05 23:18:04,104 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7375127056782896, 'Total loss': 0.7375127056782896} | train loss {'Reaction outcome loss': 0.820313687957063, 'Total loss': 0.820313687957063}
2022-12-05 23:18:04,104 INFO:     Found new best model at epoch 0
2022-12-05 23:18:04,105 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:04,105 INFO:     Epoch: 1
2022-12-05 23:18:04,801 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6190825341777368, 'Total loss': 0.6190825341777368} | train loss {'Reaction outcome loss': 0.6665472182084103, 'Total loss': 0.6665472182084103}
2022-12-05 23:18:04,801 INFO:     Found new best model at epoch 1
2022-12-05 23:18:04,802 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:04,802 INFO:     Epoch: 2
2022-12-05 23:18:05,504 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5557911592451009, 'Total loss': 0.5557911592451009} | train loss {'Reaction outcome loss': 0.6127698539471139, 'Total loss': 0.6127698539471139}
2022-12-05 23:18:05,504 INFO:     Found new best model at epoch 2
2022-12-05 23:18:05,505 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:05,505 INFO:     Epoch: 3
2022-12-05 23:18:06,204 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5798871490088376, 'Total loss': 0.5798871490088376} | train loss {'Reaction outcome loss': 0.5851857354446334, 'Total loss': 0.5851857354446334}
2022-12-05 23:18:06,204 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:06,204 INFO:     Epoch: 4
2022-12-05 23:18:06,901 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5538840253244747, 'Total loss': 0.5538840253244747} | train loss {'Reaction outcome loss': 0.5775070473855856, 'Total loss': 0.5775070473855856}
2022-12-05 23:18:06,901 INFO:     Found new best model at epoch 4
2022-12-05 23:18:06,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:06,902 INFO:     Epoch: 5
2022-12-05 23:18:07,603 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.565524005077102, 'Total loss': 0.565524005077102} | train loss {'Reaction outcome loss': 0.5577901241122459, 'Total loss': 0.5577901241122459}
2022-12-05 23:18:07,603 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:07,603 INFO:     Epoch: 6
2022-12-05 23:18:08,303 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5252008278938857, 'Total loss': 0.5252008278938857} | train loss {'Reaction outcome loss': 0.5599218414754283, 'Total loss': 0.5599218414754283}
2022-12-05 23:18:08,303 INFO:     Found new best model at epoch 6
2022-12-05 23:18:08,304 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:08,304 INFO:     Epoch: 7
2022-12-05 23:18:09,002 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5358320002190091, 'Total loss': 0.5358320002190091} | train loss {'Reaction outcome loss': 0.5471016079795604, 'Total loss': 0.5471016079795604}
2022-12-05 23:18:09,003 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:09,003 INFO:     Epoch: 8
2022-12-05 23:18:09,701 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5667883564125408, 'Total loss': 0.5667883564125408} | train loss {'Reaction outcome loss': 0.5532698217703371, 'Total loss': 0.5532698217703371}
2022-12-05 23:18:09,701 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:09,701 INFO:     Epoch: 9
2022-12-05 23:18:10,397 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5448365573855963, 'Total loss': 0.5448365573855963} | train loss {'Reaction outcome loss': 0.5463515566319835, 'Total loss': 0.5463515566319835}
2022-12-05 23:18:10,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:10,397 INFO:     Epoch: 10
2022-12-05 23:18:11,093 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5315870776433836, 'Total loss': 0.5315870776433836} | train loss {'Reaction outcome loss': 0.5447395592319723, 'Total loss': 0.5447395592319723}
2022-12-05 23:18:11,093 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:11,093 INFO:     Epoch: 11
2022-12-05 23:18:11,793 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5327706709504128, 'Total loss': 0.5327706709504128} | train loss {'Reaction outcome loss': 0.5431484421296996, 'Total loss': 0.5431484421296996}
2022-12-05 23:18:11,793 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:11,793 INFO:     Epoch: 12
2022-12-05 23:18:12,490 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5343417494811795, 'Total loss': 0.5343417494811795} | train loss {'Reaction outcome loss': 0.5337803167348005, 'Total loss': 0.5337803167348005}
2022-12-05 23:18:12,490 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:12,491 INFO:     Epoch: 13
2022-12-05 23:18:13,189 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5732554447921839, 'Total loss': 0.5732554447921839} | train loss {'Reaction outcome loss': 0.5307075127046935, 'Total loss': 0.5307075127046935}
2022-12-05 23:18:13,190 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:13,190 INFO:     Epoch: 14
2022-12-05 23:18:13,887 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5240055491978471, 'Total loss': 0.5240055491978471} | train loss {'Reaction outcome loss': 0.5377792131535861, 'Total loss': 0.5377792131535861}
2022-12-05 23:18:13,887 INFO:     Found new best model at epoch 14
2022-12-05 23:18:13,887 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:13,888 INFO:     Epoch: 15
2022-12-05 23:18:14,589 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.526519696820866, 'Total loss': 0.526519696820866} | train loss {'Reaction outcome loss': 0.5335153579103703, 'Total loss': 0.5335153579103703}
2022-12-05 23:18:14,589 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:14,590 INFO:     Epoch: 16
2022-12-05 23:18:15,297 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5218282528221607, 'Total loss': 0.5218282528221607} | train loss {'Reaction outcome loss': 0.5312930250654415, 'Total loss': 0.5312930250654415}
2022-12-05 23:18:15,297 INFO:     Found new best model at epoch 16
2022-12-05 23:18:15,298 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:15,298 INFO:     Epoch: 17
2022-12-05 23:18:16,001 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5119524110447277, 'Total loss': 0.5119524110447277} | train loss {'Reaction outcome loss': 0.5314765329871859, 'Total loss': 0.5314765329871859}
2022-12-05 23:18:16,002 INFO:     Found new best model at epoch 17
2022-12-05 23:18:16,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:16,002 INFO:     Epoch: 18
2022-12-05 23:18:16,700 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4948136725208976, 'Total loss': 0.4948136725208976} | train loss {'Reaction outcome loss': 0.5249737984063674, 'Total loss': 0.5249737984063674}
2022-12-05 23:18:16,700 INFO:     Found new best model at epoch 18
2022-12-05 23:18:16,700 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:16,700 INFO:     Epoch: 19
2022-12-05 23:18:17,398 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.537373573942618, 'Total loss': 0.537373573942618} | train loss {'Reaction outcome loss': 0.5265749791446998, 'Total loss': 0.5265749791446998}
2022-12-05 23:18:17,398 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:17,398 INFO:     Epoch: 20
2022-12-05 23:18:18,096 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5328986577012322, 'Total loss': 0.5328986577012322} | train loss {'Reaction outcome loss': 0.539056943995612, 'Total loss': 0.539056943995612}
2022-12-05 23:18:18,096 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:18,096 INFO:     Epoch: 21
2022-12-05 23:18:18,794 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5018100000240586, 'Total loss': 0.5018100000240586} | train loss {'Reaction outcome loss': 0.5255268358454412, 'Total loss': 0.5255268358454412}
2022-12-05 23:18:18,795 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:18,795 INFO:     Epoch: 22
2022-12-05 23:18:19,497 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5280856029553846, 'Total loss': 0.5280856029553846} | train loss {'Reaction outcome loss': 0.5256788903353166, 'Total loss': 0.5256788903353166}
2022-12-05 23:18:19,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:19,497 INFO:     Epoch: 23
2022-12-05 23:18:20,193 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5001797988502816, 'Total loss': 0.5001797988502816} | train loss {'Reaction outcome loss': 0.5303490084652998, 'Total loss': 0.5303490084652998}
2022-12-05 23:18:20,193 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:20,193 INFO:     Epoch: 24
2022-12-05 23:18:20,890 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5207741985266859, 'Total loss': 0.5207741985266859} | train loss {'Reaction outcome loss': 0.5172574986608661, 'Total loss': 0.5172574986608661}
2022-12-05 23:18:20,890 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:20,890 INFO:     Epoch: 25
2022-12-05 23:18:21,586 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5292956375262954, 'Total loss': 0.5292956375262954} | train loss {'Reaction outcome loss': 0.5258356191065847, 'Total loss': 0.5258356191065847}
2022-12-05 23:18:21,587 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:21,587 INFO:     Epoch: 26
2022-12-05 23:18:22,284 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5133905840868299, 'Total loss': 0.5133905840868299} | train loss {'Reaction outcome loss': 0.5293602374135231, 'Total loss': 0.5293602374135231}
2022-12-05 23:18:22,284 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:22,284 INFO:     Epoch: 27
2022-12-05 23:18:22,984 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5405415174635974, 'Total loss': 0.5405415174635974} | train loss {'Reaction outcome loss': 0.5210890196415843, 'Total loss': 0.5210890196415843}
2022-12-05 23:18:22,984 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:22,985 INFO:     Epoch: 28
2022-12-05 23:18:23,686 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4971721118146723, 'Total loss': 0.4971721118146723} | train loss {'Reaction outcome loss': 0.5212244360422601, 'Total loss': 0.5212244360422601}
2022-12-05 23:18:23,686 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:23,686 INFO:     Epoch: 29
2022-12-05 23:18:24,386 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4961066413670778, 'Total loss': 0.4961066413670778} | train loss {'Reaction outcome loss': 0.5204420048363355, 'Total loss': 0.5204420048363355}
2022-12-05 23:18:24,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:24,386 INFO:     Epoch: 30
2022-12-05 23:18:25,091 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5193058804354884, 'Total loss': 0.5193058804354884} | train loss {'Reaction outcome loss': 0.5184557847222503, 'Total loss': 0.5184557847222503}
2022-12-05 23:18:25,092 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:25,092 INFO:     Epoch: 31
2022-12-05 23:18:25,794 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5073317194526846, 'Total loss': 0.5073317194526846} | train loss {'Reaction outcome loss': 0.5153068372181484, 'Total loss': 0.5153068372181484}
2022-12-05 23:18:25,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:25,794 INFO:     Epoch: 32
2022-12-05 23:18:26,496 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5734441930597479, 'Total loss': 0.5734441930597479} | train loss {'Reaction outcome loss': 0.5191908477520456, 'Total loss': 0.5191908477520456}
2022-12-05 23:18:26,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:26,497 INFO:     Epoch: 33
2022-12-05 23:18:27,198 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4958028163422238, 'Total loss': 0.4958028163422238} | train loss {'Reaction outcome loss': 0.5264491913878188, 'Total loss': 0.5264491913878188}
2022-12-05 23:18:27,199 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:27,199 INFO:     Epoch: 34
2022-12-05 23:18:27,898 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5030448260632429, 'Total loss': 0.5030448260632429} | train loss {'Reaction outcome loss': 0.5115563283161241, 'Total loss': 0.5115563283161241}
2022-12-05 23:18:27,899 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:27,899 INFO:     Epoch: 35
2022-12-05 23:18:28,600 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48871671814810147, 'Total loss': 0.48871671814810147} | train loss {'Reaction outcome loss': 0.5263397682686242, 'Total loss': 0.5263397682686242}
2022-12-05 23:18:28,600 INFO:     Found new best model at epoch 35
2022-12-05 23:18:28,601 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:28,601 INFO:     Epoch: 36
2022-12-05 23:18:29,300 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49625949426130816, 'Total loss': 0.49625949426130816} | train loss {'Reaction outcome loss': 0.5196151037605441, 'Total loss': 0.5196151037605441}
2022-12-05 23:18:29,300 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:29,300 INFO:     Epoch: 37
2022-12-05 23:18:30,003 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5209324336187406, 'Total loss': 0.5209324336187406} | train loss {'Reaction outcome loss': 0.517865075809615, 'Total loss': 0.517865075809615}
2022-12-05 23:18:30,003 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:30,003 INFO:     Epoch: 38
2022-12-05 23:18:30,703 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5043612759221684, 'Total loss': 0.5043612759221684} | train loss {'Reaction outcome loss': 0.5196173385697969, 'Total loss': 0.5196173385697969}
2022-12-05 23:18:30,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:30,704 INFO:     Epoch: 39
2022-12-05 23:18:31,406 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5103642246262594, 'Total loss': 0.5103642246262594} | train loss {'Reaction outcome loss': 0.5092472895067566, 'Total loss': 0.5092472895067566}
2022-12-05 23:18:31,407 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:31,407 INFO:     Epoch: 40
2022-12-05 23:18:32,107 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.49931888485496695, 'Total loss': 0.49931888485496695} | train loss {'Reaction outcome loss': 0.523279346860185, 'Total loss': 0.523279346860185}
2022-12-05 23:18:32,107 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:32,107 INFO:     Epoch: 41
2022-12-05 23:18:32,806 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5297307558357716, 'Total loss': 0.5297307558357716} | train loss {'Reaction outcome loss': 0.5104596869677913, 'Total loss': 0.5104596869677913}
2022-12-05 23:18:32,806 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:32,806 INFO:     Epoch: 42
2022-12-05 23:18:33,505 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5416106520728632, 'Total loss': 0.5416106520728632} | train loss {'Reaction outcome loss': 0.5205824396439961, 'Total loss': 0.5205824396439961}
2022-12-05 23:18:33,505 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:33,505 INFO:     Epoch: 43
2022-12-05 23:18:34,205 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5742269925434481, 'Total loss': 0.5742269925434481} | train loss {'Reaction outcome loss': 0.5127852097457769, 'Total loss': 0.5127852097457769}
2022-12-05 23:18:34,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:34,205 INFO:     Epoch: 44
2022-12-05 23:18:34,903 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5048968426205895, 'Total loss': 0.5048968426205895} | train loss {'Reaction outcome loss': 0.5100577200553855, 'Total loss': 0.5100577200553855}
2022-12-05 23:18:34,903 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:34,903 INFO:     Epoch: 45
2022-12-05 23:18:35,608 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5255284173922106, 'Total loss': 0.5255284173922106} | train loss {'Reaction outcome loss': 0.5194601990738693, 'Total loss': 0.5194601990738693}
2022-12-05 23:18:35,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:35,608 INFO:     Epoch: 46
2022-12-05 23:18:36,313 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5037779655646194, 'Total loss': 0.5037779655646194} | train loss {'Reaction outcome loss': 0.5130989766850763, 'Total loss': 0.5130989766850763}
2022-12-05 23:18:36,313 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:36,313 INFO:     Epoch: 47
2022-12-05 23:18:37,020 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5148714777420867, 'Total loss': 0.5148714777420867} | train loss {'Reaction outcome loss': 0.5103472939559391, 'Total loss': 0.5103472939559391}
2022-12-05 23:18:37,020 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:37,021 INFO:     Epoch: 48
2022-12-05 23:18:37,729 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5122430940920656, 'Total loss': 0.5122430940920656} | train loss {'Reaction outcome loss': 0.5185125510303341, 'Total loss': 0.5185125510303341}
2022-12-05 23:18:37,729 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:37,729 INFO:     Epoch: 49
2022-12-05 23:18:38,432 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5045287937603213, 'Total loss': 0.5045287937603213} | train loss {'Reaction outcome loss': 0.5078797269840629, 'Total loss': 0.5078797269840629}
2022-12-05 23:18:38,432 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:38,432 INFO:     Epoch: 50
2022-12-05 23:18:39,135 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.524046006527814, 'Total loss': 0.524046006527814} | train loss {'Reaction outcome loss': 0.5164900114341658, 'Total loss': 0.5164900114341658}
2022-12-05 23:18:39,135 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:39,135 INFO:     Epoch: 51
2022-12-05 23:18:39,842 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5007372559471563, 'Total loss': 0.5007372559471563} | train loss {'Reaction outcome loss': 0.5117680726002674, 'Total loss': 0.5117680726002674}
2022-12-05 23:18:39,842 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:39,843 INFO:     Epoch: 52
2022-12-05 23:18:40,547 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49397736110470514, 'Total loss': 0.49397736110470514} | train loss {'Reaction outcome loss': 0.5141666864862248, 'Total loss': 0.5141666864862248}
2022-12-05 23:18:40,547 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:40,547 INFO:     Epoch: 53
2022-12-05 23:18:41,251 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5359978411685337, 'Total loss': 0.5359978411685337} | train loss {'Reaction outcome loss': 0.5149907665593284, 'Total loss': 0.5149907665593284}
2022-12-05 23:18:41,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:41,251 INFO:     Epoch: 54
2022-12-05 23:18:41,954 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5075114477764476, 'Total loss': 0.5075114477764476} | train loss {'Reaction outcome loss': 0.5124751688874498, 'Total loss': 0.5124751688874498}
2022-12-05 23:18:41,954 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:41,955 INFO:     Epoch: 55
2022-12-05 23:18:42,660 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5135563910007477, 'Total loss': 0.5135563910007477} | train loss {'Reaction outcome loss': 0.5122255633680188, 'Total loss': 0.5122255633680188}
2022-12-05 23:18:42,660 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:42,660 INFO:     Epoch: 56
2022-12-05 23:18:43,367 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5098712139508941, 'Total loss': 0.5098712139508941} | train loss {'Reaction outcome loss': 0.5201467678863175, 'Total loss': 0.5201467678863175}
2022-12-05 23:18:43,367 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:43,367 INFO:     Epoch: 57
2022-12-05 23:18:44,079 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5174828161570159, 'Total loss': 0.5174828161570159} | train loss {'Reaction outcome loss': 0.5061349828632511, 'Total loss': 0.5061349828632511}
2022-12-05 23:18:44,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:44,080 INFO:     Epoch: 58
2022-12-05 23:18:44,784 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49759094789624214, 'Total loss': 0.49759094789624214} | train loss {'Reaction outcome loss': 0.52187264896169, 'Total loss': 0.52187264896169}
2022-12-05 23:18:44,784 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:44,784 INFO:     Epoch: 59
2022-12-05 23:18:45,490 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.52200917086818, 'Total loss': 0.52200917086818} | train loss {'Reaction outcome loss': 0.510155632605358, 'Total loss': 0.510155632605358}
2022-12-05 23:18:45,490 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:45,490 INFO:     Epoch: 60
2022-12-05 23:18:46,206 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.519789877940308, 'Total loss': 0.519789877940308} | train loss {'Reaction outcome loss': 0.5162936205158428, 'Total loss': 0.5162936205158428}
2022-12-05 23:18:46,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:46,207 INFO:     Epoch: 61
2022-12-05 23:18:46,911 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5112623819573359, 'Total loss': 0.5112623819573359} | train loss {'Reaction outcome loss': 0.51678174186726, 'Total loss': 0.51678174186726}
2022-12-05 23:18:46,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:46,911 INFO:     Epoch: 62
2022-12-05 23:18:47,615 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5204000117426569, 'Total loss': 0.5204000117426569} | train loss {'Reaction outcome loss': 0.5207840493138955, 'Total loss': 0.5207840493138955}
2022-12-05 23:18:47,615 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:47,615 INFO:     Epoch: 63
2022-12-05 23:18:48,318 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4953889697790146, 'Total loss': 0.4953889697790146} | train loss {'Reaction outcome loss': 0.5201279373193274, 'Total loss': 0.5201279373193274}
2022-12-05 23:18:48,318 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:48,318 INFO:     Epoch: 64
2022-12-05 23:18:49,021 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48891194334084337, 'Total loss': 0.48891194334084337} | train loss {'Reaction outcome loss': 0.5073621898889542, 'Total loss': 0.5073621898889542}
2022-12-05 23:18:49,021 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:49,021 INFO:     Epoch: 65
2022-12-05 23:18:49,727 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.53363892740824, 'Total loss': 0.53363892740824} | train loss {'Reaction outcome loss': 0.5170090228319169, 'Total loss': 0.5170090228319169}
2022-12-05 23:18:49,728 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:49,728 INFO:     Epoch: 66
2022-12-05 23:18:50,435 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.511699611490423, 'Total loss': 0.511699611490423} | train loss {'Reaction outcome loss': 0.5165571397664596, 'Total loss': 0.5165571397664596}
2022-12-05 23:18:50,435 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:50,435 INFO:     Epoch: 67
2022-12-05 23:18:51,142 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5333642092618075, 'Total loss': 0.5333642092618075} | train loss {'Reaction outcome loss': 0.5104498636357638, 'Total loss': 0.5104498636357638}
2022-12-05 23:18:51,142 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:51,142 INFO:     Epoch: 68
2022-12-05 23:18:51,852 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.539707864550027, 'Total loss': 0.539707864550027} | train loss {'Reaction outcome loss': 0.515792380607858, 'Total loss': 0.515792380607858}
2022-12-05 23:18:51,853 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:51,853 INFO:     Epoch: 69
2022-12-05 23:18:52,574 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5238319730216806, 'Total loss': 0.5238319730216806} | train loss {'Reaction outcome loss': 0.5195633215563638, 'Total loss': 0.5195633215563638}
2022-12-05 23:18:52,574 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:52,575 INFO:     Epoch: 70
2022-12-05 23:18:53,297 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5056158771569078, 'Total loss': 0.5056158771569078} | train loss {'Reaction outcome loss': 0.5203985509215568, 'Total loss': 0.5203985509215568}
2022-12-05 23:18:53,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:53,297 INFO:     Epoch: 71
2022-12-05 23:18:54,017 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5214853652498939, 'Total loss': 0.5214853652498939} | train loss {'Reaction outcome loss': 0.5081961567304573, 'Total loss': 0.5081961567304573}
2022-12-05 23:18:54,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:54,017 INFO:     Epoch: 72
2022-12-05 23:18:54,737 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5204044963148508, 'Total loss': 0.5204044963148508} | train loss {'Reaction outcome loss': 0.51902367265857, 'Total loss': 0.51902367265857}
2022-12-05 23:18:54,737 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:54,737 INFO:     Epoch: 73
2022-12-05 23:18:55,459 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.49014830453829333, 'Total loss': 0.49014830453829333} | train loss {'Reaction outcome loss': 0.5125525694112388, 'Total loss': 0.5125525694112388}
2022-12-05 23:18:55,459 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:55,459 INFO:     Epoch: 74
2022-12-05 23:18:56,184 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4900861814279448, 'Total loss': 0.4900861814279448} | train loss {'Reaction outcome loss': 0.5188243457857443, 'Total loss': 0.5188243457857443}
2022-12-05 23:18:56,186 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:56,186 INFO:     Epoch: 75
2022-12-05 23:18:56,906 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5184339223937555, 'Total loss': 0.5184339223937555} | train loss {'Reaction outcome loss': 0.5102889475773792, 'Total loss': 0.5102889475773792}
2022-12-05 23:18:56,906 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:56,907 INFO:     Epoch: 76
2022-12-05 23:18:57,629 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.501611702144146, 'Total loss': 0.501611702144146} | train loss {'Reaction outcome loss': 0.5103438022185345, 'Total loss': 0.5103438022185345}
2022-12-05 23:18:57,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:57,630 INFO:     Epoch: 77
2022-12-05 23:18:58,351 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5083307576450434, 'Total loss': 0.5083307576450434} | train loss {'Reaction outcome loss': 0.5097800135004277, 'Total loss': 0.5097800135004277}
2022-12-05 23:18:58,351 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:58,351 INFO:     Epoch: 78
2022-12-05 23:18:59,071 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5165877498008988, 'Total loss': 0.5165877498008988} | train loss {'Reaction outcome loss': 0.5115402796438762, 'Total loss': 0.5115402796438762}
2022-12-05 23:18:59,071 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:59,071 INFO:     Epoch: 79
2022-12-05 23:18:59,794 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5053925609046762, 'Total loss': 0.5053925609046762} | train loss {'Reaction outcome loss': 0.5163842175079851, 'Total loss': 0.5163842175079851}
2022-12-05 23:18:59,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:18:59,795 INFO:     Epoch: 80
2022-12-05 23:19:00,515 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5107335583730177, 'Total loss': 0.5107335583730177} | train loss {'Reaction outcome loss': 0.5123464709033771, 'Total loss': 0.5123464709033771}
2022-12-05 23:19:00,516 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:00,516 INFO:     Epoch: 81
2022-12-05 23:19:01,240 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6221551353281195, 'Total loss': 0.6221551353281195} | train loss {'Reaction outcome loss': 0.511424182020888, 'Total loss': 0.511424182020888}
2022-12-05 23:19:01,241 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:01,241 INFO:     Epoch: 82
2022-12-05 23:19:01,961 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5028590200976892, 'Total loss': 0.5028590200976892} | train loss {'Reaction outcome loss': 0.5213765279370911, 'Total loss': 0.5213765279370911}
2022-12-05 23:19:01,961 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:01,962 INFO:     Epoch: 83
2022-12-05 23:19:02,690 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49691060998223047, 'Total loss': 0.49691060998223047} | train loss {'Reaction outcome loss': 0.5109635401745232, 'Total loss': 0.5109635401745232}
2022-12-05 23:19:02,691 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:02,691 INFO:     Epoch: 84
2022-12-05 23:19:03,419 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5321895784952424, 'Total loss': 0.5321895784952424} | train loss {'Reaction outcome loss': 0.515306290315122, 'Total loss': 0.515306290315122}
2022-12-05 23:19:03,419 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:03,419 INFO:     Epoch: 85
2022-12-05 23:19:04,145 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5125292106108232, 'Total loss': 0.5125292106108232} | train loss {'Reaction outcome loss': 0.5131834712563729, 'Total loss': 0.5131834712563729}
2022-12-05 23:19:04,145 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:04,145 INFO:     Epoch: 86
2022-12-05 23:19:04,866 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5217944041571834, 'Total loss': 0.5217944041571834} | train loss {'Reaction outcome loss': 0.510539474961709, 'Total loss': 0.510539474961709}
2022-12-05 23:19:04,866 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:04,866 INFO:     Epoch: 87
2022-12-05 23:19:05,589 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5296700153161179, 'Total loss': 0.5296700153161179} | train loss {'Reaction outcome loss': 0.509280650834648, 'Total loss': 0.509280650834648}
2022-12-05 23:19:05,589 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:05,589 INFO:     Epoch: 88
2022-12-05 23:19:06,312 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5050541656938466, 'Total loss': 0.5050541656938466} | train loss {'Reaction outcome loss': 0.5150423824178929, 'Total loss': 0.5150423824178929}
2022-12-05 23:19:06,312 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:06,312 INFO:     Epoch: 89
2022-12-05 23:19:07,033 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5207863490689885, 'Total loss': 0.5207863490689885} | train loss {'Reaction outcome loss': 0.5145869784817404, 'Total loss': 0.5145869784817404}
2022-12-05 23:19:07,033 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:07,034 INFO:     Epoch: 90
2022-12-05 23:19:07,757 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4905538917942481, 'Total loss': 0.4905538917942481} | train loss {'Reaction outcome loss': 0.5076710850000381, 'Total loss': 0.5076710850000381}
2022-12-05 23:19:07,757 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:07,757 INFO:     Epoch: 91
2022-12-05 23:19:08,479 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5181687240573493, 'Total loss': 0.5181687240573493} | train loss {'Reaction outcome loss': 0.5115317228497291, 'Total loss': 0.5115317228497291}
2022-12-05 23:19:08,479 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:08,479 INFO:     Epoch: 92
2022-12-05 23:19:09,206 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5510289601304315, 'Total loss': 0.5510289601304315} | train loss {'Reaction outcome loss': 0.5132713772204458, 'Total loss': 0.5132713772204458}
2022-12-05 23:19:09,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:09,206 INFO:     Epoch: 93
2022-12-05 23:19:09,927 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5086990310387178, 'Total loss': 0.5086990310387178} | train loss {'Reaction outcome loss': 0.512943684993958, 'Total loss': 0.512943684993958}
2022-12-05 23:19:09,927 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:09,927 INFO:     Epoch: 94
2022-12-05 23:19:10,647 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5354181216521696, 'Total loss': 0.5354181216521696} | train loss {'Reaction outcome loss': 0.5205817688484581, 'Total loss': 0.5205817688484581}
2022-12-05 23:19:10,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:10,647 INFO:     Epoch: 95
2022-12-05 23:19:11,367 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5112397142431953, 'Total loss': 0.5112397142431953} | train loss {'Reaction outcome loss': 0.5200958428334217, 'Total loss': 0.5200958428334217}
2022-12-05 23:19:11,367 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:11,367 INFO:     Epoch: 96
2022-12-05 23:19:12,089 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4891308139670979, 'Total loss': 0.4891308139670979} | train loss {'Reaction outcome loss': 0.51274124019, 'Total loss': 0.51274124019}
2022-12-05 23:19:12,089 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:12,090 INFO:     Epoch: 97
2022-12-05 23:19:12,813 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5716084614396095, 'Total loss': 0.5716084614396095} | train loss {'Reaction outcome loss': 0.5079499200290564, 'Total loss': 0.5079499200290564}
2022-12-05 23:19:12,813 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:12,813 INFO:     Epoch: 98
2022-12-05 23:19:13,532 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5263144400986758, 'Total loss': 0.5263144400986758} | train loss {'Reaction outcome loss': 0.5181638182425986, 'Total loss': 0.5181638182425986}
2022-12-05 23:19:13,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:13,532 INFO:     Epoch: 99
2022-12-05 23:19:14,251 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5132837918671694, 'Total loss': 0.5132837918671694} | train loss {'Reaction outcome loss': 0.5127902716398239, 'Total loss': 0.5127902716398239}
2022-12-05 23:19:14,251 INFO:     Best model found after epoch 36 of 100.
2022-12-05 23:19:14,251 INFO:   Done with stage: TRAINING
2022-12-05 23:19:14,251 INFO:   Starting stage: EVALUATION
2022-12-05 23:19:14,382 INFO:   Done with stage: EVALUATION
2022-12-05 23:19:14,382 INFO:   Leaving out SEQ value Fold_2
2022-12-05 23:19:14,394 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:19:14,395 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:19:15,033 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:19:15,034 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:19:15,105 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:19:15,105 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:19:15,105 INFO:     No hyperparam tuning for this model
2022-12-05 23:19:15,105 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:19:15,105 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:19:15,106 INFO:     None feature selector for col prot
2022-12-05 23:19:15,106 INFO:     None feature selector for col prot
2022-12-05 23:19:15,106 INFO:     None feature selector for col prot
2022-12-05 23:19:15,106 INFO:     None feature selector for col chem
2022-12-05 23:19:15,106 INFO:     None feature selector for col chem
2022-12-05 23:19:15,106 INFO:     None feature selector for col chem
2022-12-05 23:19:15,107 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:19:15,107 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:19:15,108 INFO:     Number of params in model 215731
2022-12-05 23:19:15,111 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:19:15,111 INFO:   Starting stage: TRAINING
2022-12-05 23:19:15,169 INFO:     Val loss before train {'Reaction outcome loss': 0.9911355030807582, 'Total loss': 0.9911355030807582}
2022-12-05 23:19:15,169 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:15,170 INFO:     Epoch: 0
2022-12-05 23:19:15,893 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6882038671861995, 'Total loss': 0.6882038671861995} | train loss {'Reaction outcome loss': 0.8169389037407844, 'Total loss': 0.8169389037407844}
2022-12-05 23:19:15,893 INFO:     Found new best model at epoch 0
2022-12-05 23:19:15,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:15,894 INFO:     Epoch: 1
2022-12-05 23:19:16,623 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6494434496218507, 'Total loss': 0.6494434496218507} | train loss {'Reaction outcome loss': 0.6857480226981978, 'Total loss': 0.6857480226981978}
2022-12-05 23:19:16,623 INFO:     Found new best model at epoch 1
2022-12-05 23:19:16,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:16,624 INFO:     Epoch: 2
2022-12-05 23:19:17,351 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5979977778413079, 'Total loss': 0.5979977778413079} | train loss {'Reaction outcome loss': 0.643048587417313, 'Total loss': 0.643048587417313}
2022-12-05 23:19:17,351 INFO:     Found new best model at epoch 2
2022-12-05 23:19:17,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:17,352 INFO:     Epoch: 3
2022-12-05 23:19:18,078 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6022427339445461, 'Total loss': 0.6022427339445461} | train loss {'Reaction outcome loss': 0.6057038742762345, 'Total loss': 0.6057038742762345}
2022-12-05 23:19:18,078 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:18,078 INFO:     Epoch: 4
2022-12-05 23:19:18,812 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5600180991671302, 'Total loss': 0.5600180991671302} | train loss {'Reaction outcome loss': 0.601154671295693, 'Total loss': 0.601154671295693}
2022-12-05 23:19:18,812 INFO:     Found new best model at epoch 4
2022-12-05 23:19:18,812 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:18,813 INFO:     Epoch: 5
2022-12-05 23:19:19,538 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5739308392459695, 'Total loss': 0.5739308392459695} | train loss {'Reaction outcome loss': 0.5882004699726336, 'Total loss': 0.5882004699726336}
2022-12-05 23:19:19,538 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:19,538 INFO:     Epoch: 6
2022-12-05 23:19:20,264 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5801679668101397, 'Total loss': 0.5801679668101397} | train loss {'Reaction outcome loss': 0.5880218562688905, 'Total loss': 0.5880218562688905}
2022-12-05 23:19:20,264 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:20,264 INFO:     Epoch: 7
2022-12-05 23:19:20,994 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5543811788613145, 'Total loss': 0.5543811788613145} | train loss {'Reaction outcome loss': 0.569195493331805, 'Total loss': 0.569195493331805}
2022-12-05 23:19:20,994 INFO:     Found new best model at epoch 7
2022-12-05 23:19:20,994 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:20,995 INFO:     Epoch: 8
2022-12-05 23:19:21,724 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.548370210961862, 'Total loss': 0.548370210961862} | train loss {'Reaction outcome loss': 0.5676583270674292, 'Total loss': 0.5676583270674292}
2022-12-05 23:19:21,724 INFO:     Found new best model at epoch 8
2022-12-05 23:19:21,725 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:21,725 INFO:     Epoch: 9
2022-12-05 23:19:22,451 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5420435301282189, 'Total loss': 0.5420435301282189} | train loss {'Reaction outcome loss': 0.5693659801714817, 'Total loss': 0.5693659801714817}
2022-12-05 23:19:22,451 INFO:     Found new best model at epoch 9
2022-12-05 23:19:22,452 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:22,452 INFO:     Epoch: 10
2022-12-05 23:19:23,179 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5469603484327142, 'Total loss': 0.5469603484327142} | train loss {'Reaction outcome loss': 0.5687907989992786, 'Total loss': 0.5687907989992786}
2022-12-05 23:19:23,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:23,179 INFO:     Epoch: 11
2022-12-05 23:19:23,902 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5959843810309063, 'Total loss': 0.5959843810309063} | train loss {'Reaction outcome loss': 0.5650214359224567, 'Total loss': 0.5650214359224567}
2022-12-05 23:19:23,902 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:23,903 INFO:     Epoch: 12
2022-12-05 23:19:24,632 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5646952566775408, 'Total loss': 0.5646952566775408} | train loss {'Reaction outcome loss': 0.5615733616989151, 'Total loss': 0.5615733616989151}
2022-12-05 23:19:24,632 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:24,632 INFO:     Epoch: 13
2022-12-05 23:19:25,360 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5673953521658074, 'Total loss': 0.5673953521658074} | train loss {'Reaction outcome loss': 0.55240590172077, 'Total loss': 0.55240590172077}
2022-12-05 23:19:25,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:25,361 INFO:     Epoch: 14
2022-12-05 23:19:26,088 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.563758250664581, 'Total loss': 0.563758250664581} | train loss {'Reaction outcome loss': 0.553406120915162, 'Total loss': 0.553406120915162}
2022-12-05 23:19:26,088 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:26,088 INFO:     Epoch: 15
2022-12-05 23:19:26,817 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5394655476239595, 'Total loss': 0.5394655476239595} | train loss {'Reaction outcome loss': 0.558204035025829, 'Total loss': 0.558204035025829}
2022-12-05 23:19:26,817 INFO:     Found new best model at epoch 15
2022-12-05 23:19:26,817 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:26,818 INFO:     Epoch: 16
2022-12-05 23:19:27,541 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.549582685936581, 'Total loss': 0.549582685936581} | train loss {'Reaction outcome loss': 0.5502152047779879, 'Total loss': 0.5502152047779879}
2022-12-05 23:19:27,542 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:27,542 INFO:     Epoch: 17
2022-12-05 23:19:28,265 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5518761236559261, 'Total loss': 0.5518761236559261} | train loss {'Reaction outcome loss': 0.5504802920919681, 'Total loss': 0.5504802920919681}
2022-12-05 23:19:28,265 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:28,265 INFO:     Epoch: 18
2022-12-05 23:19:28,989 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5508679883046583, 'Total loss': 0.5508679883046583} | train loss {'Reaction outcome loss': 0.5459944892463534, 'Total loss': 0.5459944892463534}
2022-12-05 23:19:28,989 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:28,989 INFO:     Epoch: 19
2022-12-05 23:19:29,716 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.545767177912322, 'Total loss': 0.545767177912322} | train loss {'Reaction outcome loss': 0.5490973869316008, 'Total loss': 0.5490973869316008}
2022-12-05 23:19:29,716 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:29,716 INFO:     Epoch: 20
2022-12-05 23:19:30,439 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5265748913992535, 'Total loss': 0.5265748913992535} | train loss {'Reaction outcome loss': 0.5397337566955611, 'Total loss': 0.5397337566955611}
2022-12-05 23:19:30,439 INFO:     Found new best model at epoch 20
2022-12-05 23:19:30,440 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:30,440 INFO:     Epoch: 21
2022-12-05 23:19:31,166 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5800194645469839, 'Total loss': 0.5800194645469839} | train loss {'Reaction outcome loss': 0.5404524875555926, 'Total loss': 0.5404524875555926}
2022-12-05 23:19:31,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:31,166 INFO:     Epoch: 22
2022-12-05 23:19:31,889 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5489080893722448, 'Total loss': 0.5489080893722448} | train loss {'Reaction outcome loss': 0.5458751787178913, 'Total loss': 0.5458751787178913}
2022-12-05 23:19:31,889 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:31,889 INFO:     Epoch: 23
2022-12-05 23:19:32,617 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5641443837772716, 'Total loss': 0.5641443837772716} | train loss {'Reaction outcome loss': 0.5498734102075399, 'Total loss': 0.5498734102075399}
2022-12-05 23:19:32,617 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:32,617 INFO:     Epoch: 24
2022-12-05 23:19:33,343 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5275590375743129, 'Total loss': 0.5275590375743129} | train loss {'Reaction outcome loss': 0.5392229826555319, 'Total loss': 0.5392229826555319}
2022-12-05 23:19:33,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:33,343 INFO:     Epoch: 25
2022-12-05 23:19:34,068 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5443061766299334, 'Total loss': 0.5443061766299334} | train loss {'Reaction outcome loss': 0.5354215918779976, 'Total loss': 0.5354215918779976}
2022-12-05 23:19:34,069 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:34,069 INFO:     Epoch: 26
2022-12-05 23:19:34,793 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.53306118669835, 'Total loss': 0.53306118669835} | train loss {'Reaction outcome loss': 0.5399548833066152, 'Total loss': 0.5399548833066152}
2022-12-05 23:19:34,793 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:34,793 INFO:     Epoch: 27
2022-12-05 23:19:35,517 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5663834593512795, 'Total loss': 0.5663834593512795} | train loss {'Reaction outcome loss': 0.5336071389165484, 'Total loss': 0.5336071389165484}
2022-12-05 23:19:35,518 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:35,518 INFO:     Epoch: 28
2022-12-05 23:19:36,241 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5572332191196355, 'Total loss': 0.5572332191196355} | train loss {'Reaction outcome loss': 0.5359398256308636, 'Total loss': 0.5359398256308636}
2022-12-05 23:19:36,241 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:36,242 INFO:     Epoch: 29
2022-12-05 23:19:36,969 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5617794570597735, 'Total loss': 0.5617794570597735} | train loss {'Reaction outcome loss': 0.5391274230924212, 'Total loss': 0.5391274230924212}
2022-12-05 23:19:36,969 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:36,969 INFO:     Epoch: 30
2022-12-05 23:19:37,693 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5301458496939052, 'Total loss': 0.5301458496939052} | train loss {'Reaction outcome loss': 0.5469636371743823, 'Total loss': 0.5469636371743823}
2022-12-05 23:19:37,693 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:37,693 INFO:     Epoch: 31
2022-12-05 23:19:38,416 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5410917143930088, 'Total loss': 0.5410917143930088} | train loss {'Reaction outcome loss': 0.5254386221529984, 'Total loss': 0.5254386221529984}
2022-12-05 23:19:38,416 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:38,416 INFO:     Epoch: 32
2022-12-05 23:19:39,144 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5332175310362469, 'Total loss': 0.5332175310362469} | train loss {'Reaction outcome loss': 0.5324719528316969, 'Total loss': 0.5324719528316969}
2022-12-05 23:19:39,144 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:39,144 INFO:     Epoch: 33
2022-12-05 23:19:39,870 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5256234996698119, 'Total loss': 0.5256234996698119} | train loss {'Reaction outcome loss': 0.5309593715527763, 'Total loss': 0.5309593715527763}
2022-12-05 23:19:39,870 INFO:     Found new best model at epoch 33
2022-12-05 23:19:39,871 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:39,871 INFO:     Epoch: 34
2022-12-05 23:19:40,594 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5465100827542219, 'Total loss': 0.5465100827542219} | train loss {'Reaction outcome loss': 0.5494322258571864, 'Total loss': 0.5494322258571864}
2022-12-05 23:19:40,594 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:40,595 INFO:     Epoch: 35
2022-12-05 23:19:41,322 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5442450100725348, 'Total loss': 0.5442450100725348} | train loss {'Reaction outcome loss': 0.5210041779617549, 'Total loss': 0.5210041779617549}
2022-12-05 23:19:41,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:41,322 INFO:     Epoch: 36
2022-12-05 23:19:42,046 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5774318697777662, 'Total loss': 0.5774318697777662} | train loss {'Reaction outcome loss': 0.5370277890912917, 'Total loss': 0.5370277890912917}
2022-12-05 23:19:42,046 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:42,046 INFO:     Epoch: 37
2022-12-05 23:19:42,774 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5541852492500435, 'Total loss': 0.5541852492500435} | train loss {'Reaction outcome loss': 0.5399106617881219, 'Total loss': 0.5399106617881219}
2022-12-05 23:19:42,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:42,774 INFO:     Epoch: 38
2022-12-05 23:19:43,500 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5390671681274067, 'Total loss': 0.5390671681274067} | train loss {'Reaction outcome loss': 0.5322593469304685, 'Total loss': 0.5322593469304685}
2022-12-05 23:19:43,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:43,500 INFO:     Epoch: 39
2022-12-05 23:19:44,226 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5304447663101283, 'Total loss': 0.5304447663101283} | train loss {'Reaction outcome loss': 0.5277970325246997, 'Total loss': 0.5277970325246997}
2022-12-05 23:19:44,226 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:44,226 INFO:     Epoch: 40
2022-12-05 23:19:44,951 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.555273595858704, 'Total loss': 0.555273595858704} | train loss {'Reaction outcome loss': 0.5422941814911993, 'Total loss': 0.5422941814911993}
2022-12-05 23:19:44,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:44,951 INFO:     Epoch: 41
2022-12-05 23:19:45,660 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5617177039384842, 'Total loss': 0.5617177039384842} | train loss {'Reaction outcome loss': 0.5249360008881643, 'Total loss': 0.5249360008881643}
2022-12-05 23:19:45,660 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:45,660 INFO:     Epoch: 42
2022-12-05 23:19:46,367 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5286089811812748, 'Total loss': 0.5286089811812748} | train loss {'Reaction outcome loss': 0.5328463334213143, 'Total loss': 0.5328463334213143}
2022-12-05 23:19:46,368 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:46,368 INFO:     Epoch: 43
2022-12-05 23:19:47,071 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5401366010985591, 'Total loss': 0.5401366010985591} | train loss {'Reaction outcome loss': 0.5284928694246751, 'Total loss': 0.5284928694246751}
2022-12-05 23:19:47,071 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:47,071 INFO:     Epoch: 44
2022-12-05 23:19:47,775 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5546196570450609, 'Total loss': 0.5546196570450609} | train loss {'Reaction outcome loss': 0.5241464048262067, 'Total loss': 0.5241464048262067}
2022-12-05 23:19:47,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:47,776 INFO:     Epoch: 45
2022-12-05 23:19:48,475 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.544425562701442, 'Total loss': 0.544425562701442} | train loss {'Reaction outcome loss': 0.5244813270052435, 'Total loss': 0.5244813270052435}
2022-12-05 23:19:48,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:48,475 INFO:     Epoch: 46
2022-12-05 23:19:49,177 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5286610627716238, 'Total loss': 0.5286610627716238} | train loss {'Reaction outcome loss': 0.5318162784523327, 'Total loss': 0.5318162784523327}
2022-12-05 23:19:49,177 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:49,177 INFO:     Epoch: 47
2022-12-05 23:19:49,883 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5385249670256268, 'Total loss': 0.5385249670256268} | train loss {'Reaction outcome loss': 0.533136096379535, 'Total loss': 0.533136096379535}
2022-12-05 23:19:49,883 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:49,883 INFO:     Epoch: 48
2022-12-05 23:19:50,586 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.53846636549993, 'Total loss': 0.53846636549993} | train loss {'Reaction outcome loss': 0.5286855186648697, 'Total loss': 0.5286855186648697}
2022-12-05 23:19:50,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:50,586 INFO:     Epoch: 49
2022-12-05 23:19:51,289 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5064877082001079, 'Total loss': 0.5064877082001079} | train loss {'Reaction outcome loss': 0.5217321431226576, 'Total loss': 0.5217321431226576}
2022-12-05 23:19:51,289 INFO:     Found new best model at epoch 49
2022-12-05 23:19:51,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:51,290 INFO:     Epoch: 50
2022-12-05 23:19:51,991 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5070299292829904, 'Total loss': 0.5070299292829904} | train loss {'Reaction outcome loss': 0.5233273360169368, 'Total loss': 0.5233273360169368}
2022-12-05 23:19:51,991 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:51,991 INFO:     Epoch: 51
2022-12-05 23:19:52,695 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5194846449250524, 'Total loss': 0.5194846449250524} | train loss {'Reaction outcome loss': 0.5228735905476216, 'Total loss': 0.5228735905476216}
2022-12-05 23:19:52,695 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:52,695 INFO:     Epoch: 52
2022-12-05 23:19:53,397 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.531484842300415, 'Total loss': 0.531484842300415} | train loss {'Reaction outcome loss': 0.5199158148244325, 'Total loss': 0.5199158148244325}
2022-12-05 23:19:53,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:53,398 INFO:     Epoch: 53
2022-12-05 23:19:54,102 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5361575856804848, 'Total loss': 0.5361575856804848} | train loss {'Reaction outcome loss': 0.5230149708175467, 'Total loss': 0.5230149708175467}
2022-12-05 23:19:54,102 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:54,102 INFO:     Epoch: 54
2022-12-05 23:19:54,804 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5468090146102689, 'Total loss': 0.5468090146102689} | train loss {'Reaction outcome loss': 0.5250417608843159, 'Total loss': 0.5250417608843159}
2022-12-05 23:19:54,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:54,804 INFO:     Epoch: 55
2022-12-05 23:19:55,505 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48430200801654294, 'Total loss': 0.48430200801654294} | train loss {'Reaction outcome loss': 0.5251489020129929, 'Total loss': 0.5251489020129929}
2022-12-05 23:19:55,505 INFO:     Found new best model at epoch 55
2022-12-05 23:19:55,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:55,506 INFO:     Epoch: 56
2022-12-05 23:19:56,206 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5141831589016047, 'Total loss': 0.5141831589016047} | train loss {'Reaction outcome loss': 0.5182622954671682, 'Total loss': 0.5182622954671682}
2022-12-05 23:19:56,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:56,207 INFO:     Epoch: 57
2022-12-05 23:19:56,907 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49486138231375, 'Total loss': 0.49486138231375} | train loss {'Reaction outcome loss': 0.5230332378313126, 'Total loss': 0.5230332378313126}
2022-12-05 23:19:56,907 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:56,907 INFO:     Epoch: 58
2022-12-05 23:19:57,615 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5405338680879637, 'Total loss': 0.5405338680879637} | train loss {'Reaction outcome loss': 0.5292483080434895, 'Total loss': 0.5292483080434895}
2022-12-05 23:19:57,616 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:57,616 INFO:     Epoch: 59
2022-12-05 23:19:58,328 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5219683396545324, 'Total loss': 0.5219683396545324} | train loss {'Reaction outcome loss': 0.5186282869292657, 'Total loss': 0.5186282869292657}
2022-12-05 23:19:58,328 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:58,328 INFO:     Epoch: 60
2022-12-05 23:19:59,040 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5126215842637148, 'Total loss': 0.5126215842637148} | train loss {'Reaction outcome loss': 0.5118883849246058, 'Total loss': 0.5118883849246058}
2022-12-05 23:19:59,041 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:59,041 INFO:     Epoch: 61
2022-12-05 23:19:59,754 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5539049584079873, 'Total loss': 0.5539049584079873} | train loss {'Reaction outcome loss': 0.5112778262088173, 'Total loss': 0.5112778262088173}
2022-12-05 23:19:59,754 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:19:59,754 INFO:     Epoch: 62
2022-12-05 23:20:00,464 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5142012753269889, 'Total loss': 0.5142012753269889} | train loss {'Reaction outcome loss': 0.5172748060120262, 'Total loss': 0.5172748060120262}
2022-12-05 23:20:00,464 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:00,464 INFO:     Epoch: 63
2022-12-05 23:20:01,179 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5447118668393656, 'Total loss': 0.5447118668393656} | train loss {'Reaction outcome loss': 0.5341968764419015, 'Total loss': 0.5341968764419015}
2022-12-05 23:20:01,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:01,180 INFO:     Epoch: 64
2022-12-05 23:20:01,892 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5431077500635927, 'Total loss': 0.5431077500635927} | train loss {'Reaction outcome loss': 0.5298109558912424, 'Total loss': 0.5298109558912424}
2022-12-05 23:20:01,892 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:01,892 INFO:     Epoch: 65
2022-12-05 23:20:02,603 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5170754820785739, 'Total loss': 0.5170754820785739} | train loss {'Reaction outcome loss': 0.5213823919052537, 'Total loss': 0.5213823919052537}
2022-12-05 23:20:02,603 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:02,603 INFO:     Epoch: 66
2022-12-05 23:20:03,314 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5477833497253332, 'Total loss': 0.5477833497253332} | train loss {'Reaction outcome loss': 0.529202750578583, 'Total loss': 0.529202750578583}
2022-12-05 23:20:03,315 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:03,315 INFO:     Epoch: 67
2022-12-05 23:20:04,027 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5341268097135153, 'Total loss': 0.5341268097135153} | train loss {'Reaction outcome loss': 0.527623179651465, 'Total loss': 0.527623179651465}
2022-12-05 23:20:04,027 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:04,027 INFO:     Epoch: 68
2022-12-05 23:20:04,737 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5186124802990393, 'Total loss': 0.5186124802990393} | train loss {'Reaction outcome loss': 0.5205835833361274, 'Total loss': 0.5205835833361274}
2022-12-05 23:20:04,737 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:04,737 INFO:     Epoch: 69
2022-12-05 23:20:05,450 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5048656030981378, 'Total loss': 0.5048656030981378} | train loss {'Reaction outcome loss': 0.5213449251675896, 'Total loss': 0.5213449251675896}
2022-12-05 23:20:05,450 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:05,451 INFO:     Epoch: 70
2022-12-05 23:20:06,165 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5311504033478823, 'Total loss': 0.5311504033478823} | train loss {'Reaction outcome loss': 0.5200636511148229, 'Total loss': 0.5200636511148229}
2022-12-05 23:20:06,165 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:06,165 INFO:     Epoch: 71
2022-12-05 23:20:06,876 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6570258093151179, 'Total loss': 0.6570258093151179} | train loss {'Reaction outcome loss': 0.5250379112567979, 'Total loss': 0.5250379112567979}
2022-12-05 23:20:06,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:06,876 INFO:     Epoch: 72
2022-12-05 23:20:07,595 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5097895969044078, 'Total loss': 0.5097895969044078} | train loss {'Reaction outcome loss': 0.5181532151061996, 'Total loss': 0.5181532151061996}
2022-12-05 23:20:07,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:07,595 INFO:     Epoch: 73
2022-12-05 23:20:08,311 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5232518609951843, 'Total loss': 0.5232518609951843} | train loss {'Reaction outcome loss': 0.5224532896378511, 'Total loss': 0.5224532896378511}
2022-12-05 23:20:08,311 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:08,312 INFO:     Epoch: 74
2022-12-05 23:20:09,024 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5925513119860129, 'Total loss': 0.5925513119860129} | train loss {'Reaction outcome loss': 0.5110609475900287, 'Total loss': 0.5110609475900287}
2022-12-05 23:20:09,024 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:09,024 INFO:     Epoch: 75
2022-12-05 23:20:09,735 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5725913542238149, 'Total loss': 0.5725913542238149} | train loss {'Reaction outcome loss': 0.5225386427119676, 'Total loss': 0.5225386427119676}
2022-12-05 23:20:09,735 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:09,735 INFO:     Epoch: 76
2022-12-05 23:20:10,445 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4972427277402444, 'Total loss': 0.4972427277402444} | train loss {'Reaction outcome loss': 0.522971920073334, 'Total loss': 0.522971920073334}
2022-12-05 23:20:10,445 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:10,445 INFO:     Epoch: 77
2022-12-05 23:20:11,159 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5628132034431804, 'Total loss': 0.5628132034431804} | train loss {'Reaction outcome loss': 0.5172264993130437, 'Total loss': 0.5172264993130437}
2022-12-05 23:20:11,159 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:11,159 INFO:     Epoch: 78
2022-12-05 23:20:11,872 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.529726139862429, 'Total loss': 0.529726139862429} | train loss {'Reaction outcome loss': 0.5205836477067306, 'Total loss': 0.5205836477067306}
2022-12-05 23:20:11,873 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:11,873 INFO:     Epoch: 79
2022-12-05 23:20:12,586 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5039161348884756, 'Total loss': 0.5039161348884756} | train loss {'Reaction outcome loss': 0.5102696323160248, 'Total loss': 0.5102696323160248}
2022-12-05 23:20:12,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:12,586 INFO:     Epoch: 80
2022-12-05 23:20:13,301 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5652639398520644, 'Total loss': 0.5652639398520644} | train loss {'Reaction outcome loss': 0.5205789569177126, 'Total loss': 0.5205789569177126}
2022-12-05 23:20:13,301 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:13,301 INFO:     Epoch: 81
2022-12-05 23:20:14,012 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5221202149987221, 'Total loss': 0.5221202149987221} | train loss {'Reaction outcome loss': 0.5520508849789739, 'Total loss': 0.5520508849789739}
2022-12-05 23:20:14,012 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:14,012 INFO:     Epoch: 82
2022-12-05 23:20:14,725 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5461861745200374, 'Total loss': 0.5461861745200374} | train loss {'Reaction outcome loss': 0.515320981984679, 'Total loss': 0.515320981984679}
2022-12-05 23:20:14,726 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:14,726 INFO:     Epoch: 83
2022-12-05 23:20:15,437 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5389818191866983, 'Total loss': 0.5389818191866983} | train loss {'Reaction outcome loss': 0.517963992910618, 'Total loss': 0.517963992910618}
2022-12-05 23:20:15,437 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:15,437 INFO:     Epoch: 84
2022-12-05 23:20:16,148 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5322687937454744, 'Total loss': 0.5322687937454744} | train loss {'Reaction outcome loss': 0.5178639067691347, 'Total loss': 0.5178639067691347}
2022-12-05 23:20:16,149 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:16,149 INFO:     Epoch: 85
2022-12-05 23:20:16,865 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5495725345205177, 'Total loss': 0.5495725345205177} | train loss {'Reaction outcome loss': 0.5316941237401384, 'Total loss': 0.5316941237401384}
2022-12-05 23:20:16,865 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:16,865 INFO:     Epoch: 86
2022-12-05 23:20:17,578 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.514189600944519, 'Total loss': 0.514189600944519} | train loss {'Reaction outcome loss': 0.5169922717609386, 'Total loss': 0.5169922717609386}
2022-12-05 23:20:17,579 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:17,579 INFO:     Epoch: 87
2022-12-05 23:20:18,293 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5131320458921519, 'Total loss': 0.5131320458921519} | train loss {'Reaction outcome loss': 0.5115472564383255, 'Total loss': 0.5115472564383255}
2022-12-05 23:20:18,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:18,293 INFO:     Epoch: 88
2022-12-05 23:20:19,007 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5282909958200022, 'Total loss': 0.5282909958200022} | train loss {'Reaction outcome loss': 0.5119388994010474, 'Total loss': 0.5119388994010474}
2022-12-05 23:20:19,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:19,007 INFO:     Epoch: 89
2022-12-05 23:20:19,720 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5206089466810226, 'Total loss': 0.5206089466810226} | train loss {'Reaction outcome loss': 0.5115873775150823, 'Total loss': 0.5115873775150823}
2022-12-05 23:20:19,721 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:19,721 INFO:     Epoch: 90
2022-12-05 23:20:20,433 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6994169029322538, 'Total loss': 0.6994169029322538} | train loss {'Reaction outcome loss': 0.5238667396519349, 'Total loss': 0.5238667396519349}
2022-12-05 23:20:20,434 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:20,434 INFO:     Epoch: 91
2022-12-05 23:20:21,147 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5291549637913704, 'Total loss': 0.5291549637913704} | train loss {'Reaction outcome loss': 0.5273718562444695, 'Total loss': 0.5273718562444695}
2022-12-05 23:20:21,147 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:21,147 INFO:     Epoch: 92
2022-12-05 23:20:21,865 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5070805278691378, 'Total loss': 0.5070805278691378} | train loss {'Reaction outcome loss': 0.5166180437272377, 'Total loss': 0.5166180437272377}
2022-12-05 23:20:21,865 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:21,866 INFO:     Epoch: 93
2022-12-05 23:20:22,583 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.507790865545923, 'Total loss': 0.507790865545923} | train loss {'Reaction outcome loss': 0.5219420998504287, 'Total loss': 0.5219420998504287}
2022-12-05 23:20:22,583 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:22,583 INFO:     Epoch: 94
2022-12-05 23:20:23,294 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5722246285189282, 'Total loss': 0.5722246285189282} | train loss {'Reaction outcome loss': 0.5160190385845509, 'Total loss': 0.5160190385845509}
2022-12-05 23:20:23,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:23,294 INFO:     Epoch: 95
2022-12-05 23:20:24,008 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5284534408287569, 'Total loss': 0.5284534408287569} | train loss {'Reaction outcome loss': 0.5169728328341897, 'Total loss': 0.5169728328341897}
2022-12-05 23:20:24,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:24,008 INFO:     Epoch: 96
2022-12-05 23:20:24,723 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5044118487699465, 'Total loss': 0.5044118487699465} | train loss {'Reaction outcome loss': 0.516078456617922, 'Total loss': 0.516078456617922}
2022-12-05 23:20:24,723 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:24,723 INFO:     Epoch: 97
2022-12-05 23:20:25,439 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5224808224222877, 'Total loss': 0.5224808224222877} | train loss {'Reaction outcome loss': 0.5173083934706715, 'Total loss': 0.5173083934706715}
2022-12-05 23:20:25,439 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:25,439 INFO:     Epoch: 98
2022-12-05 23:20:26,153 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.514308747920123, 'Total loss': 0.514308747920123} | train loss {'Reaction outcome loss': 0.515618439929688, 'Total loss': 0.515618439929688}
2022-12-05 23:20:26,155 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:26,155 INFO:     Epoch: 99
2022-12-05 23:20:26,870 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5006803846494718, 'Total loss': 0.5006803846494718} | train loss {'Reaction outcome loss': 0.5197394488281325, 'Total loss': 0.5197394488281325}
2022-12-05 23:20:26,871 INFO:     Best model found after epoch 56 of 100.
2022-12-05 23:20:26,871 INFO:   Done with stage: TRAINING
2022-12-05 23:20:26,871 INFO:   Starting stage: EVALUATION
2022-12-05 23:20:26,995 INFO:   Done with stage: EVALUATION
2022-12-05 23:20:26,995 INFO:   Leaving out SEQ value Fold_3
2022-12-05 23:20:27,008 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-12-05 23:20:27,008 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:20:27,649 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:20:27,649 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:20:27,719 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:20:27,719 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:20:27,719 INFO:     No hyperparam tuning for this model
2022-12-05 23:20:27,720 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:20:27,720 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:20:27,720 INFO:     None feature selector for col prot
2022-12-05 23:20:27,720 INFO:     None feature selector for col prot
2022-12-05 23:20:27,720 INFO:     None feature selector for col prot
2022-12-05 23:20:27,721 INFO:     None feature selector for col chem
2022-12-05 23:20:27,721 INFO:     None feature selector for col chem
2022-12-05 23:20:27,721 INFO:     None feature selector for col chem
2022-12-05 23:20:27,721 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:20:27,721 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:20:27,723 INFO:     Number of params in model 215731
2022-12-05 23:20:27,726 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:20:27,726 INFO:   Starting stage: TRAINING
2022-12-05 23:20:27,784 INFO:     Val loss before train {'Reaction outcome loss': 0.9961114769632166, 'Total loss': 0.9961114769632166}
2022-12-05 23:20:27,784 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:27,784 INFO:     Epoch: 0
2022-12-05 23:20:28,496 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6681572449478236, 'Total loss': 0.6681572449478236} | train loss {'Reaction outcome loss': 0.7924844218760121, 'Total loss': 0.7924844218760121}
2022-12-05 23:20:28,496 INFO:     Found new best model at epoch 0
2022-12-05 23:20:28,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:28,497 INFO:     Epoch: 1
2022-12-05 23:20:29,203 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6175402243706313, 'Total loss': 0.6175402243706313} | train loss {'Reaction outcome loss': 0.6504294945269214, 'Total loss': 0.6504294945269214}
2022-12-05 23:20:29,204 INFO:     Found new best model at epoch 1
2022-12-05 23:20:29,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:29,205 INFO:     Epoch: 2
2022-12-05 23:20:29,919 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5770191990516402, 'Total loss': 0.5770191990516402} | train loss {'Reaction outcome loss': 0.6086247777452274, 'Total loss': 0.6086247777452274}
2022-12-05 23:20:29,919 INFO:     Found new best model at epoch 2
2022-12-05 23:20:29,919 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:29,919 INFO:     Epoch: 3
2022-12-05 23:20:30,630 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6063492325219241, 'Total loss': 0.6063492325219241} | train loss {'Reaction outcome loss': 0.582220026485774, 'Total loss': 0.582220026485774}
2022-12-05 23:20:30,631 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:30,631 INFO:     Epoch: 4
2022-12-05 23:20:31,339 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5769916698336601, 'Total loss': 0.5769916698336601} | train loss {'Reaction outcome loss': 0.5741095285026394, 'Total loss': 0.5741095285026394}
2022-12-05 23:20:31,339 INFO:     Found new best model at epoch 4
2022-12-05 23:20:31,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:31,339 INFO:     Epoch: 5
2022-12-05 23:20:32,047 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5965865845368667, 'Total loss': 0.5965865845368667} | train loss {'Reaction outcome loss': 0.5511754937317906, 'Total loss': 0.5511754937317906}
2022-12-05 23:20:32,047 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:32,047 INFO:     Epoch: 6
2022-12-05 23:20:32,753 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5837368707765233, 'Total loss': 0.5837368707765233} | train loss {'Reaction outcome loss': 0.5553326336096744, 'Total loss': 0.5553326336096744}
2022-12-05 23:20:32,754 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:32,754 INFO:     Epoch: 7
2022-12-05 23:20:33,460 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5511173856529322, 'Total loss': 0.5511173856529322} | train loss {'Reaction outcome loss': 0.5459529327494758, 'Total loss': 0.5459529327494758}
2022-12-05 23:20:33,460 INFO:     Found new best model at epoch 7
2022-12-05 23:20:33,461 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:33,461 INFO:     Epoch: 8
2022-12-05 23:20:34,168 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5682043487375433, 'Total loss': 0.5682043487375433} | train loss {'Reaction outcome loss': 0.5523054254906518, 'Total loss': 0.5523054254906518}
2022-12-05 23:20:34,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:34,168 INFO:     Epoch: 9
2022-12-05 23:20:34,877 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5422348149798133, 'Total loss': 0.5422348149798133} | train loss {'Reaction outcome loss': 0.541301013377248, 'Total loss': 0.541301013377248}
2022-12-05 23:20:34,878 INFO:     Found new best model at epoch 9
2022-12-05 23:20:34,878 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:34,878 INFO:     Epoch: 10
2022-12-05 23:20:35,585 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5522995401512493, 'Total loss': 0.5522995401512493} | train loss {'Reaction outcome loss': 0.5481729749514133, 'Total loss': 0.5481729749514133}
2022-12-05 23:20:35,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:35,586 INFO:     Epoch: 11
2022-12-05 23:20:36,296 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.6037685830484737, 'Total loss': 0.6037685830484737} | train loss {'Reaction outcome loss': 0.5351288763844237, 'Total loss': 0.5351288763844237}
2022-12-05 23:20:36,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:36,296 INFO:     Epoch: 12
2022-12-05 23:20:37,002 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5924341726032171, 'Total loss': 0.5924341726032171} | train loss {'Reaction outcome loss': 0.5357933229329634, 'Total loss': 0.5357933229329634}
2022-12-05 23:20:37,003 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:37,003 INFO:     Epoch: 13
2022-12-05 23:20:37,715 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5546648288992319, 'Total loss': 0.5546648288992319} | train loss {'Reaction outcome loss': 0.5415570600300419, 'Total loss': 0.5415570600300419}
2022-12-05 23:20:37,715 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:37,715 INFO:     Epoch: 14
2022-12-05 23:20:38,425 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5380722562020476, 'Total loss': 0.5380722562020476} | train loss {'Reaction outcome loss': 0.5379643800003188, 'Total loss': 0.5379643800003188}
2022-12-05 23:20:38,426 INFO:     Found new best model at epoch 14
2022-12-05 23:20:38,426 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:38,426 INFO:     Epoch: 15
2022-12-05 23:20:39,133 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.542797946117141, 'Total loss': 0.542797946117141} | train loss {'Reaction outcome loss': 0.5339810926087049, 'Total loss': 0.5339810926087049}
2022-12-05 23:20:39,133 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:39,133 INFO:     Epoch: 16
2022-12-05 23:20:39,843 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5386468995023858, 'Total loss': 0.5386468995023858} | train loss {'Reaction outcome loss': 0.5351537197828293, 'Total loss': 0.5351537197828293}
2022-12-05 23:20:39,843 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:39,843 INFO:     Epoch: 17
2022-12-05 23:20:40,550 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5578172877430916, 'Total loss': 0.5578172877430916} | train loss {'Reaction outcome loss': 0.535693419162108, 'Total loss': 0.535693419162108}
2022-12-05 23:20:40,550 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:40,550 INFO:     Epoch: 18
2022-12-05 23:20:41,257 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5550256446003914, 'Total loss': 0.5550256446003914} | train loss {'Reaction outcome loss': 0.5341111434357507, 'Total loss': 0.5341111434357507}
2022-12-05 23:20:41,257 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:41,257 INFO:     Epoch: 19
2022-12-05 23:20:41,963 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5452333712442354, 'Total loss': 0.5452333712442354} | train loss {'Reaction outcome loss': 0.5345333700277367, 'Total loss': 0.5345333700277367}
2022-12-05 23:20:41,964 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:41,964 INFO:     Epoch: 20
2022-12-05 23:20:42,673 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5552920963276516, 'Total loss': 0.5552920963276516} | train loss {'Reaction outcome loss': 0.5318947152215607, 'Total loss': 0.5318947152215607}
2022-12-05 23:20:42,673 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:42,673 INFO:     Epoch: 21
2022-12-05 23:20:43,380 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.537553609772162, 'Total loss': 0.537553609772162} | train loss {'Reaction outcome loss': 0.5331798961576151, 'Total loss': 0.5331798961576151}
2022-12-05 23:20:43,381 INFO:     Found new best model at epoch 21
2022-12-05 23:20:43,381 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:43,381 INFO:     Epoch: 22
2022-12-05 23:20:44,090 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5439207469197836, 'Total loss': 0.5439207469197836} | train loss {'Reaction outcome loss': 0.5348559160013588, 'Total loss': 0.5348559160013588}
2022-12-05 23:20:44,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:44,090 INFO:     Epoch: 23
2022-12-05 23:20:44,795 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5227359662001784, 'Total loss': 0.5227359662001784} | train loss {'Reaction outcome loss': 0.5299105372355909, 'Total loss': 0.5299105372355909}
2022-12-05 23:20:44,795 INFO:     Found new best model at epoch 23
2022-12-05 23:20:44,796 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:44,796 INFO:     Epoch: 24
2022-12-05 23:20:45,503 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5490360537713225, 'Total loss': 0.5490360537713225} | train loss {'Reaction outcome loss': 0.5346537524948315, 'Total loss': 0.5346537524948315}
2022-12-05 23:20:45,503 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:45,503 INFO:     Epoch: 25
2022-12-05 23:20:46,210 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5483647581528533, 'Total loss': 0.5483647581528533} | train loss {'Reaction outcome loss': 0.534320281841317, 'Total loss': 0.534320281841317}
2022-12-05 23:20:46,210 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:46,210 INFO:     Epoch: 26
2022-12-05 23:20:46,911 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5549034835262732, 'Total loss': 0.5549034835262732} | train loss {'Reaction outcome loss': 0.5269152611494065, 'Total loss': 0.5269152611494065}
2022-12-05 23:20:46,912 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:46,912 INFO:     Epoch: 27
2022-12-05 23:20:47,616 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5159866000440988, 'Total loss': 0.5159866000440988} | train loss {'Reaction outcome loss': 0.5304703080532502, 'Total loss': 0.5304703080532502}
2022-12-05 23:20:47,617 INFO:     Found new best model at epoch 27
2022-12-05 23:20:47,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:47,618 INFO:     Epoch: 28
2022-12-05 23:20:48,321 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5339196439493786, 'Total loss': 0.5339196439493786} | train loss {'Reaction outcome loss': 0.5304516524076461, 'Total loss': 0.5304516524076461}
2022-12-05 23:20:48,321 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:48,321 INFO:     Epoch: 29
2022-12-05 23:20:49,030 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5420160012489016, 'Total loss': 0.5420160012489016} | train loss {'Reaction outcome loss': 0.5304823267216585, 'Total loss': 0.5304823267216585}
2022-12-05 23:20:49,030 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:49,030 INFO:     Epoch: 30
2022-12-05 23:20:49,735 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5556207712401043, 'Total loss': 0.5556207712401043} | train loss {'Reaction outcome loss': 0.534820966027221, 'Total loss': 0.534820966027221}
2022-12-05 23:20:49,735 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:49,736 INFO:     Epoch: 31
2022-12-05 23:20:50,444 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5356622561812401, 'Total loss': 0.5356622561812401} | train loss {'Reaction outcome loss': 0.529582903823074, 'Total loss': 0.529582903823074}
2022-12-05 23:20:50,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:50,444 INFO:     Epoch: 32
2022-12-05 23:20:51,154 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5659969313578173, 'Total loss': 0.5659969313578173} | train loss {'Reaction outcome loss': 0.5295643914719017, 'Total loss': 0.5295643914719017}
2022-12-05 23:20:51,155 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:51,155 INFO:     Epoch: 33
2022-12-05 23:20:51,866 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5395217124711383, 'Total loss': 0.5395217124711383} | train loss {'Reaction outcome loss': 0.5328295266749907, 'Total loss': 0.5328295266749907}
2022-12-05 23:20:51,866 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:51,866 INFO:     Epoch: 34
2022-12-05 23:20:52,575 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5352618836543777, 'Total loss': 0.5352618836543777} | train loss {'Reaction outcome loss': 0.5309498781452373, 'Total loss': 0.5309498781452373}
2022-12-05 23:20:52,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:52,575 INFO:     Epoch: 35
2022-12-05 23:20:53,281 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5578042282299562, 'Total loss': 0.5578042282299562} | train loss {'Reaction outcome loss': 0.5301819716789284, 'Total loss': 0.5301819716789284}
2022-12-05 23:20:53,281 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:53,281 INFO:     Epoch: 36
2022-12-05 23:20:53,989 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5462087548591874, 'Total loss': 0.5462087548591874} | train loss {'Reaction outcome loss': 0.5359313036714282, 'Total loss': 0.5359313036714282}
2022-12-05 23:20:53,989 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:53,989 INFO:     Epoch: 37
2022-12-05 23:20:54,694 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5803517770360817, 'Total loss': 0.5803517770360817} | train loss {'Reaction outcome loss': 0.5319071230231499, 'Total loss': 0.5319071230231499}
2022-12-05 23:20:54,695 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:54,695 INFO:     Epoch: 38
2022-12-05 23:20:55,399 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5511120530692014, 'Total loss': 0.5511120530692014} | train loss {'Reaction outcome loss': 0.5320687543068613, 'Total loss': 0.5320687543068613}
2022-12-05 23:20:55,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:55,399 INFO:     Epoch: 39
2022-12-05 23:20:56,104 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5533730811016127, 'Total loss': 0.5533730811016127} | train loss {'Reaction outcome loss': 0.5289507831845964, 'Total loss': 0.5289507831845964}
2022-12-05 23:20:56,104 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:56,104 INFO:     Epoch: 40
2022-12-05 23:20:56,809 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5401935659941625, 'Total loss': 0.5401935659941625} | train loss {'Reaction outcome loss': 0.5269789848400622, 'Total loss': 0.5269789848400622}
2022-12-05 23:20:56,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:56,810 INFO:     Epoch: 41
2022-12-05 23:20:57,514 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5218413451855833, 'Total loss': 0.5218413451855833} | train loss {'Reaction outcome loss': 0.5222544942583357, 'Total loss': 0.5222544942583357}
2022-12-05 23:20:57,514 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:57,514 INFO:     Epoch: 42
2022-12-05 23:20:58,221 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5550557327541438, 'Total loss': 0.5550557327541438} | train loss {'Reaction outcome loss': 0.5302116418979606, 'Total loss': 0.5302116418979606}
2022-12-05 23:20:58,221 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:58,221 INFO:     Epoch: 43
2022-12-05 23:20:58,927 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5402281338518317, 'Total loss': 0.5402281338518317} | train loss {'Reaction outcome loss': 0.5305963714512028, 'Total loss': 0.5305963714512028}
2022-12-05 23:20:58,927 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:58,927 INFO:     Epoch: 44
2022-12-05 23:20:59,633 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5276863967830484, 'Total loss': 0.5276863967830484} | train loss {'Reaction outcome loss': 0.529884318855344, 'Total loss': 0.529884318855344}
2022-12-05 23:20:59,633 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:20:59,633 INFO:     Epoch: 45
2022-12-05 23:21:00,341 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.550947136499665, 'Total loss': 0.550947136499665} | train loss {'Reaction outcome loss': 0.5318248852175109, 'Total loss': 0.5318248852175109}
2022-12-05 23:21:00,342 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:00,342 INFO:     Epoch: 46
2022-12-05 23:21:01,047 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5601316927508875, 'Total loss': 0.5601316927508875} | train loss {'Reaction outcome loss': 0.5334241598236318, 'Total loss': 0.5334241598236318}
2022-12-05 23:21:01,047 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:01,047 INFO:     Epoch: 47
2022-12-05 23:21:01,754 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.6355143338441849, 'Total loss': 0.6355143338441849} | train loss {'Reaction outcome loss': 0.5339093193107721, 'Total loss': 0.5339093193107721}
2022-12-05 23:21:01,754 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:01,754 INFO:     Epoch: 48
2022-12-05 23:21:02,465 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5353283262388273, 'Total loss': 0.5353283262388273} | train loss {'Reaction outcome loss': 0.533578305828328, 'Total loss': 0.533578305828328}
2022-12-05 23:21:02,465 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:02,465 INFO:     Epoch: 49
2022-12-05 23:21:03,171 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5622423626482487, 'Total loss': 0.5622423626482487} | train loss {'Reaction outcome loss': 0.531413688890788, 'Total loss': 0.531413688890788}
2022-12-05 23:21:03,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:03,171 INFO:     Epoch: 50
2022-12-05 23:21:03,883 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5365233560177413, 'Total loss': 0.5365233560177413} | train loss {'Reaction outcome loss': 0.5257557843412671, 'Total loss': 0.5257557843412671}
2022-12-05 23:21:03,883 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:03,883 INFO:     Epoch: 51
2022-12-05 23:21:04,591 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5687713838097724, 'Total loss': 0.5687713838097724} | train loss {'Reaction outcome loss': 0.5293606851173907, 'Total loss': 0.5293606851173907}
2022-12-05 23:21:04,591 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:04,591 INFO:     Epoch: 52
2022-12-05 23:21:05,296 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5606372342868284, 'Total loss': 0.5606372342868284} | train loss {'Reaction outcome loss': 0.5324571546243162, 'Total loss': 0.5324571546243162}
2022-12-05 23:21:05,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:05,297 INFO:     Epoch: 53
2022-12-05 23:21:06,002 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5204062895341353, 'Total loss': 0.5204062895341353} | train loss {'Reaction outcome loss': 0.5306676187077347, 'Total loss': 0.5306676187077347}
2022-12-05 23:21:06,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:06,002 INFO:     Epoch: 54
2022-12-05 23:21:06,710 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5495986051180146, 'Total loss': 0.5495986051180146} | train loss {'Reaction outcome loss': 0.5340139238201842, 'Total loss': 0.5340139238201842}
2022-12-05 23:21:06,711 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:06,711 INFO:     Epoch: 55
2022-12-05 23:21:07,415 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5543854524466124, 'Total loss': 0.5543854524466124} | train loss {'Reaction outcome loss': 0.528930618933269, 'Total loss': 0.528930618933269}
2022-12-05 23:21:07,415 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:07,415 INFO:     Epoch: 56
2022-12-05 23:21:08,122 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5332655971023169, 'Total loss': 0.5332655971023169} | train loss {'Reaction outcome loss': 0.5359295023339136, 'Total loss': 0.5359295023339136}
2022-12-05 23:21:08,122 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:08,122 INFO:     Epoch: 57
2022-12-05 23:21:08,828 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5227554599669847, 'Total loss': 0.5227554599669847} | train loss {'Reaction outcome loss': 0.5319053962522623, 'Total loss': 0.5319053962522623}
2022-12-05 23:21:08,828 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:08,828 INFO:     Epoch: 58
2022-12-05 23:21:09,537 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5343836742368612, 'Total loss': 0.5343836742368612} | train loss {'Reaction outcome loss': 0.5263374443565096, 'Total loss': 0.5263374443565096}
2022-12-05 23:21:09,537 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:09,537 INFO:     Epoch: 59
2022-12-05 23:21:10,247 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5154936615039002, 'Total loss': 0.5154936615039002} | train loss {'Reaction outcome loss': 0.5350721392096306, 'Total loss': 0.5350721392096306}
2022-12-05 23:21:10,248 INFO:     Found new best model at epoch 59
2022-12-05 23:21:10,248 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:10,248 INFO:     Epoch: 60
2022-12-05 23:21:10,953 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.533149394122037, 'Total loss': 0.533149394122037} | train loss {'Reaction outcome loss': 0.5314855671658808, 'Total loss': 0.5314855671658808}
2022-12-05 23:21:10,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:10,953 INFO:     Epoch: 61
2022-12-05 23:21:11,657 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.550611899657683, 'Total loss': 0.550611899657683} | train loss {'Reaction outcome loss': 0.5292562606991554, 'Total loss': 0.5292562606991554}
2022-12-05 23:21:11,658 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:11,658 INFO:     Epoch: 62
2022-12-05 23:21:12,366 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5473326620730486, 'Total loss': 0.5473326620730486} | train loss {'Reaction outcome loss': 0.5260962957326247, 'Total loss': 0.5260962957326247}
2022-12-05 23:21:12,366 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:12,366 INFO:     Epoch: 63
2022-12-05 23:21:13,076 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5402663959698244, 'Total loss': 0.5402663959698244} | train loss {'Reaction outcome loss': 0.5291264783058848, 'Total loss': 0.5291264783058848}
2022-12-05 23:21:13,076 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:13,076 INFO:     Epoch: 64
2022-12-05 23:21:13,785 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5426239581270651, 'Total loss': 0.5426239581270651} | train loss {'Reaction outcome loss': 0.5292982735195938, 'Total loss': 0.5292982735195938}
2022-12-05 23:21:13,785 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:13,785 INFO:     Epoch: 65
2022-12-05 23:21:14,497 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5256943140517581, 'Total loss': 0.5256943140517581} | train loss {'Reaction outcome loss': 0.5342075353982497, 'Total loss': 0.5342075353982497}
2022-12-05 23:21:14,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:14,497 INFO:     Epoch: 66
2022-12-05 23:21:15,201 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.6058300391516902, 'Total loss': 0.6058300391516902} | train loss {'Reaction outcome loss': 0.5267333548896167, 'Total loss': 0.5267333548896167}
2022-12-05 23:21:15,201 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:15,201 INFO:     Epoch: 67
2022-12-05 23:21:15,903 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5736117058179595, 'Total loss': 0.5736117058179595} | train loss {'Reaction outcome loss': 0.5280469056294889, 'Total loss': 0.5280469056294889}
2022-12-05 23:21:15,904 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:15,904 INFO:     Epoch: 68
2022-12-05 23:21:16,608 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5669043023477901, 'Total loss': 0.5669043023477901} | train loss {'Reaction outcome loss': 0.5253000253317307, 'Total loss': 0.5253000253317307}
2022-12-05 23:21:16,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:16,608 INFO:     Epoch: 69
2022-12-05 23:21:17,313 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5364283689043738, 'Total loss': 0.5364283689043738} | train loss {'Reaction outcome loss': 0.5297190852919403, 'Total loss': 0.5297190852919403}
2022-12-05 23:21:17,314 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:17,314 INFO:     Epoch: 70
2022-12-05 23:21:18,015 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5136595364998687, 'Total loss': 0.5136595364998687} | train loss {'Reaction outcome loss': 0.5327183078746407, 'Total loss': 0.5327183078746407}
2022-12-05 23:21:18,016 INFO:     Found new best model at epoch 70
2022-12-05 23:21:18,016 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:18,016 INFO:     Epoch: 71
2022-12-05 23:21:18,720 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5411802337250926, 'Total loss': 0.5411802337250926} | train loss {'Reaction outcome loss': 0.5334227326573158, 'Total loss': 0.5334227326573158}
2022-12-05 23:21:18,721 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:18,721 INFO:     Epoch: 72
2022-12-05 23:21:19,422 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5380098050968214, 'Total loss': 0.5380098050968214} | train loss {'Reaction outcome loss': 0.5310111582887416, 'Total loss': 0.5310111582887416}
2022-12-05 23:21:19,422 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:19,423 INFO:     Epoch: 73
2022-12-05 23:21:20,124 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5446202355352315, 'Total loss': 0.5446202355352315} | train loss {'Reaction outcome loss': 0.5276431874353058, 'Total loss': 0.5276431874353058}
2022-12-05 23:21:20,124 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:20,124 INFO:     Epoch: 74
2022-12-05 23:21:20,829 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5303365588188171, 'Total loss': 0.5303365588188171} | train loss {'Reaction outcome loss': 0.5259475985351874, 'Total loss': 0.5259475985351874}
2022-12-05 23:21:20,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:20,829 INFO:     Epoch: 75
2022-12-05 23:21:21,532 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5211540155790069, 'Total loss': 0.5211540155790069} | train loss {'Reaction outcome loss': 0.5316641357480263, 'Total loss': 0.5316641357480263}
2022-12-05 23:21:21,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:21,532 INFO:     Epoch: 76
2022-12-05 23:21:22,241 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5751661272211508, 'Total loss': 0.5751661272211508} | train loss {'Reaction outcome loss': 0.531731764516052, 'Total loss': 0.531731764516052}
2022-12-05 23:21:22,241 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:22,241 INFO:     Epoch: 77
2022-12-05 23:21:22,948 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5100951641798019, 'Total loss': 0.5100951641798019} | train loss {'Reaction outcome loss': 0.530755426172091, 'Total loss': 0.530755426172091}
2022-12-05 23:21:22,948 INFO:     Found new best model at epoch 77
2022-12-05 23:21:22,949 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:22,949 INFO:     Epoch: 78
2022-12-05 23:21:23,656 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5551595193418589, 'Total loss': 0.5551595193418589} | train loss {'Reaction outcome loss': 0.5261545486596166, 'Total loss': 0.5261545486596166}
2022-12-05 23:21:23,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:23,656 INFO:     Epoch: 79
2022-12-05 23:21:24,366 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5074259584600275, 'Total loss': 0.5074259584600275} | train loss {'Reaction outcome loss': 0.5368914345697481, 'Total loss': 0.5368914345697481}
2022-12-05 23:21:24,366 INFO:     Found new best model at epoch 79
2022-12-05 23:21:24,367 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:24,367 INFO:     Epoch: 80
2022-12-05 23:21:25,070 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5545859350399538, 'Total loss': 0.5545859350399538} | train loss {'Reaction outcome loss': 0.5307354799946961, 'Total loss': 0.5307354799946961}
2022-12-05 23:21:25,070 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:25,070 INFO:     Epoch: 81
2022-12-05 23:21:25,774 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5396084812554446, 'Total loss': 0.5396084812554446} | train loss {'Reaction outcome loss': 0.5316687167907248, 'Total loss': 0.5316687167907248}
2022-12-05 23:21:25,775 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:25,775 INFO:     Epoch: 82
2022-12-05 23:21:26,483 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5448569777336988, 'Total loss': 0.5448569777336988} | train loss {'Reaction outcome loss': 0.5384309675012316, 'Total loss': 0.5384309675012316}
2022-12-05 23:21:26,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:26,483 INFO:     Epoch: 83
2022-12-05 23:21:27,185 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5395183996720747, 'Total loss': 0.5395183996720747} | train loss {'Reaction outcome loss': 0.530653521053645, 'Total loss': 0.530653521053645}
2022-12-05 23:21:27,185 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:27,185 INFO:     Epoch: 84
2022-12-05 23:21:27,887 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5094393441792239, 'Total loss': 0.5094393441792239} | train loss {'Reaction outcome loss': 0.5310091141535311, 'Total loss': 0.5310091141535311}
2022-12-05 23:21:27,887 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:27,887 INFO:     Epoch: 85
2022-12-05 23:21:28,590 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5452088605273854, 'Total loss': 0.5452088605273854} | train loss {'Reaction outcome loss': 0.5286175790489936, 'Total loss': 0.5286175790489936}
2022-12-05 23:21:28,590 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:28,590 INFO:     Epoch: 86
2022-12-05 23:21:29,293 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5292564559389245, 'Total loss': 0.5292564559389245} | train loss {'Reaction outcome loss': 0.5304761258923277, 'Total loss': 0.5304761258923277}
2022-12-05 23:21:29,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:29,293 INFO:     Epoch: 87
2022-12-05 23:21:29,998 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5593597895719788, 'Total loss': 0.5593597895719788} | train loss {'Reaction outcome loss': 0.5315516538765965, 'Total loss': 0.5315516538765965}
2022-12-05 23:21:29,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:29,998 INFO:     Epoch: 88
2022-12-05 23:21:30,703 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5700755722143434, 'Total loss': 0.5700755722143434} | train loss {'Reaction outcome loss': 0.5276923785404283, 'Total loss': 0.5276923785404283}
2022-12-05 23:21:30,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:30,703 INFO:     Epoch: 89
2022-12-05 23:21:31,407 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5417347320101478, 'Total loss': 0.5417347320101478} | train loss {'Reaction outcome loss': 0.5278656416401571, 'Total loss': 0.5278656416401571}
2022-12-05 23:21:31,409 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:31,409 INFO:     Epoch: 90
2022-12-05 23:21:32,112 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5634364478967406, 'Total loss': 0.5634364478967406} | train loss {'Reaction outcome loss': 0.5328014773373702, 'Total loss': 0.5328014773373702}
2022-12-05 23:21:32,112 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:32,112 INFO:     Epoch: 91
2022-12-05 23:21:32,815 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5358583344654604, 'Total loss': 0.5358583344654604} | train loss {'Reaction outcome loss': 0.5321919114005809, 'Total loss': 0.5321919114005809}
2022-12-05 23:21:32,815 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:32,815 INFO:     Epoch: 92
2022-12-05 23:21:33,517 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5292080640792847, 'Total loss': 0.5292080640792847} | train loss {'Reaction outcome loss': 0.5253784351202906, 'Total loss': 0.5253784351202906}
2022-12-05 23:21:33,517 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:33,517 INFO:     Epoch: 93
2022-12-05 23:21:34,223 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5217605676840652, 'Total loss': 0.5217605676840652} | train loss {'Reaction outcome loss': 0.5296619377574142, 'Total loss': 0.5296619377574142}
2022-12-05 23:21:34,223 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:34,223 INFO:     Epoch: 94
2022-12-05 23:21:34,927 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5583151782100851, 'Total loss': 0.5583151782100851} | train loss {'Reaction outcome loss': 0.5306723556348256, 'Total loss': 0.5306723556348256}
2022-12-05 23:21:34,927 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:34,927 INFO:     Epoch: 95
2022-12-05 23:21:35,629 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5375839417630975, 'Total loss': 0.5375839417630975} | train loss {'Reaction outcome loss': 0.5291294004235949, 'Total loss': 0.5291294004235949}
2022-12-05 23:21:35,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:35,630 INFO:     Epoch: 96
2022-12-05 23:21:36,334 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5341253179040822, 'Total loss': 0.5341253179040822} | train loss {'Reaction outcome loss': 0.5224286146309911, 'Total loss': 0.5224286146309911}
2022-12-05 23:21:36,334 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:36,334 INFO:     Epoch: 97
2022-12-05 23:21:37,040 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6252168999476866, 'Total loss': 0.6252168999476866} | train loss {'Reaction outcome loss': 0.5364198429243905, 'Total loss': 0.5364198429243905}
2022-12-05 23:21:37,040 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:37,040 INFO:     Epoch: 98
2022-12-05 23:21:37,744 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.526293548670682, 'Total loss': 0.526293548670682} | train loss {'Reaction outcome loss': 0.5297622854612312, 'Total loss': 0.5297622854612312}
2022-12-05 23:21:37,744 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:37,744 INFO:     Epoch: 99
2022-12-05 23:21:38,449 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5478454462506555, 'Total loss': 0.5478454462506555} | train loss {'Reaction outcome loss': 0.5293034200157438, 'Total loss': 0.5293034200157438}
2022-12-05 23:21:38,449 INFO:     Best model found after epoch 80 of 100.
2022-12-05 23:21:38,449 INFO:   Done with stage: TRAINING
2022-12-05 23:21:38,449 INFO:   Starting stage: EVALUATION
2022-12-05 23:21:38,580 INFO:   Done with stage: EVALUATION
2022-12-05 23:21:38,580 INFO:   Leaving out SEQ value Fold_4
2022-12-05 23:21:38,593 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:21:38,593 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:21:39,241 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:21:39,241 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:21:39,313 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:21:39,313 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:21:39,313 INFO:     No hyperparam tuning for this model
2022-12-05 23:21:39,313 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:21:39,313 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:21:39,314 INFO:     None feature selector for col prot
2022-12-05 23:21:39,314 INFO:     None feature selector for col prot
2022-12-05 23:21:39,314 INFO:     None feature selector for col prot
2022-12-05 23:21:39,315 INFO:     None feature selector for col chem
2022-12-05 23:21:39,315 INFO:     None feature selector for col chem
2022-12-05 23:21:39,315 INFO:     None feature selector for col chem
2022-12-05 23:21:39,315 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:21:39,315 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:21:39,316 INFO:     Number of params in model 215731
2022-12-05 23:21:39,320 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:21:39,320 INFO:   Starting stage: TRAINING
2022-12-05 23:21:39,379 INFO:     Val loss before train {'Reaction outcome loss': 0.9922779676589099, 'Total loss': 0.9922779676589099}
2022-12-05 23:21:39,379 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:39,379 INFO:     Epoch: 0
2022-12-05 23:21:40,088 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6726527952335097, 'Total loss': 0.6726527952335097} | train loss {'Reaction outcome loss': 0.8125902951849617, 'Total loss': 0.8125902951849617}
2022-12-05 23:21:40,088 INFO:     Found new best model at epoch 0
2022-12-05 23:21:40,089 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:40,089 INFO:     Epoch: 1
2022-12-05 23:21:40,796 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.681970864534378, 'Total loss': 0.681970864534378} | train loss {'Reaction outcome loss': 0.6667274662674318, 'Total loss': 0.6667274662674318}
2022-12-05 23:21:40,797 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:40,797 INFO:     Epoch: 2
2022-12-05 23:21:41,504 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6272125318646431, 'Total loss': 0.6272125318646431} | train loss {'Reaction outcome loss': 0.6313137906765648, 'Total loss': 0.6313137906765648}
2022-12-05 23:21:41,505 INFO:     Found new best model at epoch 2
2022-12-05 23:21:41,505 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:41,505 INFO:     Epoch: 3
2022-12-05 23:21:42,215 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6275946531783451, 'Total loss': 0.6275946531783451} | train loss {'Reaction outcome loss': 0.6102808542579774, 'Total loss': 0.6102808542579774}
2022-12-05 23:21:42,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:42,215 INFO:     Epoch: 4
2022-12-05 23:21:42,922 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5574804977937178, 'Total loss': 0.5574804977937178} | train loss {'Reaction outcome loss': 0.5989820074576598, 'Total loss': 0.5989820074576598}
2022-12-05 23:21:42,922 INFO:     Found new best model at epoch 4
2022-12-05 23:21:42,923 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:42,923 INFO:     Epoch: 5
2022-12-05 23:21:43,628 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5952235907316208, 'Total loss': 0.5952235907316208} | train loss {'Reaction outcome loss': 0.5797854090026515, 'Total loss': 0.5797854090026515}
2022-12-05 23:21:43,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:43,628 INFO:     Epoch: 6
2022-12-05 23:21:44,334 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5790745334869082, 'Total loss': 0.5790745334869082} | train loss {'Reaction outcome loss': 0.5683024093086421, 'Total loss': 0.5683024093086421}
2022-12-05 23:21:44,334 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:44,334 INFO:     Epoch: 7
2022-12-05 23:21:45,042 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5359700505029071, 'Total loss': 0.5359700505029071} | train loss {'Reaction outcome loss': 0.5624184417067027, 'Total loss': 0.5624184417067027}
2022-12-05 23:21:45,042 INFO:     Found new best model at epoch 7
2022-12-05 23:21:45,043 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:45,043 INFO:     Epoch: 8
2022-12-05 23:21:45,750 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5332327593456615, 'Total loss': 0.5332327593456615} | train loss {'Reaction outcome loss': 0.5571834656753039, 'Total loss': 0.5571834656753039}
2022-12-05 23:21:45,750 INFO:     Found new best model at epoch 8
2022-12-05 23:21:45,751 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:45,751 INFO:     Epoch: 9
2022-12-05 23:21:46,459 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5469525730745359, 'Total loss': 0.5469525730745359} | train loss {'Reaction outcome loss': 0.5537622941710688, 'Total loss': 0.5537622941710688}
2022-12-05 23:21:46,459 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:46,459 INFO:     Epoch: 10
2022-12-05 23:21:47,166 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5257356187159364, 'Total loss': 0.5257356187159364} | train loss {'Reaction outcome loss': 0.5444197006795087, 'Total loss': 0.5444197006795087}
2022-12-05 23:21:47,166 INFO:     Found new best model at epoch 10
2022-12-05 23:21:47,167 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:47,167 INFO:     Epoch: 11
2022-12-05 23:21:47,873 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5336630821905353, 'Total loss': 0.5336630821905353} | train loss {'Reaction outcome loss': 0.5461632066070732, 'Total loss': 0.5461632066070732}
2022-12-05 23:21:47,873 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:47,873 INFO:     Epoch: 12
2022-12-05 23:21:48,582 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5402047776363113, 'Total loss': 0.5402047776363113} | train loss {'Reaction outcome loss': 0.5592263266142563, 'Total loss': 0.5592263266142563}
2022-12-05 23:21:48,582 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:48,583 INFO:     Epoch: 13
2022-12-05 23:21:49,292 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5106893960725177, 'Total loss': 0.5106893960725177} | train loss {'Reaction outcome loss': 0.5532608978819811, 'Total loss': 0.5532608978819811}
2022-12-05 23:21:49,292 INFO:     Found new best model at epoch 13
2022-12-05 23:21:49,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:49,293 INFO:     Epoch: 14
2022-12-05 23:21:50,003 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.599597306414084, 'Total loss': 0.599597306414084} | train loss {'Reaction outcome loss': 0.5458848295725791, 'Total loss': 0.5458848295725791}
2022-12-05 23:21:50,004 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:50,004 INFO:     Epoch: 15
2022-12-05 23:21:50,714 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5124435966665094, 'Total loss': 0.5124435966665094} | train loss {'Reaction outcome loss': 0.5556399585747043, 'Total loss': 0.5556399585747043}
2022-12-05 23:21:50,714 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:50,714 INFO:     Epoch: 16
2022-12-05 23:21:51,423 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5082467706366018, 'Total loss': 0.5082467706366018} | train loss {'Reaction outcome loss': 0.5497567339947349, 'Total loss': 0.5497567339947349}
2022-12-05 23:21:51,423 INFO:     Found new best model at epoch 16
2022-12-05 23:21:51,423 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:51,424 INFO:     Epoch: 17
2022-12-05 23:21:52,131 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5234452865340493, 'Total loss': 0.5234452865340493} | train loss {'Reaction outcome loss': 0.5546405069861817, 'Total loss': 0.5546405069861817}
2022-12-05 23:21:52,132 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:52,132 INFO:     Epoch: 18
2022-12-05 23:21:52,844 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5332483324137601, 'Total loss': 0.5332483324137601} | train loss {'Reaction outcome loss': 0.5451059738996058, 'Total loss': 0.5451059738996058}
2022-12-05 23:21:52,844 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:52,844 INFO:     Epoch: 19
2022-12-05 23:21:53,555 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5387925962832841, 'Total loss': 0.5387925962832841} | train loss {'Reaction outcome loss': 0.544528355806885, 'Total loss': 0.544528355806885}
2022-12-05 23:21:53,556 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:53,556 INFO:     Epoch: 20
2022-12-05 23:21:54,266 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5272374539212747, 'Total loss': 0.5272374539212747} | train loss {'Reaction outcome loss': 0.5405621968420894, 'Total loss': 0.5405621968420894}
2022-12-05 23:21:54,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:54,266 INFO:     Epoch: 21
2022-12-05 23:21:54,980 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.616216476668011, 'Total loss': 0.616216476668011} | train loss {'Reaction outcome loss': 0.540056920847912, 'Total loss': 0.540056920847912}
2022-12-05 23:21:54,981 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:54,981 INFO:     Epoch: 22
2022-12-05 23:21:55,694 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5131945908069611, 'Total loss': 0.5131945908069611} | train loss {'Reaction outcome loss': 0.5631466128444864, 'Total loss': 0.5631466128444864}
2022-12-05 23:21:55,694 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:55,694 INFO:     Epoch: 23
2022-12-05 23:21:56,402 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.530642762102864, 'Total loss': 0.530642762102864} | train loss {'Reaction outcome loss': 0.5429593150914922, 'Total loss': 0.5429593150914922}
2022-12-05 23:21:56,402 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:56,403 INFO:     Epoch: 24
2022-12-05 23:21:57,103 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.505581447346644, 'Total loss': 0.505581447346644} | train loss {'Reaction outcome loss': 0.5511991075175976, 'Total loss': 0.5511991075175976}
2022-12-05 23:21:57,103 INFO:     Found new best model at epoch 24
2022-12-05 23:21:57,104 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:57,104 INFO:     Epoch: 25
2022-12-05 23:21:57,803 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.540987650101835, 'Total loss': 0.540987650101835} | train loss {'Reaction outcome loss': 0.5479029832701934, 'Total loss': 0.5479029832701934}
2022-12-05 23:21:57,803 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:57,803 INFO:     Epoch: 26
2022-12-05 23:21:58,506 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5241024406118826, 'Total loss': 0.5241024406118826} | train loss {'Reaction outcome loss': 0.5401857687756118, 'Total loss': 0.5401857687756118}
2022-12-05 23:21:58,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:58,506 INFO:     Epoch: 27
2022-12-05 23:21:59,211 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5135908658531579, 'Total loss': 0.5135908658531579} | train loss {'Reaction outcome loss': 0.5489516296850042, 'Total loss': 0.5489516296850042}
2022-12-05 23:21:59,211 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:59,211 INFO:     Epoch: 28
2022-12-05 23:21:59,915 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5168735114010897, 'Total loss': 0.5168735114010897} | train loss {'Reaction outcome loss': 0.5374753827734394, 'Total loss': 0.5374753827734394}
2022-12-05 23:21:59,915 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:21:59,915 INFO:     Epoch: 29
2022-12-05 23:22:00,624 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5164541486989368, 'Total loss': 0.5164541486989368} | train loss {'Reaction outcome loss': 0.5449093354013768, 'Total loss': 0.5449093354013768}
2022-12-05 23:22:00,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:00,624 INFO:     Epoch: 30
2022-12-05 23:22:01,328 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5015810338610952, 'Total loss': 0.5015810338610952} | train loss {'Reaction outcome loss': 0.5444261610266651, 'Total loss': 0.5444261610266651}
2022-12-05 23:22:01,328 INFO:     Found new best model at epoch 30
2022-12-05 23:22:01,329 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:01,329 INFO:     Epoch: 31
2022-12-05 23:22:02,030 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5216768526218154, 'Total loss': 0.5216768526218154} | train loss {'Reaction outcome loss': 0.5450334032989947, 'Total loss': 0.5450334032989947}
2022-12-05 23:22:02,030 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:02,030 INFO:     Epoch: 32
2022-12-05 23:22:02,731 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5456327057697556, 'Total loss': 0.5456327057697556} | train loss {'Reaction outcome loss': 0.5447470086064898, 'Total loss': 0.5447470086064898}
2022-12-05 23:22:02,732 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:02,732 INFO:     Epoch: 33
2022-12-05 23:22:03,441 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5339914235201749, 'Total loss': 0.5339914235201749} | train loss {'Reaction outcome loss': 0.5452083675605566, 'Total loss': 0.5452083675605566}
2022-12-05 23:22:03,441 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:03,441 INFO:     Epoch: 34
2022-12-05 23:22:04,146 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5159984109076586, 'Total loss': 0.5159984109076586} | train loss {'Reaction outcome loss': 0.5356047353763812, 'Total loss': 0.5356047353763812}
2022-12-05 23:22:04,146 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:04,146 INFO:     Epoch: 35
2022-12-05 23:22:04,848 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5117693529887632, 'Total loss': 0.5117693529887632} | train loss {'Reaction outcome loss': 0.5461143622182401, 'Total loss': 0.5461143622182401}
2022-12-05 23:22:04,848 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:04,848 INFO:     Epoch: 36
2022-12-05 23:22:05,549 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5640479495579546, 'Total loss': 0.5640479495579546} | train loss {'Reaction outcome loss': 0.5424418694335922, 'Total loss': 0.5424418694335922}
2022-12-05 23:22:05,550 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:05,550 INFO:     Epoch: 37
2022-12-05 23:22:06,251 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5519693961197679, 'Total loss': 0.5519693961197679} | train loss {'Reaction outcome loss': 0.5491657736164476, 'Total loss': 0.5491657736164476}
2022-12-05 23:22:06,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:06,251 INFO:     Epoch: 38
2022-12-05 23:22:06,952 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5161960538138043, 'Total loss': 0.5161960538138043} | train loss {'Reaction outcome loss': 0.5360655251302218, 'Total loss': 0.5360655251302218}
2022-12-05 23:22:06,952 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:06,952 INFO:     Epoch: 39
2022-12-05 23:22:07,656 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5266034027392213, 'Total loss': 0.5266034027392213} | train loss {'Reaction outcome loss': 0.5432278929270713, 'Total loss': 0.5432278929270713}
2022-12-05 23:22:07,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:07,656 INFO:     Epoch: 40
2022-12-05 23:22:08,359 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.534674733877182, 'Total loss': 0.534674733877182} | train loss {'Reaction outcome loss': 0.5362469191975922, 'Total loss': 0.5362469191975922}
2022-12-05 23:22:08,359 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:08,359 INFO:     Epoch: 41
2022-12-05 23:22:09,063 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5245102759112011, 'Total loss': 0.5245102759112011} | train loss {'Reaction outcome loss': 0.5481213171955063, 'Total loss': 0.5481213171955063}
2022-12-05 23:22:09,064 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:09,064 INFO:     Epoch: 42
2022-12-05 23:22:09,768 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.548876675015146, 'Total loss': 0.548876675015146} | train loss {'Reaction outcome loss': 0.5416356292572099, 'Total loss': 0.5416356292572099}
2022-12-05 23:22:09,768 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:09,768 INFO:     Epoch: 43
2022-12-05 23:22:10,475 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5411444624716585, 'Total loss': 0.5411444624716585} | train loss {'Reaction outcome loss': 0.5525759313149974, 'Total loss': 0.5525759313149974}
2022-12-05 23:22:10,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:10,475 INFO:     Epoch: 44
2022-12-05 23:22:11,179 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5241490930996158, 'Total loss': 0.5241490930996158} | train loss {'Reaction outcome loss': 0.5537130272822824, 'Total loss': 0.5537130272822824}
2022-12-05 23:22:11,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:11,179 INFO:     Epoch: 45
2022-12-05 23:22:11,882 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5472704358398914, 'Total loss': 0.5472704358398914} | train loss {'Reaction outcome loss': 0.5446898763780652, 'Total loss': 0.5446898763780652}
2022-12-05 23:22:11,882 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:11,882 INFO:     Epoch: 46
2022-12-05 23:22:12,584 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5825868865305727, 'Total loss': 0.5825868865305727} | train loss {'Reaction outcome loss': 0.5476399184117916, 'Total loss': 0.5476399184117916}
2022-12-05 23:22:12,584 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:12,584 INFO:     Epoch: 47
2022-12-05 23:22:13,290 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5142079659483649, 'Total loss': 0.5142079659483649} | train loss {'Reaction outcome loss': 0.5522472453624131, 'Total loss': 0.5522472453624131}
2022-12-05 23:22:13,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:13,290 INFO:     Epoch: 48
2022-12-05 23:22:13,992 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5007900409400463, 'Total loss': 0.5007900409400463} | train loss {'Reaction outcome loss': 0.5408327227179338, 'Total loss': 0.5408327227179338}
2022-12-05 23:22:13,992 INFO:     Found new best model at epoch 48
2022-12-05 23:22:13,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:13,993 INFO:     Epoch: 49
2022-12-05 23:22:14,694 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5137018476697531, 'Total loss': 0.5137018476697531} | train loss {'Reaction outcome loss': 0.5379066592542386, 'Total loss': 0.5379066592542386}
2022-12-05 23:22:14,694 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:14,694 INFO:     Epoch: 50
2022-12-05 23:22:15,396 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5509109740907495, 'Total loss': 0.5509109740907495} | train loss {'Reaction outcome loss': 0.5367103704074134, 'Total loss': 0.5367103704074134}
2022-12-05 23:22:15,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:15,396 INFO:     Epoch: 51
2022-12-05 23:22:16,100 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5418027998371557, 'Total loss': 0.5418027998371557} | train loss {'Reaction outcome loss': 0.5374033228835461, 'Total loss': 0.5374033228835461}
2022-12-05 23:22:16,100 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:16,101 INFO:     Epoch: 52
2022-12-05 23:22:16,802 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5261630920523946, 'Total loss': 0.5261630920523946} | train loss {'Reaction outcome loss': 0.549167126718803, 'Total loss': 0.549167126718803}
2022-12-05 23:22:16,802 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:16,802 INFO:     Epoch: 53
2022-12-05 23:22:17,509 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5147795010019433, 'Total loss': 0.5147795010019433} | train loss {'Reaction outcome loss': 0.5468265110785179, 'Total loss': 0.5468265110785179}
2022-12-05 23:22:17,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:17,509 INFO:     Epoch: 54
2022-12-05 23:22:18,217 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5241150964390148, 'Total loss': 0.5241150964390148} | train loss {'Reaction outcome loss': 0.5356987042706988, 'Total loss': 0.5356987042706988}
2022-12-05 23:22:18,217 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:18,217 INFO:     Epoch: 55
2022-12-05 23:22:18,925 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5192887153137814, 'Total loss': 0.5192887153137814} | train loss {'Reaction outcome loss': 0.5395665361210402, 'Total loss': 0.5395665361210402}
2022-12-05 23:22:18,925 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:18,925 INFO:     Epoch: 56
2022-12-05 23:22:19,632 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5652572627771985, 'Total loss': 0.5652572627771985} | train loss {'Reaction outcome loss': 0.5427975332447392, 'Total loss': 0.5427975332447392}
2022-12-05 23:22:19,632 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:19,632 INFO:     Epoch: 57
2022-12-05 23:22:20,336 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5682171024382114, 'Total loss': 0.5682171024382114} | train loss {'Reaction outcome loss': 0.5358770670188282, 'Total loss': 0.5358770670188282}
2022-12-05 23:22:20,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:20,337 INFO:     Epoch: 58
2022-12-05 23:22:21,038 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5231070437214591, 'Total loss': 0.5231070437214591} | train loss {'Reaction outcome loss': 0.5419269116663257, 'Total loss': 0.5419269116663257}
2022-12-05 23:22:21,038 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:21,038 INFO:     Epoch: 59
2022-12-05 23:22:21,743 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5204694088209759, 'Total loss': 0.5204694088209759} | train loss {'Reaction outcome loss': 0.5457212366616195, 'Total loss': 0.5457212366616195}
2022-12-05 23:22:21,743 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:21,743 INFO:     Epoch: 60
2022-12-05 23:22:22,449 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5301889011805708, 'Total loss': 0.5301889011805708} | train loss {'Reaction outcome loss': 0.5346096939886147, 'Total loss': 0.5346096939886147}
2022-12-05 23:22:22,450 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:22,450 INFO:     Epoch: 61
2022-12-05 23:22:23,155 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5615125731988386, 'Total loss': 0.5615125731988386} | train loss {'Reaction outcome loss': 0.5447966879919955, 'Total loss': 0.5447966879919955}
2022-12-05 23:22:23,156 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:23,156 INFO:     Epoch: 62
2022-12-05 23:22:23,860 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5291123512116346, 'Total loss': 0.5291123512116346} | train loss {'Reaction outcome loss': 0.5444672939929402, 'Total loss': 0.5444672939929402}
2022-12-05 23:22:23,860 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:23,860 INFO:     Epoch: 63
2022-12-05 23:22:24,561 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5249578722498633, 'Total loss': 0.5249578722498633} | train loss {'Reaction outcome loss': 0.5478659374752508, 'Total loss': 0.5478659374752508}
2022-12-05 23:22:24,561 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:24,561 INFO:     Epoch: 64
2022-12-05 23:22:25,265 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5612998178059404, 'Total loss': 0.5612998178059404} | train loss {'Reaction outcome loss': 0.5490097796265413, 'Total loss': 0.5490097796265413}
2022-12-05 23:22:25,265 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:25,265 INFO:     Epoch: 65
2022-12-05 23:22:25,969 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.541048635813323, 'Total loss': 0.541048635813323} | train loss {'Reaction outcome loss': 0.5449038177487339, 'Total loss': 0.5449038177487339}
2022-12-05 23:22:25,969 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:25,969 INFO:     Epoch: 66
2022-12-05 23:22:26,676 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5590115414763038, 'Total loss': 0.5590115414763038} | train loss {'Reaction outcome loss': 0.5396593857692321, 'Total loss': 0.5396593857692321}
2022-12-05 23:22:26,676 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:26,677 INFO:     Epoch: 67
2022-12-05 23:22:27,380 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.570074936883016, 'Total loss': 0.570074936883016} | train loss {'Reaction outcome loss': 0.5361051361570474, 'Total loss': 0.5361051361570474}
2022-12-05 23:22:27,381 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:27,381 INFO:     Epoch: 68
2022-12-05 23:22:28,086 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.523719843138348, 'Total loss': 0.523719843138348} | train loss {'Reaction outcome loss': 0.5396231196911229, 'Total loss': 0.5396231196911229}
2022-12-05 23:22:28,086 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:28,086 INFO:     Epoch: 69
2022-12-05 23:22:28,787 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5195580314506184, 'Total loss': 0.5195580314506184} | train loss {'Reaction outcome loss': 0.5415781310454071, 'Total loss': 0.5415781310454071}
2022-12-05 23:22:28,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:28,787 INFO:     Epoch: 70
2022-12-05 23:22:29,492 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5265400555323471, 'Total loss': 0.5265400555323471} | train loss {'Reaction outcome loss': 0.5405426145444515, 'Total loss': 0.5405426145444515}
2022-12-05 23:22:29,492 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:29,492 INFO:     Epoch: 71
2022-12-05 23:22:30,196 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5524375208399512, 'Total loss': 0.5524375208399512} | train loss {'Reaction outcome loss': 0.5400761317024346, 'Total loss': 0.5400761317024346}
2022-12-05 23:22:30,196 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:30,196 INFO:     Epoch: 72
2022-12-05 23:22:30,901 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5576120323755525, 'Total loss': 0.5576120323755525} | train loss {'Reaction outcome loss': 0.5390445580969938, 'Total loss': 0.5390445580969938}
2022-12-05 23:22:30,901 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:30,901 INFO:     Epoch: 73
2022-12-05 23:22:31,602 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5216283317316662, 'Total loss': 0.5216283317316662} | train loss {'Reaction outcome loss': 0.5430096656325375, 'Total loss': 0.5430096656325375}
2022-12-05 23:22:31,603 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:31,603 INFO:     Epoch: 74
2022-12-05 23:22:32,304 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5204601775516163, 'Total loss': 0.5204601775516163} | train loss {'Reaction outcome loss': 0.537853605110153, 'Total loss': 0.537853605110153}
2022-12-05 23:22:32,304 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:32,304 INFO:     Epoch: 75
2022-12-05 23:22:33,008 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5307525531812147, 'Total loss': 0.5307525531812147} | train loss {'Reaction outcome loss': 0.5346222347636455, 'Total loss': 0.5346222347636455}
2022-12-05 23:22:33,009 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:33,009 INFO:     Epoch: 76
2022-12-05 23:22:33,710 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5220413289286874, 'Total loss': 0.5220413289286874} | train loss {'Reaction outcome loss': 0.5434757124195214, 'Total loss': 0.5434757124195214}
2022-12-05 23:22:33,711 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:33,711 INFO:     Epoch: 77
2022-12-05 23:22:34,413 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.532779185609384, 'Total loss': 0.532779185609384} | train loss {'Reaction outcome loss': 0.5491037269232244, 'Total loss': 0.5491037269232244}
2022-12-05 23:22:34,413 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:34,413 INFO:     Epoch: 78
2022-12-05 23:22:35,118 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5092204904014414, 'Total loss': 0.5092204904014414} | train loss {'Reaction outcome loss': 0.5450828972495037, 'Total loss': 0.5450828972495037}
2022-12-05 23:22:35,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:35,119 INFO:     Epoch: 79
2022-12-05 23:22:35,823 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5137344442985274, 'Total loss': 0.5137344442985274} | train loss {'Reaction outcome loss': 0.5351113663450909, 'Total loss': 0.5351113663450909}
2022-12-05 23:22:35,823 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:35,823 INFO:     Epoch: 80
2022-12-05 23:22:36,526 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5642799802801826, 'Total loss': 0.5642799802801826} | train loss {'Reaction outcome loss': 0.5357393272492567, 'Total loss': 0.5357393272492567}
2022-12-05 23:22:36,526 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:36,526 INFO:     Epoch: 81
2022-12-05 23:22:37,228 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5418731841174039, 'Total loss': 0.5418731841174039} | train loss {'Reaction outcome loss': 0.5434915292480214, 'Total loss': 0.5434915292480214}
2022-12-05 23:22:37,228 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:37,229 INFO:     Epoch: 82
2022-12-05 23:22:37,932 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5230845897035166, 'Total loss': 0.5230845897035166} | train loss {'Reaction outcome loss': 0.5433829406857008, 'Total loss': 0.5433829406857008}
2022-12-05 23:22:37,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:37,933 INFO:     Epoch: 83
2022-12-05 23:22:38,637 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5434876524589278, 'Total loss': 0.5434876524589278} | train loss {'Reaction outcome loss': 0.5385419618986879, 'Total loss': 0.5385419618986879}
2022-12-05 23:22:38,637 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:38,637 INFO:     Epoch: 84
2022-12-05 23:22:39,339 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6153707673603838, 'Total loss': 0.6153707673603838} | train loss {'Reaction outcome loss': 0.5384172193917186, 'Total loss': 0.5384172193917186}
2022-12-05 23:22:39,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:39,339 INFO:     Epoch: 85
2022-12-05 23:22:40,047 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5327748896723444, 'Total loss': 0.5327748896723444} | train loss {'Reaction outcome loss': 0.537407743069626, 'Total loss': 0.537407743069626}
2022-12-05 23:22:40,048 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:40,048 INFO:     Epoch: 86
2022-12-05 23:22:40,750 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5614943097938191, 'Total loss': 0.5614943097938191} | train loss {'Reaction outcome loss': 0.5434675632942061, 'Total loss': 0.5434675632942061}
2022-12-05 23:22:40,751 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:40,751 INFO:     Epoch: 87
2022-12-05 23:22:41,454 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5274176956577734, 'Total loss': 0.5274176956577734} | train loss {'Reaction outcome loss': 0.5425929268482725, 'Total loss': 0.5425929268482725}
2022-12-05 23:22:41,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:41,455 INFO:     Epoch: 88
2022-12-05 23:22:42,157 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5250118334184993, 'Total loss': 0.5250118334184993} | train loss {'Reaction outcome loss': 0.5509773699740167, 'Total loss': 0.5509773699740167}
2022-12-05 23:22:42,157 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:42,157 INFO:     Epoch: 89
2022-12-05 23:22:42,857 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5344923738051545, 'Total loss': 0.5344923738051545} | train loss {'Reaction outcome loss': 0.5494895903808386, 'Total loss': 0.5494895903808386}
2022-12-05 23:22:42,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:42,857 INFO:     Epoch: 90
2022-12-05 23:22:43,558 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5290706652131948, 'Total loss': 0.5290706652131948} | train loss {'Reaction outcome loss': 0.5488714183631697, 'Total loss': 0.5488714183631697}
2022-12-05 23:22:43,558 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:43,558 INFO:     Epoch: 91
2022-12-05 23:22:44,263 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5266709957610477, 'Total loss': 0.5266709957610477} | train loss {'Reaction outcome loss': 0.552075543866949, 'Total loss': 0.552075543866949}
2022-12-05 23:22:44,263 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:44,263 INFO:     Epoch: 92
2022-12-05 23:22:44,971 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.530061871829358, 'Total loss': 0.530061871829358} | train loss {'Reaction outcome loss': 0.5369901496630448, 'Total loss': 0.5369901496630448}
2022-12-05 23:22:44,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:44,971 INFO:     Epoch: 93
2022-12-05 23:22:45,671 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5339514464139938, 'Total loss': 0.5339514464139938} | train loss {'Reaction outcome loss': 0.5445638807558337, 'Total loss': 0.5445638807558337}
2022-12-05 23:22:45,671 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:45,672 INFO:     Epoch: 94
2022-12-05 23:22:46,376 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5154048024930737, 'Total loss': 0.5154048024930737} | train loss {'Reaction outcome loss': 0.544913066724534, 'Total loss': 0.544913066724534}
2022-12-05 23:22:46,376 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:46,376 INFO:     Epoch: 95
2022-12-05 23:22:47,075 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5074628991159525, 'Total loss': 0.5074628991159525} | train loss {'Reaction outcome loss': 0.5399849083621492, 'Total loss': 0.5399849083621492}
2022-12-05 23:22:47,076 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:47,076 INFO:     Epoch: 96
2022-12-05 23:22:47,780 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5168434212153609, 'Total loss': 0.5168434212153609} | train loss {'Reaction outcome loss': 0.5439742234071739, 'Total loss': 0.5439742234071739}
2022-12-05 23:22:47,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:47,780 INFO:     Epoch: 97
2022-12-05 23:22:48,479 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5171779827638106, 'Total loss': 0.5171779827638106} | train loss {'Reaction outcome loss': 0.5337887276491897, 'Total loss': 0.5337887276491897}
2022-12-05 23:22:48,480 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:48,480 INFO:     Epoch: 98
2022-12-05 23:22:49,185 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5645942958918485, 'Total loss': 0.5645942958918485} | train loss {'Reaction outcome loss': 0.5402881092870766, 'Total loss': 0.5402881092870766}
2022-12-05 23:22:49,185 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:49,185 INFO:     Epoch: 99
2022-12-05 23:22:49,890 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5649051720445807, 'Total loss': 0.5649051720445807} | train loss {'Reaction outcome loss': 0.5422653288011127, 'Total loss': 0.5422653288011127}
2022-12-05 23:22:49,890 INFO:     Best model found after epoch 49 of 100.
2022-12-05 23:22:49,890 INFO:   Done with stage: TRAINING
2022-12-05 23:22:49,891 INFO:   Starting stage: EVALUATION
2022-12-05 23:22:50,014 INFO:   Done with stage: EVALUATION
2022-12-05 23:22:50,014 INFO:   Leaving out SEQ value Fold_5
2022-12-05 23:22:50,026 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:22:50,027 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:22:50,659 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:22:50,659 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:22:50,730 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:22:50,730 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:22:50,730 INFO:     No hyperparam tuning for this model
2022-12-05 23:22:50,730 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:22:50,730 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:22:50,731 INFO:     None feature selector for col prot
2022-12-05 23:22:50,731 INFO:     None feature selector for col prot
2022-12-05 23:22:50,731 INFO:     None feature selector for col prot
2022-12-05 23:22:50,732 INFO:     None feature selector for col chem
2022-12-05 23:22:50,732 INFO:     None feature selector for col chem
2022-12-05 23:22:50,732 INFO:     None feature selector for col chem
2022-12-05 23:22:50,732 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:22:50,732 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:22:50,734 INFO:     Number of params in model 215731
2022-12-05 23:22:50,737 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:22:50,737 INFO:   Starting stage: TRAINING
2022-12-05 23:22:50,794 INFO:     Val loss before train {'Reaction outcome loss': 1.0000968995419415, 'Total loss': 1.0000968995419415}
2022-12-05 23:22:50,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:50,795 INFO:     Epoch: 0
2022-12-05 23:22:51,499 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7179730317809365, 'Total loss': 0.7179730317809365} | train loss {'Reaction outcome loss': 0.8092691176120312, 'Total loss': 0.8092691176120312}
2022-12-05 23:22:51,499 INFO:     Found new best model at epoch 0
2022-12-05 23:22:51,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:51,500 INFO:     Epoch: 1
2022-12-05 23:22:52,204 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6663757251067595, 'Total loss': 0.6663757251067595} | train loss {'Reaction outcome loss': 0.6815883160358475, 'Total loss': 0.6815883160358475}
2022-12-05 23:22:52,205 INFO:     Found new best model at epoch 1
2022-12-05 23:22:52,205 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:52,206 INFO:     Epoch: 2
2022-12-05 23:22:52,917 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6152423484758898, 'Total loss': 0.6152423484758898} | train loss {'Reaction outcome loss': 0.642520320271292, 'Total loss': 0.642520320271292}
2022-12-05 23:22:52,917 INFO:     Found new best model at epoch 2
2022-12-05 23:22:52,917 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:52,917 INFO:     Epoch: 3
2022-12-05 23:22:53,621 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6076918494972315, 'Total loss': 0.6076918494972315} | train loss {'Reaction outcome loss': 0.6247830229901499, 'Total loss': 0.6247830229901499}
2022-12-05 23:22:53,621 INFO:     Found new best model at epoch 3
2022-12-05 23:22:53,622 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:53,622 INFO:     Epoch: 4
2022-12-05 23:22:54,332 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5965459123253822, 'Total loss': 0.5965459123253822} | train loss {'Reaction outcome loss': 0.6000777712512401, 'Total loss': 0.6000777712512401}
2022-12-05 23:22:54,332 INFO:     Found new best model at epoch 4
2022-12-05 23:22:54,333 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:54,333 INFO:     Epoch: 5
2022-12-05 23:22:55,037 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6511153666810556, 'Total loss': 0.6511153666810556} | train loss {'Reaction outcome loss': 0.5878137562784457, 'Total loss': 0.5878137562784457}
2022-12-05 23:22:55,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:55,037 INFO:     Epoch: 6
2022-12-05 23:22:55,741 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6453494707291777, 'Total loss': 0.6453494707291777} | train loss {'Reaction outcome loss': 0.5819342424191775, 'Total loss': 0.5819342424191775}
2022-12-05 23:22:55,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:55,741 INFO:     Epoch: 7
2022-12-05 23:22:56,448 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5863560956310142, 'Total loss': 0.5863560956310142} | train loss {'Reaction outcome loss': 0.5756045007897962, 'Total loss': 0.5756045007897962}
2022-12-05 23:22:56,448 INFO:     Found new best model at epoch 7
2022-12-05 23:22:56,449 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:56,449 INFO:     Epoch: 8
2022-12-05 23:22:57,160 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5386396145278757, 'Total loss': 0.5386396145278757} | train loss {'Reaction outcome loss': 0.5733374387867027, 'Total loss': 0.5733374387867027}
2022-12-05 23:22:57,160 INFO:     Found new best model at epoch 8
2022-12-05 23:22:57,161 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:57,161 INFO:     Epoch: 9
2022-12-05 23:22:57,867 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.6063543199138208, 'Total loss': 0.6063543199138208} | train loss {'Reaction outcome loss': 0.5667280294001102, 'Total loss': 0.5667280294001102}
2022-12-05 23:22:57,867 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:57,867 INFO:     Epoch: 10
2022-12-05 23:22:58,574 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5489553111520681, 'Total loss': 0.5489553111520681} | train loss {'Reaction outcome loss': 0.5667127253067109, 'Total loss': 0.5667127253067109}
2022-12-05 23:22:58,574 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:58,575 INFO:     Epoch: 11
2022-12-05 23:22:59,282 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.586259431459687, 'Total loss': 0.586259431459687} | train loss {'Reaction outcome loss': 0.5559649686178854, 'Total loss': 0.5559649686178854}
2022-12-05 23:22:59,282 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:59,282 INFO:     Epoch: 12
2022-12-05 23:22:59,989 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.6047956665808504, 'Total loss': 0.6047956665808504} | train loss {'Reaction outcome loss': 0.5608781627829997, 'Total loss': 0.5608781627829997}
2022-12-05 23:22:59,989 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:22:59,989 INFO:     Epoch: 13
2022-12-05 23:23:00,699 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5699229734865102, 'Total loss': 0.5699229734865102} | train loss {'Reaction outcome loss': 0.558388122627812, 'Total loss': 0.558388122627812}
2022-12-05 23:23:00,699 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:00,699 INFO:     Epoch: 14
2022-12-05 23:23:01,406 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5557789399542592, 'Total loss': 0.5557789399542592} | train loss {'Reaction outcome loss': 0.5443878286187688, 'Total loss': 0.5443878286187688}
2022-12-05 23:23:01,406 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:01,406 INFO:     Epoch: 15
2022-12-05 23:23:02,116 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6046048694036223, 'Total loss': 0.6046048694036223} | train loss {'Reaction outcome loss': 0.551911483368566, 'Total loss': 0.551911483368566}
2022-12-05 23:23:02,116 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:02,116 INFO:     Epoch: 16
2022-12-05 23:23:02,825 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.6050512783906676, 'Total loss': 0.6050512783906676} | train loss {'Reaction outcome loss': 0.538528248667717, 'Total loss': 0.538528248667717}
2022-12-05 23:23:02,825 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:02,826 INFO:     Epoch: 17
2022-12-05 23:23:03,532 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.6017520657994531, 'Total loss': 0.6017520657994531} | train loss {'Reaction outcome loss': 0.5486268362090472, 'Total loss': 0.5486268362090472}
2022-12-05 23:23:03,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:03,532 INFO:     Epoch: 18
2022-12-05 23:23:04,238 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5698366177014329, 'Total loss': 0.5698366177014329} | train loss {'Reaction outcome loss': 0.5468730298021147, 'Total loss': 0.5468730298021147}
2022-12-05 23:23:04,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:04,238 INFO:     Epoch: 19
2022-12-05 23:23:04,945 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.60012132471258, 'Total loss': 0.60012132471258} | train loss {'Reaction outcome loss': 0.5475143074628807, 'Total loss': 0.5475143074628807}
2022-12-05 23:23:04,946 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:04,946 INFO:     Epoch: 20
2022-12-05 23:23:05,652 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5390757464549758, 'Total loss': 0.5390757464549758} | train loss {'Reaction outcome loss': 0.5388937474739167, 'Total loss': 0.5388937474739167}
2022-12-05 23:23:05,652 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:05,653 INFO:     Epoch: 21
2022-12-05 23:23:06,360 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5583220855756239, 'Total loss': 0.5583220855756239} | train loss {'Reaction outcome loss': 0.5265788226238182, 'Total loss': 0.5265788226238182}
2022-12-05 23:23:06,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:06,360 INFO:     Epoch: 22
2022-12-05 23:23:07,069 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.6601886193860661, 'Total loss': 0.6601886193860661} | train loss {'Reaction outcome loss': 0.5277011941878065, 'Total loss': 0.5277011941878065}
2022-12-05 23:23:07,069 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:07,069 INFO:     Epoch: 23
2022-12-05 23:23:07,780 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5955648787996985, 'Total loss': 0.5955648787996985} | train loss {'Reaction outcome loss': 0.5333068688670474, 'Total loss': 0.5333068688670474}
2022-12-05 23:23:07,780 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:07,780 INFO:     Epoch: 24
2022-12-05 23:23:08,496 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5445186346769333, 'Total loss': 0.5445186346769333} | train loss {'Reaction outcome loss': 0.5314122144613536, 'Total loss': 0.5314122144613536}
2022-12-05 23:23:08,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:08,496 INFO:     Epoch: 25
2022-12-05 23:23:09,207 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5644758357243105, 'Total loss': 0.5644758357243105} | train loss {'Reaction outcome loss': 0.5267072932253922, 'Total loss': 0.5267072932253922}
2022-12-05 23:23:09,207 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:09,207 INFO:     Epoch: 26
2022-12-05 23:23:09,919 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5567238723689859, 'Total loss': 0.5567238723689859} | train loss {'Reaction outcome loss': 0.5291089364177277, 'Total loss': 0.5291089364177277}
2022-12-05 23:23:09,919 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:09,919 INFO:     Epoch: 27
2022-12-05 23:23:10,629 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5288290005515922, 'Total loss': 0.5288290005515922} | train loss {'Reaction outcome loss': 0.5226365721994831, 'Total loss': 0.5226365721994831}
2022-12-05 23:23:10,629 INFO:     Found new best model at epoch 27
2022-12-05 23:23:10,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:10,630 INFO:     Epoch: 28
2022-12-05 23:23:11,340 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5244430787861347, 'Total loss': 0.5244430787861347} | train loss {'Reaction outcome loss': 0.5217996193396468, 'Total loss': 0.5217996193396468}
2022-12-05 23:23:11,341 INFO:     Found new best model at epoch 28
2022-12-05 23:23:11,342 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:11,342 INFO:     Epoch: 29
2022-12-05 23:23:12,050 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5354057018729773, 'Total loss': 0.5354057018729773} | train loss {'Reaction outcome loss': 0.5118650497508145, 'Total loss': 0.5118650497508145}
2022-12-05 23:23:12,050 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:12,050 INFO:     Epoch: 30
2022-12-05 23:23:12,761 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5348550169305368, 'Total loss': 0.5348550169305368} | train loss {'Reaction outcome loss': 0.5253711881176117, 'Total loss': 0.5253711881176117}
2022-12-05 23:23:12,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:12,761 INFO:     Epoch: 31
2022-12-05 23:23:13,471 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5603598512031815, 'Total loss': 0.5603598512031815} | train loss {'Reaction outcome loss': 0.5241957917929657, 'Total loss': 0.5241957917929657}
2022-12-05 23:23:13,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:13,472 INFO:     Epoch: 32
2022-12-05 23:23:14,183 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5523358905179934, 'Total loss': 0.5523358905179934} | train loss {'Reaction outcome loss': 0.5196715441322134, 'Total loss': 0.5196715441322134}
2022-12-05 23:23:14,183 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:14,183 INFO:     Epoch: 33
2022-12-05 23:23:14,893 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5404461219229482, 'Total loss': 0.5404461219229482} | train loss {'Reaction outcome loss': 0.5201746242180947, 'Total loss': 0.5201746242180947}
2022-12-05 23:23:14,893 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:14,893 INFO:     Epoch: 34
2022-12-05 23:23:15,609 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5275660150430419, 'Total loss': 0.5275660150430419} | train loss {'Reaction outcome loss': 0.5080261385488894, 'Total loss': 0.5080261385488894}
2022-12-05 23:23:15,609 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:15,609 INFO:     Epoch: 35
2022-12-05 23:23:16,314 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5399795675819571, 'Total loss': 0.5399795675819571} | train loss {'Reaction outcome loss': 0.5066373842738329, 'Total loss': 0.5066373842738329}
2022-12-05 23:23:16,314 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:16,315 INFO:     Epoch: 36
2022-12-05 23:23:17,021 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5234902270815589, 'Total loss': 0.5234902270815589} | train loss {'Reaction outcome loss': 0.5167395206949403, 'Total loss': 0.5167395206949403}
2022-12-05 23:23:17,021 INFO:     Found new best model at epoch 36
2022-12-05 23:23:17,022 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:17,022 INFO:     Epoch: 37
2022-12-05 23:23:17,726 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5141231112859466, 'Total loss': 0.5141231112859466} | train loss {'Reaction outcome loss': 0.5159032543700549, 'Total loss': 0.5159032543700549}
2022-12-05 23:23:17,726 INFO:     Found new best model at epoch 37
2022-12-05 23:23:17,727 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:17,727 INFO:     Epoch: 38
2022-12-05 23:23:18,436 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5211511589586735, 'Total loss': 0.5211511589586735} | train loss {'Reaction outcome loss': 0.5153560642633708, 'Total loss': 0.5153560642633708}
2022-12-05 23:23:18,437 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:18,437 INFO:     Epoch: 39
2022-12-05 23:23:19,140 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5310027751732956, 'Total loss': 0.5310027751732956} | train loss {'Reaction outcome loss': 0.515315750313382, 'Total loss': 0.515315750313382}
2022-12-05 23:23:19,140 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:19,140 INFO:     Epoch: 40
2022-12-05 23:23:19,842 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5337072814052756, 'Total loss': 0.5337072814052756} | train loss {'Reaction outcome loss': 0.5136074942927207, 'Total loss': 0.5136074942927207}
2022-12-05 23:23:19,842 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:19,843 INFO:     Epoch: 41
2022-12-05 23:23:20,546 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5333941761742939, 'Total loss': 0.5333941761742939} | train loss {'Reaction outcome loss': 0.5124013686492559, 'Total loss': 0.5124013686492559}
2022-12-05 23:23:20,546 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:20,546 INFO:     Epoch: 42
2022-12-05 23:23:21,249 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5147202512757345, 'Total loss': 0.5147202512757345} | train loss {'Reaction outcome loss': 0.511205393640745, 'Total loss': 0.511205393640745}
2022-12-05 23:23:21,249 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:21,249 INFO:     Epoch: 43
2022-12-05 23:23:21,952 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.502053978768262, 'Total loss': 0.502053978768262} | train loss {'Reaction outcome loss': 0.5166030842210015, 'Total loss': 0.5166030842210015}
2022-12-05 23:23:21,953 INFO:     Found new best model at epoch 43
2022-12-05 23:23:21,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:21,953 INFO:     Epoch: 44
2022-12-05 23:23:22,661 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5137525952675126, 'Total loss': 0.5137525952675126} | train loss {'Reaction outcome loss': 0.513465519393644, 'Total loss': 0.513465519393644}
2022-12-05 23:23:22,661 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:22,661 INFO:     Epoch: 45
2022-12-05 23:23:23,365 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5057642910290848, 'Total loss': 0.5057642910290848} | train loss {'Reaction outcome loss': 0.5178790866968132, 'Total loss': 0.5178790866968132}
2022-12-05 23:23:23,366 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:23,366 INFO:     Epoch: 46
2022-12-05 23:23:24,069 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.6027707985856317, 'Total loss': 0.6027707985856317} | train loss {'Reaction outcome loss': 0.5067022547967011, 'Total loss': 0.5067022547967011}
2022-12-05 23:23:24,069 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:24,069 INFO:     Epoch: 47
2022-12-05 23:23:24,774 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5368449105457826, 'Total loss': 0.5368449105457826} | train loss {'Reaction outcome loss': 0.516582093171535, 'Total loss': 0.516582093171535}
2022-12-05 23:23:24,775 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:24,775 INFO:     Epoch: 48
2022-12-05 23:23:25,486 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5209086219018156, 'Total loss': 0.5209086219018156} | train loss {'Reaction outcome loss': 0.5072060343358786, 'Total loss': 0.5072060343358786}
2022-12-05 23:23:25,486 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:25,487 INFO:     Epoch: 49
2022-12-05 23:23:26,192 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5321440310640768, 'Total loss': 0.5321440310640768} | train loss {'Reaction outcome loss': 0.5165101996352596, 'Total loss': 0.5165101996352596}
2022-12-05 23:23:26,192 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:26,192 INFO:     Epoch: 50
2022-12-05 23:23:26,897 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5573572340336713, 'Total loss': 0.5573572340336713} | train loss {'Reaction outcome loss': 0.5093967293899867, 'Total loss': 0.5093967293899867}
2022-12-05 23:23:26,897 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:26,897 INFO:     Epoch: 51
2022-12-05 23:23:27,601 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5166565718298609, 'Total loss': 0.5166565718298609} | train loss {'Reaction outcome loss': 0.5115677895805528, 'Total loss': 0.5115677895805528}
2022-12-05 23:23:27,601 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:27,601 INFO:     Epoch: 52
2022-12-05 23:23:28,309 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4963375214825977, 'Total loss': 0.4963375214825977} | train loss {'Reaction outcome loss': 0.5028886623800762, 'Total loss': 0.5028886623800762}
2022-12-05 23:23:28,309 INFO:     Found new best model at epoch 52
2022-12-05 23:23:28,310 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:28,310 INFO:     Epoch: 53
2022-12-05 23:23:29,016 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.633995614268563, 'Total loss': 0.633995614268563} | train loss {'Reaction outcome loss': 0.5127507483646754, 'Total loss': 0.5127507483646754}
2022-12-05 23:23:29,016 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:29,016 INFO:     Epoch: 54
2022-12-05 23:23:29,728 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5906310948458585, 'Total loss': 0.5906310948458585} | train loss {'Reaction outcome loss': 0.5108319006019062, 'Total loss': 0.5108319006019062}
2022-12-05 23:23:29,728 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:29,728 INFO:     Epoch: 55
2022-12-05 23:23:30,436 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5363360406322912, 'Total loss': 0.5363360406322912} | train loss {'Reaction outcome loss': 0.5082006512750541, 'Total loss': 0.5082006512750541}
2022-12-05 23:23:30,437 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:30,437 INFO:     Epoch: 56
2022-12-05 23:23:31,145 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5208926942538131, 'Total loss': 0.5208926942538131} | train loss {'Reaction outcome loss': 0.5103841439610527, 'Total loss': 0.5103841439610527}
2022-12-05 23:23:31,145 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:31,145 INFO:     Epoch: 57
2022-12-05 23:23:31,857 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5435204898769205, 'Total loss': 0.5435204898769205} | train loss {'Reaction outcome loss': 0.5084198768581113, 'Total loss': 0.5084198768581113}
2022-12-05 23:23:31,857 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:31,857 INFO:     Epoch: 58
2022-12-05 23:23:32,564 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5368943617425181, 'Total loss': 0.5368943617425181} | train loss {'Reaction outcome loss': 0.518912261351943, 'Total loss': 0.518912261351943}
2022-12-05 23:23:32,564 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:32,564 INFO:     Epoch: 59
2022-12-05 23:23:33,270 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.522757828574289, 'Total loss': 0.522757828574289} | train loss {'Reaction outcome loss': 0.5027178262150095, 'Total loss': 0.5027178262150095}
2022-12-05 23:23:33,270 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:33,270 INFO:     Epoch: 60
2022-12-05 23:23:33,972 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.530407093803991, 'Total loss': 0.530407093803991} | train loss {'Reaction outcome loss': 0.49876299434371535, 'Total loss': 0.49876299434371535}
2022-12-05 23:23:33,973 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:33,973 INFO:     Epoch: 61
2022-12-05 23:23:34,680 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5777892917394638, 'Total loss': 0.5777892917394638} | train loss {'Reaction outcome loss': 0.5122439760354257, 'Total loss': 0.5122439760354257}
2022-12-05 23:23:34,680 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:34,680 INFO:     Epoch: 62
2022-12-05 23:23:35,390 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5839475948702205, 'Total loss': 0.5839475948702205} | train loss {'Reaction outcome loss': 0.5026032820704484, 'Total loss': 0.5026032820704484}
2022-12-05 23:23:35,390 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:35,390 INFO:     Epoch: 63
2022-12-05 23:23:36,094 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5200898708267645, 'Total loss': 0.5200898708267645} | train loss {'Reaction outcome loss': 0.5115405739765735, 'Total loss': 0.5115405739765735}
2022-12-05 23:23:36,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:36,095 INFO:     Epoch: 64
2022-12-05 23:23:36,800 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5383558517152612, 'Total loss': 0.5383558517152612} | train loss {'Reaction outcome loss': 0.5088728962526206, 'Total loss': 0.5088728962526206}
2022-12-05 23:23:36,800 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:36,800 INFO:     Epoch: 65
2022-12-05 23:23:37,509 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5046809376640753, 'Total loss': 0.5046809376640753} | train loss {'Reaction outcome loss': 0.5077478317243438, 'Total loss': 0.5077478317243438}
2022-12-05 23:23:37,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:37,509 INFO:     Epoch: 66
2022-12-05 23:23:38,218 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5544085204601288, 'Total loss': 0.5544085204601288} | train loss {'Reaction outcome loss': 0.5032042421761059, 'Total loss': 0.5032042421761059}
2022-12-05 23:23:38,218 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:38,218 INFO:     Epoch: 67
2022-12-05 23:23:38,921 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5077406425367702, 'Total loss': 0.5077406425367702} | train loss {'Reaction outcome loss': 0.5161590621836724, 'Total loss': 0.5161590621836724}
2022-12-05 23:23:38,921 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:38,921 INFO:     Epoch: 68
2022-12-05 23:23:39,624 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5430892326615073, 'Total loss': 0.5430892326615073} | train loss {'Reaction outcome loss': 0.5037718149683168, 'Total loss': 0.5037718149683168}
2022-12-05 23:23:39,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:39,624 INFO:     Epoch: 69
2022-12-05 23:23:40,328 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5223103524609045, 'Total loss': 0.5223103524609045} | train loss {'Reaction outcome loss': 0.5156456046407262, 'Total loss': 0.5156456046407262}
2022-12-05 23:23:40,328 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:40,328 INFO:     Epoch: 70
2022-12-05 23:23:41,036 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5339913832193072, 'Total loss': 0.5339913832193072} | train loss {'Reaction outcome loss': 0.5076574216927251, 'Total loss': 0.5076574216927251}
2022-12-05 23:23:41,036 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:41,037 INFO:     Epoch: 71
2022-12-05 23:23:41,744 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5168608701364561, 'Total loss': 0.5168608701364561} | train loss {'Reaction outcome loss': 0.5072606326110901, 'Total loss': 0.5072606326110901}
2022-12-05 23:23:41,744 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:41,744 INFO:     Epoch: 72
2022-12-05 23:23:42,449 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5035054514353926, 'Total loss': 0.5035054514353926} | train loss {'Reaction outcome loss': 0.5104613751773873, 'Total loss': 0.5104613751773873}
2022-12-05 23:23:42,449 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:42,450 INFO:     Epoch: 73
2022-12-05 23:23:43,160 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.6054366999729113, 'Total loss': 0.6054366999729113} | train loss {'Reaction outcome loss': 0.5083540104209415, 'Total loss': 0.5083540104209415}
2022-12-05 23:23:43,160 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:43,161 INFO:     Epoch: 74
2022-12-05 23:23:43,867 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5523900586095724, 'Total loss': 0.5523900586095724} | train loss {'Reaction outcome loss': 0.5129465226444506, 'Total loss': 0.5129465226444506}
2022-12-05 23:23:43,867 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:43,867 INFO:     Epoch: 75
2022-12-05 23:23:44,570 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5908160920847546, 'Total loss': 0.5908160920847546} | train loss {'Reaction outcome loss': 0.5121585727939683, 'Total loss': 0.5121585727939683}
2022-12-05 23:23:44,570 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:44,570 INFO:     Epoch: 76
2022-12-05 23:23:45,277 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5356505509804595, 'Total loss': 0.5356505509804595} | train loss {'Reaction outcome loss': 0.5071179216216889, 'Total loss': 0.5071179216216889}
2022-12-05 23:23:45,277 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:45,277 INFO:     Epoch: 77
2022-12-05 23:23:45,983 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5108289583162828, 'Total loss': 0.5108289583162828} | train loss {'Reaction outcome loss': 0.5085150353129833, 'Total loss': 0.5085150353129833}
2022-12-05 23:23:45,983 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:45,983 INFO:     Epoch: 78
2022-12-05 23:23:46,695 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5102053531868891, 'Total loss': 0.5102053531868891} | train loss {'Reaction outcome loss': 0.5091677878292338, 'Total loss': 0.5091677878292338}
2022-12-05 23:23:46,695 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:46,695 INFO:     Epoch: 79
2022-12-05 23:23:47,402 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5071649592031132, 'Total loss': 0.5071649592031132} | train loss {'Reaction outcome loss': 0.5023310480999851, 'Total loss': 0.5023310480999851}
2022-12-05 23:23:47,402 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:47,402 INFO:     Epoch: 80
2022-12-05 23:23:48,107 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5215046033263206, 'Total loss': 0.5215046033263206} | train loss {'Reaction outcome loss': 0.5091400633175527, 'Total loss': 0.5091400633175527}
2022-12-05 23:23:48,107 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:48,107 INFO:     Epoch: 81
2022-12-05 23:23:48,816 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5432433448731899, 'Total loss': 0.5432433448731899} | train loss {'Reaction outcome loss': 0.5093984454870224, 'Total loss': 0.5093984454870224}
2022-12-05 23:23:48,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:48,816 INFO:     Epoch: 82
2022-12-05 23:23:49,524 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5659353103150021, 'Total loss': 0.5659353103150021} | train loss {'Reaction outcome loss': 0.5104044988571156, 'Total loss': 0.5104044988571156}
2022-12-05 23:23:49,524 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:49,524 INFO:     Epoch: 83
2022-12-05 23:23:50,231 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5681607371026819, 'Total loss': 0.5681607371026819} | train loss {'Reaction outcome loss': 0.4980532040879611, 'Total loss': 0.4980532040879611}
2022-12-05 23:23:50,231 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:50,231 INFO:     Epoch: 84
2022-12-05 23:23:50,943 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.517633949152448, 'Total loss': 0.517633949152448} | train loss {'Reaction outcome loss': 0.5096342766717556, 'Total loss': 0.5096342766717556}
2022-12-05 23:23:50,943 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:50,943 INFO:     Epoch: 85
2022-12-05 23:23:51,649 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.531688969920982, 'Total loss': 0.531688969920982} | train loss {'Reaction outcome loss': 0.5114631189574157, 'Total loss': 0.5114631189574157}
2022-12-05 23:23:51,649 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:51,649 INFO:     Epoch: 86
2022-12-05 23:23:52,359 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5337591374462302, 'Total loss': 0.5337591374462302} | train loss {'Reaction outcome loss': 0.5046057591755544, 'Total loss': 0.5046057591755544}
2022-12-05 23:23:52,359 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:52,359 INFO:     Epoch: 87
2022-12-05 23:23:53,066 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.553838330575011, 'Total loss': 0.553838330575011} | train loss {'Reaction outcome loss': 0.508383136963652, 'Total loss': 0.508383136963652}
2022-12-05 23:23:53,067 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:53,067 INFO:     Epoch: 88
2022-12-05 23:23:53,773 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6164355416866866, 'Total loss': 0.6164355416866866} | train loss {'Reaction outcome loss': 0.5097883909700378, 'Total loss': 0.5097883909700378}
2022-12-05 23:23:53,773 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:53,773 INFO:     Epoch: 89
2022-12-05 23:23:54,485 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5278728865087032, 'Total loss': 0.5278728865087032} | train loss {'Reaction outcome loss': 0.5129813855333675, 'Total loss': 0.5129813855333675}
2022-12-05 23:23:54,486 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:54,486 INFO:     Epoch: 90
2022-12-05 23:23:55,199 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5462634302675724, 'Total loss': 0.5462634302675724} | train loss {'Reaction outcome loss': 0.5020813836806244, 'Total loss': 0.5020813836806244}
2022-12-05 23:23:55,199 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:55,199 INFO:     Epoch: 91
2022-12-05 23:23:55,911 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5320972864600745, 'Total loss': 0.5320972864600745} | train loss {'Reaction outcome loss': 0.5076796776284614, 'Total loss': 0.5076796776284614}
2022-12-05 23:23:55,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:55,911 INFO:     Epoch: 92
2022-12-05 23:23:56,623 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5166275992312215, 'Total loss': 0.5166275992312215} | train loss {'Reaction outcome loss': 0.5065646035176131, 'Total loss': 0.5065646035176131}
2022-12-05 23:23:56,623 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:56,623 INFO:     Epoch: 93
2022-12-05 23:23:57,331 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5674799335273829, 'Total loss': 0.5674799335273829} | train loss {'Reaction outcome loss': 0.5059971585869789, 'Total loss': 0.5059971585869789}
2022-12-05 23:23:57,331 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:57,331 INFO:     Epoch: 94
2022-12-05 23:23:58,042 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5202267058193684, 'Total loss': 0.5202267058193684} | train loss {'Reaction outcome loss': 0.5067873419893365, 'Total loss': 0.5067873419893365}
2022-12-05 23:23:58,042 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:58,042 INFO:     Epoch: 95
2022-12-05 23:23:58,750 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.522714685310017, 'Total loss': 0.522714685310017} | train loss {'Reaction outcome loss': 0.5057650505294723, 'Total loss': 0.5057650505294723}
2022-12-05 23:23:58,750 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:58,750 INFO:     Epoch: 96
2022-12-05 23:23:59,461 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5349054634571075, 'Total loss': 0.5349054634571075} | train loss {'Reaction outcome loss': 0.5088992904751531, 'Total loss': 0.5088992904751531}
2022-12-05 23:23:59,461 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:23:59,461 INFO:     Epoch: 97
2022-12-05 23:24:00,172 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.521115954965353, 'Total loss': 0.521115954965353} | train loss {'Reaction outcome loss': 0.511994901383596, 'Total loss': 0.511994901383596}
2022-12-05 23:24:00,172 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:00,172 INFO:     Epoch: 98
2022-12-05 23:24:00,881 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.510730445723642, 'Total loss': 0.510730445723642} | train loss {'Reaction outcome loss': 0.5085290667991484, 'Total loss': 0.5085290667991484}
2022-12-05 23:24:00,881 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:00,881 INFO:     Epoch: 99
2022-12-05 23:24:01,590 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5347896905785258, 'Total loss': 0.5347896905785258} | train loss {'Reaction outcome loss': 0.5003894515215389, 'Total loss': 0.5003894515215389}
2022-12-05 23:24:01,590 INFO:     Best model found after epoch 53 of 100.
2022-12-05 23:24:01,590 INFO:   Done with stage: TRAINING
2022-12-05 23:24:01,590 INFO:   Starting stage: EVALUATION
2022-12-05 23:24:01,708 INFO:   Done with stage: EVALUATION
2022-12-05 23:24:01,708 INFO:   Leaving out SEQ value Fold_6
2022-12-05 23:24:01,721 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:24:01,721 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:24:02,361 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:24:02,361 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:24:02,431 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:24:02,432 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:24:02,432 INFO:     No hyperparam tuning for this model
2022-12-05 23:24:02,432 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:24:02,432 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:24:02,432 INFO:     None feature selector for col prot
2022-12-05 23:24:02,433 INFO:     None feature selector for col prot
2022-12-05 23:24:02,433 INFO:     None feature selector for col prot
2022-12-05 23:24:02,433 INFO:     None feature selector for col chem
2022-12-05 23:24:02,433 INFO:     None feature selector for col chem
2022-12-05 23:24:02,433 INFO:     None feature selector for col chem
2022-12-05 23:24:02,433 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:24:02,433 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:24:02,435 INFO:     Number of params in model 215731
2022-12-05 23:24:02,438 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:24:02,438 INFO:   Starting stage: TRAINING
2022-12-05 23:24:02,496 INFO:     Val loss before train {'Reaction outcome loss': 1.0146744589913974, 'Total loss': 1.0146744589913974}
2022-12-05 23:24:02,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:02,496 INFO:     Epoch: 0
2022-12-05 23:24:03,210 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6556291099299084, 'Total loss': 0.6556291099299084} | train loss {'Reaction outcome loss': 0.8149477370113496, 'Total loss': 0.8149477370113496}
2022-12-05 23:24:03,210 INFO:     Found new best model at epoch 0
2022-12-05 23:24:03,210 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:03,211 INFO:     Epoch: 1
2022-12-05 23:24:03,919 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6327276615933939, 'Total loss': 0.6327276615933939} | train loss {'Reaction outcome loss': 0.6696100995427201, 'Total loss': 0.6696100995427201}
2022-12-05 23:24:03,919 INFO:     Found new best model at epoch 1
2022-12-05 23:24:03,920 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:03,920 INFO:     Epoch: 2
2022-12-05 23:24:04,629 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6693839410489256, 'Total loss': 0.6693839410489256} | train loss {'Reaction outcome loss': 0.6229966279526471, 'Total loss': 0.6229966279526471}
2022-12-05 23:24:04,629 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:04,629 INFO:     Epoch: 3
2022-12-05 23:24:05,339 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5684199814092029, 'Total loss': 0.5684199814092029} | train loss {'Reaction outcome loss': 0.5959546356066036, 'Total loss': 0.5959546356066036}
2022-12-05 23:24:05,339 INFO:     Found new best model at epoch 3
2022-12-05 23:24:05,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:05,340 INFO:     Epoch: 4
2022-12-05 23:24:06,045 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5781308316032995, 'Total loss': 0.5781308316032995} | train loss {'Reaction outcome loss': 0.5920735484192728, 'Total loss': 0.5920735484192728}
2022-12-05 23:24:06,045 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:06,046 INFO:     Epoch: 5
2022-12-05 23:24:06,760 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5827373113821853, 'Total loss': 0.5827373113821853} | train loss {'Reaction outcome loss': 0.5791824705566955, 'Total loss': 0.5791824705566955}
2022-12-05 23:24:06,760 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:06,761 INFO:     Epoch: 6
2022-12-05 23:24:07,474 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5290525650436227, 'Total loss': 0.5290525650436227} | train loss {'Reaction outcome loss': 0.5638279897209845, 'Total loss': 0.5638279897209845}
2022-12-05 23:24:07,475 INFO:     Found new best model at epoch 6
2022-12-05 23:24:07,476 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:07,476 INFO:     Epoch: 7
2022-12-05 23:24:08,188 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5952124893665314, 'Total loss': 0.5952124893665314} | train loss {'Reaction outcome loss': 0.5603438824535865, 'Total loss': 0.5603438824535865}
2022-12-05 23:24:08,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:08,188 INFO:     Epoch: 8
2022-12-05 23:24:08,901 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5473809425126422, 'Total loss': 0.5473809425126422} | train loss {'Reaction outcome loss': 0.5606508002529743, 'Total loss': 0.5606508002529743}
2022-12-05 23:24:08,901 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:08,902 INFO:     Epoch: 9
2022-12-05 23:24:09,618 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5574928786266934, 'Total loss': 0.5574928786266934} | train loss {'Reaction outcome loss': 0.5596480246497552, 'Total loss': 0.5596480246497552}
2022-12-05 23:24:09,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:09,618 INFO:     Epoch: 10
2022-12-05 23:24:10,332 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5557591285217892, 'Total loss': 0.5557591285217892} | train loss {'Reaction outcome loss': 0.5554177600000552, 'Total loss': 0.5554177600000552}
2022-12-05 23:24:10,332 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:10,332 INFO:     Epoch: 11
2022-12-05 23:24:11,046 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5264200378548015, 'Total loss': 0.5264200378548015} | train loss {'Reaction outcome loss': 0.549955150859076, 'Total loss': 0.549955150859076}
2022-12-05 23:24:11,046 INFO:     Found new best model at epoch 11
2022-12-05 23:24:11,046 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:11,047 INFO:     Epoch: 12
2022-12-05 23:24:11,760 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.534083566205068, 'Total loss': 0.534083566205068} | train loss {'Reaction outcome loss': 0.5447048649252185, 'Total loss': 0.5447048649252185}
2022-12-05 23:24:11,760 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:11,760 INFO:     Epoch: 13
2022-12-05 23:24:12,474 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5238485043360428, 'Total loss': 0.5238485043360428} | train loss {'Reaction outcome loss': 0.5382789129670332, 'Total loss': 0.5382789129670332}
2022-12-05 23:24:12,474 INFO:     Found new best model at epoch 13
2022-12-05 23:24:12,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:12,475 INFO:     Epoch: 14
2022-12-05 23:24:13,191 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.52212228896943, 'Total loss': 0.52212228896943} | train loss {'Reaction outcome loss': 0.5449868019534508, 'Total loss': 0.5449868019534508}
2022-12-05 23:24:13,192 INFO:     Found new best model at epoch 14
2022-12-05 23:24:13,192 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:13,192 INFO:     Epoch: 15
2022-12-05 23:24:13,910 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5286350101232529, 'Total loss': 0.5286350101232529} | train loss {'Reaction outcome loss': 0.5363324716506217, 'Total loss': 0.5363324716506217}
2022-12-05 23:24:13,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:13,911 INFO:     Epoch: 16
2022-12-05 23:24:14,624 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5355850949206136, 'Total loss': 0.5355850949206136} | train loss {'Reaction outcome loss': 0.5495277635964305, 'Total loss': 0.5495277635964305}
2022-12-05 23:24:14,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:14,624 INFO:     Epoch: 17
2022-12-05 23:24:15,338 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5072680535641584, 'Total loss': 0.5072680535641584} | train loss {'Reaction outcome loss': 0.5449179330848248, 'Total loss': 0.5449179330848248}
2022-12-05 23:24:15,338 INFO:     Found new best model at epoch 17
2022-12-05 23:24:15,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:15,339 INFO:     Epoch: 18
2022-12-05 23:24:16,055 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5171136720614, 'Total loss': 0.5171136720614} | train loss {'Reaction outcome loss': 0.5353883895796803, 'Total loss': 0.5353883895796803}
2022-12-05 23:24:16,055 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:16,055 INFO:     Epoch: 19
2022-12-05 23:24:16,771 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5130787241187963, 'Total loss': 0.5130787241187963} | train loss {'Reaction outcome loss': 0.5366583421585048, 'Total loss': 0.5366583421585048}
2022-12-05 23:24:16,772 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:16,772 INFO:     Epoch: 20
2022-12-05 23:24:17,490 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5331756374375387, 'Total loss': 0.5331756374375387} | train loss {'Reaction outcome loss': 0.5347382375585888, 'Total loss': 0.5347382375585888}
2022-12-05 23:24:17,490 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:17,490 INFO:     Epoch: 21
2022-12-05 23:24:18,206 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5105654329738833, 'Total loss': 0.5105654329738833} | train loss {'Reaction outcome loss': 0.5356413941634329, 'Total loss': 0.5356413941634329}
2022-12-05 23:24:18,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:18,206 INFO:     Epoch: 22
2022-12-05 23:24:18,924 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5182180865244432, 'Total loss': 0.5182180865244432} | train loss {'Reaction outcome loss': 0.5351258883712745, 'Total loss': 0.5351258883712745}
2022-12-05 23:24:18,924 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:18,924 INFO:     Epoch: 23
2022-12-05 23:24:19,638 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5401372753761031, 'Total loss': 0.5401372753761031} | train loss {'Reaction outcome loss': 0.5465276415048823, 'Total loss': 0.5465276415048823}
2022-12-05 23:24:19,638 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:19,638 INFO:     Epoch: 24
2022-12-05 23:24:20,354 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5415865602818403, 'Total loss': 0.5415865602818403} | train loss {'Reaction outcome loss': 0.593735179075828, 'Total loss': 0.593735179075828}
2022-12-05 23:24:20,354 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:20,354 INFO:     Epoch: 25
2022-12-05 23:24:21,067 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5404912111434069, 'Total loss': 0.5404912111434069} | train loss {'Reaction outcome loss': 0.5449295520239513, 'Total loss': 0.5449295520239513}
2022-12-05 23:24:21,068 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:21,068 INFO:     Epoch: 26
2022-12-05 23:24:21,782 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5288451696661386, 'Total loss': 0.5288451696661386} | train loss {'Reaction outcome loss': 0.535965565658035, 'Total loss': 0.535965565658035}
2022-12-05 23:24:21,783 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:21,783 INFO:     Epoch: 27
2022-12-05 23:24:22,496 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5153085474263538, 'Total loss': 0.5153085474263538} | train loss {'Reaction outcome loss': 0.5354926209097449, 'Total loss': 0.5354926209097449}
2022-12-05 23:24:22,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:22,497 INFO:     Epoch: 28
2022-12-05 23:24:23,210 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5218903056599877, 'Total loss': 0.5218903056599877} | train loss {'Reaction outcome loss': 0.5352731015880098, 'Total loss': 0.5352731015880098}
2022-12-05 23:24:23,210 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:23,210 INFO:     Epoch: 29
2022-12-05 23:24:23,924 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5321979502385313, 'Total loss': 0.5321979502385313} | train loss {'Reaction outcome loss': 0.5358857429220609, 'Total loss': 0.5358857429220609}
2022-12-05 23:24:23,924 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:23,924 INFO:     Epoch: 30
2022-12-05 23:24:24,638 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5067399929870259, 'Total loss': 0.5067399929870259} | train loss {'Reaction outcome loss': 0.5370597040604966, 'Total loss': 0.5370597040604966}
2022-12-05 23:24:24,638 INFO:     Found new best model at epoch 30
2022-12-05 23:24:24,639 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:24,639 INFO:     Epoch: 31
2022-12-05 23:24:25,352 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5302153940905224, 'Total loss': 0.5302153940905224} | train loss {'Reaction outcome loss': 0.5323686303065615, 'Total loss': 0.5323686303065615}
2022-12-05 23:24:25,353 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:25,353 INFO:     Epoch: 32
2022-12-05 23:24:26,067 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5153136463327841, 'Total loss': 0.5153136463327841} | train loss {'Reaction outcome loss': 0.5286446682777, 'Total loss': 0.5286446682777}
2022-12-05 23:24:26,068 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:26,068 INFO:     Epoch: 33
2022-12-05 23:24:26,782 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5232648625969887, 'Total loss': 0.5232648625969887} | train loss {'Reaction outcome loss': 0.5388759516390712, 'Total loss': 0.5388759516390712}
2022-12-05 23:24:26,782 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:26,782 INFO:     Epoch: 34
2022-12-05 23:24:27,497 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4897413362156261, 'Total loss': 0.4897413362156261} | train loss {'Reaction outcome loss': 0.5625166631782585, 'Total loss': 0.5625166631782585}
2022-12-05 23:24:27,497 INFO:     Found new best model at epoch 34
2022-12-05 23:24:27,498 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:27,498 INFO:     Epoch: 35
2022-12-05 23:24:28,212 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4975349564443935, 'Total loss': 0.4975349564443935} | train loss {'Reaction outcome loss': 0.5323657041136552, 'Total loss': 0.5323657041136552}
2022-12-05 23:24:28,212 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:28,212 INFO:     Epoch: 36
2022-12-05 23:24:28,928 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4967889657074755, 'Total loss': 0.4967889657074755} | train loss {'Reaction outcome loss': 0.5327391754760433, 'Total loss': 0.5327391754760433}
2022-12-05 23:24:28,928 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:28,928 INFO:     Epoch: 37
2022-12-05 23:24:29,641 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5047324296425689, 'Total loss': 0.5047324296425689} | train loss {'Reaction outcome loss': 0.5320074706968025, 'Total loss': 0.5320074706968025}
2022-12-05 23:24:29,642 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:29,642 INFO:     Epoch: 38
2022-12-05 23:24:30,358 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5023992224173113, 'Total loss': 0.5023992224173113} | train loss {'Reaction outcome loss': 0.5362384083722285, 'Total loss': 0.5362384083722285}
2022-12-05 23:24:30,359 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:30,359 INFO:     Epoch: 39
2022-12-05 23:24:31,078 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5133487528020685, 'Total loss': 0.5133487528020685} | train loss {'Reaction outcome loss': 0.5275547203988682, 'Total loss': 0.5275547203988682}
2022-12-05 23:24:31,078 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:31,078 INFO:     Epoch: 40
2022-12-05 23:24:31,794 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5469348518685861, 'Total loss': 0.5469348518685861} | train loss {'Reaction outcome loss': 0.5281514707426748, 'Total loss': 0.5281514707426748}
2022-12-05 23:24:31,794 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:31,794 INFO:     Epoch: 41
2022-12-05 23:24:32,508 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5253348536789417, 'Total loss': 0.5253348536789417} | train loss {'Reaction outcome loss': 0.5273711389978888, 'Total loss': 0.5273711389978888}
2022-12-05 23:24:32,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:32,509 INFO:     Epoch: 42
2022-12-05 23:24:33,230 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5173147940500216, 'Total loss': 0.5173147940500216} | train loss {'Reaction outcome loss': 0.5396692883751171, 'Total loss': 0.5396692883751171}
2022-12-05 23:24:33,230 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:33,231 INFO:     Epoch: 43
2022-12-05 23:24:33,944 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5173600106076761, 'Total loss': 0.5173600106076761} | train loss {'Reaction outcome loss': 0.5272871120587775, 'Total loss': 0.5272871120587775}
2022-12-05 23:24:33,945 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:33,945 INFO:     Epoch: 44
2022-12-05 23:24:34,657 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5334336032921617, 'Total loss': 0.5334336032921617} | train loss {'Reaction outcome loss': 0.5318266182745758, 'Total loss': 0.5318266182745758}
2022-12-05 23:24:34,658 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:34,658 INFO:     Epoch: 45
2022-12-05 23:24:35,370 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5184854837981138, 'Total loss': 0.5184854837981138} | train loss {'Reaction outcome loss': 0.5325332567518056, 'Total loss': 0.5325332567518056}
2022-12-05 23:24:35,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:35,370 INFO:     Epoch: 46
2022-12-05 23:24:36,083 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5049341876398433, 'Total loss': 0.5049341876398433} | train loss {'Reaction outcome loss': 0.5439574653320467, 'Total loss': 0.5439574653320467}
2022-12-05 23:24:36,083 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:36,084 INFO:     Epoch: 47
2022-12-05 23:24:36,799 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.51594787734476, 'Total loss': 0.51594787734476} | train loss {'Reaction outcome loss': 0.5355064040917134, 'Total loss': 0.5355064040917134}
2022-12-05 23:24:36,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:36,800 INFO:     Epoch: 48
2022-12-05 23:24:37,514 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5113627673550085, 'Total loss': 0.5113627673550085} | train loss {'Reaction outcome loss': 0.5383989116561557, 'Total loss': 0.5383989116561557}
2022-12-05 23:24:37,514 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:37,515 INFO:     Epoch: 49
2022-12-05 23:24:38,227 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5200830491429026, 'Total loss': 0.5200830491429026} | train loss {'Reaction outcome loss': 0.5286111003617465, 'Total loss': 0.5286111003617465}
2022-12-05 23:24:38,227 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:38,228 INFO:     Epoch: 50
2022-12-05 23:24:38,942 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5261304026300256, 'Total loss': 0.5261304026300256} | train loss {'Reaction outcome loss': 0.5404712240464291, 'Total loss': 0.5404712240464291}
2022-12-05 23:24:38,943 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:38,943 INFO:     Epoch: 51
2022-12-05 23:24:39,657 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5202639905566518, 'Total loss': 0.5202639905566518} | train loss {'Reaction outcome loss': 0.530634394119143, 'Total loss': 0.530634394119143}
2022-12-05 23:24:39,657 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:39,657 INFO:     Epoch: 52
2022-12-05 23:24:40,373 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5089293393221769, 'Total loss': 0.5089293393221769} | train loss {'Reaction outcome loss': 0.5337466085367357, 'Total loss': 0.5337466085367357}
2022-12-05 23:24:40,373 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:40,373 INFO:     Epoch: 53
2022-12-05 23:24:41,090 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5506194762208245, 'Total loss': 0.5506194762208245} | train loss {'Reaction outcome loss': 0.5299523509831473, 'Total loss': 0.5299523509831473}
2022-12-05 23:24:41,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:41,090 INFO:     Epoch: 54
2022-12-05 23:24:41,805 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5231462771242316, 'Total loss': 0.5231462771242316} | train loss {'Reaction outcome loss': 0.524711857380172, 'Total loss': 0.524711857380172}
2022-12-05 23:24:41,805 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:41,806 INFO:     Epoch: 55
2022-12-05 23:24:42,520 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5467397374185649, 'Total loss': 0.5467397374185649} | train loss {'Reaction outcome loss': 0.5348769232087772, 'Total loss': 0.5348769232087772}
2022-12-05 23:24:42,521 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:42,521 INFO:     Epoch: 56
2022-12-05 23:24:43,236 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5062457837841727, 'Total loss': 0.5062457837841727} | train loss {'Reaction outcome loss': 0.5247907783338416, 'Total loss': 0.5247907783338416}
2022-12-05 23:24:43,236 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:43,236 INFO:     Epoch: 57
2022-12-05 23:24:43,953 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5086473497477445, 'Total loss': 0.5086473497477445} | train loss {'Reaction outcome loss': 0.5281029207149317, 'Total loss': 0.5281029207149317}
2022-12-05 23:24:43,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:43,953 INFO:     Epoch: 58
2022-12-05 23:24:44,662 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5541702173650265, 'Total loss': 0.5541702173650265} | train loss {'Reaction outcome loss': 0.521632829386937, 'Total loss': 0.521632829386937}
2022-12-05 23:24:44,662 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:44,662 INFO:     Epoch: 59
2022-12-05 23:24:45,370 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5106008831750263, 'Total loss': 0.5106008831750263} | train loss {'Reaction outcome loss': 0.522755808977463, 'Total loss': 0.522755808977463}
2022-12-05 23:24:45,371 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:45,371 INFO:     Epoch: 60
2022-12-05 23:24:46,080 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5160083330490373, 'Total loss': 0.5160083330490373} | train loss {'Reaction outcome loss': 0.5279888131538866, 'Total loss': 0.5279888131538866}
2022-12-05 23:24:46,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:46,080 INFO:     Epoch: 61
2022-12-05 23:24:46,788 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5194595198739659, 'Total loss': 0.5194595198739659} | train loss {'Reaction outcome loss': 0.5291817194899084, 'Total loss': 0.5291817194899084}
2022-12-05 23:24:46,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:46,788 INFO:     Epoch: 62
2022-12-05 23:24:47,499 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5233812311833556, 'Total loss': 0.5233812311833556} | train loss {'Reaction outcome loss': 0.53581882434094, 'Total loss': 0.53581882434094}
2022-12-05 23:24:47,499 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:47,499 INFO:     Epoch: 63
2022-12-05 23:24:48,214 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5228303772482005, 'Total loss': 0.5228303772482005} | train loss {'Reaction outcome loss': 0.5331414576001495, 'Total loss': 0.5331414576001495}
2022-12-05 23:24:48,214 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:48,214 INFO:     Epoch: 64
2022-12-05 23:24:48,928 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4996267320080237, 'Total loss': 0.4996267320080237} | train loss {'Reaction outcome loss': 0.5296948807019937, 'Total loss': 0.5296948807019937}
2022-12-05 23:24:48,928 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:48,928 INFO:     Epoch: 65
2022-12-05 23:24:49,641 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.516895224086263, 'Total loss': 0.516895224086263} | train loss {'Reaction outcome loss': 0.5320850884492853, 'Total loss': 0.5320850884492853}
2022-12-05 23:24:49,641 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:49,641 INFO:     Epoch: 66
2022-12-05 23:24:50,354 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5286197631873868, 'Total loss': 0.5286197631873868} | train loss {'Reaction outcome loss': 0.5301892272977211, 'Total loss': 0.5301892272977211}
2022-12-05 23:24:50,354 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:50,354 INFO:     Epoch: 67
2022-12-05 23:24:51,067 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5002576844258741, 'Total loss': 0.5002576844258741} | train loss {'Reaction outcome loss': 0.5365029283260044, 'Total loss': 0.5365029283260044}
2022-12-05 23:24:51,067 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:51,068 INFO:     Epoch: 68
2022-12-05 23:24:51,783 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.52678194032474, 'Total loss': 0.52678194032474} | train loss {'Reaction outcome loss': 0.543681665108754, 'Total loss': 0.543681665108754}
2022-12-05 23:24:51,783 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:51,783 INFO:     Epoch: 69
2022-12-05 23:24:52,499 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.529848807237365, 'Total loss': 0.529848807237365} | train loss {'Reaction outcome loss': 0.5390906315221478, 'Total loss': 0.5390906315221478}
2022-12-05 23:24:52,499 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:52,499 INFO:     Epoch: 70
2022-12-05 23:24:53,217 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5288343483751471, 'Total loss': 0.5288343483751471} | train loss {'Reaction outcome loss': 0.5358712164127091, 'Total loss': 0.5358712164127091}
2022-12-05 23:24:53,217 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:53,217 INFO:     Epoch: 71
2022-12-05 23:24:53,933 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5430204377255656, 'Total loss': 0.5430204377255656} | train loss {'Reaction outcome loss': 0.5319162132576681, 'Total loss': 0.5319162132576681}
2022-12-05 23:24:53,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:53,933 INFO:     Epoch: 72
2022-12-05 23:24:54,646 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5488916320556944, 'Total loss': 0.5488916320556944} | train loss {'Reaction outcome loss': 0.5276291539311891, 'Total loss': 0.5276291539311891}
2022-12-05 23:24:54,646 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:54,646 INFO:     Epoch: 73
2022-12-05 23:24:55,361 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5597669184207916, 'Total loss': 0.5597669184207916} | train loss {'Reaction outcome loss': 0.548124068058454, 'Total loss': 0.548124068058454}
2022-12-05 23:24:55,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:55,361 INFO:     Epoch: 74
2022-12-05 23:24:56,079 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.512529518455267, 'Total loss': 0.512529518455267} | train loss {'Reaction outcome loss': 0.5485581933004171, 'Total loss': 0.5485581933004171}
2022-12-05 23:24:56,079 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:56,079 INFO:     Epoch: 75
2022-12-05 23:24:56,791 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5529652546075258, 'Total loss': 0.5529652546075258} | train loss {'Reaction outcome loss': 0.5367058260358779, 'Total loss': 0.5367058260358779}
2022-12-05 23:24:56,791 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:56,791 INFO:     Epoch: 76
2022-12-05 23:24:57,506 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.577532833950086, 'Total loss': 0.577532833950086} | train loss {'Reaction outcome loss': 0.5364935414993811, 'Total loss': 0.5364935414993811}
2022-12-05 23:24:57,507 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:57,507 INFO:     Epoch: 77
2022-12-05 23:24:58,223 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5956013636155562, 'Total loss': 0.5956013636155562} | train loss {'Reaction outcome loss': 0.5321294471078556, 'Total loss': 0.5321294471078556}
2022-12-05 23:24:58,223 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:58,223 INFO:     Epoch: 78
2022-12-05 23:24:58,938 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5404013178565286, 'Total loss': 0.5404013178565286} | train loss {'Reaction outcome loss': 0.526855245835868, 'Total loss': 0.526855245835868}
2022-12-05 23:24:58,938 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:58,938 INFO:     Epoch: 79
2022-12-05 23:24:59,657 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.543616442179138, 'Total loss': 0.543616442179138} | train loss {'Reaction outcome loss': 0.5227303495253568, 'Total loss': 0.5227303495253568}
2022-12-05 23:24:59,657 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:24:59,657 INFO:     Epoch: 80
2022-12-05 23:25:00,371 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5045858289707791, 'Total loss': 0.5045858289707791} | train loss {'Reaction outcome loss': 0.5332213378386942, 'Total loss': 0.5332213378386942}
2022-12-05 23:25:00,371 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:00,371 INFO:     Epoch: 81
2022-12-05 23:25:01,085 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5040518285875971, 'Total loss': 0.5040518285875971} | train loss {'Reaction outcome loss': 0.5325073281431246, 'Total loss': 0.5325073281431246}
2022-12-05 23:25:01,086 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:01,086 INFO:     Epoch: 82
2022-12-05 23:25:01,798 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4941905266181989, 'Total loss': 0.4941905266181989} | train loss {'Reaction outcome loss': 0.5260470631392861, 'Total loss': 0.5260470631392861}
2022-12-05 23:25:01,798 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:01,798 INFO:     Epoch: 83
2022-12-05 23:25:02,516 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5064043155448004, 'Total loss': 0.5064043155448004} | train loss {'Reaction outcome loss': 0.530760443162339, 'Total loss': 0.530760443162339}
2022-12-05 23:25:02,516 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:02,516 INFO:     Epoch: 84
2022-12-05 23:25:03,227 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5485997260971502, 'Total loss': 0.5485997260971502} | train loss {'Reaction outcome loss': 0.5291237752085273, 'Total loss': 0.5291237752085273}
2022-12-05 23:25:03,228 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:03,228 INFO:     Epoch: 85
2022-12-05 23:25:03,939 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.513664922253652, 'Total loss': 0.513664922253652} | train loss {'Reaction outcome loss': 0.5331268457748629, 'Total loss': 0.5331268457748629}
2022-12-05 23:25:03,939 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:03,939 INFO:     Epoch: 86
2022-12-05 23:25:04,653 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.51626630008898, 'Total loss': 0.51626630008898} | train loss {'Reaction outcome loss': 0.5364014859262266, 'Total loss': 0.5364014859262266}
2022-12-05 23:25:04,653 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:04,653 INFO:     Epoch: 87
2022-12-05 23:25:05,368 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5082185945727609, 'Total loss': 0.5082185945727609} | train loss {'Reaction outcome loss': 0.5275876875589733, 'Total loss': 0.5275876875589733}
2022-12-05 23:25:05,368 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:05,368 INFO:     Epoch: 88
2022-12-05 23:25:06,081 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5602605515582995, 'Total loss': 0.5602605515582995} | train loss {'Reaction outcome loss': 0.5303782484369722, 'Total loss': 0.5303782484369722}
2022-12-05 23:25:06,081 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:06,081 INFO:     Epoch: 89
2022-12-05 23:25:06,797 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5280908498574387, 'Total loss': 0.5280908498574387} | train loss {'Reaction outcome loss': 0.5305414694749754, 'Total loss': 0.5305414694749754}
2022-12-05 23:25:06,797 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:06,797 INFO:     Epoch: 90
2022-12-05 23:25:07,511 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5461706217717041, 'Total loss': 0.5461706217717041} | train loss {'Reaction outcome loss': 0.5307052044974647, 'Total loss': 0.5307052044974647}
2022-12-05 23:25:07,512 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:07,512 INFO:     Epoch: 91
2022-12-05 23:25:08,224 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5210233039476655, 'Total loss': 0.5210233039476655} | train loss {'Reaction outcome loss': 0.5339015597997889, 'Total loss': 0.5339015597997889}
2022-12-05 23:25:08,224 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:08,224 INFO:     Epoch: 92
2022-12-05 23:25:08,935 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5169406661933119, 'Total loss': 0.5169406661933119} | train loss {'Reaction outcome loss': 0.5261384765146232, 'Total loss': 0.5261384765146232}
2022-12-05 23:25:08,935 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:08,935 INFO:     Epoch: 93
2022-12-05 23:25:09,646 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5539820668372241, 'Total loss': 0.5539820668372241} | train loss {'Reaction outcome loss': 0.5267457816644237, 'Total loss': 0.5267457816644237}
2022-12-05 23:25:09,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:09,647 INFO:     Epoch: 94
2022-12-05 23:25:10,360 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5149281363595616, 'Total loss': 0.5149281363595616} | train loss {'Reaction outcome loss': 0.5317987448532089, 'Total loss': 0.5317987448532089}
2022-12-05 23:25:10,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:10,360 INFO:     Epoch: 95
2022-12-05 23:25:11,075 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5389530198140577, 'Total loss': 0.5389530198140577} | train loss {'Reaction outcome loss': 0.5369992761114831, 'Total loss': 0.5369992761114831}
2022-12-05 23:25:11,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:11,075 INFO:     Epoch: 96
2022-12-05 23:25:11,787 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5308217589150775, 'Total loss': 0.5308217589150775} | train loss {'Reaction outcome loss': 0.5243112721338091, 'Total loss': 0.5243112721338091}
2022-12-05 23:25:11,787 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:11,787 INFO:     Epoch: 97
2022-12-05 23:25:12,500 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5337221690199592, 'Total loss': 0.5337221690199592} | train loss {'Reaction outcome loss': 0.5283003498306159, 'Total loss': 0.5283003498306159}
2022-12-05 23:25:12,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:12,500 INFO:     Epoch: 98
2022-12-05 23:25:13,216 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5483348650688474, 'Total loss': 0.5483348650688474} | train loss {'Reaction outcome loss': 0.52788661347951, 'Total loss': 0.52788661347951}
2022-12-05 23:25:13,217 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:13,217 INFO:     Epoch: 99
2022-12-05 23:25:13,932 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5136733566495505, 'Total loss': 0.5136733566495505} | train loss {'Reaction outcome loss': 0.5251927439345854, 'Total loss': 0.5251927439345854}
2022-12-05 23:25:13,932 INFO:     Best model found after epoch 35 of 100.
2022-12-05 23:25:13,932 INFO:   Done with stage: TRAINING
2022-12-05 23:25:13,932 INFO:   Starting stage: EVALUATION
2022-12-05 23:25:14,056 INFO:   Done with stage: EVALUATION
2022-12-05 23:25:14,057 INFO:   Leaving out SEQ value Fold_7
2022-12-05 23:25:14,070 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:25:14,070 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:25:14,718 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:25:14,718 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:25:14,789 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:25:14,789 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:25:14,789 INFO:     No hyperparam tuning for this model
2022-12-05 23:25:14,789 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:25:14,789 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:25:14,790 INFO:     None feature selector for col prot
2022-12-05 23:25:14,790 INFO:     None feature selector for col prot
2022-12-05 23:25:14,790 INFO:     None feature selector for col prot
2022-12-05 23:25:14,791 INFO:     None feature selector for col chem
2022-12-05 23:25:14,791 INFO:     None feature selector for col chem
2022-12-05 23:25:14,791 INFO:     None feature selector for col chem
2022-12-05 23:25:14,791 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:25:14,791 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:25:14,793 INFO:     Number of params in model 215731
2022-12-05 23:25:14,796 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:25:14,796 INFO:   Starting stage: TRAINING
2022-12-05 23:25:14,855 INFO:     Val loss before train {'Reaction outcome loss': 1.0357903187925166, 'Total loss': 1.0357903187925166}
2022-12-05 23:25:14,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:14,855 INFO:     Epoch: 0
2022-12-05 23:25:15,566 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8882516195828264, 'Total loss': 0.8882516195828264} | train loss {'Reaction outcome loss': 0.7806826449538532, 'Total loss': 0.7806826449538532}
2022-12-05 23:25:15,566 INFO:     Found new best model at epoch 0
2022-12-05 23:25:15,566 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:15,567 INFO:     Epoch: 1
2022-12-05 23:25:16,280 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.708788934756409, 'Total loss': 0.708788934756409} | train loss {'Reaction outcome loss': 0.6699386610223456, 'Total loss': 0.6699386610223456}
2022-12-05 23:25:16,281 INFO:     Found new best model at epoch 1
2022-12-05 23:25:16,282 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:16,282 INFO:     Epoch: 2
2022-12-05 23:25:16,996 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6943233588879759, 'Total loss': 0.6943233588879759} | train loss {'Reaction outcome loss': 0.6208279602350253, 'Total loss': 0.6208279602350253}
2022-12-05 23:25:16,996 INFO:     Found new best model at epoch 2
2022-12-05 23:25:16,997 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:16,997 INFO:     Epoch: 3
2022-12-05 23:25:17,707 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6374897018752315, 'Total loss': 0.6374897018752315} | train loss {'Reaction outcome loss': 0.5988581337426838, 'Total loss': 0.5988581337426838}
2022-12-05 23:25:17,707 INFO:     Found new best model at epoch 3
2022-12-05 23:25:17,708 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:17,708 INFO:     Epoch: 4
2022-12-05 23:25:18,422 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6274239718914032, 'Total loss': 0.6274239718914032} | train loss {'Reaction outcome loss': 0.5912268585280368, 'Total loss': 0.5912268585280368}
2022-12-05 23:25:18,423 INFO:     Found new best model at epoch 4
2022-12-05 23:25:18,423 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:18,423 INFO:     Epoch: 5
2022-12-05 23:25:19,134 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6109454462474043, 'Total loss': 0.6109454462474043} | train loss {'Reaction outcome loss': 0.584929049618331, 'Total loss': 0.584929049618331}
2022-12-05 23:25:19,134 INFO:     Found new best model at epoch 5
2022-12-05 23:25:19,135 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:19,135 INFO:     Epoch: 6
2022-12-05 23:25:19,848 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5933153256773949, 'Total loss': 0.5933153256773949} | train loss {'Reaction outcome loss': 0.5584066321372021, 'Total loss': 0.5584066321372021}
2022-12-05 23:25:19,848 INFO:     Found new best model at epoch 6
2022-12-05 23:25:19,849 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:19,849 INFO:     Epoch: 7
2022-12-05 23:25:20,560 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6104680096561258, 'Total loss': 0.6104680096561258} | train loss {'Reaction outcome loss': 0.5582944612633362, 'Total loss': 0.5582944612633362}
2022-12-05 23:25:20,560 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:20,560 INFO:     Epoch: 8
2022-12-05 23:25:21,273 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.629212002185258, 'Total loss': 0.629212002185258} | train loss {'Reaction outcome loss': 0.5556856882475648, 'Total loss': 0.5556856882475648}
2022-12-05 23:25:21,273 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:21,273 INFO:     Epoch: 9
2022-12-05 23:25:21,985 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.6040023497559808, 'Total loss': 0.6040023497559808} | train loss {'Reaction outcome loss': 0.5552413161346305, 'Total loss': 0.5552413161346305}
2022-12-05 23:25:21,985 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:21,985 INFO:     Epoch: 10
2022-12-05 23:25:22,697 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6124435690316287, 'Total loss': 0.6124435690316287} | train loss {'Reaction outcome loss': 0.5617011748103478, 'Total loss': 0.5617011748103478}
2022-12-05 23:25:22,697 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:22,697 INFO:     Epoch: 11
2022-12-05 23:25:23,408 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5736120007932186, 'Total loss': 0.5736120007932186} | train loss {'Reaction outcome loss': 0.5405129989390431, 'Total loss': 0.5405129989390431}
2022-12-05 23:25:23,408 INFO:     Found new best model at epoch 11
2022-12-05 23:25:23,409 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:23,409 INFO:     Epoch: 12
2022-12-05 23:25:24,118 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.6359083943746306, 'Total loss': 0.6359083943746306} | train loss {'Reaction outcome loss': 0.5487511772134526, 'Total loss': 0.5487511772134526}
2022-12-05 23:25:24,118 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:24,119 INFO:     Epoch: 13
2022-12-05 23:25:24,829 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.605733179233291, 'Total loss': 0.605733179233291} | train loss {'Reaction outcome loss': 0.5545547390696008, 'Total loss': 0.5545547390696008}
2022-12-05 23:25:24,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:24,829 INFO:     Epoch: 14
2022-12-05 23:25:25,543 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5950126062062654, 'Total loss': 0.5950126062062654} | train loss {'Reaction outcome loss': 0.5510523976222707, 'Total loss': 0.5510523976222707}
2022-12-05 23:25:25,544 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:25,544 INFO:     Epoch: 15
2022-12-05 23:25:26,255 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5815362334251404, 'Total loss': 0.5815362334251404} | train loss {'Reaction outcome loss': 0.5421971671946859, 'Total loss': 0.5421971671946859}
2022-12-05 23:25:26,255 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:26,255 INFO:     Epoch: 16
2022-12-05 23:25:26,966 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5753968473185193, 'Total loss': 0.5753968473185193} | train loss {'Reaction outcome loss': 0.5393884858787663, 'Total loss': 0.5393884858787663}
2022-12-05 23:25:26,967 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:26,967 INFO:     Epoch: 17
2022-12-05 23:25:27,677 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.6048131381923502, 'Total loss': 0.6048131381923502} | train loss {'Reaction outcome loss': 0.539514212231887, 'Total loss': 0.539514212231887}
2022-12-05 23:25:27,678 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:27,678 INFO:     Epoch: 18
2022-12-05 23:25:28,392 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5848552720113234, 'Total loss': 0.5848552720113234} | train loss {'Reaction outcome loss': 0.539924824255922, 'Total loss': 0.539924824255922}
2022-12-05 23:25:28,392 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:28,393 INFO:     Epoch: 19
2022-12-05 23:25:29,106 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5945291949266737, 'Total loss': 0.5945291949266737} | train loss {'Reaction outcome loss': 0.5298897572736508, 'Total loss': 0.5298897572736508}
2022-12-05 23:25:29,106 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:29,106 INFO:     Epoch: 20
2022-12-05 23:25:29,823 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5854453146457672, 'Total loss': 0.5854453146457672} | train loss {'Reaction outcome loss': 0.5397104184757843, 'Total loss': 0.5397104184757843}
2022-12-05 23:25:29,823 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:29,823 INFO:     Epoch: 21
2022-12-05 23:25:30,537 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.6526749926534566, 'Total loss': 0.6526749926534566} | train loss {'Reaction outcome loss': 0.5312338790550888, 'Total loss': 0.5312338790550888}
2022-12-05 23:25:30,537 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:30,537 INFO:     Epoch: 22
2022-12-05 23:25:31,250 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5439231846142899, 'Total loss': 0.5439231846142899} | train loss {'Reaction outcome loss': 0.5392331774176856, 'Total loss': 0.5392331774176856}
2022-12-05 23:25:31,250 INFO:     Found new best model at epoch 22
2022-12-05 23:25:31,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:31,251 INFO:     Epoch: 23
2022-12-05 23:25:31,966 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.6188777529380538, 'Total loss': 0.6188777529380538} | train loss {'Reaction outcome loss': 0.5290728588456567, 'Total loss': 0.5290728588456567}
2022-12-05 23:25:31,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:31,966 INFO:     Epoch: 24
2022-12-05 23:25:32,677 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.6013431366194378, 'Total loss': 0.6013431366194378} | train loss {'Reaction outcome loss': 0.521872156484407, 'Total loss': 0.521872156484407}
2022-12-05 23:25:32,677 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:32,677 INFO:     Epoch: 25
2022-12-05 23:25:33,387 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5624599578705701, 'Total loss': 0.5624599578705701} | train loss {'Reaction outcome loss': 0.5294131292444975, 'Total loss': 0.5294131292444975}
2022-12-05 23:25:33,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:33,388 INFO:     Epoch: 26
2022-12-05 23:25:34,097 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5688588896935637, 'Total loss': 0.5688588896935637} | train loss {'Reaction outcome loss': 0.5293629562806504, 'Total loss': 0.5293629562806504}
2022-12-05 23:25:34,097 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:34,098 INFO:     Epoch: 27
2022-12-05 23:25:34,809 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5673707418821075, 'Total loss': 0.5673707418821075} | train loss {'Reaction outcome loss': 0.5215616387575261, 'Total loss': 0.5215616387575261}
2022-12-05 23:25:34,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:34,809 INFO:     Epoch: 28
2022-12-05 23:25:35,521 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.588567966087298, 'Total loss': 0.588567966087298} | train loss {'Reaction outcome loss': 0.5183728376350664, 'Total loss': 0.5183728376350664}
2022-12-05 23:25:35,521 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:35,521 INFO:     Epoch: 29
2022-12-05 23:25:36,234 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5779358470304445, 'Total loss': 0.5779358470304445} | train loss {'Reaction outcome loss': 0.5232419347171842, 'Total loss': 0.5232419347171842}
2022-12-05 23:25:36,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:36,235 INFO:     Epoch: 30
2022-12-05 23:25:36,949 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.542780065401034, 'Total loss': 0.542780065401034} | train loss {'Reaction outcome loss': 0.5192812529773365, 'Total loss': 0.5192812529773365}
2022-12-05 23:25:36,949 INFO:     Found new best model at epoch 30
2022-12-05 23:25:36,950 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:36,950 INFO:     Epoch: 31
2022-12-05 23:25:37,664 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.620524215427312, 'Total loss': 0.620524215427312} | train loss {'Reaction outcome loss': 0.5208015868417647, 'Total loss': 0.5208015868417647}
2022-12-05 23:25:37,664 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:37,664 INFO:     Epoch: 32
2022-12-05 23:25:38,377 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.580883106047457, 'Total loss': 0.580883106047457} | train loss {'Reaction outcome loss': 0.5204653801464358, 'Total loss': 0.5204653801464358}
2022-12-05 23:25:38,377 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:38,377 INFO:     Epoch: 33
2022-12-05 23:25:39,091 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.6203767948529937, 'Total loss': 0.6203767948529937} | train loss {'Reaction outcome loss': 0.5319091668013136, 'Total loss': 0.5319091668013136}
2022-12-05 23:25:39,091 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:39,091 INFO:     Epoch: 34
2022-12-05 23:25:39,804 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5503937537697229, 'Total loss': 0.5503937537697229} | train loss {'Reaction outcome loss': 0.516699633802389, 'Total loss': 0.516699633802389}
2022-12-05 23:25:39,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:39,804 INFO:     Epoch: 35
2022-12-05 23:25:40,521 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5711704018441114, 'Total loss': 0.5711704018441114} | train loss {'Reaction outcome loss': 0.5084833019537481, 'Total loss': 0.5084833019537481}
2022-12-05 23:25:40,523 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:40,523 INFO:     Epoch: 36
2022-12-05 23:25:41,238 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5623267313296144, 'Total loss': 0.5623267313296144} | train loss {'Reaction outcome loss': 0.5145685804380021, 'Total loss': 0.5145685804380021}
2022-12-05 23:25:41,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:41,238 INFO:     Epoch: 37
2022-12-05 23:25:41,951 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5277678709138524, 'Total loss': 0.5277678709138524} | train loss {'Reaction outcome loss': 0.5104310957697005, 'Total loss': 0.5104310957697005}
2022-12-05 23:25:41,951 INFO:     Found new best model at epoch 37
2022-12-05 23:25:41,952 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:41,952 INFO:     Epoch: 38
2022-12-05 23:25:42,666 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5738980492407625, 'Total loss': 0.5738980492407625} | train loss {'Reaction outcome loss': 0.5122288158427366, 'Total loss': 0.5122288158427366}
2022-12-05 23:25:42,666 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:42,666 INFO:     Epoch: 39
2022-12-05 23:25:43,384 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5640806088393385, 'Total loss': 0.5640806088393385} | train loss {'Reaction outcome loss': 0.5160576324110572, 'Total loss': 0.5160576324110572}
2022-12-05 23:25:43,384 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:43,384 INFO:     Epoch: 40
2022-12-05 23:25:44,095 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5557012774727561, 'Total loss': 0.5557012774727561} | train loss {'Reaction outcome loss': 0.5186763312893841, 'Total loss': 0.5186763312893841}
2022-12-05 23:25:44,095 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:44,095 INFO:     Epoch: 41
2022-12-05 23:25:44,807 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5672034871849146, 'Total loss': 0.5672034871849146} | train loss {'Reaction outcome loss': 0.519140742568352, 'Total loss': 0.519140742568352}
2022-12-05 23:25:44,807 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:44,807 INFO:     Epoch: 42
2022-12-05 23:25:45,524 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.6019771525805647, 'Total loss': 0.6019771525805647} | train loss {'Reaction outcome loss': 0.5111817253625345, 'Total loss': 0.5111817253625345}
2022-12-05 23:25:45,524 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:45,524 INFO:     Epoch: 43
2022-12-05 23:25:46,238 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5443418764255263, 'Total loss': 0.5443418764255263} | train loss {'Reaction outcome loss': 0.5017108848461738, 'Total loss': 0.5017108848461738}
2022-12-05 23:25:46,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:46,238 INFO:     Epoch: 44
2022-12-05 23:25:46,952 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5639516883953051, 'Total loss': 0.5639516883953051} | train loss {'Reaction outcome loss': 0.5074354789638327, 'Total loss': 0.5074354789638327}
2022-12-05 23:25:46,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:46,953 INFO:     Epoch: 45
2022-12-05 23:25:47,665 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5801630026914857, 'Total loss': 0.5801630026914857} | train loss {'Reaction outcome loss': 0.5093000191245002, 'Total loss': 0.5093000191245002}
2022-12-05 23:25:47,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:47,665 INFO:     Epoch: 46
2022-12-05 23:25:48,377 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5907975360751152, 'Total loss': 0.5907975360751152} | train loss {'Reaction outcome loss': 0.5074273831689888, 'Total loss': 0.5074273831689888}
2022-12-05 23:25:48,377 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:48,377 INFO:     Epoch: 47
2022-12-05 23:25:49,090 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5279225507243113, 'Total loss': 0.5279225507243113} | train loss {'Reaction outcome loss': 0.5111919016490581, 'Total loss': 0.5111919016490581}
2022-12-05 23:25:49,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:49,090 INFO:     Epoch: 48
2022-12-05 23:25:49,804 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5330249843272296, 'Total loss': 0.5330249843272296} | train loss {'Reaction outcome loss': 0.5113873867250165, 'Total loss': 0.5113873867250165}
2022-12-05 23:25:49,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:49,804 INFO:     Epoch: 49
2022-12-05 23:25:50,521 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5543344820087607, 'Total loss': 0.5543344820087607} | train loss {'Reaction outcome loss': 0.5024295111416806, 'Total loss': 0.5024295111416806}
2022-12-05 23:25:50,521 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:50,521 INFO:     Epoch: 50
2022-12-05 23:25:51,239 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.563424613326788, 'Total loss': 0.563424613326788} | train loss {'Reaction outcome loss': 0.5039301128220944, 'Total loss': 0.5039301128220944}
2022-12-05 23:25:51,239 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:51,239 INFO:     Epoch: 51
2022-12-05 23:25:51,953 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.584624132649465, 'Total loss': 0.584624132649465} | train loss {'Reaction outcome loss': 0.5039714184487879, 'Total loss': 0.5039714184487879}
2022-12-05 23:25:51,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:51,953 INFO:     Epoch: 52
2022-12-05 23:25:52,667 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.6568409665064379, 'Total loss': 0.6568409665064379} | train loss {'Reaction outcome loss': 0.4959285872034457, 'Total loss': 0.4959285872034457}
2022-12-05 23:25:52,667 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:52,668 INFO:     Epoch: 53
2022-12-05 23:25:53,380 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5206786035136743, 'Total loss': 0.5206786035136743} | train loss {'Reaction outcome loss': 0.5053020840725646, 'Total loss': 0.5053020840725646}
2022-12-05 23:25:53,380 INFO:     Found new best model at epoch 53
2022-12-05 23:25:53,380 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:53,381 INFO:     Epoch: 54
2022-12-05 23:25:54,092 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5830165201967413, 'Total loss': 0.5830165201967413} | train loss {'Reaction outcome loss': 0.5020470540774497, 'Total loss': 0.5020470540774497}
2022-12-05 23:25:54,092 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:54,092 INFO:     Epoch: 55
2022-12-05 23:25:54,804 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5441428328102286, 'Total loss': 0.5441428328102286} | train loss {'Reaction outcome loss': 0.5103346665016553, 'Total loss': 0.5103346665016553}
2022-12-05 23:25:54,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:54,804 INFO:     Epoch: 56
2022-12-05 23:25:55,515 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5264238545840437, 'Total loss': 0.5264238545840437} | train loss {'Reaction outcome loss': 0.49413004555260603, 'Total loss': 0.49413004555260603}
2022-12-05 23:25:55,515 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:55,515 INFO:     Epoch: 57
2022-12-05 23:25:56,225 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5601532066410239, 'Total loss': 0.5601532066410239} | train loss {'Reaction outcome loss': 0.49949717690587525, 'Total loss': 0.49949717690587525}
2022-12-05 23:25:56,225 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:56,225 INFO:     Epoch: 58
2022-12-05 23:25:56,936 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5562980229204352, 'Total loss': 0.5562980229204352} | train loss {'Reaction outcome loss': 0.49868755730298847, 'Total loss': 0.49868755730298847}
2022-12-05 23:25:56,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:56,937 INFO:     Epoch: 59
2022-12-05 23:25:57,647 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5818545357747511, 'Total loss': 0.5818545357747511} | train loss {'Reaction outcome loss': 0.5128565894568015, 'Total loss': 0.5128565894568015}
2022-12-05 23:25:57,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:57,647 INFO:     Epoch: 60
2022-12-05 23:25:58,360 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5383594063195315, 'Total loss': 0.5383594063195315} | train loss {'Reaction outcome loss': 0.4960122657449622, 'Total loss': 0.4960122657449622}
2022-12-05 23:25:58,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:58,360 INFO:     Epoch: 61
2022-12-05 23:25:59,074 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5624527125196024, 'Total loss': 0.5624527125196024} | train loss {'Reaction outcome loss': 0.5091423904485548, 'Total loss': 0.5091423904485548}
2022-12-05 23:25:59,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:59,075 INFO:     Epoch: 62
2022-12-05 23:25:59,792 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5965432545000856, 'Total loss': 0.5965432545000856} | train loss {'Reaction outcome loss': 0.5030093300354248, 'Total loss': 0.5030093300354248}
2022-12-05 23:25:59,792 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:25:59,793 INFO:     Epoch: 63
2022-12-05 23:26:00,506 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5440187115560878, 'Total loss': 0.5440187115560878} | train loss {'Reaction outcome loss': 0.49734350013346806, 'Total loss': 0.49734350013346806}
2022-12-05 23:26:00,506 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:00,506 INFO:     Epoch: 64
2022-12-05 23:26:01,219 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5179872265593573, 'Total loss': 0.5179872265593573} | train loss {'Reaction outcome loss': 0.5111148278342055, 'Total loss': 0.5111148278342055}
2022-12-05 23:26:01,220 INFO:     Found new best model at epoch 64
2022-12-05 23:26:01,220 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:01,220 INFO:     Epoch: 65
2022-12-05 23:26:01,936 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5665796402503144, 'Total loss': 0.5665796402503144} | train loss {'Reaction outcome loss': 0.4944687338775921, 'Total loss': 0.4944687338775921}
2022-12-05 23:26:01,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:01,936 INFO:     Epoch: 66
2022-12-05 23:26:02,654 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.532634558325464, 'Total loss': 0.532634558325464} | train loss {'Reaction outcome loss': 0.5059174026554896, 'Total loss': 0.5059174026554896}
2022-12-05 23:26:02,654 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:02,654 INFO:     Epoch: 67
2022-12-05 23:26:03,370 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5308443362062628, 'Total loss': 0.5308443362062628} | train loss {'Reaction outcome loss': 0.5055919990607118, 'Total loss': 0.5055919990607118}
2022-12-05 23:26:03,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:03,370 INFO:     Epoch: 68
2022-12-05 23:26:04,084 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5596387311816216, 'Total loss': 0.5596387311816216} | train loss {'Reaction outcome loss': 0.4907573714912662, 'Total loss': 0.4907573714912662}
2022-12-05 23:26:04,084 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:04,084 INFO:     Epoch: 69
2022-12-05 23:26:04,796 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5729070905257355, 'Total loss': 0.5729070905257355} | train loss {'Reaction outcome loss': 0.501000123860141, 'Total loss': 0.501000123860141}
2022-12-05 23:26:04,796 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:04,797 INFO:     Epoch: 70
2022-12-05 23:26:05,509 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5923789820887826, 'Total loss': 0.5923789820887826} | train loss {'Reaction outcome loss': 0.5021108052267237, 'Total loss': 0.5021108052267237}
2022-12-05 23:26:05,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:05,509 INFO:     Epoch: 71
2022-12-05 23:26:06,221 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5416234548796307, 'Total loss': 0.5416234548796307} | train loss {'Reaction outcome loss': 0.5021147407599119, 'Total loss': 0.5021147407599119}
2022-12-05 23:26:06,221 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:06,221 INFO:     Epoch: 72
2022-12-05 23:26:06,937 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5312852663072672, 'Total loss': 0.5312852663072672} | train loss {'Reaction outcome loss': 0.5049510049192529, 'Total loss': 0.5049510049192529}
2022-12-05 23:26:06,937 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:06,937 INFO:     Epoch: 73
2022-12-05 23:26:07,655 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.6211922629313036, 'Total loss': 0.6211922629313036} | train loss {'Reaction outcome loss': 0.49532579573301166, 'Total loss': 0.49532579573301166}
2022-12-05 23:26:07,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:07,656 INFO:     Epoch: 74
2022-12-05 23:26:08,369 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5426985736597668, 'Total loss': 0.5426985736597668} | train loss {'Reaction outcome loss': 0.5088465906630614, 'Total loss': 0.5088465906630614}
2022-12-05 23:26:08,369 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:08,369 INFO:     Epoch: 75
2022-12-05 23:26:09,084 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5255474468523805, 'Total loss': 0.5255474468523805} | train loss {'Reaction outcome loss': 0.4957657383251954, 'Total loss': 0.4957657383251954}
2022-12-05 23:26:09,084 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:09,085 INFO:     Epoch: 76
2022-12-05 23:26:09,799 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5419920906424522, 'Total loss': 0.5419920906424522} | train loss {'Reaction outcome loss': 0.4986357534764267, 'Total loss': 0.4986357534764267}
2022-12-05 23:26:09,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:09,799 INFO:     Epoch: 77
2022-12-05 23:26:10,512 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5964497327804565, 'Total loss': 0.5964497327804565} | train loss {'Reaction outcome loss': 0.4977755853642336, 'Total loss': 0.4977755853642336}
2022-12-05 23:26:10,512 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:10,512 INFO:     Epoch: 78
2022-12-05 23:26:11,229 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5551254241303964, 'Total loss': 0.5551254241303964} | train loss {'Reaction outcome loss': 0.5234108438737962, 'Total loss': 0.5234108438737962}
2022-12-05 23:26:11,229 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:11,229 INFO:     Epoch: 79
2022-12-05 23:26:11,943 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5499278198588978, 'Total loss': 0.5499278198588978} | train loss {'Reaction outcome loss': 0.5096189130836652, 'Total loss': 0.5096189130836652}
2022-12-05 23:26:11,944 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:11,944 INFO:     Epoch: 80
2022-12-05 23:26:12,663 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5770683606917207, 'Total loss': 0.5770683606917207} | train loss {'Reaction outcome loss': 0.5060712246842652, 'Total loss': 0.5060712246842652}
2022-12-05 23:26:12,663 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:12,663 INFO:     Epoch: 81
2022-12-05 23:26:13,377 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5513844767754729, 'Total loss': 0.5513844767754729} | train loss {'Reaction outcome loss': 0.49288040520208565, 'Total loss': 0.49288040520208565}
2022-12-05 23:26:13,377 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:13,377 INFO:     Epoch: 82
2022-12-05 23:26:14,090 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.55693150379441, 'Total loss': 0.55693150379441} | train loss {'Reaction outcome loss': 0.4934240463472571, 'Total loss': 0.4934240463472571}
2022-12-05 23:26:14,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:14,090 INFO:     Epoch: 83
2022-12-05 23:26:14,807 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.595967254855416, 'Total loss': 0.595967254855416} | train loss {'Reaction outcome loss': 0.4977119960765607, 'Total loss': 0.4977119960765607}
2022-12-05 23:26:14,807 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:14,807 INFO:     Epoch: 84
2022-12-05 23:26:15,522 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5699068131771955, 'Total loss': 0.5699068131771955} | train loss {'Reaction outcome loss': 0.5000458527280975, 'Total loss': 0.5000458527280975}
2022-12-05 23:26:15,522 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:15,522 INFO:     Epoch: 85
2022-12-05 23:26:16,236 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5693764002485708, 'Total loss': 0.5693764002485708} | train loss {'Reaction outcome loss': 0.5139394135248323, 'Total loss': 0.5139394135248323}
2022-12-05 23:26:16,236 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:16,236 INFO:     Epoch: 86
2022-12-05 23:26:16,950 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5318767353892326, 'Total loss': 0.5318767353892326} | train loss {'Reaction outcome loss': 0.5049037848889586, 'Total loss': 0.5049037848889586}
2022-12-05 23:26:16,950 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:16,950 INFO:     Epoch: 87
2022-12-05 23:26:17,665 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5929915803399953, 'Total loss': 0.5929915803399953} | train loss {'Reaction outcome loss': 0.49785337317357903, 'Total loss': 0.49785337317357903}
2022-12-05 23:26:17,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:17,665 INFO:     Epoch: 88
2022-12-05 23:26:18,382 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5715121322057464, 'Total loss': 0.5715121322057464} | train loss {'Reaction outcome loss': 0.5029264897832021, 'Total loss': 0.5029264897832021}
2022-12-05 23:26:18,382 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:18,383 INFO:     Epoch: 89
2022-12-05 23:26:19,100 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.53679785606536, 'Total loss': 0.53679785606536} | train loss {'Reaction outcome loss': 0.5024593655955092, 'Total loss': 0.5024593655955092}
2022-12-05 23:26:19,100 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:19,100 INFO:     Epoch: 90
2022-12-05 23:26:19,814 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5818673131818121, 'Total loss': 0.5818673131818121} | train loss {'Reaction outcome loss': 0.4998015092331388, 'Total loss': 0.4998015092331388}
2022-12-05 23:26:19,814 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:19,815 INFO:     Epoch: 91
2022-12-05 23:26:20,533 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5603290904651989, 'Total loss': 0.5603290904651989} | train loss {'Reaction outcome loss': 0.5050711377188262, 'Total loss': 0.5050711377188262}
2022-12-05 23:26:20,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:20,533 INFO:     Epoch: 92
2022-12-05 23:26:21,247 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5856363556601785, 'Total loss': 0.5856363556601785} | train loss {'Reaction outcome loss': 0.5164381737711459, 'Total loss': 0.5164381737711459}
2022-12-05 23:26:21,247 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:21,247 INFO:     Epoch: 93
2022-12-05 23:26:21,966 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7040257609703324, 'Total loss': 0.7040257609703324} | train loss {'Reaction outcome loss': 0.5150880551772562, 'Total loss': 0.5150880551772562}
2022-12-05 23:26:21,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:21,966 INFO:     Epoch: 94
2022-12-05 23:26:22,685 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5729298476468433, 'Total loss': 0.5729298476468433} | train loss {'Reaction outcome loss': 0.5026983937271211, 'Total loss': 0.5026983937271211}
2022-12-05 23:26:22,685 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:22,685 INFO:     Epoch: 95
2022-12-05 23:26:23,400 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5388333269140937, 'Total loss': 0.5388333269140937} | train loss {'Reaction outcome loss': 0.49964853158967215, 'Total loss': 0.49964853158967215}
2022-12-05 23:26:23,400 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:23,400 INFO:     Epoch: 96
2022-12-05 23:26:24,113 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.563438644124703, 'Total loss': 0.563438644124703} | train loss {'Reaction outcome loss': 0.496508233716734, 'Total loss': 0.496508233716734}
2022-12-05 23:26:24,114 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:24,114 INFO:     Epoch: 97
2022-12-05 23:26:24,830 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5472170602191578, 'Total loss': 0.5472170602191578} | train loss {'Reaction outcome loss': 0.5052569335767705, 'Total loss': 0.5052569335767705}
2022-12-05 23:26:24,830 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:24,831 INFO:     Epoch: 98
2022-12-05 23:26:25,546 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5590378723361276, 'Total loss': 0.5590378723361276} | train loss {'Reaction outcome loss': 0.4953602946962905, 'Total loss': 0.4953602946962905}
2022-12-05 23:26:25,546 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:25,546 INFO:     Epoch: 99
2022-12-05 23:26:26,260 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.58945457264781, 'Total loss': 0.58945457264781} | train loss {'Reaction outcome loss': 0.5071189205854121, 'Total loss': 0.5071189205854121}
2022-12-05 23:26:26,260 INFO:     Best model found after epoch 65 of 100.
2022-12-05 23:26:26,261 INFO:   Done with stage: TRAINING
2022-12-05 23:26:26,261 INFO:   Starting stage: EVALUATION
2022-12-05 23:26:26,385 INFO:   Done with stage: EVALUATION
2022-12-05 23:26:26,385 INFO:   Leaving out SEQ value Fold_8
2022-12-05 23:26:26,399 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 23:26:26,399 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:26:27,041 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:26:27,041 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:26:27,112 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:26:27,112 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:26:27,112 INFO:     No hyperparam tuning for this model
2022-12-05 23:26:27,112 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:26:27,112 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:26:27,113 INFO:     None feature selector for col prot
2022-12-05 23:26:27,113 INFO:     None feature selector for col prot
2022-12-05 23:26:27,113 INFO:     None feature selector for col prot
2022-12-05 23:26:27,114 INFO:     None feature selector for col chem
2022-12-05 23:26:27,114 INFO:     None feature selector for col chem
2022-12-05 23:26:27,114 INFO:     None feature selector for col chem
2022-12-05 23:26:27,114 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:26:27,114 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:26:27,116 INFO:     Number of params in model 215731
2022-12-05 23:26:27,119 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:26:27,119 INFO:   Starting stage: TRAINING
2022-12-05 23:26:27,177 INFO:     Val loss before train {'Reaction outcome loss': 0.9896809985471327, 'Total loss': 0.9896809985471327}
2022-12-05 23:26:27,177 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:27,177 INFO:     Epoch: 0
2022-12-05 23:26:27,882 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6973822186159533, 'Total loss': 0.6973822186159533} | train loss {'Reaction outcome loss': 0.7993782795354968, 'Total loss': 0.7993782795354968}
2022-12-05 23:26:27,882 INFO:     Found new best model at epoch 0
2022-12-05 23:26:27,883 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:27,883 INFO:     Epoch: 1
2022-12-05 23:26:28,587 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6438148201898087, 'Total loss': 0.6438148201898087} | train loss {'Reaction outcome loss': 0.6725817832057593, 'Total loss': 0.6725817832057593}
2022-12-05 23:26:28,587 INFO:     Found new best model at epoch 1
2022-12-05 23:26:28,588 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:28,588 INFO:     Epoch: 2
2022-12-05 23:26:29,294 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6689624481422957, 'Total loss': 0.6689624481422957} | train loss {'Reaction outcome loss': 0.6130442397027719, 'Total loss': 0.6130442397027719}
2022-12-05 23:26:29,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:29,294 INFO:     Epoch: 3
2022-12-05 23:26:30,001 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.599623454864635, 'Total loss': 0.599623454864635} | train loss {'Reaction outcome loss': 0.5959219222308182, 'Total loss': 0.5959219222308182}
2022-12-05 23:26:30,001 INFO:     Found new best model at epoch 3
2022-12-05 23:26:30,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:30,002 INFO:     Epoch: 4
2022-12-05 23:26:30,708 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5787809255511261, 'Total loss': 0.5787809255511261} | train loss {'Reaction outcome loss': 0.5826780797883135, 'Total loss': 0.5826780797883135}
2022-12-05 23:26:30,709 INFO:     Found new best model at epoch 4
2022-12-05 23:26:30,710 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:30,710 INFO:     Epoch: 5
2022-12-05 23:26:31,414 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.561857366977736, 'Total loss': 0.561857366977736} | train loss {'Reaction outcome loss': 0.5703946209711129, 'Total loss': 0.5703946209711129}
2022-12-05 23:26:31,415 INFO:     Found new best model at epoch 5
2022-12-05 23:26:31,415 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:31,415 INFO:     Epoch: 6
2022-12-05 23:26:32,118 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5645239124464434, 'Total loss': 0.5645239124464434} | train loss {'Reaction outcome loss': 0.572100394023735, 'Total loss': 0.572100394023735}
2022-12-05 23:26:32,118 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:32,118 INFO:     Epoch: 7
2022-12-05 23:26:32,821 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5587783095448516, 'Total loss': 0.5587783095448516} | train loss {'Reaction outcome loss': 0.5509707169821028, 'Total loss': 0.5509707169821028}
2022-12-05 23:26:32,822 INFO:     Found new best model at epoch 7
2022-12-05 23:26:32,822 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:32,822 INFO:     Epoch: 8
2022-12-05 23:26:33,529 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6001570862393046, 'Total loss': 0.6001570862393046} | train loss {'Reaction outcome loss': 0.554613934432874, 'Total loss': 0.554613934432874}
2022-12-05 23:26:33,529 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:33,529 INFO:     Epoch: 9
2022-12-05 23:26:34,232 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5666047251501749, 'Total loss': 0.5666047251501749} | train loss {'Reaction outcome loss': 0.5506486332685244, 'Total loss': 0.5506486332685244}
2022-12-05 23:26:34,232 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:34,233 INFO:     Epoch: 10
2022-12-05 23:26:34,940 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5742393794447876, 'Total loss': 0.5742393794447876} | train loss {'Reaction outcome loss': 0.5374970188150641, 'Total loss': 0.5374970188150641}
2022-12-05 23:26:34,940 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:34,940 INFO:     Epoch: 11
2022-12-05 23:26:35,645 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5620553070722625, 'Total loss': 0.5620553070722625} | train loss {'Reaction outcome loss': 0.538158684175034, 'Total loss': 0.538158684175034}
2022-12-05 23:26:35,645 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:35,645 INFO:     Epoch: 12
2022-12-05 23:26:36,349 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5581198535686316, 'Total loss': 0.5581198535686316} | train loss {'Reaction outcome loss': 0.5374720823325094, 'Total loss': 0.5374720823325094}
2022-12-05 23:26:36,349 INFO:     Found new best model at epoch 12
2022-12-05 23:26:36,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:36,350 INFO:     Epoch: 13
2022-12-05 23:26:37,053 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5397238121476284, 'Total loss': 0.5397238121476284} | train loss {'Reaction outcome loss': 0.5349789670378459, 'Total loss': 0.5349789670378459}
2022-12-05 23:26:37,053 INFO:     Found new best model at epoch 13
2022-12-05 23:26:37,054 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:37,054 INFO:     Epoch: 14
2022-12-05 23:26:37,759 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.6404953495014546, 'Total loss': 0.6404953495014546} | train loss {'Reaction outcome loss': 0.5345030469728298, 'Total loss': 0.5345030469728298}
2022-12-05 23:26:37,759 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:37,759 INFO:     Epoch: 15
2022-12-05 23:26:38,464 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5913718862589016, 'Total loss': 0.5913718862589016} | train loss {'Reaction outcome loss': 0.5324807778977957, 'Total loss': 0.5324807778977957}
2022-12-05 23:26:38,464 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:38,464 INFO:     Epoch: 16
2022-12-05 23:26:39,168 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5489006624665371, 'Total loss': 0.5489006624665371} | train loss {'Reaction outcome loss': 0.5274334990220969, 'Total loss': 0.5274334990220969}
2022-12-05 23:26:39,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:39,168 INFO:     Epoch: 17
2022-12-05 23:26:39,873 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5530729945315871, 'Total loss': 0.5530729945315871} | train loss {'Reaction outcome loss': 0.5234754978999739, 'Total loss': 0.5234754978999739}
2022-12-05 23:26:39,874 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:39,874 INFO:     Epoch: 18
2022-12-05 23:26:40,580 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5499359157889389, 'Total loss': 0.5499359157889389} | train loss {'Reaction outcome loss': 0.5269433830360897, 'Total loss': 0.5269433830360897}
2022-12-05 23:26:40,580 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:40,580 INFO:     Epoch: 19
2022-12-05 23:26:41,286 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5164788517841074, 'Total loss': 0.5164788517841074} | train loss {'Reaction outcome loss': 0.5163903410439609, 'Total loss': 0.5163903410439609}
2022-12-05 23:26:41,286 INFO:     Found new best model at epoch 19
2022-12-05 23:26:41,286 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:41,287 INFO:     Epoch: 20
2022-12-05 23:26:41,992 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5329674281353174, 'Total loss': 0.5329674281353174} | train loss {'Reaction outcome loss': 0.521433245085302, 'Total loss': 0.521433245085302}
2022-12-05 23:26:41,992 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:41,992 INFO:     Epoch: 21
2022-12-05 23:26:42,699 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.534293249595997, 'Total loss': 0.534293249595997} | train loss {'Reaction outcome loss': 0.5209182850161537, 'Total loss': 0.5209182850161537}
2022-12-05 23:26:42,699 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:42,699 INFO:     Epoch: 22
2022-12-05 23:26:43,408 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.6129793101964995, 'Total loss': 0.6129793101964995} | train loss {'Reaction outcome loss': 0.5155303686490802, 'Total loss': 0.5155303686490802}
2022-12-05 23:26:43,409 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:43,409 INFO:     Epoch: 23
2022-12-05 23:26:44,116 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5277714171381884, 'Total loss': 0.5277714171381884} | train loss {'Reaction outcome loss': 0.5024616536607996, 'Total loss': 0.5024616536607996}
2022-12-05 23:26:44,116 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:44,116 INFO:     Epoch: 24
2022-12-05 23:26:44,824 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5202823870403822, 'Total loss': 0.5202823870403822} | train loss {'Reaction outcome loss': 0.5166358755382358, 'Total loss': 0.5166358755382358}
2022-12-05 23:26:44,824 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:44,824 INFO:     Epoch: 25
2022-12-05 23:26:45,530 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5286742823068485, 'Total loss': 0.5286742823068485} | train loss {'Reaction outcome loss': 0.5178374949170917, 'Total loss': 0.5178374949170917}
2022-12-05 23:26:45,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:45,530 INFO:     Epoch: 26
2022-12-05 23:26:46,236 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.564892885989921, 'Total loss': 0.564892885989921} | train loss {'Reaction outcome loss': 0.5135095684376897, 'Total loss': 0.5135095684376897}
2022-12-05 23:26:46,236 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:46,236 INFO:     Epoch: 27
2022-12-05 23:26:46,941 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5340655633183413, 'Total loss': 0.5340655633183413} | train loss {'Reaction outcome loss': 0.5176087001063785, 'Total loss': 0.5176087001063785}
2022-12-05 23:26:46,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:46,941 INFO:     Epoch: 28
2022-12-05 23:26:47,646 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5144152010596076, 'Total loss': 0.5144152010596076} | train loss {'Reaction outcome loss': 0.5151702872798091, 'Total loss': 0.5151702872798091}
2022-12-05 23:26:47,646 INFO:     Found new best model at epoch 28
2022-12-05 23:26:47,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:47,647 INFO:     Epoch: 29
2022-12-05 23:26:48,353 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5346680616223535, 'Total loss': 0.5346680616223535} | train loss {'Reaction outcome loss': 0.5017520919686458, 'Total loss': 0.5017520919686458}
2022-12-05 23:26:48,353 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:48,353 INFO:     Epoch: 30
2022-12-05 23:26:49,063 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5342631769734759, 'Total loss': 0.5342631769734759} | train loss {'Reaction outcome loss': 0.513694273399525, 'Total loss': 0.513694273399525}
2022-12-05 23:26:49,063 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:49,063 INFO:     Epoch: 31
2022-12-05 23:26:49,769 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5377755747285, 'Total loss': 0.5377755747285} | train loss {'Reaction outcome loss': 0.5081676682915355, 'Total loss': 0.5081676682915355}
2022-12-05 23:26:49,770 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:49,770 INFO:     Epoch: 32
2022-12-05 23:26:50,478 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5557372743307158, 'Total loss': 0.5557372743307158} | train loss {'Reaction outcome loss': 0.5056216590961472, 'Total loss': 0.5056216590961472}
2022-12-05 23:26:50,478 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:50,478 INFO:     Epoch: 33
2022-12-05 23:26:51,183 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5321432248104451, 'Total loss': 0.5321432248104451} | train loss {'Reaction outcome loss': 0.5067671515413972, 'Total loss': 0.5067671515413972}
2022-12-05 23:26:51,184 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:51,184 INFO:     Epoch: 34
2022-12-05 23:26:51,889 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5492682068846947, 'Total loss': 0.5492682068846947} | train loss {'Reaction outcome loss': 0.5067584653858279, 'Total loss': 0.5067584653858279}
2022-12-05 23:26:51,889 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:51,889 INFO:     Epoch: 35
2022-12-05 23:26:52,595 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5990644949813222, 'Total loss': 0.5990644949813222} | train loss {'Reaction outcome loss': 0.5152000873425945, 'Total loss': 0.5152000873425945}
2022-12-05 23:26:52,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:52,595 INFO:     Epoch: 36
2022-12-05 23:26:53,307 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5452728354653646, 'Total loss': 0.5452728354653646} | train loss {'Reaction outcome loss': 0.5113063039349728, 'Total loss': 0.5113063039349728}
2022-12-05 23:26:53,307 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:53,307 INFO:     Epoch: 37
2022-12-05 23:26:54,015 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5431457057941792, 'Total loss': 0.5431457057941792} | train loss {'Reaction outcome loss': 0.5033697032171195, 'Total loss': 0.5033697032171195}
2022-12-05 23:26:54,015 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:54,015 INFO:     Epoch: 38
2022-12-05 23:26:54,728 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5594509957834731, 'Total loss': 0.5594509957834731} | train loss {'Reaction outcome loss': 0.4988730401411408, 'Total loss': 0.4988730401411408}
2022-12-05 23:26:54,728 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:54,728 INFO:     Epoch: 39
2022-12-05 23:26:55,437 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5988654029923816, 'Total loss': 0.5988654029923816} | train loss {'Reaction outcome loss': 0.5146715093220844, 'Total loss': 0.5146715093220844}
2022-12-05 23:26:55,437 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:55,437 INFO:     Epoch: 40
2022-12-05 23:26:56,146 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5950011888215708, 'Total loss': 0.5950011888215708} | train loss {'Reaction outcome loss': 0.5133846956686895, 'Total loss': 0.5133846956686895}
2022-12-05 23:26:56,146 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:56,146 INFO:     Epoch: 41
2022-12-05 23:26:56,854 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5245507262473883, 'Total loss': 0.5245507262473883} | train loss {'Reaction outcome loss': 0.5011884181714449, 'Total loss': 0.5011884181714449}
2022-12-05 23:26:56,854 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:56,854 INFO:     Epoch: 42
2022-12-05 23:26:57,562 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5092029332421547, 'Total loss': 0.5092029332421547} | train loss {'Reaction outcome loss': 0.5037473799263845, 'Total loss': 0.5037473799263845}
2022-12-05 23:26:57,563 INFO:     Found new best model at epoch 42
2022-12-05 23:26:57,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:57,563 INFO:     Epoch: 43
2022-12-05 23:26:58,271 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5164692644463029, 'Total loss': 0.5164692644463029} | train loss {'Reaction outcome loss': 0.5079766106715456, 'Total loss': 0.5079766106715456}
2022-12-05 23:26:58,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:58,271 INFO:     Epoch: 44
2022-12-05 23:26:58,974 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5327949399171874, 'Total loss': 0.5327949399171874} | train loss {'Reaction outcome loss': 0.5048352412146623, 'Total loss': 0.5048352412146623}
2022-12-05 23:26:58,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:58,974 INFO:     Epoch: 45
2022-12-05 23:26:59,678 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5473606995371885, 'Total loss': 0.5473606995371885} | train loss {'Reaction outcome loss': 0.4986519679793569, 'Total loss': 0.4986519679793569}
2022-12-05 23:26:59,679 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:26:59,679 INFO:     Epoch: 46
2022-12-05 23:27:00,385 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5366095547066179, 'Total loss': 0.5366095547066179} | train loss {'Reaction outcome loss': 0.5086748032662712, 'Total loss': 0.5086748032662712}
2022-12-05 23:27:00,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:00,386 INFO:     Epoch: 47
2022-12-05 23:27:01,092 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5813499307909678, 'Total loss': 0.5813499307909678} | train loss {'Reaction outcome loss': 0.5074106908601815, 'Total loss': 0.5074106908601815}
2022-12-05 23:27:01,093 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:01,093 INFO:     Epoch: 48
2022-12-05 23:27:01,797 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5456589453442152, 'Total loss': 0.5456589453442152} | train loss {'Reaction outcome loss': 0.4999834622760288, 'Total loss': 0.4999834622760288}
2022-12-05 23:27:01,798 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:01,798 INFO:     Epoch: 49
2022-12-05 23:27:02,503 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5414440323447072, 'Total loss': 0.5414440323447072} | train loss {'Reaction outcome loss': 0.5065438745879247, 'Total loss': 0.5065438745879247}
2022-12-05 23:27:02,503 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:02,503 INFO:     Epoch: 50
2022-12-05 23:27:03,209 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5257668037747227, 'Total loss': 0.5257668037747227} | train loss {'Reaction outcome loss': 0.5093274604162721, 'Total loss': 0.5093274604162721}
2022-12-05 23:27:03,209 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:03,209 INFO:     Epoch: 51
2022-12-05 23:27:03,916 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5302142008792522, 'Total loss': 0.5302142008792522} | train loss {'Reaction outcome loss': 0.4976350737155461, 'Total loss': 0.4976350737155461}
2022-12-05 23:27:03,916 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:03,916 INFO:     Epoch: 52
2022-12-05 23:27:04,621 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5222110592348631, 'Total loss': 0.5222110592348631} | train loss {'Reaction outcome loss': 0.5204931832239276, 'Total loss': 0.5204931832239276}
2022-12-05 23:27:04,621 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:04,621 INFO:     Epoch: 53
2022-12-05 23:27:05,325 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5420499629406041, 'Total loss': 0.5420499629406041} | train loss {'Reaction outcome loss': 0.5017749646403751, 'Total loss': 0.5017749646403751}
2022-12-05 23:27:05,325 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:05,326 INFO:     Epoch: 54
2022-12-05 23:27:06,034 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5619774810796561, 'Total loss': 0.5619774810796561} | train loss {'Reaction outcome loss': 0.5110922904043901, 'Total loss': 0.5110922904043901}
2022-12-05 23:27:06,034 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:06,034 INFO:     Epoch: 55
2022-12-05 23:27:06,740 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5711076117532198, 'Total loss': 0.5711076117532198} | train loss {'Reaction outcome loss': 0.5093036124207935, 'Total loss': 0.5093036124207935}
2022-12-05 23:27:06,740 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:06,740 INFO:     Epoch: 56
2022-12-05 23:27:07,445 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5264339426229167, 'Total loss': 0.5264339426229167} | train loss {'Reaction outcome loss': 0.5068326477633148, 'Total loss': 0.5068326477633148}
2022-12-05 23:27:07,445 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:07,445 INFO:     Epoch: 57
2022-12-05 23:27:08,151 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5369316058796506, 'Total loss': 0.5369316058796506} | train loss {'Reaction outcome loss': 0.49855258602832186, 'Total loss': 0.49855258602832186}
2022-12-05 23:27:08,151 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:08,151 INFO:     Epoch: 58
2022-12-05 23:27:08,857 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5346407789823621, 'Total loss': 0.5346407789823621} | train loss {'Reaction outcome loss': 0.5080153326824551, 'Total loss': 0.5080153326824551}
2022-12-05 23:27:08,858 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:08,858 INFO:     Epoch: 59
2022-12-05 23:27:09,562 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5077242619076441, 'Total loss': 0.5077242619076441} | train loss {'Reaction outcome loss': 0.5000286446731599, 'Total loss': 0.5000286446731599}
2022-12-05 23:27:09,563 INFO:     Found new best model at epoch 59
2022-12-05 23:27:09,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:09,563 INFO:     Epoch: 60
2022-12-05 23:27:10,270 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5019075229417446, 'Total loss': 0.5019075229417446} | train loss {'Reaction outcome loss': 0.5010241704886077, 'Total loss': 0.5010241704886077}
2022-12-05 23:27:10,270 INFO:     Found new best model at epoch 60
2022-12-05 23:27:10,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:10,271 INFO:     Epoch: 61
2022-12-05 23:27:10,976 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5283514947392219, 'Total loss': 0.5283514947392219} | train loss {'Reaction outcome loss': 0.5083292938891004, 'Total loss': 0.5083292938891004}
2022-12-05 23:27:10,976 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:10,976 INFO:     Epoch: 62
2022-12-05 23:27:11,681 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5151476212019144, 'Total loss': 0.5151476212019144} | train loss {'Reaction outcome loss': 0.505715476684883, 'Total loss': 0.505715476684883}
2022-12-05 23:27:11,681 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:11,681 INFO:     Epoch: 63
2022-12-05 23:27:12,389 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5028505664925242, 'Total loss': 0.5028505664925242} | train loss {'Reaction outcome loss': 0.4995340637129838, 'Total loss': 0.4995340637129838}
2022-12-05 23:27:12,389 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:12,389 INFO:     Epoch: 64
2022-12-05 23:27:13,097 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5060993318640908, 'Total loss': 0.5060993318640908} | train loss {'Reaction outcome loss': 0.5064621732616034, 'Total loss': 0.5064621732616034}
2022-12-05 23:27:13,097 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:13,097 INFO:     Epoch: 65
2022-12-05 23:27:13,804 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5620666700740193, 'Total loss': 0.5620666700740193} | train loss {'Reaction outcome loss': 0.5086378177902737, 'Total loss': 0.5086378177902737}
2022-12-05 23:27:13,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:13,805 INFO:     Epoch: 66
2022-12-05 23:27:14,511 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5476976861787397, 'Total loss': 0.5476976861787397} | train loss {'Reaction outcome loss': 0.5039352615837192, 'Total loss': 0.5039352615837192}
2022-12-05 23:27:14,512 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:14,512 INFO:     Epoch: 67
2022-12-05 23:27:15,219 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5053110836550246, 'Total loss': 0.5053110836550246} | train loss {'Reaction outcome loss': 0.5013056173309928, 'Total loss': 0.5013056173309928}
2022-12-05 23:27:15,219 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:15,220 INFO:     Epoch: 68
2022-12-05 23:27:15,928 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5194050714720128, 'Total loss': 0.5194050714720128} | train loss {'Reaction outcome loss': 0.5021715063418521, 'Total loss': 0.5021715063418521}
2022-12-05 23:27:15,928 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:15,928 INFO:     Epoch: 69
2022-12-05 23:27:16,634 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6043031513690948, 'Total loss': 0.6043031513690948} | train loss {'Reaction outcome loss': 0.5074305251607152, 'Total loss': 0.5074305251607152}
2022-12-05 23:27:16,635 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:16,635 INFO:     Epoch: 70
2022-12-05 23:27:17,345 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5544637805500696, 'Total loss': 0.5544637805500696} | train loss {'Reaction outcome loss': 0.5059394100528272, 'Total loss': 0.5059394100528272}
2022-12-05 23:27:17,345 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:17,345 INFO:     Epoch: 71
2022-12-05 23:27:18,053 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5151634098485459, 'Total loss': 0.5151634098485459} | train loss {'Reaction outcome loss': 0.5008274741226533, 'Total loss': 0.5008274741226533}
2022-12-05 23:27:18,054 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:18,054 INFO:     Epoch: 72
2022-12-05 23:27:18,759 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5162625091020451, 'Total loss': 0.5162625091020451} | train loss {'Reaction outcome loss': 0.507026275345048, 'Total loss': 0.507026275345048}
2022-12-05 23:27:18,759 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:18,759 INFO:     Epoch: 73
2022-12-05 23:27:19,467 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.551358794057092, 'Total loss': 0.551358794057092} | train loss {'Reaction outcome loss': 0.4989172730778084, 'Total loss': 0.4989172730778084}
2022-12-05 23:27:19,467 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:19,467 INFO:     Epoch: 74
2022-12-05 23:27:20,180 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5119438005048175, 'Total loss': 0.5119438005048175} | train loss {'Reaction outcome loss': 0.5034588585745116, 'Total loss': 0.5034588585745116}
2022-12-05 23:27:20,181 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:20,181 INFO:     Epoch: 75
2022-12-05 23:27:20,893 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5353217568508414, 'Total loss': 0.5353217568508414} | train loss {'Reaction outcome loss': 0.5102131563986911, 'Total loss': 0.5102131563986911}
2022-12-05 23:27:20,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:20,894 INFO:     Epoch: 76
2022-12-05 23:27:21,610 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5246821475583453, 'Total loss': 0.5246821475583453} | train loss {'Reaction outcome loss': 0.5046547072344139, 'Total loss': 0.5046547072344139}
2022-12-05 23:27:21,610 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:21,610 INFO:     Epoch: 77
2022-12-05 23:27:22,322 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5194033917992614, 'Total loss': 0.5194033917992614} | train loss {'Reaction outcome loss': 0.5030446095300503, 'Total loss': 0.5030446095300503}
2022-12-05 23:27:22,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:22,322 INFO:     Epoch: 78
2022-12-05 23:27:23,034 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5191475541092628, 'Total loss': 0.5191475541092628} | train loss {'Reaction outcome loss': 0.5009718044493042, 'Total loss': 0.5009718044493042}
2022-12-05 23:27:23,034 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:23,034 INFO:     Epoch: 79
2022-12-05 23:27:23,744 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5225908388925153, 'Total loss': 0.5225908388925153} | train loss {'Reaction outcome loss': 0.5032674693426148, 'Total loss': 0.5032674693426148}
2022-12-05 23:27:23,744 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:23,744 INFO:     Epoch: 80
2022-12-05 23:27:24,455 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5258764832518822, 'Total loss': 0.5258764832518822} | train loss {'Reaction outcome loss': 0.5085088073230181, 'Total loss': 0.5085088073230181}
2022-12-05 23:27:24,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:24,455 INFO:     Epoch: 81
2022-12-05 23:27:25,165 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5083603491616804, 'Total loss': 0.5083603491616804} | train loss {'Reaction outcome loss': 0.5101223738222825, 'Total loss': 0.5101223738222825}
2022-12-05 23:27:25,165 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:25,165 INFO:     Epoch: 82
2022-12-05 23:27:25,876 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5337614812130151, 'Total loss': 0.5337614812130151} | train loss {'Reaction outcome loss': 0.5044177799317681, 'Total loss': 0.5044177799317681}
2022-12-05 23:27:25,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:25,876 INFO:     Epoch: 83
2022-12-05 23:27:26,585 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5740194674148116, 'Total loss': 0.5740194674148116} | train loss {'Reaction outcome loss': 0.5094832863475456, 'Total loss': 0.5094832863475456}
2022-12-05 23:27:26,585 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:26,585 INFO:     Epoch: 84
2022-12-05 23:27:27,297 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.518893402329711, 'Total loss': 0.518893402329711} | train loss {'Reaction outcome loss': 0.5055638000857635, 'Total loss': 0.5055638000857635}
2022-12-05 23:27:27,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:27,297 INFO:     Epoch: 85
2022-12-05 23:27:28,008 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5469701321319093, 'Total loss': 0.5469701321319093} | train loss {'Reaction outcome loss': 0.4973663906337785, 'Total loss': 0.4973663906337785}
2022-12-05 23:27:28,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:28,008 INFO:     Epoch: 86
2022-12-05 23:27:28,718 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5542201032472212, 'Total loss': 0.5542201032472212} | train loss {'Reaction outcome loss': 0.5012400375037896, 'Total loss': 0.5012400375037896}
2022-12-05 23:27:28,719 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:28,719 INFO:     Epoch: 87
2022-12-05 23:27:29,430 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5298797217912452, 'Total loss': 0.5298797217912452} | train loss {'Reaction outcome loss': 0.5021072268241742, 'Total loss': 0.5021072268241742}
2022-12-05 23:27:29,430 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:29,430 INFO:     Epoch: 88
2022-12-05 23:27:30,145 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5321097571489423, 'Total loss': 0.5321097571489423} | train loss {'Reaction outcome loss': 0.4980386807048907, 'Total loss': 0.4980386807048907}
2022-12-05 23:27:30,145 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:30,145 INFO:     Epoch: 89
2022-12-05 23:27:30,855 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5651689604964367, 'Total loss': 0.5651689604964367} | train loss {'Reaction outcome loss': 0.5016626555045121, 'Total loss': 0.5016626555045121}
2022-12-05 23:27:30,855 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:30,855 INFO:     Epoch: 90
2022-12-05 23:27:31,564 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5684714457669924, 'Total loss': 0.5684714457669924} | train loss {'Reaction outcome loss': 0.506604227802304, 'Total loss': 0.506604227802304}
2022-12-05 23:27:31,565 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:31,565 INFO:     Epoch: 91
2022-12-05 23:27:32,274 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5443207205728043, 'Total loss': 0.5443207205728043} | train loss {'Reaction outcome loss': 0.5090152333627959, 'Total loss': 0.5090152333627959}
2022-12-05 23:27:32,274 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:32,274 INFO:     Epoch: 92
2022-12-05 23:27:32,983 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.526894784944002, 'Total loss': 0.526894784944002} | train loss {'Reaction outcome loss': 0.5015188251301402, 'Total loss': 0.5015188251301402}
2022-12-05 23:27:32,984 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:32,984 INFO:     Epoch: 93
2022-12-05 23:27:33,698 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5545947288357934, 'Total loss': 0.5545947288357934} | train loss {'Reaction outcome loss': 0.5080771033087226, 'Total loss': 0.5080771033087226}
2022-12-05 23:27:33,699 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:33,699 INFO:     Epoch: 94
2022-12-05 23:27:34,408 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5025551000306773, 'Total loss': 0.5025551000306773} | train loss {'Reaction outcome loss': 0.4945662759977286, 'Total loss': 0.4945662759977286}
2022-12-05 23:27:34,408 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:34,408 INFO:     Epoch: 95
2022-12-05 23:27:35,116 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5402463397314382, 'Total loss': 0.5402463397314382} | train loss {'Reaction outcome loss': 0.5007864382789761, 'Total loss': 0.5007864382789761}
2022-12-05 23:27:35,117 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:35,117 INFO:     Epoch: 96
2022-12-05 23:27:35,831 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5380559120067331, 'Total loss': 0.5380559120067331} | train loss {'Reaction outcome loss': 0.5034520265753152, 'Total loss': 0.5034520265753152}
2022-12-05 23:27:35,831 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:35,831 INFO:     Epoch: 97
2022-12-05 23:27:36,544 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5378891811814419, 'Total loss': 0.5378891811814419} | train loss {'Reaction outcome loss': 0.504029342385589, 'Total loss': 0.504029342385589}
2022-12-05 23:27:36,544 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:36,544 INFO:     Epoch: 98
2022-12-05 23:27:37,255 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5090385103641555, 'Total loss': 0.5090385103641555} | train loss {'Reaction outcome loss': 0.4947207359994044, 'Total loss': 0.4947207359994044}
2022-12-05 23:27:37,256 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:37,256 INFO:     Epoch: 99
2022-12-05 23:27:37,966 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4934192902820055, 'Total loss': 0.4934192902820055} | train loss {'Reaction outcome loss': 0.499565629624441, 'Total loss': 0.499565629624441}
2022-12-05 23:27:37,966 INFO:     Found new best model at epoch 99
2022-12-05 23:27:37,967 INFO:     Best model found after epoch 100 of 100.
2022-12-05 23:27:37,967 INFO:   Done with stage: TRAINING
2022-12-05 23:27:37,967 INFO:   Starting stage: EVALUATION
2022-12-05 23:27:38,103 INFO:   Done with stage: EVALUATION
2022-12-05 23:27:38,104 INFO:   Leaving out SEQ value Fold_9
2022-12-05 23:27:38,116 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:27:38,116 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:27:38,762 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:27:38,762 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:27:38,833 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:27:38,834 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:27:38,834 INFO:     No hyperparam tuning for this model
2022-12-05 23:27:38,834 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:27:38,834 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:27:38,835 INFO:     None feature selector for col prot
2022-12-05 23:27:38,835 INFO:     None feature selector for col prot
2022-12-05 23:27:38,835 INFO:     None feature selector for col prot
2022-12-05 23:27:38,835 INFO:     None feature selector for col chem
2022-12-05 23:27:38,836 INFO:     None feature selector for col chem
2022-12-05 23:27:38,836 INFO:     None feature selector for col chem
2022-12-05 23:27:38,836 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:27:38,836 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:27:38,837 INFO:     Number of params in model 215731
2022-12-05 23:27:38,841 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:27:38,841 INFO:   Starting stage: TRAINING
2022-12-05 23:27:38,900 INFO:     Val loss before train {'Reaction outcome loss': 1.0647365640510211, 'Total loss': 1.0647365640510211}
2022-12-05 23:27:38,900 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:38,900 INFO:     Epoch: 0
2022-12-05 23:27:39,622 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6897868337956342, 'Total loss': 0.6897868337956342} | train loss {'Reaction outcome loss': 0.7987005504278036, 'Total loss': 0.7987005504278036}
2022-12-05 23:27:39,622 INFO:     Found new best model at epoch 0
2022-12-05 23:27:39,622 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:39,623 INFO:     Epoch: 1
2022-12-05 23:27:40,342 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.585441030561924, 'Total loss': 0.585441030561924} | train loss {'Reaction outcome loss': 0.6612064297488223, 'Total loss': 0.6612064297488223}
2022-12-05 23:27:40,342 INFO:     Found new best model at epoch 1
2022-12-05 23:27:40,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:40,343 INFO:     Epoch: 2
2022-12-05 23:27:41,064 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6476183706386522, 'Total loss': 0.6476183706386522} | train loss {'Reaction outcome loss': 0.6056577007056247, 'Total loss': 0.6056577007056247}
2022-12-05 23:27:41,064 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:41,064 INFO:     Epoch: 3
2022-12-05 23:27:41,781 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5874142314900052, 'Total loss': 0.5874142314900052} | train loss {'Reaction outcome loss': 0.5855425710484445, 'Total loss': 0.5855425710484445}
2022-12-05 23:27:41,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:41,781 INFO:     Epoch: 4
2022-12-05 23:27:42,501 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.545465119860389, 'Total loss': 0.545465119860389} | train loss {'Reaction outcome loss': 0.574158801180631, 'Total loss': 0.574158801180631}
2022-12-05 23:27:42,501 INFO:     Found new best model at epoch 4
2022-12-05 23:27:42,502 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:42,502 INFO:     Epoch: 5
2022-12-05 23:27:43,215 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6707304594191638, 'Total loss': 0.6707304594191638} | train loss {'Reaction outcome loss': 0.5735737356821052, 'Total loss': 0.5735737356821052}
2022-12-05 23:27:43,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:43,215 INFO:     Epoch: 6
2022-12-05 23:27:43,931 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5291654271158305, 'Total loss': 0.5291654271158305} | train loss {'Reaction outcome loss': 0.5668029446712872, 'Total loss': 0.5668029446712872}
2022-12-05 23:27:43,931 INFO:     Found new best model at epoch 6
2022-12-05 23:27:43,931 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:43,932 INFO:     Epoch: 7
2022-12-05 23:27:44,647 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5368405343456701, 'Total loss': 0.5368405343456701} | train loss {'Reaction outcome loss': 0.5531304810754201, 'Total loss': 0.5531304810754201}
2022-12-05 23:27:44,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:44,647 INFO:     Epoch: 8
2022-12-05 23:27:45,367 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.546879933977669, 'Total loss': 0.546879933977669} | train loss {'Reaction outcome loss': 0.5495732552843237, 'Total loss': 0.5495732552843237}
2022-12-05 23:27:45,368 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:45,368 INFO:     Epoch: 9
2022-12-05 23:27:46,086 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5168408531356942, 'Total loss': 0.5168408531356942} | train loss {'Reaction outcome loss': 0.5425995712127039, 'Total loss': 0.5425995712127039}
2022-12-05 23:27:46,086 INFO:     Found new best model at epoch 9
2022-12-05 23:27:46,087 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:46,087 INFO:     Epoch: 10
2022-12-05 23:27:46,808 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5260996649211104, 'Total loss': 0.5260996649211104} | train loss {'Reaction outcome loss': 0.5442337842605375, 'Total loss': 0.5442337842605375}
2022-12-05 23:27:46,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:46,809 INFO:     Epoch: 11
2022-12-05 23:27:47,526 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5230981809171763, 'Total loss': 0.5230981809171763} | train loss {'Reaction outcome loss': 0.5436119329832826, 'Total loss': 0.5436119329832826}
2022-12-05 23:27:47,526 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:47,527 INFO:     Epoch: 12
2022-12-05 23:27:48,249 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.507854050533338, 'Total loss': 0.507854050533338} | train loss {'Reaction outcome loss': 0.5356220382789851, 'Total loss': 0.5356220382789851}
2022-12-05 23:27:48,249 INFO:     Found new best model at epoch 12
2022-12-05 23:27:48,250 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:48,250 INFO:     Epoch: 13
2022-12-05 23:27:48,964 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5381775213913484, 'Total loss': 0.5381775213913484} | train loss {'Reaction outcome loss': 0.5318330259096284, 'Total loss': 0.5318330259096284}
2022-12-05 23:27:48,965 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:48,965 INFO:     Epoch: 14
2022-12-05 23:27:49,682 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.528422645885836, 'Total loss': 0.528422645885836} | train loss {'Reaction outcome loss': 0.5462749258347368, 'Total loss': 0.5462749258347368}
2022-12-05 23:27:49,682 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:49,682 INFO:     Epoch: 15
2022-12-05 23:27:50,396 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.517019733786583, 'Total loss': 0.517019733786583} | train loss {'Reaction outcome loss': 0.5424970823607826, 'Total loss': 0.5424970823607826}
2022-12-05 23:27:50,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:50,397 INFO:     Epoch: 16
2022-12-05 23:27:51,110 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5479305921630426, 'Total loss': 0.5479305921630426} | train loss {'Reaction outcome loss': 0.5317102551218952, 'Total loss': 0.5317102551218952}
2022-12-05 23:27:51,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:51,111 INFO:     Epoch: 17
2022-12-05 23:27:51,824 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.520077181133357, 'Total loss': 0.520077181133357} | train loss {'Reaction outcome loss': 0.5421139127933062, 'Total loss': 0.5421139127933062}
2022-12-05 23:27:51,824 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:51,824 INFO:     Epoch: 18
2022-12-05 23:27:52,540 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4913813031532548, 'Total loss': 0.4913813031532548} | train loss {'Reaction outcome loss': 0.525126843980932, 'Total loss': 0.525126843980932}
2022-12-05 23:27:52,541 INFO:     Found new best model at epoch 18
2022-12-05 23:27:52,541 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:52,541 INFO:     Epoch: 19
2022-12-05 23:27:53,258 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5501620837233283, 'Total loss': 0.5501620837233283} | train loss {'Reaction outcome loss': 0.5247518833470248, 'Total loss': 0.5247518833470248}
2022-12-05 23:27:53,258 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:53,258 INFO:     Epoch: 20
2022-12-05 23:27:53,971 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.502280882475051, 'Total loss': 0.502280882475051} | train loss {'Reaction outcome loss': 0.5169268650500488, 'Total loss': 0.5169268650500488}
2022-12-05 23:27:53,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:53,971 INFO:     Epoch: 21
2022-12-05 23:27:54,685 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49803812158378685, 'Total loss': 0.49803812158378685} | train loss {'Reaction outcome loss': 0.5223141998535226, 'Total loss': 0.5223141998535226}
2022-12-05 23:27:54,685 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:54,685 INFO:     Epoch: 22
2022-12-05 23:27:55,398 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5271654637022452, 'Total loss': 0.5271654637022452} | train loss {'Reaction outcome loss': 0.5177998060156942, 'Total loss': 0.5177998060156942}
2022-12-05 23:27:55,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:55,399 INFO:     Epoch: 23
2022-12-05 23:27:56,112 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4999115619469773, 'Total loss': 0.4999115619469773} | train loss {'Reaction outcome loss': 0.5288296819698473, 'Total loss': 0.5288296819698473}
2022-12-05 23:27:56,112 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:56,112 INFO:     Epoch: 24
2022-12-05 23:27:56,826 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5060490562834523, 'Total loss': 0.5060490562834523} | train loss {'Reaction outcome loss': 0.5222099907847069, 'Total loss': 0.5222099907847069}
2022-12-05 23:27:56,826 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:56,827 INFO:     Epoch: 25
2022-12-05 23:27:57,545 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4802713072435422, 'Total loss': 0.4802713072435422} | train loss {'Reaction outcome loss': 0.524891487499963, 'Total loss': 0.524891487499963}
2022-12-05 23:27:57,545 INFO:     Found new best model at epoch 25
2022-12-05 23:27:57,545 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:57,546 INFO:     Epoch: 26
2022-12-05 23:27:58,265 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5493824322792616, 'Total loss': 0.5493824322792616} | train loss {'Reaction outcome loss': 0.5276733104682524, 'Total loss': 0.5276733104682524}
2022-12-05 23:27:58,265 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:58,265 INFO:     Epoch: 27
2022-12-05 23:27:58,980 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49848062274130905, 'Total loss': 0.49848062274130905} | train loss {'Reaction outcome loss': 0.5156478857704503, 'Total loss': 0.5156478857704503}
2022-12-05 23:27:58,980 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:58,980 INFO:     Epoch: 28
2022-12-05 23:27:59,702 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4884741631421176, 'Total loss': 0.4884741631421176} | train loss {'Reaction outcome loss': 0.5236716619146015, 'Total loss': 0.5236716619146015}
2022-12-05 23:27:59,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:27:59,703 INFO:     Epoch: 29
2022-12-05 23:28:00,419 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5124075378883969, 'Total loss': 0.5124075378883969} | train loss {'Reaction outcome loss': 0.5167599148814556, 'Total loss': 0.5167599148814556}
2022-12-05 23:28:00,419 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:00,419 INFO:     Epoch: 30
2022-12-05 23:28:01,134 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5530396442521702, 'Total loss': 0.5530396442521702} | train loss {'Reaction outcome loss': 0.5152506967063858, 'Total loss': 0.5152506967063858}
2022-12-05 23:28:01,135 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:01,135 INFO:     Epoch: 31
2022-12-05 23:28:01,853 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.589599376375025, 'Total loss': 0.589599376375025} | train loss {'Reaction outcome loss': 0.5189650998854263, 'Total loss': 0.5189650998854263}
2022-12-05 23:28:01,853 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:01,853 INFO:     Epoch: 32
2022-12-05 23:28:02,575 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5114446837793697, 'Total loss': 0.5114446837793697} | train loss {'Reaction outcome loss': 0.5218166933971861, 'Total loss': 0.5218166933971861}
2022-12-05 23:28:02,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:02,575 INFO:     Epoch: 33
2022-12-05 23:28:03,290 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5610864717851985, 'Total loss': 0.5610864717851985} | train loss {'Reaction outcome loss': 0.5177138517139411, 'Total loss': 0.5177138517139411}
2022-12-05 23:28:03,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:03,290 INFO:     Epoch: 34
2022-12-05 23:28:04,008 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4959110919047486, 'Total loss': 0.4959110919047486} | train loss {'Reaction outcome loss': 0.5302972170988075, 'Total loss': 0.5302972170988075}
2022-12-05 23:28:04,008 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:04,008 INFO:     Epoch: 35
2022-12-05 23:28:04,724 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5230889591303739, 'Total loss': 0.5230889591303739} | train loss {'Reaction outcome loss': 0.5130039611963276, 'Total loss': 0.5130039611963276}
2022-12-05 23:28:04,724 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:04,724 INFO:     Epoch: 36
2022-12-05 23:28:05,439 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5252788937227293, 'Total loss': 0.5252788937227293} | train loss {'Reaction outcome loss': 0.5163952031960855, 'Total loss': 0.5163952031960855}
2022-12-05 23:28:05,439 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:05,439 INFO:     Epoch: 37
2022-12-05 23:28:06,157 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5194255597889423, 'Total loss': 0.5194255597889423} | train loss {'Reaction outcome loss': 0.512659606797647, 'Total loss': 0.512659606797647}
2022-12-05 23:28:06,158 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:06,158 INFO:     Epoch: 38
2022-12-05 23:28:06,875 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5086167861114849, 'Total loss': 0.5086167861114849} | train loss {'Reaction outcome loss': 0.5117935677650969, 'Total loss': 0.5117935677650969}
2022-12-05 23:28:06,875 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:06,875 INFO:     Epoch: 39
2022-12-05 23:28:07,587 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5176686881618067, 'Total loss': 0.5176686881618067} | train loss {'Reaction outcome loss': 0.5148941553857646, 'Total loss': 0.5148941553857646}
2022-12-05 23:28:07,588 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:07,588 INFO:     Epoch: 40
2022-12-05 23:28:08,303 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5027020641348579, 'Total loss': 0.5027020641348579} | train loss {'Reaction outcome loss': 0.5136356136878493, 'Total loss': 0.5136356136878493}
2022-12-05 23:28:08,303 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:08,303 INFO:     Epoch: 41
2022-12-05 23:28:09,013 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5654461238194596, 'Total loss': 0.5654461238194596} | train loss {'Reaction outcome loss': 0.5034822057253918, 'Total loss': 0.5034822057253918}
2022-12-05 23:28:09,013 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:09,013 INFO:     Epoch: 42
2022-12-05 23:28:09,723 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5017978362739086, 'Total loss': 0.5017978362739086} | train loss {'Reaction outcome loss': 0.5081444915218151, 'Total loss': 0.5081444915218151}
2022-12-05 23:28:09,724 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:09,724 INFO:     Epoch: 43
2022-12-05 23:28:10,437 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5059450834312222, 'Total loss': 0.5059450834312222} | train loss {'Reaction outcome loss': 0.5096136929414533, 'Total loss': 0.5096136929414533}
2022-12-05 23:28:10,437 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:10,437 INFO:     Epoch: 44
2022-12-05 23:28:11,158 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5469397441907362, 'Total loss': 0.5469397441907362} | train loss {'Reaction outcome loss': 0.5099886867560839, 'Total loss': 0.5099886867560839}
2022-12-05 23:28:11,158 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:11,158 INFO:     Epoch: 45
2022-12-05 23:28:11,869 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4805268943309784, 'Total loss': 0.4805268943309784} | train loss {'Reaction outcome loss': 0.5145588806766247, 'Total loss': 0.5145588806766247}
2022-12-05 23:28:11,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:11,869 INFO:     Epoch: 46
2022-12-05 23:28:12,581 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5104814645918933, 'Total loss': 0.5104814645918933} | train loss {'Reaction outcome loss': 0.5091519410672941, 'Total loss': 0.5091519410672941}
2022-12-05 23:28:12,581 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:12,581 INFO:     Epoch: 47
2022-12-05 23:28:13,296 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5573846792632883, 'Total loss': 0.5573846792632883} | train loss {'Reaction outcome loss': 0.5089751176747234, 'Total loss': 0.5089751176747234}
2022-12-05 23:28:13,296 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:13,296 INFO:     Epoch: 48
2022-12-05 23:28:14,005 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5217958157035437, 'Total loss': 0.5217958157035437} | train loss {'Reaction outcome loss': 0.5118391314136838, 'Total loss': 0.5118391314136838}
2022-12-05 23:28:14,005 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:14,005 INFO:     Epoch: 49
2022-12-05 23:28:14,715 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5624997412616556, 'Total loss': 0.5624997412616556} | train loss {'Reaction outcome loss': 0.5100216665851925, 'Total loss': 0.5100216665851925}
2022-12-05 23:28:14,715 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:14,715 INFO:     Epoch: 50
2022-12-05 23:28:15,427 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.536488979038867, 'Total loss': 0.536488979038867} | train loss {'Reaction outcome loss': 0.5279684430629257, 'Total loss': 0.5279684430629257}
2022-12-05 23:28:15,428 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:15,428 INFO:     Epoch: 51
2022-12-05 23:28:16,137 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5542031357234175, 'Total loss': 0.5542031357234175} | train loss {'Reaction outcome loss': 0.5057332455689608, 'Total loss': 0.5057332455689608}
2022-12-05 23:28:16,137 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:16,137 INFO:     Epoch: 52
2022-12-05 23:28:16,848 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49395234340971167, 'Total loss': 0.49395234340971167} | train loss {'Reaction outcome loss': 0.5050457336841837, 'Total loss': 0.5050457336841837}
2022-12-05 23:28:16,849 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:16,849 INFO:     Epoch: 53
2022-12-05 23:28:17,559 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5085028731687502, 'Total loss': 0.5085028731687502} | train loss {'Reaction outcome loss': 0.5013762190636353, 'Total loss': 0.5013762190636353}
2022-12-05 23:28:17,559 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:17,559 INFO:     Epoch: 54
2022-12-05 23:28:18,269 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48932763561606407, 'Total loss': 0.48932763561606407} | train loss {'Reaction outcome loss': 0.5071607440830725, 'Total loss': 0.5071607440830725}
2022-12-05 23:28:18,269 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:18,269 INFO:     Epoch: 55
2022-12-05 23:28:18,979 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5115399621427059, 'Total loss': 0.5115399621427059} | train loss {'Reaction outcome loss': 0.5048227722828205, 'Total loss': 0.5048227722828205}
2022-12-05 23:28:18,979 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:18,980 INFO:     Epoch: 56
2022-12-05 23:28:19,688 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5085819593884728, 'Total loss': 0.5085819593884728} | train loss {'Reaction outcome loss': 0.5105675002823957, 'Total loss': 0.5105675002823957}
2022-12-05 23:28:19,688 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:19,688 INFO:     Epoch: 57
2022-12-05 23:28:20,399 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5130631469867446, 'Total loss': 0.5130631469867446} | train loss {'Reaction outcome loss': 0.5009825309014574, 'Total loss': 0.5009825309014574}
2022-12-05 23:28:20,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:20,400 INFO:     Epoch: 58
2022-12-05 23:28:21,111 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5030197640034285, 'Total loss': 0.5030197640034285} | train loss {'Reaction outcome loss': 0.5017952310290896, 'Total loss': 0.5017952310290896}
2022-12-05 23:28:21,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:21,111 INFO:     Epoch: 59
2022-12-05 23:28:21,822 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.538207782940431, 'Total loss': 0.538207782940431} | train loss {'Reaction outcome loss': 0.5067431234758393, 'Total loss': 0.5067431234758393}
2022-12-05 23:28:21,822 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:21,822 INFO:     Epoch: 60
2022-12-05 23:28:22,537 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5505538410083815, 'Total loss': 0.5505538410083815} | train loss {'Reaction outcome loss': 0.5223370016465786, 'Total loss': 0.5223370016465786}
2022-12-05 23:28:22,537 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:22,537 INFO:     Epoch: 61
2022-12-05 23:28:23,247 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5170501829548315, 'Total loss': 0.5170501829548315} | train loss {'Reaction outcome loss': 0.5132523005911214, 'Total loss': 0.5132523005911214}
2022-12-05 23:28:23,252 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:23,252 INFO:     Epoch: 62
2022-12-05 23:28:23,960 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5071528147567402, 'Total loss': 0.5071528147567402} | train loss {'Reaction outcome loss': 0.5068626654775519, 'Total loss': 0.5068626654775519}
2022-12-05 23:28:23,960 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:23,960 INFO:     Epoch: 63
2022-12-05 23:28:24,670 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5942273498936133, 'Total loss': 0.5942273498936133} | train loss {'Reaction outcome loss': 0.5116838725653254, 'Total loss': 0.5116838725653254}
2022-12-05 23:28:24,670 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:24,670 INFO:     Epoch: 64
2022-12-05 23:28:25,380 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5403893732211806, 'Total loss': 0.5403893732211806} | train loss {'Reaction outcome loss': 0.52466529215637, 'Total loss': 0.52466529215637}
2022-12-05 23:28:25,380 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:25,380 INFO:     Epoch: 65
2022-12-05 23:28:26,089 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5702149854464964, 'Total loss': 0.5702149854464964} | train loss {'Reaction outcome loss': 0.5123998112524086, 'Total loss': 0.5123998112524086}
2022-12-05 23:28:26,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:26,090 INFO:     Epoch: 66
2022-12-05 23:28:26,800 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.47219736129045486, 'Total loss': 0.47219736129045486} | train loss {'Reaction outcome loss': 0.5161389251831572, 'Total loss': 0.5161389251831572}
2022-12-05 23:28:26,800 INFO:     Found new best model at epoch 66
2022-12-05 23:28:26,801 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:26,801 INFO:     Epoch: 67
2022-12-05 23:28:27,511 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5139954977414825, 'Total loss': 0.5139954977414825} | train loss {'Reaction outcome loss': 0.4952317844804844, 'Total loss': 0.4952317844804844}
2022-12-05 23:28:27,511 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:27,511 INFO:     Epoch: 68
2022-12-05 23:28:28,221 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.521083494479006, 'Total loss': 0.521083494479006} | train loss {'Reaction outcome loss': 0.4952298698999621, 'Total loss': 0.4952298698999621}
2022-12-05 23:28:28,221 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:28,222 INFO:     Epoch: 69
2022-12-05 23:28:28,934 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.524984712627801, 'Total loss': 0.524984712627801} | train loss {'Reaction outcome loss': 0.5177138932200096, 'Total loss': 0.5177138932200096}
2022-12-05 23:28:28,935 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:28,935 INFO:     Epoch: 70
2022-12-05 23:28:29,645 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5078349858522415, 'Total loss': 0.5078349858522415} | train loss {'Reaction outcome loss': 0.5111442058976845, 'Total loss': 0.5111442058976845}
2022-12-05 23:28:29,646 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:29,646 INFO:     Epoch: 71
2022-12-05 23:28:30,357 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5697967125610872, 'Total loss': 0.5697967125610872} | train loss {'Reaction outcome loss': 0.49180865358666853, 'Total loss': 0.49180865358666853}
2022-12-05 23:28:30,357 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:30,357 INFO:     Epoch: 72
2022-12-05 23:28:31,070 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5055478909476236, 'Total loss': 0.5055478909476236} | train loss {'Reaction outcome loss': 0.5076530557653682, 'Total loss': 0.5076530557653682}
2022-12-05 23:28:31,070 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:31,070 INFO:     Epoch: 73
2022-12-05 23:28:31,783 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5058873681859537, 'Total loss': 0.5058873681859537} | train loss {'Reaction outcome loss': 0.5059167805772561, 'Total loss': 0.5059167805772561}
2022-12-05 23:28:31,783 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:31,783 INFO:     Epoch: 74
2022-12-05 23:28:32,494 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5324415754188191, 'Total loss': 0.5324415754188191} | train loss {'Reaction outcome loss': 0.5056157755224329, 'Total loss': 0.5056157755224329}
2022-12-05 23:28:32,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:32,494 INFO:     Epoch: 75
2022-12-05 23:28:33,207 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4988405511460521, 'Total loss': 0.4988405511460521} | train loss {'Reaction outcome loss': 0.5153245712943405, 'Total loss': 0.5153245712943405}
2022-12-05 23:28:33,207 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:33,207 INFO:     Epoch: 76
2022-12-05 23:28:33,917 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4682962169701403, 'Total loss': 0.4682962169701403} | train loss {'Reaction outcome loss': 0.5042736988197937, 'Total loss': 0.5042736988197937}
2022-12-05 23:28:33,917 INFO:     Found new best model at epoch 76
2022-12-05 23:28:33,918 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:33,918 INFO:     Epoch: 77
2022-12-05 23:28:34,628 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4977735521441156, 'Total loss': 0.4977735521441156} | train loss {'Reaction outcome loss': 0.5084128539692535, 'Total loss': 0.5084128539692535}
2022-12-05 23:28:34,628 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:34,629 INFO:     Epoch: 78
2022-12-05 23:28:35,340 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5247004990550604, 'Total loss': 0.5247004990550604} | train loss {'Reaction outcome loss': 0.49973496070757567, 'Total loss': 0.49973496070757567}
2022-12-05 23:28:35,341 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:35,341 INFO:     Epoch: 79
2022-12-05 23:28:36,051 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4863801242952997, 'Total loss': 0.4863801242952997} | train loss {'Reaction outcome loss': 0.5077301313278646, 'Total loss': 0.5077301313278646}
2022-12-05 23:28:36,051 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:36,051 INFO:     Epoch: 80
2022-12-05 23:28:36,762 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5410661446777257, 'Total loss': 0.5410661446777257} | train loss {'Reaction outcome loss': 0.5075255479769185, 'Total loss': 0.5075255479769185}
2022-12-05 23:28:36,762 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:36,763 INFO:     Epoch: 81
2022-12-05 23:28:37,478 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4888473776253787, 'Total loss': 0.4888473776253787} | train loss {'Reaction outcome loss': 0.5176191190964644, 'Total loss': 0.5176191190964644}
2022-12-05 23:28:37,479 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:37,479 INFO:     Epoch: 82
2022-12-05 23:28:38,189 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4887701692906293, 'Total loss': 0.4887701692906293} | train loss {'Reaction outcome loss': 0.50421384845668, 'Total loss': 0.50421384845668}
2022-12-05 23:28:38,189 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:38,189 INFO:     Epoch: 83
2022-12-05 23:28:38,899 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5446531874212351, 'Total loss': 0.5446531874212351} | train loss {'Reaction outcome loss': 0.5098457093904858, 'Total loss': 0.5098457093904858}
2022-12-05 23:28:38,900 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:38,900 INFO:     Epoch: 84
2022-12-05 23:28:39,610 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5191458064046773, 'Total loss': 0.5191458064046773} | train loss {'Reaction outcome loss': 0.5104431940717735, 'Total loss': 0.5104431940717735}
2022-12-05 23:28:39,610 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:39,610 INFO:     Epoch: 85
2022-12-05 23:28:40,321 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4932600530711087, 'Total loss': 0.4932600530711087} | train loss {'Reaction outcome loss': 0.509922646076573, 'Total loss': 0.509922646076573}
2022-12-05 23:28:40,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:40,322 INFO:     Epoch: 86
2022-12-05 23:28:41,033 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49736198444258084, 'Total loss': 0.49736198444258084} | train loss {'Reaction outcome loss': 0.5177779913793209, 'Total loss': 0.5177779913793209}
2022-12-05 23:28:41,033 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:41,033 INFO:     Epoch: 87
2022-12-05 23:28:41,746 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.48750626905397937, 'Total loss': 0.48750626905397937} | train loss {'Reaction outcome loss': 0.5121778564109101, 'Total loss': 0.5121778564109101}
2022-12-05 23:28:41,746 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:41,746 INFO:     Epoch: 88
2022-12-05 23:28:42,457 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4881441549144008, 'Total loss': 0.4881441549144008} | train loss {'Reaction outcome loss': 0.520582119794751, 'Total loss': 0.520582119794751}
2022-12-05 23:28:42,457 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:42,457 INFO:     Epoch: 89
2022-12-05 23:28:43,168 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5178965445269238, 'Total loss': 0.5178965445269238} | train loss {'Reaction outcome loss': 0.5111530261483752, 'Total loss': 0.5111530261483752}
2022-12-05 23:28:43,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:43,168 INFO:     Epoch: 90
2022-12-05 23:28:43,878 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4869571070779454, 'Total loss': 0.4869571070779454} | train loss {'Reaction outcome loss': 0.520251684041641, 'Total loss': 0.520251684041641}
2022-12-05 23:28:43,878 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:43,878 INFO:     Epoch: 91
2022-12-05 23:28:44,589 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.499243212017146, 'Total loss': 0.499243212017146} | train loss {'Reaction outcome loss': 0.5023324849755175, 'Total loss': 0.5023324849755175}
2022-12-05 23:28:44,589 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:44,589 INFO:     Epoch: 92
2022-12-05 23:28:45,301 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.512246463786472, 'Total loss': 0.512246463786472} | train loss {'Reaction outcome loss': 0.5062463065300152, 'Total loss': 0.5062463065300152}
2022-12-05 23:28:45,301 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:45,301 INFO:     Epoch: 93
2022-12-05 23:28:46,029 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48264567079869186, 'Total loss': 0.48264567079869186} | train loss {'Reaction outcome loss': 0.5047307588190202, 'Total loss': 0.5047307588190202}
2022-12-05 23:28:46,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:46,029 INFO:     Epoch: 94
2022-12-05 23:28:46,747 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48850589990615845, 'Total loss': 0.48850589990615845} | train loss {'Reaction outcome loss': 0.5177870023682684, 'Total loss': 0.5177870023682684}
2022-12-05 23:28:46,747 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:46,747 INFO:     Epoch: 95
2022-12-05 23:28:47,463 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5470654944127257, 'Total loss': 0.5470654944127257} | train loss {'Reaction outcome loss': 0.49588624596113134, 'Total loss': 0.49588624596113134}
2022-12-05 23:28:47,463 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:47,464 INFO:     Epoch: 96
2022-12-05 23:28:48,174 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5030707161534916, 'Total loss': 0.5030707161534916} | train loss {'Reaction outcome loss': 0.5138391557070408, 'Total loss': 0.5138391557070408}
2022-12-05 23:28:48,175 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:48,175 INFO:     Epoch: 97
2022-12-05 23:28:48,885 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49474754904142837, 'Total loss': 0.49474754904142837} | train loss {'Reaction outcome loss': 0.5016169445249836, 'Total loss': 0.5016169445249836}
2022-12-05 23:28:48,885 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:48,885 INFO:     Epoch: 98
2022-12-05 23:28:49,602 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5326143713159994, 'Total loss': 0.5326143713159994} | train loss {'Reaction outcome loss': 0.5003723886452223, 'Total loss': 0.5003723886452223}
2022-12-05 23:28:49,602 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:49,602 INFO:     Epoch: 99
2022-12-05 23:28:50,313 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48659894175150176, 'Total loss': 0.48659894175150176} | train loss {'Reaction outcome loss': 0.5071744281150069, 'Total loss': 0.5071744281150069}
2022-12-05 23:28:50,313 INFO:     Best model found after epoch 77 of 100.
2022-12-05 23:28:50,313 INFO:   Done with stage: TRAINING
2022-12-05 23:28:50,313 INFO:   Starting stage: EVALUATION
2022-12-05 23:28:50,437 INFO:   Done with stage: EVALUATION
2022-12-05 23:28:50,446 INFO:   Leaving out SEQ value Fold_0
2022-12-05 23:28:50,458 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:28:50,458 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:28:51,102 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:28:51,102 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:28:51,173 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:28:51,173 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:28:51,173 INFO:     No hyperparam tuning for this model
2022-12-05 23:28:51,173 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:28:51,173 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:28:51,174 INFO:     None feature selector for col prot
2022-12-05 23:28:51,174 INFO:     None feature selector for col prot
2022-12-05 23:28:51,174 INFO:     None feature selector for col prot
2022-12-05 23:28:51,175 INFO:     None feature selector for col chem
2022-12-05 23:28:51,175 INFO:     None feature selector for col chem
2022-12-05 23:28:51,175 INFO:     None feature selector for col chem
2022-12-05 23:28:51,175 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:28:51,175 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:28:51,176 INFO:     Number of params in model 215731
2022-12-05 23:28:51,180 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:28:51,180 INFO:   Starting stage: TRAINING
2022-12-05 23:28:51,238 INFO:     Val loss before train {'Reaction outcome loss': 0.9765207225626166, 'Total loss': 0.9765207225626166}
2022-12-05 23:28:51,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:51,238 INFO:     Epoch: 0
2022-12-05 23:28:51,947 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7453425567258488, 'Total loss': 0.7453425567258488} | train loss {'Reaction outcome loss': 0.8176695676708994, 'Total loss': 0.8176695676708994}
2022-12-05 23:28:51,947 INFO:     Found new best model at epoch 0
2022-12-05 23:28:51,948 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:51,948 INFO:     Epoch: 1
2022-12-05 23:28:52,658 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6375036869536747, 'Total loss': 0.6375036869536747} | train loss {'Reaction outcome loss': 0.6831207226826111, 'Total loss': 0.6831207226826111}
2022-12-05 23:28:52,659 INFO:     Found new best model at epoch 1
2022-12-05 23:28:52,659 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:52,659 INFO:     Epoch: 2
2022-12-05 23:28:53,369 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6051354259252548, 'Total loss': 0.6051354259252548} | train loss {'Reaction outcome loss': 0.6279252870724752, 'Total loss': 0.6279252870724752}
2022-12-05 23:28:53,369 INFO:     Found new best model at epoch 2
2022-12-05 23:28:53,369 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:53,370 INFO:     Epoch: 3
2022-12-05 23:28:54,077 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5367623161185872, 'Total loss': 0.5367623161185872} | train loss {'Reaction outcome loss': 0.6093401638602438, 'Total loss': 0.6093401638602438}
2022-12-05 23:28:54,077 INFO:     Found new best model at epoch 3
2022-12-05 23:28:54,077 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:54,077 INFO:     Epoch: 4
2022-12-05 23:28:54,787 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5320504300973632, 'Total loss': 0.5320504300973632} | train loss {'Reaction outcome loss': 0.6048209492252906, 'Total loss': 0.6048209492252906}
2022-12-05 23:28:54,787 INFO:     Found new best model at epoch 4
2022-12-05 23:28:54,788 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:54,788 INFO:     Epoch: 5
2022-12-05 23:28:55,497 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5519879890436475, 'Total loss': 0.5519879890436475} | train loss {'Reaction outcome loss': 0.5804323887052806, 'Total loss': 0.5804323887052806}
2022-12-05 23:28:55,497 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:55,497 INFO:     Epoch: 6
2022-12-05 23:28:56,205 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5833045596426184, 'Total loss': 0.5833045596426184} | train loss {'Reaction outcome loss': 0.5849429550561828, 'Total loss': 0.5849429550561828}
2022-12-05 23:28:56,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:56,206 INFO:     Epoch: 7
2022-12-05 23:28:56,919 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5443289056420326, 'Total loss': 0.5443289056420326} | train loss {'Reaction outcome loss': 0.5812577430897878, 'Total loss': 0.5812577430897878}
2022-12-05 23:28:56,919 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:56,919 INFO:     Epoch: 8
2022-12-05 23:28:57,634 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5306253484026953, 'Total loss': 0.5306253484026953} | train loss {'Reaction outcome loss': 0.5667729558732345, 'Total loss': 0.5667729558732345}
2022-12-05 23:28:57,634 INFO:     Found new best model at epoch 8
2022-12-05 23:28:57,635 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:57,635 INFO:     Epoch: 9
2022-12-05 23:28:58,350 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5535171539946036, 'Total loss': 0.5535171539946036} | train loss {'Reaction outcome loss': 0.5610425885359527, 'Total loss': 0.5610425885359527}
2022-12-05 23:28:58,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:58,350 INFO:     Epoch: 10
2022-12-05 23:28:59,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5452416640791026, 'Total loss': 0.5452416640791026} | train loss {'Reaction outcome loss': 0.563621102195037, 'Total loss': 0.563621102195037}
2022-12-05 23:28:59,061 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:59,061 INFO:     Epoch: 11
2022-12-05 23:28:59,773 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.527899063446305, 'Total loss': 0.527899063446305} | train loss {'Reaction outcome loss': 0.5672209197089739, 'Total loss': 0.5672209197089739}
2022-12-05 23:28:59,774 INFO:     Found new best model at epoch 11
2022-12-05 23:28:59,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:28:59,774 INFO:     Epoch: 12
2022-12-05 23:29:00,488 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5605113309892741, 'Total loss': 0.5605113309892741} | train loss {'Reaction outcome loss': 0.5622986186491815, 'Total loss': 0.5622986186491815}
2022-12-05 23:29:00,488 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:00,488 INFO:     Epoch: 13
2022-12-05 23:29:01,200 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5289112038233064, 'Total loss': 0.5289112038233064} | train loss {'Reaction outcome loss': 0.5591323579009245, 'Total loss': 0.5591323579009245}
2022-12-05 23:29:01,201 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:01,201 INFO:     Epoch: 14
2022-12-05 23:29:01,910 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5734401961619203, 'Total loss': 0.5734401961619203} | train loss {'Reaction outcome loss': 0.5574500494399052, 'Total loss': 0.5574500494399052}
2022-12-05 23:29:01,911 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:01,911 INFO:     Epoch: 15
2022-12-05 23:29:02,621 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5308611806143414, 'Total loss': 0.5308611806143414} | train loss {'Reaction outcome loss': 0.5588254958149875, 'Total loss': 0.5588254958149875}
2022-12-05 23:29:02,621 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:02,621 INFO:     Epoch: 16
2022-12-05 23:29:03,330 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5195256549526345, 'Total loss': 0.5195256549526345} | train loss {'Reaction outcome loss': 0.546352711163069, 'Total loss': 0.546352711163069}
2022-12-05 23:29:03,330 INFO:     Found new best model at epoch 16
2022-12-05 23:29:03,331 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:03,331 INFO:     Epoch: 17
2022-12-05 23:29:04,041 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5379459207708185, 'Total loss': 0.5379459207708185} | train loss {'Reaction outcome loss': 0.5586227016742171, 'Total loss': 0.5586227016742171}
2022-12-05 23:29:04,041 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:04,041 INFO:     Epoch: 18
2022-12-05 23:29:04,756 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5235377279194918, 'Total loss': 0.5235377279194918} | train loss {'Reaction outcome loss': 0.5432975998050288, 'Total loss': 0.5432975998050288}
2022-12-05 23:29:04,756 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:04,756 INFO:     Epoch: 19
2022-12-05 23:29:05,472 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5066285844553601, 'Total loss': 0.5066285844553601} | train loss {'Reaction outcome loss': 0.5445513772337061, 'Total loss': 0.5445513772337061}
2022-12-05 23:29:05,472 INFO:     Found new best model at epoch 19
2022-12-05 23:29:05,473 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:05,473 INFO:     Epoch: 20
2022-12-05 23:29:06,183 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5256696390834722, 'Total loss': 0.5256696390834722} | train loss {'Reaction outcome loss': 0.5502181239954012, 'Total loss': 0.5502181239954012}
2022-12-05 23:29:06,183 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:06,183 INFO:     Epoch: 21
2022-12-05 23:29:06,893 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5154429911212488, 'Total loss': 0.5154429911212488} | train loss {'Reaction outcome loss': 0.5525457308842585, 'Total loss': 0.5525457308842585}
2022-12-05 23:29:06,894 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:06,894 INFO:     Epoch: 22
2022-12-05 23:29:07,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5153584890067577, 'Total loss': 0.5153584890067577} | train loss {'Reaction outcome loss': 0.5491675023095086, 'Total loss': 0.5491675023095086}
2022-12-05 23:29:07,605 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:07,605 INFO:     Epoch: 23
2022-12-05 23:29:08,315 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5206414921717211, 'Total loss': 0.5206414921717211} | train loss {'Reaction outcome loss': 0.537680782287227, 'Total loss': 0.537680782287227}
2022-12-05 23:29:08,315 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:08,315 INFO:     Epoch: 24
2022-12-05 23:29:09,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5646802230992101, 'Total loss': 0.5646802230992101} | train loss {'Reaction outcome loss': 0.5352064616781865, 'Total loss': 0.5352064616781865}
2022-12-05 23:29:09,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:09,029 INFO:     Epoch: 25
2022-12-05 23:29:09,743 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5544460727409883, 'Total loss': 0.5544460727409883} | train loss {'Reaction outcome loss': 0.5535297934342975, 'Total loss': 0.5535297934342975}
2022-12-05 23:29:09,743 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:09,744 INFO:     Epoch: 26
2022-12-05 23:29:10,455 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.513542060486295, 'Total loss': 0.513542060486295} | train loss {'Reaction outcome loss': 0.5439310909403481, 'Total loss': 0.5439310909403481}
2022-12-05 23:29:10,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:10,455 INFO:     Epoch: 27
2022-12-05 23:29:11,172 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5273862257599831, 'Total loss': 0.5273862257599831} | train loss {'Reaction outcome loss': 0.5467529692630536, 'Total loss': 0.5467529692630536}
2022-12-05 23:29:11,172 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:11,172 INFO:     Epoch: 28
2022-12-05 23:29:11,885 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5292617570270192, 'Total loss': 0.5292617570270192} | train loss {'Reaction outcome loss': 0.5333182138470021, 'Total loss': 0.5333182138470021}
2022-12-05 23:29:11,885 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:11,885 INFO:     Epoch: 29
2022-12-05 23:29:12,596 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5203995948488062, 'Total loss': 0.5203995948488062} | train loss {'Reaction outcome loss': 0.5399119522166156, 'Total loss': 0.5399119522166156}
2022-12-05 23:29:12,597 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:12,597 INFO:     Epoch: 30
2022-12-05 23:29:13,308 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5311042510650374, 'Total loss': 0.5311042510650374} | train loss {'Reaction outcome loss': 0.5426296735944053, 'Total loss': 0.5426296735944053}
2022-12-05 23:29:13,308 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:13,308 INFO:     Epoch: 31
2022-12-05 23:29:14,018 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5141213898631659, 'Total loss': 0.5141213898631659} | train loss {'Reaction outcome loss': 0.5463582806379689, 'Total loss': 0.5463582806379689}
2022-12-05 23:29:14,018 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:14,018 INFO:     Epoch: 32
2022-12-05 23:29:14,727 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.518166992474686, 'Total loss': 0.518166992474686} | train loss {'Reaction outcome loss': 0.5380177873710872, 'Total loss': 0.5380177873710872}
2022-12-05 23:29:14,727 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:14,728 INFO:     Epoch: 33
2022-12-05 23:29:15,438 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5087764886292544, 'Total loss': 0.5087764886292544} | train loss {'Reaction outcome loss': 0.5320652565628532, 'Total loss': 0.5320652565628532}
2022-12-05 23:29:15,438 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:15,438 INFO:     Epoch: 34
2022-12-05 23:29:16,149 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4974926886233417, 'Total loss': 0.4974926886233417} | train loss {'Reaction outcome loss': 0.5361427113937915, 'Total loss': 0.5361427113937915}
2022-12-05 23:29:16,149 INFO:     Found new best model at epoch 34
2022-12-05 23:29:16,149 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:16,150 INFO:     Epoch: 35
2022-12-05 23:29:16,861 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5002102709629319, 'Total loss': 0.5002102709629319} | train loss {'Reaction outcome loss': 0.5356239274083844, 'Total loss': 0.5356239274083844}
2022-12-05 23:29:16,861 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:16,861 INFO:     Epoch: 36
2022-12-05 23:29:17,572 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5398405800488862, 'Total loss': 0.5398405800488862} | train loss {'Reaction outcome loss': 0.5339610218994228, 'Total loss': 0.5339610218994228}
2022-12-05 23:29:17,572 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:17,573 INFO:     Epoch: 37
2022-12-05 23:29:18,283 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49830626154487784, 'Total loss': 0.49830626154487784} | train loss {'Reaction outcome loss': 0.5407554782353915, 'Total loss': 0.5407554782353915}
2022-12-05 23:29:18,283 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:18,283 INFO:     Epoch: 38
2022-12-05 23:29:18,993 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5073258165608753, 'Total loss': 0.5073258165608753} | train loss {'Reaction outcome loss': 0.539751045647179, 'Total loss': 0.539751045647179}
2022-12-05 23:29:18,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:18,994 INFO:     Epoch: 39
2022-12-05 23:29:19,704 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.523640900850296, 'Total loss': 0.523640900850296} | train loss {'Reaction outcome loss': 0.5366347566066001, 'Total loss': 0.5366347566066001}
2022-12-05 23:29:19,705 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:19,705 INFO:     Epoch: 40
2022-12-05 23:29:20,420 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5125557661733844, 'Total loss': 0.5125557661733844} | train loss {'Reaction outcome loss': 0.5399442755500314, 'Total loss': 0.5399442755500314}
2022-12-05 23:29:20,420 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:20,420 INFO:     Epoch: 41
2022-12-05 23:29:21,133 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.49990535171871836, 'Total loss': 0.49990535171871836} | train loss {'Reaction outcome loss': 0.5411012943396684, 'Total loss': 0.5411012943396684}
2022-12-05 23:29:21,133 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:21,133 INFO:     Epoch: 42
2022-12-05 23:29:21,848 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.50144628028978, 'Total loss': 0.50144628028978} | train loss {'Reaction outcome loss': 0.5356927918881057, 'Total loss': 0.5356927918881057}
2022-12-05 23:29:21,848 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:21,848 INFO:     Epoch: 43
2022-12-05 23:29:22,563 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5302133268930695, 'Total loss': 0.5302133268930695} | train loss {'Reaction outcome loss': 0.5389819084874049, 'Total loss': 0.5389819084874049}
2022-12-05 23:29:22,563 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:22,563 INFO:     Epoch: 44
2022-12-05 23:29:23,279 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5049201111224565, 'Total loss': 0.5049201111224565} | train loss {'Reaction outcome loss': 0.536796020170455, 'Total loss': 0.536796020170455}
2022-12-05 23:29:23,279 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:23,280 INFO:     Epoch: 45
2022-12-05 23:29:23,990 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5439554405483332, 'Total loss': 0.5439554405483332} | train loss {'Reaction outcome loss': 0.5343798432755567, 'Total loss': 0.5343798432755567}
2022-12-05 23:29:23,990 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:23,990 INFO:     Epoch: 46
2022-12-05 23:29:24,703 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.513369286263531, 'Total loss': 0.513369286263531} | train loss {'Reaction outcome loss': 0.5300426273210811, 'Total loss': 0.5300426273210811}
2022-12-05 23:29:24,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:24,703 INFO:     Epoch: 47
2022-12-05 23:29:25,414 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5009602789174427, 'Total loss': 0.5009602789174427} | train loss {'Reaction outcome loss': 0.5301138010961928, 'Total loss': 0.5301138010961928}
2022-12-05 23:29:25,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:25,414 INFO:     Epoch: 48
2022-12-05 23:29:26,124 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4926786151799289, 'Total loss': 0.4926786151799289} | train loss {'Reaction outcome loss': 0.5360417561492457, 'Total loss': 0.5360417561492457}
2022-12-05 23:29:26,125 INFO:     Found new best model at epoch 48
2022-12-05 23:29:26,126 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:26,126 INFO:     Epoch: 49
2022-12-05 23:29:26,835 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48606031760573387, 'Total loss': 0.48606031760573387} | train loss {'Reaction outcome loss': 0.5306398237660445, 'Total loss': 0.5306398237660445}
2022-12-05 23:29:26,835 INFO:     Found new best model at epoch 49
2022-12-05 23:29:26,836 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:26,836 INFO:     Epoch: 50
2022-12-05 23:29:27,547 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4883939285169948, 'Total loss': 0.4883939285169948} | train loss {'Reaction outcome loss': 0.5331311079895931, 'Total loss': 0.5331311079895931}
2022-12-05 23:29:27,547 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:27,547 INFO:     Epoch: 51
2022-12-05 23:29:28,261 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49252392758022656, 'Total loss': 0.49252392758022656} | train loss {'Reaction outcome loss': 0.5312886928219483, 'Total loss': 0.5312886928219483}
2022-12-05 23:29:28,261 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:28,261 INFO:     Epoch: 52
2022-12-05 23:29:28,971 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49192576144229283, 'Total loss': 0.49192576144229283} | train loss {'Reaction outcome loss': 0.5295561199728777, 'Total loss': 0.5295561199728777}
2022-12-05 23:29:28,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:28,971 INFO:     Epoch: 53
2022-12-05 23:29:29,680 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5508362813429399, 'Total loss': 0.5508362813429399} | train loss {'Reaction outcome loss': 0.5315900321310831, 'Total loss': 0.5315900321310831}
2022-12-05 23:29:29,680 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:29,680 INFO:     Epoch: 54
2022-12-05 23:29:30,391 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5212368474087932, 'Total loss': 0.5212368474087932} | train loss {'Reaction outcome loss': 0.5273085293786125, 'Total loss': 0.5273085293786125}
2022-12-05 23:29:30,391 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:30,391 INFO:     Epoch: 55
2022-12-05 23:29:31,101 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5056800551035188, 'Total loss': 0.5056800551035188} | train loss {'Reaction outcome loss': 0.53574931814603, 'Total loss': 0.53574931814603}
2022-12-05 23:29:31,101 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:31,101 INFO:     Epoch: 56
2022-12-05 23:29:31,814 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5214637788859281, 'Total loss': 0.5214637788859281} | train loss {'Reaction outcome loss': 0.530295344258127, 'Total loss': 0.530295344258127}
2022-12-05 23:29:31,814 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:31,815 INFO:     Epoch: 57
2022-12-05 23:29:32,529 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48265836387872696, 'Total loss': 0.48265836387872696} | train loss {'Reaction outcome loss': 0.5314266646982204, 'Total loss': 0.5314266646982204}
2022-12-05 23:29:32,529 INFO:     Found new best model at epoch 57
2022-12-05 23:29:32,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:32,530 INFO:     Epoch: 58
2022-12-05 23:29:33,242 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5087620263749902, 'Total loss': 0.5087620263749902} | train loss {'Reaction outcome loss': 0.524269710004571, 'Total loss': 0.524269710004571}
2022-12-05 23:29:33,242 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:33,242 INFO:     Epoch: 59
2022-12-05 23:29:33,952 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5046490986238826, 'Total loss': 0.5046490986238826} | train loss {'Reaction outcome loss': 0.5219423761251967, 'Total loss': 0.5219423761251967}
2022-12-05 23:29:33,952 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:33,952 INFO:     Epoch: 60
2022-12-05 23:29:34,665 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5346142094243657, 'Total loss': 0.5346142094243657} | train loss {'Reaction outcome loss': 0.5333378862755501, 'Total loss': 0.5333378862755501}
2022-12-05 23:29:34,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:34,665 INFO:     Epoch: 61
2022-12-05 23:29:35,374 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4864110956815156, 'Total loss': 0.4864110956815156} | train loss {'Reaction outcome loss': 0.5359465762490203, 'Total loss': 0.5359465762490203}
2022-12-05 23:29:35,375 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:35,375 INFO:     Epoch: 62
2022-12-05 23:29:36,091 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5288855877112258, 'Total loss': 0.5288855877112258} | train loss {'Reaction outcome loss': 0.523343589564084, 'Total loss': 0.523343589564084}
2022-12-05 23:29:36,091 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:36,091 INFO:     Epoch: 63
2022-12-05 23:29:36,805 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5111311477693644, 'Total loss': 0.5111311477693644} | train loss {'Reaction outcome loss': 0.5242957806418299, 'Total loss': 0.5242957806418299}
2022-12-05 23:29:36,805 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:36,805 INFO:     Epoch: 64
2022-12-05 23:29:37,515 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5104158439419486, 'Total loss': 0.5104158439419486} | train loss {'Reaction outcome loss': 0.5234490779458512, 'Total loss': 0.5234490779458512}
2022-12-05 23:29:37,515 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:37,515 INFO:     Epoch: 65
2022-12-05 23:29:38,226 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5151287244463508, 'Total loss': 0.5151287244463508} | train loss {'Reaction outcome loss': 0.5409993303690844, 'Total loss': 0.5409993303690844}
2022-12-05 23:29:38,227 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:38,227 INFO:     Epoch: 66
2022-12-05 23:29:38,936 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5443119291554798, 'Total loss': 0.5443119291554798} | train loss {'Reaction outcome loss': 0.53951207949565, 'Total loss': 0.53951207949565}
2022-12-05 23:29:38,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:38,936 INFO:     Epoch: 67
2022-12-05 23:29:39,649 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5189332020553675, 'Total loss': 0.5189332020553675} | train loss {'Reaction outcome loss': 0.5334708768712274, 'Total loss': 0.5334708768712274}
2022-12-05 23:29:39,649 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:39,650 INFO:     Epoch: 68
2022-12-05 23:29:40,361 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4800267761403864, 'Total loss': 0.4800267761403864} | train loss {'Reaction outcome loss': 0.5335291249428683, 'Total loss': 0.5335291249428683}
2022-12-05 23:29:40,361 INFO:     Found new best model at epoch 68
2022-12-05 23:29:40,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:40,362 INFO:     Epoch: 69
2022-12-05 23:29:41,072 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.48432130366563797, 'Total loss': 0.48432130366563797} | train loss {'Reaction outcome loss': 0.5242592584990297, 'Total loss': 0.5242592584990297}
2022-12-05 23:29:41,072 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:41,072 INFO:     Epoch: 70
2022-12-05 23:29:41,782 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5203536979176782, 'Total loss': 0.5203536979176782} | train loss {'Reaction outcome loss': 0.520372062921524, 'Total loss': 0.520372062921524}
2022-12-05 23:29:41,783 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:41,783 INFO:     Epoch: 71
2022-12-05 23:29:42,495 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49047274921428075, 'Total loss': 0.49047274921428075} | train loss {'Reaction outcome loss': 0.5247151236905743, 'Total loss': 0.5247151236905743}
2022-12-05 23:29:42,495 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:42,495 INFO:     Epoch: 72
2022-12-05 23:29:43,205 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4916869100521911, 'Total loss': 0.4916869100521911} | train loss {'Reaction outcome loss': 0.5282305607719249, 'Total loss': 0.5282305607719249}
2022-12-05 23:29:43,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:43,206 INFO:     Epoch: 73
2022-12-05 23:29:43,917 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4801382612098347, 'Total loss': 0.4801382612098347} | train loss {'Reaction outcome loss': 0.5219172596448829, 'Total loss': 0.5219172596448829}
2022-12-05 23:29:43,917 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:43,917 INFO:     Epoch: 74
2022-12-05 23:29:44,630 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.48825831000100484, 'Total loss': 0.48825831000100484} | train loss {'Reaction outcome loss': 0.5251021354425291, 'Total loss': 0.5251021354425291}
2022-12-05 23:29:44,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:44,630 INFO:     Epoch: 75
2022-12-05 23:29:45,344 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49469739266417245, 'Total loss': 0.49469739266417245} | train loss {'Reaction outcome loss': 0.5388249216171411, 'Total loss': 0.5388249216171411}
2022-12-05 23:29:45,344 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:45,344 INFO:     Epoch: 76
2022-12-05 23:29:46,065 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47288815067573026, 'Total loss': 0.47288815067573026} | train loss {'Reaction outcome loss': 0.5254418179392815, 'Total loss': 0.5254418179392815}
2022-12-05 23:29:46,065 INFO:     Found new best model at epoch 76
2022-12-05 23:29:46,066 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:46,066 INFO:     Epoch: 77
2022-12-05 23:29:46,776 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5123175355521116, 'Total loss': 0.5123175355521116} | train loss {'Reaction outcome loss': 0.5191884005615707, 'Total loss': 0.5191884005615707}
2022-12-05 23:29:46,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:46,776 INFO:     Epoch: 78
2022-12-05 23:29:47,493 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.48165767978538165, 'Total loss': 0.48165767978538165} | train loss {'Reaction outcome loss': 0.53120768281371, 'Total loss': 0.53120768281371}
2022-12-05 23:29:47,493 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:47,493 INFO:     Epoch: 79
2022-12-05 23:29:48,208 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49408613179217686, 'Total loss': 0.49408613179217686} | train loss {'Reaction outcome loss': 0.5228810455755666, 'Total loss': 0.5228810455755666}
2022-12-05 23:29:48,208 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:48,208 INFO:     Epoch: 80
2022-12-05 23:29:48,920 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.544153724543073, 'Total loss': 0.544153724543073} | train loss {'Reaction outcome loss': 0.5264736605197312, 'Total loss': 0.5264736605197312}
2022-12-05 23:29:48,920 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:48,920 INFO:     Epoch: 81
2022-12-05 23:29:49,630 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4888168309222568, 'Total loss': 0.4888168309222568} | train loss {'Reaction outcome loss': 0.5226784232119663, 'Total loss': 0.5226784232119663}
2022-12-05 23:29:49,630 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:49,630 INFO:     Epoch: 82
2022-12-05 23:29:50,342 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.47317556833679025, 'Total loss': 0.47317556833679025} | train loss {'Reaction outcome loss': 0.5176157524228578, 'Total loss': 0.5176157524228578}
2022-12-05 23:29:50,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:50,343 INFO:     Epoch: 83
2022-12-05 23:29:51,058 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5088707012209025, 'Total loss': 0.5088707012209025} | train loss {'Reaction outcome loss': 0.5193585998374923, 'Total loss': 0.5193585998374923}
2022-12-05 23:29:51,058 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:51,058 INFO:     Epoch: 84
2022-12-05 23:29:51,767 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5032122053883292, 'Total loss': 0.5032122053883292} | train loss {'Reaction outcome loss': 0.5283002635004067, 'Total loss': 0.5283002635004067}
2022-12-05 23:29:51,767 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:51,767 INFO:     Epoch: 85
2022-12-05 23:29:52,477 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5569249886003408, 'Total loss': 0.5569249886003408} | train loss {'Reaction outcome loss': 0.5275026937486672, 'Total loss': 0.5275026937486672}
2022-12-05 23:29:52,477 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:52,477 INFO:     Epoch: 86
2022-12-05 23:29:53,187 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49712943929162895, 'Total loss': 0.49712943929162895} | train loss {'Reaction outcome loss': 0.5313089910907829, 'Total loss': 0.5313089910907829}
2022-12-05 23:29:53,187 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:53,187 INFO:     Epoch: 87
2022-12-05 23:29:53,896 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4793587364256382, 'Total loss': 0.4793587364256382} | train loss {'Reaction outcome loss': 0.5242794536144627, 'Total loss': 0.5242794536144627}
2022-12-05 23:29:53,896 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:53,896 INFO:     Epoch: 88
2022-12-05 23:29:54,607 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6495909257368608, 'Total loss': 0.6495909257368608} | train loss {'Reaction outcome loss': 0.5370152817081343, 'Total loss': 0.5370152817081343}
2022-12-05 23:29:54,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:54,608 INFO:     Epoch: 89
2022-12-05 23:29:55,320 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5163781246678396, 'Total loss': 0.5163781246678396} | train loss {'Reaction outcome loss': 0.5310195170433415, 'Total loss': 0.5310195170433415}
2022-12-05 23:29:55,320 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:55,320 INFO:     Epoch: 90
2022-12-05 23:29:56,033 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4823423464867202, 'Total loss': 0.4823423464867202} | train loss {'Reaction outcome loss': 0.5263556584052229, 'Total loss': 0.5263556584052229}
2022-12-05 23:29:56,034 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:56,034 INFO:     Epoch: 91
2022-12-05 23:29:56,745 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4968332187695937, 'Total loss': 0.4968332187695937} | train loss {'Reaction outcome loss': 0.5192803847320709, 'Total loss': 0.5192803847320709}
2022-12-05 23:29:56,746 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:56,746 INFO:     Epoch: 92
2022-12-05 23:29:57,456 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5200032026252963, 'Total loss': 0.5200032026252963} | train loss {'Reaction outcome loss': 0.5184076207610759, 'Total loss': 0.5184076207610759}
2022-12-05 23:29:57,456 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:57,456 INFO:     Epoch: 93
2022-12-05 23:29:58,166 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48602882196957414, 'Total loss': 0.48602882196957414} | train loss {'Reaction outcome loss': 0.5256924740291438, 'Total loss': 0.5256924740291438}
2022-12-05 23:29:58,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:58,166 INFO:     Epoch: 94
2022-12-05 23:29:58,880 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5406877831979231, 'Total loss': 0.5406877831979231} | train loss {'Reaction outcome loss': 0.5205655362200641, 'Total loss': 0.5205655362200641}
2022-12-05 23:29:58,880 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:58,880 INFO:     Epoch: 95
2022-12-05 23:29:59,597 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49426237934015016, 'Total loss': 0.49426237934015016} | train loss {'Reaction outcome loss': 0.5315089712620746, 'Total loss': 0.5315089712620746}
2022-12-05 23:29:59,597 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:29:59,597 INFO:     Epoch: 96
2022-12-05 23:30:00,309 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5006963055242192, 'Total loss': 0.5006963055242192} | train loss {'Reaction outcome loss': 0.5334213325369214, 'Total loss': 0.5334213325369214}
2022-12-05 23:30:00,309 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:00,309 INFO:     Epoch: 97
2022-12-05 23:30:01,022 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49545352770523593, 'Total loss': 0.49545352770523593} | train loss {'Reaction outcome loss': 0.5332694815599966, 'Total loss': 0.5332694815599966}
2022-12-05 23:30:01,022 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:01,023 INFO:     Epoch: 98
2022-12-05 23:30:01,736 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47799096561291, 'Total loss': 0.47799096561291} | train loss {'Reaction outcome loss': 0.5140067129603282, 'Total loss': 0.5140067129603282}
2022-12-05 23:30:01,736 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:01,736 INFO:     Epoch: 99
2022-12-05 23:30:02,447 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49976820227774704, 'Total loss': 0.49976820227774704} | train loss {'Reaction outcome loss': 0.5298121674401075, 'Total loss': 0.5298121674401075}
2022-12-05 23:30:02,447 INFO:     Best model found after epoch 77 of 100.
2022-12-05 23:30:02,447 INFO:   Done with stage: TRAINING
2022-12-05 23:30:02,447 INFO:   Starting stage: EVALUATION
2022-12-05 23:30:02,571 INFO:   Done with stage: EVALUATION
2022-12-05 23:30:02,572 INFO:   Leaving out SEQ value Fold_1
2022-12-05 23:30:02,585 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:30:02,585 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:30:03,233 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:30:03,233 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:30:03,304 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:30:03,304 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:30:03,304 INFO:     No hyperparam tuning for this model
2022-12-05 23:30:03,304 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:30:03,305 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:30:03,305 INFO:     None feature selector for col prot
2022-12-05 23:30:03,305 INFO:     None feature selector for col prot
2022-12-05 23:30:03,305 INFO:     None feature selector for col prot
2022-12-05 23:30:03,306 INFO:     None feature selector for col chem
2022-12-05 23:30:03,306 INFO:     None feature selector for col chem
2022-12-05 23:30:03,306 INFO:     None feature selector for col chem
2022-12-05 23:30:03,306 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:30:03,306 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:30:03,308 INFO:     Number of params in model 215731
2022-12-05 23:30:03,311 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:30:03,311 INFO:   Starting stage: TRAINING
2022-12-05 23:30:03,370 INFO:     Val loss before train {'Reaction outcome loss': 0.9853230362588709, 'Total loss': 0.9853230362588709}
2022-12-05 23:30:03,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:03,370 INFO:     Epoch: 0
2022-12-05 23:30:04,079 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7045958631417968, 'Total loss': 0.7045958631417968} | train loss {'Reaction outcome loss': 0.8082706224067733, 'Total loss': 0.8082706224067733}
2022-12-05 23:30:04,079 INFO:     Found new best model at epoch 0
2022-12-05 23:30:04,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:04,080 INFO:     Epoch: 1
2022-12-05 23:30:04,795 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6961399709636514, 'Total loss': 0.6961399709636514} | train loss {'Reaction outcome loss': 0.6676980761984582, 'Total loss': 0.6676980761984582}
2022-12-05 23:30:04,795 INFO:     Found new best model at epoch 1
2022-12-05 23:30:04,796 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:04,796 INFO:     Epoch: 2
2022-12-05 23:30:05,508 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6098813583905046, 'Total loss': 0.6098813583905046} | train loss {'Reaction outcome loss': 0.6278148697093431, 'Total loss': 0.6278148697093431}
2022-12-05 23:30:05,508 INFO:     Found new best model at epoch 2
2022-12-05 23:30:05,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:05,509 INFO:     Epoch: 3
2022-12-05 23:30:06,221 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6612358967011626, 'Total loss': 0.6612358967011626} | train loss {'Reaction outcome loss': 0.6059966209808342, 'Total loss': 0.6059966209808342}
2022-12-05 23:30:06,222 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:06,222 INFO:     Epoch: 4
2022-12-05 23:30:06,931 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5704949227246371, 'Total loss': 0.5704949227246371} | train loss {'Reaction outcome loss': 0.6139756316839442, 'Total loss': 0.6139756316839442}
2022-12-05 23:30:06,931 INFO:     Found new best model at epoch 4
2022-12-05 23:30:06,932 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:06,932 INFO:     Epoch: 5
2022-12-05 23:30:07,641 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6174691502343524, 'Total loss': 0.6174691502343524} | train loss {'Reaction outcome loss': 0.5725184861223708, 'Total loss': 0.5725184861223708}
2022-12-05 23:30:07,641 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:07,641 INFO:     Epoch: 6
2022-12-05 23:30:08,352 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5392713208090175, 'Total loss': 0.5392713208090175} | train loss {'Reaction outcome loss': 0.5684304180807671, 'Total loss': 0.5684304180807671}
2022-12-05 23:30:08,352 INFO:     Found new best model at epoch 6
2022-12-05 23:30:08,353 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:08,353 INFO:     Epoch: 7
2022-12-05 23:30:09,062 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5515694245696068, 'Total loss': 0.5515694245696068} | train loss {'Reaction outcome loss': 0.5633780850693282, 'Total loss': 0.5633780850693282}
2022-12-05 23:30:09,063 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:09,063 INFO:     Epoch: 8
2022-12-05 23:30:09,773 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.521558093753728, 'Total loss': 0.521558093753728} | train loss {'Reaction outcome loss': 0.5649923311795301, 'Total loss': 0.5649923311795301}
2022-12-05 23:30:09,773 INFO:     Found new best model at epoch 8
2022-12-05 23:30:09,773 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:09,774 INFO:     Epoch: 9
2022-12-05 23:30:10,483 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5476515171202746, 'Total loss': 0.5476515171202746} | train loss {'Reaction outcome loss': 0.5541041979664251, 'Total loss': 0.5541041979664251}
2022-12-05 23:30:10,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:10,484 INFO:     Epoch: 10
2022-12-05 23:30:11,194 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5648519396781921, 'Total loss': 0.5648519396781921} | train loss {'Reaction outcome loss': 0.5520517273395047, 'Total loss': 0.5520517273395047}
2022-12-05 23:30:11,194 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:11,194 INFO:     Epoch: 11
2022-12-05 23:30:11,903 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5288894962180745, 'Total loss': 0.5288894962180745} | train loss {'Reaction outcome loss': 0.5429083941285668, 'Total loss': 0.5429083941285668}
2022-12-05 23:30:11,903 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:11,903 INFO:     Epoch: 12
2022-12-05 23:30:12,613 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5735231299291957, 'Total loss': 0.5735231299291957} | train loss {'Reaction outcome loss': 0.5468929409377488, 'Total loss': 0.5468929409377488}
2022-12-05 23:30:12,613 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:12,613 INFO:     Epoch: 13
2022-12-05 23:30:13,324 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5870562459934842, 'Total loss': 0.5870562459934842} | train loss {'Reaction outcome loss': 0.5624180421353835, 'Total loss': 0.5624180421353835}
2022-12-05 23:30:13,324 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:13,324 INFO:     Epoch: 14
2022-12-05 23:30:14,034 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5472832295027646, 'Total loss': 0.5472832295027646} | train loss {'Reaction outcome loss': 0.543087782587117, 'Total loss': 0.543087782587117}
2022-12-05 23:30:14,034 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:14,034 INFO:     Epoch: 15
2022-12-05 23:30:14,745 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6314266093752601, 'Total loss': 0.6314266093752601} | train loss {'Reaction outcome loss': 0.543776550514978, 'Total loss': 0.543776550514978}
2022-12-05 23:30:14,745 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:14,745 INFO:     Epoch: 16
2022-12-05 23:30:15,456 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5763375379822471, 'Total loss': 0.5763375379822471} | train loss {'Reaction outcome loss': 0.5556496100628424, 'Total loss': 0.5556496100628424}
2022-12-05 23:30:15,456 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:15,456 INFO:     Epoch: 17
2022-12-05 23:30:16,165 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5154096612876112, 'Total loss': 0.5154096612876112} | train loss {'Reaction outcome loss': 0.5498160832082695, 'Total loss': 0.5498160832082695}
2022-12-05 23:30:16,166 INFO:     Found new best model at epoch 17
2022-12-05 23:30:16,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:16,166 INFO:     Epoch: 18
2022-12-05 23:30:16,877 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5328885956921361, 'Total loss': 0.5328885956921361} | train loss {'Reaction outcome loss': 0.54683473211551, 'Total loss': 0.54683473211551}
2022-12-05 23:30:16,877 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:16,878 INFO:     Epoch: 19
2022-12-05 23:30:17,586 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5857634869488803, 'Total loss': 0.5857634869488803} | train loss {'Reaction outcome loss': 0.5414259240694856, 'Total loss': 0.5414259240694856}
2022-12-05 23:30:17,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:17,586 INFO:     Epoch: 20
2022-12-05 23:30:18,296 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.574278093197129, 'Total loss': 0.574278093197129} | train loss {'Reaction outcome loss': 0.5445765916273179, 'Total loss': 0.5445765916273179}
2022-12-05 23:30:18,297 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:18,297 INFO:     Epoch: 21
2022-12-05 23:30:19,007 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5345654487609863, 'Total loss': 0.5345654487609863} | train loss {'Reaction outcome loss': 0.5361588614189673, 'Total loss': 0.5361588614189673}
2022-12-05 23:30:19,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:19,007 INFO:     Epoch: 22
2022-12-05 23:30:19,717 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5307462459260767, 'Total loss': 0.5307462459260767} | train loss {'Reaction outcome loss': 0.5433667687028043, 'Total loss': 0.5433667687028043}
2022-12-05 23:30:19,717 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:19,717 INFO:     Epoch: 23
2022-12-05 23:30:20,430 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5498253692957488, 'Total loss': 0.5498253692957488} | train loss {'Reaction outcome loss': 0.5436043598753239, 'Total loss': 0.5436043598753239}
2022-12-05 23:30:20,431 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:20,431 INFO:     Epoch: 24
2022-12-05 23:30:21,145 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5902126668529077, 'Total loss': 0.5902126668529077} | train loss {'Reaction outcome loss': 0.5414185583108833, 'Total loss': 0.5414185583108833}
2022-12-05 23:30:21,145 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:21,145 INFO:     Epoch: 25
2022-12-05 23:30:21,855 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5233917974612929, 'Total loss': 0.5233917974612929} | train loss {'Reaction outcome loss': 0.5370008053205274, 'Total loss': 0.5370008053205274}
2022-12-05 23:30:21,856 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:21,856 INFO:     Epoch: 26
2022-12-05 23:30:22,569 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.564482206986709, 'Total loss': 0.564482206986709} | train loss {'Reaction outcome loss': 0.5365133734763061, 'Total loss': 0.5365133734763061}
2022-12-05 23:30:22,570 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:22,570 INFO:     Epoch: 27
2022-12-05 23:30:23,283 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5443079471588135, 'Total loss': 0.5443079471588135} | train loss {'Reaction outcome loss': 0.5272591172562919, 'Total loss': 0.5272591172562919}
2022-12-05 23:30:23,283 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:23,283 INFO:     Epoch: 28
2022-12-05 23:30:23,993 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5252816175872629, 'Total loss': 0.5252816175872629} | train loss {'Reaction outcome loss': 0.5359625877277089, 'Total loss': 0.5359625877277089}
2022-12-05 23:30:23,993 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:23,993 INFO:     Epoch: 29
2022-12-05 23:30:24,703 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5265768935734575, 'Total loss': 0.5265768935734575} | train loss {'Reaction outcome loss': 0.5405774333699029, 'Total loss': 0.5405774333699029}
2022-12-05 23:30:24,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:24,703 INFO:     Epoch: 30
2022-12-05 23:30:25,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5287013656713746, 'Total loss': 0.5287013656713746} | train loss {'Reaction outcome loss': 0.5307674013070671, 'Total loss': 0.5307674013070671}
2022-12-05 23:30:25,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:25,414 INFO:     Epoch: 31
2022-12-05 23:30:26,124 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5293222225525163, 'Total loss': 0.5293222225525163} | train loss {'Reaction outcome loss': 0.5378955319101512, 'Total loss': 0.5378955319101512}
2022-12-05 23:30:26,124 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:26,124 INFO:     Epoch: 32
2022-12-05 23:30:26,835 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5295095680789514, 'Total loss': 0.5295095680789514} | train loss {'Reaction outcome loss': 0.5414315166502346, 'Total loss': 0.5414315166502346}
2022-12-05 23:30:26,835 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:26,835 INFO:     Epoch: 33
2022-12-05 23:30:27,545 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5780615173280239, 'Total loss': 0.5780615173280239} | train loss {'Reaction outcome loss': 0.5412195625937419, 'Total loss': 0.5412195625937419}
2022-12-05 23:30:27,545 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:27,545 INFO:     Epoch: 34
2022-12-05 23:30:28,259 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5651594258167527, 'Total loss': 0.5651594258167527} | train loss {'Reaction outcome loss': 0.5348374249964107, 'Total loss': 0.5348374249964107}
2022-12-05 23:30:28,260 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:28,260 INFO:     Epoch: 35
2022-12-05 23:30:28,971 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5214746431870894, 'Total loss': 0.5214746431870894} | train loss {'Reaction outcome loss': 0.5361708322999931, 'Total loss': 0.5361708322999931}
2022-12-05 23:30:28,971 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:28,971 INFO:     Epoch: 36
2022-12-05 23:30:29,686 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5603189519183203, 'Total loss': 0.5603189519183203} | train loss {'Reaction outcome loss': 0.5474079049791885, 'Total loss': 0.5474079049791885}
2022-12-05 23:30:29,686 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:29,686 INFO:     Epoch: 37
2022-12-05 23:30:30,399 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5246953307227655, 'Total loss': 0.5246953307227655} | train loss {'Reaction outcome loss': 0.533629873512984, 'Total loss': 0.533629873512984}
2022-12-05 23:30:30,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:30,399 INFO:     Epoch: 38
2022-12-05 23:30:31,111 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5185702781785618, 'Total loss': 0.5185702781785618} | train loss {'Reaction outcome loss': 0.5296677899686432, 'Total loss': 0.5296677899686432}
2022-12-05 23:30:31,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:31,111 INFO:     Epoch: 39
2022-12-05 23:30:31,827 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5258281549269502, 'Total loss': 0.5258281549269502} | train loss {'Reaction outcome loss': 0.5319768914628608, 'Total loss': 0.5319768914628608}
2022-12-05 23:30:31,828 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:31,828 INFO:     Epoch: 40
2022-12-05 23:30:32,543 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5605221133340489, 'Total loss': 0.5605221133340489} | train loss {'Reaction outcome loss': 0.5287138897518397, 'Total loss': 0.5287138897518397}
2022-12-05 23:30:32,543 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:32,543 INFO:     Epoch: 41
2022-12-05 23:30:33,254 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5418545326048677, 'Total loss': 0.5418545326048677} | train loss {'Reaction outcome loss': 0.5366284006279007, 'Total loss': 0.5366284006279007}
2022-12-05 23:30:33,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:33,254 INFO:     Epoch: 42
2022-12-05 23:30:33,964 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5251668813553724, 'Total loss': 0.5251668813553724} | train loss {'Reaction outcome loss': 0.531766534515238, 'Total loss': 0.531766534515238}
2022-12-05 23:30:33,964 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:33,964 INFO:     Epoch: 43
2022-12-05 23:30:34,680 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5106945928524841, 'Total loss': 0.5106945928524841} | train loss {'Reaction outcome loss': 0.5298077830901513, 'Total loss': 0.5298077830901513}
2022-12-05 23:30:34,680 INFO:     Found new best model at epoch 43
2022-12-05 23:30:34,681 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:34,681 INFO:     Epoch: 44
2022-12-05 23:30:35,394 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5537331070412289, 'Total loss': 0.5537331070412289} | train loss {'Reaction outcome loss': 0.5438051744390596, 'Total loss': 0.5438051744390596}
2022-12-05 23:30:35,394 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:35,394 INFO:     Epoch: 45
2022-12-05 23:30:36,104 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.544255178083073, 'Total loss': 0.544255178083073} | train loss {'Reaction outcome loss': 0.5370188278828555, 'Total loss': 0.5370188278828555}
2022-12-05 23:30:36,104 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:36,104 INFO:     Epoch: 46
2022-12-05 23:30:36,815 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5021176934242249, 'Total loss': 0.5021176934242249} | train loss {'Reaction outcome loss': 0.5367515149869417, 'Total loss': 0.5367515149869417}
2022-12-05 23:30:36,815 INFO:     Found new best model at epoch 46
2022-12-05 23:30:36,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:36,816 INFO:     Epoch: 47
2022-12-05 23:30:37,531 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.530017963187261, 'Total loss': 0.530017963187261} | train loss {'Reaction outcome loss': 0.5282755398195282, 'Total loss': 0.5282755398195282}
2022-12-05 23:30:37,531 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:37,531 INFO:     Epoch: 48
2022-12-05 23:30:38,244 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5365443073890426, 'Total loss': 0.5365443073890426} | train loss {'Reaction outcome loss': 0.5344861289750227, 'Total loss': 0.5344861289750227}
2022-12-05 23:30:38,244 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:38,244 INFO:     Epoch: 49
2022-12-05 23:30:38,956 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5362917625091292, 'Total loss': 0.5362917625091292} | train loss {'Reaction outcome loss': 0.5382049825751347, 'Total loss': 0.5382049825751347}
2022-12-05 23:30:38,956 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:38,956 INFO:     Epoch: 50
2022-12-05 23:30:39,668 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5246441838416186, 'Total loss': 0.5246441838416186} | train loss {'Reaction outcome loss': 0.522234968961733, 'Total loss': 0.522234968961733}
2022-12-05 23:30:39,668 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:39,668 INFO:     Epoch: 51
2022-12-05 23:30:40,381 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5704883188009262, 'Total loss': 0.5704883188009262} | train loss {'Reaction outcome loss': 0.5285565607581544, 'Total loss': 0.5285565607581544}
2022-12-05 23:30:40,382 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:40,382 INFO:     Epoch: 52
2022-12-05 23:30:41,094 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5021277340975675, 'Total loss': 0.5021277340975675} | train loss {'Reaction outcome loss': 0.5266742357599591, 'Total loss': 0.5266742357599591}
2022-12-05 23:30:41,094 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:41,094 INFO:     Epoch: 53
2022-12-05 23:30:41,806 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5565517063845288, 'Total loss': 0.5565517063845288} | train loss {'Reaction outcome loss': 0.5277020585561089, 'Total loss': 0.5277020585561089}
2022-12-05 23:30:41,806 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:41,806 INFO:     Epoch: 54
2022-12-05 23:30:42,517 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5191357691179622, 'Total loss': 0.5191357691179622} | train loss {'Reaction outcome loss': 0.5177200144601737, 'Total loss': 0.5177200144601737}
2022-12-05 23:30:42,517 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:42,517 INFO:     Epoch: 55
2022-12-05 23:30:43,231 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5268486744978211, 'Total loss': 0.5268486744978211} | train loss {'Reaction outcome loss': 0.5227837796635956, 'Total loss': 0.5227837796635956}
2022-12-05 23:30:43,231 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:43,232 INFO:     Epoch: 56
2022-12-05 23:30:43,943 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5133924545212225, 'Total loss': 0.5133924545212225} | train loss {'Reaction outcome loss': 0.5215299224918369, 'Total loss': 0.5215299224918369}
2022-12-05 23:30:43,943 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:43,943 INFO:     Epoch: 57
2022-12-05 23:30:44,653 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5214351205663248, 'Total loss': 0.5214351205663248} | train loss {'Reaction outcome loss': 0.5290448514194142, 'Total loss': 0.5290448514194142}
2022-12-05 23:30:44,653 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:44,653 INFO:     Epoch: 58
2022-12-05 23:30:45,365 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.537364237010479, 'Total loss': 0.537364237010479} | train loss {'Reaction outcome loss': 0.5362150369264819, 'Total loss': 0.5362150369264819}
2022-12-05 23:30:45,365 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:45,365 INFO:     Epoch: 59
2022-12-05 23:30:46,088 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5491673614491116, 'Total loss': 0.5491673614491116} | train loss {'Reaction outcome loss': 0.5331243510067705, 'Total loss': 0.5331243510067705}
2022-12-05 23:30:46,088 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:46,088 INFO:     Epoch: 60
2022-12-05 23:30:46,800 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5185828032818708, 'Total loss': 0.5185828032818708} | train loss {'Reaction outcome loss': 0.5321558356164438, 'Total loss': 0.5321558356164438}
2022-12-05 23:30:46,800 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:46,800 INFO:     Epoch: 61
2022-12-05 23:30:47,513 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5309012132612142, 'Total loss': 0.5309012132612142} | train loss {'Reaction outcome loss': 0.523489570991713, 'Total loss': 0.523489570991713}
2022-12-05 23:30:47,513 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:47,513 INFO:     Epoch: 62
2022-12-05 23:30:48,225 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4926597001877698, 'Total loss': 0.4926597001877698} | train loss {'Reaction outcome loss': 0.5253478525591041, 'Total loss': 0.5253478525591041}
2022-12-05 23:30:48,226 INFO:     Found new best model at epoch 62
2022-12-05 23:30:48,226 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:48,226 INFO:     Epoch: 63
2022-12-05 23:30:48,943 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5167172700166702, 'Total loss': 0.5167172700166702} | train loss {'Reaction outcome loss': 0.5206235004400435, 'Total loss': 0.5206235004400435}
2022-12-05 23:30:48,943 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:48,943 INFO:     Epoch: 64
2022-12-05 23:30:49,658 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5315044461326166, 'Total loss': 0.5315044461326166} | train loss {'Reaction outcome loss': 0.5279183251753088, 'Total loss': 0.5279183251753088}
2022-12-05 23:30:49,658 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:49,658 INFO:     Epoch: 65
2022-12-05 23:30:50,370 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5105373893271793, 'Total loss': 0.5105373893271793} | train loss {'Reaction outcome loss': 0.522402972405256, 'Total loss': 0.522402972405256}
2022-12-05 23:30:50,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:50,370 INFO:     Epoch: 66
2022-12-05 23:30:51,081 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5362267460335385, 'Total loss': 0.5362267460335385} | train loss {'Reaction outcome loss': 0.518521902833873, 'Total loss': 0.518521902833873}
2022-12-05 23:30:51,082 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:51,082 INFO:     Epoch: 67
2022-12-05 23:30:51,793 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5019314986738291, 'Total loss': 0.5019314986738291} | train loss {'Reaction outcome loss': 0.5217084834024099, 'Total loss': 0.5217084834024099}
2022-12-05 23:30:51,793 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:51,794 INFO:     Epoch: 68
2022-12-05 23:30:52,508 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5154489380392161, 'Total loss': 0.5154489380392161} | train loss {'Reaction outcome loss': 0.5308300260348842, 'Total loss': 0.5308300260348842}
2022-12-05 23:30:52,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:52,509 INFO:     Epoch: 69
2022-12-05 23:30:53,220 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5496477545662359, 'Total loss': 0.5496477545662359} | train loss {'Reaction outcome loss': 0.53547193544355, 'Total loss': 0.53547193544355}
2022-12-05 23:30:53,220 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:53,220 INFO:     Epoch: 70
2022-12-05 23:30:53,932 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4971716647798365, 'Total loss': 0.4971716647798365} | train loss {'Reaction outcome loss': 0.538052392965145, 'Total loss': 0.538052392965145}
2022-12-05 23:30:53,932 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:53,932 INFO:     Epoch: 71
2022-12-05 23:30:54,650 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5303234068507497, 'Total loss': 0.5303234068507497} | train loss {'Reaction outcome loss': 0.5124528001435855, 'Total loss': 0.5124528001435855}
2022-12-05 23:30:54,650 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:54,650 INFO:     Epoch: 72
2022-12-05 23:30:55,364 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5018760870126161, 'Total loss': 0.5018760870126161} | train loss {'Reaction outcome loss': 0.530327936295073, 'Total loss': 0.530327936295073}
2022-12-05 23:30:55,364 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:55,364 INFO:     Epoch: 73
2022-12-05 23:30:56,075 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5158736245198683, 'Total loss': 0.5158736245198683} | train loss {'Reaction outcome loss': 0.5232141407636496, 'Total loss': 0.5232141407636496}
2022-12-05 23:30:56,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:56,076 INFO:     Epoch: 74
2022-12-05 23:30:56,790 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5445491048422727, 'Total loss': 0.5445491048422727} | train loss {'Reaction outcome loss': 0.5207031375242148, 'Total loss': 0.5207031375242148}
2022-12-05 23:30:56,791 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:56,791 INFO:     Epoch: 75
2022-12-05 23:30:57,508 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.514707780697129, 'Total loss': 0.514707780697129} | train loss {'Reaction outcome loss': 0.5318329349944466, 'Total loss': 0.5318329349944466}
2022-12-05 23:30:57,508 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:57,508 INFO:     Epoch: 76
2022-12-05 23:30:58,220 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5242819894443859, 'Total loss': 0.5242819894443859} | train loss {'Reaction outcome loss': 0.5205993449036409, 'Total loss': 0.5205993449036409}
2022-12-05 23:30:58,220 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:58,220 INFO:     Epoch: 77
2022-12-05 23:30:58,932 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5323220708153464, 'Total loss': 0.5323220708153464} | train loss {'Reaction outcome loss': 0.5282751698846276, 'Total loss': 0.5282751698846276}
2022-12-05 23:30:58,933 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:58,933 INFO:     Epoch: 78
2022-12-05 23:30:59,645 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5278180959549817, 'Total loss': 0.5278180959549817} | train loss {'Reaction outcome loss': 0.5244055940630102, 'Total loss': 0.5244055940630102}
2022-12-05 23:30:59,645 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:30:59,645 INFO:     Epoch: 79
2022-12-05 23:31:00,356 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.503890073434873, 'Total loss': 0.503890073434873} | train loss {'Reaction outcome loss': 0.5174846423201656, 'Total loss': 0.5174846423201656}
2022-12-05 23:31:00,356 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:00,356 INFO:     Epoch: 80
2022-12-05 23:31:01,066 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5481858101080764, 'Total loss': 0.5481858101080764} | train loss {'Reaction outcome loss': 0.5191476647006837, 'Total loss': 0.5191476647006837}
2022-12-05 23:31:01,067 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:01,067 INFO:     Epoch: 81
2022-12-05 23:31:01,780 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5521059632301331, 'Total loss': 0.5521059632301331} | train loss {'Reaction outcome loss': 0.5235386562725974, 'Total loss': 0.5235386562725974}
2022-12-05 23:31:01,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:01,781 INFO:     Epoch: 82
2022-12-05 23:31:02,492 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5140976770357653, 'Total loss': 0.5140976770357653} | train loss {'Reaction outcome loss': 0.5236302175774024, 'Total loss': 0.5236302175774024}
2022-12-05 23:31:02,492 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:02,492 INFO:     Epoch: 83
2022-12-05 23:31:03,203 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5087490515275435, 'Total loss': 0.5087490515275435} | train loss {'Reaction outcome loss': 0.5232014952280261, 'Total loss': 0.5232014952280261}
2022-12-05 23:31:03,203 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:03,203 INFO:     Epoch: 84
2022-12-05 23:31:03,914 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5239424661479213, 'Total loss': 0.5239424661479213} | train loss {'Reaction outcome loss': 0.5185050785782849, 'Total loss': 0.5185050785782849}
2022-12-05 23:31:03,914 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:03,914 INFO:     Epoch: 85
2022-12-05 23:31:04,629 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5175970874049447, 'Total loss': 0.5175970874049447} | train loss {'Reaction outcome loss': 0.5215773314599567, 'Total loss': 0.5215773314599567}
2022-12-05 23:31:04,629 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:04,630 INFO:     Epoch: 86
2022-12-05 23:31:05,343 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.518832226368514, 'Total loss': 0.518832226368514} | train loss {'Reaction outcome loss': 0.5251947327060738, 'Total loss': 0.5251947327060738}
2022-12-05 23:31:05,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:05,343 INFO:     Epoch: 87
2022-12-05 23:31:06,053 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5112096606330438, 'Total loss': 0.5112096606330438} | train loss {'Reaction outcome loss': 0.5278613166921293, 'Total loss': 0.5278613166921293}
2022-12-05 23:31:06,053 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:06,053 INFO:     Epoch: 88
2022-12-05 23:31:06,763 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.522688506001776, 'Total loss': 0.522688506001776} | train loss {'Reaction outcome loss': 0.5125333601043291, 'Total loss': 0.5125333601043291}
2022-12-05 23:31:06,763 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:06,764 INFO:     Epoch: 89
2022-12-05 23:31:07,474 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4942451420832764, 'Total loss': 0.4942451420832764} | train loss {'Reaction outcome loss': 0.5249197984996595, 'Total loss': 0.5249197984996595}
2022-12-05 23:31:07,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:07,475 INFO:     Epoch: 90
2022-12-05 23:31:08,184 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5129370452328161, 'Total loss': 0.5129370452328161} | train loss {'Reaction outcome loss': 0.5499129805276509, 'Total loss': 0.5499129805276509}
2022-12-05 23:31:08,184 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:08,184 INFO:     Epoch: 91
2022-12-05 23:31:08,894 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5650867508216337, 'Total loss': 0.5650867508216337} | train loss {'Reaction outcome loss': 0.5177869791926643, 'Total loss': 0.5177869791926643}
2022-12-05 23:31:08,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:08,895 INFO:     Epoch: 92
2022-12-05 23:31:09,606 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5094251812181689, 'Total loss': 0.5094251812181689} | train loss {'Reaction outcome loss': 0.5295889898832993, 'Total loss': 0.5295889898832993}
2022-12-05 23:31:09,606 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:09,606 INFO:     Epoch: 93
2022-12-05 23:31:10,319 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5067789534276183, 'Total loss': 0.5067789534276183} | train loss {'Reaction outcome loss': 0.5274122209940483, 'Total loss': 0.5274122209940483}
2022-12-05 23:31:10,319 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:10,319 INFO:     Epoch: 94
2022-12-05 23:31:11,030 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5249717845158144, 'Total loss': 0.5249717845158144} | train loss {'Reaction outcome loss': 0.5241802695550417, 'Total loss': 0.5241802695550417}
2022-12-05 23:31:11,031 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:11,031 INFO:     Epoch: 95
2022-12-05 23:31:11,747 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5151050820608031, 'Total loss': 0.5151050820608031} | train loss {'Reaction outcome loss': 0.5153920785486246, 'Total loss': 0.5153920785486246}
2022-12-05 23:31:11,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:11,748 INFO:     Epoch: 96
2022-12-05 23:31:12,466 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5041950256987051, 'Total loss': 0.5041950256987051} | train loss {'Reaction outcome loss': 0.5161437772606549, 'Total loss': 0.5161437772606549}
2022-12-05 23:31:12,466 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:12,466 INFO:     Epoch: 97
2022-12-05 23:31:13,179 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5563616610386155, 'Total loss': 0.5563616610386155} | train loss {'Reaction outcome loss': 0.523829874058484, 'Total loss': 0.523829874058484}
2022-12-05 23:31:13,179 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:13,179 INFO:     Epoch: 98
2022-12-05 23:31:13,890 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5294923267581246, 'Total loss': 0.5294923267581246} | train loss {'Reaction outcome loss': 0.5363496318157868, 'Total loss': 0.5363496318157868}
2022-12-05 23:31:13,890 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:13,891 INFO:     Epoch: 99
2022-12-05 23:31:14,604 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5196690200404688, 'Total loss': 0.5196690200404688} | train loss {'Reaction outcome loss': 0.523467392664448, 'Total loss': 0.523467392664448}
2022-12-05 23:31:14,604 INFO:     Best model found after epoch 63 of 100.
2022-12-05 23:31:14,605 INFO:   Done with stage: TRAINING
2022-12-05 23:31:14,605 INFO:   Starting stage: EVALUATION
2022-12-05 23:31:14,730 INFO:   Done with stage: EVALUATION
2022-12-05 23:31:14,730 INFO:   Leaving out SEQ value Fold_2
2022-12-05 23:31:14,743 INFO:   examples: 20,544| examples in train: 15,422 | examples in val: 2,722| examples in test: 2,400
2022-12-05 23:31:14,743 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:31:15,375 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:31:15,376 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:31:15,446 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:31:15,446 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:31:15,446 INFO:     No hyperparam tuning for this model
2022-12-05 23:31:15,447 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:31:15,447 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:31:15,447 INFO:     None feature selector for col prot
2022-12-05 23:31:15,447 INFO:     None feature selector for col prot
2022-12-05 23:31:15,448 INFO:     None feature selector for col prot
2022-12-05 23:31:15,448 INFO:     None feature selector for col chem
2022-12-05 23:31:15,448 INFO:     None feature selector for col chem
2022-12-05 23:31:15,448 INFO:     None feature selector for col chem
2022-12-05 23:31:15,448 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:31:15,448 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:31:15,450 INFO:     Number of params in model 215731
2022-12-05 23:31:15,453 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:31:15,453 INFO:   Starting stage: TRAINING
2022-12-05 23:31:15,511 INFO:     Val loss before train {'Reaction outcome loss': 1.02226250670677, 'Total loss': 1.02226250670677}
2022-12-05 23:31:15,511 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:15,512 INFO:     Epoch: 0
2022-12-05 23:31:16,207 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6923594433207845, 'Total loss': 0.6923594433207845} | train loss {'Reaction outcome loss': 0.8037304461496995, 'Total loss': 0.8037304461496995}
2022-12-05 23:31:16,207 INFO:     Found new best model at epoch 0
2022-12-05 23:31:16,208 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:16,208 INFO:     Epoch: 1
2022-12-05 23:31:16,902 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.621108879183614, 'Total loss': 0.621108879183614} | train loss {'Reaction outcome loss': 0.6528313947663762, 'Total loss': 0.6528313947663762}
2022-12-05 23:31:16,902 INFO:     Found new best model at epoch 1
2022-12-05 23:31:16,903 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:16,903 INFO:     Epoch: 2
2022-12-05 23:31:17,600 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5661876717972201, 'Total loss': 0.5661876717972201} | train loss {'Reaction outcome loss': 0.5876850840709021, 'Total loss': 0.5876850840709021}
2022-12-05 23:31:17,600 INFO:     Found new best model at epoch 2
2022-12-05 23:31:17,600 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:17,601 INFO:     Epoch: 3
2022-12-05 23:31:18,293 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5981243256219598, 'Total loss': 0.5981243256219598} | train loss {'Reaction outcome loss': 0.5749806852014233, 'Total loss': 0.5749806852014233}
2022-12-05 23:31:18,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:18,294 INFO:     Epoch: 4
2022-12-05 23:31:18,990 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5685075919988544, 'Total loss': 0.5685075919988544} | train loss {'Reaction outcome loss': 0.5597274797462329, 'Total loss': 0.5597274797462329}
2022-12-05 23:31:18,990 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:18,990 INFO:     Epoch: 5
2022-12-05 23:31:19,690 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5591907979444016, 'Total loss': 0.5591907979444016} | train loss {'Reaction outcome loss': 0.550664841819601, 'Total loss': 0.550664841819601}
2022-12-05 23:31:19,690 INFO:     Found new best model at epoch 5
2022-12-05 23:31:19,691 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:19,691 INFO:     Epoch: 6
2022-12-05 23:31:20,385 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5516602078149485, 'Total loss': 0.5516602078149485} | train loss {'Reaction outcome loss': 0.5466705406726149, 'Total loss': 0.5466705406726149}
2022-12-05 23:31:20,385 INFO:     Found new best model at epoch 6
2022-12-05 23:31:20,386 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:20,386 INFO:     Epoch: 7
2022-12-05 23:31:21,079 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5419336065303447, 'Total loss': 0.5419336065303447} | train loss {'Reaction outcome loss': 0.543490169824901, 'Total loss': 0.543490169824901}
2022-12-05 23:31:21,079 INFO:     Found new best model at epoch 7
2022-12-05 23:31:21,080 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:21,080 INFO:     Epoch: 8
2022-12-05 23:31:21,775 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5608734017194703, 'Total loss': 0.5608734017194703} | train loss {'Reaction outcome loss': 0.5390702864441139, 'Total loss': 0.5390702864441139}
2022-12-05 23:31:21,775 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:21,775 INFO:     Epoch: 9
2022-12-05 23:31:22,476 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5543479184771694, 'Total loss': 0.5543479184771694} | train loss {'Reaction outcome loss': 0.5435129609963706, 'Total loss': 0.5435129609963706}
2022-12-05 23:31:22,476 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:22,476 INFO:     Epoch: 10
2022-12-05 23:31:23,170 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5174332406631735, 'Total loss': 0.5174332406631735} | train loss {'Reaction outcome loss': 0.5464352168359202, 'Total loss': 0.5464352168359202}
2022-12-05 23:31:23,170 INFO:     Found new best model at epoch 10
2022-12-05 23:31:23,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:23,171 INFO:     Epoch: 11
2022-12-05 23:31:23,866 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5071726975052856, 'Total loss': 0.5071726975052856} | train loss {'Reaction outcome loss': 0.5275684163530833, 'Total loss': 0.5275684163530833}
2022-12-05 23:31:23,867 INFO:     Found new best model at epoch 11
2022-12-05 23:31:23,868 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:23,868 INFO:     Epoch: 12
2022-12-05 23:31:24,565 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.509886679954307, 'Total loss': 0.509886679954307} | train loss {'Reaction outcome loss': 0.5354287454325134, 'Total loss': 0.5354287454325134}
2022-12-05 23:31:24,566 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:24,566 INFO:     Epoch: 13
2022-12-05 23:31:25,266 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5222549625607424, 'Total loss': 0.5222549625607424} | train loss {'Reaction outcome loss': 0.5297971343103781, 'Total loss': 0.5297971343103781}
2022-12-05 23:31:25,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:25,266 INFO:     Epoch: 14
2022-12-05 23:31:25,959 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5273585655661517, 'Total loss': 0.5273585655661517} | train loss {'Reaction outcome loss': 0.5345676924677806, 'Total loss': 0.5345676924677806}
2022-12-05 23:31:25,960 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:25,960 INFO:     Epoch: 15
2022-12-05 23:31:26,650 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5166704419047333, 'Total loss': 0.5166704419047333} | train loss {'Reaction outcome loss': 0.5302482966441832, 'Total loss': 0.5302482966441832}
2022-12-05 23:31:26,650 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:26,650 INFO:     Epoch: 16
2022-12-05 23:31:27,343 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.543144702911377, 'Total loss': 0.543144702911377} | train loss {'Reaction outcome loss': 0.5296520078206952, 'Total loss': 0.5296520078206952}
2022-12-05 23:31:27,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:27,343 INFO:     Epoch: 17
2022-12-05 23:31:28,034 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5915449823057929, 'Total loss': 0.5915449823057929} | train loss {'Reaction outcome loss': 0.5343379887802472, 'Total loss': 0.5343379887802472}
2022-12-05 23:31:28,034 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:28,034 INFO:     Epoch: 18
2022-12-05 23:31:28,730 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5200581373863442, 'Total loss': 0.5200581373863442} | train loss {'Reaction outcome loss': 0.5273006522556558, 'Total loss': 0.5273006522556558}
2022-12-05 23:31:28,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:28,731 INFO:     Epoch: 19
2022-12-05 23:31:29,421 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5289724070665448, 'Total loss': 0.5289724070665448} | train loss {'Reaction outcome loss': 0.5341065015906615, 'Total loss': 0.5341065015906615}
2022-12-05 23:31:29,421 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:29,421 INFO:     Epoch: 20
2022-12-05 23:31:30,112 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5358976631663567, 'Total loss': 0.5358976631663567} | train loss {'Reaction outcome loss': 0.5300805529741826, 'Total loss': 0.5300805529741826}
2022-12-05 23:31:30,112 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:30,112 INFO:     Epoch: 21
2022-12-05 23:31:30,803 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5224548827770145, 'Total loss': 0.5224548827770145} | train loss {'Reaction outcome loss': 0.523844901518703, 'Total loss': 0.523844901518703}
2022-12-05 23:31:30,803 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:30,803 INFO:     Epoch: 22
2022-12-05 23:31:31,493 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5410717413869015, 'Total loss': 0.5410717413869015} | train loss {'Reaction outcome loss': 0.5263452093383584, 'Total loss': 0.5263452093383584}
2022-12-05 23:31:31,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:31,494 INFO:     Epoch: 23
2022-12-05 23:31:32,187 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5327577161234479, 'Total loss': 0.5327577161234479} | train loss {'Reaction outcome loss': 0.5282388636803725, 'Total loss': 0.5282388636803725}
2022-12-05 23:31:32,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:32,188 INFO:     Epoch: 24
2022-12-05 23:31:32,878 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5132368726785793, 'Total loss': 0.5132368726785793} | train loss {'Reaction outcome loss': 0.5256482336160059, 'Total loss': 0.5256482336160059}
2022-12-05 23:31:32,878 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:32,878 INFO:     Epoch: 25
2022-12-05 23:31:33,569 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5275894542073094, 'Total loss': 0.5275894542073094} | train loss {'Reaction outcome loss': 0.5396382905140952, 'Total loss': 0.5396382905140952}
2022-12-05 23:31:33,569 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:33,569 INFO:     Epoch: 26
2022-12-05 23:31:34,262 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5337762430656788, 'Total loss': 0.5337762430656788} | train loss {'Reaction outcome loss': 0.525828249350623, 'Total loss': 0.525828249350623}
2022-12-05 23:31:34,262 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:34,263 INFO:     Epoch: 27
2022-12-05 23:31:34,956 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5161799466194108, 'Total loss': 0.5161799466194108} | train loss {'Reaction outcome loss': 0.5213600266647537, 'Total loss': 0.5213600266647537}
2022-12-05 23:31:34,956 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:34,956 INFO:     Epoch: 28
2022-12-05 23:31:35,647 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5227183120888333, 'Total loss': 0.5227183120888333} | train loss {'Reaction outcome loss': 0.5236374926270291, 'Total loss': 0.5236374926270291}
2022-12-05 23:31:35,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:35,647 INFO:     Epoch: 29
2022-12-05 23:31:36,337 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5387588975041412, 'Total loss': 0.5387588975041412} | train loss {'Reaction outcome loss': 0.5283964986437584, 'Total loss': 0.5283964986437584}
2022-12-05 23:31:36,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:36,337 INFO:     Epoch: 30
2022-12-05 23:31:37,027 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.529511844349462, 'Total loss': 0.529511844349462} | train loss {'Reaction outcome loss': 0.5281804753042355, 'Total loss': 0.5281804753042355}
2022-12-05 23:31:37,027 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:37,027 INFO:     Epoch: 31
2022-12-05 23:31:37,717 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5598747931247534, 'Total loss': 0.5598747931247534} | train loss {'Reaction outcome loss': 0.5251639289356366, 'Total loss': 0.5251639289356366}
2022-12-05 23:31:37,717 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:37,717 INFO:     Epoch: 32
2022-12-05 23:31:38,411 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.506478488445282, 'Total loss': 0.506478488445282} | train loss {'Reaction outcome loss': 0.5250343356389723, 'Total loss': 0.5250343356389723}
2022-12-05 23:31:38,411 INFO:     Found new best model at epoch 32
2022-12-05 23:31:38,411 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:38,412 INFO:     Epoch: 33
2022-12-05 23:31:39,101 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5605943480203318, 'Total loss': 0.5605943480203318} | train loss {'Reaction outcome loss': 0.5219215421755778, 'Total loss': 0.5219215421755778}
2022-12-05 23:31:39,101 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:39,101 INFO:     Epoch: 34
2022-12-05 23:31:39,791 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5180215714282768, 'Total loss': 0.5180215714282768} | train loss {'Reaction outcome loss': 0.519083857659977, 'Total loss': 0.519083857659977}
2022-12-05 23:31:39,791 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:39,791 INFO:     Epoch: 35
2022-12-05 23:31:40,487 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5785763537467912, 'Total loss': 0.5785763537467912} | train loss {'Reaction outcome loss': 0.5290250868470837, 'Total loss': 0.5290250868470837}
2022-12-05 23:31:40,487 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:40,487 INFO:     Epoch: 36
2022-12-05 23:31:41,177 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5387313462967096, 'Total loss': 0.5387313462967096} | train loss {'Reaction outcome loss': 0.5223206200045669, 'Total loss': 0.5223206200045669}
2022-12-05 23:31:41,178 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:41,178 INFO:     Epoch: 37
2022-12-05 23:31:41,871 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.50907465850198, 'Total loss': 0.50907465850198} | train loss {'Reaction outcome loss': 0.5243863492462151, 'Total loss': 0.5243863492462151}
2022-12-05 23:31:41,871 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:41,871 INFO:     Epoch: 38
2022-12-05 23:31:42,565 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5205434782560482, 'Total loss': 0.5205434782560482} | train loss {'Reaction outcome loss': 0.520237656549794, 'Total loss': 0.520237656549794}
2022-12-05 23:31:42,566 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:42,566 INFO:     Epoch: 39
2022-12-05 23:31:43,259 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.528837849927503, 'Total loss': 0.528837849927503} | train loss {'Reaction outcome loss': 0.5214744729619798, 'Total loss': 0.5214744729619798}
2022-12-05 23:31:43,259 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:43,259 INFO:     Epoch: 40
2022-12-05 23:31:43,951 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5097196448680966, 'Total loss': 0.5097196448680966} | train loss {'Reaction outcome loss': 0.5251015693072956, 'Total loss': 0.5251015693072956}
2022-12-05 23:31:43,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:43,951 INFO:     Epoch: 41
2022-12-05 23:31:44,641 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5065632881813271, 'Total loss': 0.5065632881813271} | train loss {'Reaction outcome loss': 0.5212066283611836, 'Total loss': 0.5212066283611836}
2022-12-05 23:31:44,641 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:44,641 INFO:     Epoch: 42
2022-12-05 23:31:45,329 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5288251454747, 'Total loss': 0.5288251454747} | train loss {'Reaction outcome loss': 0.5237145182131732, 'Total loss': 0.5237145182131732}
2022-12-05 23:31:45,329 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:45,329 INFO:     Epoch: 43
2022-12-05 23:31:46,016 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5051248849824418, 'Total loss': 0.5051248849824418} | train loss {'Reaction outcome loss': 0.5255389096083978, 'Total loss': 0.5255389096083978}
2022-12-05 23:31:46,016 INFO:     Found new best model at epoch 43
2022-12-05 23:31:46,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:46,017 INFO:     Epoch: 44
2022-12-05 23:31:46,703 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5230070186215777, 'Total loss': 0.5230070186215777} | train loss {'Reaction outcome loss': 0.524434123791105, 'Total loss': 0.524434123791105}
2022-12-05 23:31:46,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:46,703 INFO:     Epoch: 45
2022-12-05 23:31:47,389 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5363452670186065, 'Total loss': 0.5363452670186065} | train loss {'Reaction outcome loss': 0.529663337062256, 'Total loss': 0.529663337062256}
2022-12-05 23:31:47,389 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:47,389 INFO:     Epoch: 46
2022-12-05 23:31:48,074 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5449659006540165, 'Total loss': 0.5449659006540165} | train loss {'Reaction outcome loss': 0.5220230747307979, 'Total loss': 0.5220230747307979}
2022-12-05 23:31:48,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:48,075 INFO:     Epoch: 47
2022-12-05 23:31:48,760 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5114199442918911, 'Total loss': 0.5114199442918911} | train loss {'Reaction outcome loss': 0.5312610256226725, 'Total loss': 0.5312610256226725}
2022-12-05 23:31:48,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:48,761 INFO:     Epoch: 48
2022-12-05 23:31:49,446 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5173316438530766, 'Total loss': 0.5173316438530766} | train loss {'Reaction outcome loss': 0.5226368659264814, 'Total loss': 0.5226368659264814}
2022-12-05 23:31:49,446 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:49,446 INFO:     Epoch: 49
2022-12-05 23:31:50,136 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5426113068364388, 'Total loss': 0.5426113068364388} | train loss {'Reaction outcome loss': 0.5255920925946651, 'Total loss': 0.5255920925946651}
2022-12-05 23:31:50,137 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:50,137 INFO:     Epoch: 50
2022-12-05 23:31:50,828 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5174620737170064, 'Total loss': 0.5174620737170064} | train loss {'Reaction outcome loss': 0.5222443203708443, 'Total loss': 0.5222443203708443}
2022-12-05 23:31:50,828 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:50,828 INFO:     Epoch: 51
2022-12-05 23:31:51,516 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.507506345593652, 'Total loss': 0.507506345593652} | train loss {'Reaction outcome loss': 0.5202861091284336, 'Total loss': 0.5202861091284336}
2022-12-05 23:31:51,516 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:51,516 INFO:     Epoch: 52
2022-12-05 23:31:52,202 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5708821492139683, 'Total loss': 0.5708821492139683} | train loss {'Reaction outcome loss': 0.5216950640638834, 'Total loss': 0.5216950640638834}
2022-12-05 23:31:52,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:52,202 INFO:     Epoch: 53
2022-12-05 23:31:52,888 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5186262248560439, 'Total loss': 0.5186262248560439} | train loss {'Reaction outcome loss': 0.5224996977079953, 'Total loss': 0.5224996977079953}
2022-12-05 23:31:52,888 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:52,889 INFO:     Epoch: 54
2022-12-05 23:31:53,574 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.508611393875854, 'Total loss': 0.508611393875854} | train loss {'Reaction outcome loss': 0.5256306862311739, 'Total loss': 0.5256306862311739}
2022-12-05 23:31:53,574 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:53,574 INFO:     Epoch: 55
2022-12-05 23:31:54,264 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5234025151923646, 'Total loss': 0.5234025151923646} | train loss {'Reaction outcome loss': 0.5250254588750388, 'Total loss': 0.5250254588750388}
2022-12-05 23:31:54,265 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:54,265 INFO:     Epoch: 56
2022-12-05 23:31:54,951 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5199527504832245, 'Total loss': 0.5199527504832245} | train loss {'Reaction outcome loss': 0.5225674398088851, 'Total loss': 0.5225674398088851}
2022-12-05 23:31:54,952 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:54,952 INFO:     Epoch: 57
2022-12-05 23:31:55,640 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5024891083323678, 'Total loss': 0.5024891083323678} | train loss {'Reaction outcome loss': 0.5274306169065697, 'Total loss': 0.5274306169065697}
2022-12-05 23:31:55,640 INFO:     Found new best model at epoch 57
2022-12-05 23:31:55,641 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:55,641 INFO:     Epoch: 58
2022-12-05 23:31:56,328 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5209697526554729, 'Total loss': 0.5209697526554729} | train loss {'Reaction outcome loss': 0.5159133063065066, 'Total loss': 0.5159133063065066}
2022-12-05 23:31:56,328 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:56,328 INFO:     Epoch: 59
2022-12-05 23:31:57,013 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.530994518205177, 'Total loss': 0.530994518205177} | train loss {'Reaction outcome loss': 0.5196231842288338, 'Total loss': 0.5196231842288338}
2022-12-05 23:31:57,013 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:57,013 INFO:     Epoch: 60
2022-12-05 23:31:57,698 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5499708922796471, 'Total loss': 0.5499708922796471} | train loss {'Reaction outcome loss': 0.5264774076795182, 'Total loss': 0.5264774076795182}
2022-12-05 23:31:57,698 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:57,698 INFO:     Epoch: 61
2022-12-05 23:31:58,384 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5906567490378092, 'Total loss': 0.5906567490378092} | train loss {'Reaction outcome loss': 0.5169288571073801, 'Total loss': 0.5169288571073801}
2022-12-05 23:31:58,385 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:58,385 INFO:     Epoch: 62
2022-12-05 23:31:59,075 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5443576879279558, 'Total loss': 0.5443576879279558} | train loss {'Reaction outcome loss': 0.5248019297711582, 'Total loss': 0.5248019297711582}
2022-12-05 23:31:59,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:59,075 INFO:     Epoch: 63
2022-12-05 23:31:59,760 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5414993922377742, 'Total loss': 0.5414993922377742} | train loss {'Reaction outcome loss': 0.5274262362125008, 'Total loss': 0.5274262362125008}
2022-12-05 23:31:59,760 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:31:59,760 INFO:     Epoch: 64
2022-12-05 23:32:00,446 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.516974925994873, 'Total loss': 0.516974925994873} | train loss {'Reaction outcome loss': 0.5246228034689219, 'Total loss': 0.5246228034689219}
2022-12-05 23:32:00,446 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:00,446 INFO:     Epoch: 65
2022-12-05 23:32:01,134 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5132834977188776, 'Total loss': 0.5132834977188776} | train loss {'Reaction outcome loss': 0.5203238138272059, 'Total loss': 0.5203238138272059}
2022-12-05 23:32:01,134 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:01,135 INFO:     Epoch: 66
2022-12-05 23:32:01,821 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5017768304015315, 'Total loss': 0.5017768304015315} | train loss {'Reaction outcome loss': 0.5222172798642973, 'Total loss': 0.5222172798642973}
2022-12-05 23:32:01,821 INFO:     Found new best model at epoch 66
2022-12-05 23:32:01,822 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:01,822 INFO:     Epoch: 67
2022-12-05 23:32:02,510 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.511065540272136, 'Total loss': 0.511065540272136} | train loss {'Reaction outcome loss': 0.5220519601062126, 'Total loss': 0.5220519601062126}
2022-12-05 23:32:02,510 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:02,510 INFO:     Epoch: 68
2022-12-05 23:32:03,200 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5511889346810275, 'Total loss': 0.5511889346810275} | train loss {'Reaction outcome loss': 0.5224845474933688, 'Total loss': 0.5224845474933688}
2022-12-05 23:32:03,201 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:03,201 INFO:     Epoch: 69
2022-12-05 23:32:03,887 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5173590682273688, 'Total loss': 0.5173590682273688} | train loss {'Reaction outcome loss': 0.5158067076656334, 'Total loss': 0.5158067076656334}
2022-12-05 23:32:03,887 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:03,887 INFO:     Epoch: 70
2022-12-05 23:32:04,577 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5314003305379734, 'Total loss': 0.5314003305379734} | train loss {'Reaction outcome loss': 0.526056180232788, 'Total loss': 0.526056180232788}
2022-12-05 23:32:04,577 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:04,577 INFO:     Epoch: 71
2022-12-05 23:32:05,266 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5550134445345679, 'Total loss': 0.5550134445345679} | train loss {'Reaction outcome loss': 0.5179033803123656, 'Total loss': 0.5179033803123656}
2022-12-05 23:32:05,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:05,267 INFO:     Epoch: 72
2022-12-05 23:32:05,952 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5015811892442925, 'Total loss': 0.5015811892442925} | train loss {'Reaction outcome loss': 0.5247078273306249, 'Total loss': 0.5247078273306249}
2022-12-05 23:32:05,952 INFO:     Found new best model at epoch 72
2022-12-05 23:32:05,953 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:05,953 INFO:     Epoch: 73
2022-12-05 23:32:06,638 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5373274510683015, 'Total loss': 0.5373274510683015} | train loss {'Reaction outcome loss': 0.5132811320520535, 'Total loss': 0.5132811320520535}
2022-12-05 23:32:06,638 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:06,638 INFO:     Epoch: 74
2022-12-05 23:32:07,322 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5108375604762587, 'Total loss': 0.5108375604762587} | train loss {'Reaction outcome loss': 0.5206275897649314, 'Total loss': 0.5206275897649314}
2022-12-05 23:32:07,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:07,322 INFO:     Epoch: 75
2022-12-05 23:32:08,006 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5124620940796164, 'Total loss': 0.5124620940796164} | train loss {'Reaction outcome loss': 0.5269464557967245, 'Total loss': 0.5269464557967245}
2022-12-05 23:32:08,006 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:08,006 INFO:     Epoch: 76
2022-12-05 23:32:08,692 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5194054731102877, 'Total loss': 0.5194054731102877} | train loss {'Reaction outcome loss': 0.5223994166029934, 'Total loss': 0.5223994166029934}
2022-12-05 23:32:08,692 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:08,692 INFO:     Epoch: 77
2022-12-05 23:32:09,376 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.536233204395272, 'Total loss': 0.536233204395272} | train loss {'Reaction outcome loss': 0.5232934502892475, 'Total loss': 0.5232934502892475}
2022-12-05 23:32:09,376 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:09,376 INFO:     Epoch: 78
2022-12-05 23:32:10,062 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5155964105628258, 'Total loss': 0.5155964105628258} | train loss {'Reaction outcome loss': 0.5225836284056739, 'Total loss': 0.5225836284056739}
2022-12-05 23:32:10,062 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:10,062 INFO:     Epoch: 79
2022-12-05 23:32:10,747 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5042959274940713, 'Total loss': 0.5042959274940713} | train loss {'Reaction outcome loss': 0.5238828703575609, 'Total loss': 0.5238828703575609}
2022-12-05 23:32:10,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:10,748 INFO:     Epoch: 80
2022-12-05 23:32:11,432 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5289340237545412, 'Total loss': 0.5289340237545412} | train loss {'Reaction outcome loss': 0.5199150666285353, 'Total loss': 0.5199150666285353}
2022-12-05 23:32:11,433 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:11,433 INFO:     Epoch: 81
2022-12-05 23:32:12,121 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5241975413505421, 'Total loss': 0.5241975413505421} | train loss {'Reaction outcome loss': 0.5199313253411614, 'Total loss': 0.5199313253411614}
2022-12-05 23:32:12,121 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:12,121 INFO:     Epoch: 82
2022-12-05 23:32:12,809 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5328520848307499, 'Total loss': 0.5328520848307499} | train loss {'Reaction outcome loss': 0.5254026329863616, 'Total loss': 0.5254026329863616}
2022-12-05 23:32:12,809 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:12,810 INFO:     Epoch: 83
2022-12-05 23:32:13,495 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.52001003401224, 'Total loss': 0.52001003401224} | train loss {'Reaction outcome loss': 0.5174819443730397, 'Total loss': 0.5174819443730397}
2022-12-05 23:32:13,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:13,496 INFO:     Epoch: 84
2022-12-05 23:32:14,184 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5199094851349675, 'Total loss': 0.5199094851349675} | train loss {'Reaction outcome loss': 0.5250968324074606, 'Total loss': 0.5250968324074606}
2022-12-05 23:32:14,184 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:14,184 INFO:     Epoch: 85
2022-12-05 23:32:14,869 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5018613296885823, 'Total loss': 0.5018613296885823} | train loss {'Reaction outcome loss': 0.5202610241674289, 'Total loss': 0.5202610241674289}
2022-12-05 23:32:14,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:14,869 INFO:     Epoch: 86
2022-12-05 23:32:15,554 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.530683140075484, 'Total loss': 0.530683140075484} | train loss {'Reaction outcome loss': 0.5239902010720795, 'Total loss': 0.5239902010720795}
2022-12-05 23:32:15,554 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:15,554 INFO:     Epoch: 87
2022-12-05 23:32:16,239 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5304938305255978, 'Total loss': 0.5304938305255978} | train loss {'Reaction outcome loss': 0.5189865305092325, 'Total loss': 0.5189865305092325}
2022-12-05 23:32:16,239 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:16,239 INFO:     Epoch: 88
2022-12-05 23:32:16,923 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5083355179359746, 'Total loss': 0.5083355179359746} | train loss {'Reaction outcome loss': 0.5155344374199626, 'Total loss': 0.5155344374199626}
2022-12-05 23:32:16,924 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:16,924 INFO:     Epoch: 89
2022-12-05 23:32:17,608 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5277526205362275, 'Total loss': 0.5277526205362275} | train loss {'Reaction outcome loss': 0.5251396814693554, 'Total loss': 0.5251396814693554}
2022-12-05 23:32:17,608 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:17,608 INFO:     Epoch: 90
2022-12-05 23:32:18,292 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5039064534181772, 'Total loss': 0.5039064534181772} | train loss {'Reaction outcome loss': 0.5211807214867524, 'Total loss': 0.5211807214867524}
2022-12-05 23:32:18,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:18,293 INFO:     Epoch: 91
2022-12-05 23:32:18,977 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5184140316275663, 'Total loss': 0.5184140316275663} | train loss {'Reaction outcome loss': 0.5233076079381452, 'Total loss': 0.5233076079381452}
2022-12-05 23:32:18,978 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:18,978 INFO:     Epoch: 92
2022-12-05 23:32:19,665 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.52704503577809, 'Total loss': 0.52704503577809} | train loss {'Reaction outcome loss': 0.5173280140794659, 'Total loss': 0.5173280140794659}
2022-12-05 23:32:19,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:19,665 INFO:     Epoch: 93
2022-12-05 23:32:20,350 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.525063477629839, 'Total loss': 0.525063477629839} | train loss {'Reaction outcome loss': 0.5222946665099053, 'Total loss': 0.5222946665099053}
2022-12-05 23:32:20,350 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:20,350 INFO:     Epoch: 94
2022-12-05 23:32:21,035 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5014409339705179, 'Total loss': 0.5014409339705179} | train loss {'Reaction outcome loss': 0.5211224074927603, 'Total loss': 0.5211224074927603}
2022-12-05 23:32:21,035 INFO:     Found new best model at epoch 94
2022-12-05 23:32:21,035 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:21,036 INFO:     Epoch: 95
2022-12-05 23:32:21,721 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5189596889323966, 'Total loss': 0.5189596889323966} | train loss {'Reaction outcome loss': 0.5243828350453951, 'Total loss': 0.5243828350453951}
2022-12-05 23:32:21,721 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:21,721 INFO:     Epoch: 96
2022-12-05 23:32:22,406 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5347511588140975, 'Total loss': 0.5347511588140975} | train loss {'Reaction outcome loss': 0.5203699548709442, 'Total loss': 0.5203699548709442}
2022-12-05 23:32:22,407 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:22,407 INFO:     Epoch: 97
2022-12-05 23:32:23,092 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5197780866955601, 'Total loss': 0.5197780866955601} | train loss {'Reaction outcome loss': 0.5272216056145078, 'Total loss': 0.5272216056145078}
2022-12-05 23:32:23,092 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:23,093 INFO:     Epoch: 98
2022-12-05 23:32:23,777 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5106190096500308, 'Total loss': 0.5106190096500308} | train loss {'Reaction outcome loss': 0.5298074561777946, 'Total loss': 0.5298074561777946}
2022-12-05 23:32:23,777 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:23,777 INFO:     Epoch: 99
2022-12-05 23:32:24,463 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.517417641573174, 'Total loss': 0.517417641573174} | train loss {'Reaction outcome loss': 0.5216613969614892, 'Total loss': 0.5216613969614892}
2022-12-05 23:32:24,463 INFO:     Best model found after epoch 95 of 100.
2022-12-05 23:32:24,463 INFO:   Done with stage: TRAINING
2022-12-05 23:32:24,464 INFO:   Starting stage: EVALUATION
2022-12-05 23:32:24,610 INFO:   Done with stage: EVALUATION
2022-12-05 23:32:24,610 INFO:   Leaving out SEQ value Fold_3
2022-12-05 23:32:24,623 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-12-05 23:32:24,623 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:32:25,257 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:32:25,257 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:32:25,327 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:32:25,327 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:32:25,327 INFO:     No hyperparam tuning for this model
2022-12-05 23:32:25,327 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:32:25,327 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:32:25,328 INFO:     None feature selector for col prot
2022-12-05 23:32:25,328 INFO:     None feature selector for col prot
2022-12-05 23:32:25,328 INFO:     None feature selector for col prot
2022-12-05 23:32:25,329 INFO:     None feature selector for col chem
2022-12-05 23:32:25,329 INFO:     None feature selector for col chem
2022-12-05 23:32:25,329 INFO:     None feature selector for col chem
2022-12-05 23:32:25,329 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:32:25,329 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:32:25,331 INFO:     Number of params in model 215731
2022-12-05 23:32:25,334 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:32:25,334 INFO:   Starting stage: TRAINING
2022-12-05 23:32:25,391 INFO:     Val loss before train {'Reaction outcome loss': 1.0235556426436403, 'Total loss': 1.0235556426436403}
2022-12-05 23:32:25,391 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:25,392 INFO:     Epoch: 0
2022-12-05 23:32:26,088 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.729372252558553, 'Total loss': 0.729372252558553} | train loss {'Reaction outcome loss': 0.8109246829494101, 'Total loss': 0.8109246829494101}
2022-12-05 23:32:26,089 INFO:     Found new best model at epoch 0
2022-12-05 23:32:26,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:26,090 INFO:     Epoch: 1
2022-12-05 23:32:26,790 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6169752970684407, 'Total loss': 0.6169752970684407} | train loss {'Reaction outcome loss': 0.6855439033176078, 'Total loss': 0.6855439033176078}
2022-12-05 23:32:26,790 INFO:     Found new best model at epoch 1
2022-12-05 23:32:26,791 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:26,791 INFO:     Epoch: 2
2022-12-05 23:32:27,487 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6163129557010739, 'Total loss': 0.6163129557010739} | train loss {'Reaction outcome loss': 0.6257511752917141, 'Total loss': 0.6257511752917141}
2022-12-05 23:32:27,487 INFO:     Found new best model at epoch 2
2022-12-05 23:32:27,488 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:27,488 INFO:     Epoch: 3
2022-12-05 23:32:28,184 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.608780253765195, 'Total loss': 0.608780253765195} | train loss {'Reaction outcome loss': 0.606283084168786, 'Total loss': 0.606283084168786}
2022-12-05 23:32:28,184 INFO:     Found new best model at epoch 3
2022-12-05 23:32:28,185 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:28,185 INFO:     Epoch: 4
2022-12-05 23:32:28,881 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5855614865242049, 'Total loss': 0.5855614865242049} | train loss {'Reaction outcome loss': 0.5907406836870264, 'Total loss': 0.5907406836870264}
2022-12-05 23:32:28,881 INFO:     Found new best model at epoch 4
2022-12-05 23:32:28,882 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:28,882 INFO:     Epoch: 5
2022-12-05 23:32:29,575 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5636767072733059, 'Total loss': 0.5636767072733059} | train loss {'Reaction outcome loss': 0.5720357473512165, 'Total loss': 0.5720357473512165}
2022-12-05 23:32:29,575 INFO:     Found new best model at epoch 5
2022-12-05 23:32:29,576 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:29,576 INFO:     Epoch: 6
2022-12-05 23:32:30,270 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6174201161362404, 'Total loss': 0.6174201161362404} | train loss {'Reaction outcome loss': 0.5688071407255579, 'Total loss': 0.5688071407255579}
2022-12-05 23:32:30,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:30,271 INFO:     Epoch: 7
2022-12-05 23:32:30,965 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5636457048876341, 'Total loss': 0.5636457048876341} | train loss {'Reaction outcome loss': 0.570195278244429, 'Total loss': 0.570195278244429}
2022-12-05 23:32:30,966 INFO:     Found new best model at epoch 7
2022-12-05 23:32:30,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:30,966 INFO:     Epoch: 8
2022-12-05 23:32:31,663 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5684509568436201, 'Total loss': 0.5684509568436201} | train loss {'Reaction outcome loss': 0.5557993419590543, 'Total loss': 0.5557993419590543}
2022-12-05 23:32:31,664 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:31,664 INFO:     Epoch: 9
2022-12-05 23:32:32,357 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5649255604244942, 'Total loss': 0.5649255604244942} | train loss {'Reaction outcome loss': 0.5539715068384272, 'Total loss': 0.5539715068384272}
2022-12-05 23:32:32,358 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:32,358 INFO:     Epoch: 10
2022-12-05 23:32:33,054 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5378909159538358, 'Total loss': 0.5378909159538358} | train loss {'Reaction outcome loss': 0.5449365500788219, 'Total loss': 0.5449365500788219}
2022-12-05 23:32:33,055 INFO:     Found new best model at epoch 10
2022-12-05 23:32:33,055 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:33,055 INFO:     Epoch: 11
2022-12-05 23:32:33,748 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5596652107183323, 'Total loss': 0.5596652107183323} | train loss {'Reaction outcome loss': 0.5511805998375181, 'Total loss': 0.5511805998375181}
2022-12-05 23:32:33,748 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:33,749 INFO:     Epoch: 12
2022-12-05 23:32:34,442 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5657509904961253, 'Total loss': 0.5657509904961253} | train loss {'Reaction outcome loss': 0.5517287747781785, 'Total loss': 0.5517287747781785}
2022-12-05 23:32:34,443 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:34,443 INFO:     Epoch: 13
2022-12-05 23:32:35,137 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5459346632624782, 'Total loss': 0.5459346632624782} | train loss {'Reaction outcome loss': 0.5401918449607052, 'Total loss': 0.5401918449607052}
2022-12-05 23:32:35,137 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:35,137 INFO:     Epoch: 14
2022-12-05 23:32:35,831 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5396068706068882, 'Total loss': 0.5396068706068882} | train loss {'Reaction outcome loss': 0.544339761076892, 'Total loss': 0.544339761076892}
2022-12-05 23:32:35,831 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:35,831 INFO:     Epoch: 15
2022-12-05 23:32:36,531 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5680310954881269, 'Total loss': 0.5680310954881269} | train loss {'Reaction outcome loss': 0.5529407505862048, 'Total loss': 0.5529407505862048}
2022-12-05 23:32:36,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:36,532 INFO:     Epoch: 16
2022-12-05 23:32:37,227 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5451935529708862, 'Total loss': 0.5451935529708862} | train loss {'Reaction outcome loss': 0.5421357777763586, 'Total loss': 0.5421357777763586}
2022-12-05 23:32:37,228 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:37,228 INFO:     Epoch: 17
2022-12-05 23:32:37,924 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5295535582442616, 'Total loss': 0.5295535582442616} | train loss {'Reaction outcome loss': 0.5336480662226677, 'Total loss': 0.5336480662226677}
2022-12-05 23:32:37,924 INFO:     Found new best model at epoch 17
2022-12-05 23:32:37,925 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:37,925 INFO:     Epoch: 18
2022-12-05 23:32:38,623 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5976280715576437, 'Total loss': 0.5976280715576437} | train loss {'Reaction outcome loss': 0.5377178830934353, 'Total loss': 0.5377178830934353}
2022-12-05 23:32:38,623 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:38,623 INFO:     Epoch: 19
2022-12-05 23:32:39,318 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5430169552564621, 'Total loss': 0.5430169552564621} | train loss {'Reaction outcome loss': 0.5348169217954893, 'Total loss': 0.5348169217954893}
2022-12-05 23:32:39,318 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:39,318 INFO:     Epoch: 20
2022-12-05 23:32:40,012 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5686677964620812, 'Total loss': 0.5686677964620812} | train loss {'Reaction outcome loss': 0.5314720590583614, 'Total loss': 0.5314720590583614}
2022-12-05 23:32:40,013 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:40,013 INFO:     Epoch: 21
2022-12-05 23:32:40,707 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5385445384092109, 'Total loss': 0.5385445384092109} | train loss {'Reaction outcome loss': 0.5278130314144932, 'Total loss': 0.5278130314144932}
2022-12-05 23:32:40,707 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:40,708 INFO:     Epoch: 22
2022-12-05 23:32:41,402 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5213687669399173, 'Total loss': 0.5213687669399173} | train loss {'Reaction outcome loss': 0.5399307305695581, 'Total loss': 0.5399307305695581}
2022-12-05 23:32:41,403 INFO:     Found new best model at epoch 22
2022-12-05 23:32:41,403 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:41,403 INFO:     Epoch: 23
2022-12-05 23:32:42,098 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.559649355882822, 'Total loss': 0.559649355882822} | train loss {'Reaction outcome loss': 0.5278129867720799, 'Total loss': 0.5278129867720799}
2022-12-05 23:32:42,098 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:42,098 INFO:     Epoch: 24
2022-12-05 23:32:42,794 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5513699550268262, 'Total loss': 0.5513699550268262} | train loss {'Reaction outcome loss': 0.5321569172818152, 'Total loss': 0.5321569172818152}
2022-12-05 23:32:42,795 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:42,795 INFO:     Epoch: 25
2022-12-05 23:32:43,493 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5177678833174151, 'Total loss': 0.5177678833174151} | train loss {'Reaction outcome loss': 0.5297845480505561, 'Total loss': 0.5297845480505561}
2022-12-05 23:32:43,493 INFO:     Found new best model at epoch 25
2022-12-05 23:32:43,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:43,494 INFO:     Epoch: 26
2022-12-05 23:32:44,191 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5489132989977681, 'Total loss': 0.5489132989977681} | train loss {'Reaction outcome loss': 0.5221087117908431, 'Total loss': 0.5221087117908431}
2022-12-05 23:32:44,191 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:44,192 INFO:     Epoch: 27
2022-12-05 23:32:44,889 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5882885119942731, 'Total loss': 0.5882885119942731} | train loss {'Reaction outcome loss': 0.5276446205670716, 'Total loss': 0.5276446205670716}
2022-12-05 23:32:44,890 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:44,890 INFO:     Epoch: 28
2022-12-05 23:32:45,585 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5509307453798693, 'Total loss': 0.5509307453798693} | train loss {'Reaction outcome loss': 0.5261666258705444, 'Total loss': 0.5261666258705444}
2022-12-05 23:32:45,585 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:45,585 INFO:     Epoch: 29
2022-12-05 23:32:46,283 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5579866302567859, 'Total loss': 0.5579866302567859} | train loss {'Reaction outcome loss': 0.5252197542395748, 'Total loss': 0.5252197542395748}
2022-12-05 23:32:46,283 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:46,284 INFO:     Epoch: 30
2022-12-05 23:32:46,984 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.519333707385285, 'Total loss': 0.519333707385285} | train loss {'Reaction outcome loss': 0.5231207010076672, 'Total loss': 0.5231207010076672}
2022-12-05 23:32:46,984 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:46,984 INFO:     Epoch: 31
2022-12-05 23:32:47,686 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5727020900609882, 'Total loss': 0.5727020900609882} | train loss {'Reaction outcome loss': 0.5241170049202247, 'Total loss': 0.5241170049202247}
2022-12-05 23:32:47,686 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:47,686 INFO:     Epoch: 32
2022-12-05 23:32:48,384 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5274720160767089, 'Total loss': 0.5274720160767089} | train loss {'Reaction outcome loss': 0.5235540005149412, 'Total loss': 0.5235540005149412}
2022-12-05 23:32:48,385 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:48,385 INFO:     Epoch: 33
2022-12-05 23:32:49,088 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5703680251919946, 'Total loss': 0.5703680251919946} | train loss {'Reaction outcome loss': 0.5264365044651461, 'Total loss': 0.5264365044651461}
2022-12-05 23:32:49,088 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:49,088 INFO:     Epoch: 34
2022-12-05 23:32:49,789 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5598678072524625, 'Total loss': 0.5598678072524625} | train loss {'Reaction outcome loss': 0.5206806471601861, 'Total loss': 0.5206806471601861}
2022-12-05 23:32:49,789 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:49,789 INFO:     Epoch: 35
2022-12-05 23:32:50,495 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5300622041835341, 'Total loss': 0.5300622041835341} | train loss {'Reaction outcome loss': 0.5162221241559162, 'Total loss': 0.5162221241559162}
2022-12-05 23:32:50,496 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:50,496 INFO:     Epoch: 36
2022-12-05 23:32:51,199 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5334448925284452, 'Total loss': 0.5334448925284452} | train loss {'Reaction outcome loss': 0.5311603808134305, 'Total loss': 0.5311603808134305}
2022-12-05 23:32:51,200 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:51,200 INFO:     Epoch: 37
2022-12-05 23:32:51,903 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5387743489686833, 'Total loss': 0.5387743489686833} | train loss {'Reaction outcome loss': 0.5180566534399986, 'Total loss': 0.5180566534399986}
2022-12-05 23:32:51,903 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:51,903 INFO:     Epoch: 38
2022-12-05 23:32:52,606 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5180242016564968, 'Total loss': 0.5180242016564968} | train loss {'Reaction outcome loss': 0.5178312300780757, 'Total loss': 0.5178312300780757}
2022-12-05 23:32:52,606 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:52,606 INFO:     Epoch: 39
2022-12-05 23:32:53,311 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5342454445916552, 'Total loss': 0.5342454445916552} | train loss {'Reaction outcome loss': 0.5204104036092758, 'Total loss': 0.5204104036092758}
2022-12-05 23:32:53,311 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:53,311 INFO:     Epoch: 40
2022-12-05 23:32:54,013 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5539013736469801, 'Total loss': 0.5539013736469801} | train loss {'Reaction outcome loss': 0.5342863434162296, 'Total loss': 0.5342863434162296}
2022-12-05 23:32:54,013 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:54,014 INFO:     Epoch: 41
2022-12-05 23:32:54,716 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5613968912945237, 'Total loss': 0.5613968912945237} | train loss {'Reaction outcome loss': 0.5221237025422151, 'Total loss': 0.5221237025422151}
2022-12-05 23:32:54,716 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:54,716 INFO:     Epoch: 42
2022-12-05 23:32:55,419 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5488098416217538, 'Total loss': 0.5488098416217538} | train loss {'Reaction outcome loss': 0.5196735210350303, 'Total loss': 0.5196735210350303}
2022-12-05 23:32:55,420 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:55,420 INFO:     Epoch: 43
2022-12-05 23:32:56,122 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.564893786297288, 'Total loss': 0.564893786297288} | train loss {'Reaction outcome loss': 0.51580725573614, 'Total loss': 0.51580725573614}
2022-12-05 23:32:56,122 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:56,122 INFO:     Epoch: 44
2022-12-05 23:32:56,827 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.6314481212649234, 'Total loss': 0.6314481212649234} | train loss {'Reaction outcome loss': 0.5207010063602299, 'Total loss': 0.5207010063602299}
2022-12-05 23:32:56,828 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:56,828 INFO:     Epoch: 45
2022-12-05 23:32:57,531 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5123539244712785, 'Total loss': 0.5123539244712785} | train loss {'Reaction outcome loss': 0.5190434116931235, 'Total loss': 0.5190434116931235}
2022-12-05 23:32:57,532 INFO:     Found new best model at epoch 45
2022-12-05 23:32:57,533 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:57,533 INFO:     Epoch: 46
2022-12-05 23:32:58,237 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5272851066533909, 'Total loss': 0.5272851066533909} | train loss {'Reaction outcome loss': 0.5182431075172346, 'Total loss': 0.5182431075172346}
2022-12-05 23:32:58,237 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:58,237 INFO:     Epoch: 47
2022-12-05 23:32:58,946 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5062927444313847, 'Total loss': 0.5062927444313847} | train loss {'Reaction outcome loss': 0.5128486379370337, 'Total loss': 0.5128486379370337}
2022-12-05 23:32:58,946 INFO:     Found new best model at epoch 47
2022-12-05 23:32:58,947 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:58,947 INFO:     Epoch: 48
2022-12-05 23:32:59,655 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49844906080600826, 'Total loss': 0.49844906080600826} | train loss {'Reaction outcome loss': 0.5126277220542313, 'Total loss': 0.5126277220542313}
2022-12-05 23:32:59,655 INFO:     Found new best model at epoch 48
2022-12-05 23:32:59,655 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:32:59,656 INFO:     Epoch: 49
2022-12-05 23:33:00,360 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5590287197467892, 'Total loss': 0.5590287197467892} | train loss {'Reaction outcome loss': 0.5127315301387037, 'Total loss': 0.5127315301387037}
2022-12-05 23:33:00,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:00,360 INFO:     Epoch: 50
2022-12-05 23:33:01,065 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5308373064495796, 'Total loss': 0.5308373064495796} | train loss {'Reaction outcome loss': 0.5114740728721267, 'Total loss': 0.5114740728721267}
2022-12-05 23:33:01,065 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:01,066 INFO:     Epoch: 51
2022-12-05 23:33:01,774 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5313088131505389, 'Total loss': 0.5313088131505389} | train loss {'Reaction outcome loss': 0.5112743116915226, 'Total loss': 0.5112743116915226}
2022-12-05 23:33:01,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:01,774 INFO:     Epoch: 52
2022-12-05 23:33:02,481 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5493382236292196, 'Total loss': 0.5493382236292196} | train loss {'Reaction outcome loss': 0.5128537641807658, 'Total loss': 0.5128537641807658}
2022-12-05 23:33:02,481 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:02,481 INFO:     Epoch: 53
2022-12-05 23:33:03,188 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5360605086005011, 'Total loss': 0.5360605086005011} | train loss {'Reaction outcome loss': 0.5256546780955597, 'Total loss': 0.5256546780955597}
2022-12-05 23:33:03,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:03,188 INFO:     Epoch: 54
2022-12-05 23:33:03,892 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5308362183182739, 'Total loss': 0.5308362183182739} | train loss {'Reaction outcome loss': 0.5066917969188729, 'Total loss': 0.5066917969188729}
2022-12-05 23:33:03,893 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:03,893 INFO:     Epoch: 55
2022-12-05 23:33:04,598 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5202144862607468, 'Total loss': 0.5202144862607468} | train loss {'Reaction outcome loss': 0.5150479470975087, 'Total loss': 0.5150479470975087}
2022-12-05 23:33:04,598 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:04,598 INFO:     Epoch: 56
2022-12-05 23:33:05,308 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4864495743152707, 'Total loss': 0.4864495743152707} | train loss {'Reaction outcome loss': 0.5142195105674814, 'Total loss': 0.5142195105674814}
2022-12-05 23:33:05,308 INFO:     Found new best model at epoch 56
2022-12-05 23:33:05,309 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:05,309 INFO:     Epoch: 57
2022-12-05 23:33:06,017 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5301952452160591, 'Total loss': 0.5301952452160591} | train loss {'Reaction outcome loss': 0.5216640201015551, 'Total loss': 0.5216640201015551}
2022-12-05 23:33:06,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:06,017 INFO:     Epoch: 58
2022-12-05 23:33:06,720 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5517694367918857, 'Total loss': 0.5517694367918857} | train loss {'Reaction outcome loss': 0.51171884450634, 'Total loss': 0.51171884450634}
2022-12-05 23:33:06,720 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:06,720 INFO:     Epoch: 59
2022-12-05 23:33:07,424 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5217543881992961, 'Total loss': 0.5217543881992961} | train loss {'Reaction outcome loss': 0.519832473920017, 'Total loss': 0.519832473920017}
2022-12-05 23:33:07,424 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:07,424 INFO:     Epoch: 60
2022-12-05 23:33:08,129 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5342261714990749, 'Total loss': 0.5342261714990749} | train loss {'Reaction outcome loss': 0.5147282555088645, 'Total loss': 0.5147282555088645}
2022-12-05 23:33:08,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:08,129 INFO:     Epoch: 61
2022-12-05 23:33:08,835 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5332535553810208, 'Total loss': 0.5332535553810208} | train loss {'Reaction outcome loss': 0.5172916051672131, 'Total loss': 0.5172916051672131}
2022-12-05 23:33:08,835 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:08,835 INFO:     Epoch: 62
2022-12-05 23:33:09,538 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5139081602872804, 'Total loss': 0.5139081602872804} | train loss {'Reaction outcome loss': 0.5053124879715872, 'Total loss': 0.5053124879715872}
2022-12-05 23:33:09,539 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:09,539 INFO:     Epoch: 63
2022-12-05 23:33:10,241 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5125304703102556, 'Total loss': 0.5125304703102556} | train loss {'Reaction outcome loss': 0.5126148166715122, 'Total loss': 0.5126148166715122}
2022-12-05 23:33:10,241 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:10,241 INFO:     Epoch: 64
2022-12-05 23:33:10,946 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5200642361197361, 'Total loss': 0.5200642361197361} | train loss {'Reaction outcome loss': 0.5090601639058746, 'Total loss': 0.5090601639058746}
2022-12-05 23:33:10,946 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:10,946 INFO:     Epoch: 65
2022-12-05 23:33:11,650 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5175606112840564, 'Total loss': 0.5175606112840564} | train loss {'Reaction outcome loss': 0.5187334093402644, 'Total loss': 0.5187334093402644}
2022-12-05 23:33:11,651 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:11,651 INFO:     Epoch: 66
2022-12-05 23:33:12,356 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5292190171258394, 'Total loss': 0.5292190171258394} | train loss {'Reaction outcome loss': 0.5070076037625797, 'Total loss': 0.5070076037625797}
2022-12-05 23:33:12,356 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:12,357 INFO:     Epoch: 67
2022-12-05 23:33:13,064 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5013224108274593, 'Total loss': 0.5013224108274593} | train loss {'Reaction outcome loss': 0.5186726811235068, 'Total loss': 0.5186726811235068}
2022-12-05 23:33:13,064 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:13,064 INFO:     Epoch: 68
2022-12-05 23:33:13,769 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5370664173780486, 'Total loss': 0.5370664173780486} | train loss {'Reaction outcome loss': 0.5096781375955363, 'Total loss': 0.5096781375955363}
2022-12-05 23:33:13,769 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:13,769 INFO:     Epoch: 69
2022-12-05 23:33:14,471 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.49781109496604564, 'Total loss': 0.49781109496604564} | train loss {'Reaction outcome loss': 0.5079257546267548, 'Total loss': 0.5079257546267548}
2022-12-05 23:33:14,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:14,471 INFO:     Epoch: 70
2022-12-05 23:33:15,174 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5036997479754824, 'Total loss': 0.5036997479754824} | train loss {'Reaction outcome loss': 0.5111717496250496, 'Total loss': 0.5111717496250496}
2022-12-05 23:33:15,174 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:15,174 INFO:     Epoch: 71
2022-12-05 23:33:15,880 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.562530378962672, 'Total loss': 0.562530378962672} | train loss {'Reaction outcome loss': 0.5110741482406366, 'Total loss': 0.5110741482406366}
2022-12-05 23:33:15,880 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:15,880 INFO:     Epoch: 72
2022-12-05 23:33:16,583 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5405295595180156, 'Total loss': 0.5405295595180156} | train loss {'Reaction outcome loss': 0.5112658586414134, 'Total loss': 0.5112658586414134}
2022-12-05 23:33:16,584 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:16,584 INFO:     Epoch: 73
2022-12-05 23:33:17,290 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5689290505509044, 'Total loss': 0.5689290505509044} | train loss {'Reaction outcome loss': 0.5103075256357428, 'Total loss': 0.5103075256357428}
2022-12-05 23:33:17,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:17,291 INFO:     Epoch: 74
2022-12-05 23:33:17,999 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.510111752637597, 'Total loss': 0.510111752637597} | train loss {'Reaction outcome loss': 0.5085365658045792, 'Total loss': 0.5085365658045792}
2022-12-05 23:33:17,999 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:17,999 INFO:     Epoch: 75
2022-12-05 23:33:18,704 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5225092858769173, 'Total loss': 0.5225092858769173} | train loss {'Reaction outcome loss': 0.5035219261514359, 'Total loss': 0.5035219261514359}
2022-12-05 23:33:18,705 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:18,705 INFO:     Epoch: 76
2022-12-05 23:33:19,408 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5172544606896334, 'Total loss': 0.5172544606896334} | train loss {'Reaction outcome loss': 0.5025512726336229, 'Total loss': 0.5025512726336229}
2022-12-05 23:33:19,408 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:19,408 INFO:     Epoch: 77
2022-12-05 23:33:20,111 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5527395051579143, 'Total loss': 0.5527395051579143} | train loss {'Reaction outcome loss': 0.511769099924408, 'Total loss': 0.511769099924408}
2022-12-05 23:33:20,112 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:20,112 INFO:     Epoch: 78
2022-12-05 23:33:20,814 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5170868510423705, 'Total loss': 0.5170868510423705} | train loss {'Reaction outcome loss': 0.5072181225433702, 'Total loss': 0.5072181225433702}
2022-12-05 23:33:20,814 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:20,814 INFO:     Epoch: 79
2022-12-05 23:33:21,517 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5331152490405149, 'Total loss': 0.5331152490405149} | train loss {'Reaction outcome loss': 0.5116087350627927, 'Total loss': 0.5116087350627927}
2022-12-05 23:33:21,517 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:21,518 INFO:     Epoch: 80
2022-12-05 23:33:22,221 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5390038712080135, 'Total loss': 0.5390038712080135} | train loss {'Reaction outcome loss': 0.5012271865958073, 'Total loss': 0.5012271865958073}
2022-12-05 23:33:22,221 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:22,221 INFO:     Epoch: 81
2022-12-05 23:33:22,926 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4931923352008642, 'Total loss': 0.4931923352008642} | train loss {'Reaction outcome loss': 0.5046884736931715, 'Total loss': 0.5046884736931715}
2022-12-05 23:33:22,926 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:22,926 INFO:     Epoch: 82
2022-12-05 23:33:23,629 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49338463919107306, 'Total loss': 0.49338463919107306} | train loss {'Reaction outcome loss': 0.5157130824737861, 'Total loss': 0.5157130824737861}
2022-12-05 23:33:23,629 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:23,630 INFO:     Epoch: 83
2022-12-05 23:33:24,331 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5384005848751512, 'Total loss': 0.5384005848751512} | train loss {'Reaction outcome loss': 0.5050539401833152, 'Total loss': 0.5050539401833152}
2022-12-05 23:33:24,331 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:24,332 INFO:     Epoch: 84
2022-12-05 23:33:25,034 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5101447545511778, 'Total loss': 0.5101447545511778} | train loss {'Reaction outcome loss': 0.5067894061813589, 'Total loss': 0.5067894061813589}
2022-12-05 23:33:25,034 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:25,034 INFO:     Epoch: 85
2022-12-05 23:33:25,737 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5036016283340232, 'Total loss': 0.5036016283340232} | train loss {'Reaction outcome loss': 0.5008819641270599, 'Total loss': 0.5008819641270599}
2022-12-05 23:33:25,737 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:25,738 INFO:     Epoch: 86
2022-12-05 23:33:26,441 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.49265703143075457, 'Total loss': 0.49265703143075457} | train loss {'Reaction outcome loss': 0.5122708350908561, 'Total loss': 0.5122708350908561}
2022-12-05 23:33:26,441 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:26,441 INFO:     Epoch: 87
2022-12-05 23:33:27,143 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5176637290522109, 'Total loss': 0.5176637290522109} | train loss {'Reaction outcome loss': 0.5111253621270422, 'Total loss': 0.5111253621270422}
2022-12-05 23:33:27,143 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:27,143 INFO:     Epoch: 88
2022-12-05 23:33:27,847 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5362852382105451, 'Total loss': 0.5362852382105451} | train loss {'Reaction outcome loss': 0.5098713358528302, 'Total loss': 0.5098713358528302}
2022-12-05 23:33:27,848 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:27,848 INFO:     Epoch: 89
2022-12-05 23:33:28,551 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49450767871945406, 'Total loss': 0.49450767871945406} | train loss {'Reaction outcome loss': 0.5082876983358234, 'Total loss': 0.5082876983358234}
2022-12-05 23:33:28,551 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:28,551 INFO:     Epoch: 90
2022-12-05 23:33:29,255 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5173265220120896, 'Total loss': 0.5173265220120896} | train loss {'Reaction outcome loss': 0.5149033719398937, 'Total loss': 0.5149033719398937}
2022-12-05 23:33:29,255 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:29,255 INFO:     Epoch: 91
2022-12-05 23:33:29,958 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5346988578175389, 'Total loss': 0.5346988578175389} | train loss {'Reaction outcome loss': 0.5039354256186329, 'Total loss': 0.5039354256186329}
2022-12-05 23:33:29,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:29,959 INFO:     Epoch: 92
2022-12-05 23:33:30,665 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5185950682606808, 'Total loss': 0.5185950682606808} | train loss {'Reaction outcome loss': 0.5117599102134098, 'Total loss': 0.5117599102134098}
2022-12-05 23:33:30,665 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:30,665 INFO:     Epoch: 93
2022-12-05 23:33:31,370 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4952274737663047, 'Total loss': 0.4952274737663047} | train loss {'Reaction outcome loss': 0.5129074771873287, 'Total loss': 0.5129074771873287}
2022-12-05 23:33:31,371 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:31,371 INFO:     Epoch: 94
2022-12-05 23:33:32,075 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5186948429706485, 'Total loss': 0.5186948429706485} | train loss {'Reaction outcome loss': 0.5161645959024547, 'Total loss': 0.5161645959024547}
2022-12-05 23:33:32,075 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:32,075 INFO:     Epoch: 95
2022-12-05 23:33:32,779 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5169565289519554, 'Total loss': 0.5169565289519554} | train loss {'Reaction outcome loss': 0.5163951984560881, 'Total loss': 0.5163951984560881}
2022-12-05 23:33:32,779 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:32,779 INFO:     Epoch: 96
2022-12-05 23:33:33,482 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5326911578344744, 'Total loss': 0.5326911578344744} | train loss {'Reaction outcome loss': 0.5118043306054639, 'Total loss': 0.5118043306054639}
2022-12-05 23:33:33,482 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:33,482 INFO:     Epoch: 97
2022-12-05 23:33:34,186 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5086855798266655, 'Total loss': 0.5086855798266655} | train loss {'Reaction outcome loss': 0.5045330753458328, 'Total loss': 0.5045330753458328}
2022-12-05 23:33:34,187 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:34,187 INFO:     Epoch: 98
2022-12-05 23:33:34,891 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.502292723156685, 'Total loss': 0.502292723156685} | train loss {'Reaction outcome loss': 0.5096983988387663, 'Total loss': 0.5096983988387663}
2022-12-05 23:33:34,891 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:34,892 INFO:     Epoch: 99
2022-12-05 23:33:35,595 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.521705441003622, 'Total loss': 0.521705441003622} | train loss {'Reaction outcome loss': 0.5175732697253345, 'Total loss': 0.5175732697253345}
2022-12-05 23:33:35,595 INFO:     Best model found after epoch 57 of 100.
2022-12-05 23:33:35,595 INFO:   Done with stage: TRAINING
2022-12-05 23:33:35,595 INFO:   Starting stage: EVALUATION
2022-12-05 23:33:35,731 INFO:   Done with stage: EVALUATION
2022-12-05 23:33:35,731 INFO:   Leaving out SEQ value Fold_4
2022-12-05 23:33:35,744 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:33:35,744 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:33:36,388 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:33:36,388 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:33:36,459 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:33:36,459 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:33:36,459 INFO:     No hyperparam tuning for this model
2022-12-05 23:33:36,459 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:33:36,459 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:33:36,460 INFO:     None feature selector for col prot
2022-12-05 23:33:36,460 INFO:     None feature selector for col prot
2022-12-05 23:33:36,460 INFO:     None feature selector for col prot
2022-12-05 23:33:36,461 INFO:     None feature selector for col chem
2022-12-05 23:33:36,461 INFO:     None feature selector for col chem
2022-12-05 23:33:36,461 INFO:     None feature selector for col chem
2022-12-05 23:33:36,461 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:33:36,461 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:33:36,463 INFO:     Number of params in model 215731
2022-12-05 23:33:36,466 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:33:36,466 INFO:   Starting stage: TRAINING
2022-12-05 23:33:36,524 INFO:     Val loss before train {'Reaction outcome loss': 0.9667334319515661, 'Total loss': 0.9667334319515661}
2022-12-05 23:33:36,524 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:36,525 INFO:     Epoch: 0
2022-12-05 23:33:37,234 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6751140904697505, 'Total loss': 0.6751140904697505} | train loss {'Reaction outcome loss': 0.8192628608782765, 'Total loss': 0.8192628608782765}
2022-12-05 23:33:37,235 INFO:     Found new best model at epoch 0
2022-12-05 23:33:37,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:37,235 INFO:     Epoch: 1
2022-12-05 23:33:37,946 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.665713407099247, 'Total loss': 0.665713407099247} | train loss {'Reaction outcome loss': 0.6754082878561396, 'Total loss': 0.6754082878561396}
2022-12-05 23:33:37,946 INFO:     Found new best model at epoch 1
2022-12-05 23:33:37,947 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:37,947 INFO:     Epoch: 2
2022-12-05 23:33:38,657 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5986416604031216, 'Total loss': 0.5986416604031216} | train loss {'Reaction outcome loss': 0.6346706757661302, 'Total loss': 0.6346706757661302}
2022-12-05 23:33:38,657 INFO:     Found new best model at epoch 2
2022-12-05 23:33:38,658 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:38,658 INFO:     Epoch: 3
2022-12-05 23:33:39,372 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6040003469044511, 'Total loss': 0.6040003469044511} | train loss {'Reaction outcome loss': 0.6028632899286294, 'Total loss': 0.6028632899286294}
2022-12-05 23:33:39,372 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:39,372 INFO:     Epoch: 4
2022-12-05 23:33:40,086 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6032745242118835, 'Total loss': 0.6032745242118835} | train loss {'Reaction outcome loss': 0.5886873821822195, 'Total loss': 0.5886873821822195}
2022-12-05 23:33:40,086 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:40,087 INFO:     Epoch: 5
2022-12-05 23:33:40,797 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5614676563577219, 'Total loss': 0.5614676563577219} | train loss {'Reaction outcome loss': 0.5845083931559011, 'Total loss': 0.5845083931559011}
2022-12-05 23:33:40,797 INFO:     Found new best model at epoch 5
2022-12-05 23:33:40,798 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:40,798 INFO:     Epoch: 6
2022-12-05 23:33:41,512 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6328567219051447, 'Total loss': 0.6328567219051447} | train loss {'Reaction outcome loss': 0.5657615218809259, 'Total loss': 0.5657615218809259}
2022-12-05 23:33:41,512 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:41,512 INFO:     Epoch: 7
2022-12-05 23:33:42,224 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5870077610015869, 'Total loss': 0.5870077610015869} | train loss {'Reaction outcome loss': 0.5658194154636701, 'Total loss': 0.5658194154636701}
2022-12-05 23:33:42,224 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:42,224 INFO:     Epoch: 8
2022-12-05 23:33:42,934 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5514091571623628, 'Total loss': 0.5514091571623628} | train loss {'Reaction outcome loss': 0.5536580996716071, 'Total loss': 0.5536580996716071}
2022-12-05 23:33:42,934 INFO:     Found new best model at epoch 8
2022-12-05 23:33:42,935 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:42,935 INFO:     Epoch: 9
2022-12-05 23:33:43,646 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5763596259057522, 'Total loss': 0.5763596259057522} | train loss {'Reaction outcome loss': 0.5423465961070075, 'Total loss': 0.5423465961070075}
2022-12-05 23:33:43,646 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:43,646 INFO:     Epoch: 10
2022-12-05 23:33:44,356 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5317713658918034, 'Total loss': 0.5317713658918034} | train loss {'Reaction outcome loss': 0.5555094083552419, 'Total loss': 0.5555094083552419}
2022-12-05 23:33:44,356 INFO:     Found new best model at epoch 10
2022-12-05 23:33:44,357 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:44,357 INFO:     Epoch: 11
2022-12-05 23:33:45,068 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5434368063103069, 'Total loss': 0.5434368063103069} | train loss {'Reaction outcome loss': 0.54785352785457, 'Total loss': 0.54785352785457}
2022-12-05 23:33:45,068 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:45,068 INFO:     Epoch: 12
2022-12-05 23:33:45,779 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5371260033412413, 'Total loss': 0.5371260033412413} | train loss {'Reaction outcome loss': 0.5483904570522096, 'Total loss': 0.5483904570522096}
2022-12-05 23:33:45,779 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:45,779 INFO:     Epoch: 13
2022-12-05 23:33:46,491 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5247985591942613, 'Total loss': 0.5247985591942613} | train loss {'Reaction outcome loss': 0.541406600521161, 'Total loss': 0.541406600521161}
2022-12-05 23:33:46,492 INFO:     Found new best model at epoch 13
2022-12-05 23:33:46,492 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:46,492 INFO:     Epoch: 14
2022-12-05 23:33:47,202 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5601383061571554, 'Total loss': 0.5601383061571554} | train loss {'Reaction outcome loss': 0.5476280745224431, 'Total loss': 0.5476280745224431}
2022-12-05 23:33:47,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:47,202 INFO:     Epoch: 15
2022-12-05 23:33:47,911 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5468851212750782, 'Total loss': 0.5468851212750782} | train loss {'Reaction outcome loss': 0.5582186502823041, 'Total loss': 0.5582186502823041}
2022-12-05 23:33:47,912 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:47,912 INFO:     Epoch: 16
2022-12-05 23:33:48,622 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5604853230443868, 'Total loss': 0.5604853230443868} | train loss {'Reaction outcome loss': 0.5405686838544814, 'Total loss': 0.5405686838544814}
2022-12-05 23:33:48,622 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:48,622 INFO:     Epoch: 17
2022-12-05 23:33:49,335 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5229833688248288, 'Total loss': 0.5229833688248288} | train loss {'Reaction outcome loss': 0.5502978354571801, 'Total loss': 0.5502978354571801}
2022-12-05 23:33:49,335 INFO:     Found new best model at epoch 17
2022-12-05 23:33:49,336 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:49,336 INFO:     Epoch: 18
2022-12-05 23:33:50,047 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.570538302036849, 'Total loss': 0.570538302036849} | train loss {'Reaction outcome loss': 0.539613815936965, 'Total loss': 0.539613815936965}
2022-12-05 23:33:50,047 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:50,047 INFO:     Epoch: 19
2022-12-05 23:33:50,755 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5206879834559831, 'Total loss': 0.5206879834559831} | train loss {'Reaction outcome loss': 0.549515231056252, 'Total loss': 0.549515231056252}
2022-12-05 23:33:50,755 INFO:     Found new best model at epoch 19
2022-12-05 23:33:50,756 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:50,756 INFO:     Epoch: 20
2022-12-05 23:33:51,459 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.524852997877381, 'Total loss': 0.524852997877381} | train loss {'Reaction outcome loss': 0.5445199894157016, 'Total loss': 0.5445199894157016}
2022-12-05 23:33:51,459 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:51,459 INFO:     Epoch: 21
2022-12-05 23:33:52,162 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5414095730944113, 'Total loss': 0.5414095730944113} | train loss {'Reaction outcome loss': 0.5366381965728424, 'Total loss': 0.5366381965728424}
2022-12-05 23:33:52,162 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:52,163 INFO:     Epoch: 22
2022-12-05 23:33:52,864 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.6037169749086554, 'Total loss': 0.6037169749086554} | train loss {'Reaction outcome loss': 0.5429510762575667, 'Total loss': 0.5429510762575667}
2022-12-05 23:33:52,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:52,864 INFO:     Epoch: 23
2022-12-05 23:33:53,564 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5565043538808823, 'Total loss': 0.5565043538808823} | train loss {'Reaction outcome loss': 0.5477957833513074, 'Total loss': 0.5477957833513074}
2022-12-05 23:33:53,564 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:53,564 INFO:     Epoch: 24
2022-12-05 23:33:54,271 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5290861664847895, 'Total loss': 0.5290861664847895} | train loss {'Reaction outcome loss': 0.5256230223939004, 'Total loss': 0.5256230223939004}
2022-12-05 23:33:54,271 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:54,271 INFO:     Epoch: 25
2022-12-05 23:33:54,974 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5459492155774073, 'Total loss': 0.5459492155774073} | train loss {'Reaction outcome loss': 0.5361472097364998, 'Total loss': 0.5361472097364998}
2022-12-05 23:33:54,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:54,974 INFO:     Epoch: 26
2022-12-05 23:33:55,677 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5368249460377477, 'Total loss': 0.5368249460377477} | train loss {'Reaction outcome loss': 0.534306932229413, 'Total loss': 0.534306932229413}
2022-12-05 23:33:55,677 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:55,677 INFO:     Epoch: 27
2022-12-05 23:33:56,378 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5564791272309694, 'Total loss': 0.5564791272309694} | train loss {'Reaction outcome loss': 0.5239225384526649, 'Total loss': 0.5239225384526649}
2022-12-05 23:33:56,378 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:56,378 INFO:     Epoch: 28
2022-12-05 23:33:57,077 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5817582566629756, 'Total loss': 0.5817582566629756} | train loss {'Reaction outcome loss': 0.5273820880332939, 'Total loss': 0.5273820880332939}
2022-12-05 23:33:57,077 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:57,077 INFO:     Epoch: 29
2022-12-05 23:33:57,778 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5228652256456289, 'Total loss': 0.5228652256456289} | train loss {'Reaction outcome loss': 0.561296211744127, 'Total loss': 0.561296211744127}
2022-12-05 23:33:57,778 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:57,778 INFO:     Epoch: 30
2022-12-05 23:33:58,482 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5697424621744589, 'Total loss': 0.5697424621744589} | train loss {'Reaction outcome loss': 0.5273223552430569, 'Total loss': 0.5273223552430569}
2022-12-05 23:33:58,482 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:58,482 INFO:     Epoch: 31
2022-12-05 23:33:59,183 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5231838849457827, 'Total loss': 0.5231838849457827} | train loss {'Reaction outcome loss': 0.5222816163229074, 'Total loss': 0.5222816163229074}
2022-12-05 23:33:59,184 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:59,184 INFO:     Epoch: 32
2022-12-05 23:33:59,885 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5206814381209287, 'Total loss': 0.5206814381209287} | train loss {'Reaction outcome loss': 0.5270451379087773, 'Total loss': 0.5270451379087773}
2022-12-05 23:33:59,886 INFO:     Found new best model at epoch 32
2022-12-05 23:33:59,886 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:33:59,886 INFO:     Epoch: 33
2022-12-05 23:34:00,588 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5172413323413242, 'Total loss': 0.5172413323413242} | train loss {'Reaction outcome loss': 0.5291425771558815, 'Total loss': 0.5291425771558815}
2022-12-05 23:34:00,588 INFO:     Found new best model at epoch 33
2022-12-05 23:34:00,589 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:00,589 INFO:     Epoch: 34
2022-12-05 23:34:01,289 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5229383385316893, 'Total loss': 0.5229383385316893} | train loss {'Reaction outcome loss': 0.5201280701015643, 'Total loss': 0.5201280701015643}
2022-12-05 23:34:01,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:01,290 INFO:     Epoch: 35
2022-12-05 23:34:01,990 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5117959539321336, 'Total loss': 0.5117959539321336} | train loss {'Reaction outcome loss': 0.5204220777339781, 'Total loss': 0.5204220777339781}
2022-12-05 23:34:01,991 INFO:     Found new best model at epoch 35
2022-12-05 23:34:01,991 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:01,991 INFO:     Epoch: 36
2022-12-05 23:34:02,692 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5359810414639387, 'Total loss': 0.5359810414639387} | train loss {'Reaction outcome loss': 0.5317971187564525, 'Total loss': 0.5317971187564525}
2022-12-05 23:34:02,692 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:02,692 INFO:     Epoch: 37
2022-12-05 23:34:03,395 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49912280894138594, 'Total loss': 0.49912280894138594} | train loss {'Reaction outcome loss': 0.5187711485243036, 'Total loss': 0.5187711485243036}
2022-12-05 23:34:03,395 INFO:     Found new best model at epoch 37
2022-12-05 23:34:03,396 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:03,396 INFO:     Epoch: 38
2022-12-05 23:34:04,096 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.530929630791599, 'Total loss': 0.530929630791599} | train loss {'Reaction outcome loss': 0.5218068328704911, 'Total loss': 0.5218068328704911}
2022-12-05 23:34:04,096 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:04,097 INFO:     Epoch: 39
2022-12-05 23:34:04,799 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5508773143995892, 'Total loss': 0.5508773143995892} | train loss {'Reaction outcome loss': 0.5319450501510911, 'Total loss': 0.5319450501510911}
2022-12-05 23:34:04,799 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:04,799 INFO:     Epoch: 40
2022-12-05 23:34:05,504 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5251762589270418, 'Total loss': 0.5251762589270418} | train loss {'Reaction outcome loss': 0.5189288288113559, 'Total loss': 0.5189288288113559}
2022-12-05 23:34:05,505 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:05,505 INFO:     Epoch: 41
2022-12-05 23:34:06,209 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5398167486895215, 'Total loss': 0.5398167486895215} | train loss {'Reaction outcome loss': 0.524401795918401, 'Total loss': 0.524401795918401}
2022-12-05 23:34:06,210 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:06,210 INFO:     Epoch: 42
2022-12-05 23:34:06,910 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5081504007632082, 'Total loss': 0.5081504007632082} | train loss {'Reaction outcome loss': 0.5242565861839031, 'Total loss': 0.5242565861839031}
2022-12-05 23:34:06,910 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:06,910 INFO:     Epoch: 43
2022-12-05 23:34:07,611 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5302380831404165, 'Total loss': 0.5302380831404165} | train loss {'Reaction outcome loss': 0.5173355745646994, 'Total loss': 0.5173355745646994}
2022-12-05 23:34:07,611 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:07,611 INFO:     Epoch: 44
2022-12-05 23:34:08,313 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5098600749942389, 'Total loss': 0.5098600749942389} | train loss {'Reaction outcome loss': 0.5165657983255773, 'Total loss': 0.5165657983255773}
2022-12-05 23:34:08,313 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:08,313 INFO:     Epoch: 45
2022-12-05 23:34:09,018 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5098692862824961, 'Total loss': 0.5098692862824961} | train loss {'Reaction outcome loss': 0.5192608958796451, 'Total loss': 0.5192608958796451}
2022-12-05 23:34:09,018 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:09,018 INFO:     Epoch: 46
2022-12-05 23:34:09,719 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5134405334564772, 'Total loss': 0.5134405334564772} | train loss {'Reaction outcome loss': 0.5300971625244569, 'Total loss': 0.5300971625244569}
2022-12-05 23:34:09,719 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:09,719 INFO:     Epoch: 47
2022-12-05 23:34:10,422 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5187506069513884, 'Total loss': 0.5187506069513884} | train loss {'Reaction outcome loss': 0.5266263676196458, 'Total loss': 0.5266263676196458}
2022-12-05 23:34:10,422 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:10,422 INFO:     Epoch: 48
2022-12-05 23:34:11,123 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5304458893158219, 'Total loss': 0.5304458893158219} | train loss {'Reaction outcome loss': 0.5218828185367198, 'Total loss': 0.5218828185367198}
2022-12-05 23:34:11,124 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:11,124 INFO:     Epoch: 49
2022-12-05 23:34:11,827 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5002938136458397, 'Total loss': 0.5002938136458397} | train loss {'Reaction outcome loss': 0.5306458588433169, 'Total loss': 0.5306458588433169}
2022-12-05 23:34:11,827 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:11,827 INFO:     Epoch: 50
2022-12-05 23:34:12,529 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5265456742861054, 'Total loss': 0.5265456742861054} | train loss {'Reaction outcome loss': 0.5181915531394935, 'Total loss': 0.5181915531394935}
2022-12-05 23:34:12,529 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:12,529 INFO:     Epoch: 51
2022-12-05 23:34:13,230 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5402197939428416, 'Total loss': 0.5402197939428416} | train loss {'Reaction outcome loss': 0.5129887065454292, 'Total loss': 0.5129887065454292}
2022-12-05 23:34:13,230 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:13,230 INFO:     Epoch: 52
2022-12-05 23:34:13,934 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5190687694332816, 'Total loss': 0.5190687694332816} | train loss {'Reaction outcome loss': 0.5207950800415958, 'Total loss': 0.5207950800415958}
2022-12-05 23:34:13,934 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:13,934 INFO:     Epoch: 53
2022-12-05 23:34:14,639 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5814508138732477, 'Total loss': 0.5814508138732477} | train loss {'Reaction outcome loss': 0.5098607637259641, 'Total loss': 0.5098607637259641}
2022-12-05 23:34:14,639 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:14,639 INFO:     Epoch: 54
2022-12-05 23:34:15,341 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5291920317844911, 'Total loss': 0.5291920317844911} | train loss {'Reaction outcome loss': 0.527714454189041, 'Total loss': 0.527714454189041}
2022-12-05 23:34:15,341 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:15,341 INFO:     Epoch: 55
2022-12-05 23:34:16,043 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5237749733708121, 'Total loss': 0.5237749733708121} | train loss {'Reaction outcome loss': 0.5084368229394982, 'Total loss': 0.5084368229394982}
2022-12-05 23:34:16,043 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:16,043 INFO:     Epoch: 56
2022-12-05 23:34:16,747 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5114410770210353, 'Total loss': 0.5114410770210353} | train loss {'Reaction outcome loss': 0.5244546469285903, 'Total loss': 0.5244546469285903}
2022-12-05 23:34:16,747 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:16,747 INFO:     Epoch: 57
2022-12-05 23:34:17,448 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5038309503685344, 'Total loss': 0.5038309503685344} | train loss {'Reaction outcome loss': 0.5126726326371471, 'Total loss': 0.5126726326371471}
2022-12-05 23:34:17,448 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:17,448 INFO:     Epoch: 58
2022-12-05 23:34:18,148 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.6310840851881288, 'Total loss': 0.6310840851881288} | train loss {'Reaction outcome loss': 0.5180182671136702, 'Total loss': 0.5180182671136702}
2022-12-05 23:34:18,149 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:18,149 INFO:     Epoch: 59
2022-12-05 23:34:18,850 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.526139762591232, 'Total loss': 0.526139762591232} | train loss {'Reaction outcome loss': 0.5257984831144935, 'Total loss': 0.5257984831144935}
2022-12-05 23:34:18,850 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:18,851 INFO:     Epoch: 60
2022-12-05 23:34:19,555 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5531000555916266, 'Total loss': 0.5531000555916266} | train loss {'Reaction outcome loss': 0.5159758001203961, 'Total loss': 0.5159758001203961}
2022-12-05 23:34:19,555 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:19,556 INFO:     Epoch: 61
2022-12-05 23:34:20,257 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5095802030780099, 'Total loss': 0.5095802030780099} | train loss {'Reaction outcome loss': 0.5491736522811627, 'Total loss': 0.5491736522811627}
2022-12-05 23:34:20,257 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:20,257 INFO:     Epoch: 62
2022-12-05 23:34:20,958 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5317819707772948, 'Total loss': 0.5317819707772948} | train loss {'Reaction outcome loss': 0.5157268002133455, 'Total loss': 0.5157268002133455}
2022-12-05 23:34:20,958 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:20,958 INFO:     Epoch: 63
2022-12-05 23:34:21,659 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5067567036233165, 'Total loss': 0.5067567036233165} | train loss {'Reaction outcome loss': 0.5113811472106559, 'Total loss': 0.5113811472106559}
2022-12-05 23:34:21,660 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:21,660 INFO:     Epoch: 64
2022-12-05 23:34:22,367 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.48822818899696524, 'Total loss': 0.48822818899696524} | train loss {'Reaction outcome loss': 0.5161214645705487, 'Total loss': 0.5161214645705487}
2022-12-05 23:34:22,367 INFO:     Found new best model at epoch 64
2022-12-05 23:34:22,367 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:22,367 INFO:     Epoch: 65
2022-12-05 23:34:23,069 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5235440700568936, 'Total loss': 0.5235440700568936} | train loss {'Reaction outcome loss': 0.5129887109946626, 'Total loss': 0.5129887109946626}
2022-12-05 23:34:23,069 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:23,069 INFO:     Epoch: 66
2022-12-05 23:34:23,774 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5455007383769209, 'Total loss': 0.5455007383769209} | train loss {'Reaction outcome loss': 0.525909039896992, 'Total loss': 0.525909039896992}
2022-12-05 23:34:23,774 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:23,774 INFO:     Epoch: 67
2022-12-05 23:34:24,475 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49828500469977205, 'Total loss': 0.49828500469977205} | train loss {'Reaction outcome loss': 0.5214564052187962, 'Total loss': 0.5214564052187962}
2022-12-05 23:34:24,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:24,475 INFO:     Epoch: 68
2022-12-05 23:34:25,180 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5073998177593405, 'Total loss': 0.5073998177593405} | train loss {'Reaction outcome loss': 0.5113950632361748, 'Total loss': 0.5113950632361748}
2022-12-05 23:34:25,180 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:25,181 INFO:     Epoch: 69
2022-12-05 23:34:25,881 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5354950428009033, 'Total loss': 0.5354950428009033} | train loss {'Reaction outcome loss': 0.5126496318139528, 'Total loss': 0.5126496318139528}
2022-12-05 23:34:25,881 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:25,882 INFO:     Epoch: 70
2022-12-05 23:34:26,586 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5270561562343077, 'Total loss': 0.5270561562343077} | train loss {'Reaction outcome loss': 0.5115756795021446, 'Total loss': 0.5115756795021446}
2022-12-05 23:34:26,586 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:26,586 INFO:     Epoch: 71
2022-12-05 23:34:27,290 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5516157109629024, 'Total loss': 0.5516157109629024} | train loss {'Reaction outcome loss': 0.5140606570038718, 'Total loss': 0.5140606570038718}
2022-12-05 23:34:27,290 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:27,290 INFO:     Epoch: 72
2022-12-05 23:34:27,998 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5278805311430584, 'Total loss': 0.5278805311430584} | train loss {'Reaction outcome loss': 0.5097649196984797, 'Total loss': 0.5097649196984797}
2022-12-05 23:34:27,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:27,998 INFO:     Epoch: 73
2022-12-05 23:34:28,703 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5047598562457345, 'Total loss': 0.5047598562457345} | train loss {'Reaction outcome loss': 0.5257590205563225, 'Total loss': 0.5257590205563225}
2022-12-05 23:34:28,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:28,703 INFO:     Epoch: 74
2022-12-05 23:34:29,404 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5149632319808006, 'Total loss': 0.5149632319808006} | train loss {'Reaction outcome loss': 0.5234465354729277, 'Total loss': 0.5234465354729277}
2022-12-05 23:34:29,404 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:29,404 INFO:     Epoch: 75
2022-12-05 23:34:30,105 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.524539245123213, 'Total loss': 0.524539245123213} | train loss {'Reaction outcome loss': 0.5275818552927449, 'Total loss': 0.5275818552927449}
2022-12-05 23:34:30,106 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:30,106 INFO:     Epoch: 76
2022-12-05 23:34:30,808 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5402855175462636, 'Total loss': 0.5402855175462636} | train loss {'Reaction outcome loss': 0.5098105966441544, 'Total loss': 0.5098105966441544}
2022-12-05 23:34:30,808 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:30,808 INFO:     Epoch: 77
2022-12-05 23:34:31,509 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.519412250681357, 'Total loss': 0.519412250681357} | train loss {'Reaction outcome loss': 0.517081935848543, 'Total loss': 0.517081935848543}
2022-12-05 23:34:31,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:31,509 INFO:     Epoch: 78
2022-12-05 23:34:32,211 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.528433065184138, 'Total loss': 0.528433065184138} | train loss {'Reaction outcome loss': 0.5146674436181482, 'Total loss': 0.5146674436181482}
2022-12-05 23:34:32,211 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:32,211 INFO:     Epoch: 79
2022-12-05 23:34:32,917 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5329312776977365, 'Total loss': 0.5329312776977365} | train loss {'Reaction outcome loss': 0.5117627407279458, 'Total loss': 0.5117627407279458}
2022-12-05 23:34:32,917 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:32,917 INFO:     Epoch: 80
2022-12-05 23:34:33,623 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49344963986765256, 'Total loss': 0.49344963986765256} | train loss {'Reaction outcome loss': 0.5126943850983122, 'Total loss': 0.5126943850983122}
2022-12-05 23:34:33,624 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:33,624 INFO:     Epoch: 81
2022-12-05 23:34:34,326 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5300731462511149, 'Total loss': 0.5300731462511149} | train loss {'Reaction outcome loss': 0.5189585358749035, 'Total loss': 0.5189585358749035}
2022-12-05 23:34:34,326 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:34,326 INFO:     Epoch: 82
2022-12-05 23:34:35,031 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5880129743706096, 'Total loss': 0.5880129743706096} | train loss {'Reaction outcome loss': 0.5323747009762868, 'Total loss': 0.5323747009762868}
2022-12-05 23:34:35,031 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:35,031 INFO:     Epoch: 83
2022-12-05 23:34:35,732 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5198977189985189, 'Total loss': 0.5198977189985189} | train loss {'Reaction outcome loss': 0.5256213087301987, 'Total loss': 0.5256213087301987}
2022-12-05 23:34:35,732 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:35,732 INFO:     Epoch: 84
2022-12-05 23:34:36,433 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5163720304315741, 'Total loss': 0.5163720304315741} | train loss {'Reaction outcome loss': 0.5192656754666887, 'Total loss': 0.5192656754666887}
2022-12-05 23:34:36,433 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:36,434 INFO:     Epoch: 85
2022-12-05 23:34:37,135 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5138047181747176, 'Total loss': 0.5138047181747176} | train loss {'Reaction outcome loss': 0.5111630268183797, 'Total loss': 0.5111630268183797}
2022-12-05 23:34:37,135 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:37,135 INFO:     Epoch: 86
2022-12-05 23:34:37,836 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5070739835500717, 'Total loss': 0.5070739835500717} | train loss {'Reaction outcome loss': 0.5058382708534055, 'Total loss': 0.5058382708534055}
2022-12-05 23:34:37,836 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:37,836 INFO:     Epoch: 87
2022-12-05 23:34:38,538 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5340299064462836, 'Total loss': 0.5340299064462836} | train loss {'Reaction outcome loss': 0.5061482315965993, 'Total loss': 0.5061482315965993}
2022-12-05 23:34:38,538 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:38,538 INFO:     Epoch: 88
2022-12-05 23:34:39,243 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5122143124992197, 'Total loss': 0.5122143124992197} | train loss {'Reaction outcome loss': 0.5138797220898422, 'Total loss': 0.5138797220898422}
2022-12-05 23:34:39,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:39,243 INFO:     Epoch: 89
2022-12-05 23:34:39,947 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5313215546987273, 'Total loss': 0.5313215546987273} | train loss {'Reaction outcome loss': 0.5068832843666726, 'Total loss': 0.5068832843666726}
2022-12-05 23:34:39,948 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:39,948 INFO:     Epoch: 90
2022-12-05 23:34:40,650 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5444101867350665, 'Total loss': 0.5444101867350665} | train loss {'Reaction outcome loss': 0.5242368197030867, 'Total loss': 0.5242368197030867}
2022-12-05 23:34:40,650 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:40,650 INFO:     Epoch: 91
2022-12-05 23:34:41,352 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5221458239988848, 'Total loss': 0.5221458239988848} | train loss {'Reaction outcome loss': 0.5295860356526819, 'Total loss': 0.5295860356526819}
2022-12-05 23:34:41,352 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:41,353 INFO:     Epoch: 92
2022-12-05 23:34:42,056 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5570001832463525, 'Total loss': 0.5570001832463525} | train loss {'Reaction outcome loss': 0.5104640523793726, 'Total loss': 0.5104640523793726}
2022-12-05 23:34:42,056 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:42,057 INFO:     Epoch: 93
2022-12-05 23:34:42,761 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5039060000668872, 'Total loss': 0.5039060000668872} | train loss {'Reaction outcome loss': 0.5184722697203942, 'Total loss': 0.5184722697203942}
2022-12-05 23:34:42,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:42,761 INFO:     Epoch: 94
2022-12-05 23:34:43,461 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5128450424156406, 'Total loss': 0.5128450424156406} | train loss {'Reaction outcome loss': 0.5116483671854624, 'Total loss': 0.5116483671854624}
2022-12-05 23:34:43,461 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:43,461 INFO:     Epoch: 95
2022-12-05 23:34:44,162 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5796750262379646, 'Total loss': 0.5796750262379646} | train loss {'Reaction outcome loss': 0.5146904550341942, 'Total loss': 0.5146904550341942}
2022-12-05 23:34:44,162 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:44,163 INFO:     Epoch: 96
2022-12-05 23:34:44,864 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5329971787604418, 'Total loss': 0.5329971787604418} | train loss {'Reaction outcome loss': 0.5085989278364127, 'Total loss': 0.5085989278364127}
2022-12-05 23:34:44,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:44,864 INFO:     Epoch: 97
2022-12-05 23:34:45,567 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5575828078118238, 'Total loss': 0.5575828078118238} | train loss {'Reaction outcome loss': 0.5104901852154056, 'Total loss': 0.5104901852154056}
2022-12-05 23:34:45,567 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:45,567 INFO:     Epoch: 98
2022-12-05 23:34:46,268 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5164969306100499, 'Total loss': 0.5164969306100499} | train loss {'Reaction outcome loss': 0.5166486734920276, 'Total loss': 0.5166486734920276}
2022-12-05 23:34:46,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:46,269 INFO:     Epoch: 99
2022-12-05 23:34:46,971 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4947236573154276, 'Total loss': 0.4947236573154276} | train loss {'Reaction outcome loss': 0.5152769500789373, 'Total loss': 0.5152769500789373}
2022-12-05 23:34:46,971 INFO:     Best model found after epoch 65 of 100.
2022-12-05 23:34:46,971 INFO:   Done with stage: TRAINING
2022-12-05 23:34:46,971 INFO:   Starting stage: EVALUATION
2022-12-05 23:34:47,094 INFO:   Done with stage: EVALUATION
2022-12-05 23:34:47,095 INFO:   Leaving out SEQ value Fold_5
2022-12-05 23:34:47,107 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:34:47,107 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:34:47,731 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:34:47,731 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:34:47,802 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:34:47,802 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:34:47,802 INFO:     No hyperparam tuning for this model
2022-12-05 23:34:47,802 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:34:47,802 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:34:47,803 INFO:     None feature selector for col prot
2022-12-05 23:34:47,803 INFO:     None feature selector for col prot
2022-12-05 23:34:47,803 INFO:     None feature selector for col prot
2022-12-05 23:34:47,803 INFO:     None feature selector for col chem
2022-12-05 23:34:47,804 INFO:     None feature selector for col chem
2022-12-05 23:34:47,804 INFO:     None feature selector for col chem
2022-12-05 23:34:47,804 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:34:47,804 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:34:47,805 INFO:     Number of params in model 215731
2022-12-05 23:34:47,808 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:34:47,808 INFO:   Starting stage: TRAINING
2022-12-05 23:34:47,866 INFO:     Val loss before train {'Reaction outcome loss': 1.024738677523353, 'Total loss': 1.024738677523353}
2022-12-05 23:34:47,866 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:47,866 INFO:     Epoch: 0
2022-12-05 23:34:48,568 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7526128779758107, 'Total loss': 0.7526128779758107} | train loss {'Reaction outcome loss': 0.8084587377575245, 'Total loss': 0.8084587377575245}
2022-12-05 23:34:48,568 INFO:     Found new best model at epoch 0
2022-12-05 23:34:48,568 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:48,569 INFO:     Epoch: 1
2022-12-05 23:34:49,274 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6754005578431216, 'Total loss': 0.6754005578431216} | train loss {'Reaction outcome loss': 0.6636733544258936, 'Total loss': 0.6636733544258936}
2022-12-05 23:34:49,275 INFO:     Found new best model at epoch 1
2022-12-05 23:34:49,275 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:49,275 INFO:     Epoch: 2
2022-12-05 23:34:49,978 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6940712610428984, 'Total loss': 0.6940712610428984} | train loss {'Reaction outcome loss': 0.6293360551419528, 'Total loss': 0.6293360551419528}
2022-12-05 23:34:49,978 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:49,978 INFO:     Epoch: 3
2022-12-05 23:34:50,681 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.625923712822524, 'Total loss': 0.625923712822524} | train loss {'Reaction outcome loss': 0.5933530313765955, 'Total loss': 0.5933530313765955}
2022-12-05 23:34:50,681 INFO:     Found new best model at epoch 3
2022-12-05 23:34:50,682 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:50,682 INFO:     Epoch: 4
2022-12-05 23:34:51,384 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7257710776545785, 'Total loss': 0.7257710776545785} | train loss {'Reaction outcome loss': 0.5820750445730773, 'Total loss': 0.5820750445730773}
2022-12-05 23:34:51,384 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:51,385 INFO:     Epoch: 5
2022-12-05 23:34:52,086 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6091710390015082, 'Total loss': 0.6091710390015082} | train loss {'Reaction outcome loss': 0.587237478509123, 'Total loss': 0.587237478509123}
2022-12-05 23:34:52,086 INFO:     Found new best model at epoch 5
2022-12-05 23:34:52,087 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:52,087 INFO:     Epoch: 6
2022-12-05 23:34:52,792 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6483584114096381, 'Total loss': 0.6483584114096381} | train loss {'Reaction outcome loss': 0.5683482245180137, 'Total loss': 0.5683482245180137}
2022-12-05 23:34:52,792 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:52,792 INFO:     Epoch: 7
2022-12-05 23:34:53,499 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6022779880599543, 'Total loss': 0.6022779880599543} | train loss {'Reaction outcome loss': 0.5624999159019486, 'Total loss': 0.5624999159019486}
2022-12-05 23:34:53,499 INFO:     Found new best model at epoch 7
2022-12-05 23:34:53,500 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:53,500 INFO:     Epoch: 8
2022-12-05 23:34:54,202 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.617596572773023, 'Total loss': 0.617596572773023} | train loss {'Reaction outcome loss': 0.5685532839463548, 'Total loss': 0.5685532839463548}
2022-12-05 23:34:54,202 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:54,202 INFO:     Epoch: 9
2022-12-05 23:34:54,904 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.6000676717270504, 'Total loss': 0.6000676717270504} | train loss {'Reaction outcome loss': 0.5594419480456032, 'Total loss': 0.5594419480456032}
2022-12-05 23:34:54,904 INFO:     Found new best model at epoch 9
2022-12-05 23:34:54,905 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:54,905 INFO:     Epoch: 10
2022-12-05 23:34:55,609 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5820331627672369, 'Total loss': 0.5820331627672369} | train loss {'Reaction outcome loss': 0.5605281456882655, 'Total loss': 0.5605281456882655}
2022-12-05 23:34:55,609 INFO:     Found new best model at epoch 10
2022-12-05 23:34:55,610 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:55,610 INFO:     Epoch: 11
2022-12-05 23:34:56,315 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5756825154477899, 'Total loss': 0.5756825154477899} | train loss {'Reaction outcome loss': 0.5493350267968318, 'Total loss': 0.5493350267968318}
2022-12-05 23:34:56,315 INFO:     Found new best model at epoch 11
2022-12-05 23:34:56,316 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:56,316 INFO:     Epoch: 12
2022-12-05 23:34:57,017 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5821170833977786, 'Total loss': 0.5821170833977786} | train loss {'Reaction outcome loss': 0.547458611458902, 'Total loss': 0.547458611458902}
2022-12-05 23:34:57,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:57,017 INFO:     Epoch: 13
2022-12-05 23:34:57,718 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5930271676995538, 'Total loss': 0.5930271676995538} | train loss {'Reaction outcome loss': 0.55008635826801, 'Total loss': 0.55008635826801}
2022-12-05 23:34:57,718 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:57,718 INFO:     Epoch: 14
2022-12-05 23:34:58,424 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5900835435498845, 'Total loss': 0.5900835435498845} | train loss {'Reaction outcome loss': 0.5477325640796016, 'Total loss': 0.5477325640796016}
2022-12-05 23:34:58,424 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:58,424 INFO:     Epoch: 15
2022-12-05 23:34:59,129 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5623456558043306, 'Total loss': 0.5623456558043306} | train loss {'Reaction outcome loss': 0.5414315749879791, 'Total loss': 0.5414315749879791}
2022-12-05 23:34:59,129 INFO:     Found new best model at epoch 15
2022-12-05 23:34:59,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:59,130 INFO:     Epoch: 16
2022-12-05 23:34:59,830 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5574178550053727, 'Total loss': 0.5574178550053727} | train loss {'Reaction outcome loss': 0.5419615037166156, 'Total loss': 0.5419615037166156}
2022-12-05 23:34:59,831 INFO:     Found new best model at epoch 16
2022-12-05 23:34:59,831 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:34:59,831 INFO:     Epoch: 17
2022-12-05 23:35:00,532 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.605192592875524, 'Total loss': 0.605192592875524} | train loss {'Reaction outcome loss': 0.5545341233734177, 'Total loss': 0.5545341233734177}
2022-12-05 23:35:00,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:00,532 INFO:     Epoch: 18
2022-12-05 23:35:01,233 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5814198573881929, 'Total loss': 0.5814198573881929} | train loss {'Reaction outcome loss': 0.559806348582511, 'Total loss': 0.559806348582511}
2022-12-05 23:35:01,234 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:01,234 INFO:     Epoch: 19
2022-12-05 23:35:01,935 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.6180061664093625, 'Total loss': 0.6180061664093625} | train loss {'Reaction outcome loss': 0.5449530370684288, 'Total loss': 0.5449530370684288}
2022-12-05 23:35:01,935 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:01,935 INFO:     Epoch: 20
2022-12-05 23:35:02,639 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.6278064332225106, 'Total loss': 0.6278064332225106} | train loss {'Reaction outcome loss': 0.5433408963656136, 'Total loss': 0.5433408963656136}
2022-12-05 23:35:02,639 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:02,639 INFO:     Epoch: 21
2022-12-05 23:35:03,340 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5522609190507368, 'Total loss': 0.5522609190507368} | train loss {'Reaction outcome loss': 0.5485158024529214, 'Total loss': 0.5485158024529214}
2022-12-05 23:35:03,340 INFO:     Found new best model at epoch 21
2022-12-05 23:35:03,340 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:03,340 INFO:     Epoch: 22
2022-12-05 23:35:04,041 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.6037943268364127, 'Total loss': 0.6037943268364127} | train loss {'Reaction outcome loss': 0.5362319169860137, 'Total loss': 0.5362319169860137}
2022-12-05 23:35:04,041 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:04,041 INFO:     Epoch: 23
2022-12-05 23:35:04,742 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5596523162993517, 'Total loss': 0.5596523162993517} | train loss {'Reaction outcome loss': 0.5352098009123011, 'Total loss': 0.5352098009123011}
2022-12-05 23:35:04,742 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:04,742 INFO:     Epoch: 24
2022-12-05 23:35:05,446 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5778521062298254, 'Total loss': 0.5778521062298254} | train loss {'Reaction outcome loss': 0.531719943832772, 'Total loss': 0.531719943832772}
2022-12-05 23:35:05,446 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:05,446 INFO:     Epoch: 25
2022-12-05 23:35:06,149 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.6281676854599606, 'Total loss': 0.6281676854599606} | train loss {'Reaction outcome loss': 0.5349157382602151, 'Total loss': 0.5349157382602151}
2022-12-05 23:35:06,149 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:06,149 INFO:     Epoch: 26
2022-12-05 23:35:06,851 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5736493102528832, 'Total loss': 0.5736493102528832} | train loss {'Reaction outcome loss': 0.5406593458975858, 'Total loss': 0.5406593458975858}
2022-12-05 23:35:06,851 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:06,852 INFO:     Epoch: 27
2022-12-05 23:35:07,553 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5715530975298448, 'Total loss': 0.5715530975298448} | train loss {'Reaction outcome loss': 0.5324341497319912, 'Total loss': 0.5324341497319912}
2022-12-05 23:35:07,554 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:07,554 INFO:     Epoch: 28
2022-12-05 23:35:08,254 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5580467906865206, 'Total loss': 0.5580467906865206} | train loss {'Reaction outcome loss': 0.5435344581058633, 'Total loss': 0.5435344581058633}
2022-12-05 23:35:08,254 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:08,254 INFO:     Epoch: 29
2022-12-05 23:35:08,956 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5762082223187793, 'Total loss': 0.5762082223187793} | train loss {'Reaction outcome loss': 0.5509072622427573, 'Total loss': 0.5509072622427573}
2022-12-05 23:35:08,956 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:08,956 INFO:     Epoch: 30
2022-12-05 23:35:09,660 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.6275827031243931, 'Total loss': 0.6275827031243931} | train loss {'Reaction outcome loss': 0.5368882311500518, 'Total loss': 0.5368882311500518}
2022-12-05 23:35:09,660 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:09,660 INFO:     Epoch: 31
2022-12-05 23:35:10,365 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5713638399134983, 'Total loss': 0.5713638399134983} | train loss {'Reaction outcome loss': 0.5413633236248679, 'Total loss': 0.5413633236248679}
2022-12-05 23:35:10,366 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:10,366 INFO:     Epoch: 32
2022-12-05 23:35:11,071 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5788811355490576, 'Total loss': 0.5788811355490576} | train loss {'Reaction outcome loss': 0.528234454467591, 'Total loss': 0.528234454467591}
2022-12-05 23:35:11,071 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:11,071 INFO:     Epoch: 33
2022-12-05 23:35:11,773 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5655548233877529, 'Total loss': 0.5655548233877529} | train loss {'Reaction outcome loss': 0.5285202881343934, 'Total loss': 0.5285202881343934}
2022-12-05 23:35:11,773 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:11,774 INFO:     Epoch: 34
2022-12-05 23:35:12,475 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.6392801092429594, 'Total loss': 0.6392801092429594} | train loss {'Reaction outcome loss': 0.5306985424718393, 'Total loss': 0.5306985424718393}
2022-12-05 23:35:12,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:12,475 INFO:     Epoch: 35
2022-12-05 23:35:13,180 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.6074015725065361, 'Total loss': 0.6074015725065361} | train loss {'Reaction outcome loss': 0.5324663111434774, 'Total loss': 0.5324663111434774}
2022-12-05 23:35:13,180 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:13,180 INFO:     Epoch: 36
2022-12-05 23:35:13,886 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5757565247741613, 'Total loss': 0.5757565247741613} | train loss {'Reaction outcome loss': 0.5413417110317632, 'Total loss': 0.5413417110317632}
2022-12-05 23:35:13,886 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:13,886 INFO:     Epoch: 37
2022-12-05 23:35:14,590 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5770861452276056, 'Total loss': 0.5770861452276056} | train loss {'Reaction outcome loss': 0.5390827923047881, 'Total loss': 0.5390827923047881}
2022-12-05 23:35:14,590 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:14,590 INFO:     Epoch: 38
2022-12-05 23:35:15,294 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5927248712290417, 'Total loss': 0.5927248712290417} | train loss {'Reaction outcome loss': 0.5288342925218436, 'Total loss': 0.5288342925218436}
2022-12-05 23:35:15,294 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:15,294 INFO:     Epoch: 39
2022-12-05 23:35:15,996 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5593550923195753, 'Total loss': 0.5593550923195753} | train loss {'Reaction outcome loss': 0.5362418789250648, 'Total loss': 0.5362418789250648}
2022-12-05 23:35:15,996 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:15,996 INFO:     Epoch: 40
2022-12-05 23:35:16,702 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.6238105256449092, 'Total loss': 0.6238105256449092} | train loss {'Reaction outcome loss': 0.5482830063775483, 'Total loss': 0.5482830063775483}
2022-12-05 23:35:16,702 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:16,703 INFO:     Epoch: 41
2022-12-05 23:35:17,408 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5757634192705154, 'Total loss': 0.5757634192705154} | train loss {'Reaction outcome loss': 0.5415545760951785, 'Total loss': 0.5415545760951785}
2022-12-05 23:35:17,408 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:17,408 INFO:     Epoch: 42
2022-12-05 23:35:18,112 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5583832087841901, 'Total loss': 0.5583832087841901} | train loss {'Reaction outcome loss': 0.5274768154992748, 'Total loss': 0.5274768154992748}
2022-12-05 23:35:18,112 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:18,112 INFO:     Epoch: 43
2022-12-05 23:35:18,815 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5423121946779165, 'Total loss': 0.5423121946779165} | train loss {'Reaction outcome loss': 0.5262472604812398, 'Total loss': 0.5262472604812398}
2022-12-05 23:35:18,815 INFO:     Found new best model at epoch 43
2022-12-05 23:35:18,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:18,816 INFO:     Epoch: 44
2022-12-05 23:35:19,520 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5679945884780451, 'Total loss': 0.5679945884780451} | train loss {'Reaction outcome loss': 0.5367163183838732, 'Total loss': 0.5367163183838732}
2022-12-05 23:35:19,520 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:19,521 INFO:     Epoch: 45
2022-12-05 23:35:20,226 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.561049719425765, 'Total loss': 0.561049719425765} | train loss {'Reaction outcome loss': 0.5255868099479057, 'Total loss': 0.5255868099479057}
2022-12-05 23:35:20,227 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:20,227 INFO:     Epoch: 46
2022-12-05 23:35:20,929 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5457018559629266, 'Total loss': 0.5457018559629266} | train loss {'Reaction outcome loss': 0.5320471308612631, 'Total loss': 0.5320471308612631}
2022-12-05 23:35:20,929 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:20,929 INFO:     Epoch: 47
2022-12-05 23:35:21,632 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5818169387904081, 'Total loss': 0.5818169387904081} | train loss {'Reaction outcome loss': 0.5419501270118513, 'Total loss': 0.5419501270118513}
2022-12-05 23:35:21,632 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:21,632 INFO:     Epoch: 48
2022-12-05 23:35:22,337 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5530496259981935, 'Total loss': 0.5530496259981935} | train loss {'Reaction outcome loss': 0.5387499568916043, 'Total loss': 0.5387499568916043}
2022-12-05 23:35:22,337 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:22,337 INFO:     Epoch: 49
2022-12-05 23:35:23,039 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5646156665276397, 'Total loss': 0.5646156665276397} | train loss {'Reaction outcome loss': 0.5279130398744514, 'Total loss': 0.5279130398744514}
2022-12-05 23:35:23,039 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:23,040 INFO:     Epoch: 50
2022-12-05 23:35:23,741 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5498943173072555, 'Total loss': 0.5498943173072555} | train loss {'Reaction outcome loss': 0.5386837105519375, 'Total loss': 0.5386837105519375}
2022-12-05 23:35:23,741 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:23,742 INFO:     Epoch: 51
2022-12-05 23:35:24,444 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5835765200582418, 'Total loss': 0.5835765200582418} | train loss {'Reaction outcome loss': 0.5328005513087715, 'Total loss': 0.5328005513087715}
2022-12-05 23:35:24,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:24,444 INFO:     Epoch: 52
2022-12-05 23:35:25,147 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5779289508407767, 'Total loss': 0.5779289508407767} | train loss {'Reaction outcome loss': 0.5266666413560087, 'Total loss': 0.5266666413560087}
2022-12-05 23:35:25,147 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:25,147 INFO:     Epoch: 53
2022-12-05 23:35:25,850 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5498824468390509, 'Total loss': 0.5498824468390509} | train loss {'Reaction outcome loss': 0.52038545796067, 'Total loss': 0.52038545796067}
2022-12-05 23:35:25,850 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:25,850 INFO:     Epoch: 54
2022-12-05 23:35:26,553 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5638996945186094, 'Total loss': 0.5638996945186094} | train loss {'Reaction outcome loss': 0.5319049886243064, 'Total loss': 0.5319049886243064}
2022-12-05 23:35:26,553 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:26,553 INFO:     Epoch: 55
2022-12-05 23:35:27,258 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5755572827024893, 'Total loss': 0.5755572827024893} | train loss {'Reaction outcome loss': 0.5230858733779505, 'Total loss': 0.5230858733779505}
2022-12-05 23:35:27,259 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:27,259 INFO:     Epoch: 56
2022-12-05 23:35:27,964 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5943536297841505, 'Total loss': 0.5943536297841505} | train loss {'Reaction outcome loss': 0.5272621078108464, 'Total loss': 0.5272621078108464}
2022-12-05 23:35:27,964 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:27,964 INFO:     Epoch: 57
2022-12-05 23:35:28,668 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5854326601732861, 'Total loss': 0.5854326601732861} | train loss {'Reaction outcome loss': 0.534612076243891, 'Total loss': 0.534612076243891}
2022-12-05 23:35:28,669 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:28,669 INFO:     Epoch: 58
2022-12-05 23:35:29,373 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5498610186305913, 'Total loss': 0.5498610186305913} | train loss {'Reaction outcome loss': 0.5362526235672144, 'Total loss': 0.5362526235672144}
2022-12-05 23:35:29,373 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:29,373 INFO:     Epoch: 59
2022-12-05 23:35:30,077 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.6022383902560581, 'Total loss': 0.6022383902560581} | train loss {'Reaction outcome loss': 0.5318232856178091, 'Total loss': 0.5318232856178091}
2022-12-05 23:35:30,078 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:30,078 INFO:     Epoch: 60
2022-12-05 23:35:30,782 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5904617749831893, 'Total loss': 0.5904617749831893} | train loss {'Reaction outcome loss': 0.5181729675907838, 'Total loss': 0.5181729675907838}
2022-12-05 23:35:30,782 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:30,783 INFO:     Epoch: 61
2022-12-05 23:35:31,492 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5929439501328901, 'Total loss': 0.5929439501328901} | train loss {'Reaction outcome loss': 0.5314351209262123, 'Total loss': 0.5314351209262123}
2022-12-05 23:35:31,492 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:31,492 INFO:     Epoch: 62
2022-12-05 23:35:32,195 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5421535894274712, 'Total loss': 0.5421535894274712} | train loss {'Reaction outcome loss': 0.5262550144543049, 'Total loss': 0.5262550144543049}
2022-12-05 23:35:32,196 INFO:     Found new best model at epoch 62
2022-12-05 23:35:32,197 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:32,197 INFO:     Epoch: 63
2022-12-05 23:35:32,900 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5826136916875839, 'Total loss': 0.5826136916875839} | train loss {'Reaction outcome loss': 0.5374252522281306, 'Total loss': 0.5374252522281306}
2022-12-05 23:35:32,900 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:32,900 INFO:     Epoch: 64
2022-12-05 23:35:33,602 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5558768808841705, 'Total loss': 0.5558768808841705} | train loss {'Reaction outcome loss': 0.5415215350476353, 'Total loss': 0.5415215350476353}
2022-12-05 23:35:33,602 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:33,602 INFO:     Epoch: 65
2022-12-05 23:35:34,305 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5700708085840399, 'Total loss': 0.5700708085840399} | train loss {'Reaction outcome loss': 0.5327484895463898, 'Total loss': 0.5327484895463898}
2022-12-05 23:35:34,305 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:34,305 INFO:     Epoch: 66
2022-12-05 23:35:35,007 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5448838452046568, 'Total loss': 0.5448838452046568} | train loss {'Reaction outcome loss': 0.5280778120886459, 'Total loss': 0.5280778120886459}
2022-12-05 23:35:35,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:35,007 INFO:     Epoch: 67
2022-12-05 23:35:35,710 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5528386208144102, 'Total loss': 0.5528386208144102} | train loss {'Reaction outcome loss': 0.5264087723575623, 'Total loss': 0.5264087723575623}
2022-12-05 23:35:35,710 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:35,710 INFO:     Epoch: 68
2022-12-05 23:35:36,414 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5375065932219679, 'Total loss': 0.5375065932219679} | train loss {'Reaction outcome loss': 0.5277551051968263, 'Total loss': 0.5277551051968263}
2022-12-05 23:35:36,414 INFO:     Found new best model at epoch 68
2022-12-05 23:35:36,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:36,415 INFO:     Epoch: 69
2022-12-05 23:35:37,115 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5620715790851549, 'Total loss': 0.5620715790851549} | train loss {'Reaction outcome loss': 0.5263046805826035, 'Total loss': 0.5263046805826035}
2022-12-05 23:35:37,115 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:37,115 INFO:     Epoch: 70
2022-12-05 23:35:37,817 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5444006743756208, 'Total loss': 0.5444006743756208} | train loss {'Reaction outcome loss': 0.5329518614992922, 'Total loss': 0.5329518614992922}
2022-12-05 23:35:37,817 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:37,817 INFO:     Epoch: 71
2022-12-05 23:35:38,518 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5740151730450717, 'Total loss': 0.5740151730450717} | train loss {'Reaction outcome loss': 0.5332721143900624, 'Total loss': 0.5332721143900624}
2022-12-05 23:35:38,519 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:38,519 INFO:     Epoch: 72
2022-12-05 23:35:39,238 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5390332476659254, 'Total loss': 0.5390332476659254} | train loss {'Reaction outcome loss': 0.5300978857134035, 'Total loss': 0.5300978857134035}
2022-12-05 23:35:39,238 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:39,238 INFO:     Epoch: 73
2022-12-05 23:35:39,959 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5820208896290172, 'Total loss': 0.5820208896290172} | train loss {'Reaction outcome loss': 0.5294841593093718, 'Total loss': 0.5294841593093718}
2022-12-05 23:35:39,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:39,959 INFO:     Epoch: 74
2022-12-05 23:35:40,677 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5574030513790521, 'Total loss': 0.5574030513790521} | train loss {'Reaction outcome loss': 0.52675423940063, 'Total loss': 0.52675423940063}
2022-12-05 23:35:40,677 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:40,677 INFO:     Epoch: 75
2022-12-05 23:35:41,396 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.6273368021303957, 'Total loss': 0.6273368021303957} | train loss {'Reaction outcome loss': 0.524449851228158, 'Total loss': 0.524449851228158}
2022-12-05 23:35:41,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:41,397 INFO:     Epoch: 76
2022-12-05 23:35:42,119 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5672106309370561, 'Total loss': 0.5672106309370561} | train loss {'Reaction outcome loss': 0.5318603373183548, 'Total loss': 0.5318603373183548}
2022-12-05 23:35:42,120 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:42,120 INFO:     Epoch: 77
2022-12-05 23:35:42,842 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.702856264331124, 'Total loss': 0.702856264331124} | train loss {'Reaction outcome loss': 0.5221018355626327, 'Total loss': 0.5221018355626327}
2022-12-05 23:35:42,842 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:42,842 INFO:     Epoch: 78
2022-12-05 23:35:43,560 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7527956678108736, 'Total loss': 0.7527956678108736} | train loss {'Reaction outcome loss': 0.5410845443184077, 'Total loss': 0.5410845443184077}
2022-12-05 23:35:43,560 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:43,560 INFO:     Epoch: 79
2022-12-05 23:35:44,282 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5466135791079565, 'Total loss': 0.5466135791079565} | train loss {'Reaction outcome loss': 0.5306040703164421, 'Total loss': 0.5306040703164421}
2022-12-05 23:35:44,282 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:44,282 INFO:     Epoch: 80
2022-12-05 23:35:44,999 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5579868690534071, 'Total loss': 0.5579868690534071} | train loss {'Reaction outcome loss': 0.5226204329536028, 'Total loss': 0.5226204329536028}
2022-12-05 23:35:45,000 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:45,000 INFO:     Epoch: 81
2022-12-05 23:35:45,719 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5529225075786764, 'Total loss': 0.5529225075786764} | train loss {'Reaction outcome loss': 0.5240305724896883, 'Total loss': 0.5240305724896883}
2022-12-05 23:35:45,720 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:45,720 INFO:     Epoch: 82
2022-12-05 23:35:46,425 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5988476445729082, 'Total loss': 0.5988476445729082} | train loss {'Reaction outcome loss': 0.5314317988721948, 'Total loss': 0.5314317988721948}
2022-12-05 23:35:46,425 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:46,425 INFO:     Epoch: 83
2022-12-05 23:35:47,127 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5564352158795703, 'Total loss': 0.5564352158795703} | train loss {'Reaction outcome loss': 0.5401514754724889, 'Total loss': 0.5401514754724889}
2022-12-05 23:35:47,127 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:47,127 INFO:     Epoch: 84
2022-12-05 23:35:47,829 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5549546852707863, 'Total loss': 0.5549546852707863} | train loss {'Reaction outcome loss': 0.529682338901377, 'Total loss': 0.529682338901377}
2022-12-05 23:35:47,829 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:47,829 INFO:     Epoch: 85
2022-12-05 23:35:48,533 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.560047833756967, 'Total loss': 0.560047833756967} | train loss {'Reaction outcome loss': 0.5265727152648242, 'Total loss': 0.5265727152648242}
2022-12-05 23:35:48,534 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:48,534 INFO:     Epoch: 86
2022-12-05 23:35:49,234 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5605243413963101, 'Total loss': 0.5605243413963101} | train loss {'Reaction outcome loss': 0.52911737428503, 'Total loss': 0.52911737428503}
2022-12-05 23:35:49,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:49,235 INFO:     Epoch: 87
2022-12-05 23:35:49,938 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5568680505860936, 'Total loss': 0.5568680505860936} | train loss {'Reaction outcome loss': 0.5286571329783815, 'Total loss': 0.5286571329783815}
2022-12-05 23:35:49,938 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:49,938 INFO:     Epoch: 88
2022-12-05 23:35:50,639 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5785347853194583, 'Total loss': 0.5785347853194583} | train loss {'Reaction outcome loss': 0.5234942994860985, 'Total loss': 0.5234942994860985}
2022-12-05 23:35:50,640 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:50,640 INFO:     Epoch: 89
2022-12-05 23:35:51,342 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5458621850067918, 'Total loss': 0.5458621850067918} | train loss {'Reaction outcome loss': 0.5208326789893603, 'Total loss': 0.5208326789893603}
2022-12-05 23:35:51,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:51,343 INFO:     Epoch: 90
2022-12-05 23:35:52,044 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5912558223036203, 'Total loss': 0.5912558223036203} | train loss {'Reaction outcome loss': 0.5284173597378076, 'Total loss': 0.5284173597378076}
2022-12-05 23:35:52,045 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:52,045 INFO:     Epoch: 91
2022-12-05 23:35:52,746 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5744853399016641, 'Total loss': 0.5744853399016641} | train loss {'Reaction outcome loss': 0.533765207478392, 'Total loss': 0.533765207478392}
2022-12-05 23:35:52,746 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:52,747 INFO:     Epoch: 92
2022-12-05 23:35:53,447 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6095899451862682, 'Total loss': 0.6095899451862682} | train loss {'Reaction outcome loss': 0.5280535318832166, 'Total loss': 0.5280535318832166}
2022-12-05 23:35:53,447 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:53,447 INFO:     Epoch: 93
2022-12-05 23:35:54,148 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5869301594793797, 'Total loss': 0.5869301594793797} | train loss {'Reaction outcome loss': 0.5302912876583062, 'Total loss': 0.5302912876583062}
2022-12-05 23:35:54,148 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:54,148 INFO:     Epoch: 94
2022-12-05 23:35:54,849 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5825361680578102, 'Total loss': 0.5825361680578102} | train loss {'Reaction outcome loss': 0.5286173831958038, 'Total loss': 0.5286173831958038}
2022-12-05 23:35:54,849 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:54,849 INFO:     Epoch: 95
2022-12-05 23:35:55,550 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5624361844225363, 'Total loss': 0.5624361844225363} | train loss {'Reaction outcome loss': 0.5302328271527401, 'Total loss': 0.5302328271527401}
2022-12-05 23:35:55,550 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:55,550 INFO:     Epoch: 96
2022-12-05 23:35:56,251 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5591058819131418, 'Total loss': 0.5591058819131418} | train loss {'Reaction outcome loss': 0.5233612625825743, 'Total loss': 0.5233612625825743}
2022-12-05 23:35:56,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:56,251 INFO:     Epoch: 97
2022-12-05 23:35:56,955 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.542562301185998, 'Total loss': 0.542562301185998} | train loss {'Reaction outcome loss': 0.5374143443971511, 'Total loss': 0.5374143443971511}
2022-12-05 23:35:56,955 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:56,955 INFO:     Epoch: 98
2022-12-05 23:35:57,656 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5609312213279984, 'Total loss': 0.5609312213279984} | train loss {'Reaction outcome loss': 0.5290500489082414, 'Total loss': 0.5290500489082414}
2022-12-05 23:35:57,656 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:57,656 INFO:     Epoch: 99
2022-12-05 23:35:58,357 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5422017642042853, 'Total loss': 0.5422017642042853} | train loss {'Reaction outcome loss': 0.531755696951981, 'Total loss': 0.531755696951981}
2022-12-05 23:35:58,357 INFO:     Best model found after epoch 69 of 100.
2022-12-05 23:35:58,357 INFO:   Done with stage: TRAINING
2022-12-05 23:35:58,357 INFO:   Starting stage: EVALUATION
2022-12-05 23:35:58,481 INFO:   Done with stage: EVALUATION
2022-12-05 23:35:58,481 INFO:   Leaving out SEQ value Fold_6
2022-12-05 23:35:58,494 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:35:58,494 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:35:59,128 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:35:59,128 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:35:59,200 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:35:59,200 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:35:59,200 INFO:     No hyperparam tuning for this model
2022-12-05 23:35:59,200 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:35:59,200 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:35:59,201 INFO:     None feature selector for col prot
2022-12-05 23:35:59,201 INFO:     None feature selector for col prot
2022-12-05 23:35:59,201 INFO:     None feature selector for col prot
2022-12-05 23:35:59,202 INFO:     None feature selector for col chem
2022-12-05 23:35:59,202 INFO:     None feature selector for col chem
2022-12-05 23:35:59,202 INFO:     None feature selector for col chem
2022-12-05 23:35:59,202 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:35:59,202 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:35:59,204 INFO:     Number of params in model 215731
2022-12-05 23:35:59,207 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:35:59,207 INFO:   Starting stage: TRAINING
2022-12-05 23:35:59,265 INFO:     Val loss before train {'Reaction outcome loss': 1.0164725330065598, 'Total loss': 1.0164725330065598}
2022-12-05 23:35:59,265 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:59,265 INFO:     Epoch: 0
2022-12-05 23:35:59,969 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8208318115635351, 'Total loss': 0.8208318115635351} | train loss {'Reaction outcome loss': 0.8026263841733277, 'Total loss': 0.8026263841733277}
2022-12-05 23:35:59,969 INFO:     Found new best model at epoch 0
2022-12-05 23:35:59,970 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:35:59,970 INFO:     Epoch: 1
2022-12-05 23:36:00,676 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.646030646156181, 'Total loss': 0.646030646156181} | train loss {'Reaction outcome loss': 0.68529575598626, 'Total loss': 0.68529575598626}
2022-12-05 23:36:00,676 INFO:     Found new best model at epoch 1
2022-12-05 23:36:00,677 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:00,677 INFO:     Epoch: 2
2022-12-05 23:36:01,378 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6679404452443123, 'Total loss': 0.6679404452443123} | train loss {'Reaction outcome loss': 0.6300715189879602, 'Total loss': 0.6300715189879602}
2022-12-05 23:36:01,378 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:01,378 INFO:     Epoch: 3
2022-12-05 23:36:02,081 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6034159694205631, 'Total loss': 0.6034159694205631} | train loss {'Reaction outcome loss': 0.6112746272145616, 'Total loss': 0.6112746272145616}
2022-12-05 23:36:02,081 INFO:     Found new best model at epoch 3
2022-12-05 23:36:02,082 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:02,082 INFO:     Epoch: 4
2022-12-05 23:36:02,783 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6124268377369101, 'Total loss': 0.6124268377369101} | train loss {'Reaction outcome loss': 0.5930049922543499, 'Total loss': 0.5930049922543499}
2022-12-05 23:36:02,784 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:02,784 INFO:     Epoch: 5
2022-12-05 23:36:03,486 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.585388333960013, 'Total loss': 0.585388333960013} | train loss {'Reaction outcome loss': 0.5772228434018278, 'Total loss': 0.5772228434018278}
2022-12-05 23:36:03,487 INFO:     Found new best model at epoch 5
2022-12-05 23:36:03,487 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:03,487 INFO:     Epoch: 6
2022-12-05 23:36:04,189 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.599167385223237, 'Total loss': 0.599167385223237} | train loss {'Reaction outcome loss': 0.5704765884499801, 'Total loss': 0.5704765884499801}
2022-12-05 23:36:04,189 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:04,189 INFO:     Epoch: 7
2022-12-05 23:36:04,892 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5818127989768982, 'Total loss': 0.5818127989768982} | train loss {'Reaction outcome loss': 0.5646084307538353, 'Total loss': 0.5646084307538353}
2022-12-05 23:36:04,892 INFO:     Found new best model at epoch 7
2022-12-05 23:36:04,893 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:04,893 INFO:     Epoch: 8
2022-12-05 23:36:05,594 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5946875803849914, 'Total loss': 0.5946875803849914} | train loss {'Reaction outcome loss': 0.5483439112843772, 'Total loss': 0.5483439112843772}
2022-12-05 23:36:05,594 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:05,594 INFO:     Epoch: 9
2022-12-05 23:36:06,298 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5959101515737447, 'Total loss': 0.5959101515737447} | train loss {'Reaction outcome loss': 0.5524599366342491, 'Total loss': 0.5524599366342491}
2022-12-05 23:36:06,298 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:06,298 INFO:     Epoch: 10
2022-12-05 23:36:06,997 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.534204516898502, 'Total loss': 0.534204516898502} | train loss {'Reaction outcome loss': 0.5433346223055955, 'Total loss': 0.5433346223055955}
2022-12-05 23:36:06,997 INFO:     Found new best model at epoch 10
2022-12-05 23:36:06,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:06,998 INFO:     Epoch: 11
2022-12-05 23:36:07,698 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.544086795638908, 'Total loss': 0.544086795638908} | train loss {'Reaction outcome loss': 0.5325542177989898, 'Total loss': 0.5325542177989898}
2022-12-05 23:36:07,699 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:07,699 INFO:     Epoch: 12
2022-12-05 23:36:08,399 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5670561302791942, 'Total loss': 0.5670561302791942} | train loss {'Reaction outcome loss': 0.540209060135158, 'Total loss': 0.540209060135158}
2022-12-05 23:36:08,399 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:08,399 INFO:     Epoch: 13
2022-12-05 23:36:09,099 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.584722523662177, 'Total loss': 0.584722523662177} | train loss {'Reaction outcome loss': 0.5505981462204504, 'Total loss': 0.5505981462204504}
2022-12-05 23:36:09,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:09,099 INFO:     Epoch: 14
2022-12-05 23:36:09,804 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.6000108867883682, 'Total loss': 0.6000108867883682} | train loss {'Reaction outcome loss': 0.534696989575861, 'Total loss': 0.534696989575861}
2022-12-05 23:36:09,804 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:09,804 INFO:     Epoch: 15
2022-12-05 23:36:10,509 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5547899637709964, 'Total loss': 0.5547899637709964} | train loss {'Reaction outcome loss': 0.5297513330121514, 'Total loss': 0.5297513330121514}
2022-12-05 23:36:10,509 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:10,509 INFO:     Epoch: 16
2022-12-05 23:36:11,213 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5570061816410585, 'Total loss': 0.5570061816410585} | train loss {'Reaction outcome loss': 0.5317446566545047, 'Total loss': 0.5317446566545047}
2022-12-05 23:36:11,213 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:11,213 INFO:     Epoch: 17
2022-12-05 23:36:11,917 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5509120327505198, 'Total loss': 0.5509120327505198} | train loss {'Reaction outcome loss': 0.5180115947416919, 'Total loss': 0.5180115947416919}
2022-12-05 23:36:11,917 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:11,917 INFO:     Epoch: 18
2022-12-05 23:36:12,618 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.6228696541352705, 'Total loss': 0.6228696541352705} | train loss {'Reaction outcome loss': 0.5307341093717799, 'Total loss': 0.5307341093717799}
2022-12-05 23:36:12,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:12,618 INFO:     Epoch: 19
2022-12-05 23:36:13,319 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.6171045818112113, 'Total loss': 0.6171045818112113} | train loss {'Reaction outcome loss': 0.5263984115654791, 'Total loss': 0.5263984115654791}
2022-12-05 23:36:13,319 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:13,319 INFO:     Epoch: 20
2022-12-05 23:36:14,021 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5493543649261649, 'Total loss': 0.5493543649261649} | train loss {'Reaction outcome loss': 0.522418936103703, 'Total loss': 0.522418936103703}
2022-12-05 23:36:14,021 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:14,021 INFO:     Epoch: 21
2022-12-05 23:36:14,722 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.539492817087607, 'Total loss': 0.539492817087607} | train loss {'Reaction outcome loss': 0.526098271824329, 'Total loss': 0.526098271824329}
2022-12-05 23:36:14,722 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:14,722 INFO:     Epoch: 22
2022-12-05 23:36:15,422 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5349241908301007, 'Total loss': 0.5349241908301007} | train loss {'Reaction outcome loss': 0.5224105001461168, 'Total loss': 0.5224105001461168}
2022-12-05 23:36:15,422 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:15,423 INFO:     Epoch: 23
2022-12-05 23:36:16,123 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5336156589063731, 'Total loss': 0.5336156589063731} | train loss {'Reaction outcome loss': 0.5228390757612854, 'Total loss': 0.5228390757612854}
2022-12-05 23:36:16,123 INFO:     Found new best model at epoch 23
2022-12-05 23:36:16,124 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:16,124 INFO:     Epoch: 24
2022-12-05 23:36:16,827 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5323992547663775, 'Total loss': 0.5323992547663775} | train loss {'Reaction outcome loss': 0.5238862208388595, 'Total loss': 0.5238862208388595}
2022-12-05 23:36:16,827 INFO:     Found new best model at epoch 24
2022-12-05 23:36:16,828 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:16,828 INFO:     Epoch: 25
2022-12-05 23:36:17,528 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5621741745959629, 'Total loss': 0.5621741745959629} | train loss {'Reaction outcome loss': 0.5163912914904506, 'Total loss': 0.5163912914904506}
2022-12-05 23:36:17,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:17,528 INFO:     Epoch: 26
2022-12-05 23:36:18,228 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5531714585694399, 'Total loss': 0.5531714585694399} | train loss {'Reaction outcome loss': 0.5275287935849626, 'Total loss': 0.5275287935849626}
2022-12-05 23:36:18,228 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:18,228 INFO:     Epoch: 27
2022-12-05 23:36:18,930 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5278396020558748, 'Total loss': 0.5278396020558748} | train loss {'Reaction outcome loss': 0.5200345329789497, 'Total loss': 0.5200345329789497}
2022-12-05 23:36:18,930 INFO:     Found new best model at epoch 27
2022-12-05 23:36:18,931 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:18,931 INFO:     Epoch: 28
2022-12-05 23:36:19,632 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5374641845172102, 'Total loss': 0.5374641845172102} | train loss {'Reaction outcome loss': 0.5185450843067817, 'Total loss': 0.5185450843067817}
2022-12-05 23:36:19,632 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:19,632 INFO:     Epoch: 29
2022-12-05 23:36:20,332 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.556352415884083, 'Total loss': 0.556352415884083} | train loss {'Reaction outcome loss': 0.5196949202522092, 'Total loss': 0.5196949202522092}
2022-12-05 23:36:20,332 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:20,332 INFO:     Epoch: 30
2022-12-05 23:36:21,031 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5477362288670107, 'Total loss': 0.5477362288670107} | train loss {'Reaction outcome loss': 0.5130657589869944, 'Total loss': 0.5130657589869944}
2022-12-05 23:36:21,032 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:21,032 INFO:     Epoch: 31
2022-12-05 23:36:21,730 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5648881081830371, 'Total loss': 0.5648881081830371} | train loss {'Reaction outcome loss': 0.5153094686733687, 'Total loss': 0.5153094686733687}
2022-12-05 23:36:21,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:21,731 INFO:     Epoch: 32
2022-12-05 23:36:22,431 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5800599056211385, 'Total loss': 0.5800599056211385} | train loss {'Reaction outcome loss': 0.5151803986685961, 'Total loss': 0.5151803986685961}
2022-12-05 23:36:22,432 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:22,432 INFO:     Epoch: 33
2022-12-05 23:36:23,132 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5975105515257879, 'Total loss': 0.5975105515257879} | train loss {'Reaction outcome loss': 0.5153726210237032, 'Total loss': 0.5153726210237032}
2022-12-05 23:36:23,132 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:23,132 INFO:     Epoch: 34
2022-12-05 23:36:23,831 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5613292448899962, 'Total loss': 0.5613292448899962} | train loss {'Reaction outcome loss': 0.5157128728715031, 'Total loss': 0.5157128728715031}
2022-12-05 23:36:23,831 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:23,831 INFO:     Epoch: 35
2022-12-05 23:36:24,531 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5332798686894503, 'Total loss': 0.5332798686894503} | train loss {'Reaction outcome loss': 0.5042803344214976, 'Total loss': 0.5042803344214976}
2022-12-05 23:36:24,532 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:24,532 INFO:     Epoch: 36
2022-12-05 23:36:25,234 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5353688296269287, 'Total loss': 0.5353688296269287} | train loss {'Reaction outcome loss': 0.5091188894631906, 'Total loss': 0.5091188894631906}
2022-12-05 23:36:25,235 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:25,235 INFO:     Epoch: 37
2022-12-05 23:36:25,935 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5309659858996217, 'Total loss': 0.5309659858996217} | train loss {'Reaction outcome loss': 0.5091608315706253, 'Total loss': 0.5091608315706253}
2022-12-05 23:36:25,935 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:25,936 INFO:     Epoch: 38
2022-12-05 23:36:26,638 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5305430977181955, 'Total loss': 0.5305430977181955} | train loss {'Reaction outcome loss': 0.5261844749513426, 'Total loss': 0.5261844749513426}
2022-12-05 23:36:26,638 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:26,638 INFO:     Epoch: 39
2022-12-05 23:36:27,341 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5350059396163984, 'Total loss': 0.5350059396163984} | train loss {'Reaction outcome loss': 0.5169226539279768, 'Total loss': 0.5169226539279768}
2022-12-05 23:36:27,341 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:27,341 INFO:     Epoch: 40
2022-12-05 23:36:28,042 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5762764811515808, 'Total loss': 0.5762764811515808} | train loss {'Reaction outcome loss': 0.5090878836901082, 'Total loss': 0.5090878836901082}
2022-12-05 23:36:28,042 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:28,042 INFO:     Epoch: 41
2022-12-05 23:36:28,742 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.6325526244261048, 'Total loss': 0.6325526244261048} | train loss {'Reaction outcome loss': 0.5143192042464669, 'Total loss': 0.5143192042464669}
2022-12-05 23:36:28,742 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:28,742 INFO:     Epoch: 42
2022-12-05 23:36:29,443 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.572666657241908, 'Total loss': 0.572666657241908} | train loss {'Reaction outcome loss': 0.5260526569869354, 'Total loss': 0.5260526569869354}
2022-12-05 23:36:29,443 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:29,443 INFO:     Epoch: 43
2022-12-05 23:36:30,145 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5736131769689646, 'Total loss': 0.5736131769689646} | train loss {'Reaction outcome loss': 0.5085996615621242, 'Total loss': 0.5085996615621242}
2022-12-05 23:36:30,146 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:30,146 INFO:     Epoch: 44
2022-12-05 23:36:30,845 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5446876165541735, 'Total loss': 0.5446876165541735} | train loss {'Reaction outcome loss': 0.5182883833584032, 'Total loss': 0.5182883833584032}
2022-12-05 23:36:30,846 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:30,846 INFO:     Epoch: 45
2022-12-05 23:36:31,545 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.516192682764747, 'Total loss': 0.516192682764747} | train loss {'Reaction outcome loss': 0.5083750705159296, 'Total loss': 0.5083750705159296}
2022-12-05 23:36:31,546 INFO:     Found new best model at epoch 45
2022-12-05 23:36:31,546 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:31,546 INFO:     Epoch: 46
2022-12-05 23:36:32,246 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5137944986874406, 'Total loss': 0.5137944986874406} | train loss {'Reaction outcome loss': 0.5077587556139178, 'Total loss': 0.5077587556139178}
2022-12-05 23:36:32,246 INFO:     Found new best model at epoch 46
2022-12-05 23:36:32,247 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:32,247 INFO:     Epoch: 47
2022-12-05 23:36:32,950 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.533112183213234, 'Total loss': 0.533112183213234} | train loss {'Reaction outcome loss': 0.5133450060238239, 'Total loss': 0.5133450060238239}
2022-12-05 23:36:32,951 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:32,951 INFO:     Epoch: 48
2022-12-05 23:36:33,651 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5339178019626574, 'Total loss': 0.5339178019626574} | train loss {'Reaction outcome loss': 0.5254303438340121, 'Total loss': 0.5254303438340121}
2022-12-05 23:36:33,651 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:33,651 INFO:     Epoch: 49
2022-12-05 23:36:34,354 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5686905356970701, 'Total loss': 0.5686905356970701} | train loss {'Reaction outcome loss': 0.5102995433486425, 'Total loss': 0.5102995433486425}
2022-12-05 23:36:34,355 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:34,355 INFO:     Epoch: 50
2022-12-05 23:36:35,057 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5364635925401341, 'Total loss': 0.5364635925401341} | train loss {'Reaction outcome loss': 0.5050511934798256, 'Total loss': 0.5050511934798256}
2022-12-05 23:36:35,058 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:35,058 INFO:     Epoch: 51
2022-12-05 23:36:35,760 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5532517866654829, 'Total loss': 0.5532517866654829} | train loss {'Reaction outcome loss': 0.502598347270537, 'Total loss': 0.502598347270537}
2022-12-05 23:36:35,761 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:35,761 INFO:     Epoch: 52
2022-12-05 23:36:36,461 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5296840261329304, 'Total loss': 0.5296840261329304} | train loss {'Reaction outcome loss': 0.521772689182266, 'Total loss': 0.521772689182266}
2022-12-05 23:36:36,461 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:36,461 INFO:     Epoch: 53
2022-12-05 23:36:37,162 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5459709025242112, 'Total loss': 0.5459709025242112} | train loss {'Reaction outcome loss': 0.5094382459456138, 'Total loss': 0.5094382459456138}
2022-12-05 23:36:37,162 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:37,162 INFO:     Epoch: 54
2022-12-05 23:36:37,868 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5307495099577036, 'Total loss': 0.5307495099577036} | train loss {'Reaction outcome loss': 0.5170549699048764, 'Total loss': 0.5170549699048764}
2022-12-05 23:36:37,869 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:37,869 INFO:     Epoch: 55
2022-12-05 23:36:38,575 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5470676422119141, 'Total loss': 0.5470676422119141} | train loss {'Reaction outcome loss': 0.5157332486107282, 'Total loss': 0.5157332486107282}
2022-12-05 23:36:38,575 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:38,575 INFO:     Epoch: 56
2022-12-05 23:36:39,275 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5203569751571525, 'Total loss': 0.5203569751571525} | train loss {'Reaction outcome loss': 0.5164348428186617, 'Total loss': 0.5164348428186617}
2022-12-05 23:36:39,275 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:39,275 INFO:     Epoch: 57
2022-12-05 23:36:39,976 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5171487751332197, 'Total loss': 0.5171487751332197} | train loss {'Reaction outcome loss': 0.5161382390661278, 'Total loss': 0.5161382390661278}
2022-12-05 23:36:39,976 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:39,976 INFO:     Epoch: 58
2022-12-05 23:36:40,678 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5431965630162846, 'Total loss': 0.5431965630162846} | train loss {'Reaction outcome loss': 0.5101560891760506, 'Total loss': 0.5101560891760506}
2022-12-05 23:36:40,678 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:40,678 INFO:     Epoch: 59
2022-12-05 23:36:41,379 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5518392439592968, 'Total loss': 0.5518392439592968} | train loss {'Reaction outcome loss': 0.514315172667928, 'Total loss': 0.514315172667928}
2022-12-05 23:36:41,380 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:41,380 INFO:     Epoch: 60
2022-12-05 23:36:42,080 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5791929628361355, 'Total loss': 0.5791929628361355} | train loss {'Reaction outcome loss': 0.5075115204580423, 'Total loss': 0.5075115204580423}
2022-12-05 23:36:42,081 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:42,081 INFO:     Epoch: 61
2022-12-05 23:36:42,782 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5833993418650194, 'Total loss': 0.5833993418650194} | train loss {'Reaction outcome loss': 0.5060354089326704, 'Total loss': 0.5060354089326704}
2022-12-05 23:36:42,782 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:42,782 INFO:     Epoch: 62
2022-12-05 23:36:43,482 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5298618796196851, 'Total loss': 0.5298618796196851} | train loss {'Reaction outcome loss': 0.5118295649209847, 'Total loss': 0.5118295649209847}
2022-12-05 23:36:43,483 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:43,483 INFO:     Epoch: 63
2022-12-05 23:36:44,184 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.551589893346483, 'Total loss': 0.551589893346483} | train loss {'Reaction outcome loss': 0.5096148011172831, 'Total loss': 0.5096148011172831}
2022-12-05 23:36:44,184 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:44,184 INFO:     Epoch: 64
2022-12-05 23:36:44,888 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5449050929058682, 'Total loss': 0.5449050929058682} | train loss {'Reaction outcome loss': 0.5067322062637641, 'Total loss': 0.5067322062637641}
2022-12-05 23:36:44,888 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:44,888 INFO:     Epoch: 65
2022-12-05 23:36:45,589 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5931921818039634, 'Total loss': 0.5931921818039634} | train loss {'Reaction outcome loss': 0.51158952235757, 'Total loss': 0.51158952235757}
2022-12-05 23:36:45,589 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:45,589 INFO:     Epoch: 66
2022-12-05 23:36:46,291 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.6131454137238589, 'Total loss': 0.6131454137238589} | train loss {'Reaction outcome loss': 0.5113929976154918, 'Total loss': 0.5113929976154918}
2022-12-05 23:36:46,291 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:46,291 INFO:     Epoch: 67
2022-12-05 23:36:46,991 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.557504918764938, 'Total loss': 0.557504918764938} | train loss {'Reaction outcome loss': 0.5092581785340541, 'Total loss': 0.5092581785340541}
2022-12-05 23:36:46,991 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:46,991 INFO:     Epoch: 68
2022-12-05 23:36:47,696 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5506802695718679, 'Total loss': 0.5506802695718679} | train loss {'Reaction outcome loss': 0.521551930816912, 'Total loss': 0.521551930816912}
2022-12-05 23:36:47,696 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:47,696 INFO:     Epoch: 69
2022-12-05 23:36:48,398 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.534250067716295, 'Total loss': 0.534250067716295} | train loss {'Reaction outcome loss': 0.5124396381311511, 'Total loss': 0.5124396381311511}
2022-12-05 23:36:48,398 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:48,398 INFO:     Epoch: 70
2022-12-05 23:36:49,099 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5443150231784041, 'Total loss': 0.5443150231784041} | train loss {'Reaction outcome loss': 0.5106274743191144, 'Total loss': 0.5106274743191144}
2022-12-05 23:36:49,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:49,099 INFO:     Epoch: 71
2022-12-05 23:36:49,803 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.514291956343434, 'Total loss': 0.514291956343434} | train loss {'Reaction outcome loss': 0.5080136802831763, 'Total loss': 0.5080136802831763}
2022-12-05 23:36:49,803 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:49,803 INFO:     Epoch: 72
2022-12-05 23:36:50,504 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5372228023003448, 'Total loss': 0.5372228023003448} | train loss {'Reaction outcome loss': 0.49963886460557067, 'Total loss': 0.49963886460557067}
2022-12-05 23:36:50,505 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:50,505 INFO:     Epoch: 73
2022-12-05 23:36:51,208 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.586176301268014, 'Total loss': 0.586176301268014} | train loss {'Reaction outcome loss': 0.5078327336654007, 'Total loss': 0.5078327336654007}
2022-12-05 23:36:51,209 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:51,209 INFO:     Epoch: 74
2022-12-05 23:36:51,908 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5099978910928423, 'Total loss': 0.5099978910928423} | train loss {'Reaction outcome loss': 0.5161023490571112, 'Total loss': 0.5161023490571112}
2022-12-05 23:36:51,908 INFO:     Found new best model at epoch 74
2022-12-05 23:36:51,909 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:51,909 INFO:     Epoch: 75
2022-12-05 23:36:52,612 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5266459716314619, 'Total loss': 0.5266459716314619} | train loss {'Reaction outcome loss': 0.5090528132944454, 'Total loss': 0.5090528132944454}
2022-12-05 23:36:52,612 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:52,612 INFO:     Epoch: 76
2022-12-05 23:36:53,317 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.580683863975785, 'Total loss': 0.580683863975785} | train loss {'Reaction outcome loss': 0.5186628934885809, 'Total loss': 0.5186628934885809}
2022-12-05 23:36:53,317 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:53,317 INFO:     Epoch: 77
2022-12-05 23:36:54,016 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5814635272730481, 'Total loss': 0.5814635272730481} | train loss {'Reaction outcome loss': 0.5091783223967803, 'Total loss': 0.5091783223967803}
2022-12-05 23:36:54,017 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:54,017 INFO:     Epoch: 78
2022-12-05 23:36:54,717 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5805939584970474, 'Total loss': 0.5805939584970474} | train loss {'Reaction outcome loss': 0.5141333061372221, 'Total loss': 0.5141333061372221}
2022-12-05 23:36:54,718 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:54,718 INFO:     Epoch: 79
2022-12-05 23:36:55,420 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5358913937075571, 'Total loss': 0.5358913937075571} | train loss {'Reaction outcome loss': 0.5190706755664305, 'Total loss': 0.5190706755664305}
2022-12-05 23:36:55,420 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:55,420 INFO:     Epoch: 80
2022-12-05 23:36:56,125 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.608602068640969, 'Total loss': 0.608602068640969} | train loss {'Reaction outcome loss': 0.4965907330063892, 'Total loss': 0.4965907330063892}
2022-12-05 23:36:56,125 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:56,125 INFO:     Epoch: 81
2022-12-05 23:36:56,827 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6754550744186748, 'Total loss': 0.6754550744186748} | train loss {'Reaction outcome loss': 0.510950100868337, 'Total loss': 0.510950100868337}
2022-12-05 23:36:56,827 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:56,827 INFO:     Epoch: 82
2022-12-05 23:36:57,527 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5709015645764091, 'Total loss': 0.5709015645764091} | train loss {'Reaction outcome loss': 0.5180920764260929, 'Total loss': 0.5180920764260929}
2022-12-05 23:36:57,527 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:57,527 INFO:     Epoch: 83
2022-12-05 23:36:58,228 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5498880804939703, 'Total loss': 0.5498880804939703} | train loss {'Reaction outcome loss': 0.509779952375995, 'Total loss': 0.509779952375995}
2022-12-05 23:36:58,228 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:58,228 INFO:     Epoch: 84
2022-12-05 23:36:58,929 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.554230813275684, 'Total loss': 0.554230813275684} | train loss {'Reaction outcome loss': 0.5103901851213413, 'Total loss': 0.5103901851213413}
2022-12-05 23:36:58,930 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:58,930 INFO:     Epoch: 85
2022-12-05 23:36:59,636 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5673720352351665, 'Total loss': 0.5673720352351665} | train loss {'Reaction outcome loss': 0.5101341783999455, 'Total loss': 0.5101341783999455}
2022-12-05 23:36:59,636 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:36:59,636 INFO:     Epoch: 86
2022-12-05 23:37:00,339 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5270888673310931, 'Total loss': 0.5270888673310931} | train loss {'Reaction outcome loss': 0.5033366385138469, 'Total loss': 0.5033366385138469}
2022-12-05 23:37:00,339 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:00,339 INFO:     Epoch: 87
2022-12-05 23:37:01,039 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5568277673287825, 'Total loss': 0.5568277673287825} | train loss {'Reaction outcome loss': 0.5173638478705758, 'Total loss': 0.5173638478705758}
2022-12-05 23:37:01,040 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:01,040 INFO:     Epoch: 88
2022-12-05 23:37:01,742 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5544361346824602, 'Total loss': 0.5544361346824602} | train loss {'Reaction outcome loss': 0.5078055329530345, 'Total loss': 0.5078055329530345}
2022-12-05 23:37:01,743 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:01,743 INFO:     Epoch: 89
2022-12-05 23:37:02,443 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5810659419406544, 'Total loss': 0.5810659419406544} | train loss {'Reaction outcome loss': 0.5168092383546867, 'Total loss': 0.5168092383546867}
2022-12-05 23:37:02,444 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:02,444 INFO:     Epoch: 90
2022-12-05 23:37:03,144 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5392469601197676, 'Total loss': 0.5392469601197676} | train loss {'Reaction outcome loss': 0.5069344224114167, 'Total loss': 0.5069344224114167}
2022-12-05 23:37:03,144 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:03,145 INFO:     Epoch: 91
2022-12-05 23:37:03,854 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.519075196236372, 'Total loss': 0.519075196236372} | train loss {'Reaction outcome loss': 0.5058409240443696, 'Total loss': 0.5058409240443696}
2022-12-05 23:37:03,854 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:03,854 INFO:     Epoch: 92
2022-12-05 23:37:04,555 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5354389724406329, 'Total loss': 0.5354389724406329} | train loss {'Reaction outcome loss': 0.50977752355459, 'Total loss': 0.50977752355459}
2022-12-05 23:37:04,555 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:04,555 INFO:     Epoch: 93
2022-12-05 23:37:05,255 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5628057901154865, 'Total loss': 0.5628057901154865} | train loss {'Reaction outcome loss': 0.5071739128787025, 'Total loss': 0.5071739128787025}
2022-12-05 23:37:05,256 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:05,257 INFO:     Epoch: 94
2022-12-05 23:37:05,957 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5270863473415375, 'Total loss': 0.5270863473415375} | train loss {'Reaction outcome loss': 0.5142615764488575, 'Total loss': 0.5142615764488575}
2022-12-05 23:37:05,957 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:05,957 INFO:     Epoch: 95
2022-12-05 23:37:06,658 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5429829528385942, 'Total loss': 0.5429829528385942} | train loss {'Reaction outcome loss': 0.5077414928901534, 'Total loss': 0.5077414928901534}
2022-12-05 23:37:06,658 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:06,658 INFO:     Epoch: 96
2022-12-05 23:37:07,358 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5134671865539118, 'Total loss': 0.5134671865539118} | train loss {'Reaction outcome loss': 0.5105836509693007, 'Total loss': 0.5105836509693007}
2022-12-05 23:37:07,358 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:07,358 INFO:     Epoch: 97
2022-12-05 23:37:08,059 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5241114358333024, 'Total loss': 0.5241114358333024} | train loss {'Reaction outcome loss': 0.501433228862732, 'Total loss': 0.501433228862732}
2022-12-05 23:37:08,059 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:08,059 INFO:     Epoch: 98
2022-12-05 23:37:08,759 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5232275947928429, 'Total loss': 0.5232275947928429} | train loss {'Reaction outcome loss': 0.49617691974481754, 'Total loss': 0.49617691974481754}
2022-12-05 23:37:08,759 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:08,759 INFO:     Epoch: 99
2022-12-05 23:37:09,462 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5659902048381892, 'Total loss': 0.5659902048381892} | train loss {'Reaction outcome loss': 0.5073961257813913, 'Total loss': 0.5073961257813913}
2022-12-05 23:37:09,462 INFO:     Best model found after epoch 75 of 100.
2022-12-05 23:37:09,463 INFO:   Done with stage: TRAINING
2022-12-05 23:37:09,463 INFO:   Starting stage: EVALUATION
2022-12-05 23:37:09,586 INFO:   Done with stage: EVALUATION
2022-12-05 23:37:09,586 INFO:   Leaving out SEQ value Fold_7
2022-12-05 23:37:09,599 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:37:09,599 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:37:10,237 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:37:10,237 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:37:10,309 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:37:10,309 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:37:10,309 INFO:     No hyperparam tuning for this model
2022-12-05 23:37:10,309 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:37:10,309 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:37:10,310 INFO:     None feature selector for col prot
2022-12-05 23:37:10,310 INFO:     None feature selector for col prot
2022-12-05 23:37:10,310 INFO:     None feature selector for col prot
2022-12-05 23:37:10,311 INFO:     None feature selector for col chem
2022-12-05 23:37:10,311 INFO:     None feature selector for col chem
2022-12-05 23:37:10,311 INFO:     None feature selector for col chem
2022-12-05 23:37:10,311 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:37:10,311 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:37:10,313 INFO:     Number of params in model 215731
2022-12-05 23:37:10,316 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:37:10,316 INFO:   Starting stage: TRAINING
2022-12-05 23:37:10,374 INFO:     Val loss before train {'Reaction outcome loss': 0.9684154784137552, 'Total loss': 0.9684154784137552}
2022-12-05 23:37:10,374 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:10,374 INFO:     Epoch: 0
2022-12-05 23:37:11,083 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6817110539837317, 'Total loss': 0.6817110539837317} | train loss {'Reaction outcome loss': 0.8058091064374293, 'Total loss': 0.8058091064374293}
2022-12-05 23:37:11,083 INFO:     Found new best model at epoch 0
2022-12-05 23:37:11,084 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:11,084 INFO:     Epoch: 1
2022-12-05 23:37:11,788 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6314233263785188, 'Total loss': 0.6314233263785188} | train loss {'Reaction outcome loss': 0.6593946726812471, 'Total loss': 0.6593946726812471}
2022-12-05 23:37:11,788 INFO:     Found new best model at epoch 1
2022-12-05 23:37:11,789 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:11,789 INFO:     Epoch: 2
2022-12-05 23:37:12,493 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6066859110512517, 'Total loss': 0.6066859110512517} | train loss {'Reaction outcome loss': 0.6166645098597773, 'Total loss': 0.6166645098597773}
2022-12-05 23:37:12,493 INFO:     Found new best model at epoch 2
2022-12-05 23:37:12,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:12,494 INFO:     Epoch: 3
2022-12-05 23:37:13,200 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5342683433131739, 'Total loss': 0.5342683433131739} | train loss {'Reaction outcome loss': 0.597505713182111, 'Total loss': 0.597505713182111}
2022-12-05 23:37:13,200 INFO:     Found new best model at epoch 3
2022-12-05 23:37:13,201 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:13,201 INFO:     Epoch: 4
2022-12-05 23:37:13,907 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5457865633070469, 'Total loss': 0.5457865633070469} | train loss {'Reaction outcome loss': 0.5753352419743615, 'Total loss': 0.5753352419743615}
2022-12-05 23:37:13,907 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:13,907 INFO:     Epoch: 5
2022-12-05 23:37:14,611 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5382271937348626, 'Total loss': 0.5382271937348626} | train loss {'Reaction outcome loss': 0.5721992119065216, 'Total loss': 0.5721992119065216}
2022-12-05 23:37:14,611 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:14,611 INFO:     Epoch: 6
2022-12-05 23:37:15,321 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5182396468113769, 'Total loss': 0.5182396468113769} | train loss {'Reaction outcome loss': 0.5738901771124332, 'Total loss': 0.5738901771124332}
2022-12-05 23:37:15,321 INFO:     Found new best model at epoch 6
2022-12-05 23:37:15,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:15,322 INFO:     Epoch: 7
2022-12-05 23:37:16,025 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5316704748706385, 'Total loss': 0.5316704748706385} | train loss {'Reaction outcome loss': 0.5588575811876405, 'Total loss': 0.5588575811876405}
2022-12-05 23:37:16,025 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:16,025 INFO:     Epoch: 8
2022-12-05 23:37:16,728 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5394042323936116, 'Total loss': 0.5394042323936116} | train loss {'Reaction outcome loss': 0.5545871745073988, 'Total loss': 0.5545871745073988}
2022-12-05 23:37:16,728 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:16,729 INFO:     Epoch: 9
2022-12-05 23:37:17,432 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5511809746650133, 'Total loss': 0.5511809746650133} | train loss {'Reaction outcome loss': 0.5470143551788023, 'Total loss': 0.5470143551788023}
2022-12-05 23:37:17,432 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:17,432 INFO:     Epoch: 10
2022-12-05 23:37:18,133 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5389822504737161, 'Total loss': 0.5389822504737161} | train loss {'Reaction outcome loss': 0.544025310825917, 'Total loss': 0.544025310825917}
2022-12-05 23:37:18,134 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:18,134 INFO:     Epoch: 11
2022-12-05 23:37:18,839 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5293961932713335, 'Total loss': 0.5293961932713335} | train loss {'Reaction outcome loss': 0.5398343791884761, 'Total loss': 0.5398343791884761}
2022-12-05 23:37:18,839 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:18,839 INFO:     Epoch: 12
2022-12-05 23:37:19,549 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5351862900636413, 'Total loss': 0.5351862900636413} | train loss {'Reaction outcome loss': 0.5503506014544156, 'Total loss': 0.5503506014544156}
2022-12-05 23:37:19,549 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:19,549 INFO:     Epoch: 13
2022-12-05 23:37:20,254 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4995959489182992, 'Total loss': 0.4995959489182992} | train loss {'Reaction outcome loss': 0.5416752695436439, 'Total loss': 0.5416752695436439}
2022-12-05 23:37:20,254 INFO:     Found new best model at epoch 13
2022-12-05 23:37:20,255 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:20,255 INFO:     Epoch: 14
2022-12-05 23:37:20,959 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5583587363362312, 'Total loss': 0.5583587363362312} | train loss {'Reaction outcome loss': 0.5390106950315737, 'Total loss': 0.5390106950315737}
2022-12-05 23:37:20,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:20,959 INFO:     Epoch: 15
2022-12-05 23:37:21,663 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4877282607961785, 'Total loss': 0.4877282607961785} | train loss {'Reaction outcome loss': 0.5377834046319607, 'Total loss': 0.5377834046319607}
2022-12-05 23:37:21,663 INFO:     Found new best model at epoch 15
2022-12-05 23:37:21,664 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:21,664 INFO:     Epoch: 16
2022-12-05 23:37:22,370 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5277958349748091, 'Total loss': 0.5277958349748091} | train loss {'Reaction outcome loss': 0.5359444671100185, 'Total loss': 0.5359444671100185}
2022-12-05 23:37:22,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:22,370 INFO:     Epoch: 17
2022-12-05 23:37:23,074 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5282219790599563, 'Total loss': 0.5282219790599563} | train loss {'Reaction outcome loss': 0.5405878986442282, 'Total loss': 0.5405878986442282}
2022-12-05 23:37:23,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:23,074 INFO:     Epoch: 18
2022-12-05 23:37:23,781 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.49606507136063144, 'Total loss': 0.49606507136063144} | train loss {'Reaction outcome loss': 0.5320538936723624, 'Total loss': 0.5320538936723624}
2022-12-05 23:37:23,781 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:23,781 INFO:     Epoch: 19
2022-12-05 23:37:24,483 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.508392234756188, 'Total loss': 0.508392234756188} | train loss {'Reaction outcome loss': 0.5355201358756712, 'Total loss': 0.5355201358756712}
2022-12-05 23:37:24,484 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:24,484 INFO:     Epoch: 20
2022-12-05 23:37:25,188 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4932905157858675, 'Total loss': 0.4932905157858675} | train loss {'Reaction outcome loss': 0.540915826996488, 'Total loss': 0.540915826996488}
2022-12-05 23:37:25,188 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:25,188 INFO:     Epoch: 21
2022-12-05 23:37:25,892 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5204388343475082, 'Total loss': 0.5204388343475082} | train loss {'Reaction outcome loss': 0.5311716141239289, 'Total loss': 0.5311716141239289}
2022-12-05 23:37:25,892 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:25,892 INFO:     Epoch: 22
2022-12-05 23:37:26,595 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4999751529910348, 'Total loss': 0.4999751529910348} | train loss {'Reaction outcome loss': 0.5396899492029221, 'Total loss': 0.5396899492029221}
2022-12-05 23:37:26,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:26,595 INFO:     Epoch: 23
2022-12-05 23:37:27,298 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5190285681323572, 'Total loss': 0.5190285681323572} | train loss {'Reaction outcome loss': 0.5291364710297315, 'Total loss': 0.5291364710297315}
2022-12-05 23:37:27,298 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:27,298 INFO:     Epoch: 24
2022-12-05 23:37:28,002 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5082270049236037, 'Total loss': 0.5082270049236037} | train loss {'Reaction outcome loss': 0.5280590369215896, 'Total loss': 0.5280590369215896}
2022-12-05 23:37:28,002 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:28,002 INFO:     Epoch: 25
2022-12-05 23:37:28,706 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5653893886642023, 'Total loss': 0.5653893886642023} | train loss {'Reaction outcome loss': 0.5286485135194755, 'Total loss': 0.5286485135194755}
2022-12-05 23:37:28,706 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:28,706 INFO:     Epoch: 26
2022-12-05 23:37:29,413 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5238666527650573, 'Total loss': 0.5238666527650573} | train loss {'Reaction outcome loss': 0.5364007865709643, 'Total loss': 0.5364007865709643}
2022-12-05 23:37:29,413 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:29,413 INFO:     Epoch: 27
2022-12-05 23:37:30,119 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.504265408962965, 'Total loss': 0.504265408962965} | train loss {'Reaction outcome loss': 0.5319476211443543, 'Total loss': 0.5319476211443543}
2022-12-05 23:37:30,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:30,119 INFO:     Epoch: 28
2022-12-05 23:37:30,826 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4946432310071858, 'Total loss': 0.4946432310071858} | train loss {'Reaction outcome loss': 0.530748667856378, 'Total loss': 0.530748667856378}
2022-12-05 23:37:30,826 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:30,826 INFO:     Epoch: 29
2022-12-05 23:37:31,530 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4892946244640784, 'Total loss': 0.4892946244640784} | train loss {'Reaction outcome loss': 0.527316598642257, 'Total loss': 0.527316598642257}
2022-12-05 23:37:31,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:31,530 INFO:     Epoch: 30
2022-12-05 23:37:32,237 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4897485605695031, 'Total loss': 0.4897485605695031} | train loss {'Reaction outcome loss': 0.5318638686571391, 'Total loss': 0.5318638686571391}
2022-12-05 23:37:32,237 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:32,237 INFO:     Epoch: 31
2022-12-05 23:37:32,941 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5261649337004531, 'Total loss': 0.5261649337004531} | train loss {'Reaction outcome loss': 0.5311876542025036, 'Total loss': 0.5311876542025036}
2022-12-05 23:37:32,941 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:32,941 INFO:     Epoch: 32
2022-12-05 23:37:33,645 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5116737708449364, 'Total loss': 0.5116737708449364} | train loss {'Reaction outcome loss': 0.5291660572251966, 'Total loss': 0.5291660572251966}
2022-12-05 23:37:33,645 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:33,645 INFO:     Epoch: 33
2022-12-05 23:37:34,348 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5232245742597363, 'Total loss': 0.5232245742597363} | train loss {'Reaction outcome loss': 0.5294716989681605, 'Total loss': 0.5294716989681605}
2022-12-05 23:37:34,348 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:34,348 INFO:     Epoch: 34
2022-12-05 23:37:35,052 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4923350407995961, 'Total loss': 0.4923350407995961} | train loss {'Reaction outcome loss': 0.5285559319440396, 'Total loss': 0.5285559319440396}
2022-12-05 23:37:35,052 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:35,052 INFO:     Epoch: 35
2022-12-05 23:37:35,756 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4978875280781226, 'Total loss': 0.4978875280781226} | train loss {'Reaction outcome loss': 0.5317061225613279, 'Total loss': 0.5317061225613279}
2022-12-05 23:37:35,756 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:35,756 INFO:     Epoch: 36
2022-12-05 23:37:36,460 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5049948550083421, 'Total loss': 0.5049948550083421} | train loss {'Reaction outcome loss': 0.5308891529397618, 'Total loss': 0.5308891529397618}
2022-12-05 23:37:36,461 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:36,461 INFO:     Epoch: 37
2022-12-05 23:37:37,171 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5146015889265321, 'Total loss': 0.5146015889265321} | train loss {'Reaction outcome loss': 0.5329102973543829, 'Total loss': 0.5329102973543829}
2022-12-05 23:37:37,171 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:37,171 INFO:     Epoch: 38
2022-12-05 23:37:37,877 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.522401710125533, 'Total loss': 0.522401710125533} | train loss {'Reaction outcome loss': 0.5250072926883737, 'Total loss': 0.5250072926883737}
2022-12-05 23:37:37,877 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:37,877 INFO:     Epoch: 39
2022-12-05 23:37:38,585 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5213872966441241, 'Total loss': 0.5213872966441241} | train loss {'Reaction outcome loss': 0.5333462105763536, 'Total loss': 0.5333462105763536}
2022-12-05 23:37:38,585 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:38,585 INFO:     Epoch: 40
2022-12-05 23:37:39,293 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5215491340918974, 'Total loss': 0.5215491340918974} | train loss {'Reaction outcome loss': 0.5236975106020128, 'Total loss': 0.5236975106020128}
2022-12-05 23:37:39,293 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:39,293 INFO:     Epoch: 41
2022-12-05 23:37:39,997 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4834551574154334, 'Total loss': 0.4834551574154334} | train loss {'Reaction outcome loss': 0.5270658063912584, 'Total loss': 0.5270658063912584}
2022-12-05 23:37:39,997 INFO:     Found new best model at epoch 41
2022-12-05 23:37:39,998 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:39,998 INFO:     Epoch: 42
2022-12-05 23:37:40,705 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5158688971264795, 'Total loss': 0.5158688971264795} | train loss {'Reaction outcome loss': 0.5337072428796561, 'Total loss': 0.5337072428796561}
2022-12-05 23:37:40,705 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:40,705 INFO:     Epoch: 43
2022-12-05 23:37:41,414 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5330872337587855, 'Total loss': 0.5330872337587855} | train loss {'Reaction outcome loss': 0.5323577868121285, 'Total loss': 0.5323577868121285}
2022-12-05 23:37:41,414 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:41,414 INFO:     Epoch: 44
2022-12-05 23:37:42,119 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5470169261097908, 'Total loss': 0.5470169261097908} | train loss {'Reaction outcome loss': 0.5354857392488949, 'Total loss': 0.5354857392488949}
2022-12-05 23:37:42,119 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:42,119 INFO:     Epoch: 45
2022-12-05 23:37:42,824 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49844700572165573, 'Total loss': 0.49844700572165573} | train loss {'Reaction outcome loss': 0.5280525415775276, 'Total loss': 0.5280525415775276}
2022-12-05 23:37:42,825 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:42,825 INFO:     Epoch: 46
2022-12-05 23:37:43,529 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.538061683150855, 'Total loss': 0.538061683150855} | train loss {'Reaction outcome loss': 0.5318443160504103, 'Total loss': 0.5318443160504103}
2022-12-05 23:37:43,529 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:43,529 INFO:     Epoch: 47
2022-12-05 23:37:44,236 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5082434493709694, 'Total loss': 0.5082434493709694} | train loss {'Reaction outcome loss': 0.5294407996078653, 'Total loss': 0.5294407996078653}
2022-12-05 23:37:44,236 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:44,237 INFO:     Epoch: 48
2022-12-05 23:37:44,941 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.48333443904464896, 'Total loss': 0.48333443904464896} | train loss {'Reaction outcome loss': 0.5315718061981662, 'Total loss': 0.5315718061981662}
2022-12-05 23:37:44,941 INFO:     Found new best model at epoch 48
2022-12-05 23:37:44,942 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:44,942 INFO:     Epoch: 49
2022-12-05 23:37:45,647 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5106490113857117, 'Total loss': 0.5106490113857117} | train loss {'Reaction outcome loss': 0.5257262609778873, 'Total loss': 0.5257262609778873}
2022-12-05 23:37:45,647 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:45,647 INFO:     Epoch: 50
2022-12-05 23:37:46,358 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5066179216585376, 'Total loss': 0.5066179216585376} | train loss {'Reaction outcome loss': 0.5310681308469465, 'Total loss': 0.5310681308469465}
2022-12-05 23:37:46,359 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:46,359 INFO:     Epoch: 51
2022-12-05 23:37:47,066 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4998937482860955, 'Total loss': 0.4998937482860955} | train loss {'Reaction outcome loss': 0.5316135286683997, 'Total loss': 0.5316135286683997}
2022-12-05 23:37:47,066 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:47,066 INFO:     Epoch: 52
2022-12-05 23:37:47,771 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5395767306062308, 'Total loss': 0.5395767306062308} | train loss {'Reaction outcome loss': 0.5271224955156926, 'Total loss': 0.5271224955156926}
2022-12-05 23:37:47,771 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:47,771 INFO:     Epoch: 53
2022-12-05 23:37:48,475 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5246698802167719, 'Total loss': 0.5246698802167719} | train loss {'Reaction outcome loss': 0.5269864444290439, 'Total loss': 0.5269864444290439}
2022-12-05 23:37:48,475 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:48,475 INFO:     Epoch: 54
2022-12-05 23:37:49,183 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5338758772069757, 'Total loss': 0.5338758772069757} | train loss {'Reaction outcome loss': 0.5244840780092824, 'Total loss': 0.5244840780092824}
2022-12-05 23:37:49,183 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:49,183 INFO:     Epoch: 55
2022-12-05 23:37:49,891 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5350332900204442, 'Total loss': 0.5350332900204442} | train loss {'Reaction outcome loss': 0.5290132308559071, 'Total loss': 0.5290132308559071}
2022-12-05 23:37:49,891 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:49,891 INFO:     Epoch: 56
2022-12-05 23:37:50,596 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5251522809267044, 'Total loss': 0.5251522809267044} | train loss {'Reaction outcome loss': 0.5296513209900549, 'Total loss': 0.5296513209900549}
2022-12-05 23:37:50,596 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:50,596 INFO:     Epoch: 57
2022-12-05 23:37:51,301 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5338806970552965, 'Total loss': 0.5338806970552965} | train loss {'Reaction outcome loss': 0.519513534802583, 'Total loss': 0.519513534802583}
2022-12-05 23:37:51,301 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:51,301 INFO:     Epoch: 58
2022-12-05 23:37:52,006 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5174441669474948, 'Total loss': 0.5174441669474948} | train loss {'Reaction outcome loss': 0.5310077165523844, 'Total loss': 0.5310077165523844}
2022-12-05 23:37:52,007 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:52,007 INFO:     Epoch: 59
2022-12-05 23:37:52,712 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4962536526674574, 'Total loss': 0.4962536526674574} | train loss {'Reaction outcome loss': 0.5251638964419404, 'Total loss': 0.5251638964419404}
2022-12-05 23:37:52,712 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:52,712 INFO:     Epoch: 60
2022-12-05 23:37:53,417 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5323810421607711, 'Total loss': 0.5323810421607711} | train loss {'Reaction outcome loss': 0.5253872972342276, 'Total loss': 0.5253872972342276}
2022-12-05 23:37:53,417 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:53,417 INFO:     Epoch: 61
2022-12-05 23:37:54,129 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5124249275435101, 'Total loss': 0.5124249275435101} | train loss {'Reaction outcome loss': 0.532654486897011, 'Total loss': 0.532654486897011}
2022-12-05 23:37:54,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:54,129 INFO:     Epoch: 62
2022-12-05 23:37:54,840 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49953899600289087, 'Total loss': 0.49953899600289087} | train loss {'Reaction outcome loss': 0.5261124695741362, 'Total loss': 0.5261124695741362}
2022-12-05 23:37:54,840 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:54,840 INFO:     Epoch: 63
2022-12-05 23:37:55,546 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5215444720604203, 'Total loss': 0.5215444720604203} | train loss {'Reaction outcome loss': 0.5274852460791026, 'Total loss': 0.5274852460791026}
2022-12-05 23:37:55,546 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:55,546 INFO:     Epoch: 64
2022-12-05 23:37:56,251 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5051243596456267, 'Total loss': 0.5051243596456267} | train loss {'Reaction outcome loss': 0.532166299800719, 'Total loss': 0.532166299800719}
2022-12-05 23:37:56,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:56,251 INFO:     Epoch: 65
2022-12-05 23:37:56,957 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4970246607607061, 'Total loss': 0.4970246607607061} | train loss {'Reaction outcome loss': 0.5286706586278254, 'Total loss': 0.5286706586278254}
2022-12-05 23:37:56,957 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:56,958 INFO:     Epoch: 66
2022-12-05 23:37:57,662 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5153134587136182, 'Total loss': 0.5153134587136182} | train loss {'Reaction outcome loss': 0.5262857012811207, 'Total loss': 0.5262857012811207}
2022-12-05 23:37:57,662 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:57,662 INFO:     Epoch: 67
2022-12-05 23:37:58,367 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5149704329669476, 'Total loss': 0.5149704329669476} | train loss {'Reaction outcome loss': 0.5278693071055797, 'Total loss': 0.5278693071055797}
2022-12-05 23:37:58,368 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:58,368 INFO:     Epoch: 68
2022-12-05 23:37:59,074 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49333133751695807, 'Total loss': 0.49333133751695807} | train loss {'Reaction outcome loss': 0.5292375611682092, 'Total loss': 0.5292375611682092}
2022-12-05 23:37:59,074 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:59,074 INFO:     Epoch: 69
2022-12-05 23:37:59,781 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4999416101385247, 'Total loss': 0.4999416101385247} | train loss {'Reaction outcome loss': 0.52983169011291, 'Total loss': 0.52983169011291}
2022-12-05 23:37:59,782 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:37:59,782 INFO:     Epoch: 70
2022-12-05 23:38:00,499 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5042351375926625, 'Total loss': 0.5042351375926625} | train loss {'Reaction outcome loss': 0.5288293175399303, 'Total loss': 0.5288293175399303}
2022-12-05 23:38:00,499 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:00,499 INFO:     Epoch: 71
2022-12-05 23:38:01,216 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5077497363090515, 'Total loss': 0.5077497363090515} | train loss {'Reaction outcome loss': 0.5228645863432076, 'Total loss': 0.5228645863432076}
2022-12-05 23:38:01,216 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:01,216 INFO:     Epoch: 72
2022-12-05 23:38:01,936 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.49837031452493236, 'Total loss': 0.49837031452493236} | train loss {'Reaction outcome loss': 0.5272420809994782, 'Total loss': 0.5272420809994782}
2022-12-05 23:38:01,936 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:01,936 INFO:     Epoch: 73
2022-12-05 23:38:02,652 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5002594163472002, 'Total loss': 0.5002594163472002} | train loss {'Reaction outcome loss': 0.523478553600369, 'Total loss': 0.523478553600369}
2022-12-05 23:38:02,653 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:02,653 INFO:     Epoch: 74
2022-12-05 23:38:03,369 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47555326399478043, 'Total loss': 0.47555326399478043} | train loss {'Reaction outcome loss': 0.5297859023895956, 'Total loss': 0.5297859023895956}
2022-12-05 23:38:03,370 INFO:     Found new best model at epoch 74
2022-12-05 23:38:03,370 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:03,370 INFO:     Epoch: 75
2022-12-05 23:38:04,088 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4970167296176607, 'Total loss': 0.4970167296176607} | train loss {'Reaction outcome loss': 0.5224291796405469, 'Total loss': 0.5224291796405469}
2022-12-05 23:38:04,088 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:04,088 INFO:     Epoch: 76
2022-12-05 23:38:04,805 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.519052545455369, 'Total loss': 0.519052545455369} | train loss {'Reaction outcome loss': 0.5274557619085235, 'Total loss': 0.5274557619085235}
2022-12-05 23:38:04,805 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:04,806 INFO:     Epoch: 77
2022-12-05 23:38:05,523 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5565352243455973, 'Total loss': 0.5565352243455973} | train loss {'Reaction outcome loss': 0.5307533134736361, 'Total loss': 0.5307533134736361}
2022-12-05 23:38:05,523 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:05,523 INFO:     Epoch: 78
2022-12-05 23:38:06,242 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.500462800941684, 'Total loss': 0.500462800941684} | train loss {'Reaction outcome loss': 0.5281287381245244, 'Total loss': 0.5281287381245244}
2022-12-05 23:38:06,242 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:06,242 INFO:     Epoch: 79
2022-12-05 23:38:06,962 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4963198412548412, 'Total loss': 0.4963198412548412} | train loss {'Reaction outcome loss': 0.5261433555354034, 'Total loss': 0.5261433555354034}
2022-12-05 23:38:06,962 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:06,962 INFO:     Epoch: 80
2022-12-05 23:38:07,681 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49558900499885733, 'Total loss': 0.49558900499885733} | train loss {'Reaction outcome loss': 0.5304731961580054, 'Total loss': 0.5304731961580054}
2022-12-05 23:38:07,682 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:07,682 INFO:     Epoch: 81
2022-12-05 23:38:08,397 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5249354947697032, 'Total loss': 0.5249354947697032} | train loss {'Reaction outcome loss': 0.5268178690345057, 'Total loss': 0.5268178690345057}
2022-12-05 23:38:08,397 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:08,397 INFO:     Epoch: 82
2022-12-05 23:38:09,109 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5231419158252802, 'Total loss': 0.5231419158252802} | train loss {'Reaction outcome loss': 0.5329776212813393, 'Total loss': 0.5329776212813393}
2022-12-05 23:38:09,110 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:09,110 INFO:     Epoch: 83
2022-12-05 23:38:09,822 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.49938811734318733, 'Total loss': 0.49938811734318733} | train loss {'Reaction outcome loss': 0.5314387081851882, 'Total loss': 0.5314387081851882}
2022-12-05 23:38:09,822 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:09,823 INFO:     Epoch: 84
2022-12-05 23:38:10,538 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4853959466246041, 'Total loss': 0.4853959466246041} | train loss {'Reaction outcome loss': 0.5216428217508139, 'Total loss': 0.5216428217508139}
2022-12-05 23:38:10,538 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:10,539 INFO:     Epoch: 85
2022-12-05 23:38:11,251 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5026205822148107, 'Total loss': 0.5026205822148107} | train loss {'Reaction outcome loss': 0.5364148838505629, 'Total loss': 0.5364148838505629}
2022-12-05 23:38:11,252 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:11,252 INFO:     Epoch: 86
2022-12-05 23:38:11,966 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5093006014146588, 'Total loss': 0.5093006014146588} | train loss {'Reaction outcome loss': 0.5238954076964047, 'Total loss': 0.5238954076964047}
2022-12-05 23:38:11,966 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:11,966 INFO:     Epoch: 87
2022-12-05 23:38:12,680 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4941813683306629, 'Total loss': 0.4941813683306629} | train loss {'Reaction outcome loss': 0.5316493348368714, 'Total loss': 0.5316493348368714}
2022-12-05 23:38:12,680 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:12,680 INFO:     Epoch: 88
2022-12-05 23:38:13,392 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5085284797982736, 'Total loss': 0.5085284797982736} | train loss {'Reaction outcome loss': 0.5323463451237448, 'Total loss': 0.5323463451237448}
2022-12-05 23:38:13,392 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:13,393 INFO:     Epoch: 89
2022-12-05 23:38:14,105 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49775718931447377, 'Total loss': 0.49775718931447377} | train loss {'Reaction outcome loss': 0.523226406485323, 'Total loss': 0.523226406485323}
2022-12-05 23:38:14,106 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:14,106 INFO:     Epoch: 90
2022-12-05 23:38:14,818 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5047731548547745, 'Total loss': 0.5047731548547745} | train loss {'Reaction outcome loss': 0.5304888529522765, 'Total loss': 0.5304888529522765}
2022-12-05 23:38:14,818 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:14,818 INFO:     Epoch: 91
2022-12-05 23:38:15,530 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5170718986879695, 'Total loss': 0.5170718986879695} | train loss {'Reaction outcome loss': 0.5217122017375885, 'Total loss': 0.5217122017375885}
2022-12-05 23:38:15,531 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:15,531 INFO:     Epoch: 92
2022-12-05 23:38:16,243 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5123403366993774, 'Total loss': 0.5123403366993774} | train loss {'Reaction outcome loss': 0.5298328507210939, 'Total loss': 0.5298328507210939}
2022-12-05 23:38:16,243 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:16,243 INFO:     Epoch: 93
2022-12-05 23:38:16,959 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5065733996981924, 'Total loss': 0.5065733996981924} | train loss {'Reaction outcome loss': 0.5315421299948808, 'Total loss': 0.5315421299948808}
2022-12-05 23:38:16,959 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:16,959 INFO:     Epoch: 94
2022-12-05 23:38:17,676 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5022089142691005, 'Total loss': 0.5022089142691005} | train loss {'Reaction outcome loss': 0.5236693989605673, 'Total loss': 0.5236693989605673}
2022-12-05 23:38:17,676 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:17,677 INFO:     Epoch: 95
2022-12-05 23:38:18,393 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5349909222938798, 'Total loss': 0.5349909222938798} | train loss {'Reaction outcome loss': 0.5266899649173983, 'Total loss': 0.5266899649173983}
2022-12-05 23:38:18,393 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:18,393 INFO:     Epoch: 96
2022-12-05 23:38:19,108 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4918423423712904, 'Total loss': 0.4918423423712904} | train loss {'Reaction outcome loss': 0.5260094115811009, 'Total loss': 0.5260094115811009}
2022-12-05 23:38:19,108 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:19,108 INFO:     Epoch: 97
2022-12-05 23:38:19,824 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49534179947592993, 'Total loss': 0.49534179947592993} | train loss {'Reaction outcome loss': 0.522734698809443, 'Total loss': 0.522734698809443}
2022-12-05 23:38:19,824 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:19,824 INFO:     Epoch: 98
2022-12-05 23:38:20,542 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5107375444336371, 'Total loss': 0.5107375444336371} | train loss {'Reaction outcome loss': 0.5297252892726853, 'Total loss': 0.5297252892726853}
2022-12-05 23:38:20,542 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:20,542 INFO:     Epoch: 99
2022-12-05 23:38:21,256 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4817189601334659, 'Total loss': 0.4817189601334659} | train loss {'Reaction outcome loss': 0.5253321749548758, 'Total loss': 0.5253321749548758}
2022-12-05 23:38:21,257 INFO:     Best model found after epoch 75 of 100.
2022-12-05 23:38:21,257 INFO:   Done with stage: TRAINING
2022-12-05 23:38:21,257 INFO:   Starting stage: EVALUATION
2022-12-05 23:38:21,375 INFO:   Done with stage: EVALUATION
2022-12-05 23:38:21,376 INFO:   Leaving out SEQ value Fold_8
2022-12-05 23:38:21,388 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-12-05 23:38:21,389 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:38:22,032 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:38:22,032 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:38:22,103 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:38:22,103 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:38:22,103 INFO:     No hyperparam tuning for this model
2022-12-05 23:38:22,103 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:38:22,103 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:38:22,104 INFO:     None feature selector for col prot
2022-12-05 23:38:22,104 INFO:     None feature selector for col prot
2022-12-05 23:38:22,104 INFO:     None feature selector for col prot
2022-12-05 23:38:22,105 INFO:     None feature selector for col chem
2022-12-05 23:38:22,105 INFO:     None feature selector for col chem
2022-12-05 23:38:22,105 INFO:     None feature selector for col chem
2022-12-05 23:38:22,105 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:38:22,105 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:38:22,107 INFO:     Number of params in model 215731
2022-12-05 23:38:22,110 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:38:22,110 INFO:   Starting stage: TRAINING
2022-12-05 23:38:22,168 INFO:     Val loss before train {'Reaction outcome loss': 1.0807397243651478, 'Total loss': 1.0807397243651478}
2022-12-05 23:38:22,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:22,168 INFO:     Epoch: 0
2022-12-05 23:38:22,880 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7322621697729285, 'Total loss': 0.7322621697729285} | train loss {'Reaction outcome loss': 0.8189340910363582, 'Total loss': 0.8189340910363582}
2022-12-05 23:38:22,880 INFO:     Found new best model at epoch 0
2022-12-05 23:38:22,880 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:22,881 INFO:     Epoch: 1
2022-12-05 23:38:23,590 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.605408063666387, 'Total loss': 0.605408063666387} | train loss {'Reaction outcome loss': 0.6815417793489271, 'Total loss': 0.6815417793489271}
2022-12-05 23:38:23,590 INFO:     Found new best model at epoch 1
2022-12-05 23:38:23,591 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:23,591 INFO:     Epoch: 2
2022-12-05 23:38:24,304 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5958300151608207, 'Total loss': 0.5958300151608207} | train loss {'Reaction outcome loss': 0.6272490409112745, 'Total loss': 0.6272490409112745}
2022-12-05 23:38:24,304 INFO:     Found new best model at epoch 2
2022-12-05 23:38:24,304 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:24,304 INFO:     Epoch: 3
2022-12-05 23:38:25,020 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6001865335486152, 'Total loss': 0.6001865335486152} | train loss {'Reaction outcome loss': 0.6079602153190682, 'Total loss': 0.6079602153190682}
2022-12-05 23:38:25,020 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:25,020 INFO:     Epoch: 4
2022-12-05 23:38:25,732 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5851025202057578, 'Total loss': 0.5851025202057578} | train loss {'Reaction outcome loss': 0.5936187938336404, 'Total loss': 0.5936187938336404}
2022-12-05 23:38:25,732 INFO:     Found new best model at epoch 4
2022-12-05 23:38:25,733 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:25,733 INFO:     Epoch: 5
2022-12-05 23:38:26,451 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.570089424198324, 'Total loss': 0.570089424198324} | train loss {'Reaction outcome loss': 0.5791872901721827, 'Total loss': 0.5791872901721827}
2022-12-05 23:38:26,452 INFO:     Found new best model at epoch 5
2022-12-05 23:38:26,453 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:26,453 INFO:     Epoch: 6
2022-12-05 23:38:27,168 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5713517862287435, 'Total loss': 0.5713517862287435} | train loss {'Reaction outcome loss': 0.5776603208674539, 'Total loss': 0.5776603208674539}
2022-12-05 23:38:27,168 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:27,168 INFO:     Epoch: 7
2022-12-05 23:38:27,885 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5762779252095656, 'Total loss': 0.5762779252095656} | train loss {'Reaction outcome loss': 0.5676868964707659, 'Total loss': 0.5676868964707659}
2022-12-05 23:38:27,885 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:27,886 INFO:     Epoch: 8
2022-12-05 23:38:28,599 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5412838899276473, 'Total loss': 0.5412838899276473} | train loss {'Reaction outcome loss': 0.5509333975853459, 'Total loss': 0.5509333975853459}
2022-12-05 23:38:28,599 INFO:     Found new best model at epoch 8
2022-12-05 23:38:28,600 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:28,600 INFO:     Epoch: 9
2022-12-05 23:38:29,313 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5693700889294798, 'Total loss': 0.5693700889294798} | train loss {'Reaction outcome loss': 0.554923600186744, 'Total loss': 0.554923600186744}
2022-12-05 23:38:29,314 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:29,314 INFO:     Epoch: 10
2022-12-05 23:38:30,026 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5370816713707014, 'Total loss': 0.5370816713707014} | train loss {'Reaction outcome loss': 0.5487621480058278, 'Total loss': 0.5487621480058278}
2022-12-05 23:38:30,027 INFO:     Found new best model at epoch 10
2022-12-05 23:38:30,027 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:30,027 INFO:     Epoch: 11
2022-12-05 23:38:30,739 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5134642957286402, 'Total loss': 0.5134642957286402} | train loss {'Reaction outcome loss': 0.5493581361107288, 'Total loss': 0.5493581361107288}
2022-12-05 23:38:30,739 INFO:     Found new best model at epoch 11
2022-12-05 23:38:30,739 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:30,740 INFO:     Epoch: 12
2022-12-05 23:38:31,452 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5076825879514217, 'Total loss': 0.5076825879514217} | train loss {'Reaction outcome loss': 0.5419523247307346, 'Total loss': 0.5419523247307346}
2022-12-05 23:38:31,452 INFO:     Found new best model at epoch 12
2022-12-05 23:38:31,453 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:31,453 INFO:     Epoch: 13
2022-12-05 23:38:32,166 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5292183709415522, 'Total loss': 0.5292183709415522} | train loss {'Reaction outcome loss': 0.5306380332838143, 'Total loss': 0.5306380332838143}
2022-12-05 23:38:32,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:32,166 INFO:     Epoch: 14
2022-12-05 23:38:32,877 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5451500585133379, 'Total loss': 0.5451500585133379} | train loss {'Reaction outcome loss': 0.5389944481993875, 'Total loss': 0.5389944481993875}
2022-12-05 23:38:32,877 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:32,877 INFO:     Epoch: 15
2022-12-05 23:38:33,587 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5278809375383637, 'Total loss': 0.5278809375383637} | train loss {'Reaction outcome loss': 0.5368985778261577, 'Total loss': 0.5368985778261577}
2022-12-05 23:38:33,587 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:33,587 INFO:     Epoch: 16
2022-12-05 23:38:34,299 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5202864564277909, 'Total loss': 0.5202864564277909} | train loss {'Reaction outcome loss': 0.5345452848461366, 'Total loss': 0.5345452848461366}
2022-12-05 23:38:34,299 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:34,299 INFO:     Epoch: 17
2022-12-05 23:38:35,011 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5228821987455542, 'Total loss': 0.5228821987455542} | train loss {'Reaction outcome loss': 0.5239211952373866, 'Total loss': 0.5239211952373866}
2022-12-05 23:38:35,011 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:35,011 INFO:     Epoch: 18
2022-12-05 23:38:35,721 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5318958799947392, 'Total loss': 0.5318958799947392} | train loss {'Reaction outcome loss': 0.5404018320503735, 'Total loss': 0.5404018320503735}
2022-12-05 23:38:35,721 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:35,721 INFO:     Epoch: 19
2022-12-05 23:38:36,432 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5410821261731061, 'Total loss': 0.5410821261731061} | train loss {'Reaction outcome loss': 0.5221216146864237, 'Total loss': 0.5221216146864237}
2022-12-05 23:38:36,432 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:36,432 INFO:     Epoch: 20
2022-12-05 23:38:37,142 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49843395433642645, 'Total loss': 0.49843395433642645} | train loss {'Reaction outcome loss': 0.5204924611795333, 'Total loss': 0.5204924611795333}
2022-12-05 23:38:37,142 INFO:     Found new best model at epoch 20
2022-12-05 23:38:37,143 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:37,143 INFO:     Epoch: 21
2022-12-05 23:38:37,854 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.517296911301938, 'Total loss': 0.517296911301938} | train loss {'Reaction outcome loss': 0.5216184490991216, 'Total loss': 0.5216184490991216}
2022-12-05 23:38:37,854 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:37,854 INFO:     Epoch: 22
2022-12-05 23:38:38,569 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4975755593993447, 'Total loss': 0.4975755593993447} | train loss {'Reaction outcome loss': 0.5281622554025343, 'Total loss': 0.5281622554025343}
2022-12-05 23:38:38,570 INFO:     Found new best model at epoch 22
2022-12-05 23:38:38,571 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:38,571 INFO:     Epoch: 23
2022-12-05 23:38:39,283 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.505449188026515, 'Total loss': 0.505449188026515} | train loss {'Reaction outcome loss': 0.5185255732146963, 'Total loss': 0.5185255732146963}
2022-12-05 23:38:39,284 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:39,284 INFO:     Epoch: 24
2022-12-05 23:38:39,999 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5116364393721927, 'Total loss': 0.5116364393721927} | train loss {'Reaction outcome loss': 0.5123790967608651, 'Total loss': 0.5123790967608651}
2022-12-05 23:38:39,999 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:39,999 INFO:     Epoch: 25
2022-12-05 23:38:40,714 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49260595576329663, 'Total loss': 0.49260595576329663} | train loss {'Reaction outcome loss': 0.5281241134770455, 'Total loss': 0.5281241134770455}
2022-12-05 23:38:40,715 INFO:     Found new best model at epoch 25
2022-12-05 23:38:40,715 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:40,715 INFO:     Epoch: 26
2022-12-05 23:38:41,432 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4868512637913227, 'Total loss': 0.4868512637913227} | train loss {'Reaction outcome loss': 0.5122589347583633, 'Total loss': 0.5122589347583633}
2022-12-05 23:38:41,432 INFO:     Found new best model at epoch 26
2022-12-05 23:38:41,433 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:41,433 INFO:     Epoch: 27
2022-12-05 23:38:42,145 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5026933726939288, 'Total loss': 0.5026933726939288} | train loss {'Reaction outcome loss': 0.524880766267738, 'Total loss': 0.524880766267738}
2022-12-05 23:38:42,145 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:42,145 INFO:     Epoch: 28
2022-12-05 23:38:42,860 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5415422862226312, 'Total loss': 0.5415422862226312} | train loss {'Reaction outcome loss': 0.5178473472234703, 'Total loss': 0.5178473472234703}
2022-12-05 23:38:42,860 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:42,860 INFO:     Epoch: 29
2022-12-05 23:38:43,571 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5044899108734998, 'Total loss': 0.5044899108734998} | train loss {'Reaction outcome loss': 0.5214736021213955, 'Total loss': 0.5214736021213955}
2022-12-05 23:38:43,571 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:43,572 INFO:     Epoch: 30
2022-12-05 23:38:44,283 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5111620121381499, 'Total loss': 0.5111620121381499} | train loss {'Reaction outcome loss': 0.5245016770617615, 'Total loss': 0.5245016770617615}
2022-12-05 23:38:44,283 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:44,283 INFO:     Epoch: 31
2022-12-05 23:38:44,995 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4953905049372803, 'Total loss': 0.4953905049372803} | train loss {'Reaction outcome loss': 0.5180584361115771, 'Total loss': 0.5180584361115771}
2022-12-05 23:38:44,995 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:44,996 INFO:     Epoch: 32
2022-12-05 23:38:45,706 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5258341076021845, 'Total loss': 0.5258341076021845} | train loss {'Reaction outcome loss': 0.5241153979253385, 'Total loss': 0.5241153979253385}
2022-12-05 23:38:45,707 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:45,707 INFO:     Epoch: 33
2022-12-05 23:38:46,422 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5406253392046149, 'Total loss': 0.5406253392046149} | train loss {'Reaction outcome loss': 0.5150120698756748, 'Total loss': 0.5150120698756748}
2022-12-05 23:38:46,422 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:46,422 INFO:     Epoch: 34
2022-12-05 23:38:47,133 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4797385707497597, 'Total loss': 0.4797385707497597} | train loss {'Reaction outcome loss': 0.5133895458833825, 'Total loss': 0.5133895458833825}
2022-12-05 23:38:47,133 INFO:     Found new best model at epoch 34
2022-12-05 23:38:47,134 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:47,134 INFO:     Epoch: 35
2022-12-05 23:38:47,846 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5243766006420959, 'Total loss': 0.5243766006420959} | train loss {'Reaction outcome loss': 0.5148290214279005, 'Total loss': 0.5148290214279005}
2022-12-05 23:38:47,846 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:47,846 INFO:     Epoch: 36
2022-12-05 23:38:48,561 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5312747040932829, 'Total loss': 0.5312747040932829} | train loss {'Reaction outcome loss': 0.5174803620264414, 'Total loss': 0.5174803620264414}
2022-12-05 23:38:48,561 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:48,562 INFO:     Epoch: 37
2022-12-05 23:38:49,278 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5171303664418784, 'Total loss': 0.5171303664418784} | train loss {'Reaction outcome loss': 0.5166728401015843, 'Total loss': 0.5166728401015843}
2022-12-05 23:38:49,278 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:49,278 INFO:     Epoch: 38
2022-12-05 23:38:49,995 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5166981768879023, 'Total loss': 0.5166981768879023} | train loss {'Reaction outcome loss': 0.5155563758265588, 'Total loss': 0.5155563758265588}
2022-12-05 23:38:49,995 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:49,995 INFO:     Epoch: 39
2022-12-05 23:38:50,705 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5237722965804014, 'Total loss': 0.5237722965804014} | train loss {'Reaction outcome loss': 0.511006077871688, 'Total loss': 0.511006077871688}
2022-12-05 23:38:50,705 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:50,705 INFO:     Epoch: 40
2022-12-05 23:38:51,416 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5021181201392954, 'Total loss': 0.5021181201392954} | train loss {'Reaction outcome loss': 0.5088638139948729, 'Total loss': 0.5088638139948729}
2022-12-05 23:38:51,416 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:51,416 INFO:     Epoch: 41
2022-12-05 23:38:52,128 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5135766975581646, 'Total loss': 0.5135766975581646} | train loss {'Reaction outcome loss': 0.5166542624994632, 'Total loss': 0.5166542624994632}
2022-12-05 23:38:52,129 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:52,129 INFO:     Epoch: 42
2022-12-05 23:38:52,840 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5117936974222009, 'Total loss': 0.5117936974222009} | train loss {'Reaction outcome loss': 0.5146353329501806, 'Total loss': 0.5146353329501806}
2022-12-05 23:38:52,840 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:52,841 INFO:     Epoch: 43
2022-12-05 23:38:53,555 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48399673707105895, 'Total loss': 0.48399673707105895} | train loss {'Reaction outcome loss': 0.5172277711211674, 'Total loss': 0.5172277711211674}
2022-12-05 23:38:53,555 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:53,555 INFO:     Epoch: 44
2022-12-05 23:38:54,265 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48367241431366315, 'Total loss': 0.48367241431366315} | train loss {'Reaction outcome loss': 0.516344583142669, 'Total loss': 0.516344583142669}
2022-12-05 23:38:54,266 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:54,266 INFO:     Epoch: 45
2022-12-05 23:38:54,974 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5283456045118246, 'Total loss': 0.5283456045118246} | train loss {'Reaction outcome loss': 0.525726267707444, 'Total loss': 0.525726267707444}
2022-12-05 23:38:54,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:54,974 INFO:     Epoch: 46
2022-12-05 23:38:55,682 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4916911084543575, 'Total loss': 0.4916911084543575} | train loss {'Reaction outcome loss': 0.5227793795206854, 'Total loss': 0.5227793795206854}
2022-12-05 23:38:55,682 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:55,682 INFO:     Epoch: 47
2022-12-05 23:38:56,390 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4946402324871583, 'Total loss': 0.4946402324871583} | train loss {'Reaction outcome loss': 0.5086491515920046, 'Total loss': 0.5086491515920046}
2022-12-05 23:38:56,390 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:56,390 INFO:     Epoch: 48
2022-12-05 23:38:57,098 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5235185359011997, 'Total loss': 0.5235185359011997} | train loss {'Reaction outcome loss': 0.5181366783837157, 'Total loss': 0.5181366783837157}
2022-12-05 23:38:57,099 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:57,099 INFO:     Epoch: 49
2022-12-05 23:38:57,810 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5084475663236596, 'Total loss': 0.5084475663236596} | train loss {'Reaction outcome loss': 0.5175857887633385, 'Total loss': 0.5175857887633385}
2022-12-05 23:38:57,810 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:57,810 INFO:     Epoch: 50
2022-12-05 23:38:58,516 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5052760060537945, 'Total loss': 0.5052760060537945} | train loss {'Reaction outcome loss': 0.5126974699838508, 'Total loss': 0.5126974699838508}
2022-12-05 23:38:58,516 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:58,516 INFO:     Epoch: 51
2022-12-05 23:38:59,220 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48736150698228314, 'Total loss': 0.48736150698228314} | train loss {'Reaction outcome loss': 0.5109053176016577, 'Total loss': 0.5109053176016577}
2022-12-05 23:38:59,220 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:59,220 INFO:     Epoch: 52
2022-12-05 23:38:59,926 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5170897299593146, 'Total loss': 0.5170897299593146} | train loss {'Reaction outcome loss': 0.5182031225413084, 'Total loss': 0.5182031225413084}
2022-12-05 23:38:59,927 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:38:59,927 INFO:     Epoch: 53
2022-12-05 23:39:00,635 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5073912204666571, 'Total loss': 0.5073912204666571} | train loss {'Reaction outcome loss': 0.5204696267422649, 'Total loss': 0.5204696267422649}
2022-12-05 23:39:00,635 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:00,635 INFO:     Epoch: 54
2022-12-05 23:39:01,343 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4946704649112441, 'Total loss': 0.4946704649112441} | train loss {'Reaction outcome loss': 0.5108292643581668, 'Total loss': 0.5108292643581668}
2022-12-05 23:39:01,343 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:01,343 INFO:     Epoch: 55
2022-12-05 23:39:02,045 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4693987061354247, 'Total loss': 0.4693987061354247} | train loss {'Reaction outcome loss': 0.5121878039452338, 'Total loss': 0.5121878039452338}
2022-12-05 23:39:02,045 INFO:     Found new best model at epoch 55
2022-12-05 23:39:02,046 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:02,046 INFO:     Epoch: 56
2022-12-05 23:39:02,752 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.50284593552351, 'Total loss': 0.50284593552351} | train loss {'Reaction outcome loss': 0.5098604504920302, 'Total loss': 0.5098604504920302}
2022-12-05 23:39:02,752 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:02,752 INFO:     Epoch: 57
2022-12-05 23:39:03,454 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48324819044633344, 'Total loss': 0.48324819044633344} | train loss {'Reaction outcome loss': 0.5199578140651987, 'Total loss': 0.5199578140651987}
2022-12-05 23:39:03,455 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:03,455 INFO:     Epoch: 58
2022-12-05 23:39:04,157 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.48552369529550726, 'Total loss': 0.48552369529550726} | train loss {'Reaction outcome loss': 0.5145600005503623, 'Total loss': 0.5145600005503623}
2022-12-05 23:39:04,157 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:04,157 INFO:     Epoch: 59
2022-12-05 23:39:04,864 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4922334003177556, 'Total loss': 0.4922334003177556} | train loss {'Reaction outcome loss': 0.518145602016199, 'Total loss': 0.518145602016199}
2022-12-05 23:39:04,864 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:04,864 INFO:     Epoch: 60
2022-12-05 23:39:05,567 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4802970933643254, 'Total loss': 0.4802970933643254} | train loss {'Reaction outcome loss': 0.5129648074507713, 'Total loss': 0.5129648074507713}
2022-12-05 23:39:05,567 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:05,568 INFO:     Epoch: 61
2022-12-05 23:39:06,274 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48261694474653766, 'Total loss': 0.48261694474653766} | train loss {'Reaction outcome loss': 0.5279515981674194, 'Total loss': 0.5279515981674194}
2022-12-05 23:39:06,274 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:06,274 INFO:     Epoch: 62
2022-12-05 23:39:06,977 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4978726160797206, 'Total loss': 0.4978726160797206} | train loss {'Reaction outcome loss': 0.5062467665561745, 'Total loss': 0.5062467665561745}
2022-12-05 23:39:06,977 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:06,977 INFO:     Epoch: 63
2022-12-05 23:39:07,684 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4952772185206413, 'Total loss': 0.4952772185206413} | train loss {'Reaction outcome loss': 0.5192028789390479, 'Total loss': 0.5192028789390479}
2022-12-05 23:39:07,684 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:07,684 INFO:     Epoch: 64
2022-12-05 23:39:08,387 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49297234178944066, 'Total loss': 0.49297234178944066} | train loss {'Reaction outcome loss': 0.5148792206159523, 'Total loss': 0.5148792206159523}
2022-12-05 23:39:08,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:08,387 INFO:     Epoch: 65
2022-12-05 23:39:09,090 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5099204097959128, 'Total loss': 0.5099204097959128} | train loss {'Reaction outcome loss': 0.5143821470799946, 'Total loss': 0.5143821470799946}
2022-12-05 23:39:09,090 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:09,090 INFO:     Epoch: 66
2022-12-05 23:39:09,794 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49165477468208835, 'Total loss': 0.49165477468208835} | train loss {'Reaction outcome loss': 0.5129953958694974, 'Total loss': 0.5129953958694974}
2022-12-05 23:39:09,795 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:09,796 INFO:     Epoch: 67
2022-12-05 23:39:10,503 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5050769197669897, 'Total loss': 0.5050769197669897} | train loss {'Reaction outcome loss': 0.5077930247230876, 'Total loss': 0.5077930247230876}
2022-12-05 23:39:10,503 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:10,503 INFO:     Epoch: 68
2022-12-05 23:39:11,210 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4857433865016157, 'Total loss': 0.4857433865016157} | train loss {'Reaction outcome loss': 0.5207122707318875, 'Total loss': 0.5207122707318875}
2022-12-05 23:39:11,210 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:11,210 INFO:     Epoch: 69
2022-12-05 23:39:11,918 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4873635545372963, 'Total loss': 0.4873635545372963} | train loss {'Reaction outcome loss': 0.5133773366650266, 'Total loss': 0.5133773366650266}
2022-12-05 23:39:11,918 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:11,918 INFO:     Epoch: 70
2022-12-05 23:39:12,628 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.49677876620130107, 'Total loss': 0.49677876620130107} | train loss {'Reaction outcome loss': 0.5181820356557446, 'Total loss': 0.5181820356557446}
2022-12-05 23:39:12,629 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:12,629 INFO:     Epoch: 71
2022-12-05 23:39:13,341 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.523765454576774, 'Total loss': 0.523765454576774} | train loss {'Reaction outcome loss': 0.5083985152023454, 'Total loss': 0.5083985152023454}
2022-12-05 23:39:13,341 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:13,341 INFO:     Epoch: 72
2022-12-05 23:39:14,049 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5038007897409525, 'Total loss': 0.5038007897409525} | train loss {'Reaction outcome loss': 0.5168233680869302, 'Total loss': 0.5168233680869302}
2022-12-05 23:39:14,050 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:14,050 INFO:     Epoch: 73
2022-12-05 23:39:14,763 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48942992463707924, 'Total loss': 0.48942992463707924} | train loss {'Reaction outcome loss': 0.5129098436765133, 'Total loss': 0.5129098436765133}
2022-12-05 23:39:14,763 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:14,763 INFO:     Epoch: 74
2022-12-05 23:39:15,471 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.49864834343845194, 'Total loss': 0.49864834343845194} | train loss {'Reaction outcome loss': 0.5189376005362119, 'Total loss': 0.5189376005362119}
2022-12-05 23:39:15,471 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:15,471 INFO:     Epoch: 75
2022-12-05 23:39:16,178 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49179317395795474, 'Total loss': 0.49179317395795474} | train loss {'Reaction outcome loss': 0.5149927585115356, 'Total loss': 0.5149927585115356}
2022-12-05 23:39:16,178 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:16,179 INFO:     Epoch: 76
2022-12-05 23:39:16,887 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5056672441688451, 'Total loss': 0.5056672441688451} | train loss {'Reaction outcome loss': 0.5244703101775339, 'Total loss': 0.5244703101775339}
2022-12-05 23:39:16,887 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:16,887 INFO:     Epoch: 77
2022-12-05 23:39:17,597 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4788531180132519, 'Total loss': 0.4788531180132519} | train loss {'Reaction outcome loss': 0.5132266338313779, 'Total loss': 0.5132266338313779}
2022-12-05 23:39:17,597 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:17,597 INFO:     Epoch: 78
2022-12-05 23:39:18,310 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5537385601889003, 'Total loss': 0.5537385601889003} | train loss {'Reaction outcome loss': 0.5134692381346418, 'Total loss': 0.5134692381346418}
2022-12-05 23:39:18,310 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:18,310 INFO:     Epoch: 79
2022-12-05 23:39:19,018 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5086548965085637, 'Total loss': 0.5086548965085637} | train loss {'Reaction outcome loss': 0.5097414646898547, 'Total loss': 0.5097414646898547}
2022-12-05 23:39:19,018 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:19,019 INFO:     Epoch: 80
2022-12-05 23:39:19,730 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5158274207602848, 'Total loss': 0.5158274207602848} | train loss {'Reaction outcome loss': 0.5315148424837859, 'Total loss': 0.5315148424837859}
2022-12-05 23:39:19,730 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:19,730 INFO:     Epoch: 81
2022-12-05 23:39:20,441 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.489428372207013, 'Total loss': 0.489428372207013} | train loss {'Reaction outcome loss': 0.5117298644336481, 'Total loss': 0.5117298644336481}
2022-12-05 23:39:20,441 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:20,441 INFO:     Epoch: 82
2022-12-05 23:39:21,147 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4825799817388708, 'Total loss': 0.4825799817388708} | train loss {'Reaction outcome loss': 0.5121802833652304, 'Total loss': 0.5121802833652304}
2022-12-05 23:39:21,147 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:21,147 INFO:     Epoch: 83
2022-12-05 23:39:21,853 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5005785579031165, 'Total loss': 0.5005785579031165} | train loss {'Reaction outcome loss': 0.51453379908156, 'Total loss': 0.51453379908156}
2022-12-05 23:39:21,853 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:21,853 INFO:     Epoch: 84
2022-12-05 23:39:22,561 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5114451700990851, 'Total loss': 0.5114451700990851} | train loss {'Reaction outcome loss': 0.5230211320543482, 'Total loss': 0.5230211320543482}
2022-12-05 23:39:22,561 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:22,561 INFO:     Epoch: 85
2022-12-05 23:39:23,268 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5434856150637973, 'Total loss': 0.5434856150637973} | train loss {'Reaction outcome loss': 0.5141373974301161, 'Total loss': 0.5141373974301161}
2022-12-05 23:39:23,268 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:23,268 INFO:     Epoch: 86
2022-12-05 23:39:23,974 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4928992824120955, 'Total loss': 0.4928992824120955} | train loss {'Reaction outcome loss': 0.5100709478100461, 'Total loss': 0.5100709478100461}
2022-12-05 23:39:23,974 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:23,974 INFO:     Epoch: 87
2022-12-05 23:39:24,680 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5034433532167565, 'Total loss': 0.5034433532167565} | train loss {'Reaction outcome loss': 0.5249926875075025, 'Total loss': 0.5249926875075025}
2022-12-05 23:39:24,680 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:24,680 INFO:     Epoch: 88
2022-12-05 23:39:25,387 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4845658256248994, 'Total loss': 0.4845658256248994} | train loss {'Reaction outcome loss': 0.5147936214362422, 'Total loss': 0.5147936214362422}
2022-12-05 23:39:25,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:25,387 INFO:     Epoch: 89
2022-12-05 23:39:26,096 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.48825130611658096, 'Total loss': 0.48825130611658096} | train loss {'Reaction outcome loss': 0.510917853203512, 'Total loss': 0.510917853203512}
2022-12-05 23:39:26,096 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:26,096 INFO:     Epoch: 90
2022-12-05 23:39:26,806 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4881183701482686, 'Total loss': 0.4881183701482686} | train loss {'Reaction outcome loss': 0.510656880515237, 'Total loss': 0.510656880515237}
2022-12-05 23:39:26,806 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:26,806 INFO:     Epoch: 91
2022-12-05 23:39:27,512 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5036756301468069, 'Total loss': 0.5036756301468069} | train loss {'Reaction outcome loss': 0.523147587694468, 'Total loss': 0.523147587694468}
2022-12-05 23:39:27,512 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:27,512 INFO:     Epoch: 92
2022-12-05 23:39:28,218 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5080146396701987, 'Total loss': 0.5080146396701987} | train loss {'Reaction outcome loss': 0.5140564804596286, 'Total loss': 0.5140564804596286}
2022-12-05 23:39:28,218 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:28,219 INFO:     Epoch: 93
2022-12-05 23:39:28,926 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5181390270590782, 'Total loss': 0.5181390270590782} | train loss {'Reaction outcome loss': 0.5162253570292266, 'Total loss': 0.5162253570292266}
2022-12-05 23:39:28,926 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:28,926 INFO:     Epoch: 94
2022-12-05 23:39:29,633 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48969044434753334, 'Total loss': 0.48969044434753334} | train loss {'Reaction outcome loss': 0.5137553903905134, 'Total loss': 0.5137553903905134}
2022-12-05 23:39:29,633 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:29,633 INFO:     Epoch: 95
2022-12-05 23:39:30,342 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.535819870504466, 'Total loss': 0.535819870504466} | train loss {'Reaction outcome loss': 0.5130111035560408, 'Total loss': 0.5130111035560408}
2022-12-05 23:39:30,342 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:30,343 INFO:     Epoch: 96
2022-12-05 23:39:31,054 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5152175108140166, 'Total loss': 0.5152175108140166} | train loss {'Reaction outcome loss': 0.512867335951136, 'Total loss': 0.512867335951136}
2022-12-05 23:39:31,054 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:31,054 INFO:     Epoch: 97
2022-12-05 23:39:31,763 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5095215341584249, 'Total loss': 0.5095215341584249} | train loss {'Reaction outcome loss': 0.5152387053615624, 'Total loss': 0.5152387053615624}
2022-12-05 23:39:31,763 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:31,763 INFO:     Epoch: 98
2022-12-05 23:39:32,469 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4991007257591594, 'Total loss': 0.4991007257591594} | train loss {'Reaction outcome loss': 0.520227377633414, 'Total loss': 0.520227377633414}
2022-12-05 23:39:32,469 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:32,469 INFO:     Epoch: 99
2022-12-05 23:39:33,174 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4978569597005844, 'Total loss': 0.4978569597005844} | train loss {'Reaction outcome loss': 0.5119311446624417, 'Total loss': 0.5119311446624417}
2022-12-05 23:39:33,174 INFO:     Best model found after epoch 56 of 100.
2022-12-05 23:39:33,174 INFO:   Done with stage: TRAINING
2022-12-05 23:39:33,174 INFO:   Starting stage: EVALUATION
2022-12-05 23:39:33,292 INFO:   Done with stage: EVALUATION
2022-12-05 23:39:33,293 INFO:   Leaving out SEQ value Fold_9
2022-12-05 23:39:33,305 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-12-05 23:39:33,305 INFO:   Starting stage: FEATURE SCALING
2022-12-05 23:39:33,942 INFO:   Done with stage: FEATURE SCALING
2022-12-05 23:39:33,942 INFO:   Starting stage: SCALING TARGETS
2022-12-05 23:39:34,013 INFO:   Done with stage: SCALING TARGETS
2022-12-05 23:39:34,013 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:39:34,013 INFO:     No hyperparam tuning for this model
2022-12-05 23:39:34,013 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-05 23:39:34,013 INFO:   Starting stage: FEATURE SELECTION
2022-12-05 23:39:34,014 INFO:     None feature selector for col prot
2022-12-05 23:39:34,014 INFO:     None feature selector for col prot
2022-12-05 23:39:34,014 INFO:     None feature selector for col prot
2022-12-05 23:39:34,015 INFO:     None feature selector for col chem
2022-12-05 23:39:34,015 INFO:     None feature selector for col chem
2022-12-05 23:39:34,015 INFO:     None feature selector for col chem
2022-12-05 23:39:34,015 INFO:   Done with stage: FEATURE SELECTION
2022-12-05 23:39:34,015 INFO:   Starting stage: BUILD MODEL
2022-12-05 23:39:34,017 INFO:     Number of params in model 215731
2022-12-05 23:39:34,020 INFO:   Done with stage: BUILD MODEL
2022-12-05 23:39:34,020 INFO:   Starting stage: TRAINING
2022-12-05 23:39:34,078 INFO:     Val loss before train {'Reaction outcome loss': 0.9999030543999239, 'Total loss': 0.9999030543999239}
2022-12-05 23:39:34,078 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:34,078 INFO:     Epoch: 0
2022-12-05 23:39:34,788 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6771824366667054, 'Total loss': 0.6771824366667054} | train loss {'Reaction outcome loss': 0.8250201525475814, 'Total loss': 0.8250201525475814}
2022-12-05 23:39:34,789 INFO:     Found new best model at epoch 0
2022-12-05 23:39:34,789 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:34,789 INFO:     Epoch: 1
2022-12-05 23:39:35,497 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6007652614604343, 'Total loss': 0.6007652614604343} | train loss {'Reaction outcome loss': 0.6844083343440222, 'Total loss': 0.6844083343440222}
2022-12-05 23:39:35,497 INFO:     Found new best model at epoch 1
2022-12-05 23:39:35,498 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:35,498 INFO:     Epoch: 2
2022-12-05 23:39:36,205 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5682653771205382, 'Total loss': 0.5682653771205382} | train loss {'Reaction outcome loss': 0.6290547810344078, 'Total loss': 0.6290547810344078}
2022-12-05 23:39:36,205 INFO:     Found new best model at epoch 2
2022-12-05 23:39:36,206 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:36,206 INFO:     Epoch: 3
2022-12-05 23:39:36,912 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5706934759562666, 'Total loss': 0.5706934759562666} | train loss {'Reaction outcome loss': 0.598030694436116, 'Total loss': 0.598030694436116}
2022-12-05 23:39:36,913 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:36,913 INFO:     Epoch: 4
2022-12-05 23:39:37,618 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5310494032773104, 'Total loss': 0.5310494032773104} | train loss {'Reaction outcome loss': 0.5837455990946727, 'Total loss': 0.5837455990946727}
2022-12-05 23:39:37,618 INFO:     Found new best model at epoch 4
2022-12-05 23:39:37,618 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:37,619 INFO:     Epoch: 5
2022-12-05 23:39:38,325 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5652598609978502, 'Total loss': 0.5652598609978502} | train loss {'Reaction outcome loss': 0.5799330334605174, 'Total loss': 0.5799330334605174}
2022-12-05 23:39:38,325 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:38,325 INFO:     Epoch: 6
2022-12-05 23:39:39,037 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5692722228440371, 'Total loss': 0.5692722228440371} | train loss {'Reaction outcome loss': 0.5661120405081312, 'Total loss': 0.5661120405081312}
2022-12-05 23:39:39,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:39,037 INFO:     Epoch: 7
2022-12-05 23:39:39,747 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5586847893216393, 'Total loss': 0.5586847893216393} | train loss {'Reaction outcome loss': 0.5705527678916329, 'Total loss': 0.5705527678916329}
2022-12-05 23:39:39,747 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:39,747 INFO:     Epoch: 8
2022-12-05 23:39:40,457 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5274835831739686, 'Total loss': 0.5274835831739686} | train loss {'Reaction outcome loss': 0.5636117817807625, 'Total loss': 0.5636117817807625}
2022-12-05 23:39:40,457 INFO:     Found new best model at epoch 8
2022-12-05 23:39:40,458 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:40,458 INFO:     Epoch: 9
2022-12-05 23:39:41,165 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.567402568730441, 'Total loss': 0.567402568730441} | train loss {'Reaction outcome loss': 0.5561492847286256, 'Total loss': 0.5561492847286256}
2022-12-05 23:39:41,166 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:41,166 INFO:     Epoch: 10
2022-12-05 23:39:41,875 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.505451881072738, 'Total loss': 0.505451881072738} | train loss {'Reaction outcome loss': 0.5502871577797631, 'Total loss': 0.5502871577797631}
2022-12-05 23:39:41,875 INFO:     Found new best model at epoch 10
2022-12-05 23:39:41,876 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:41,876 INFO:     Epoch: 11
2022-12-05 23:39:42,582 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5909728401086547, 'Total loss': 0.5909728401086547} | train loss {'Reaction outcome loss': 0.5599977422943, 'Total loss': 0.5599977422943}
2022-12-05 23:39:42,582 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:42,582 INFO:     Epoch: 12
2022-12-05 23:39:43,288 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5052035803144629, 'Total loss': 0.5052035803144629} | train loss {'Reaction outcome loss': 0.5553937369753957, 'Total loss': 0.5553937369753957}
2022-12-05 23:39:43,288 INFO:     Found new best model at epoch 12
2022-12-05 23:39:43,289 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:43,289 INFO:     Epoch: 13
2022-12-05 23:39:43,995 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5313138155774637, 'Total loss': 0.5313138155774637} | train loss {'Reaction outcome loss': 0.5504768390042579, 'Total loss': 0.5504768390042579}
2022-12-05 23:39:43,995 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:43,995 INFO:     Epoch: 14
2022-12-05 23:39:44,703 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5451471690427173, 'Total loss': 0.5451471690427173} | train loss {'Reaction outcome loss': 0.5441355731504166, 'Total loss': 0.5441355731504166}
2022-12-05 23:39:44,703 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:44,703 INFO:     Epoch: 15
2022-12-05 23:39:45,419 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5334056006236509, 'Total loss': 0.5334056006236509} | train loss {'Reaction outcome loss': 0.5510828293528152, 'Total loss': 0.5510828293528152}
2022-12-05 23:39:45,420 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:45,420 INFO:     Epoch: 16
2022-12-05 23:39:46,132 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4907666915519671, 'Total loss': 0.4907666915519671} | train loss {'Reaction outcome loss': 0.5480549953847762, 'Total loss': 0.5480549953847762}
2022-12-05 23:39:46,133 INFO:     Found new best model at epoch 16
2022-12-05 23:39:46,133 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:46,133 INFO:     Epoch: 17
2022-12-05 23:39:46,842 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5047755718908526, 'Total loss': 0.5047755718908526} | train loss {'Reaction outcome loss': 0.5574691862712505, 'Total loss': 0.5574691862712505}
2022-12-05 23:39:46,842 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:46,842 INFO:     Epoch: 18
2022-12-05 23:39:47,554 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.6651240905577486, 'Total loss': 0.6651240905577486} | train loss {'Reaction outcome loss': 0.5447859276408473, 'Total loss': 0.5447859276408473}
2022-12-05 23:39:47,555 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:47,555 INFO:     Epoch: 19
2022-12-05 23:39:48,269 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5478305207057432, 'Total loss': 0.5478305207057432} | train loss {'Reaction outcome loss': 0.5399319187168651, 'Total loss': 0.5399319187168651}
2022-12-05 23:39:48,270 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:48,270 INFO:     Epoch: 20
2022-12-05 23:39:48,981 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5522949284111912, 'Total loss': 0.5522949284111912} | train loss {'Reaction outcome loss': 0.5375422033583105, 'Total loss': 0.5375422033583105}
2022-12-05 23:39:48,981 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:48,981 INFO:     Epoch: 21
2022-12-05 23:39:49,689 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5190030217848041, 'Total loss': 0.5190030217848041} | train loss {'Reaction outcome loss': 0.5511439496930312, 'Total loss': 0.5511439496930312}
2022-12-05 23:39:49,690 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:49,690 INFO:     Epoch: 22
2022-12-05 23:39:50,398 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5351272709667683, 'Total loss': 0.5351272709667683} | train loss {'Reaction outcome loss': 0.5463514483650687, 'Total loss': 0.5463514483650687}
2022-12-05 23:39:50,398 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:50,398 INFO:     Epoch: 23
2022-12-05 23:39:51,107 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.517169672657143, 'Total loss': 0.517169672657143} | train loss {'Reaction outcome loss': 0.5398255654606923, 'Total loss': 0.5398255654606923}
2022-12-05 23:39:51,108 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:51,108 INFO:     Epoch: 24
2022-12-05 23:39:51,819 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4849619608033787, 'Total loss': 0.4849619608033787} | train loss {'Reaction outcome loss': 0.5418348989264685, 'Total loss': 0.5418348989264685}
2022-12-05 23:39:51,819 INFO:     Found new best model at epoch 24
2022-12-05 23:39:51,820 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:51,820 INFO:     Epoch: 25
2022-12-05 23:39:52,535 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4976039549166506, 'Total loss': 0.4976039549166506} | train loss {'Reaction outcome loss': 0.5415697319787524, 'Total loss': 0.5415697319787524}
2022-12-05 23:39:52,535 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:52,535 INFO:     Epoch: 26
2022-12-05 23:39:53,251 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5127404013817961, 'Total loss': 0.5127404013817961} | train loss {'Reaction outcome loss': 0.5361001646063226, 'Total loss': 0.5361001646063226}
2022-12-05 23:39:53,251 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:53,251 INFO:     Epoch: 27
2022-12-05 23:39:53,960 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5508556393059817, 'Total loss': 0.5508556393059817} | train loss {'Reaction outcome loss': 0.5392819045767611, 'Total loss': 0.5392819045767611}
2022-12-05 23:39:53,960 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:53,961 INFO:     Epoch: 28
2022-12-05 23:39:54,676 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5659974952313033, 'Total loss': 0.5659974952313033} | train loss {'Reaction outcome loss': 0.5531375104116525, 'Total loss': 0.5531375104116525}
2022-12-05 23:39:54,676 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:54,676 INFO:     Epoch: 29
2022-12-05 23:39:55,387 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49517208557914605, 'Total loss': 0.49517208557914605} | train loss {'Reaction outcome loss': 0.5578568544434873, 'Total loss': 0.5578568544434873}
2022-12-05 23:39:55,387 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:55,387 INFO:     Epoch: 30
2022-12-05 23:39:56,101 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5156516900116747, 'Total loss': 0.5156516900116747} | train loss {'Reaction outcome loss': 0.5429670977583418, 'Total loss': 0.5429670977583418}
2022-12-05 23:39:56,101 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:56,101 INFO:     Epoch: 31
2022-12-05 23:39:56,816 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.529417676681822, 'Total loss': 0.529417676681822} | train loss {'Reaction outcome loss': 0.5339605699440366, 'Total loss': 0.5339605699440366}
2022-12-05 23:39:56,816 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:56,816 INFO:     Epoch: 32
2022-12-05 23:39:57,528 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5046251294287768, 'Total loss': 0.5046251294287768} | train loss {'Reaction outcome loss': 0.5391820936429839, 'Total loss': 0.5391820936429839}
2022-12-05 23:39:57,528 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:57,528 INFO:     Epoch: 33
2022-12-05 23:39:58,239 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5672852004116232, 'Total loss': 0.5672852004116232} | train loss {'Reaction outcome loss': 0.5323477744573524, 'Total loss': 0.5323477744573524}
2022-12-05 23:39:58,239 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:58,239 INFO:     Epoch: 34
2022-12-05 23:39:58,949 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5776172690093517, 'Total loss': 0.5776172690093517} | train loss {'Reaction outcome loss': 0.5401867490812291, 'Total loss': 0.5401867490812291}
2022-12-05 23:39:58,949 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:58,949 INFO:     Epoch: 35
2022-12-05 23:39:59,659 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48638189787214453, 'Total loss': 0.48638189787214453} | train loss {'Reaction outcome loss': 0.5342375651937024, 'Total loss': 0.5342375651937024}
2022-12-05 23:39:59,660 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:39:59,660 INFO:     Epoch: 36
2022-12-05 23:40:00,372 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5238735249096697, 'Total loss': 0.5238735249096697} | train loss {'Reaction outcome loss': 0.5360240686066479, 'Total loss': 0.5360240686066479}
2022-12-05 23:40:00,372 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:00,372 INFO:     Epoch: 37
2022-12-05 23:40:01,084 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4802739972418005, 'Total loss': 0.4802739972418005} | train loss {'Reaction outcome loss': 0.5331087717296261, 'Total loss': 0.5331087717296261}
2022-12-05 23:40:01,084 INFO:     Found new best model at epoch 37
2022-12-05 23:40:01,085 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:01,085 INFO:     Epoch: 38
2022-12-05 23:40:01,797 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5239346548914909, 'Total loss': 0.5239346548914909} | train loss {'Reaction outcome loss': 0.5358957044991405, 'Total loss': 0.5358957044991405}
2022-12-05 23:40:01,797 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:01,797 INFO:     Epoch: 39
2022-12-05 23:40:02,508 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5331925174052065, 'Total loss': 0.5331925174052065} | train loss {'Reaction outcome loss': 0.5403302462718748, 'Total loss': 0.5403302462718748}
2022-12-05 23:40:02,508 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:02,508 INFO:     Epoch: 40
2022-12-05 23:40:03,218 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.516660406508229, 'Total loss': 0.516660406508229} | train loss {'Reaction outcome loss': 0.5430505591848118, 'Total loss': 0.5430505591848118}
2022-12-05 23:40:03,218 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:03,218 INFO:     Epoch: 41
2022-12-05 23:40:03,928 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.48090431873093953, 'Total loss': 0.48090431873093953} | train loss {'Reaction outcome loss': 0.5374653497446886, 'Total loss': 0.5374653497446886}
2022-12-05 23:40:03,929 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:03,929 INFO:     Epoch: 42
2022-12-05 23:40:04,641 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5040876445445147, 'Total loss': 0.5040876445445147} | train loss {'Reaction outcome loss': 0.5363966724288608, 'Total loss': 0.5363966724288608}
2022-12-05 23:40:04,641 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:04,642 INFO:     Epoch: 43
2022-12-05 23:40:05,360 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4987764554944905, 'Total loss': 0.4987764554944905} | train loss {'Reaction outcome loss': 0.5445209339049905, 'Total loss': 0.5445209339049905}
2022-12-05 23:40:05,360 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:05,360 INFO:     Epoch: 44
2022-12-05 23:40:06,072 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5068686919456179, 'Total loss': 0.5068686919456179} | train loss {'Reaction outcome loss': 0.5309617615301117, 'Total loss': 0.5309617615301117}
2022-12-05 23:40:06,072 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:06,072 INFO:     Epoch: 45
2022-12-05 23:40:06,786 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49451988664540375, 'Total loss': 0.49451988664540375} | train loss {'Reaction outcome loss': 0.5270452935565338, 'Total loss': 0.5270452935565338}
2022-12-05 23:40:06,786 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:06,787 INFO:     Epoch: 46
2022-12-05 23:40:07,498 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4766041880304163, 'Total loss': 0.4766041880304163} | train loss {'Reaction outcome loss': 0.525281731484209, 'Total loss': 0.525281731484209}
2022-12-05 23:40:07,499 INFO:     Found new best model at epoch 46
2022-12-05 23:40:07,499 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:07,499 INFO:     Epoch: 47
2022-12-05 23:40:08,214 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5774521624500101, 'Total loss': 0.5774521624500101} | train loss {'Reaction outcome loss': 0.5253228743368314, 'Total loss': 0.5253228743368314}
2022-12-05 23:40:08,215 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:08,215 INFO:     Epoch: 48
2022-12-05 23:40:08,925 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.6178506578911435, 'Total loss': 0.6178506578911435} | train loss {'Reaction outcome loss': 0.5298047713060611, 'Total loss': 0.5298047713060611}
2022-12-05 23:40:08,925 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:08,925 INFO:     Epoch: 49
2022-12-05 23:40:09,639 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4717095477337187, 'Total loss': 0.4717095477337187} | train loss {'Reaction outcome loss': 0.5409465891870893, 'Total loss': 0.5409465891870893}
2022-12-05 23:40:09,639 INFO:     Found new best model at epoch 49
2022-12-05 23:40:09,640 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:09,640 INFO:     Epoch: 50
2022-12-05 23:40:10,351 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.48374712467193604, 'Total loss': 0.48374712467193604} | train loss {'Reaction outcome loss': 0.5204114064803773, 'Total loss': 0.5204114064803773}
2022-12-05 23:40:10,351 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:10,351 INFO:     Epoch: 51
2022-12-05 23:40:11,062 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5443455658175729, 'Total loss': 0.5443455658175729} | train loss {'Reaction outcome loss': 0.5317031529388929, 'Total loss': 0.5317031529388929}
2022-12-05 23:40:11,062 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:11,062 INFO:     Epoch: 52
2022-12-05 23:40:11,779 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.518478453497995, 'Total loss': 0.518478453497995} | train loss {'Reaction outcome loss': 0.5306069920450328, 'Total loss': 0.5306069920450328}
2022-12-05 23:40:11,779 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:11,779 INFO:     Epoch: 53
2022-12-05 23:40:12,493 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4974805143746463, 'Total loss': 0.4974805143746463} | train loss {'Reaction outcome loss': 0.5203974905766939, 'Total loss': 0.5203974905766939}
2022-12-05 23:40:12,494 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:12,494 INFO:     Epoch: 54
2022-12-05 23:40:13,203 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4935104189948602, 'Total loss': 0.4935104189948602} | train loss {'Reaction outcome loss': 0.5189331768736666, 'Total loss': 0.5189331768736666}
2022-12-05 23:40:13,203 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:13,203 INFO:     Epoch: 55
2022-12-05 23:40:13,912 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.48220927437598055, 'Total loss': 0.48220927437598055} | train loss {'Reaction outcome loss': 0.5251102018573506, 'Total loss': 0.5251102018573506}
2022-12-05 23:40:13,913 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:13,913 INFO:     Epoch: 56
2022-12-05 23:40:14,623 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5192587748169899, 'Total loss': 0.5192587748169899} | train loss {'Reaction outcome loss': 0.5276440468273664, 'Total loss': 0.5276440468273664}
2022-12-05 23:40:14,623 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:14,623 INFO:     Epoch: 57
2022-12-05 23:40:15,334 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5079323080453005, 'Total loss': 0.5079323080453005} | train loss {'Reaction outcome loss': 0.5378667137883453, 'Total loss': 0.5378667137883453}
2022-12-05 23:40:15,334 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:15,334 INFO:     Epoch: 58
2022-12-05 23:40:16,047 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4937782551754605, 'Total loss': 0.4937782551754605} | train loss {'Reaction outcome loss': 0.5346238420567351, 'Total loss': 0.5346238420567351}
2022-12-05 23:40:16,047 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:16,048 INFO:     Epoch: 59
2022-12-05 23:40:16,758 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5117396973073483, 'Total loss': 0.5117396973073483} | train loss {'Reaction outcome loss': 0.5144611761951442, 'Total loss': 0.5144611761951442}
2022-12-05 23:40:16,758 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:16,758 INFO:     Epoch: 60
2022-12-05 23:40:17,467 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5041982406242327, 'Total loss': 0.5041982406242327} | train loss {'Reaction outcome loss': 0.5360695463925721, 'Total loss': 0.5360695463925721}
2022-12-05 23:40:17,467 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:17,468 INFO:     Epoch: 61
2022-12-05 23:40:18,181 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4703765938227827, 'Total loss': 0.4703765938227827} | train loss {'Reaction outcome loss': 0.5314650836623149, 'Total loss': 0.5314650836623149}
2022-12-05 23:40:18,181 INFO:     Found new best model at epoch 61
2022-12-05 23:40:18,182 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:18,182 INFO:     Epoch: 62
2022-12-05 23:40:18,895 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4994063204662366, 'Total loss': 0.4994063204662366} | train loss {'Reaction outcome loss': 0.5241900193184493, 'Total loss': 0.5241900193184493}
2022-12-05 23:40:18,895 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:18,895 INFO:     Epoch: 63
2022-12-05 23:40:19,610 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49450764737345954, 'Total loss': 0.49450764737345954} | train loss {'Reaction outcome loss': 0.5235512139584854, 'Total loss': 0.5235512139584854}
2022-12-05 23:40:19,610 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:19,610 INFO:     Epoch: 64
2022-12-05 23:40:20,322 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5200513120401989, 'Total loss': 0.5200513120401989} | train loss {'Reaction outcome loss': 0.5254805665010744, 'Total loss': 0.5254805665010744}
2022-12-05 23:40:20,322 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:20,322 INFO:     Epoch: 65
2022-12-05 23:40:21,036 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5076287148351019, 'Total loss': 0.5076287148351019} | train loss {'Reaction outcome loss': 0.5294160962496933, 'Total loss': 0.5294160962496933}
2022-12-05 23:40:21,037 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:21,037 INFO:     Epoch: 66
2022-12-05 23:40:21,747 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5117535516619682, 'Total loss': 0.5117535516619682} | train loss {'Reaction outcome loss': 0.5229481128666565, 'Total loss': 0.5229481128666565}
2022-12-05 23:40:21,747 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:21,747 INFO:     Epoch: 67
2022-12-05 23:40:22,461 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5144743580709804, 'Total loss': 0.5144743580709804} | train loss {'Reaction outcome loss': 0.5274324670041862, 'Total loss': 0.5274324670041862}
2022-12-05 23:40:22,461 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:22,461 INFO:     Epoch: 68
2022-12-05 23:40:23,172 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49658481776714325, 'Total loss': 0.49658481776714325} | train loss {'Reaction outcome loss': 0.5230390837318019, 'Total loss': 0.5230390837318019}
2022-12-05 23:40:23,172 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:23,172 INFO:     Epoch: 69
2022-12-05 23:40:23,883 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4728980978781527, 'Total loss': 0.4728980978781527} | train loss {'Reaction outcome loss': 0.5297681625314087, 'Total loss': 0.5297681625314087}
2022-12-05 23:40:23,883 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:23,883 INFO:     Epoch: 70
2022-12-05 23:40:24,595 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4940944882956418, 'Total loss': 0.4940944882956418} | train loss {'Reaction outcome loss': 0.5225386280521207, 'Total loss': 0.5225386280521207}
2022-12-05 23:40:24,595 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:24,595 INFO:     Epoch: 71
2022-12-05 23:40:25,306 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5307864367284558, 'Total loss': 0.5307864367284558} | train loss {'Reaction outcome loss': 0.5349558042852502, 'Total loss': 0.5349558042852502}
2022-12-05 23:40:25,306 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:25,306 INFO:     Epoch: 72
2022-12-05 23:40:26,015 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.47641167349436064, 'Total loss': 0.47641167349436064} | train loss {'Reaction outcome loss': 0.5372158702885211, 'Total loss': 0.5372158702885211}
2022-12-05 23:40:26,015 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:26,015 INFO:     Epoch: 73
2022-12-05 23:40:26,724 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46474484354257584, 'Total loss': 0.46474484354257584} | train loss {'Reaction outcome loss': 0.5203837766557148, 'Total loss': 0.5203837766557148}
2022-12-05 23:40:26,724 INFO:     Found new best model at epoch 73
2022-12-05 23:40:26,725 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:26,725 INFO:     Epoch: 74
2022-12-05 23:40:27,433 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5191101990640163, 'Total loss': 0.5191101990640163} | train loss {'Reaction outcome loss': 0.524839776126962, 'Total loss': 0.524839776126962}
2022-12-05 23:40:27,433 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:27,433 INFO:     Epoch: 75
2022-12-05 23:40:28,142 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5256157253276218, 'Total loss': 0.5256157253276218} | train loss {'Reaction outcome loss': 0.5273900181055069, 'Total loss': 0.5273900181055069}
2022-12-05 23:40:28,142 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:28,142 INFO:     Epoch: 76
2022-12-05 23:40:28,854 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5105423246594992, 'Total loss': 0.5105423246594992} | train loss {'Reaction outcome loss': 0.5323731947825988, 'Total loss': 0.5323731947825988}
2022-12-05 23:40:28,854 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:28,854 INFO:     Epoch: 77
2022-12-05 23:40:29,566 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5033430602740158, 'Total loss': 0.5033430602740158} | train loss {'Reaction outcome loss': 0.5179845212321532, 'Total loss': 0.5179845212321532}
2022-12-05 23:40:29,566 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:29,566 INFO:     Epoch: 78
2022-12-05 23:40:30,276 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.459670826792717, 'Total loss': 0.459670826792717} | train loss {'Reaction outcome loss': 0.5140132094443086, 'Total loss': 0.5140132094443086}
2022-12-05 23:40:30,276 INFO:     Found new best model at epoch 78
2022-12-05 23:40:30,276 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:30,277 INFO:     Epoch: 79
2022-12-05 23:40:30,986 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4680793583393097, 'Total loss': 0.4680793583393097} | train loss {'Reaction outcome loss': 0.5205429811709323, 'Total loss': 0.5205429811709323}
2022-12-05 23:40:30,987 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:30,987 INFO:     Epoch: 80
2022-12-05 23:40:31,695 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4749548516490243, 'Total loss': 0.4749548516490243} | train loss {'Reaction outcome loss': 0.5240560107777718, 'Total loss': 0.5240560107777718}
2022-12-05 23:40:31,695 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:31,695 INFO:     Epoch: 81
2022-12-05 23:40:32,402 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.501422639597546, 'Total loss': 0.501422639597546} | train loss {'Reaction outcome loss': 0.5198323989686696, 'Total loss': 0.5198323989686696}
2022-12-05 23:40:32,402 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:32,402 INFO:     Epoch: 82
2022-12-05 23:40:33,111 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4801046194678003, 'Total loss': 0.4801046194678003} | train loss {'Reaction outcome loss': 0.5207883774148307, 'Total loss': 0.5207883774148307}
2022-12-05 23:40:33,111 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:33,111 INFO:     Epoch: 83
2022-12-05 23:40:33,822 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.47277985547076573, 'Total loss': 0.47277985547076573} | train loss {'Reaction outcome loss': 0.5250262122163888, 'Total loss': 0.5250262122163888}
2022-12-05 23:40:33,822 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:33,822 INFO:     Epoch: 84
2022-12-05 23:40:34,530 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49820471521128307, 'Total loss': 0.49820471521128307} | train loss {'Reaction outcome loss': 0.52258023311976, 'Total loss': 0.52258023311976}
2022-12-05 23:40:34,530 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:34,531 INFO:     Epoch: 85
2022-12-05 23:40:35,240 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47841106389056554, 'Total loss': 0.47841106389056554} | train loss {'Reaction outcome loss': 0.5175153899651307, 'Total loss': 0.5175153899651307}
2022-12-05 23:40:35,240 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:35,240 INFO:     Epoch: 86
2022-12-05 23:40:35,948 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.46940984441475436, 'Total loss': 0.46940984441475436} | train loss {'Reaction outcome loss': 0.5217773919163445, 'Total loss': 0.5217773919163445}
2022-12-05 23:40:35,948 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:35,948 INFO:     Epoch: 87
2022-12-05 23:40:36,655 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4989472546360709, 'Total loss': 0.4989472546360709} | train loss {'Reaction outcome loss': 0.5366950959329181, 'Total loss': 0.5366950959329181}
2022-12-05 23:40:36,655 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:36,655 INFO:     Epoch: 88
2022-12-05 23:40:37,361 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4799583364616741, 'Total loss': 0.4799583364616741} | train loss {'Reaction outcome loss': 0.5266823748405646, 'Total loss': 0.5266823748405646}
2022-12-05 23:40:37,361 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:37,361 INFO:     Epoch: 89
2022-12-05 23:40:38,068 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49561888487501576, 'Total loss': 0.49561888487501576} | train loss {'Reaction outcome loss': 0.5198301996900002, 'Total loss': 0.5198301996900002}
2022-12-05 23:40:38,068 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:38,068 INFO:     Epoch: 90
2022-12-05 23:40:38,776 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4877600520849228, 'Total loss': 0.4877600520849228} | train loss {'Reaction outcome loss': 0.5282842867860669, 'Total loss': 0.5282842867860669}
2022-12-05 23:40:38,776 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:38,776 INFO:     Epoch: 91
2022-12-05 23:40:39,487 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4772574400359934, 'Total loss': 0.4772574400359934} | train loss {'Reaction outcome loss': 0.5210919846791909, 'Total loss': 0.5210919846791909}
2022-12-05 23:40:39,487 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:39,487 INFO:     Epoch: 92
2022-12-05 23:40:40,195 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5068040798333558, 'Total loss': 0.5068040798333558} | train loss {'Reaction outcome loss': 0.522971138961402, 'Total loss': 0.522971138961402}
2022-12-05 23:40:40,195 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:40,195 INFO:     Epoch: 93
2022-12-05 23:40:40,904 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47357331825928256, 'Total loss': 0.47357331825928256} | train loss {'Reaction outcome loss': 0.522675818578917, 'Total loss': 0.522675818578917}
2022-12-05 23:40:40,904 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:40,904 INFO:     Epoch: 94
2022-12-05 23:40:41,614 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4923044246706096, 'Total loss': 0.4923044246706096} | train loss {'Reaction outcome loss': 0.5215533043932818, 'Total loss': 0.5215533043932818}
2022-12-05 23:40:41,614 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:41,614 INFO:     Epoch: 95
2022-12-05 23:40:42,321 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4616271514784206, 'Total loss': 0.4616271514784206} | train loss {'Reaction outcome loss': 0.5432117354532002, 'Total loss': 0.5432117354532002}
2022-12-05 23:40:42,321 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:42,322 INFO:     Epoch: 96
2022-12-05 23:40:43,029 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47672783346338704, 'Total loss': 0.47672783346338704} | train loss {'Reaction outcome loss': 0.5197181635963267, 'Total loss': 0.5197181635963267}
2022-12-05 23:40:43,029 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:43,029 INFO:     Epoch: 97
2022-12-05 23:40:43,735 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5223943956873633, 'Total loss': 0.5223943956873633} | train loss {'Reaction outcome loss': 0.5170907793257401, 'Total loss': 0.5170907793257401}
2022-12-05 23:40:43,736 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:43,736 INFO:     Epoch: 98
2022-12-05 23:40:44,443 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5189679515632716, 'Total loss': 0.5189679515632716} | train loss {'Reaction outcome loss': 0.5167177560237738, 'Total loss': 0.5167177560237738}
2022-12-05 23:40:44,443 INFO:     Current learning rate [0.001491528877467142]
2022-12-05 23:40:44,443 INFO:     Epoch: 99
2022-12-05 23:40:45,150 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.52957359328866, 'Total loss': 0.52957359328866} | train loss {'Reaction outcome loss': 0.52042566318261, 'Total loss': 0.52042566318261}
2022-12-05 23:40:45,150 INFO:     Best model found after epoch 79 of 100.
2022-12-05 23:40:45,150 INFO:   Done with stage: TRAINING
2022-12-05 23:40:45,150 INFO:   Starting stage: EVALUATION
2022-12-05 23:40:45,275 INFO:   Done with stage: EVALUATION
2022-12-05 23:40:45,275 INFO: Done with stage: RUNNING SPLITS
2022-12-05 23:40:45,275 INFO: Starting stage: COMPUTE METRICS
2022-12-05 23:40:46,447 INFO: Done with stage: COMPUTE METRICS
2022-12-05 23:40:46,447 INFO: Starting stage: EXPORT RESULTS
2022-12-05 23:40:46,464 INFO:   Final results averaged over 50 folds: 
2022-12-05 23:40:46,468 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.201193           NaN  0.326086       NaN
2022-12-05 23:40:48,123 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-05 23:40:48,128 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-05 23:40:48,130 DEBUG:   interactive is False
2022-12-05 23:40:48,130 DEBUG:   platform is linux
2022-12-05 23:40:48,130 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-05 23:40:48,300 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-05 23:40:48,302 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-05 23:40:48,741 DEBUG:   Loaded backend agg version unknown.
2022-12-05 23:40:48,743 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 23:40:48,743 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,743 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,744 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,745 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 23:40:48,746 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,746 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 23:40:48,783 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,783 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,784 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,785 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 23:40:48,786 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,786 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 23:40:48,794 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-05 23:40:48,794 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,794 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,794 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,794 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,794 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,794 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-05 23:40:48,795 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-05 23:40:48,796 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-05 23:40:48,797 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,797 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,797 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-05 23:40:48,797 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-05 23:40:48,797 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-05 23:40:48,797 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-05 23:40:49,142 INFO: Done with stage: EXPORT RESULTS
2022-12-05 23:40:49,142 INFO: Starting stage: SAVE MODEL
2022-12-05 23:40:49,215 INFO: Done with stage: SAVE MODEL
2022-12-05 23:40:49,215 INFO: Wall time for program:  3587.43 seconds
