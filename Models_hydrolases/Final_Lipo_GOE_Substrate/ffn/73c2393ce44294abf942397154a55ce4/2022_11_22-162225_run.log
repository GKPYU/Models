2022-11-23 01:42:52,653 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/73c2393ce44294abf942397154a55ce4/2022_11_22-162225",
  "seed": 3,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "cat",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-23 01:42:52,664 INFO: Starting stage: BUILD FEATURIZERS
2022-11-23 01:42:52,667 INFO:   Creating esm representation model
2022-11-23 01:42:52,667 INFO:   Done esm representation model
2022-11-23 01:42:52,667 INFO: Done with stage: BUILD FEATURIZERS
2022-11-23 01:42:52,667 INFO: Starting stage: BUILDING DATASET
2022-11-23 01:42:52,738 INFO: Done with stage: BUILDING DATASET
2022-11-23 01:42:52,739 INFO: Starting stage: FEATURIZING DATA
2022-11-23 01:42:52,739 INFO:   Featurizing proteins
2022-11-23 01:42:52,741 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-23 01:42:52,759 INFO:   Loaded feature cache of size 204
2022-11-23 01:42:52,761 INFO:   Starting to pool ESM Embeddings
2022-11-23 01:42:52,853 INFO:   Featurizing molecules
2022-11-23 01:42:53,241 INFO: Done with stage: FEATURIZING DATA
2022-11-23 01:42:53,241 INFO: Starting stage: RUNNING SPLITS
2022-11-23 01:42:53,250 INFO:   Leaving out SEQ value Fold_0
2022-11-23 01:42:53,265 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 01:42:53,265 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:42:53,977 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:42:53,977 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:42:54,050 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:42:54,050 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:42:54,050 INFO:     No hyperparam tuning for this model
2022-11-23 01:42:54,050 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:42:54,050 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:42:54,051 INFO:     None feature selector for col prot
2022-11-23 01:42:54,051 INFO:     None feature selector for col prot
2022-11-23 01:42:54,052 INFO:     None feature selector for col prot
2022-11-23 01:42:54,052 INFO:     None feature selector for col chem
2022-11-23 01:42:54,052 INFO:     None feature selector for col chem
2022-11-23 01:42:54,052 INFO:     None feature selector for col chem
2022-11-23 01:42:54,052 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:42:54,052 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:42:54,054 INFO:     Number of params in model 168571
2022-11-23 01:42:54,054 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:42:54,054 INFO:   Starting stage: TRAINING
2022-11-23 01:42:55,752 INFO:     Val loss before train {'Reaction outcome loss': 1.0407376233921495, 'Total loss': 1.0407376233921495}
2022-11-23 01:42:55,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:55,753 INFO:     Epoch: 0
2022-11-23 01:42:56,603 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8925058037735695, 'Total loss': 0.8925058037735695} | train loss {'Reaction outcome loss': 0.8586886782870918, 'Total loss': 0.8586886782870918}
2022-11-23 01:42:56,603 INFO:     Found new best model at epoch 0
2022-11-23 01:42:56,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:56,604 INFO:     Epoch: 1
2022-11-23 01:42:57,404 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8841267214264981, 'Total loss': 0.8841267214264981} | train loss {'Reaction outcome loss': 0.8318836425171524, 'Total loss': 0.8318836425171524}
2022-11-23 01:42:57,404 INFO:     Found new best model at epoch 1
2022-11-23 01:42:57,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:57,405 INFO:     Epoch: 2
2022-11-23 01:42:58,248 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8882524683031925, 'Total loss': 0.8882524683031925} | train loss {'Reaction outcome loss': 0.822917604055561, 'Total loss': 0.822917604055561}
2022-11-23 01:42:58,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:58,248 INFO:     Epoch: 3
2022-11-23 01:42:59,055 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8935310902983643, 'Total loss': 0.8935310902983643} | train loss {'Reaction outcome loss': 0.8156568541145716, 'Total loss': 0.8156568541145716}
2022-11-23 01:42:59,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:59,056 INFO:     Epoch: 4
2022-11-23 01:42:59,892 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9087349758591763, 'Total loss': 0.9087349758591763} | train loss {'Reaction outcome loss': 0.8122360118832744, 'Total loss': 0.8122360118832744}
2022-11-23 01:42:59,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:59,892 INFO:     Epoch: 5
2022-11-23 01:43:00,700 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8681256590887557, 'Total loss': 0.8681256590887557} | train loss {'Reaction outcome loss': 0.8135429347147707, 'Total loss': 0.8135429347147707}
2022-11-23 01:43:00,700 INFO:     Found new best model at epoch 5
2022-11-23 01:43:00,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:00,701 INFO:     Epoch: 6
2022-11-23 01:43:01,544 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8651487189669942, 'Total loss': 0.8651487189669942} | train loss {'Reaction outcome loss': 0.8034861575140327, 'Total loss': 0.8034861575140327}
2022-11-23 01:43:01,544 INFO:     Found new best model at epoch 6
2022-11-23 01:43:01,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:01,545 INFO:     Epoch: 7
2022-11-23 01:43:02,392 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.872315623039423, 'Total loss': 0.872315623039423} | train loss {'Reaction outcome loss': 0.8031884684670166, 'Total loss': 0.8031884684670166}
2022-11-23 01:43:02,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:02,393 INFO:     Epoch: 8
2022-11-23 01:43:03,231 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8590884222540744, 'Total loss': 0.8590884222540744} | train loss {'Reaction outcome loss': 0.8132515718213847, 'Total loss': 0.8132515718213847}
2022-11-23 01:43:03,231 INFO:     Found new best model at epoch 8
2022-11-23 01:43:03,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:03,232 INFO:     Epoch: 9
2022-11-23 01:43:04,089 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8657511140024939, 'Total loss': 0.8657511140024939} | train loss {'Reaction outcome loss': 0.8045598263623285, 'Total loss': 0.8045598263623285}
2022-11-23 01:43:04,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:04,089 INFO:     Epoch: 10
2022-11-23 01:43:04,884 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8698756209639615, 'Total loss': 0.8698756209639615} | train loss {'Reaction outcome loss': 0.8009998259730027, 'Total loss': 0.8009998259730027}
2022-11-23 01:43:04,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:04,884 INFO:     Epoch: 11
2022-11-23 01:43:05,646 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8698722997377085, 'Total loss': 0.8698722997377085} | train loss {'Reaction outcome loss': 0.8015227689117682, 'Total loss': 0.8015227689117682}
2022-11-23 01:43:05,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:05,646 INFO:     Epoch: 12
2022-11-23 01:43:06,484 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8509928057360094, 'Total loss': 0.8509928057360094} | train loss {'Reaction outcome loss': 0.7997443846991805, 'Total loss': 0.7997443846991805}
2022-11-23 01:43:06,484 INFO:     Found new best model at epoch 12
2022-11-23 01:43:06,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:06,485 INFO:     Epoch: 13
2022-11-23 01:43:07,286 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8564632257749868, 'Total loss': 0.8564632257749868} | train loss {'Reaction outcome loss': 0.7995443561526595, 'Total loss': 0.7995443561526595}
2022-11-23 01:43:07,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:07,286 INFO:     Epoch: 14
2022-11-23 01:43:08,077 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8753989837890448, 'Total loss': 0.8753989837890448} | train loss {'Reaction outcome loss': 0.7977588025272869, 'Total loss': 0.7977588025272869}
2022-11-23 01:43:08,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:08,078 INFO:     Epoch: 15
2022-11-23 01:43:08,852 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8567335529382839, 'Total loss': 0.8567335529382839} | train loss {'Reaction outcome loss': 0.8007585462488112, 'Total loss': 0.8007585462488112}
2022-11-23 01:43:08,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:08,852 INFO:     Epoch: 16
2022-11-23 01:43:09,601 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8548782460911329, 'Total loss': 0.8548782460911329} | train loss {'Reaction outcome loss': 0.7959547401940237, 'Total loss': 0.7959547401940237}
2022-11-23 01:43:09,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:09,602 INFO:     Epoch: 17
2022-11-23 01:43:10,394 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8486870665882909, 'Total loss': 0.8486870665882909} | train loss {'Reaction outcome loss': 0.7948732979473521, 'Total loss': 0.7948732979473521}
2022-11-23 01:43:10,395 INFO:     Found new best model at epoch 17
2022-11-23 01:43:10,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:10,395 INFO:     Epoch: 18
2022-11-23 01:43:11,235 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8475354119788768, 'Total loss': 0.8475354119788768} | train loss {'Reaction outcome loss': 0.7945792926628081, 'Total loss': 0.7945792926628081}
2022-11-23 01:43:11,235 INFO:     Found new best model at epoch 18
2022-11-23 01:43:11,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:11,236 INFO:     Epoch: 19
2022-11-23 01:43:12,043 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8559569674868917, 'Total loss': 0.8559569674868917} | train loss {'Reaction outcome loss': 0.7942011241541534, 'Total loss': 0.7942011241541534}
2022-11-23 01:43:12,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:12,043 INFO:     Epoch: 20
2022-11-23 01:43:12,814 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8663538417150808, 'Total loss': 0.8663538417150808} | train loss {'Reaction outcome loss': 0.7931423773531054, 'Total loss': 0.7931423773531054}
2022-11-23 01:43:12,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:12,814 INFO:     Epoch: 21
2022-11-23 01:43:13,618 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.857722211715787, 'Total loss': 0.857722211715787} | train loss {'Reaction outcome loss': 0.799886350382547, 'Total loss': 0.799886350382547}
2022-11-23 01:43:13,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:13,618 INFO:     Epoch: 22
2022-11-23 01:43:14,373 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8575062197308208, 'Total loss': 0.8575062197308208} | train loss {'Reaction outcome loss': 0.7970198510123081, 'Total loss': 0.7970198510123081}
2022-11-23 01:43:14,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:14,373 INFO:     Epoch: 23
2022-11-23 01:43:15,142 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.860985281855561, 'Total loss': 0.860985281855561} | train loss {'Reaction outcome loss': 0.7990840717417295, 'Total loss': 0.7990840717417295}
2022-11-23 01:43:15,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:15,143 INFO:     Epoch: 24
2022-11-23 01:43:15,911 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8436705012654149, 'Total loss': 0.8436705012654149} | train loss {'Reaction outcome loss': 0.7970469743013382, 'Total loss': 0.7970469743013382}
2022-11-23 01:43:15,911 INFO:     Found new best model at epoch 24
2022-11-23 01:43:15,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:15,912 INFO:     Epoch: 25
2022-11-23 01:43:16,716 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8461860044057979, 'Total loss': 0.8461860044057979} | train loss {'Reaction outcome loss': 0.794194750976367, 'Total loss': 0.794194750976367}
2022-11-23 01:43:16,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:16,717 INFO:     Epoch: 26
2022-11-23 01:43:17,528 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8474687310152276, 'Total loss': 0.8474687310152276} | train loss {'Reaction outcome loss': 0.7895710214239652, 'Total loss': 0.7895710214239652}
2022-11-23 01:43:17,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:17,529 INFO:     Epoch: 27
2022-11-23 01:43:18,298 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8569522292114967, 'Total loss': 0.8569522292114967} | train loss {'Reaction outcome loss': 0.7939143205275301, 'Total loss': 0.7939143205275301}
2022-11-23 01:43:18,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:18,299 INFO:     Epoch: 28
2022-11-23 01:43:19,148 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8495365935702657, 'Total loss': 0.8495365935702657} | train loss {'Reaction outcome loss': 0.7978555103305911, 'Total loss': 0.7978555103305911}
2022-11-23 01:43:19,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:19,148 INFO:     Epoch: 29
2022-11-23 01:43:19,987 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8476407860600671, 'Total loss': 0.8476407860600671} | train loss {'Reaction outcome loss': 0.7916262143703757, 'Total loss': 0.7916262143703757}
2022-11-23 01:43:19,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:19,987 INFO:     Epoch: 30
2022-11-23 01:43:20,743 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8387802894725356, 'Total loss': 0.8387802894725356} | train loss {'Reaction outcome loss': 0.7922881894180032, 'Total loss': 0.7922881894180032}
2022-11-23 01:43:20,743 INFO:     Found new best model at epoch 30
2022-11-23 01:43:20,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:20,744 INFO:     Epoch: 31
2022-11-23 01:43:21,546 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8503184568050296, 'Total loss': 0.8503184568050296} | train loss {'Reaction outcome loss': 0.7922339588403702, 'Total loss': 0.7922339588403702}
2022-11-23 01:43:21,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:21,546 INFO:     Epoch: 32
2022-11-23 01:43:22,387 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8428634127905202, 'Total loss': 0.8428634127905202} | train loss {'Reaction outcome loss': 0.7973427465948902, 'Total loss': 0.7973427465948902}
2022-11-23 01:43:22,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:22,387 INFO:     Epoch: 33
2022-11-23 01:43:23,218 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8375278967757558, 'Total loss': 0.8375278967757558} | train loss {'Reaction outcome loss': 0.7900044452704367, 'Total loss': 0.7900044452704367}
2022-11-23 01:43:23,218 INFO:     Found new best model at epoch 33
2022-11-23 01:43:23,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:23,219 INFO:     Epoch: 34
2022-11-23 01:43:23,987 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8692855294360671, 'Total loss': 0.8692855294360671} | train loss {'Reaction outcome loss': 0.7944192187707932, 'Total loss': 0.7944192187707932}
2022-11-23 01:43:23,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:23,987 INFO:     Epoch: 35
2022-11-23 01:43:24,735 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.848549255104952, 'Total loss': 0.848549255104952} | train loss {'Reaction outcome loss': 0.7944731410653865, 'Total loss': 0.7944731410653865}
2022-11-23 01:43:24,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:24,735 INFO:     Epoch: 36
2022-11-23 01:43:25,569 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8559241558230201, 'Total loss': 0.8559241558230201} | train loss {'Reaction outcome loss': 0.7927325162731234, 'Total loss': 0.7927325162731234}
2022-11-23 01:43:25,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:25,570 INFO:     Epoch: 37
2022-11-23 01:43:26,359 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8424692791561748, 'Total loss': 0.8424692791561748} | train loss {'Reaction outcome loss': 0.7935836415310376, 'Total loss': 0.7935836415310376}
2022-11-23 01:43:26,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:26,359 INFO:     Epoch: 38
2022-11-23 01:43:27,179 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8516317190125932, 'Total loss': 0.8516317190125932} | train loss {'Reaction outcome loss': 0.7891963633601783, 'Total loss': 0.7891963633601783}
2022-11-23 01:43:27,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:27,180 INFO:     Epoch: 39
2022-11-23 01:43:27,955 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8412646207698556, 'Total loss': 0.8412646207698556} | train loss {'Reaction outcome loss': 0.7982375045291713, 'Total loss': 0.7982375045291713}
2022-11-23 01:43:27,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:27,955 INFO:     Epoch: 40
2022-11-23 01:43:28,773 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8399132005003995, 'Total loss': 0.8399132005003995} | train loss {'Reaction outcome loss': 0.7973072566702718, 'Total loss': 0.7973072566702718}
2022-11-23 01:43:28,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:28,774 INFO:     Epoch: 41
2022-11-23 01:43:29,576 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.840070903301239, 'Total loss': 0.840070903301239} | train loss {'Reaction outcome loss': 0.7904918517489903, 'Total loss': 0.7904918517489903}
2022-11-23 01:43:29,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:29,576 INFO:     Epoch: 42
2022-11-23 01:43:30,401 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8502886004226152, 'Total loss': 0.8502886004226152} | train loss {'Reaction outcome loss': 0.7944752697329052, 'Total loss': 0.7944752697329052}
2022-11-23 01:43:30,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:30,401 INFO:     Epoch: 43
2022-11-23 01:43:31,186 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8474797661914382, 'Total loss': 0.8474797661914382} | train loss {'Reaction outcome loss': 0.792327207131464, 'Total loss': 0.792327207131464}
2022-11-23 01:43:31,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:31,186 INFO:     Epoch: 44
2022-11-23 01:43:31,944 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8582968656406846, 'Total loss': 0.8582968656406846} | train loss {'Reaction outcome loss': 0.7916920197303178, 'Total loss': 0.7916920197303178}
2022-11-23 01:43:31,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:31,944 INFO:     Epoch: 45
2022-11-23 01:43:32,720 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8470337397830431, 'Total loss': 0.8470337397830431} | train loss {'Reaction outcome loss': 0.793680234155694, 'Total loss': 0.793680234155694}
2022-11-23 01:43:32,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:32,720 INFO:     Epoch: 46
2022-11-23 01:43:33,524 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8579813990482065, 'Total loss': 0.8579813990482065} | train loss {'Reaction outcome loss': 0.7894017842949413, 'Total loss': 0.7894017842949413}
2022-11-23 01:43:33,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:33,524 INFO:     Epoch: 47
2022-11-23 01:43:34,303 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8970869488494341, 'Total loss': 0.8970869488494341} | train loss {'Reaction outcome loss': 0.7987423791992859, 'Total loss': 0.7987423791992859}
2022-11-23 01:43:34,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:34,303 INFO:     Epoch: 48
2022-11-23 01:43:35,139 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8430319788844086, 'Total loss': 0.8430319788844086} | train loss {'Reaction outcome loss': 0.7959915750095101, 'Total loss': 0.7959915750095101}
2022-11-23 01:43:35,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:35,140 INFO:     Epoch: 49
2022-11-23 01:43:35,916 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8505899698235267, 'Total loss': 0.8505899698235267} | train loss {'Reaction outcome loss': 0.7951343844904274, 'Total loss': 0.7951343844904274}
2022-11-23 01:43:35,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:35,916 INFO:     Epoch: 50
2022-11-23 01:43:36,697 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8551922281121098, 'Total loss': 0.8551922281121098} | train loss {'Reaction outcome loss': 0.7895786798879748, 'Total loss': 0.7895786798879748}
2022-11-23 01:43:36,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:36,697 INFO:     Epoch: 51
2022-11-23 01:43:37,454 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8694845909296081, 'Total loss': 0.8694845909296081} | train loss {'Reaction outcome loss': 0.7914810738846904, 'Total loss': 0.7914810738846904}
2022-11-23 01:43:37,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:37,454 INFO:     Epoch: 52
2022-11-23 01:43:38,261 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8499132332413696, 'Total loss': 0.8499132332413696} | train loss {'Reaction outcome loss': 0.7950821505462538, 'Total loss': 0.7950821505462538}
2022-11-23 01:43:38,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:38,261 INFO:     Epoch: 53
2022-11-23 01:43:39,073 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8649204511975133, 'Total loss': 0.8649204511975133} | train loss {'Reaction outcome loss': 0.788952401793394, 'Total loss': 0.788952401793394}
2022-11-23 01:43:39,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:39,073 INFO:     Epoch: 54
2022-11-23 01:43:39,873 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8460133394529653, 'Total loss': 0.8460133394529653} | train loss {'Reaction outcome loss': 0.7949113779869236, 'Total loss': 0.7949113779869236}
2022-11-23 01:43:39,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:39,873 INFO:     Epoch: 55
2022-11-23 01:43:40,668 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.86116887663686, 'Total loss': 0.86116887663686} | train loss {'Reaction outcome loss': 0.7934998297056214, 'Total loss': 0.7934998297056214}
2022-11-23 01:43:40,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:40,668 INFO:     Epoch: 56
2022-11-23 01:43:41,421 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8861423398173133, 'Total loss': 0.8861423398173133} | train loss {'Reaction outcome loss': 0.794739486741238, 'Total loss': 0.794739486741238}
2022-11-23 01:43:41,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:41,421 INFO:     Epoch: 57
2022-11-23 01:43:42,198 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.846151027568551, 'Total loss': 0.846151027568551} | train loss {'Reaction outcome loss': 0.7934261715558709, 'Total loss': 0.7934261715558709}
2022-11-23 01:43:42,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:42,198 INFO:     Epoch: 58
2022-11-23 01:43:42,999 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8639330136221509, 'Total loss': 0.8639330136221509} | train loss {'Reaction outcome loss': 0.7914720899501785, 'Total loss': 0.7914720899501785}
2022-11-23 01:43:42,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:42,999 INFO:     Epoch: 59
2022-11-23 01:43:43,835 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8496454843254977, 'Total loss': 0.8496454843254977} | train loss {'Reaction outcome loss': 0.7947582526773703, 'Total loss': 0.7947582526773703}
2022-11-23 01:43:43,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:43,835 INFO:     Epoch: 60
2022-11-23 01:43:44,610 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8444978414579879, 'Total loss': 0.8444978414579879} | train loss {'Reaction outcome loss': 0.79206937844636, 'Total loss': 0.79206937844636}
2022-11-23 01:43:44,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:44,611 INFO:     Epoch: 61
2022-11-23 01:43:45,423 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8425667320573053, 'Total loss': 0.8425667320573053} | train loss {'Reaction outcome loss': 0.7922024706103763, 'Total loss': 0.7922024706103763}
2022-11-23 01:43:45,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:45,423 INFO:     Epoch: 62
2022-11-23 01:43:46,201 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8633331656455994, 'Total loss': 0.8633331656455994} | train loss {'Reaction outcome loss': 0.7908476321179359, 'Total loss': 0.7908476321179359}
2022-11-23 01:43:46,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:46,201 INFO:     Epoch: 63
2022-11-23 01:43:46,989 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8547883643660434, 'Total loss': 0.8547883643660434} | train loss {'Reaction outcome loss': 0.7931852655821159, 'Total loss': 0.7931852655821159}
2022-11-23 01:43:46,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:46,989 INFO:     Epoch: 64
2022-11-23 01:43:47,792 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8487133515435595, 'Total loss': 0.8487133515435595} | train loss {'Reaction outcome loss': 0.7891647095074419, 'Total loss': 0.7891647095074419}
2022-11-23 01:43:47,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:47,794 INFO:     Epoch: 65
2022-11-23 01:43:48,574 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8558794384778932, 'Total loss': 0.8558794384778932} | train loss {'Reaction outcome loss': 0.7937736336569317, 'Total loss': 0.7937736336569317}
2022-11-23 01:43:48,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:48,574 INFO:     Epoch: 66
2022-11-23 01:43:49,380 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8548808014670084, 'Total loss': 0.8548808014670084} | train loss {'Reaction outcome loss': 0.7898565181454674, 'Total loss': 0.7898565181454674}
2022-11-23 01:43:49,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:49,380 INFO:     Epoch: 67
2022-11-23 01:43:50,190 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8435690444569255, 'Total loss': 0.8435690444569255} | train loss {'Reaction outcome loss': 0.7877487233671986, 'Total loss': 0.7877487233671986}
2022-11-23 01:43:50,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:50,191 INFO:     Epoch: 68
2022-11-23 01:43:51,014 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8537705644618633, 'Total loss': 0.8537705644618633} | train loss {'Reaction outcome loss': 0.7939877135098957, 'Total loss': 0.7939877135098957}
2022-11-23 01:43:51,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:51,015 INFO:     Epoch: 69
2022-11-23 01:43:51,804 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8652152044828548, 'Total loss': 0.8652152044828548} | train loss {'Reaction outcome loss': 0.793020772030119, 'Total loss': 0.793020772030119}
2022-11-23 01:43:51,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:51,805 INFO:     Epoch: 70
2022-11-23 01:43:52,604 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8538356936255167, 'Total loss': 0.8538356936255167} | train loss {'Reaction outcome loss': 0.7958801817454275, 'Total loss': 0.7958801817454275}
2022-11-23 01:43:52,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:52,605 INFO:     Epoch: 71
2022-11-23 01:43:53,411 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8529405143371848, 'Total loss': 0.8529405143371848} | train loss {'Reaction outcome loss': 0.793146762080857, 'Total loss': 0.793146762080857}
2022-11-23 01:43:53,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:53,411 INFO:     Epoch: 72
2022-11-23 01:43:54,174 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8507912872835647, 'Total loss': 0.8507912872835647} | train loss {'Reaction outcome loss': 0.7947221653627567, 'Total loss': 0.7947221653627567}
2022-11-23 01:43:54,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:54,174 INFO:     Epoch: 73
2022-11-23 01:43:54,953 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8587094718633697, 'Total loss': 0.8587094718633697} | train loss {'Reaction outcome loss': 0.7899747740049832, 'Total loss': 0.7899747740049832}
2022-11-23 01:43:54,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:54,953 INFO:     Epoch: 74
2022-11-23 01:43:55,732 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8481169689533322, 'Total loss': 0.8481169689533322} | train loss {'Reaction outcome loss': 0.7983722564626913, 'Total loss': 0.7983722564626913}
2022-11-23 01:43:55,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:55,732 INFO:     Epoch: 75
2022-11-23 01:43:56,484 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.849588414957357, 'Total loss': 0.849588414957357} | train loss {'Reaction outcome loss': 0.7927428255559968, 'Total loss': 0.7927428255559968}
2022-11-23 01:43:56,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:56,485 INFO:     Epoch: 76
2022-11-23 01:43:57,285 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8548320809075999, 'Total loss': 0.8548320809075999} | train loss {'Reaction outcome loss': 0.7891410473184507, 'Total loss': 0.7891410473184507}
2022-11-23 01:43:57,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:57,285 INFO:     Epoch: 77
2022-11-23 01:43:58,068 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.84730910700421, 'Total loss': 0.84730910700421} | train loss {'Reaction outcome loss': 0.7887131580319561, 'Total loss': 0.7887131580319561}
2022-11-23 01:43:58,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:58,068 INFO:     Epoch: 78
2022-11-23 01:43:58,836 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8910314690235049, 'Total loss': 0.8910314690235049} | train loss {'Reaction outcome loss': 0.7953831378798015, 'Total loss': 0.7953831378798015}
2022-11-23 01:43:58,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:58,837 INFO:     Epoch: 79
2022-11-23 01:43:59,615 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8488391748694486, 'Total loss': 0.8488391748694486} | train loss {'Reaction outcome loss': 0.7938707676090178, 'Total loss': 0.7938707676090178}
2022-11-23 01:43:59,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:43:59,616 INFO:     Epoch: 80
2022-11-23 01:44:00,434 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8602509845134824, 'Total loss': 0.8602509845134824} | train loss {'Reaction outcome loss': 0.7935558233837612, 'Total loss': 0.7935558233837612}
2022-11-23 01:44:00,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:00,435 INFO:     Epoch: 81
2022-11-23 01:44:01,274 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8595473516819089, 'Total loss': 0.8595473516819089} | train loss {'Reaction outcome loss': 0.7920194918014964, 'Total loss': 0.7920194918014964}
2022-11-23 01:44:01,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:01,274 INFO:     Epoch: 82
2022-11-23 01:44:02,039 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8684875202733416, 'Total loss': 0.8684875202733416} | train loss {'Reaction outcome loss': 0.7905690064195727, 'Total loss': 0.7905690064195727}
2022-11-23 01:44:02,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:02,039 INFO:     Epoch: 83
2022-11-23 01:44:02,817 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.86933497356814, 'Total loss': 0.86933497356814} | train loss {'Reaction outcome loss': 0.7926210064868457, 'Total loss': 0.7926210064868457}
2022-11-23 01:44:02,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:02,817 INFO:     Epoch: 84
2022-11-23 01:44:03,608 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8366228369779365, 'Total loss': 0.8366228369779365} | train loss {'Reaction outcome loss': 0.7914095028746323, 'Total loss': 0.7914095028746323}
2022-11-23 01:44:03,608 INFO:     Found new best model at epoch 84
2022-11-23 01:44:03,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:03,609 INFO:     Epoch: 85
2022-11-23 01:44:04,410 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8927836432013401, 'Total loss': 0.8927836432013401} | train loss {'Reaction outcome loss': 0.788869603246939, 'Total loss': 0.788869603246939}
2022-11-23 01:44:04,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:04,410 INFO:     Epoch: 86
2022-11-23 01:44:05,233 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8410651919453643, 'Total loss': 0.8410651919453643} | train loss {'Reaction outcome loss': 0.7931561397968746, 'Total loss': 0.7931561397968746}
2022-11-23 01:44:05,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:05,233 INFO:     Epoch: 87
2022-11-23 01:44:06,041 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.866628039714902, 'Total loss': 0.866628039714902} | train loss {'Reaction outcome loss': 0.7889360382420118, 'Total loss': 0.7889360382420118}
2022-11-23 01:44:06,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:06,041 INFO:     Epoch: 88
2022-11-23 01:44:06,839 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8448966519777165, 'Total loss': 0.8448966519777165} | train loss {'Reaction outcome loss': 0.7882996652214254, 'Total loss': 0.7882996652214254}
2022-11-23 01:44:06,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:06,840 INFO:     Epoch: 89
2022-11-23 01:44:07,608 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8521644611691319, 'Total loss': 0.8521644611691319} | train loss {'Reaction outcome loss': 0.7893759207647355, 'Total loss': 0.7893759207647355}
2022-11-23 01:44:07,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:07,608 INFO:     Epoch: 90
2022-11-23 01:44:08,389 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8610260542048964, 'Total loss': 0.8610260542048964} | train loss {'Reaction outcome loss': 0.7892241739347333, 'Total loss': 0.7892241739347333}
2022-11-23 01:44:08,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:08,390 INFO:     Epoch: 91
2022-11-23 01:44:09,207 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8523089927296306, 'Total loss': 0.8523089927296306} | train loss {'Reaction outcome loss': 0.7869243045322231, 'Total loss': 0.7869243045322231}
2022-11-23 01:44:09,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:09,207 INFO:     Epoch: 92
2022-11-23 01:44:10,015 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8372331933919773, 'Total loss': 0.8372331933919773} | train loss {'Reaction outcome loss': 0.7893182415454114, 'Total loss': 0.7893182415454114}
2022-11-23 01:44:10,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:10,015 INFO:     Epoch: 93
2022-11-23 01:44:10,782 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8643984711447428, 'Total loss': 0.8643984711447428} | train loss {'Reaction outcome loss': 0.7886662054501596, 'Total loss': 0.7886662054501596}
2022-11-23 01:44:10,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:10,782 INFO:     Epoch: 94
2022-11-23 01:44:11,561 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8637749677480653, 'Total loss': 0.8637749677480653} | train loss {'Reaction outcome loss': 0.79038397161687, 'Total loss': 0.79038397161687}
2022-11-23 01:44:11,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:11,561 INFO:     Epoch: 95
2022-11-23 01:44:12,338 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8428012035613837, 'Total loss': 0.8428012035613837} | train loss {'Reaction outcome loss': 0.7867561405310866, 'Total loss': 0.7867561405310866}
2022-11-23 01:44:12,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:12,338 INFO:     Epoch: 96
2022-11-23 01:44:13,156 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8356828038082567, 'Total loss': 0.8356828038082567} | train loss {'Reaction outcome loss': 0.7846560352405564, 'Total loss': 0.7846560352405564}
2022-11-23 01:44:13,156 INFO:     Found new best model at epoch 96
2022-11-23 01:44:13,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:13,157 INFO:     Epoch: 97
2022-11-23 01:44:13,980 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8500616994015006, 'Total loss': 0.8500616994015006} | train loss {'Reaction outcome loss': 0.7896288979004641, 'Total loss': 0.7896288979004641}
2022-11-23 01:44:13,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:13,980 INFO:     Epoch: 98
2022-11-23 01:44:14,738 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8637083560921425, 'Total loss': 0.8637083560921425} | train loss {'Reaction outcome loss': 0.7855359164417767, 'Total loss': 0.7855359164417767}
2022-11-23 01:44:14,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:14,738 INFO:     Epoch: 99
2022-11-23 01:44:15,530 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8453507756077966, 'Total loss': 0.8453507756077966} | train loss {'Reaction outcome loss': 0.7936356586755299, 'Total loss': 0.7936356586755299}
2022-11-23 01:44:15,530 INFO:     Best model found after epoch 97 of 100.
2022-11-23 01:44:15,531 INFO:   Done with stage: TRAINING
2022-11-23 01:44:15,531 INFO:   Starting stage: EVALUATION
2022-11-23 01:44:15,668 INFO:   Done with stage: EVALUATION
2022-11-23 01:44:15,668 INFO:   Leaving out SEQ value Fold_1
2022-11-23 01:44:15,681 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:44:15,681 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:44:16,356 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:44:16,356 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:44:16,429 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:44:16,429 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:44:16,429 INFO:     No hyperparam tuning for this model
2022-11-23 01:44:16,429 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:44:16,429 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:44:16,430 INFO:     None feature selector for col prot
2022-11-23 01:44:16,430 INFO:     None feature selector for col prot
2022-11-23 01:44:16,430 INFO:     None feature selector for col prot
2022-11-23 01:44:16,431 INFO:     None feature selector for col chem
2022-11-23 01:44:16,431 INFO:     None feature selector for col chem
2022-11-23 01:44:16,431 INFO:     None feature selector for col chem
2022-11-23 01:44:16,431 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:44:16,431 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:44:16,433 INFO:     Number of params in model 168571
2022-11-23 01:44:16,436 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:44:16,436 INFO:   Starting stage: TRAINING
2022-11-23 01:44:16,493 INFO:     Val loss before train {'Reaction outcome loss': 1.013586891645735, 'Total loss': 1.013586891645735}
2022-11-23 01:44:16,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:16,494 INFO:     Epoch: 0
2022-11-23 01:44:17,293 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8663081811233, 'Total loss': 0.8663081811233} | train loss {'Reaction outcome loss': 0.8918088524327105, 'Total loss': 0.8918088524327105}
2022-11-23 01:44:17,293 INFO:     Found new best model at epoch 0
2022-11-23 01:44:17,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:17,294 INFO:     Epoch: 1
2022-11-23 01:44:18,181 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8598541170358658, 'Total loss': 0.8598541170358658} | train loss {'Reaction outcome loss': 0.8589195406388658, 'Total loss': 0.8589195406388658}
2022-11-23 01:44:18,181 INFO:     Found new best model at epoch 1
2022-11-23 01:44:18,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:18,182 INFO:     Epoch: 2
2022-11-23 01:44:19,014 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8768336522308263, 'Total loss': 0.8768336522308263} | train loss {'Reaction outcome loss': 0.8582724551651401, 'Total loss': 0.8582724551651401}
2022-11-23 01:44:19,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:19,015 INFO:     Epoch: 3
2022-11-23 01:44:19,830 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8621882599863139, 'Total loss': 0.8621882599863139} | train loss {'Reaction outcome loss': 0.8585076034069061, 'Total loss': 0.8585076034069061}
2022-11-23 01:44:19,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:19,830 INFO:     Epoch: 4
2022-11-23 01:44:20,640 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8468585935505953, 'Total loss': 0.8468585935505953} | train loss {'Reaction outcome loss': 0.8543354242678113, 'Total loss': 0.8543354242678113}
2022-11-23 01:44:20,640 INFO:     Found new best model at epoch 4
2022-11-23 01:44:20,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:20,641 INFO:     Epoch: 5
2022-11-23 01:44:21,493 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8393606482581659, 'Total loss': 0.8393606482581659} | train loss {'Reaction outcome loss': 0.8506944799712794, 'Total loss': 0.8506944799712794}
2022-11-23 01:44:21,493 INFO:     Found new best model at epoch 5
2022-11-23 01:44:21,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:21,494 INFO:     Epoch: 6
2022-11-23 01:44:22,372 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8317055519331585, 'Total loss': 0.8317055519331585} | train loss {'Reaction outcome loss': 0.841789188881514, 'Total loss': 0.841789188881514}
2022-11-23 01:44:22,372 INFO:     Found new best model at epoch 6
2022-11-23 01:44:22,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:22,373 INFO:     Epoch: 7
2022-11-23 01:44:23,189 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8588722524317828, 'Total loss': 0.8588722524317828} | train loss {'Reaction outcome loss': 0.8438618525802365, 'Total loss': 0.8438618525802365}
2022-11-23 01:44:23,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:23,189 INFO:     Epoch: 8
2022-11-23 01:44:23,987 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8399913067167456, 'Total loss': 0.8399913067167456} | train loss {'Reaction outcome loss': 0.842402011759368, 'Total loss': 0.842402011759368}
2022-11-23 01:44:23,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:23,987 INFO:     Epoch: 9
2022-11-23 01:44:24,767 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8435278534889221, 'Total loss': 0.8435278534889221} | train loss {'Reaction outcome loss': 0.8442721970168202, 'Total loss': 0.8442721970168202}
2022-11-23 01:44:24,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:24,767 INFO:     Epoch: 10
2022-11-23 01:44:25,574 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8315299593589522, 'Total loss': 0.8315299593589522} | train loss {'Reaction outcome loss': 0.8373744573127403, 'Total loss': 0.8373744573127403}
2022-11-23 01:44:25,574 INFO:     Found new best model at epoch 10
2022-11-23 01:44:25,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:25,575 INFO:     Epoch: 11
2022-11-23 01:44:26,397 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8611093996600672, 'Total loss': 0.8611093996600672} | train loss {'Reaction outcome loss': 0.8370949594598067, 'Total loss': 0.8370949594598067}
2022-11-23 01:44:26,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:26,397 INFO:     Epoch: 12
2022-11-23 01:44:27,232 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8351238539273088, 'Total loss': 0.8351238539273088} | train loss {'Reaction outcome loss': 0.8357353396562912, 'Total loss': 0.8357353396562912}
2022-11-23 01:44:27,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:27,233 INFO:     Epoch: 13
2022-11-23 01:44:28,085 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8249388499693437, 'Total loss': 0.8249388499693437} | train loss {'Reaction outcome loss': 0.8331960502423739, 'Total loss': 0.8331960502423739}
2022-11-23 01:44:28,085 INFO:     Found new best model at epoch 13
2022-11-23 01:44:28,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:28,086 INFO:     Epoch: 14
2022-11-23 01:44:28,862 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8313143280419436, 'Total loss': 0.8313143280419436} | train loss {'Reaction outcome loss': 0.8288425300044087, 'Total loss': 0.8288425300044087}
2022-11-23 01:44:28,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:28,863 INFO:     Epoch: 15
2022-11-23 01:44:29,679 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8402190465818752, 'Total loss': 0.8402190465818752} | train loss {'Reaction outcome loss': 0.8278787910546127, 'Total loss': 0.8278787910546127}
2022-11-23 01:44:29,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:29,679 INFO:     Epoch: 16
2022-11-23 01:44:30,523 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8313055343248628, 'Total loss': 0.8313055343248628} | train loss {'Reaction outcome loss': 0.8266849180887103, 'Total loss': 0.8266849180887103}
2022-11-23 01:44:30,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:30,523 INFO:     Epoch: 17
2022-11-23 01:44:31,319 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8319526206363331, 'Total loss': 0.8319526206363331} | train loss {'Reaction outcome loss': 0.8319633139772453, 'Total loss': 0.8319633139772453}
2022-11-23 01:44:31,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:31,320 INFO:     Epoch: 18
2022-11-23 01:44:32,109 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8851482204415582, 'Total loss': 0.8851482204415582} | train loss {'Reaction outcome loss': 0.8331895578004088, 'Total loss': 0.8331895578004088}
2022-11-23 01:44:32,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:32,109 INFO:     Epoch: 19
2022-11-23 01:44:32,908 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8226778744296595, 'Total loss': 0.8226778744296595} | train loss {'Reaction outcome loss': 0.8432622741349796, 'Total loss': 0.8432622741349796}
2022-11-23 01:44:32,908 INFO:     Found new best model at epoch 19
2022-11-23 01:44:32,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:32,909 INFO:     Epoch: 20
2022-11-23 01:44:33,748 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8138022463430058, 'Total loss': 0.8138022463430058} | train loss {'Reaction outcome loss': 0.832166942628289, 'Total loss': 0.832166942628289}
2022-11-23 01:44:33,748 INFO:     Found new best model at epoch 20
2022-11-23 01:44:33,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:33,749 INFO:     Epoch: 21
2022-11-23 01:44:34,596 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8120642480525103, 'Total loss': 0.8120642480525103} | train loss {'Reaction outcome loss': 0.8229147821423496, 'Total loss': 0.8229147821423496}
2022-11-23 01:44:34,596 INFO:     Found new best model at epoch 21
2022-11-23 01:44:34,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:34,598 INFO:     Epoch: 22
2022-11-23 01:44:35,415 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8177933679385618, 'Total loss': 0.8177933679385618} | train loss {'Reaction outcome loss': 0.8297958953781166, 'Total loss': 0.8297958953781166}
2022-11-23 01:44:35,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:35,415 INFO:     Epoch: 23
2022-11-23 01:44:36,227 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.9159118499268185, 'Total loss': 0.9159118499268185} | train loss {'Reaction outcome loss': 0.8257638041669058, 'Total loss': 0.8257638041669058}
2022-11-23 01:44:36,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:36,227 INFO:     Epoch: 24
2022-11-23 01:44:37,016 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8218642432581295, 'Total loss': 0.8218642432581295} | train loss {'Reaction outcome loss': 0.8292960588507324, 'Total loss': 0.8292960588507324}
2022-11-23 01:44:37,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:37,017 INFO:     Epoch: 25
2022-11-23 01:44:37,882 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8577737259593877, 'Total loss': 0.8577737259593877} | train loss {'Reaction outcome loss': 0.8334610615423333, 'Total loss': 0.8334610615423333}
2022-11-23 01:44:37,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:37,883 INFO:     Epoch: 26
2022-11-23 01:44:38,659 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8378424407406286, 'Total loss': 0.8378424407406286} | train loss {'Reaction outcome loss': 0.8455914791055054, 'Total loss': 0.8455914791055054}
2022-11-23 01:44:38,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:38,659 INFO:     Epoch: 27
2022-11-23 01:44:39,468 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8224388178099286, 'Total loss': 0.8224388178099286} | train loss {'Reaction outcome loss': 0.8307648276993138, 'Total loss': 0.8307648276993138}
2022-11-23 01:44:39,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:39,468 INFO:     Epoch: 28
2022-11-23 01:44:40,253 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8289162862029943, 'Total loss': 0.8289162862029943} | train loss {'Reaction outcome loss': 0.824725386826133, 'Total loss': 0.824725386826133}
2022-11-23 01:44:40,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:40,253 INFO:     Epoch: 29
2022-11-23 01:44:41,052 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8315334977074103, 'Total loss': 0.8315334977074103} | train loss {'Reaction outcome loss': 0.8292222085751986, 'Total loss': 0.8292222085751986}
2022-11-23 01:44:41,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:41,052 INFO:     Epoch: 30
2022-11-23 01:44:41,838 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8084211633964018, 'Total loss': 0.8084211633964018} | train loss {'Reaction outcome loss': 0.8323344360237662, 'Total loss': 0.8323344360237662}
2022-11-23 01:44:41,838 INFO:     Found new best model at epoch 30
2022-11-23 01:44:41,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:41,839 INFO:     Epoch: 31
2022-11-23 01:44:42,627 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8292736018245871, 'Total loss': 0.8292736018245871} | train loss {'Reaction outcome loss': 0.8360279930024012, 'Total loss': 0.8360279930024012}
2022-11-23 01:44:42,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:42,627 INFO:     Epoch: 32
2022-11-23 01:44:43,434 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8273523937572133, 'Total loss': 0.8273523937572133} | train loss {'Reaction outcome loss': 0.8300099801196743, 'Total loss': 0.8300099801196743}
2022-11-23 01:44:43,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:43,435 INFO:     Epoch: 33
2022-11-23 01:44:44,224 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8285048719156872, 'Total loss': 0.8285048719156872} | train loss {'Reaction outcome loss': 0.8272945210639282, 'Total loss': 0.8272945210639282}
2022-11-23 01:44:44,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:44,224 INFO:     Epoch: 34
2022-11-23 01:44:45,003 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8124748739329252, 'Total loss': 0.8124748739329252} | train loss {'Reaction outcome loss': 0.8277368264401007, 'Total loss': 0.8277368264401007}
2022-11-23 01:44:45,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:45,003 INFO:     Epoch: 35
2022-11-23 01:44:45,824 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8332378241148862, 'Total loss': 0.8332378241148862} | train loss {'Reaction outcome loss': 0.8301590024701014, 'Total loss': 0.8301590024701014}
2022-11-23 01:44:45,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:45,824 INFO:     Epoch: 36
2022-11-23 01:44:46,632 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8262537094679746, 'Total loss': 0.8262537094679746} | train loss {'Reaction outcome loss': 0.8322870887001517, 'Total loss': 0.8322870887001517}
2022-11-23 01:44:46,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:46,633 INFO:     Epoch: 37
2022-11-23 01:44:47,471 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8155864538116888, 'Total loss': 0.8155864538116888} | train loss {'Reaction outcome loss': 0.836434769123672, 'Total loss': 0.836434769123672}
2022-11-23 01:44:47,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:47,471 INFO:     Epoch: 38
2022-11-23 01:44:48,259 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8243504782969301, 'Total loss': 0.8243504782969301} | train loss {'Reaction outcome loss': 0.8324057618797067, 'Total loss': 0.8324057618797067}
2022-11-23 01:44:48,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:48,259 INFO:     Epoch: 39
2022-11-23 01:44:49,069 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8313777080991052, 'Total loss': 0.8313777080991052} | train loss {'Reaction outcome loss': 0.8248158232704831, 'Total loss': 0.8248158232704831}
2022-11-23 01:44:49,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:49,069 INFO:     Epoch: 40
2022-11-23 01:44:49,860 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8083840967579321, 'Total loss': 0.8083840967579321} | train loss {'Reaction outcome loss': 0.823391275005302, 'Total loss': 0.823391275005302}
2022-11-23 01:44:49,860 INFO:     Found new best model at epoch 40
2022-11-23 01:44:49,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:49,861 INFO:     Epoch: 41
2022-11-23 01:44:50,633 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8123463900251822, 'Total loss': 0.8123463900251822} | train loss {'Reaction outcome loss': 0.8295816084151326, 'Total loss': 0.8295816084151326}
2022-11-23 01:44:50,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:50,634 INFO:     Epoch: 42
2022-11-23 01:44:51,452 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8178343217481266, 'Total loss': 0.8178343217481266} | train loss {'Reaction outcome loss': 0.8277988110175017, 'Total loss': 0.8277988110175017}
2022-11-23 01:44:51,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:51,452 INFO:     Epoch: 43
2022-11-23 01:44:52,260 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8332733633843336, 'Total loss': 0.8332733633843336} | train loss {'Reaction outcome loss': 0.8266426415337242, 'Total loss': 0.8266426415337242}
2022-11-23 01:44:52,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:52,260 INFO:     Epoch: 44
2022-11-23 01:44:53,016 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8048824275081808, 'Total loss': 0.8048824275081808} | train loss {'Reaction outcome loss': 0.8329614428614798, 'Total loss': 0.8329614428614798}
2022-11-23 01:44:53,016 INFO:     Found new best model at epoch 44
2022-11-23 01:44:53,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:53,017 INFO:     Epoch: 45
2022-11-23 01:44:53,822 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8412268121134151, 'Total loss': 0.8412268121134151} | train loss {'Reaction outcome loss': 0.8239354606461429, 'Total loss': 0.8239354606461429}
2022-11-23 01:44:53,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:53,822 INFO:     Epoch: 46
2022-11-23 01:44:54,606 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8104653094302524, 'Total loss': 0.8104653094302524} | train loss {'Reaction outcome loss': 0.8252425274626929, 'Total loss': 0.8252425274626929}
2022-11-23 01:44:54,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:54,607 INFO:     Epoch: 47
2022-11-23 01:44:55,408 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8208828697150404, 'Total loss': 0.8208828697150404} | train loss {'Reaction outcome loss': 0.8223464948686994, 'Total loss': 0.8223464948686994}
2022-11-23 01:44:55,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:55,408 INFO:     Epoch: 48
2022-11-23 01:44:56,199 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8335101116787303, 'Total loss': 0.8335101116787303} | train loss {'Reaction outcome loss': 0.8278071117787226, 'Total loss': 0.8278071117787226}
2022-11-23 01:44:56,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:56,199 INFO:     Epoch: 49
2022-11-23 01:44:57,019 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8146449070085179, 'Total loss': 0.8146449070085179} | train loss {'Reaction outcome loss': 0.8290958269404979, 'Total loss': 0.8290958269404979}
2022-11-23 01:44:57,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:57,020 INFO:     Epoch: 50
2022-11-23 01:44:57,824 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8218003863638098, 'Total loss': 0.8218003863638098} | train loss {'Reaction outcome loss': 0.8335628289925424, 'Total loss': 0.8335628289925424}
2022-11-23 01:44:57,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:57,824 INFO:     Epoch: 51
2022-11-23 01:44:58,657 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8148402727463029, 'Total loss': 0.8148402727463029} | train loss {'Reaction outcome loss': 0.8291477297964366, 'Total loss': 0.8291477297964366}
2022-11-23 01:44:58,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:58,658 INFO:     Epoch: 52
2022-11-23 01:44:59,476 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.809151595289057, 'Total loss': 0.809151595289057} | train loss {'Reaction outcome loss': 0.8261332049784873, 'Total loss': 0.8261332049784873}
2022-11-23 01:44:59,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:44:59,476 INFO:     Epoch: 53
2022-11-23 01:45:00,312 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8157893744381991, 'Total loss': 0.8157893744381991} | train loss {'Reaction outcome loss': 0.8267843008403354, 'Total loss': 0.8267843008403354}
2022-11-23 01:45:00,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:00,312 INFO:     Epoch: 54
2022-11-23 01:45:01,145 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.807203122837977, 'Total loss': 0.807203122837977} | train loss {'Reaction outcome loss': 0.8271894196749698, 'Total loss': 0.8271894196749698}
2022-11-23 01:45:01,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:01,145 INFO:     Epoch: 55
2022-11-23 01:45:01,916 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8174879889596592, 'Total loss': 0.8174879889596592} | train loss {'Reaction outcome loss': 0.8365851872363071, 'Total loss': 0.8365851872363071}
2022-11-23 01:45:01,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:01,917 INFO:     Epoch: 56
2022-11-23 01:45:02,773 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8580887785012071, 'Total loss': 0.8580887785012071} | train loss {'Reaction outcome loss': 0.8247767555930836, 'Total loss': 0.8247767555930836}
2022-11-23 01:45:02,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:02,773 INFO:     Epoch: 57
2022-11-23 01:45:03,566 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.808708281679587, 'Total loss': 0.808708281679587} | train loss {'Reaction outcome loss': 0.8298503978532336, 'Total loss': 0.8298503978532336}
2022-11-23 01:45:03,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:03,566 INFO:     Epoch: 58
2022-11-23 01:45:04,368 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8010141653093424, 'Total loss': 0.8010141653093424} | train loss {'Reaction outcome loss': 0.825643838899821, 'Total loss': 0.825643838899821}
2022-11-23 01:45:04,368 INFO:     Found new best model at epoch 58
2022-11-23 01:45:04,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:04,369 INFO:     Epoch: 59
2022-11-23 01:45:05,184 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8309817673130468, 'Total loss': 0.8309817673130468} | train loss {'Reaction outcome loss': 0.8265590064438731, 'Total loss': 0.8265590064438731}
2022-11-23 01:45:05,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:05,185 INFO:     Epoch: 60
2022-11-23 01:45:05,985 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8515722826123238, 'Total loss': 0.8515722826123238} | train loss {'Reaction outcome loss': 0.8294459599473698, 'Total loss': 0.8294459599473698}
2022-11-23 01:45:05,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:05,986 INFO:     Epoch: 61
2022-11-23 01:45:06,795 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8105533346533775, 'Total loss': 0.8105533346533775} | train loss {'Reaction outcome loss': 0.8296376405215939, 'Total loss': 0.8296376405215939}
2022-11-23 01:45:06,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:06,796 INFO:     Epoch: 62
2022-11-23 01:45:07,587 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8315613361244852, 'Total loss': 0.8315613361244852} | train loss {'Reaction outcome loss': 0.8262486217716928, 'Total loss': 0.8262486217716928}
2022-11-23 01:45:07,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:07,588 INFO:     Epoch: 63
2022-11-23 01:45:08,396 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8073990981687199, 'Total loss': 0.8073990981687199} | train loss {'Reaction outcome loss': 0.835781057353927, 'Total loss': 0.835781057353927}
2022-11-23 01:45:08,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:08,397 INFO:     Epoch: 64
2022-11-23 01:45:09,199 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8352953547781165, 'Total loss': 0.8352953547781165} | train loss {'Reaction outcome loss': 0.8338574615084691, 'Total loss': 0.8338574615084691}
2022-11-23 01:45:09,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:09,199 INFO:     Epoch: 65
2022-11-23 01:45:09,957 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8071795817125927, 'Total loss': 0.8071795817125927} | train loss {'Reaction outcome loss': 0.8282078632458985, 'Total loss': 0.8282078632458985}
2022-11-23 01:45:09,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:09,957 INFO:     Epoch: 66
2022-11-23 01:45:10,793 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8388746672055938, 'Total loss': 0.8388746672055938} | train loss {'Reaction outcome loss': 0.8300599817804962, 'Total loss': 0.8300599817804962}
2022-11-23 01:45:10,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:10,794 INFO:     Epoch: 67
2022-11-23 01:45:11,584 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8039382540366866, 'Total loss': 0.8039382540366866} | train loss {'Reaction outcome loss': 0.8373329528430213, 'Total loss': 0.8373329528430213}
2022-11-23 01:45:11,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:11,584 INFO:     Epoch: 68
2022-11-23 01:45:12,319 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8200930946252563, 'Total loss': 0.8200930946252563} | train loss {'Reaction outcome loss': 0.8238936043099353, 'Total loss': 0.8238936043099353}
2022-11-23 01:45:12,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:12,319 INFO:     Epoch: 69
2022-11-23 01:45:13,111 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.813508587127382, 'Total loss': 0.813508587127382} | train loss {'Reaction outcome loss': 0.8224257890753418, 'Total loss': 0.8224257890753418}
2022-11-23 01:45:13,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:13,112 INFO:     Epoch: 70
2022-11-23 01:45:13,960 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8074427484111353, 'Total loss': 0.8074427484111353} | train loss {'Reaction outcome loss': 0.8272105764280929, 'Total loss': 0.8272105764280929}
2022-11-23 01:45:13,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:13,960 INFO:     Epoch: 71
2022-11-23 01:45:14,768 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.819347701289437, 'Total loss': 0.819347701289437} | train loss {'Reaction outcome loss': 0.8360900064470315, 'Total loss': 0.8360900064470315}
2022-11-23 01:45:14,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:14,768 INFO:     Epoch: 72
2022-11-23 01:45:15,597 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8212513998150826, 'Total loss': 0.8212513998150826} | train loss {'Reaction outcome loss': 0.8267583383119058, 'Total loss': 0.8267583383119058}
2022-11-23 01:45:15,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:15,597 INFO:     Epoch: 73
2022-11-23 01:45:16,454 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8282638368281451, 'Total loss': 0.8282638368281451} | train loss {'Reaction outcome loss': 0.8279091170442249, 'Total loss': 0.8279091170442249}
2022-11-23 01:45:16,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:16,454 INFO:     Epoch: 74
2022-11-23 01:45:17,306 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.815407508476214, 'Total loss': 0.815407508476214} | train loss {'Reaction outcome loss': 0.8295175657581221, 'Total loss': 0.8295175657581221}
2022-11-23 01:45:17,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:17,306 INFO:     Epoch: 75
2022-11-23 01:45:18,126 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.815680591897531, 'Total loss': 0.815680591897531} | train loss {'Reaction outcome loss': 0.8279433010319467, 'Total loss': 0.8279433010319467}
2022-11-23 01:45:18,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:18,126 INFO:     Epoch: 76
2022-11-23 01:45:18,968 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8327851844104853, 'Total loss': 0.8327851844104853} | train loss {'Reaction outcome loss': 0.8305455884228834, 'Total loss': 0.8305455884228834}
2022-11-23 01:45:18,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:18,968 INFO:     Epoch: 77
2022-11-23 01:45:19,794 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.82908200066198, 'Total loss': 0.82908200066198} | train loss {'Reaction outcome loss': 0.8212694208390316, 'Total loss': 0.8212694208390316}
2022-11-23 01:45:19,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:19,794 INFO:     Epoch: 78
2022-11-23 01:45:20,565 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8182560151273554, 'Total loss': 0.8182560151273554} | train loss {'Reaction outcome loss': 0.8256782935215876, 'Total loss': 0.8256782935215876}
2022-11-23 01:45:20,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:20,566 INFO:     Epoch: 79
2022-11-23 01:45:21,396 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8022925989194349, 'Total loss': 0.8022925989194349} | train loss {'Reaction outcome loss': 0.8276552239410307, 'Total loss': 0.8276552239410307}
2022-11-23 01:45:21,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:21,397 INFO:     Epoch: 80
2022-11-23 01:45:22,234 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8062442588535222, 'Total loss': 0.8062442588535222} | train loss {'Reaction outcome loss': 0.8235387823842315, 'Total loss': 0.8235387823842315}
2022-11-23 01:45:22,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:22,234 INFO:     Epoch: 81
2022-11-23 01:45:23,056 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8227429335767572, 'Total loss': 0.8227429335767572} | train loss {'Reaction outcome loss': 0.8277916023847063, 'Total loss': 0.8277916023847063}
2022-11-23 01:45:23,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:23,056 INFO:     Epoch: 82
2022-11-23 01:45:23,829 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.826822513883764, 'Total loss': 0.826822513883764} | train loss {'Reaction outcome loss': 0.827932016448936, 'Total loss': 0.827932016448936}
2022-11-23 01:45:23,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:23,829 INFO:     Epoch: 83
2022-11-23 01:45:24,662 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8142968991940672, 'Total loss': 0.8142968991940672} | train loss {'Reaction outcome loss': 0.8262400268181133, 'Total loss': 0.8262400268181133}
2022-11-23 01:45:24,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:24,662 INFO:     Epoch: 84
2022-11-23 01:45:25,443 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.816531624306332, 'Total loss': 0.816531624306332} | train loss {'Reaction outcome loss': 0.8262858907220817, 'Total loss': 0.8262858907220817}
2022-11-23 01:45:25,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:25,443 INFO:     Epoch: 85
2022-11-23 01:45:26,266 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8049601296132262, 'Total loss': 0.8049601296132262} | train loss {'Reaction outcome loss': 0.8261135008774305, 'Total loss': 0.8261135008774305}
2022-11-23 01:45:26,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:26,266 INFO:     Epoch: 86
2022-11-23 01:45:27,056 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8278112960132685, 'Total loss': 0.8278112960132685} | train loss {'Reaction outcome loss': 0.8324880981252261, 'Total loss': 0.8324880981252261}
2022-11-23 01:45:27,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:27,057 INFO:     Epoch: 87
2022-11-23 01:45:27,849 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8112498305060647, 'Total loss': 0.8112498305060647} | train loss {'Reaction outcome loss': 0.832541035495789, 'Total loss': 0.832541035495789}
2022-11-23 01:45:27,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:27,849 INFO:     Epoch: 88
2022-11-23 01:45:28,649 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8017841381105509, 'Total loss': 0.8017841381105509} | train loss {'Reaction outcome loss': 0.8156737060651846, 'Total loss': 0.8156737060651846}
2022-11-23 01:45:28,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:28,650 INFO:     Epoch: 89
2022-11-23 01:45:29,423 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8407275480302897, 'Total loss': 0.8407275480302897} | train loss {'Reaction outcome loss': 0.816486364796094, 'Total loss': 0.816486364796094}
2022-11-23 01:45:29,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:29,424 INFO:     Epoch: 90
2022-11-23 01:45:30,255 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.825913586399772, 'Total loss': 0.825913586399772} | train loss {'Reaction outcome loss': 0.8283877670764923, 'Total loss': 0.8283877670764923}
2022-11-23 01:45:30,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:30,256 INFO:     Epoch: 91
2022-11-23 01:45:31,095 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.80787878009406, 'Total loss': 0.80787878009406} | train loss {'Reaction outcome loss': 0.8250846158155063, 'Total loss': 0.8250846158155063}
2022-11-23 01:45:31,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:31,095 INFO:     Epoch: 92
2022-11-23 01:45:31,949 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8027477257631042, 'Total loss': 0.8027477257631042} | train loss {'Reaction outcome loss': 0.8191106463009529, 'Total loss': 0.8191106463009529}
2022-11-23 01:45:31,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:31,949 INFO:     Epoch: 93
2022-11-23 01:45:32,746 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.822034009478309, 'Total loss': 0.822034009478309} | train loss {'Reaction outcome loss': 0.8247191946998782, 'Total loss': 0.8247191946998782}
2022-11-23 01:45:32,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:32,746 INFO:     Epoch: 94
2022-11-23 01:45:33,534 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8134154027158563, 'Total loss': 0.8134154027158563} | train loss {'Reaction outcome loss': 0.8234253292865599, 'Total loss': 0.8234253292865599}
2022-11-23 01:45:33,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:33,535 INFO:     Epoch: 95
2022-11-23 01:45:34,349 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8018739636648785, 'Total loss': 0.8018739636648785} | train loss {'Reaction outcome loss': 0.8334224623465828, 'Total loss': 0.8334224623465828}
2022-11-23 01:45:34,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:34,349 INFO:     Epoch: 96
2022-11-23 01:45:35,126 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8253914185545661, 'Total loss': 0.8253914185545661} | train loss {'Reaction outcome loss': 0.8227220490152537, 'Total loss': 0.8227220490152537}
2022-11-23 01:45:35,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:35,126 INFO:     Epoch: 97
2022-11-23 01:45:35,897 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.81571283868768, 'Total loss': 0.81571283868768} | train loss {'Reaction outcome loss': 0.8201413100909608, 'Total loss': 0.8201413100909608}
2022-11-23 01:45:35,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:35,898 INFO:     Epoch: 98
2022-11-23 01:45:36,716 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8297452689571814, 'Total loss': 0.8297452689571814} | train loss {'Reaction outcome loss': 0.8219967519464763, 'Total loss': 0.8219967519464763}
2022-11-23 01:45:36,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:36,717 INFO:     Epoch: 99
2022-11-23 01:45:37,533 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8691148764707826, 'Total loss': 0.8691148764707826} | train loss {'Reaction outcome loss': 0.8164472076212347, 'Total loss': 0.8164472076212347}
2022-11-23 01:45:37,533 INFO:     Best model found after epoch 59 of 100.
2022-11-23 01:45:37,534 INFO:   Done with stage: TRAINING
2022-11-23 01:45:37,534 INFO:   Starting stage: EVALUATION
2022-11-23 01:45:37,658 INFO:   Done with stage: EVALUATION
2022-11-23 01:45:37,658 INFO:   Leaving out SEQ value Fold_2
2022-11-23 01:45:37,671 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 01:45:37,671 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:45:38,334 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:45:38,334 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:45:38,407 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:45:38,407 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:45:38,407 INFO:     No hyperparam tuning for this model
2022-11-23 01:45:38,407 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:45:38,407 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:45:38,408 INFO:     None feature selector for col prot
2022-11-23 01:45:38,408 INFO:     None feature selector for col prot
2022-11-23 01:45:38,408 INFO:     None feature selector for col prot
2022-11-23 01:45:38,409 INFO:     None feature selector for col chem
2022-11-23 01:45:38,409 INFO:     None feature selector for col chem
2022-11-23 01:45:38,409 INFO:     None feature selector for col chem
2022-11-23 01:45:38,409 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:45:38,409 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:45:38,410 INFO:     Number of params in model 168571
2022-11-23 01:45:38,413 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:45:38,414 INFO:   Starting stage: TRAINING
2022-11-23 01:45:38,470 INFO:     Val loss before train {'Reaction outcome loss': 0.949894457362419, 'Total loss': 0.949894457362419}
2022-11-23 01:45:38,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:38,470 INFO:     Epoch: 0
2022-11-23 01:45:39,254 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7699702090995256, 'Total loss': 0.7699702090995256} | train loss {'Reaction outcome loss': 0.9098422829000676, 'Total loss': 0.9098422829000676}
2022-11-23 01:45:39,254 INFO:     Found new best model at epoch 0
2022-11-23 01:45:39,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:39,255 INFO:     Epoch: 1
2022-11-23 01:45:40,058 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7629002582195193, 'Total loss': 0.7629002582195193} | train loss {'Reaction outcome loss': 0.869697855754954, 'Total loss': 0.869697855754954}
2022-11-23 01:45:40,059 INFO:     Found new best model at epoch 1
2022-11-23 01:45:40,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:40,060 INFO:     Epoch: 2
2022-11-23 01:45:40,885 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7634952186151992, 'Total loss': 0.7634952186151992} | train loss {'Reaction outcome loss': 0.8629615265326421, 'Total loss': 0.8629615265326421}
2022-11-23 01:45:40,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:40,885 INFO:     Epoch: 3
2022-11-23 01:45:41,706 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7647796598977821, 'Total loss': 0.7647796598977821} | train loss {'Reaction outcome loss': 0.8633867106476768, 'Total loss': 0.8633867106476768}
2022-11-23 01:45:41,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:41,706 INFO:     Epoch: 4
2022-11-23 01:45:42,488 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7760670649450879, 'Total loss': 0.7760670649450879} | train loss {'Reaction outcome loss': 0.8536674638019234, 'Total loss': 0.8536674638019234}
2022-11-23 01:45:42,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:42,489 INFO:     Epoch: 5
2022-11-23 01:45:43,251 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.757281270138053, 'Total loss': 0.757281270138053} | train loss {'Reaction outcome loss': 0.855795051597181, 'Total loss': 0.855795051597181}
2022-11-23 01:45:43,251 INFO:     Found new best model at epoch 5
2022-11-23 01:45:43,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:43,252 INFO:     Epoch: 6
2022-11-23 01:45:43,995 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.762409761894581, 'Total loss': 0.762409761894581} | train loss {'Reaction outcome loss': 0.8488647921285668, 'Total loss': 0.8488647921285668}
2022-11-23 01:45:43,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:43,995 INFO:     Epoch: 7
2022-11-23 01:45:44,786 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7528390738853189, 'Total loss': 0.7528390738853189} | train loss {'Reaction outcome loss': 0.8462008187761072, 'Total loss': 0.8462008187761072}
2022-11-23 01:45:44,786 INFO:     Found new best model at epoch 7
2022-11-23 01:45:44,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:44,787 INFO:     Epoch: 8
2022-11-23 01:45:45,622 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.750609147687291, 'Total loss': 0.750609147687291} | train loss {'Reaction outcome loss': 0.8425638223769235, 'Total loss': 0.8425638223769235}
2022-11-23 01:45:45,622 INFO:     Found new best model at epoch 8
2022-11-23 01:45:45,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:45,623 INFO:     Epoch: 9
2022-11-23 01:45:46,439 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7342762136182119, 'Total loss': 0.7342762136182119} | train loss {'Reaction outcome loss': 0.8454507495291897, 'Total loss': 0.8454507495291897}
2022-11-23 01:45:46,439 INFO:     Found new best model at epoch 9
2022-11-23 01:45:46,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:46,441 INFO:     Epoch: 10
2022-11-23 01:45:47,305 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7591363087643025, 'Total loss': 0.7591363087643025} | train loss {'Reaction outcome loss': 0.844224178033774, 'Total loss': 0.844224178033774}
2022-11-23 01:45:47,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:47,305 INFO:     Epoch: 11
2022-11-23 01:45:48,123 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7390671476375225, 'Total loss': 0.7390671476375225} | train loss {'Reaction outcome loss': 0.8428152238980668, 'Total loss': 0.8428152238980668}
2022-11-23 01:45:48,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:48,123 INFO:     Epoch: 12
2022-11-23 01:45:48,942 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7460974995480028, 'Total loss': 0.7460974995480028} | train loss {'Reaction outcome loss': 0.8455859790327119, 'Total loss': 0.8455859790327119}
2022-11-23 01:45:48,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:48,942 INFO:     Epoch: 13
2022-11-23 01:45:49,748 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7375902124615603, 'Total loss': 0.7375902124615603} | train loss {'Reaction outcome loss': 0.8407859466359263, 'Total loss': 0.8407859466359263}
2022-11-23 01:45:49,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:49,748 INFO:     Epoch: 14
2022-11-23 01:45:50,587 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7386780381202698, 'Total loss': 0.7386780381202698} | train loss {'Reaction outcome loss': 0.8375616468122749, 'Total loss': 0.8375616468122749}
2022-11-23 01:45:50,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:50,587 INFO:     Epoch: 15
2022-11-23 01:45:51,354 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7679943470067756, 'Total loss': 0.7679943470067756} | train loss {'Reaction outcome loss': 0.8355940038063487, 'Total loss': 0.8355940038063487}
2022-11-23 01:45:51,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:51,354 INFO:     Epoch: 16
2022-11-23 01:45:52,155 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7352428782817929, 'Total loss': 0.7352428782817929} | train loss {'Reaction outcome loss': 0.8411838711529481, 'Total loss': 0.8411838711529481}
2022-11-23 01:45:52,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:52,156 INFO:     Epoch: 17
2022-11-23 01:45:52,962 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7394147716289343, 'Total loss': 0.7394147716289343} | train loss {'Reaction outcome loss': 0.8384758225474201, 'Total loss': 0.8384758225474201}
2022-11-23 01:45:52,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:52,962 INFO:     Epoch: 18
2022-11-23 01:45:53,762 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7423827620439751, 'Total loss': 0.7423827620439751} | train loss {'Reaction outcome loss': 0.8400889903795524, 'Total loss': 0.8400889903795524}
2022-11-23 01:45:53,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:53,762 INFO:     Epoch: 19
2022-11-23 01:45:54,545 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7383713569752005, 'Total loss': 0.7383713569752005} | train loss {'Reaction outcome loss': 0.8359822368279832, 'Total loss': 0.8359822368279832}
2022-11-23 01:45:54,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:54,545 INFO:     Epoch: 20
2022-11-23 01:45:55,324 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7396059978839963, 'Total loss': 0.7396059978839963} | train loss {'Reaction outcome loss': 0.8398437125028156, 'Total loss': 0.8398437125028156}
2022-11-23 01:45:55,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:55,325 INFO:     Epoch: 21
2022-11-23 01:45:56,117 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7601195968860803, 'Total loss': 0.7601195968860803} | train loss {'Reaction outcome loss': 0.8391581178932893, 'Total loss': 0.8391581178932893}
2022-11-23 01:45:56,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:56,117 INFO:     Epoch: 22
2022-11-23 01:45:56,911 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7842257182265437, 'Total loss': 0.7842257182265437} | train loss {'Reaction outcome loss': 0.8385003662255944, 'Total loss': 0.8385003662255944}
2022-11-23 01:45:56,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:56,911 INFO:     Epoch: 23
2022-11-23 01:45:57,712 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7427427768707275, 'Total loss': 0.7427427768707275} | train loss {'Reaction outcome loss': 0.8380449262798809, 'Total loss': 0.8380449262798809}
2022-11-23 01:45:57,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:57,713 INFO:     Epoch: 24
2022-11-23 01:45:58,526 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7268731656462647, 'Total loss': 0.7268731656462647} | train loss {'Reaction outcome loss': 0.8417567878228719, 'Total loss': 0.8417567878228719}
2022-11-23 01:45:58,526 INFO:     Found new best model at epoch 24
2022-11-23 01:45:58,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:58,527 INFO:     Epoch: 25
2022-11-23 01:45:59,300 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7460104989451032, 'Total loss': 0.7460104989451032} | train loss {'Reaction outcome loss': 0.835426290504268, 'Total loss': 0.835426290504268}
2022-11-23 01:45:59,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:45:59,301 INFO:     Epoch: 26
2022-11-23 01:46:00,086 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7573651193186294, 'Total loss': 0.7573651193186294} | train loss {'Reaction outcome loss': 0.839938109404728, 'Total loss': 0.839938109404728}
2022-11-23 01:46:00,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:00,086 INFO:     Epoch: 27
2022-11-23 01:46:00,898 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7391558372697165, 'Total loss': 0.7391558372697165} | train loss {'Reaction outcome loss': 0.8391796895226494, 'Total loss': 0.8391796895226494}
2022-11-23 01:46:00,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:00,899 INFO:     Epoch: 28
2022-11-23 01:46:01,661 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7513987318027852, 'Total loss': 0.7513987318027852} | train loss {'Reaction outcome loss': 0.8381974479702653, 'Total loss': 0.8381974479702653}
2022-11-23 01:46:01,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:01,661 INFO:     Epoch: 29
2022-11-23 01:46:02,407 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.750275315240372, 'Total loss': 0.750275315240372} | train loss {'Reaction outcome loss': 0.8387676143988234, 'Total loss': 0.8387676143988234}
2022-11-23 01:46:02,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:02,407 INFO:     Epoch: 30
2022-11-23 01:46:03,224 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7429756598417149, 'Total loss': 0.7429756598417149} | train loss {'Reaction outcome loss': 0.8414233905858681, 'Total loss': 0.8414233905858681}
2022-11-23 01:46:03,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:03,224 INFO:     Epoch: 31
2022-11-23 01:46:04,032 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7397740441699361, 'Total loss': 0.7397740441699361} | train loss {'Reaction outcome loss': 0.8352120580976127, 'Total loss': 0.8352120580976127}
2022-11-23 01:46:04,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:04,032 INFO:     Epoch: 32
2022-11-23 01:46:04,884 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7368987452152164, 'Total loss': 0.7368987452152164} | train loss {'Reaction outcome loss': 0.8375733685298045, 'Total loss': 0.8375733685298045}
2022-11-23 01:46:04,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:04,885 INFO:     Epoch: 33
2022-11-23 01:46:05,718 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7560319470804792, 'Total loss': 0.7560319470804792} | train loss {'Reaction outcome loss': 0.8421581106596305, 'Total loss': 0.8421581106596305}
2022-11-23 01:46:05,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:05,718 INFO:     Epoch: 34
2022-11-23 01:46:06,594 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7378443701322689, 'Total loss': 0.7378443701322689} | train loss {'Reaction outcome loss': 0.838382434527405, 'Total loss': 0.838382434527405}
2022-11-23 01:46:06,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:06,595 INFO:     Epoch: 35
2022-11-23 01:46:07,454 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7379330015459726, 'Total loss': 0.7379330015459726} | train loss {'Reaction outcome loss': 0.8333384656026716, 'Total loss': 0.8333384656026716}
2022-11-23 01:46:07,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:07,454 INFO:     Epoch: 36
2022-11-23 01:46:08,250 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7397987398990366, 'Total loss': 0.7397987398990366} | train loss {'Reaction outcome loss': 0.8382201315682443, 'Total loss': 0.8382201315682443}
2022-11-23 01:46:08,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:08,250 INFO:     Epoch: 37
2022-11-23 01:46:09,039 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.733784859956697, 'Total loss': 0.733784859956697} | train loss {'Reaction outcome loss': 0.8330131551769914, 'Total loss': 0.8330131551769914}
2022-11-23 01:46:09,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:09,039 INFO:     Epoch: 38
2022-11-23 01:46:09,821 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7367433046185693, 'Total loss': 0.7367433046185693} | train loss {'Reaction outcome loss': 0.8328502561713829, 'Total loss': 0.8328502561713829}
2022-11-23 01:46:09,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:09,821 INFO:     Epoch: 39
2022-11-23 01:46:10,673 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7578033493008725, 'Total loss': 0.7578033493008725} | train loss {'Reaction outcome loss': 0.8358894496179018, 'Total loss': 0.8358894496179018}
2022-11-23 01:46:10,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:10,673 INFO:     Epoch: 40
2022-11-23 01:46:11,477 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.730213230432466, 'Total loss': 0.730213230432466} | train loss {'Reaction outcome loss': 0.842055144002203, 'Total loss': 0.842055144002203}
2022-11-23 01:46:11,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:11,478 INFO:     Epoch: 41
2022-11-23 01:46:12,266 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7663732801758966, 'Total loss': 0.7663732801758966} | train loss {'Reaction outcome loss': 0.8329325033748736, 'Total loss': 0.8329325033748736}
2022-11-23 01:46:12,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:12,267 INFO:     Epoch: 42
2022-11-23 01:46:13,080 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7269802245982858, 'Total loss': 0.7269802245982858} | train loss {'Reaction outcome loss': 0.8343313856691611, 'Total loss': 0.8343313856691611}
2022-11-23 01:46:13,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:13,080 INFO:     Epoch: 43
2022-11-23 01:46:13,911 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7301514107127522, 'Total loss': 0.7301514107127522} | train loss {'Reaction outcome loss': 0.8340628781035299, 'Total loss': 0.8340628781035299}
2022-11-23 01:46:13,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:13,911 INFO:     Epoch: 44
2022-11-23 01:46:14,696 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7662912219069725, 'Total loss': 0.7662912219069725} | train loss {'Reaction outcome loss': 0.838340021181302, 'Total loss': 0.838340021181302}
2022-11-23 01:46:14,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:14,696 INFO:     Epoch: 45
2022-11-23 01:46:15,490 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7343458360017732, 'Total loss': 0.7343458360017732} | train loss {'Reaction outcome loss': 0.8363748873110677, 'Total loss': 0.8363748873110677}
2022-11-23 01:46:15,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:15,490 INFO:     Epoch: 46
2022-11-23 01:46:16,327 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7531206607818604, 'Total loss': 0.7531206607818604} | train loss {'Reaction outcome loss': 0.8376987785345218, 'Total loss': 0.8376987785345218}
2022-11-23 01:46:16,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:16,328 INFO:     Epoch: 47
2022-11-23 01:46:17,139 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7357704798842586, 'Total loss': 0.7357704798842586} | train loss {'Reaction outcome loss': 0.8399794435159105, 'Total loss': 0.8399794435159105}
2022-11-23 01:46:17,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:17,139 INFO:     Epoch: 48
2022-11-23 01:46:17,929 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7332415615403375, 'Total loss': 0.7332415615403375} | train loss {'Reaction outcome loss': 0.8331052980950622, 'Total loss': 0.8331052980950622}
2022-11-23 01:46:17,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:17,930 INFO:     Epoch: 49
2022-11-23 01:46:18,698 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7501430996628695, 'Total loss': 0.7501430996628695} | train loss {'Reaction outcome loss': 0.836714329778171, 'Total loss': 0.836714329778171}
2022-11-23 01:46:18,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:18,698 INFO:     Epoch: 50
2022-11-23 01:46:19,456 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7475888978603275, 'Total loss': 0.7475888978603275} | train loss {'Reaction outcome loss': 0.8363778471458153, 'Total loss': 0.8363778471458153}
2022-11-23 01:46:19,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:19,457 INFO:     Epoch: 51
2022-11-23 01:46:20,304 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7415690415127333, 'Total loss': 0.7415690415127333} | train loss {'Reaction outcome loss': 0.8367796466975915, 'Total loss': 0.8367796466975915}
2022-11-23 01:46:20,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:20,304 INFO:     Epoch: 52
2022-11-23 01:46:21,123 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7449597522269847, 'Total loss': 0.7449597522269847} | train loss {'Reaction outcome loss': 0.8330641101862564, 'Total loss': 0.8330641101862564}
2022-11-23 01:46:21,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:21,123 INFO:     Epoch: 53
2022-11-23 01:46:21,949 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7603297081104544, 'Total loss': 0.7603297081104544} | train loss {'Reaction outcome loss': 0.8382234612449271, 'Total loss': 0.8382234612449271}
2022-11-23 01:46:21,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:21,950 INFO:     Epoch: 54
2022-11-23 01:46:22,767 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7412993138612702, 'Total loss': 0.7412993138612702} | train loss {'Reaction outcome loss': 0.8335368443952232, 'Total loss': 0.8335368443952232}
2022-11-23 01:46:22,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:22,767 INFO:     Epoch: 55
2022-11-23 01:46:23,561 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7386293667693471, 'Total loss': 0.7386293667693471} | train loss {'Reaction outcome loss': 0.8347849864207331, 'Total loss': 0.8347849864207331}
2022-11-23 01:46:23,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:23,562 INFO:     Epoch: 56
2022-11-23 01:46:24,384 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7391068346278612, 'Total loss': 0.7391068346278612} | train loss {'Reaction outcome loss': 0.8339857994044413, 'Total loss': 0.8339857994044413}
2022-11-23 01:46:24,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:24,385 INFO:     Epoch: 57
2022-11-23 01:46:25,166 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7348359355399775, 'Total loss': 0.7348359355399775} | train loss {'Reaction outcome loss': 0.8345270991081097, 'Total loss': 0.8345270991081097}
2022-11-23 01:46:25,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:25,166 INFO:     Epoch: 58
2022-11-23 01:46:25,970 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7489032440407332, 'Total loss': 0.7489032440407332} | train loss {'Reaction outcome loss': 0.8354966724749471, 'Total loss': 0.8354966724749471}
2022-11-23 01:46:25,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:25,970 INFO:     Epoch: 59
2022-11-23 01:46:26,736 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7660213812839153, 'Total loss': 0.7660213812839153} | train loss {'Reaction outcome loss': 0.8299815802544844, 'Total loss': 0.8299815802544844}
2022-11-23 01:46:26,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:26,736 INFO:     Epoch: 60
2022-11-23 01:46:27,527 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7306857400162275, 'Total loss': 0.7306857400162275} | train loss {'Reaction outcome loss': 0.8375872445643925, 'Total loss': 0.8375872445643925}
2022-11-23 01:46:27,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:27,527 INFO:     Epoch: 61
2022-11-23 01:46:28,300 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7346492333467617, 'Total loss': 0.7346492333467617} | train loss {'Reaction outcome loss': 0.8329001740842569, 'Total loss': 0.8329001740842569}
2022-11-23 01:46:28,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:28,301 INFO:     Epoch: 62
2022-11-23 01:46:29,150 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7424037567404813, 'Total loss': 0.7424037567404813} | train loss {'Reaction outcome loss': 0.8363184297426802, 'Total loss': 0.8363184297426802}
2022-11-23 01:46:29,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:29,150 INFO:     Epoch: 63
2022-11-23 01:46:29,948 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7422537983849992, 'Total loss': 0.7422537983849992} | train loss {'Reaction outcome loss': 0.8346987970051218, 'Total loss': 0.8346987970051218}
2022-11-23 01:46:29,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:29,948 INFO:     Epoch: 64
2022-11-23 01:46:30,725 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7346595234649126, 'Total loss': 0.7346595234649126} | train loss {'Reaction outcome loss': 0.8337805665663032, 'Total loss': 0.8337805665663032}
2022-11-23 01:46:30,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:30,725 INFO:     Epoch: 65
2022-11-23 01:46:31,476 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7429089043722596, 'Total loss': 0.7429089043722596} | train loss {'Reaction outcome loss': 0.8407659331550363, 'Total loss': 0.8407659331550363}
2022-11-23 01:46:31,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:31,476 INFO:     Epoch: 66
2022-11-23 01:46:32,262 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.727935699529426, 'Total loss': 0.727935699529426} | train loss {'Reaction outcome loss': 0.8329068593314437, 'Total loss': 0.8329068593314437}
2022-11-23 01:46:32,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:32,263 INFO:     Epoch: 67
2022-11-23 01:46:33,121 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7913447382838227, 'Total loss': 0.7913447382838227} | train loss {'Reaction outcome loss': 0.835179331116989, 'Total loss': 0.835179331116989}
2022-11-23 01:46:33,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:33,121 INFO:     Epoch: 68
2022-11-23 01:46:33,961 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7394620450430138, 'Total loss': 0.7394620450430138} | train loss {'Reaction outcome loss': 0.8359180466562021, 'Total loss': 0.8359180466562021}
2022-11-23 01:46:33,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:33,961 INFO:     Epoch: 69
2022-11-23 01:46:34,738 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7314860737600992, 'Total loss': 0.7314860737600992} | train loss {'Reaction outcome loss': 0.8317613874058254, 'Total loss': 0.8317613874058254}
2022-11-23 01:46:34,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:34,738 INFO:     Epoch: 70
2022-11-23 01:46:35,524 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.754932876936225, 'Total loss': 0.754932876936225} | train loss {'Reaction outcome loss': 0.8384473814827497, 'Total loss': 0.8384473814827497}
2022-11-23 01:46:35,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:35,526 INFO:     Epoch: 71
2022-11-23 01:46:36,319 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7397982221703197, 'Total loss': 0.7397982221703197} | train loss {'Reaction outcome loss': 0.8375233056359603, 'Total loss': 0.8375233056359603}
2022-11-23 01:46:36,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:36,319 INFO:     Epoch: 72
2022-11-23 01:46:37,058 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7409795598928318, 'Total loss': 0.7409795598928318} | train loss {'Reaction outcome loss': 0.8347105670292847, 'Total loss': 0.8347105670292847}
2022-11-23 01:46:37,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:37,058 INFO:     Epoch: 73
2022-11-23 01:46:37,840 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7606709329194801, 'Total loss': 0.7606709329194801} | train loss {'Reaction outcome loss': 0.8375586976037651, 'Total loss': 0.8375586976037651}
2022-11-23 01:46:37,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:37,840 INFO:     Epoch: 74
2022-11-23 01:46:38,642 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7559898571912632, 'Total loss': 0.7559898571912632} | train loss {'Reaction outcome loss': 0.8350298437671583, 'Total loss': 0.8350298437671583}
2022-11-23 01:46:38,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:38,643 INFO:     Epoch: 75
2022-11-23 01:46:39,432 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7343945496304091, 'Total loss': 0.7343945496304091} | train loss {'Reaction outcome loss': 0.8390397701839931, 'Total loss': 0.8390397701839931}
2022-11-23 01:46:39,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:39,432 INFO:     Epoch: 76
2022-11-23 01:46:40,189 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7537324005781219, 'Total loss': 0.7537324005781219} | train loss {'Reaction outcome loss': 0.8321824624645905, 'Total loss': 0.8321824624645905}
2022-11-23 01:46:40,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:40,189 INFO:     Epoch: 77
2022-11-23 01:46:40,964 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7461337668951168, 'Total loss': 0.7461337668951168} | train loss {'Reaction outcome loss': 0.8392151574619481, 'Total loss': 0.8392151574619481}
2022-11-23 01:46:40,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:40,964 INFO:     Epoch: 78
2022-11-23 01:46:41,802 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.729212088640346, 'Total loss': 0.729212088640346} | train loss {'Reaction outcome loss': 0.8370831899467062, 'Total loss': 0.8370831899467062}
2022-11-23 01:46:41,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:41,803 INFO:     Epoch: 79
2022-11-23 01:46:42,582 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7383947642736657, 'Total loss': 0.7383947642736657} | train loss {'Reaction outcome loss': 0.8371248251346292, 'Total loss': 0.8371248251346292}
2022-11-23 01:46:42,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:42,582 INFO:     Epoch: 80
2022-11-23 01:46:43,355 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7321615052777667, 'Total loss': 0.7321615052777667} | train loss {'Reaction outcome loss': 0.8353557841943913, 'Total loss': 0.8353557841943913}
2022-11-23 01:46:43,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:43,356 INFO:     Epoch: 81
2022-11-23 01:46:44,184 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7534512350725573, 'Total loss': 0.7534512350725573} | train loss {'Reaction outcome loss': 0.8323923914891774, 'Total loss': 0.8323923914891774}
2022-11-23 01:46:44,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:44,185 INFO:     Epoch: 82
2022-11-23 01:46:44,986 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7361493859180185, 'Total loss': 0.7361493859180185} | train loss {'Reaction outcome loss': 0.8324917205533043, 'Total loss': 0.8324917205533043}
2022-11-23 01:46:44,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:44,986 INFO:     Epoch: 83
2022-11-23 01:46:45,762 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7318979952224466, 'Total loss': 0.7318979952224466} | train loss {'Reaction outcome loss': 0.8330280551167785, 'Total loss': 0.8330280551167785}
2022-11-23 01:46:45,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:45,762 INFO:     Epoch: 84
2022-11-23 01:46:46,605 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.733908228402914, 'Total loss': 0.733908228402914} | train loss {'Reaction outcome loss': 0.8345262292222898, 'Total loss': 0.8345262292222898}
2022-11-23 01:46:46,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:46,606 INFO:     Epoch: 85
2022-11-23 01:46:47,444 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7325360192808994, 'Total loss': 0.7325360192808994} | train loss {'Reaction outcome loss': 0.8333626636227623, 'Total loss': 0.8333626636227623}
2022-11-23 01:46:47,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:47,444 INFO:     Epoch: 86
2022-11-23 01:46:48,273 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7573611757089925, 'Total loss': 0.7573611757089925} | train loss {'Reaction outcome loss': 0.8366951042267142, 'Total loss': 0.8366951042267142}
2022-11-23 01:46:48,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:48,273 INFO:     Epoch: 87
2022-11-23 01:46:49,036 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7683957447839338, 'Total loss': 0.7683957447839338} | train loss {'Reaction outcome loss': 0.8392549142485759, 'Total loss': 0.8392549142485759}
2022-11-23 01:46:49,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:49,036 INFO:     Epoch: 88
2022-11-23 01:46:49,888 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7342975673287414, 'Total loss': 0.7342975673287414} | train loss {'Reaction outcome loss': 0.8348076763700266, 'Total loss': 0.8348076763700266}
2022-11-23 01:46:49,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:49,888 INFO:     Epoch: 89
2022-11-23 01:46:50,707 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7322831826154576, 'Total loss': 0.7322831826154576} | train loss {'Reaction outcome loss': 0.8337957199479713, 'Total loss': 0.8337957199479713}
2022-11-23 01:46:50,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:50,707 INFO:     Epoch: 90
2022-11-23 01:46:51,540 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7340959962024245, 'Total loss': 0.7340959962024245} | train loss {'Reaction outcome loss': 0.8335976592097126, 'Total loss': 0.8335976592097126}
2022-11-23 01:46:51,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:51,541 INFO:     Epoch: 91
2022-11-23 01:46:52,335 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7343749875246093, 'Total loss': 0.7343749875246093} | train loss {'Reaction outcome loss': 0.8332542255520821, 'Total loss': 0.8332542255520821}
2022-11-23 01:46:52,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:52,335 INFO:     Epoch: 92
2022-11-23 01:46:53,178 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7438648786655692, 'Total loss': 0.7438648786655692} | train loss {'Reaction outcome loss': 0.8333858913574063, 'Total loss': 0.8333858913574063}
2022-11-23 01:46:53,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:53,178 INFO:     Epoch: 93
2022-11-23 01:46:53,974 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7280605684879214, 'Total loss': 0.7280605684879214} | train loss {'Reaction outcome loss': 0.8312096002160526, 'Total loss': 0.8312096002160526}
2022-11-23 01:46:53,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:53,975 INFO:     Epoch: 94
2022-11-23 01:46:54,768 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7595123884289764, 'Total loss': 0.7595123884289764} | train loss {'Reaction outcome loss': 0.8391092769557336, 'Total loss': 0.8391092769557336}
2022-11-23 01:46:54,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:54,768 INFO:     Epoch: 95
2022-11-23 01:46:55,569 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7479142311007477, 'Total loss': 0.7479142311007477} | train loss {'Reaction outcome loss': 0.8359428660058584, 'Total loss': 0.8359428660058584}
2022-11-23 01:46:55,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:55,569 INFO:     Epoch: 96
2022-11-23 01:46:56,395 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7327675743158474, 'Total loss': 0.7327675743158474} | train loss {'Reaction outcome loss': 0.8329066928537165, 'Total loss': 0.8329066928537165}
2022-11-23 01:46:56,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:56,396 INFO:     Epoch: 97
2022-11-23 01:46:57,210 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7395200403623803, 'Total loss': 0.7395200403623803} | train loss {'Reaction outcome loss': 0.8375639053763914, 'Total loss': 0.8375639053763914}
2022-11-23 01:46:57,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:57,210 INFO:     Epoch: 98
2022-11-23 01:46:58,100 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.739521850680196, 'Total loss': 0.739521850680196} | train loss {'Reaction outcome loss': 0.835005557195085, 'Total loss': 0.835005557195085}
2022-11-23 01:46:58,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:58,100 INFO:     Epoch: 99
2022-11-23 01:46:58,972 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7627541305020799, 'Total loss': 0.7627541305020799} | train loss {'Reaction outcome loss': 0.8339421308187188, 'Total loss': 0.8339421308187188}
2022-11-23 01:46:58,972 INFO:     Best model found after epoch 25 of 100.
2022-11-23 01:46:58,973 INFO:   Done with stage: TRAINING
2022-11-23 01:46:58,973 INFO:   Starting stage: EVALUATION
2022-11-23 01:46:59,110 INFO:   Done with stage: EVALUATION
2022-11-23 01:46:59,110 INFO:   Leaving out SEQ value Fold_3
2022-11-23 01:46:59,124 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-23 01:46:59,124 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:46:59,802 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:46:59,802 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:46:59,876 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:46:59,876 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:46:59,876 INFO:     No hyperparam tuning for this model
2022-11-23 01:46:59,876 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:46:59,876 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:46:59,877 INFO:     None feature selector for col prot
2022-11-23 01:46:59,877 INFO:     None feature selector for col prot
2022-11-23 01:46:59,877 INFO:     None feature selector for col prot
2022-11-23 01:46:59,878 INFO:     None feature selector for col chem
2022-11-23 01:46:59,878 INFO:     None feature selector for col chem
2022-11-23 01:46:59,878 INFO:     None feature selector for col chem
2022-11-23 01:46:59,878 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:46:59,878 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:46:59,880 INFO:     Number of params in model 168571
2022-11-23 01:46:59,883 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:46:59,883 INFO:   Starting stage: TRAINING
2022-11-23 01:46:59,941 INFO:     Val loss before train {'Reaction outcome loss': 1.0114046958989875, 'Total loss': 1.0114046958989875}
2022-11-23 01:46:59,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:46:59,942 INFO:     Epoch: 0
2022-11-23 01:47:00,794 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8550384405047394, 'Total loss': 0.8550384405047394} | train loss {'Reaction outcome loss': 0.8688214123249054, 'Total loss': 0.8688214123249054}
2022-11-23 01:47:00,794 INFO:     Found new best model at epoch 0
2022-11-23 01:47:00,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:00,795 INFO:     Epoch: 1
2022-11-23 01:47:01,603 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8366129751815352, 'Total loss': 0.8366129751815352} | train loss {'Reaction outcome loss': 0.8405528388641499, 'Total loss': 0.8405528388641499}
2022-11-23 01:47:01,603 INFO:     Found new best model at epoch 1
2022-11-23 01:47:01,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:01,604 INFO:     Epoch: 2
2022-11-23 01:47:02,460 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8599041187485983, 'Total loss': 0.8599041187485983} | train loss {'Reaction outcome loss': 0.8368197888013267, 'Total loss': 0.8368197888013267}
2022-11-23 01:47:02,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:02,460 INFO:     Epoch: 3
2022-11-23 01:47:03,305 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8748202448667481, 'Total loss': 0.8748202448667481} | train loss {'Reaction outcome loss': 0.8291703261465693, 'Total loss': 0.8291703261465693}
2022-11-23 01:47:03,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:03,305 INFO:     Epoch: 4
2022-11-23 01:47:04,176 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8310836414958156, 'Total loss': 0.8310836414958156} | train loss {'Reaction outcome loss': 0.8252541202085989, 'Total loss': 0.8252541202085989}
2022-11-23 01:47:04,176 INFO:     Found new best model at epoch 4
2022-11-23 01:47:04,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:04,177 INFO:     Epoch: 5
2022-11-23 01:47:05,128 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8476517359877742, 'Total loss': 0.8476517359877742} | train loss {'Reaction outcome loss': 0.8146626202412593, 'Total loss': 0.8146626202412593}
2022-11-23 01:47:05,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:05,128 INFO:     Epoch: 6
2022-11-23 01:47:05,996 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8368093371391296, 'Total loss': 0.8368093371391296} | train loss {'Reaction outcome loss': 0.8132214980360902, 'Total loss': 0.8132214980360902}
2022-11-23 01:47:05,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:05,996 INFO:     Epoch: 7
2022-11-23 01:47:06,848 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8440056318460509, 'Total loss': 0.8440056318460509} | train loss {'Reaction outcome loss': 0.8123257518305209, 'Total loss': 0.8123257518305209}
2022-11-23 01:47:06,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:06,850 INFO:     Epoch: 8
2022-11-23 01:47:07,731 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8139936528926672, 'Total loss': 0.8139936528926672} | train loss {'Reaction outcome loss': 0.80808033769636, 'Total loss': 0.80808033769636}
2022-11-23 01:47:07,731 INFO:     Found new best model at epoch 8
2022-11-23 01:47:07,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:07,732 INFO:     Epoch: 9
2022-11-23 01:47:08,632 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8307295926781588, 'Total loss': 0.8307295926781588} | train loss {'Reaction outcome loss': 0.8084382665010146, 'Total loss': 0.8084382665010146}
2022-11-23 01:47:08,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:08,632 INFO:     Epoch: 10
2022-11-23 01:47:09,536 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8050663180129473, 'Total loss': 0.8050663180129473} | train loss {'Reaction outcome loss': 0.8076502814459703, 'Total loss': 0.8076502814459703}
2022-11-23 01:47:09,536 INFO:     Found new best model at epoch 10
2022-11-23 01:47:09,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:09,537 INFO:     Epoch: 11
2022-11-23 01:47:10,427 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8058316180872362, 'Total loss': 0.8058316180872362} | train loss {'Reaction outcome loss': 0.8015967651649758, 'Total loss': 0.8015967651649758}
2022-11-23 01:47:10,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:10,428 INFO:     Epoch: 12
2022-11-23 01:47:11,273 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.808892275704894, 'Total loss': 0.808892275704894} | train loss {'Reaction outcome loss': 0.8146134081446095, 'Total loss': 0.8146134081446095}
2022-11-23 01:47:11,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:11,274 INFO:     Epoch: 13
2022-11-23 01:47:12,175 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8454350343970365, 'Total loss': 0.8454350343970365} | train loss {'Reaction outcome loss': 0.8099458884800412, 'Total loss': 0.8099458884800412}
2022-11-23 01:47:12,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:12,176 INFO:     Epoch: 14
2022-11-23 01:47:13,070 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8063655232274255, 'Total loss': 0.8063655232274255} | train loss {'Reaction outcome loss': 0.8100457056559653, 'Total loss': 0.8100457056559653}
2022-11-23 01:47:13,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:13,071 INFO:     Epoch: 15
2022-11-23 01:47:13,996 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.818557588860046, 'Total loss': 0.818557588860046} | train loss {'Reaction outcome loss': 0.809880028413647, 'Total loss': 0.809880028413647}
2022-11-23 01:47:13,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:13,997 INFO:     Epoch: 16
2022-11-23 01:47:14,868 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8184053606765215, 'Total loss': 0.8184053606765215} | train loss {'Reaction outcome loss': 0.8042721859957456, 'Total loss': 0.8042721859957456}
2022-11-23 01:47:14,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:14,868 INFO:     Epoch: 17
2022-11-23 01:47:15,762 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8071160455082738, 'Total loss': 0.8071160455082738} | train loss {'Reaction outcome loss': 0.813693890355742, 'Total loss': 0.813693890355742}
2022-11-23 01:47:15,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:15,762 INFO:     Epoch: 18
2022-11-23 01:47:16,617 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8079734805018403, 'Total loss': 0.8079734805018403} | train loss {'Reaction outcome loss': 0.8046222164797685, 'Total loss': 0.8046222164797685}
2022-11-23 01:47:16,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:16,618 INFO:     Epoch: 19
2022-11-23 01:47:17,539 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8093315716399703, 'Total loss': 0.8093315716399703} | train loss {'Reaction outcome loss': 0.8074536268357877, 'Total loss': 0.8074536268357877}
2022-11-23 01:47:17,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:17,539 INFO:     Epoch: 20
2022-11-23 01:47:18,442 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8287629880184351, 'Total loss': 0.8287629880184351} | train loss {'Reaction outcome loss': 0.7968905943411367, 'Total loss': 0.7968905943411367}
2022-11-23 01:47:18,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:18,443 INFO:     Epoch: 21
2022-11-23 01:47:19,339 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8373989386613979, 'Total loss': 0.8373989386613979} | train loss {'Reaction outcome loss': 0.806847584468347, 'Total loss': 0.806847584468347}
2022-11-23 01:47:19,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:19,339 INFO:     Epoch: 22
2022-11-23 01:47:20,230 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8297630111838497, 'Total loss': 0.8297630111838497} | train loss {'Reaction outcome loss': 0.8035998397158006, 'Total loss': 0.8035998397158006}
2022-11-23 01:47:20,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:20,231 INFO:     Epoch: 23
2022-11-23 01:47:21,129 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7996146762093832, 'Total loss': 0.7996146762093832} | train loss {'Reaction outcome loss': 0.8045947429083993, 'Total loss': 0.8045947429083993}
2022-11-23 01:47:21,129 INFO:     Found new best model at epoch 23
2022-11-23 01:47:21,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:21,130 INFO:     Epoch: 24
2022-11-23 01:47:22,005 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8089297864326211, 'Total loss': 0.8089297864326211} | train loss {'Reaction outcome loss': 0.8040773738558891, 'Total loss': 0.8040773738558891}
2022-11-23 01:47:22,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:22,005 INFO:     Epoch: 25
2022-11-23 01:47:22,881 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8041259979092797, 'Total loss': 0.8041259979092797} | train loss {'Reaction outcome loss': 0.8067793757827194, 'Total loss': 0.8067793757827194}
2022-11-23 01:47:22,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:22,881 INFO:     Epoch: 26
2022-11-23 01:47:23,760 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8018279248891875, 'Total loss': 0.8018279248891875} | train loss {'Reaction outcome loss': 0.8050873950430395, 'Total loss': 0.8050873950430395}
2022-11-23 01:47:23,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:23,760 INFO:     Epoch: 27
2022-11-23 01:47:24,620 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8185613377149715, 'Total loss': 0.8185613377149715} | train loss {'Reaction outcome loss': 0.8035898618246793, 'Total loss': 0.8035898618246793}
2022-11-23 01:47:24,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:24,621 INFO:     Epoch: 28
2022-11-23 01:47:25,464 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8183942222317984, 'Total loss': 0.8183942222317984} | train loss {'Reaction outcome loss': 0.8091542847117279, 'Total loss': 0.8091542847117279}
2022-11-23 01:47:25,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:25,465 INFO:     Epoch: 29
2022-11-23 01:47:26,363 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8395279133042624, 'Total loss': 0.8395279133042624} | train loss {'Reaction outcome loss': 0.8028086913220677, 'Total loss': 0.8028086913220677}
2022-11-23 01:47:26,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:26,363 INFO:     Epoch: 30
2022-11-23 01:47:27,236 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8186687667702519, 'Total loss': 0.8186687667702519} | train loss {'Reaction outcome loss': 0.8001882551628866, 'Total loss': 0.8001882551628866}
2022-11-23 01:47:27,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:27,236 INFO:     Epoch: 31
2022-11-23 01:47:28,113 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8189028626264527, 'Total loss': 0.8189028626264527} | train loss {'Reaction outcome loss': 0.8028521038622523, 'Total loss': 0.8028521038622523}
2022-11-23 01:47:28,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:28,113 INFO:     Epoch: 32
2022-11-23 01:47:28,948 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8176431420237519, 'Total loss': 0.8176431420237519} | train loss {'Reaction outcome loss': 0.8034352982731022, 'Total loss': 0.8034352982731022}
2022-11-23 01:47:28,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:28,948 INFO:     Epoch: 33
2022-11-23 01:47:29,783 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8107056014759596, 'Total loss': 0.8107056014759596} | train loss {'Reaction outcome loss': 0.80201163642691, 'Total loss': 0.80201163642691}
2022-11-23 01:47:29,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:29,784 INFO:     Epoch: 34
2022-11-23 01:47:30,627 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8116073594536892, 'Total loss': 0.8116073594536892} | train loss {'Reaction outcome loss': 0.8059197520768201, 'Total loss': 0.8059197520768201}
2022-11-23 01:47:30,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:30,627 INFO:     Epoch: 35
2022-11-23 01:47:31,520 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8403253846390303, 'Total loss': 0.8403253846390303} | train loss {'Reaction outcome loss': 0.8132759130295412, 'Total loss': 0.8132759130295412}
2022-11-23 01:47:31,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:31,520 INFO:     Epoch: 36
2022-11-23 01:47:32,322 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8460479732169661, 'Total loss': 0.8460479732169661} | train loss {'Reaction outcome loss': 0.7981279937573421, 'Total loss': 0.7981279937573421}
2022-11-23 01:47:32,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:32,323 INFO:     Epoch: 37
2022-11-23 01:47:33,154 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8082779736019844, 'Total loss': 0.8082779736019844} | train loss {'Reaction outcome loss': 0.8017851279228313, 'Total loss': 0.8017851279228313}
2022-11-23 01:47:33,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:33,154 INFO:     Epoch: 38
2022-11-23 01:47:33,996 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8030587199122406, 'Total loss': 0.8030587199122406} | train loss {'Reaction outcome loss': 0.8024522513764385, 'Total loss': 0.8024522513764385}
2022-11-23 01:47:33,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:33,996 INFO:     Epoch: 39
2022-11-23 01:47:34,900 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.801223719535872, 'Total loss': 0.801223719535872} | train loss {'Reaction outcome loss': 0.7990939113093011, 'Total loss': 0.7990939113093011}
2022-11-23 01:47:34,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:34,900 INFO:     Epoch: 40
2022-11-23 01:47:35,749 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8120041309401046, 'Total loss': 0.8120041309401046} | train loss {'Reaction outcome loss': 0.7994828351731162, 'Total loss': 0.7994828351731162}
2022-11-23 01:47:35,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:35,749 INFO:     Epoch: 41
2022-11-23 01:47:36,672 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.800731735174046, 'Total loss': 0.800731735174046} | train loss {'Reaction outcome loss': 0.7997303971783124, 'Total loss': 0.7997303971783124}
2022-11-23 01:47:36,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:36,673 INFO:     Epoch: 42
2022-11-23 01:47:37,532 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8067035467125648, 'Total loss': 0.8067035467125648} | train loss {'Reaction outcome loss': 0.8007449318842633, 'Total loss': 0.8007449318842633}
2022-11-23 01:47:37,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:37,532 INFO:     Epoch: 43
2022-11-23 01:47:38,461 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8075484716615011, 'Total loss': 0.8075484716615011} | train loss {'Reaction outcome loss': 0.7990488479902715, 'Total loss': 0.7990488479902715}
2022-11-23 01:47:38,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:38,463 INFO:     Epoch: 44
2022-11-23 01:47:39,306 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8212159497793331, 'Total loss': 0.8212159497793331} | train loss {'Reaction outcome loss': 0.8056222150109923, 'Total loss': 0.8056222150109923}
2022-11-23 01:47:39,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:39,306 INFO:     Epoch: 45
2022-11-23 01:47:40,232 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8401062190532684, 'Total loss': 0.8401062190532684} | train loss {'Reaction outcome loss': 0.7988386533142607, 'Total loss': 0.7988386533142607}
2022-11-23 01:47:40,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:40,233 INFO:     Epoch: 46
2022-11-23 01:47:41,097 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8019081326418145, 'Total loss': 0.8019081326418145} | train loss {'Reaction outcome loss': 0.8054429834762228, 'Total loss': 0.8054429834762228}
2022-11-23 01:47:41,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:41,098 INFO:     Epoch: 47
2022-11-23 01:47:41,973 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8112797563852265, 'Total loss': 0.8112797563852265} | train loss {'Reaction outcome loss': 0.8010911741619738, 'Total loss': 0.8010911741619738}
2022-11-23 01:47:41,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:41,973 INFO:     Epoch: 48
2022-11-23 01:47:42,839 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8221993266150008, 'Total loss': 0.8221993266150008} | train loss {'Reaction outcome loss': 0.8022350067954985, 'Total loss': 0.8022350067954985}
2022-11-23 01:47:42,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:42,840 INFO:     Epoch: 49
2022-11-23 01:47:43,690 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8073487060014591, 'Total loss': 0.8073487060014591} | train loss {'Reaction outcome loss': 0.8002176821967701, 'Total loss': 0.8002176821967701}
2022-11-23 01:47:43,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:43,690 INFO:     Epoch: 50
2022-11-23 01:47:44,534 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8248782047005587, 'Total loss': 0.8248782047005587} | train loss {'Reaction outcome loss': 0.8068451579706168, 'Total loss': 0.8068451579706168}
2022-11-23 01:47:44,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:44,535 INFO:     Epoch: 51
2022-11-23 01:47:45,401 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8909080499826476, 'Total loss': 0.8909080499826476} | train loss {'Reaction outcome loss': 0.7992491857014565, 'Total loss': 0.7992491857014565}
2022-11-23 01:47:45,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:45,401 INFO:     Epoch: 52
2022-11-23 01:47:46,244 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8051314790581547, 'Total loss': 0.8051314790581547} | train loss {'Reaction outcome loss': 0.8052783581455059, 'Total loss': 0.8052783581455059}
2022-11-23 01:47:46,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:46,244 INFO:     Epoch: 53
2022-11-23 01:47:47,079 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8073809444904327, 'Total loss': 0.8073809444904327} | train loss {'Reaction outcome loss': 0.7989680633378127, 'Total loss': 0.7989680633378127}
2022-11-23 01:47:47,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:47,079 INFO:     Epoch: 54
2022-11-23 01:47:47,934 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8109528588694196, 'Total loss': 0.8109528588694196} | train loss {'Reaction outcome loss': 0.8046006351832009, 'Total loss': 0.8046006351832009}
2022-11-23 01:47:47,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:47,935 INFO:     Epoch: 55
2022-11-23 01:47:48,794 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7968833439571913, 'Total loss': 0.7968833439571913} | train loss {'Reaction outcome loss': 0.7958970605836484, 'Total loss': 0.7958970605836484}
2022-11-23 01:47:48,794 INFO:     Found new best model at epoch 55
2022-11-23 01:47:48,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:48,795 INFO:     Epoch: 56
2022-11-23 01:47:49,606 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8021682355293008, 'Total loss': 0.8021682355293008} | train loss {'Reaction outcome loss': 0.79912447880325, 'Total loss': 0.79912447880325}
2022-11-23 01:47:49,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:49,607 INFO:     Epoch: 57
2022-11-23 01:47:50,467 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.803761365801789, 'Total loss': 0.803761365801789} | train loss {'Reaction outcome loss': 0.8083949008105714, 'Total loss': 0.8083949008105714}
2022-11-23 01:47:50,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:50,467 INFO:     Epoch: 58
2022-11-23 01:47:51,304 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8091196889101073, 'Total loss': 0.8091196889101073} | train loss {'Reaction outcome loss': 0.8025993176203206, 'Total loss': 0.8025993176203206}
2022-11-23 01:47:51,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:51,304 INFO:     Epoch: 59
2022-11-23 01:47:52,134 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8000597524088483, 'Total loss': 0.8000597524088483} | train loss {'Reaction outcome loss': 0.8017998892093392, 'Total loss': 0.8017998892093392}
2022-11-23 01:47:52,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:52,134 INFO:     Epoch: 60
2022-11-23 01:47:52,966 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.801112023203872, 'Total loss': 0.801112023203872} | train loss {'Reaction outcome loss': 0.7969862721829748, 'Total loss': 0.7969862721829748}
2022-11-23 01:47:52,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:52,966 INFO:     Epoch: 61
2022-11-23 01:47:53,773 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8377157761607059, 'Total loss': 0.8377157761607059} | train loss {'Reaction outcome loss': 0.7983159861937472, 'Total loss': 0.7983159861937472}
2022-11-23 01:47:53,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:53,774 INFO:     Epoch: 62
2022-11-23 01:47:54,562 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8008183947829313, 'Total loss': 0.8008183947829313} | train loss {'Reaction outcome loss': 0.801033950268977, 'Total loss': 0.801033950268977}
2022-11-23 01:47:54,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:54,562 INFO:     Epoch: 63
2022-11-23 01:47:55,355 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8288128272045491, 'Total loss': 0.8288128272045491} | train loss {'Reaction outcome loss': 0.7979985869838377, 'Total loss': 0.7979985869838377}
2022-11-23 01:47:55,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:55,355 INFO:     Epoch: 64
2022-11-23 01:47:56,166 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8263052819773208, 'Total loss': 0.8263052819773208} | train loss {'Reaction outcome loss': 0.7993241046927103, 'Total loss': 0.7993241046927103}
2022-11-23 01:47:56,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:56,166 INFO:     Epoch: 65
2022-11-23 01:47:57,020 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.818308365899463, 'Total loss': 0.818308365899463} | train loss {'Reaction outcome loss': 0.8051000027744858, 'Total loss': 0.8051000027744858}
2022-11-23 01:47:57,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:57,021 INFO:     Epoch: 66
2022-11-23 01:47:57,922 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8074012724466102, 'Total loss': 0.8074012724466102} | train loss {'Reaction outcome loss': 0.7995926796654125, 'Total loss': 0.7995926796654125}
2022-11-23 01:47:57,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:57,922 INFO:     Epoch: 67
2022-11-23 01:47:58,775 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8041817282521447, 'Total loss': 0.8041817282521447} | train loss {'Reaction outcome loss': 0.8012219111860535, 'Total loss': 0.8012219111860535}
2022-11-23 01:47:58,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:58,776 INFO:     Epoch: 68
2022-11-23 01:47:59,650 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7939672033454097, 'Total loss': 0.7939672033454097} | train loss {'Reaction outcome loss': 0.7999571899082435, 'Total loss': 0.7999571899082435}
2022-11-23 01:47:59,650 INFO:     Found new best model at epoch 68
2022-11-23 01:47:59,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:47:59,651 INFO:     Epoch: 69
2022-11-23 01:48:00,520 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8371882937675299, 'Total loss': 0.8371882937675299} | train loss {'Reaction outcome loss': 0.7973996667582312, 'Total loss': 0.7973996667582312}
2022-11-23 01:48:00,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:00,520 INFO:     Epoch: 70
2022-11-23 01:48:01,362 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8024939021398855, 'Total loss': 0.8024939021398855} | train loss {'Reaction outcome loss': 0.8054702739411421, 'Total loss': 0.8054702739411421}
2022-11-23 01:48:01,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:01,363 INFO:     Epoch: 71
2022-11-23 01:48:02,203 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8180986379468164, 'Total loss': 0.8180986379468164} | train loss {'Reaction outcome loss': 0.8042491126207658, 'Total loss': 0.8042491126207658}
2022-11-23 01:48:02,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:02,203 INFO:     Epoch: 72
2022-11-23 01:48:03,016 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8373416440431461, 'Total loss': 0.8373416440431461} | train loss {'Reaction outcome loss': 0.8008494597894175, 'Total loss': 0.8008494597894175}
2022-11-23 01:48:03,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:03,017 INFO:     Epoch: 73
2022-11-23 01:48:03,827 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8278102528217227, 'Total loss': 0.8278102528217227} | train loss {'Reaction outcome loss': 0.7995232291550303, 'Total loss': 0.7995232291550303}
2022-11-23 01:48:03,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:03,827 INFO:     Epoch: 74
2022-11-23 01:48:04,632 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8296714529048564, 'Total loss': 0.8296714529048564} | train loss {'Reaction outcome loss': 0.7949831112912653, 'Total loss': 0.7949831112912653}
2022-11-23 01:48:04,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:04,633 INFO:     Epoch: 75
2022-11-23 01:48:05,426 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.80379797344984, 'Total loss': 0.80379797344984} | train loss {'Reaction outcome loss': 0.7996622252856753, 'Total loss': 0.7996622252856753}
2022-11-23 01:48:05,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:05,427 INFO:     Epoch: 76
2022-11-23 01:48:06,239 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8110625951789147, 'Total loss': 0.8110625951789147} | train loss {'Reaction outcome loss': 0.8001015085742307, 'Total loss': 0.8001015085742307}
2022-11-23 01:48:06,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:06,239 INFO:     Epoch: 77
2022-11-23 01:48:07,074 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.816690570393274, 'Total loss': 0.816690570393274} | train loss {'Reaction outcome loss': 0.7970046736453296, 'Total loss': 0.7970046736453296}
2022-11-23 01:48:07,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:07,075 INFO:     Epoch: 78
2022-11-23 01:48:07,935 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8270810191021409, 'Total loss': 0.8270810191021409} | train loss {'Reaction outcome loss': 0.8008501947907264, 'Total loss': 0.8008501947907264}
2022-11-23 01:48:07,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:07,935 INFO:     Epoch: 79
2022-11-23 01:48:08,725 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8005245535872704, 'Total loss': 0.8005245535872704} | train loss {'Reaction outcome loss': 0.8038420272462162, 'Total loss': 0.8038420272462162}
2022-11-23 01:48:08,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:08,725 INFO:     Epoch: 80
2022-11-23 01:48:09,523 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8175856595815614, 'Total loss': 0.8175856595815614} | train loss {'Reaction outcome loss': 0.8007073207401935, 'Total loss': 0.8007073207401935}
2022-11-23 01:48:09,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:09,524 INFO:     Epoch: 81
2022-11-23 01:48:10,289 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8054608726917312, 'Total loss': 0.8054608726917312} | train loss {'Reaction outcome loss': 0.8008788295488789, 'Total loss': 0.8008788295488789}
2022-11-23 01:48:10,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:10,290 INFO:     Epoch: 82
2022-11-23 01:48:11,077 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8016768686993178, 'Total loss': 0.8016768686993178} | train loss {'Reaction outcome loss': 0.801495799679815, 'Total loss': 0.801495799679815}
2022-11-23 01:48:11,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:11,077 INFO:     Epoch: 83
2022-11-23 01:48:11,833 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8088047573732775, 'Total loss': 0.8088047573732775} | train loss {'Reaction outcome loss': 0.8020734546606433, 'Total loss': 0.8020734546606433}
2022-11-23 01:48:11,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:11,834 INFO:     Epoch: 84
2022-11-23 01:48:12,610 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8084339468285094, 'Total loss': 0.8084339468285094} | train loss {'Reaction outcome loss': 0.7985054095095567, 'Total loss': 0.7985054095095567}
2022-11-23 01:48:12,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:12,611 INFO:     Epoch: 85
2022-11-23 01:48:13,381 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8052374069080797, 'Total loss': 0.8052374069080797} | train loss {'Reaction outcome loss': 0.8034194541075592, 'Total loss': 0.8034194541075592}
2022-11-23 01:48:13,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:13,381 INFO:     Epoch: 86
2022-11-23 01:48:14,134 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8010384080021881, 'Total loss': 0.8010384080021881} | train loss {'Reaction outcome loss': 0.802592541700528, 'Total loss': 0.802592541700528}
2022-11-23 01:48:14,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:14,134 INFO:     Epoch: 87
2022-11-23 01:48:14,898 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8157448567623315, 'Total loss': 0.8157448567623315} | train loss {'Reaction outcome loss': 0.8019307577070386, 'Total loss': 0.8019307577070386}
2022-11-23 01:48:14,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:14,898 INFO:     Epoch: 88
2022-11-23 01:48:15,645 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8075127005577087, 'Total loss': 0.8075127005577087} | train loss {'Reaction outcome loss': 0.8007779959665895, 'Total loss': 0.8007779959665895}
2022-11-23 01:48:15,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:15,646 INFO:     Epoch: 89
2022-11-23 01:48:16,387 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8059817608012709, 'Total loss': 0.8059817608012709} | train loss {'Reaction outcome loss': 0.8032488862182868, 'Total loss': 0.8032488862182868}
2022-11-23 01:48:16,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:16,388 INFO:     Epoch: 90
2022-11-23 01:48:17,152 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7969435529653416, 'Total loss': 0.7969435529653416} | train loss {'Reaction outcome loss': 0.8003909142664921, 'Total loss': 0.8003909142664921}
2022-11-23 01:48:17,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:17,152 INFO:     Epoch: 91
2022-11-23 01:48:17,908 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.802535590737365, 'Total loss': 0.802535590737365} | train loss {'Reaction outcome loss': 0.7985275577861095, 'Total loss': 0.7985275577861095}
2022-11-23 01:48:17,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:17,908 INFO:     Epoch: 92
2022-11-23 01:48:18,663 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.802321711251902, 'Total loss': 0.802321711251902} | train loss {'Reaction outcome loss': 0.8001613222031927, 'Total loss': 0.8001613222031927}
2022-11-23 01:48:18,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:18,664 INFO:     Epoch: 93
2022-11-23 01:48:19,484 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7973826832549517, 'Total loss': 0.7973826832549517} | train loss {'Reaction outcome loss': 0.7994089342439126, 'Total loss': 0.7994089342439126}
2022-11-23 01:48:19,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:19,484 INFO:     Epoch: 94
2022-11-23 01:48:20,243 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8119943765706794, 'Total loss': 0.8119943765706794} | train loss {'Reaction outcome loss': 0.8031315614657147, 'Total loss': 0.8031315614657147}
2022-11-23 01:48:20,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:20,243 INFO:     Epoch: 95
2022-11-23 01:48:20,995 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8046200531859731, 'Total loss': 0.8046200531859731} | train loss {'Reaction outcome loss': 0.8076828401765705, 'Total loss': 0.8076828401765705}
2022-11-23 01:48:20,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:20,995 INFO:     Epoch: 96
2022-11-23 01:48:21,773 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8006410688854927, 'Total loss': 0.8006410688854927} | train loss {'Reaction outcome loss': 0.7976028957239394, 'Total loss': 0.7976028957239394}
2022-11-23 01:48:21,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:21,774 INFO:     Epoch: 97
2022-11-23 01:48:22,528 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8112616130085879, 'Total loss': 0.8112616130085879} | train loss {'Reaction outcome loss': 0.7944098170310137, 'Total loss': 0.7944098170310137}
2022-11-23 01:48:22,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:22,528 INFO:     Epoch: 98
2022-11-23 01:48:23,317 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8047697946082714, 'Total loss': 0.8047697946082714} | train loss {'Reaction outcome loss': 0.8003874883484938, 'Total loss': 0.8003874883484938}
2022-11-23 01:48:23,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:23,317 INFO:     Epoch: 99
2022-11-23 01:48:24,073 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8142201297504957, 'Total loss': 0.8142201297504957} | train loss {'Reaction outcome loss': 0.7987841443760405, 'Total loss': 0.7987841443760405}
2022-11-23 01:48:24,074 INFO:     Best model found after epoch 69 of 100.
2022-11-23 01:48:24,074 INFO:   Done with stage: TRAINING
2022-11-23 01:48:24,074 INFO:   Starting stage: EVALUATION
2022-11-23 01:48:24,218 INFO:   Done with stage: EVALUATION
2022-11-23 01:48:24,219 INFO:   Leaving out SEQ value Fold_4
2022-11-23 01:48:24,232 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:48:24,232 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:48:24,897 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:48:24,898 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:48:24,969 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:48:24,969 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:48:24,970 INFO:     No hyperparam tuning for this model
2022-11-23 01:48:24,970 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:48:24,970 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:48:24,970 INFO:     None feature selector for col prot
2022-11-23 01:48:24,971 INFO:     None feature selector for col prot
2022-11-23 01:48:24,971 INFO:     None feature selector for col prot
2022-11-23 01:48:24,971 INFO:     None feature selector for col chem
2022-11-23 01:48:24,971 INFO:     None feature selector for col chem
2022-11-23 01:48:24,972 INFO:     None feature selector for col chem
2022-11-23 01:48:24,972 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:48:24,972 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:48:24,973 INFO:     Number of params in model 168571
2022-11-23 01:48:24,976 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:48:24,976 INFO:   Starting stage: TRAINING
2022-11-23 01:48:25,034 INFO:     Val loss before train {'Reaction outcome loss': 1.019727731292898, 'Total loss': 1.019727731292898}
2022-11-23 01:48:25,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:25,034 INFO:     Epoch: 0
2022-11-23 01:48:25,842 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8465703759681095, 'Total loss': 0.8465703759681095} | train loss {'Reaction outcome loss': 0.8789710313202399, 'Total loss': 0.8789710313202399}
2022-11-23 01:48:25,842 INFO:     Found new best model at epoch 0
2022-11-23 01:48:25,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:25,843 INFO:     Epoch: 1
2022-11-23 01:48:26,676 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8758742714470084, 'Total loss': 0.8758742714470084} | train loss {'Reaction outcome loss': 0.8387623615110451, 'Total loss': 0.8387623615110451}
2022-11-23 01:48:26,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:26,676 INFO:     Epoch: 2
2022-11-23 01:48:27,445 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8431243232705377, 'Total loss': 0.8431243232705377} | train loss {'Reaction outcome loss': 0.8310926957169043, 'Total loss': 0.8310926957169043}
2022-11-23 01:48:27,445 INFO:     Found new best model at epoch 2
2022-11-23 01:48:27,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:27,446 INFO:     Epoch: 3
2022-11-23 01:48:28,277 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8574947308410298, 'Total loss': 0.8574947308410298} | train loss {'Reaction outcome loss': 0.8357683088977327, 'Total loss': 0.8357683088977327}
2022-11-23 01:48:28,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:28,277 INFO:     Epoch: 4
2022-11-23 01:48:29,112 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8404393968257037, 'Total loss': 0.8404393968257037} | train loss {'Reaction outcome loss': 0.8332950106033912, 'Total loss': 0.8332950106033912}
2022-11-23 01:48:29,112 INFO:     Found new best model at epoch 4
2022-11-23 01:48:29,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:29,113 INFO:     Epoch: 5
2022-11-23 01:48:29,932 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8476509119976651, 'Total loss': 0.8476509119976651} | train loss {'Reaction outcome loss': 0.8246421353054433, 'Total loss': 0.8246421353054433}
2022-11-23 01:48:29,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:29,932 INFO:     Epoch: 6
2022-11-23 01:48:30,744 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8404524834318594, 'Total loss': 0.8404524834318594} | train loss {'Reaction outcome loss': 0.8173108250506012, 'Total loss': 0.8173108250506012}
2022-11-23 01:48:30,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:30,745 INFO:     Epoch: 7
2022-11-23 01:48:31,551 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.853314376690171, 'Total loss': 0.853314376690171} | train loss {'Reaction outcome loss': 0.8175159408013347, 'Total loss': 0.8175159408013347}
2022-11-23 01:48:31,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:31,551 INFO:     Epoch: 8
2022-11-23 01:48:32,353 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8468101769685745, 'Total loss': 0.8468101769685745} | train loss {'Reaction outcome loss': 0.8179705233467736, 'Total loss': 0.8179705233467736}
2022-11-23 01:48:32,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:32,353 INFO:     Epoch: 9
2022-11-23 01:48:33,169 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8449745069850575, 'Total loss': 0.8449745069850575} | train loss {'Reaction outcome loss': 0.8192537443840552, 'Total loss': 0.8192537443840552}
2022-11-23 01:48:33,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:33,169 INFO:     Epoch: 10
2022-11-23 01:48:33,991 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8530124520713632, 'Total loss': 0.8530124520713632} | train loss {'Reaction outcome loss': 0.8154306651549301, 'Total loss': 0.8154306651549301}
2022-11-23 01:48:33,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:33,991 INFO:     Epoch: 11
2022-11-23 01:48:34,769 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8726702616973356, 'Total loss': 0.8726702616973356} | train loss {'Reaction outcome loss': 0.8175871561654666, 'Total loss': 0.8175871561654666}
2022-11-23 01:48:34,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:34,769 INFO:     Epoch: 12
2022-11-23 01:48:35,583 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8478767668659036, 'Total loss': 0.8478767668659036} | train loss {'Reaction outcome loss': 0.8247251228282326, 'Total loss': 0.8247251228282326}
2022-11-23 01:48:35,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:35,583 INFO:     Epoch: 13
2022-11-23 01:48:36,384 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8484445092352954, 'Total loss': 0.8484445092352954} | train loss {'Reaction outcome loss': 0.8165188916781654, 'Total loss': 0.8165188916781654}
2022-11-23 01:48:36,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:36,384 INFO:     Epoch: 14
2022-11-23 01:48:37,199 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8387297120961276, 'Total loss': 0.8387297120961276} | train loss {'Reaction outcome loss': 0.8140544207231236, 'Total loss': 0.8140544207231236}
2022-11-23 01:48:37,200 INFO:     Found new best model at epoch 14
2022-11-23 01:48:37,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:37,200 INFO:     Epoch: 15
2022-11-23 01:48:38,017 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8355842605233192, 'Total loss': 0.8355842605233192} | train loss {'Reaction outcome loss': 0.8206700986696158, 'Total loss': 0.8206700986696158}
2022-11-23 01:48:38,017 INFO:     Found new best model at epoch 15
2022-11-23 01:48:38,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:38,018 INFO:     Epoch: 16
2022-11-23 01:48:38,829 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8474710935896094, 'Total loss': 0.8474710935896094} | train loss {'Reaction outcome loss': 0.8140306412449733, 'Total loss': 0.8140306412449733}
2022-11-23 01:48:38,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:38,830 INFO:     Epoch: 17
2022-11-23 01:48:39,630 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8456837683916092, 'Total loss': 0.8456837683916092} | train loss {'Reaction outcome loss': 0.8145050398009991, 'Total loss': 0.8145050398009991}
2022-11-23 01:48:39,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:39,630 INFO:     Epoch: 18
2022-11-23 01:48:40,444 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8270393217151816, 'Total loss': 0.8270393217151816} | train loss {'Reaction outcome loss': 0.8182920427457524, 'Total loss': 0.8182920427457524}
2022-11-23 01:48:40,444 INFO:     Found new best model at epoch 18
2022-11-23 01:48:40,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:40,445 INFO:     Epoch: 19
2022-11-23 01:48:41,281 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8733641335910017, 'Total loss': 0.8733641335910017} | train loss {'Reaction outcome loss': 0.8229937257795681, 'Total loss': 0.8229937257795681}
2022-11-23 01:48:41,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:41,282 INFO:     Epoch: 20
2022-11-23 01:48:42,089 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8393941779028286, 'Total loss': 0.8393941779028286} | train loss {'Reaction outcome loss': 0.8178645701784837, 'Total loss': 0.8178645701784837}
2022-11-23 01:48:42,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:42,089 INFO:     Epoch: 21
2022-11-23 01:48:42,849 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8497967747124758, 'Total loss': 0.8497967747124758} | train loss {'Reaction outcome loss': 0.8169368956132457, 'Total loss': 0.8169368956132457}
2022-11-23 01:48:42,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:42,849 INFO:     Epoch: 22
2022-11-23 01:48:43,626 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8532043871554461, 'Total loss': 0.8532043871554461} | train loss {'Reaction outcome loss': 0.8230755277249494, 'Total loss': 0.8230755277249494}
2022-11-23 01:48:43,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:43,627 INFO:     Epoch: 23
2022-11-23 01:48:44,382 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8379739665172317, 'Total loss': 0.8379739665172317} | train loss {'Reaction outcome loss': 0.8146477610717419, 'Total loss': 0.8146477610717419}
2022-11-23 01:48:44,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:44,383 INFO:     Epoch: 24
2022-11-23 01:48:45,156 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8359255939722061, 'Total loss': 0.8359255939722061} | train loss {'Reaction outcome loss': 0.8222903859036171, 'Total loss': 0.8222903859036171}
2022-11-23 01:48:45,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:45,157 INFO:     Epoch: 25
2022-11-23 01:48:45,936 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8452943035147407, 'Total loss': 0.8452943035147407} | train loss {'Reaction outcome loss': 0.809900446941978, 'Total loss': 0.809900446941978}
2022-11-23 01:48:45,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:45,936 INFO:     Epoch: 26
2022-11-23 01:48:46,702 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8270026066086509, 'Total loss': 0.8270026066086509} | train loss {'Reaction outcome loss': 0.8217433952850851, 'Total loss': 0.8217433952850851}
2022-11-23 01:48:46,702 INFO:     Found new best model at epoch 26
2022-11-23 01:48:46,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:46,703 INFO:     Epoch: 27
2022-11-23 01:48:47,474 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8358403512022712, 'Total loss': 0.8358403512022712} | train loss {'Reaction outcome loss': 0.8082410465126578, 'Total loss': 0.8082410465126578}
2022-11-23 01:48:47,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:47,475 INFO:     Epoch: 28
2022-11-23 01:48:48,299 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8461141559210691, 'Total loss': 0.8461141559210691} | train loss {'Reaction outcome loss': 0.8098987595966229, 'Total loss': 0.8098987595966229}
2022-11-23 01:48:48,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:48,299 INFO:     Epoch: 29
2022-11-23 01:48:49,097 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8426471101966772, 'Total loss': 0.8426471101966772} | train loss {'Reaction outcome loss': 0.8145216480199142, 'Total loss': 0.8145216480199142}
2022-11-23 01:48:49,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:49,097 INFO:     Epoch: 30
2022-11-23 01:48:49,875 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8538680848750201, 'Total loss': 0.8538680848750201} | train loss {'Reaction outcome loss': 0.8079346961941314, 'Total loss': 0.8079346961941314}
2022-11-23 01:48:49,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:49,875 INFO:     Epoch: 31
2022-11-23 01:48:50,646 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.86249056187543, 'Total loss': 0.86249056187543} | train loss {'Reaction outcome loss': 0.8086526665369026, 'Total loss': 0.8086526665369026}
2022-11-23 01:48:50,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:50,647 INFO:     Epoch: 32
2022-11-23 01:48:51,447 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8524528782476078, 'Total loss': 0.8524528782476078} | train loss {'Reaction outcome loss': 0.8072442441862001, 'Total loss': 0.8072442441862001}
2022-11-23 01:48:51,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:51,447 INFO:     Epoch: 33
2022-11-23 01:48:52,220 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.82846422764388, 'Total loss': 0.82846422764388} | train loss {'Reaction outcome loss': 0.8104561853264025, 'Total loss': 0.8104561853264025}
2022-11-23 01:48:52,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:52,220 INFO:     Epoch: 34
2022-11-23 01:48:52,986 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8338610672137954, 'Total loss': 0.8338610672137954} | train loss {'Reaction outcome loss': 0.8182157051225423, 'Total loss': 0.8182157051225423}
2022-11-23 01:48:52,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:52,986 INFO:     Epoch: 35
2022-11-23 01:48:53,767 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.848021000623703, 'Total loss': 0.848021000623703} | train loss {'Reaction outcome loss': 0.8149315643648387, 'Total loss': 0.8149315643648387}
2022-11-23 01:48:53,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:53,767 INFO:     Epoch: 36
2022-11-23 01:48:54,580 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8317100798541849, 'Total loss': 0.8317100798541849} | train loss {'Reaction outcome loss': 0.8140710994058292, 'Total loss': 0.8140710994058292}
2022-11-23 01:48:54,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:54,580 INFO:     Epoch: 37
2022-11-23 01:48:55,370 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8455076366662979, 'Total loss': 0.8455076366662979} | train loss {'Reaction outcome loss': 0.8174589158069749, 'Total loss': 0.8174589158069749}
2022-11-23 01:48:55,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:55,370 INFO:     Epoch: 38
2022-11-23 01:48:56,165 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8426446643742648, 'Total loss': 0.8426446643742648} | train loss {'Reaction outcome loss': 0.8151802486977596, 'Total loss': 0.8151802486977596}
2022-11-23 01:48:56,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:56,165 INFO:     Epoch: 39
2022-11-23 01:48:56,962 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8469829505140131, 'Total loss': 0.8469829505140131} | train loss {'Reaction outcome loss': 0.8144745119670143, 'Total loss': 0.8144745119670143}
2022-11-23 01:48:56,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:56,962 INFO:     Epoch: 40
2022-11-23 01:48:57,799 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8287305398420854, 'Total loss': 0.8287305398420854} | train loss {'Reaction outcome loss': 0.8111784061198293, 'Total loss': 0.8111784061198293}
2022-11-23 01:48:57,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:57,799 INFO:     Epoch: 41
2022-11-23 01:48:58,599 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8217338560657068, 'Total loss': 0.8217338560657068} | train loss {'Reaction outcome loss': 0.8145350574964454, 'Total loss': 0.8145350574964454}
2022-11-23 01:48:58,599 INFO:     Found new best model at epoch 41
2022-11-23 01:48:58,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:58,600 INFO:     Epoch: 42
2022-11-23 01:48:59,417 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8336306309158151, 'Total loss': 0.8336306309158151} | train loss {'Reaction outcome loss': 0.8146965862044439, 'Total loss': 0.8146965862044439}
2022-11-23 01:48:59,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:48:59,417 INFO:     Epoch: 43
2022-11-23 01:49:00,210 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8310399028387937, 'Total loss': 0.8310399028387937} | train loss {'Reaction outcome loss': 0.814103385576835, 'Total loss': 0.814103385576835}
2022-11-23 01:49:00,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:00,211 INFO:     Epoch: 44
2022-11-23 01:49:01,015 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8459186012094672, 'Total loss': 0.8459186012094672} | train loss {'Reaction outcome loss': 0.8081847263975181, 'Total loss': 0.8081847263975181}
2022-11-23 01:49:01,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:01,016 INFO:     Epoch: 45
2022-11-23 01:49:01,780 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8238174813714895, 'Total loss': 0.8238174813714895} | train loss {'Reaction outcome loss': 0.8071021832193923, 'Total loss': 0.8071021832193923}
2022-11-23 01:49:01,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:01,780 INFO:     Epoch: 46
2022-11-23 01:49:02,545 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8483860492706299, 'Total loss': 0.8483860492706299} | train loss {'Reaction outcome loss': 0.8075347699617085, 'Total loss': 0.8075347699617085}
2022-11-23 01:49:02,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:02,546 INFO:     Epoch: 47
2022-11-23 01:49:03,310 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8287443694743243, 'Total loss': 0.8287443694743243} | train loss {'Reaction outcome loss': 0.8111920228853882, 'Total loss': 0.8111920228853882}
2022-11-23 01:49:03,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:03,310 INFO:     Epoch: 48
2022-11-23 01:49:04,090 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8422630347988822, 'Total loss': 0.8422630347988822} | train loss {'Reaction outcome loss': 0.8206806613607445, 'Total loss': 0.8206806613607445}
2022-11-23 01:49:04,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:04,090 INFO:     Epoch: 49
2022-11-23 01:49:04,849 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8382703905755823, 'Total loss': 0.8382703905755823} | train loss {'Reaction outcome loss': 0.8200764472667987, 'Total loss': 0.8200764472667987}
2022-11-23 01:49:04,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:04,849 INFO:     Epoch: 50
2022-11-23 01:49:05,614 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8248613381927664, 'Total loss': 0.8248613381927664} | train loss {'Reaction outcome loss': 0.81686353306418, 'Total loss': 0.81686353306418}
2022-11-23 01:49:05,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:05,615 INFO:     Epoch: 51
2022-11-23 01:49:06,392 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8711087473414161, 'Total loss': 0.8711087473414161} | train loss {'Reaction outcome loss': 0.8060727041018637, 'Total loss': 0.8060727041018637}
2022-11-23 01:49:06,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:06,392 INFO:     Epoch: 52
2022-11-23 01:49:07,147 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.846982177008282, 'Total loss': 0.846982177008282} | train loss {'Reaction outcome loss': 0.8185090130639945, 'Total loss': 0.8185090130639945}
2022-11-23 01:49:07,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:07,147 INFO:     Epoch: 53
2022-11-23 01:49:07,937 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8520757000554692, 'Total loss': 0.8520757000554692} | train loss {'Reaction outcome loss': 0.824174340195984, 'Total loss': 0.824174340195984}
2022-11-23 01:49:07,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:07,937 INFO:     Epoch: 54
2022-11-23 01:49:08,700 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8410522910681638, 'Total loss': 0.8410522910681638} | train loss {'Reaction outcome loss': 0.8138023944277513, 'Total loss': 0.8138023944277513}
2022-11-23 01:49:08,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:08,700 INFO:     Epoch: 55
2022-11-23 01:49:09,485 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8484335203062404, 'Total loss': 0.8484335203062404} | train loss {'Reaction outcome loss': 0.8121334414491769, 'Total loss': 0.8121334414491769}
2022-11-23 01:49:09,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:09,485 INFO:     Epoch: 56
2022-11-23 01:49:10,281 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8317333202470433, 'Total loss': 0.8317333202470433} | train loss {'Reaction outcome loss': 0.815373437848651, 'Total loss': 0.815373437848651}
2022-11-23 01:49:10,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:10,281 INFO:     Epoch: 57
2022-11-23 01:49:11,080 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8369974060492082, 'Total loss': 0.8369974060492082} | train loss {'Reaction outcome loss': 0.8201788748324159, 'Total loss': 0.8201788748324159}
2022-11-23 01:49:11,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:11,081 INFO:     Epoch: 58
2022-11-23 01:49:11,849 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8204424157738686, 'Total loss': 0.8204424157738686} | train loss {'Reaction outcome loss': 0.8109388342391142, 'Total loss': 0.8109388342391142}
2022-11-23 01:49:11,850 INFO:     Found new best model at epoch 58
2022-11-23 01:49:11,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:11,851 INFO:     Epoch: 59
2022-11-23 01:49:12,632 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8198665637861599, 'Total loss': 0.8198665637861599} | train loss {'Reaction outcome loss': 0.8072605637403635, 'Total loss': 0.8072605637403635}
2022-11-23 01:49:12,632 INFO:     Found new best model at epoch 59
2022-11-23 01:49:12,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:12,633 INFO:     Epoch: 60
2022-11-23 01:49:13,392 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8364233489740979, 'Total loss': 0.8364233489740979} | train loss {'Reaction outcome loss': 0.8128674049609104, 'Total loss': 0.8128674049609104}
2022-11-23 01:49:13,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:13,393 INFO:     Epoch: 61
2022-11-23 01:49:14,189 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8302433280782267, 'Total loss': 0.8302433280782267} | train loss {'Reaction outcome loss': 0.8123554457054447, 'Total loss': 0.8123554457054447}
2022-11-23 01:49:14,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:14,189 INFO:     Epoch: 62
2022-11-23 01:49:14,960 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8935395872051065, 'Total loss': 0.8935395872051065} | train loss {'Reaction outcome loss': 0.8124920051348837, 'Total loss': 0.8124920051348837}
2022-11-23 01:49:14,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:14,961 INFO:     Epoch: 63
2022-11-23 01:49:15,750 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8259504579684951, 'Total loss': 0.8259504579684951} | train loss {'Reaction outcome loss': 0.8078845204777925, 'Total loss': 0.8078845204777925}
2022-11-23 01:49:15,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:15,750 INFO:     Epoch: 64
2022-11-23 01:49:16,518 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8243933543562889, 'Total loss': 0.8243933543562889} | train loss {'Reaction outcome loss': 0.8050909272813604, 'Total loss': 0.8050909272813604}
2022-11-23 01:49:16,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:16,518 INFO:     Epoch: 65
2022-11-23 01:49:17,313 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8276495472951368, 'Total loss': 0.8276495472951368} | train loss {'Reaction outcome loss': 0.8060612300870872, 'Total loss': 0.8060612300870872}
2022-11-23 01:49:17,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:17,313 INFO:     Epoch: 66
2022-11-23 01:49:18,100 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8345745639367537, 'Total loss': 0.8345745639367537} | train loss {'Reaction outcome loss': 0.8046254277349967, 'Total loss': 0.8046254277349967}
2022-11-23 01:49:18,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:18,101 INFO:     Epoch: 67
2022-11-23 01:49:18,885 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8263595815409314, 'Total loss': 0.8263595815409314} | train loss {'Reaction outcome loss': 0.8038746622892526, 'Total loss': 0.8038746622892526}
2022-11-23 01:49:18,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:18,886 INFO:     Epoch: 68
2022-11-23 01:49:19,658 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8283700150522318, 'Total loss': 0.8283700150522318} | train loss {'Reaction outcome loss': 0.8142037727089546, 'Total loss': 0.8142037727089546}
2022-11-23 01:49:19,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:19,658 INFO:     Epoch: 69
2022-11-23 01:49:20,437 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8522303835912184, 'Total loss': 0.8522303835912184} | train loss {'Reaction outcome loss': 0.8081664871349026, 'Total loss': 0.8081664871349026}
2022-11-23 01:49:20,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:20,438 INFO:     Epoch: 70
2022-11-23 01:49:21,205 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8375433575023304, 'Total loss': 0.8375433575023304} | train loss {'Reaction outcome loss': 0.8079718910610145, 'Total loss': 0.8079718910610145}
2022-11-23 01:49:21,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:21,205 INFO:     Epoch: 71
2022-11-23 01:49:22,013 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8324047083204443, 'Total loss': 0.8324047083204443} | train loss {'Reaction outcome loss': 0.8054256015702298, 'Total loss': 0.8054256015702298}
2022-11-23 01:49:22,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:22,014 INFO:     Epoch: 72
2022-11-23 01:49:22,807 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8446419577706944, 'Total loss': 0.8446419577706944} | train loss {'Reaction outcome loss': 0.8111070954365286, 'Total loss': 0.8111070954365286}
2022-11-23 01:49:22,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:22,808 INFO:     Epoch: 73
2022-11-23 01:49:23,599 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8431851735169237, 'Total loss': 0.8431851735169237} | train loss {'Reaction outcome loss': 0.8111602122243117, 'Total loss': 0.8111602122243117}
2022-11-23 01:49:23,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:23,600 INFO:     Epoch: 74
2022-11-23 01:49:24,376 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.837604131210934, 'Total loss': 0.837604131210934} | train loss {'Reaction outcome loss': 0.804468071925254, 'Total loss': 0.804468071925254}
2022-11-23 01:49:24,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:24,377 INFO:     Epoch: 75
2022-11-23 01:49:25,128 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8276513760740106, 'Total loss': 0.8276513760740106} | train loss {'Reaction outcome loss': 0.8094607563877878, 'Total loss': 0.8094607563877878}
2022-11-23 01:49:25,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:25,128 INFO:     Epoch: 76
2022-11-23 01:49:25,964 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8503533073446967, 'Total loss': 0.8503533073446967} | train loss {'Reaction outcome loss': 0.8145858957941233, 'Total loss': 0.8145858957941233}
2022-11-23 01:49:25,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:25,964 INFO:     Epoch: 77
2022-11-23 01:49:26,771 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.827832471917976, 'Total loss': 0.827832471917976} | train loss {'Reaction outcome loss': 0.8130754737507718, 'Total loss': 0.8130754737507718}
2022-11-23 01:49:26,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:26,771 INFO:     Epoch: 78
2022-11-23 01:49:27,608 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8208729387684301, 'Total loss': 0.8208729387684301} | train loss {'Reaction outcome loss': 0.8023355060713253, 'Total loss': 0.8023355060713253}
2022-11-23 01:49:27,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:27,608 INFO:     Epoch: 79
2022-11-23 01:49:28,446 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8518436408855699, 'Total loss': 0.8518436408855699} | train loss {'Reaction outcome loss': 0.802774508955025, 'Total loss': 0.802774508955025}
2022-11-23 01:49:28,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:28,446 INFO:     Epoch: 80
2022-11-23 01:49:29,239 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8578173951669172, 'Total loss': 0.8578173951669172} | train loss {'Reaction outcome loss': 0.8053664275509144, 'Total loss': 0.8053664275509144}
2022-11-23 01:49:29,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:29,240 INFO:     Epoch: 81
2022-11-23 01:49:30,050 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8288011361252178, 'Total loss': 0.8288011361252178} | train loss {'Reaction outcome loss': 0.806634400628115, 'Total loss': 0.806634400628115}
2022-11-23 01:49:30,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:30,050 INFO:     Epoch: 82
2022-11-23 01:49:30,872 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8545695082707838, 'Total loss': 0.8545695082707838} | train loss {'Reaction outcome loss': 0.8113680962126265, 'Total loss': 0.8113680962126265}
2022-11-23 01:49:30,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:30,873 INFO:     Epoch: 83
2022-11-23 01:49:31,694 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8350721231915734, 'Total loss': 0.8350721231915734} | train loss {'Reaction outcome loss': 0.8070002771944169, 'Total loss': 0.8070002771944169}
2022-11-23 01:49:31,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:31,695 INFO:     Epoch: 84
2022-11-23 01:49:32,500 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8268615623766725, 'Total loss': 0.8268615623766725} | train loss {'Reaction outcome loss': 0.8233455935953117, 'Total loss': 0.8233455935953117}
2022-11-23 01:49:32,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:32,500 INFO:     Epoch: 85
2022-11-23 01:49:33,306 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8639409203420986, 'Total loss': 0.8639409203420986} | train loss {'Reaction outcome loss': 0.8109342662791009, 'Total loss': 0.8109342662791009}
2022-11-23 01:49:33,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:33,307 INFO:     Epoch: 86
2022-11-23 01:49:34,079 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8312388306314294, 'Total loss': 0.8312388306314294} | train loss {'Reaction outcome loss': 0.8181582077553398, 'Total loss': 0.8181582077553398}
2022-11-23 01:49:34,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:34,080 INFO:     Epoch: 87
2022-11-23 01:49:34,926 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8342399305918, 'Total loss': 0.8342399305918} | train loss {'Reaction outcome loss': 0.8098570665849848, 'Total loss': 0.8098570665849848}
2022-11-23 01:49:34,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:34,927 INFO:     Epoch: 88
2022-11-23 01:49:35,735 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8699445941231467, 'Total loss': 0.8699445941231467} | train loss {'Reaction outcome loss': 0.8052932317199012, 'Total loss': 0.8052932317199012}
2022-11-23 01:49:35,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:35,736 INFO:     Epoch: 89
2022-11-23 01:49:36,558 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8366743820634756, 'Total loss': 0.8366743820634756} | train loss {'Reaction outcome loss': 0.808110495026295, 'Total loss': 0.808110495026295}
2022-11-23 01:49:36,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:36,559 INFO:     Epoch: 90
2022-11-23 01:49:37,371 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8429810458963568, 'Total loss': 0.8429810458963568} | train loss {'Reaction outcome loss': 0.8049408830325251, 'Total loss': 0.8049408830325251}
2022-11-23 01:49:37,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:37,372 INFO:     Epoch: 91
2022-11-23 01:49:38,155 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8210001682693308, 'Total loss': 0.8210001682693308} | train loss {'Reaction outcome loss': 0.8116848128527282, 'Total loss': 0.8116848128527282}
2022-11-23 01:49:38,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:38,155 INFO:     Epoch: 92
2022-11-23 01:49:38,996 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8375746553594415, 'Total loss': 0.8375746553594415} | train loss {'Reaction outcome loss': 0.8138585233012674, 'Total loss': 0.8138585233012674}
2022-11-23 01:49:38,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:38,997 INFO:     Epoch: 93
2022-11-23 01:49:39,812 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8316240053285252, 'Total loss': 0.8316240053285252} | train loss {'Reaction outcome loss': 0.8090463120203751, 'Total loss': 0.8090463120203751}
2022-11-23 01:49:39,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:39,813 INFO:     Epoch: 94
2022-11-23 01:49:40,610 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8333883691917766, 'Total loss': 0.8333883691917766} | train loss {'Reaction outcome loss': 0.8143659565854169, 'Total loss': 0.8143659565854169}
2022-11-23 01:49:40,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:40,610 INFO:     Epoch: 95
2022-11-23 01:49:41,395 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8217401849952611, 'Total loss': 0.8217401849952611} | train loss {'Reaction outcome loss': 0.808814263898834, 'Total loss': 0.808814263898834}
2022-11-23 01:49:41,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:41,395 INFO:     Epoch: 96
2022-11-23 01:49:42,176 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8486539680849422, 'Total loss': 0.8486539680849422} | train loss {'Reaction outcome loss': 0.8084832666373929, 'Total loss': 0.8084832666373929}
2022-11-23 01:49:42,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:42,176 INFO:     Epoch: 97
2022-11-23 01:49:42,951 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8350518372925845, 'Total loss': 0.8350518372925845} | train loss {'Reaction outcome loss': 0.8122744136735013, 'Total loss': 0.8122744136735013}
2022-11-23 01:49:42,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:42,951 INFO:     Epoch: 98
2022-11-23 01:49:43,741 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8285787992856719, 'Total loss': 0.8285787992856719} | train loss {'Reaction outcome loss': 0.8049338616822895, 'Total loss': 0.8049338616822895}
2022-11-23 01:49:43,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:43,742 INFO:     Epoch: 99
2022-11-23 01:49:44,525 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8478101153265346, 'Total loss': 0.8478101153265346} | train loss {'Reaction outcome loss': 0.8112803985956709, 'Total loss': 0.8112803985956709}
2022-11-23 01:49:44,525 INFO:     Best model found after epoch 60 of 100.
2022-11-23 01:49:44,525 INFO:   Done with stage: TRAINING
2022-11-23 01:49:44,525 INFO:   Starting stage: EVALUATION
2022-11-23 01:49:44,649 INFO:   Done with stage: EVALUATION
2022-11-23 01:49:44,649 INFO:   Leaving out SEQ value Fold_5
2022-11-23 01:49:44,662 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:49:44,662 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:49:45,342 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:49:45,342 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:49:45,415 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:49:45,416 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:49:45,416 INFO:     No hyperparam tuning for this model
2022-11-23 01:49:45,416 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:49:45,416 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:49:45,417 INFO:     None feature selector for col prot
2022-11-23 01:49:45,417 INFO:     None feature selector for col prot
2022-11-23 01:49:45,417 INFO:     None feature selector for col prot
2022-11-23 01:49:45,417 INFO:     None feature selector for col chem
2022-11-23 01:49:45,417 INFO:     None feature selector for col chem
2022-11-23 01:49:45,418 INFO:     None feature selector for col chem
2022-11-23 01:49:45,418 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:49:45,418 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:49:45,419 INFO:     Number of params in model 168571
2022-11-23 01:49:45,422 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:49:45,422 INFO:   Starting stage: TRAINING
2022-11-23 01:49:45,480 INFO:     Val loss before train {'Reaction outcome loss': 0.9958873404697939, 'Total loss': 0.9958873404697939}
2022-11-23 01:49:45,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:45,481 INFO:     Epoch: 0
2022-11-23 01:49:46,298 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8643953359939835, 'Total loss': 0.8643953359939835} | train loss {'Reaction outcome loss': 0.8790037412995751, 'Total loss': 0.8790037412995751}
2022-11-23 01:49:46,298 INFO:     Found new best model at epoch 0
2022-11-23 01:49:46,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:46,299 INFO:     Epoch: 1
2022-11-23 01:49:47,090 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8460730598731474, 'Total loss': 0.8460730598731474} | train loss {'Reaction outcome loss': 0.8585004605021072, 'Total loss': 0.8585004605021072}
2022-11-23 01:49:47,090 INFO:     Found new best model at epoch 1
2022-11-23 01:49:47,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:47,091 INFO:     Epoch: 2
2022-11-23 01:49:47,872 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8690184639258818, 'Total loss': 0.8690184639258818} | train loss {'Reaction outcome loss': 0.8533197628100392, 'Total loss': 0.8533197628100392}
2022-11-23 01:49:47,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:47,872 INFO:     Epoch: 3
2022-11-23 01:49:48,649 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8450010669502345, 'Total loss': 0.8450010669502345} | train loss {'Reaction outcome loss': 0.8505898622366098, 'Total loss': 0.8505898622366098}
2022-11-23 01:49:48,649 INFO:     Found new best model at epoch 3
2022-11-23 01:49:48,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:48,650 INFO:     Epoch: 4
2022-11-23 01:49:49,466 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8325457213954492, 'Total loss': 0.8325457213954492} | train loss {'Reaction outcome loss': 0.8382643771316358, 'Total loss': 0.8382643771316358}
2022-11-23 01:49:49,466 INFO:     Found new best model at epoch 4
2022-11-23 01:49:49,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:49,467 INFO:     Epoch: 5
2022-11-23 01:49:50,253 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8250195018269799, 'Total loss': 0.8250195018269799} | train loss {'Reaction outcome loss': 0.8360973138980538, 'Total loss': 0.8360973138980538}
2022-11-23 01:49:50,254 INFO:     Found new best model at epoch 5
2022-11-23 01:49:50,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:50,255 INFO:     Epoch: 6
2022-11-23 01:49:51,120 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8113541928204623, 'Total loss': 0.8113541928204623} | train loss {'Reaction outcome loss': 0.8374856424476453, 'Total loss': 0.8374856424476453}
2022-11-23 01:49:51,120 INFO:     Found new best model at epoch 6
2022-11-23 01:49:51,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:51,122 INFO:     Epoch: 7
2022-11-23 01:49:51,930 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8283875814893029, 'Total loss': 0.8283875814893029} | train loss {'Reaction outcome loss': 0.8394510145129462, 'Total loss': 0.8394510145129462}
2022-11-23 01:49:51,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:51,930 INFO:     Epoch: 8
2022-11-23 01:49:52,771 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8226959556341171, 'Total loss': 0.8226959556341171} | train loss {'Reaction outcome loss': 0.8300297227706986, 'Total loss': 0.8300297227706986}
2022-11-23 01:49:52,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:52,771 INFO:     Epoch: 9
2022-11-23 01:49:53,598 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8096930479461496, 'Total loss': 0.8096930479461496} | train loss {'Reaction outcome loss': 0.8320619985159592, 'Total loss': 0.8320619985159592}
2022-11-23 01:49:53,598 INFO:     Found new best model at epoch 9
2022-11-23 01:49:53,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:53,599 INFO:     Epoch: 10
2022-11-23 01:49:54,413 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8265464739366011, 'Total loss': 0.8265464739366011} | train loss {'Reaction outcome loss': 0.8303488326458796, 'Total loss': 0.8303488326458796}
2022-11-23 01:49:54,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:54,413 INFO:     Epoch: 11
2022-11-23 01:49:55,230 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8136873055588115, 'Total loss': 0.8136873055588115} | train loss {'Reaction outcome loss': 0.8326611223249782, 'Total loss': 0.8326611223249782}
2022-11-23 01:49:55,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:55,230 INFO:     Epoch: 12
2022-11-23 01:49:56,058 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8097253807566382, 'Total loss': 0.8097253807566382} | train loss {'Reaction outcome loss': 0.8296195836322993, 'Total loss': 0.8296195836322993}
2022-11-23 01:49:56,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:56,059 INFO:     Epoch: 13
2022-11-23 01:49:56,843 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8035007302056659, 'Total loss': 0.8035007302056659} | train loss {'Reaction outcome loss': 0.8312193409875337, 'Total loss': 0.8312193409875337}
2022-11-23 01:49:56,843 INFO:     Found new best model at epoch 13
2022-11-23 01:49:56,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:56,844 INFO:     Epoch: 14
2022-11-23 01:49:57,670 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8141889213161035, 'Total loss': 0.8141889213161035} | train loss {'Reaction outcome loss': 0.8276691032566039, 'Total loss': 0.8276691032566039}
2022-11-23 01:49:57,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:57,670 INFO:     Epoch: 15
2022-11-23 01:49:58,495 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8025780760429122, 'Total loss': 0.8025780760429122} | train loss {'Reaction outcome loss': 0.8278097110962578, 'Total loss': 0.8278097110962578}
2022-11-23 01:49:58,495 INFO:     Found new best model at epoch 15
2022-11-23 01:49:58,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:58,496 INFO:     Epoch: 16
2022-11-23 01:49:59,330 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8133566921407526, 'Total loss': 0.8133566921407526} | train loss {'Reaction outcome loss': 0.8309459902255641, 'Total loss': 0.8309459902255641}
2022-11-23 01:49:59,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:49:59,330 INFO:     Epoch: 17
2022-11-23 01:50:00,154 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8094347762790594, 'Total loss': 0.8094347762790594} | train loss {'Reaction outcome loss': 0.8278687697974777, 'Total loss': 0.8278687697974777}
2022-11-23 01:50:00,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:00,155 INFO:     Epoch: 18
2022-11-23 01:50:00,991 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8026354306123473, 'Total loss': 0.8026354306123473} | train loss {'Reaction outcome loss': 0.825928299141075, 'Total loss': 0.825928299141075}
2022-11-23 01:50:00,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:00,991 INFO:     Epoch: 19
2022-11-23 01:50:01,831 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8070103573528203, 'Total loss': 0.8070103573528203} | train loss {'Reaction outcome loss': 0.821335984265756, 'Total loss': 0.821335984265756}
2022-11-23 01:50:01,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:01,832 INFO:     Epoch: 20
2022-11-23 01:50:02,617 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8249528502876108, 'Total loss': 0.8249528502876108} | train loss {'Reaction outcome loss': 0.8234102234907961, 'Total loss': 0.8234102234907961}
2022-11-23 01:50:02,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:02,618 INFO:     Epoch: 21
2022-11-23 01:50:03,426 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7951122955842451, 'Total loss': 0.7951122955842451} | train loss {'Reaction outcome loss': 0.830716686934112, 'Total loss': 0.830716686934112}
2022-11-23 01:50:03,426 INFO:     Found new best model at epoch 21
2022-11-23 01:50:03,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:03,427 INFO:     Epoch: 22
2022-11-23 01:50:04,238 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8061126843094826, 'Total loss': 0.8061126843094826} | train loss {'Reaction outcome loss': 0.8282947473921757, 'Total loss': 0.8282947473921757}
2022-11-23 01:50:04,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:04,238 INFO:     Epoch: 23
2022-11-23 01:50:05,047 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8020102469758554, 'Total loss': 0.8020102469758554} | train loss {'Reaction outcome loss': 0.8352726107908164, 'Total loss': 0.8352726107908164}
2022-11-23 01:50:05,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:05,047 INFO:     Epoch: 24
2022-11-23 01:50:05,849 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8280484994704073, 'Total loss': 0.8280484994704073} | train loss {'Reaction outcome loss': 0.8282075354806807, 'Total loss': 0.8282075354806807}
2022-11-23 01:50:05,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:05,850 INFO:     Epoch: 25
2022-11-23 01:50:06,633 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8040641593662176, 'Total loss': 0.8040641593662176} | train loss {'Reaction outcome loss': 0.8216871911064092, 'Total loss': 0.8216871911064092}
2022-11-23 01:50:06,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:06,633 INFO:     Epoch: 26
2022-11-23 01:50:07,451 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8132214248180389, 'Total loss': 0.8132214248180389} | train loss {'Reaction outcome loss': 0.830158528890687, 'Total loss': 0.830158528890687}
2022-11-23 01:50:07,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:07,451 INFO:     Epoch: 27
2022-11-23 01:50:08,292 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8159740485928275, 'Total loss': 0.8159740485928275} | train loss {'Reaction outcome loss': 0.8259049978574761, 'Total loss': 0.8259049978574761}
2022-11-23 01:50:08,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:08,292 INFO:     Epoch: 28
2022-11-23 01:50:09,122 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8120173093947497, 'Total loss': 0.8120173093947497} | train loss {'Reaction outcome loss': 0.8321128352450938, 'Total loss': 0.8321128352450938}
2022-11-23 01:50:09,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:09,122 INFO:     Epoch: 29
2022-11-23 01:50:09,972 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8130067099224437, 'Total loss': 0.8130067099224437} | train loss {'Reaction outcome loss': 0.8285575436677045, 'Total loss': 0.8285575436677045}
2022-11-23 01:50:09,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:09,973 INFO:     Epoch: 30
2022-11-23 01:50:10,769 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8033537688580427, 'Total loss': 0.8033537688580427} | train loss {'Reaction outcome loss': 0.8291886051898061, 'Total loss': 0.8291886051898061}
2022-11-23 01:50:10,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:10,769 INFO:     Epoch: 31
2022-11-23 01:50:11,575 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8011247888207436, 'Total loss': 0.8011247888207436} | train loss {'Reaction outcome loss': 0.8243623995618058, 'Total loss': 0.8243623995618058}
2022-11-23 01:50:11,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:11,575 INFO:     Epoch: 32
2022-11-23 01:50:12,397 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8722821826284582, 'Total loss': 0.8722821826284582} | train loss {'Reaction outcome loss': 0.8297519187936898, 'Total loss': 0.8297519187936898}
2022-11-23 01:50:12,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:12,398 INFO:     Epoch: 33
2022-11-23 01:50:13,223 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8007849224589088, 'Total loss': 0.8007849224589088} | train loss {'Reaction outcome loss': 0.8406384625898199, 'Total loss': 0.8406384625898199}
2022-11-23 01:50:13,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:13,223 INFO:     Epoch: 34
2022-11-23 01:50:14,035 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8009813597256487, 'Total loss': 0.8009813597256487} | train loss {'Reaction outcome loss': 0.8251755710253831, 'Total loss': 0.8251755710253831}
2022-11-23 01:50:14,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:14,035 INFO:     Epoch: 35
2022-11-23 01:50:14,831 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7973330623724244, 'Total loss': 0.7973330623724244} | train loss {'Reaction outcome loss': 0.8199125809466791, 'Total loss': 0.8199125809466791}
2022-11-23 01:50:14,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:14,832 INFO:     Epoch: 36
2022-11-23 01:50:15,650 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8091732216152278, 'Total loss': 0.8091732216152278} | train loss {'Reaction outcome loss': 0.8249390959015742, 'Total loss': 0.8249390959015742}
2022-11-23 01:50:15,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:15,651 INFO:     Epoch: 37
2022-11-23 01:50:16,455 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8058840490200303, 'Total loss': 0.8058840490200303} | train loss {'Reaction outcome loss': 0.8284798398432944, 'Total loss': 0.8284798398432944}
2022-11-23 01:50:16,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:16,455 INFO:     Epoch: 38
2022-11-23 01:50:17,295 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8033361854878339, 'Total loss': 0.8033361854878339} | train loss {'Reaction outcome loss': 0.8260969039097972, 'Total loss': 0.8260969039097972}
2022-11-23 01:50:17,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:17,295 INFO:     Epoch: 39
2022-11-23 01:50:18,131 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8154749856753782, 'Total loss': 0.8154749856753782} | train loss {'Reaction outcome loss': 0.8315923922216362, 'Total loss': 0.8315923922216362}
2022-11-23 01:50:18,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:18,131 INFO:     Epoch: 40
2022-11-23 01:50:18,959 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.82123437049714, 'Total loss': 0.82123437049714} | train loss {'Reaction outcome loss': 0.8301045385449521, 'Total loss': 0.8301045385449521}
2022-11-23 01:50:18,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:18,959 INFO:     Epoch: 41
2022-11-23 01:50:19,759 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7850218618457968, 'Total loss': 0.7850218618457968} | train loss {'Reaction outcome loss': 0.8288478530370272, 'Total loss': 0.8288478530370272}
2022-11-23 01:50:19,759 INFO:     Found new best model at epoch 41
2022-11-23 01:50:19,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:19,760 INFO:     Epoch: 42
2022-11-23 01:50:20,519 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8031208921562542, 'Total loss': 0.8031208921562542} | train loss {'Reaction outcome loss': 0.8302825318898267, 'Total loss': 0.8302825318898267}
2022-11-23 01:50:20,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:20,519 INFO:     Epoch: 43
2022-11-23 01:50:21,327 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7963757189837369, 'Total loss': 0.7963757189837369} | train loss {'Reaction outcome loss': 0.8293176893039271, 'Total loss': 0.8293176893039271}
2022-11-23 01:50:21,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:21,328 INFO:     Epoch: 44
2022-11-23 01:50:22,142 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.818398541347547, 'Total loss': 0.818398541347547} | train loss {'Reaction outcome loss': 0.8339345024423561, 'Total loss': 0.8339345024423561}
2022-11-23 01:50:22,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:22,142 INFO:     Epoch: 45
2022-11-23 01:50:22,957 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7897133976221085, 'Total loss': 0.7897133976221085} | train loss {'Reaction outcome loss': 0.8259061441006448, 'Total loss': 0.8259061441006448}
2022-11-23 01:50:22,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:22,957 INFO:     Epoch: 46
2022-11-23 01:50:23,745 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8028181479735808, 'Total loss': 0.8028181479735808} | train loss {'Reaction outcome loss': 0.8238809514142241, 'Total loss': 0.8238809514142241}
2022-11-23 01:50:23,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:23,746 INFO:     Epoch: 47
2022-11-23 01:50:24,549 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8057228353890505, 'Total loss': 0.8057228353890505} | train loss {'Reaction outcome loss': 0.8255751826743848, 'Total loss': 0.8255751826743848}
2022-11-23 01:50:24,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:24,549 INFO:     Epoch: 48
2022-11-23 01:50:25,343 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8425279225815426, 'Total loss': 0.8425279225815426} | train loss {'Reaction outcome loss': 0.8225226177860369, 'Total loss': 0.8225226177860369}
2022-11-23 01:50:25,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:25,343 INFO:     Epoch: 49
2022-11-23 01:50:26,176 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8027521893382072, 'Total loss': 0.8027521893382072} | train loss {'Reaction outcome loss': 0.8251833668363239, 'Total loss': 0.8251833668363239}
2022-11-23 01:50:26,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:26,176 INFO:     Epoch: 50
2022-11-23 01:50:26,976 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8050072721459649, 'Total loss': 0.8050072721459649} | train loss {'Reaction outcome loss': 0.8241271073760291, 'Total loss': 0.8241271073760291}
2022-11-23 01:50:26,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:26,976 INFO:     Epoch: 51
2022-11-23 01:50:27,751 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7979080202904615, 'Total loss': 0.7979080202904615} | train loss {'Reaction outcome loss': 0.8332399587158249, 'Total loss': 0.8332399587158249}
2022-11-23 01:50:27,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:27,751 INFO:     Epoch: 52
2022-11-23 01:50:28,568 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8303932594982061, 'Total loss': 0.8303932594982061} | train loss {'Reaction outcome loss': 0.8290262562543275, 'Total loss': 0.8290262562543275}
2022-11-23 01:50:28,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:28,568 INFO:     Epoch: 53
2022-11-23 01:50:29,366 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8211380148475821, 'Total loss': 0.8211380148475821} | train loss {'Reaction outcome loss': 0.8222582248541025, 'Total loss': 0.8222582248541025}
2022-11-23 01:50:29,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:29,366 INFO:     Epoch: 54
2022-11-23 01:50:30,152 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7974778203801676, 'Total loss': 0.7974778203801676} | train loss {'Reaction outcome loss': 0.8211050598244918, 'Total loss': 0.8211050598244918}
2022-11-23 01:50:30,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:30,152 INFO:     Epoch: 55
2022-11-23 01:50:30,957 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7919395640492439, 'Total loss': 0.7919395640492439} | train loss {'Reaction outcome loss': 0.8267805207716791, 'Total loss': 0.8267805207716791}
2022-11-23 01:50:30,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:30,957 INFO:     Epoch: 56
2022-11-23 01:50:31,747 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8169934817335822, 'Total loss': 0.8169934817335822} | train loss {'Reaction outcome loss': 0.8235590974328971, 'Total loss': 0.8235590974328971}
2022-11-23 01:50:31,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:31,747 INFO:     Epoch: 57
2022-11-23 01:50:32,540 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8031165491450917, 'Total loss': 0.8031165491450917} | train loss {'Reaction outcome loss': 0.8316062325649416, 'Total loss': 0.8316062325649416}
2022-11-23 01:50:32,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:32,541 INFO:     Epoch: 58
2022-11-23 01:50:33,326 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8092904009602286, 'Total loss': 0.8092904009602286} | train loss {'Reaction outcome loss': 0.8233161595186241, 'Total loss': 0.8233161595186241}
2022-11-23 01:50:33,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:33,327 INFO:     Epoch: 59
2022-11-23 01:50:34,157 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.80135416849093, 'Total loss': 0.80135416849093} | train loss {'Reaction outcome loss': 0.8221661591004987, 'Total loss': 0.8221661591004987}
2022-11-23 01:50:34,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:34,157 INFO:     Epoch: 60
2022-11-23 01:50:34,910 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7987703931602564, 'Total loss': 0.7987703931602564} | train loss {'Reaction outcome loss': 0.8230081250069112, 'Total loss': 0.8230081250069112}
2022-11-23 01:50:34,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:34,910 INFO:     Epoch: 61
2022-11-23 01:50:35,724 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7958065020767126, 'Total loss': 0.7958065020767126} | train loss {'Reaction outcome loss': 0.8263225733992542, 'Total loss': 0.8263225733992542}
2022-11-23 01:50:35,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:35,724 INFO:     Epoch: 62
2022-11-23 01:50:36,545 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.781315228478475, 'Total loss': 0.781315228478475} | train loss {'Reaction outcome loss': 0.8207385337002847, 'Total loss': 0.8207385337002847}
2022-11-23 01:50:36,545 INFO:     Found new best model at epoch 62
2022-11-23 01:50:36,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:36,546 INFO:     Epoch: 63
2022-11-23 01:50:37,350 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8111042624170129, 'Total loss': 0.8111042624170129} | train loss {'Reaction outcome loss': 0.8243985725679861, 'Total loss': 0.8243985725679861}
2022-11-23 01:50:37,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:37,351 INFO:     Epoch: 64
2022-11-23 01:50:38,121 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8028102571314032, 'Total loss': 0.8028102571314032} | train loss {'Reaction outcome loss': 0.817835449629467, 'Total loss': 0.817835449629467}
2022-11-23 01:50:38,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:38,121 INFO:     Epoch: 65
2022-11-23 01:50:38,910 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8269206427715041, 'Total loss': 0.8269206427715041} | train loss {'Reaction outcome loss': 0.8276392484483449, 'Total loss': 0.8276392484483449}
2022-11-23 01:50:38,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:38,910 INFO:     Epoch: 66
2022-11-23 01:50:39,680 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8072853982448578, 'Total loss': 0.8072853982448578} | train loss {'Reaction outcome loss': 0.8240777880315356, 'Total loss': 0.8240777880315356}
2022-11-23 01:50:39,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:39,680 INFO:     Epoch: 67
2022-11-23 01:50:40,487 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8093702617016706, 'Total loss': 0.8093702617016706} | train loss {'Reaction outcome loss': 0.8261807963915682, 'Total loss': 0.8261807963915682}
2022-11-23 01:50:40,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:40,487 INFO:     Epoch: 68
2022-11-23 01:50:41,385 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8286333273757588, 'Total loss': 0.8286333273757588} | train loss {'Reaction outcome loss': 0.8202805408099403, 'Total loss': 0.8202805408099403}
2022-11-23 01:50:41,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:41,385 INFO:     Epoch: 69
2022-11-23 01:50:42,203 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8172133822332729, 'Total loss': 0.8172133822332729} | train loss {'Reaction outcome loss': 0.8231588961624423, 'Total loss': 0.8231588961624423}
2022-11-23 01:50:42,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:42,203 INFO:     Epoch: 70
2022-11-23 01:50:43,051 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8011039671572772, 'Total loss': 0.8011039671572772} | train loss {'Reaction outcome loss': 0.8276988965297035, 'Total loss': 0.8276988965297035}
2022-11-23 01:50:43,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:43,052 INFO:     Epoch: 71
2022-11-23 01:50:43,862 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8228700709613886, 'Total loss': 0.8228700709613886} | train loss {'Reaction outcome loss': 0.8203860410915212, 'Total loss': 0.8203860410915212}
2022-11-23 01:50:43,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:43,862 INFO:     Epoch: 72
2022-11-23 01:50:44,644 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8147682066668164, 'Total loss': 0.8147682066668164} | train loss {'Reaction outcome loss': 0.8182903960769475, 'Total loss': 0.8182903960769475}
2022-11-23 01:50:44,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:44,644 INFO:     Epoch: 73
2022-11-23 01:50:45,473 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8095481835983016, 'Total loss': 0.8095481835983016} | train loss {'Reaction outcome loss': 0.8261311292226016, 'Total loss': 0.8261311292226016}
2022-11-23 01:50:45,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:45,475 INFO:     Epoch: 74
2022-11-23 01:50:46,278 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7881037186492573, 'Total loss': 0.7881037186492573} | train loss {'Reaction outcome loss': 0.8249622275713484, 'Total loss': 0.8249622275713484}
2022-11-23 01:50:46,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:46,278 INFO:     Epoch: 75
2022-11-23 01:50:47,094 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.804168971424753, 'Total loss': 0.804168971424753} | train loss {'Reaction outcome loss': 0.8267233067678537, 'Total loss': 0.8267233067678537}
2022-11-23 01:50:47,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:47,094 INFO:     Epoch: 76
2022-11-23 01:50:47,878 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8047830916263841, 'Total loss': 0.8047830916263841} | train loss {'Reaction outcome loss': 0.8247554169492683, 'Total loss': 0.8247554169492683}
2022-11-23 01:50:47,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:47,878 INFO:     Epoch: 77
2022-11-23 01:50:48,702 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8029701574282213, 'Total loss': 0.8029701574282213} | train loss {'Reaction outcome loss': 0.8280034996719978, 'Total loss': 0.8280034996719978}
2022-11-23 01:50:48,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:48,702 INFO:     Epoch: 78
2022-11-23 01:50:49,507 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8027365329590711, 'Total loss': 0.8027365329590711} | train loss {'Reaction outcome loss': 0.8317967987494913, 'Total loss': 0.8317967987494913}
2022-11-23 01:50:49,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:49,507 INFO:     Epoch: 79
2022-11-23 01:50:50,281 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8068604455752806, 'Total loss': 0.8068604455752806} | train loss {'Reaction outcome loss': 0.8266011441526143, 'Total loss': 0.8266011441526143}
2022-11-23 01:50:50,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:50,281 INFO:     Epoch: 80
2022-11-23 01:50:51,077 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7873783572153612, 'Total loss': 0.7873783572153612} | train loss {'Reaction outcome loss': 0.8211080524844196, 'Total loss': 0.8211080524844196}
2022-11-23 01:50:51,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:51,078 INFO:     Epoch: 81
2022-11-23 01:50:51,865 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8219158595258539, 'Total loss': 0.8219158595258539} | train loss {'Reaction outcome loss': 0.8319346190464159, 'Total loss': 0.8319346190464159}
2022-11-23 01:50:51,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:51,866 INFO:     Epoch: 82
2022-11-23 01:50:52,656 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.801764343272556, 'Total loss': 0.801764343272556} | train loss {'Reaction outcome loss': 0.8249180680103148, 'Total loss': 0.8249180680103148}
2022-11-23 01:50:52,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:52,657 INFO:     Epoch: 83
2022-11-23 01:50:53,463 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8202675587751649, 'Total loss': 0.8202675587751649} | train loss {'Reaction outcome loss': 0.8184875561158184, 'Total loss': 0.8184875561158184}
2022-11-23 01:50:53,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:53,463 INFO:     Epoch: 84
2022-11-23 01:50:54,275 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7981470166282221, 'Total loss': 0.7981470166282221} | train loss {'Reaction outcome loss': 0.8240994513638107, 'Total loss': 0.8240994513638107}
2022-11-23 01:50:54,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:54,275 INFO:     Epoch: 85
2022-11-23 01:50:55,069 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.9099453301592306, 'Total loss': 0.9099453301592306} | train loss {'Reaction outcome loss': 0.8301014334325366, 'Total loss': 0.8301014334325366}
2022-11-23 01:50:55,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:55,069 INFO:     Epoch: 86
2022-11-23 01:50:55,894 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8084061965346336, 'Total loss': 0.8084061965346336} | train loss {'Reaction outcome loss': 0.8245936804696133, 'Total loss': 0.8245936804696133}
2022-11-23 01:50:55,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:55,894 INFO:     Epoch: 87
2022-11-23 01:50:56,665 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.806352246214043, 'Total loss': 0.806352246214043} | train loss {'Reaction outcome loss': 0.8269950589429029, 'Total loss': 0.8269950589429029}
2022-11-23 01:50:56,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:56,666 INFO:     Epoch: 88
2022-11-23 01:50:57,494 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7930648848414421, 'Total loss': 0.7930648848414421} | train loss {'Reaction outcome loss': 0.8218854388244722, 'Total loss': 0.8218854388244722}
2022-11-23 01:50:57,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:57,494 INFO:     Epoch: 89
2022-11-23 01:50:58,334 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7994621585715901, 'Total loss': 0.7994621585715901} | train loss {'Reaction outcome loss': 0.8253714152675892, 'Total loss': 0.8253714152675892}
2022-11-23 01:50:58,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:58,335 INFO:     Epoch: 90
2022-11-23 01:50:59,167 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7923815243623473, 'Total loss': 0.7923815243623473} | train loss {'Reaction outcome loss': 0.8230096958426811, 'Total loss': 0.8230096958426811}
2022-11-23 01:50:59,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:50:59,167 INFO:     Epoch: 91
2022-11-23 01:51:00,024 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7886276475407861, 'Total loss': 0.7886276475407861} | train loss {'Reaction outcome loss': 0.8148579579676211, 'Total loss': 0.8148579579676211}
2022-11-23 01:51:00,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:00,025 INFO:     Epoch: 92
2022-11-23 01:51:00,904 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8458848649805243, 'Total loss': 0.8458848649805243} | train loss {'Reaction outcome loss': 0.8232876548641607, 'Total loss': 0.8232876548641607}
2022-11-23 01:51:00,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:00,905 INFO:     Epoch: 93
2022-11-23 01:51:01,771 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8137788406827233, 'Total loss': 0.8137788406827233} | train loss {'Reaction outcome loss': 0.8235857334696812, 'Total loss': 0.8235857334696812}
2022-11-23 01:51:01,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:01,771 INFO:     Epoch: 94
2022-11-23 01:51:02,648 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8098025423559275, 'Total loss': 0.8098025423559275} | train loss {'Reaction outcome loss': 0.82747233637914, 'Total loss': 0.82747233637914}
2022-11-23 01:51:02,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:02,649 INFO:     Epoch: 95
2022-11-23 01:51:03,508 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8046589344739914, 'Total loss': 0.8046589344739914} | train loss {'Reaction outcome loss': 0.8270615891889039, 'Total loss': 0.8270615891889039}
2022-11-23 01:51:03,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:03,509 INFO:     Epoch: 96
2022-11-23 01:51:04,307 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8312459696422924, 'Total loss': 0.8312459696422924} | train loss {'Reaction outcome loss': 0.8349871251747193, 'Total loss': 0.8349871251747193}
2022-11-23 01:51:04,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:04,308 INFO:     Epoch: 97
2022-11-23 01:51:05,109 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7919761917807839, 'Total loss': 0.7919761917807839} | train loss {'Reaction outcome loss': 0.8245524111305654, 'Total loss': 0.8245524111305654}
2022-11-23 01:51:05,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:05,109 INFO:     Epoch: 98
2022-11-23 01:51:05,927 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8150781365958127, 'Total loss': 0.8150781365958127} | train loss {'Reaction outcome loss': 0.828098859260922, 'Total loss': 0.828098859260922}
2022-11-23 01:51:05,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:05,928 INFO:     Epoch: 99
2022-11-23 01:51:06,757 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7991412620652806, 'Total loss': 0.7991412620652806} | train loss {'Reaction outcome loss': 0.8356927763595272, 'Total loss': 0.8356927763595272}
2022-11-23 01:51:06,757 INFO:     Best model found after epoch 63 of 100.
2022-11-23 01:51:06,757 INFO:   Done with stage: TRAINING
2022-11-23 01:51:06,757 INFO:   Starting stage: EVALUATION
2022-11-23 01:51:06,882 INFO:   Done with stage: EVALUATION
2022-11-23 01:51:06,882 INFO:   Leaving out SEQ value Fold_6
2022-11-23 01:51:06,895 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:51:06,895 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:51:07,572 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:51:07,572 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:51:07,646 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:51:07,646 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:51:07,646 INFO:     No hyperparam tuning for this model
2022-11-23 01:51:07,646 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:51:07,646 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:51:07,647 INFO:     None feature selector for col prot
2022-11-23 01:51:07,647 INFO:     None feature selector for col prot
2022-11-23 01:51:07,647 INFO:     None feature selector for col prot
2022-11-23 01:51:07,648 INFO:     None feature selector for col chem
2022-11-23 01:51:07,648 INFO:     None feature selector for col chem
2022-11-23 01:51:07,648 INFO:     None feature selector for col chem
2022-11-23 01:51:07,648 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:51:07,648 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:51:07,649 INFO:     Number of params in model 168571
2022-11-23 01:51:07,652 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:51:07,653 INFO:   Starting stage: TRAINING
2022-11-23 01:51:07,710 INFO:     Val loss before train {'Reaction outcome loss': 1.0395168946547941, 'Total loss': 1.0395168946547941}
2022-11-23 01:51:07,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:07,710 INFO:     Epoch: 0
2022-11-23 01:51:08,560 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8648637343536724, 'Total loss': 0.8648637343536724} | train loss {'Reaction outcome loss': 0.8759999044479863, 'Total loss': 0.8759999044479863}
2022-11-23 01:51:08,560 INFO:     Found new best model at epoch 0
2022-11-23 01:51:08,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:08,561 INFO:     Epoch: 1
2022-11-23 01:51:09,384 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8625699349425056, 'Total loss': 0.8625699349425056} | train loss {'Reaction outcome loss': 0.8440946055756461, 'Total loss': 0.8440946055756461}
2022-11-23 01:51:09,384 INFO:     Found new best model at epoch 1
2022-11-23 01:51:09,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:09,385 INFO:     Epoch: 2
2022-11-23 01:51:10,236 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8709672594612295, 'Total loss': 0.8709672594612295} | train loss {'Reaction outcome loss': 0.8389544836696117, 'Total loss': 0.8389544836696117}
2022-11-23 01:51:10,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:10,237 INFO:     Epoch: 3
2022-11-23 01:51:11,027 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8593927025794983, 'Total loss': 0.8593927025794983} | train loss {'Reaction outcome loss': 0.8323745255268389, 'Total loss': 0.8323745255268389}
2022-11-23 01:51:11,027 INFO:     Found new best model at epoch 3
2022-11-23 01:51:11,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:11,028 INFO:     Epoch: 4
2022-11-23 01:51:11,830 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8501157510009679, 'Total loss': 0.8501157510009679} | train loss {'Reaction outcome loss': 0.8283581481345238, 'Total loss': 0.8283581481345238}
2022-11-23 01:51:11,830 INFO:     Found new best model at epoch 4
2022-11-23 01:51:11,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:11,831 INFO:     Epoch: 5
2022-11-23 01:51:12,645 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.833711105314168, 'Total loss': 0.833711105314168} | train loss {'Reaction outcome loss': 0.829683879570615, 'Total loss': 0.829683879570615}
2022-11-23 01:51:12,645 INFO:     Found new best model at epoch 5
2022-11-23 01:51:12,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:12,646 INFO:     Epoch: 6
2022-11-23 01:51:13,433 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8470067395405336, 'Total loss': 0.8470067395405336} | train loss {'Reaction outcome loss': 0.824928539294389, 'Total loss': 0.824928539294389}
2022-11-23 01:51:13,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:13,434 INFO:     Epoch: 7
2022-11-23 01:51:14,211 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8398571068590338, 'Total loss': 0.8398571068590338} | train loss {'Reaction outcome loss': 0.820457586838353, 'Total loss': 0.820457586838353}
2022-11-23 01:51:14,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:14,211 INFO:     Epoch: 8
2022-11-23 01:51:15,041 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8534757589752023, 'Total loss': 0.8534757589752023} | train loss {'Reaction outcome loss': 0.8216679253645481, 'Total loss': 0.8216679253645481}
2022-11-23 01:51:15,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:15,041 INFO:     Epoch: 9
2022-11-23 01:51:15,833 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8249788324941288, 'Total loss': 0.8249788324941288} | train loss {'Reaction outcome loss': 0.8207789127144122, 'Total loss': 0.8207789127144122}
2022-11-23 01:51:15,833 INFO:     Found new best model at epoch 9
2022-11-23 01:51:15,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:15,834 INFO:     Epoch: 10
2022-11-23 01:51:16,612 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.850625680251555, 'Total loss': 0.850625680251555} | train loss {'Reaction outcome loss': 0.8135001744714475, 'Total loss': 0.8135001744714475}
2022-11-23 01:51:16,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:16,613 INFO:     Epoch: 11
2022-11-23 01:51:17,434 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8332475464452397, 'Total loss': 0.8332475464452397} | train loss {'Reaction outcome loss': 0.8175447988173654, 'Total loss': 0.8175447988173654}
2022-11-23 01:51:17,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:17,436 INFO:     Epoch: 12
2022-11-23 01:51:18,239 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8215126605196432, 'Total loss': 0.8215126605196432} | train loss {'Reaction outcome loss': 0.8146384295917326, 'Total loss': 0.8146384295917326}
2022-11-23 01:51:18,240 INFO:     Found new best model at epoch 12
2022-11-23 01:51:18,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:18,240 INFO:     Epoch: 13
2022-11-23 01:51:19,051 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8312864317135378, 'Total loss': 0.8312864317135378} | train loss {'Reaction outcome loss': 0.8241826986833927, 'Total loss': 0.8241826986833927}
2022-11-23 01:51:19,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:19,052 INFO:     Epoch: 14
2022-11-23 01:51:19,881 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8577312935482372, 'Total loss': 0.8577312935482372} | train loss {'Reaction outcome loss': 0.8116801673125836, 'Total loss': 0.8116801673125836}
2022-11-23 01:51:19,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:19,881 INFO:     Epoch: 15
2022-11-23 01:51:20,700 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8356446020982482, 'Total loss': 0.8356446020982482} | train loss {'Reaction outcome loss': 0.8141944524982283, 'Total loss': 0.8141944524982283}
2022-11-23 01:51:20,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:20,700 INFO:     Epoch: 16
2022-11-23 01:51:21,500 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.839932229031216, 'Total loss': 0.839932229031216} | train loss {'Reaction outcome loss': 0.8174120935220872, 'Total loss': 0.8174120935220872}
2022-11-23 01:51:21,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:21,500 INFO:     Epoch: 17
2022-11-23 01:51:22,295 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.827365290034901, 'Total loss': 0.827365290034901} | train loss {'Reaction outcome loss': 0.8138675294335811, 'Total loss': 0.8138675294335811}
2022-11-23 01:51:22,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:22,295 INFO:     Epoch: 18
2022-11-23 01:51:23,117 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8325599933212454, 'Total loss': 0.8325599933212454} | train loss {'Reaction outcome loss': 0.8102818131446838, 'Total loss': 0.8102818131446838}
2022-11-23 01:51:23,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:23,117 INFO:     Epoch: 19
2022-11-23 01:51:23,981 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.830263530666178, 'Total loss': 0.830263530666178} | train loss {'Reaction outcome loss': 0.8124357805617394, 'Total loss': 0.8124357805617394}
2022-11-23 01:51:23,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:23,982 INFO:     Epoch: 20
2022-11-23 01:51:24,785 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8393768688494508, 'Total loss': 0.8393768688494508} | train loss {'Reaction outcome loss': 0.8126348296721135, 'Total loss': 0.8126348296721135}
2022-11-23 01:51:24,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:24,785 INFO:     Epoch: 21
2022-11-23 01:51:25,603 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8485663858326998, 'Total loss': 0.8485663858326998} | train loss {'Reaction outcome loss': 0.8141112546286275, 'Total loss': 0.8141112546286275}
2022-11-23 01:51:25,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:25,603 INFO:     Epoch: 22
2022-11-23 01:51:26,417 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8272847953167829, 'Total loss': 0.8272847953167829} | train loss {'Reaction outcome loss': 0.8128016914331144, 'Total loss': 0.8128016914331144}
2022-11-23 01:51:26,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:26,417 INFO:     Epoch: 23
2022-11-23 01:51:27,235 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8250040513547984, 'Total loss': 0.8250040513547984} | train loss {'Reaction outcome loss': 0.808614635779973, 'Total loss': 0.808614635779973}
2022-11-23 01:51:27,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:27,235 INFO:     Epoch: 24
2022-11-23 01:51:28,070 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8241971270604567, 'Total loss': 0.8241971270604567} | train loss {'Reaction outcome loss': 0.8082550028639455, 'Total loss': 0.8082550028639455}
2022-11-23 01:51:28,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:28,070 INFO:     Epoch: 25
2022-11-23 01:51:28,885 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8287647542628375, 'Total loss': 0.8287647542628375} | train loss {'Reaction outcome loss': 0.80988061416053, 'Total loss': 0.80988061416053}
2022-11-23 01:51:28,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:28,885 INFO:     Epoch: 26
2022-11-23 01:51:29,702 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8322353681380098, 'Total loss': 0.8322353681380098} | train loss {'Reaction outcome loss': 0.8104506445027166, 'Total loss': 0.8104506445027166}
2022-11-23 01:51:29,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:29,702 INFO:     Epoch: 27
2022-11-23 01:51:30,528 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8347756537524137, 'Total loss': 0.8347756537524137} | train loss {'Reaction outcome loss': 0.8093254965159201, 'Total loss': 0.8093254965159201}
2022-11-23 01:51:30,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:30,528 INFO:     Epoch: 28
2022-11-23 01:51:31,362 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8390895195982673, 'Total loss': 0.8390895195982673} | train loss {'Reaction outcome loss': 0.8080949442040536, 'Total loss': 0.8080949442040536}
2022-11-23 01:51:31,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:31,362 INFO:     Epoch: 29
2022-11-23 01:51:32,150 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8249467679045417, 'Total loss': 0.8249467679045417} | train loss {'Reaction outcome loss': 0.8102878339348301, 'Total loss': 0.8102878339348301}
2022-11-23 01:51:32,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:32,150 INFO:     Epoch: 30
2022-11-23 01:51:32,970 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.816026130860502, 'Total loss': 0.816026130860502} | train loss {'Reaction outcome loss': 0.812054829131211, 'Total loss': 0.812054829131211}
2022-11-23 01:51:32,970 INFO:     Found new best model at epoch 30
2022-11-23 01:51:32,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:32,971 INFO:     Epoch: 31
2022-11-23 01:51:33,780 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8632580719210885, 'Total loss': 0.8632580719210885} | train loss {'Reaction outcome loss': 0.8099274367334381, 'Total loss': 0.8099274367334381}
2022-11-23 01:51:33,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:33,781 INFO:     Epoch: 32
2022-11-23 01:51:34,597 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8351971236142245, 'Total loss': 0.8351971236142245} | train loss {'Reaction outcome loss': 0.809754170237049, 'Total loss': 0.809754170237049}
2022-11-23 01:51:34,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:34,598 INFO:     Epoch: 33
2022-11-23 01:51:35,397 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8222691328688101, 'Total loss': 0.8222691328688101} | train loss {'Reaction outcome loss': 0.8098839607930952, 'Total loss': 0.8098839607930952}
2022-11-23 01:51:35,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:35,397 INFO:     Epoch: 34
2022-11-23 01:51:36,174 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8251441927118734, 'Total loss': 0.8251441927118734} | train loss {'Reaction outcome loss': 0.8082926201243554, 'Total loss': 0.8082926201243554}
2022-11-23 01:51:36,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:36,175 INFO:     Epoch: 35
2022-11-23 01:51:36,956 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8217918344519355, 'Total loss': 0.8217918344519355} | train loss {'Reaction outcome loss': 0.8093712832177838, 'Total loss': 0.8093712832177838}
2022-11-23 01:51:36,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:36,957 INFO:     Epoch: 36
2022-11-23 01:51:37,752 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8220944289456714, 'Total loss': 0.8220944289456714} | train loss {'Reaction outcome loss': 0.8068770009183115, 'Total loss': 0.8068770009183115}
2022-11-23 01:51:37,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:37,752 INFO:     Epoch: 37
2022-11-23 01:51:38,535 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8395061804489656, 'Total loss': 0.8395061804489656} | train loss {'Reaction outcome loss': 0.8066015917687647, 'Total loss': 0.8066015917687647}
2022-11-23 01:51:38,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:38,535 INFO:     Epoch: 38
2022-11-23 01:51:39,367 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8386277285489169, 'Total loss': 0.8386277285489169} | train loss {'Reaction outcome loss': 0.8084140642275733, 'Total loss': 0.8084140642275733}
2022-11-23 01:51:39,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:39,367 INFO:     Epoch: 39
2022-11-23 01:51:40,172 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8166843964294954, 'Total loss': 0.8166843964294954} | train loss {'Reaction outcome loss': 0.8098437556576344, 'Total loss': 0.8098437556576344}
2022-11-23 01:51:40,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:40,173 INFO:     Epoch: 40
2022-11-23 01:51:40,990 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8511168279431083, 'Total loss': 0.8511168279431083} | train loss {'Reaction outcome loss': 0.807527038358873, 'Total loss': 0.807527038358873}
2022-11-23 01:51:40,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:40,990 INFO:     Epoch: 41
2022-11-23 01:51:41,798 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8241250867193396, 'Total loss': 0.8241250867193396} | train loss {'Reaction outcome loss': 0.8070754434673055, 'Total loss': 0.8070754434673055}
2022-11-23 01:51:41,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:41,798 INFO:     Epoch: 42
2022-11-23 01:51:42,629 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8263957453044978, 'Total loss': 0.8263957453044978} | train loss {'Reaction outcome loss': 0.8100611966463828, 'Total loss': 0.8100611966463828}
2022-11-23 01:51:42,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:42,629 INFO:     Epoch: 43
2022-11-23 01:51:43,418 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8250511850823056, 'Total loss': 0.8250511850823056} | train loss {'Reaction outcome loss': 0.8028574337161356, 'Total loss': 0.8028574337161356}
2022-11-23 01:51:43,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:43,418 INFO:     Epoch: 44
2022-11-23 01:51:44,195 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8299855847250331, 'Total loss': 0.8299855847250331} | train loss {'Reaction outcome loss': 0.8050632325391616, 'Total loss': 0.8050632325391616}
2022-11-23 01:51:44,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:44,196 INFO:     Epoch: 45
2022-11-23 01:51:45,007 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8434311991388147, 'Total loss': 0.8434311991388147} | train loss {'Reaction outcome loss': 0.804394548698779, 'Total loss': 0.804394548698779}
2022-11-23 01:51:45,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:45,007 INFO:     Epoch: 46
2022-11-23 01:51:45,863 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8173120069232854, 'Total loss': 0.8173120069232854} | train loss {'Reaction outcome loss': 0.8050814885045251, 'Total loss': 0.8050814885045251}
2022-11-23 01:51:45,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:45,863 INFO:     Epoch: 47
2022-11-23 01:51:46,676 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8214181905443018, 'Total loss': 0.8214181905443018} | train loss {'Reaction outcome loss': 0.805777920950805, 'Total loss': 0.805777920950805}
2022-11-23 01:51:46,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:46,676 INFO:     Epoch: 48
2022-11-23 01:51:47,502 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8401593159545552, 'Total loss': 0.8401593159545552} | train loss {'Reaction outcome loss': 0.8045245755103326, 'Total loss': 0.8045245755103326}
2022-11-23 01:51:47,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:47,502 INFO:     Epoch: 49
2022-11-23 01:51:48,329 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8367230458693071, 'Total loss': 0.8367230458693071} | train loss {'Reaction outcome loss': 0.8041643010031793, 'Total loss': 0.8041643010031793}
2022-11-23 01:51:48,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:48,330 INFO:     Epoch: 50
2022-11-23 01:51:49,143 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.826594202355905, 'Total loss': 0.826594202355905} | train loss {'Reaction outcome loss': 0.8037083188612615, 'Total loss': 0.8037083188612615}
2022-11-23 01:51:49,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:49,144 INFO:     Epoch: 51
2022-11-23 01:51:49,940 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8362214016643438, 'Total loss': 0.8362214016643438} | train loss {'Reaction outcome loss': 0.8092137009746605, 'Total loss': 0.8092137009746605}
2022-11-23 01:51:49,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:49,940 INFO:     Epoch: 52
2022-11-23 01:51:50,758 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8210609297860753, 'Total loss': 0.8210609297860753} | train loss {'Reaction outcome loss': 0.8068903018870661, 'Total loss': 0.8068903018870661}
2022-11-23 01:51:50,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:50,759 INFO:     Epoch: 53
2022-11-23 01:51:51,584 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8345242874188856, 'Total loss': 0.8345242874188856} | train loss {'Reaction outcome loss': 0.8003142378142765, 'Total loss': 0.8003142378142765}
2022-11-23 01:51:51,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:51,584 INFO:     Epoch: 54
2022-11-23 01:51:52,428 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8390658714554526, 'Total loss': 0.8390658714554526} | train loss {'Reaction outcome loss': 0.8056355713596267, 'Total loss': 0.8056355713596267}
2022-11-23 01:51:52,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:52,429 INFO:     Epoch: 55
2022-11-23 01:51:53,260 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8376046974550594, 'Total loss': 0.8376046974550594} | train loss {'Reaction outcome loss': 0.799223451364425, 'Total loss': 0.799223451364425}
2022-11-23 01:51:53,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:53,260 INFO:     Epoch: 56
2022-11-23 01:51:54,058 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8384428071704778, 'Total loss': 0.8384428071704778} | train loss {'Reaction outcome loss': 0.8098025306338265, 'Total loss': 0.8098025306338265}
2022-11-23 01:51:54,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:54,059 INFO:     Epoch: 57
2022-11-23 01:51:54,841 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8266981474377892, 'Total loss': 0.8266981474377892} | train loss {'Reaction outcome loss': 0.8016348405470771, 'Total loss': 0.8016348405470771}
2022-11-23 01:51:54,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:54,842 INFO:     Epoch: 58
2022-11-23 01:51:55,697 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8304253085093065, 'Total loss': 0.8304253085093065} | train loss {'Reaction outcome loss': 0.8064439532256895, 'Total loss': 0.8064439532256895}
2022-11-23 01:51:55,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:55,697 INFO:     Epoch: 59
2022-11-23 01:51:56,625 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8363638784397732, 'Total loss': 0.8363638784397732} | train loss {'Reaction outcome loss': 0.8023560854696459, 'Total loss': 0.8023560854696459}
2022-11-23 01:51:56,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:56,625 INFO:     Epoch: 60
2022-11-23 01:51:57,522 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8562750843438235, 'Total loss': 0.8562750843438235} | train loss {'Reaction outcome loss': 0.8078888259347408, 'Total loss': 0.8078888259347408}
2022-11-23 01:51:57,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:57,522 INFO:     Epoch: 61
2022-11-23 01:51:58,381 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8187774365598505, 'Total loss': 0.8187774365598505} | train loss {'Reaction outcome loss': 0.8111454345766576, 'Total loss': 0.8111454345766576}
2022-11-23 01:51:58,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:58,382 INFO:     Epoch: 62
2022-11-23 01:51:59,228 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8494441455060785, 'Total loss': 0.8494441455060785} | train loss {'Reaction outcome loss': 0.8020944566495957, 'Total loss': 0.8020944566495957}
2022-11-23 01:51:59,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:51:59,229 INFO:     Epoch: 63
2022-11-23 01:52:00,171 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8316888023506511, 'Total loss': 0.8316888023506511} | train loss {'Reaction outcome loss': 0.8094409319662279, 'Total loss': 0.8094409319662279}
2022-11-23 01:52:00,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:00,171 INFO:     Epoch: 64
2022-11-23 01:52:01,093 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.830881571227854, 'Total loss': 0.830881571227854} | train loss {'Reaction outcome loss': 0.8073333167741376, 'Total loss': 0.8073333167741376}
2022-11-23 01:52:01,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:01,093 INFO:     Epoch: 65
2022-11-23 01:52:02,011 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.830282368443229, 'Total loss': 0.830282368443229} | train loss {'Reaction outcome loss': 0.8091938766019959, 'Total loss': 0.8091938766019959}
2022-11-23 01:52:02,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:02,012 INFO:     Epoch: 66
2022-11-23 01:52:02,918 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8189589841799303, 'Total loss': 0.8189589841799303} | train loss {'Reaction outcome loss': 0.8052771526478952, 'Total loss': 0.8052771526478952}
2022-11-23 01:52:02,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:02,918 INFO:     Epoch: 67
2022-11-23 01:52:03,848 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8173689320683479, 'Total loss': 0.8173689320683479} | train loss {'Reaction outcome loss': 0.8049188812653865, 'Total loss': 0.8049188812653865}
2022-11-23 01:52:03,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:03,848 INFO:     Epoch: 68
2022-11-23 01:52:04,753 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8192639019001614, 'Total loss': 0.8192639019001614} | train loss {'Reaction outcome loss': 0.8022975872360891, 'Total loss': 0.8022975872360891}
2022-11-23 01:52:04,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:04,753 INFO:     Epoch: 69
2022-11-23 01:52:05,710 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8393687043677677, 'Total loss': 0.8393687043677677} | train loss {'Reaction outcome loss': 0.8060472628041622, 'Total loss': 0.8060472628041622}
2022-11-23 01:52:05,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:05,710 INFO:     Epoch: 70
2022-11-23 01:52:06,670 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8217011453075842, 'Total loss': 0.8217011453075842} | train loss {'Reaction outcome loss': 0.8062089931580328, 'Total loss': 0.8062089931580328}
2022-11-23 01:52:06,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:06,670 INFO:     Epoch: 71
2022-11-23 01:52:07,587 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.834643773057244, 'Total loss': 0.834643773057244} | train loss {'Reaction outcome loss': 0.8044549605298427, 'Total loss': 0.8044549605298427}
2022-11-23 01:52:07,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:07,588 INFO:     Epoch: 72
2022-11-23 01:52:08,474 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8399393592368473, 'Total loss': 0.8399393592368473} | train loss {'Reaction outcome loss': 0.8029151176733356, 'Total loss': 0.8029151176733356}
2022-11-23 01:52:08,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:08,475 INFO:     Epoch: 73
2022-11-23 01:52:09,391 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8440188426863063, 'Total loss': 0.8440188426863063} | train loss {'Reaction outcome loss': 0.8014235708021349, 'Total loss': 0.8014235708021349}
2022-11-23 01:52:09,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:09,391 INFO:     Epoch: 74
2022-11-23 01:52:10,288 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8096812272613699, 'Total loss': 0.8096812272613699} | train loss {'Reaction outcome loss': 0.8085296747665252, 'Total loss': 0.8085296747665252}
2022-11-23 01:52:10,288 INFO:     Found new best model at epoch 74
2022-11-23 01:52:10,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:10,289 INFO:     Epoch: 75
2022-11-23 01:52:11,153 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8214019760489464, 'Total loss': 0.8214019760489464} | train loss {'Reaction outcome loss': 0.8015087941481222, 'Total loss': 0.8015087941481222}
2022-11-23 01:52:11,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:11,154 INFO:     Epoch: 76
2022-11-23 01:52:12,034 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8340777016498826, 'Total loss': 0.8340777016498826} | train loss {'Reaction outcome loss': 0.8083113824888584, 'Total loss': 0.8083113824888584}
2022-11-23 01:52:12,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:12,035 INFO:     Epoch: 77
2022-11-23 01:52:12,959 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8343206854029135, 'Total loss': 0.8343206854029135} | train loss {'Reaction outcome loss': 0.8098551495180976, 'Total loss': 0.8098551495180976}
2022-11-23 01:52:12,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:12,959 INFO:     Epoch: 78
2022-11-23 01:52:13,865 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8054457394914194, 'Total loss': 0.8054457394914194} | train loss {'Reaction outcome loss': 0.8008946996302374, 'Total loss': 0.8008946996302374}
2022-11-23 01:52:13,865 INFO:     Found new best model at epoch 78
2022-11-23 01:52:13,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:13,866 INFO:     Epoch: 79
2022-11-23 01:52:14,810 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8325198265639219, 'Total loss': 0.8325198265639219} | train loss {'Reaction outcome loss': 0.8040854261527138, 'Total loss': 0.8040854261527138}
2022-11-23 01:52:14,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:14,810 INFO:     Epoch: 80
2022-11-23 01:52:15,702 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8498811566016891, 'Total loss': 0.8498811566016891} | train loss {'Reaction outcome loss': 0.7973628892533241, 'Total loss': 0.7973628892533241}
2022-11-23 01:52:15,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:15,703 INFO:     Epoch: 81
2022-11-23 01:52:16,593 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8177883489565416, 'Total loss': 0.8177883489565416} | train loss {'Reaction outcome loss': 0.8060819652051695, 'Total loss': 0.8060819652051695}
2022-11-23 01:52:16,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:16,593 INFO:     Epoch: 82
2022-11-23 01:52:17,489 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8185635615478862, 'Total loss': 0.8185635615478862} | train loss {'Reaction outcome loss': 0.803845498951212, 'Total loss': 0.803845498951212}
2022-11-23 01:52:17,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:17,489 INFO:     Epoch: 83
2022-11-23 01:52:18,453 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.833282161842693, 'Total loss': 0.833282161842693} | train loss {'Reaction outcome loss': 0.8023169499731833, 'Total loss': 0.8023169499731833}
2022-11-23 01:52:18,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:18,453 INFO:     Epoch: 84
2022-11-23 01:52:19,372 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8179126774722879, 'Total loss': 0.8179126774722879} | train loss {'Reaction outcome loss': 0.8084908477481334, 'Total loss': 0.8084908477481334}
2022-11-23 01:52:19,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:19,373 INFO:     Epoch: 85
2022-11-23 01:52:20,336 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8512834683060646, 'Total loss': 0.8512834683060646} | train loss {'Reaction outcome loss': 0.8079379646768493, 'Total loss': 0.8079379646768493}
2022-11-23 01:52:20,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:20,336 INFO:     Epoch: 86
2022-11-23 01:52:21,226 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8333685181357644, 'Total loss': 0.8333685181357644} | train loss {'Reaction outcome loss': 0.8070809282362461, 'Total loss': 0.8070809282362461}
2022-11-23 01:52:21,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:21,226 INFO:     Epoch: 87
2022-11-23 01:52:22,151 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.820055987347256, 'Total loss': 0.820055987347256} | train loss {'Reaction outcome loss': 0.8077322483783768, 'Total loss': 0.8077322483783768}
2022-11-23 01:52:22,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:22,151 INFO:     Epoch: 88
2022-11-23 01:52:23,052 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8121236637234688, 'Total loss': 0.8121236637234688} | train loss {'Reaction outcome loss': 0.8035431354036254, 'Total loss': 0.8035431354036254}
2022-11-23 01:52:23,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:23,052 INFO:     Epoch: 89
2022-11-23 01:52:23,970 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8437080342661251, 'Total loss': 0.8437080342661251} | train loss {'Reaction outcome loss': 0.8034746054439775, 'Total loss': 0.8034746054439775}
2022-11-23 01:52:23,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:23,971 INFO:     Epoch: 90
2022-11-23 01:52:24,860 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8164862678809599, 'Total loss': 0.8164862678809599} | train loss {'Reaction outcome loss': 0.8078567829103239, 'Total loss': 0.8078567829103239}
2022-11-23 01:52:24,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:24,860 INFO:     Epoch: 91
2022-11-23 01:52:25,744 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.823077218099074, 'Total loss': 0.823077218099074} | train loss {'Reaction outcome loss': 0.8016672037061183, 'Total loss': 0.8016672037061183}
2022-11-23 01:52:25,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:25,745 INFO:     Epoch: 92
2022-11-23 01:52:26,682 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8503149368546226, 'Total loss': 0.8503149368546226} | train loss {'Reaction outcome loss': 0.8008613461448301, 'Total loss': 0.8008613461448301}
2022-11-23 01:52:26,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:26,683 INFO:     Epoch: 93
2022-11-23 01:52:27,540 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8277880292047154, 'Total loss': 0.8277880292047154} | train loss {'Reaction outcome loss': 0.8033272662470418, 'Total loss': 0.8033272662470418}
2022-11-23 01:52:27,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:27,540 INFO:     Epoch: 94
2022-11-23 01:52:28,370 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8355665186589415, 'Total loss': 0.8355665186589415} | train loss {'Reaction outcome loss': 0.8078434261823854, 'Total loss': 0.8078434261823854}
2022-11-23 01:52:28,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:28,370 INFO:     Epoch: 95
2022-11-23 01:52:29,225 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.826698823408647, 'Total loss': 0.826698823408647} | train loss {'Reaction outcome loss': 0.8019476188046317, 'Total loss': 0.8019476188046317}
2022-11-23 01:52:29,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:29,225 INFO:     Epoch: 96
2022-11-23 01:52:30,102 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8247744474898685, 'Total loss': 0.8247744474898685} | train loss {'Reaction outcome loss': 0.8046014189960495, 'Total loss': 0.8046014189960495}
2022-11-23 01:52:30,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:30,102 INFO:     Epoch: 97
2022-11-23 01:52:30,942 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8180798441171646, 'Total loss': 0.8180798441171646} | train loss {'Reaction outcome loss': 0.8044570017485849, 'Total loss': 0.8044570017485849}
2022-11-23 01:52:30,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:30,942 INFO:     Epoch: 98
2022-11-23 01:52:31,795 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8207854865626856, 'Total loss': 0.8207854865626856} | train loss {'Reaction outcome loss': 0.8022677691713456, 'Total loss': 0.8022677691713456}
2022-11-23 01:52:31,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:31,795 INFO:     Epoch: 99
2022-11-23 01:52:32,675 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8293082280592485, 'Total loss': 0.8293082280592485} | train loss {'Reaction outcome loss': 0.8048355220065962, 'Total loss': 0.8048355220065962}
2022-11-23 01:52:32,676 INFO:     Best model found after epoch 79 of 100.
2022-11-23 01:52:32,676 INFO:   Done with stage: TRAINING
2022-11-23 01:52:32,676 INFO:   Starting stage: EVALUATION
2022-11-23 01:52:32,796 INFO:   Done with stage: EVALUATION
2022-11-23 01:52:32,797 INFO:   Leaving out SEQ value Fold_7
2022-11-23 01:52:32,810 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:52:32,810 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:52:33,493 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:52:33,493 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:52:33,569 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:52:33,569 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:52:33,569 INFO:     No hyperparam tuning for this model
2022-11-23 01:52:33,569 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:52:33,569 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:52:33,570 INFO:     None feature selector for col prot
2022-11-23 01:52:33,570 INFO:     None feature selector for col prot
2022-11-23 01:52:33,570 INFO:     None feature selector for col prot
2022-11-23 01:52:33,571 INFO:     None feature selector for col chem
2022-11-23 01:52:33,571 INFO:     None feature selector for col chem
2022-11-23 01:52:33,571 INFO:     None feature selector for col chem
2022-11-23 01:52:33,571 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:52:33,571 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:52:33,572 INFO:     Number of params in model 168571
2022-11-23 01:52:33,576 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:52:33,576 INFO:   Starting stage: TRAINING
2022-11-23 01:52:33,637 INFO:     Val loss before train {'Reaction outcome loss': 1.0585524385625666, 'Total loss': 1.0585524385625666}
2022-11-23 01:52:33,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:33,637 INFO:     Epoch: 0
2022-11-23 01:52:34,576 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.868570934642445, 'Total loss': 0.868570934642445} | train loss {'Reaction outcome loss': 0.8674277254203071, 'Total loss': 0.8674277254203071}
2022-11-23 01:52:34,576 INFO:     Found new best model at epoch 0
2022-11-23 01:52:34,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:34,577 INFO:     Epoch: 1
2022-11-23 01:52:35,401 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8739529373970899, 'Total loss': 0.8739529373970899} | train loss {'Reaction outcome loss': 0.8400422335877592, 'Total loss': 0.8400422335877592}
2022-11-23 01:52:35,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:35,401 INFO:     Epoch: 2
2022-11-23 01:52:36,241 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.892829189246351, 'Total loss': 0.892829189246351} | train loss {'Reaction outcome loss': 0.8331178164916483, 'Total loss': 0.8331178164916483}
2022-11-23 01:52:36,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:36,242 INFO:     Epoch: 3
2022-11-23 01:52:37,077 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8693447289141741, 'Total loss': 0.8693447289141741} | train loss {'Reaction outcome loss': 0.8340742632083082, 'Total loss': 0.8340742632083082}
2022-11-23 01:52:37,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:37,077 INFO:     Epoch: 4
2022-11-23 01:52:37,902 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8701245066794482, 'Total loss': 0.8701245066794482} | train loss {'Reaction outcome loss': 0.8291021452741585, 'Total loss': 0.8291021452741585}
2022-11-23 01:52:37,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:37,903 INFO:     Epoch: 5
2022-11-23 01:52:38,744 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8754545612768694, 'Total loss': 0.8754545612768694} | train loss {'Reaction outcome loss': 0.8246535307723983, 'Total loss': 0.8246535307723983}
2022-11-23 01:52:38,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:38,744 INFO:     Epoch: 6
2022-11-23 01:52:39,584 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8473493544892832, 'Total loss': 0.8473493544892832} | train loss {'Reaction outcome loss': 0.8203073202779418, 'Total loss': 0.8203073202779418}
2022-11-23 01:52:39,584 INFO:     Found new best model at epoch 6
2022-11-23 01:52:39,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:39,585 INFO:     Epoch: 7
2022-11-23 01:52:40,402 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8395068672570315, 'Total loss': 0.8395068672570315} | train loss {'Reaction outcome loss': 0.8166714077777708, 'Total loss': 0.8166714077777708}
2022-11-23 01:52:40,402 INFO:     Found new best model at epoch 7
2022-11-23 01:52:40,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:40,403 INFO:     Epoch: 8
2022-11-23 01:52:41,267 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8478834480047226, 'Total loss': 0.8478834480047226} | train loss {'Reaction outcome loss': 0.8155202972382186, 'Total loss': 0.8155202972382186}
2022-11-23 01:52:41,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:41,267 INFO:     Epoch: 9
2022-11-23 01:52:42,137 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8478495322845199, 'Total loss': 0.8478495322845199} | train loss {'Reaction outcome loss': 0.8161506885097094, 'Total loss': 0.8161506885097094}
2022-11-23 01:52:42,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:42,138 INFO:     Epoch: 10
2022-11-23 01:52:43,044 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8480151397260752, 'Total loss': 0.8480151397260752} | train loss {'Reaction outcome loss': 0.8193217445813451, 'Total loss': 0.8193217445813451}
2022-11-23 01:52:43,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:43,044 INFO:     Epoch: 11
2022-11-23 01:52:43,924 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.846721429716457, 'Total loss': 0.846721429716457} | train loss {'Reaction outcome loss': 0.8128015852046881, 'Total loss': 0.8128015852046881}
2022-11-23 01:52:43,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:43,924 INFO:     Epoch: 12
2022-11-23 01:52:44,791 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8597912354902788, 'Total loss': 0.8597912354902788} | train loss {'Reaction outcome loss': 0.8195358611311507, 'Total loss': 0.8195358611311507}
2022-11-23 01:52:44,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:44,792 INFO:     Epoch: 13
2022-11-23 01:52:45,669 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8479829796335914, 'Total loss': 0.8479829796335914} | train loss {'Reaction outcome loss': 0.8208848277808201, 'Total loss': 0.8208848277808201}
2022-11-23 01:52:45,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:45,669 INFO:     Epoch: 14
2022-11-23 01:52:46,561 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8485525826161558, 'Total loss': 0.8485525826161558} | train loss {'Reaction outcome loss': 0.8259974142559144, 'Total loss': 0.8259974142559144}
2022-11-23 01:52:46,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:46,561 INFO:     Epoch: 15
2022-11-23 01:52:47,425 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8602313480593942, 'Total loss': 0.8602313480593942} | train loss {'Reaction outcome loss': 0.8209384771493765, 'Total loss': 0.8209384771493765}
2022-11-23 01:52:47,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:47,426 INFO:     Epoch: 16
2022-11-23 01:52:48,300 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8517515713518317, 'Total loss': 0.8517515713518317} | train loss {'Reaction outcome loss': 0.8170576452726295, 'Total loss': 0.8170576452726295}
2022-11-23 01:52:48,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:48,300 INFO:     Epoch: 17
2022-11-23 01:52:49,133 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8371620652350512, 'Total loss': 0.8371620652350512} | train loss {'Reaction outcome loss': 0.8132811794547659, 'Total loss': 0.8132811794547659}
2022-11-23 01:52:49,134 INFO:     Found new best model at epoch 17
2022-11-23 01:52:49,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:49,134 INFO:     Epoch: 18
2022-11-23 01:52:50,008 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8495047173716805, 'Total loss': 0.8495047173716805} | train loss {'Reaction outcome loss': 0.8146490210946272, 'Total loss': 0.8146490210946272}
2022-11-23 01:52:50,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:50,008 INFO:     Epoch: 19
2022-11-23 01:52:50,873 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8373820294033397, 'Total loss': 0.8373820294033397} | train loss {'Reaction outcome loss': 0.8079310335852357, 'Total loss': 0.8079310335852357}
2022-11-23 01:52:50,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:50,875 INFO:     Epoch: 20
2022-11-23 01:52:51,753 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8350661017678, 'Total loss': 0.8350661017678} | train loss {'Reaction outcome loss': 0.8102212031239923, 'Total loss': 0.8102212031239923}
2022-11-23 01:52:51,753 INFO:     Found new best model at epoch 20
2022-11-23 01:52:51,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:51,754 INFO:     Epoch: 21
2022-11-23 01:52:52,610 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8507954369891774, 'Total loss': 0.8507954369891774} | train loss {'Reaction outcome loss': 0.8124465781908768, 'Total loss': 0.8124465781908768}
2022-11-23 01:52:52,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:52,611 INFO:     Epoch: 22
2022-11-23 01:52:53,521 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8503114594654604, 'Total loss': 0.8503114594654604} | train loss {'Reaction outcome loss': 0.8126520660483403, 'Total loss': 0.8126520660483403}
2022-11-23 01:52:53,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:53,521 INFO:     Epoch: 23
2022-11-23 01:52:54,364 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.837461147796024, 'Total loss': 0.837461147796024} | train loss {'Reaction outcome loss': 0.813056672270964, 'Total loss': 0.813056672270964}
2022-11-23 01:52:54,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:54,364 INFO:     Epoch: 24
2022-11-23 01:52:55,228 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8545631942423907, 'Total loss': 0.8545631942423907} | train loss {'Reaction outcome loss': 0.8111817241921598, 'Total loss': 0.8111817241921598}
2022-11-23 01:52:55,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:55,229 INFO:     Epoch: 25
2022-11-23 01:52:56,113 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8302883383902636, 'Total loss': 0.8302883383902636} | train loss {'Reaction outcome loss': 0.8189492480233613, 'Total loss': 0.8189492480233613}
2022-11-23 01:52:56,113 INFO:     Found new best model at epoch 25
2022-11-23 01:52:56,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:56,114 INFO:     Epoch: 26
2022-11-23 01:52:56,982 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8392402922565286, 'Total loss': 0.8392402922565286} | train loss {'Reaction outcome loss': 0.8126057715189119, 'Total loss': 0.8126057715189119}
2022-11-23 01:52:56,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:56,984 INFO:     Epoch: 27
2022-11-23 01:52:57,850 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8412089361385866, 'Total loss': 0.8412089361385866} | train loss {'Reaction outcome loss': 0.8143909539770984, 'Total loss': 0.8143909539770984}
2022-11-23 01:52:57,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:57,851 INFO:     Epoch: 28
2022-11-23 01:52:58,690 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8338317247954282, 'Total loss': 0.8338317247954282} | train loss {'Reaction outcome loss': 0.8136171938678031, 'Total loss': 0.8136171938678031}
2022-11-23 01:52:58,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:58,691 INFO:     Epoch: 29
2022-11-23 01:52:59,530 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8402571515603499, 'Total loss': 0.8402571515603499} | train loss {'Reaction outcome loss': 0.8131385448007931, 'Total loss': 0.8131385448007931}
2022-11-23 01:52:59,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:52:59,531 INFO:     Epoch: 30
2022-11-23 01:53:00,343 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8417321287772872, 'Total loss': 0.8417321287772872} | train loss {'Reaction outcome loss': 0.8119640060764576, 'Total loss': 0.8119640060764576}
2022-11-23 01:53:00,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:00,343 INFO:     Epoch: 31
2022-11-23 01:53:01,189 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8338549516417764, 'Total loss': 0.8338549516417764} | train loss {'Reaction outcome loss': 0.8087196937396459, 'Total loss': 0.8087196937396459}
2022-11-23 01:53:01,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:01,189 INFO:     Epoch: 32
2022-11-23 01:53:02,048 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8474707569588315, 'Total loss': 0.8474707569588315} | train loss {'Reaction outcome loss': 0.810786898440195, 'Total loss': 0.810786898440195}
2022-11-23 01:53:02,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:02,048 INFO:     Epoch: 33
2022-11-23 01:53:02,871 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8447440761056814, 'Total loss': 0.8447440761056814} | train loss {'Reaction outcome loss': 0.8073563062951632, 'Total loss': 0.8073563062951632}
2022-11-23 01:53:02,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:02,871 INFO:     Epoch: 34
2022-11-23 01:53:03,664 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8391436528075825, 'Total loss': 0.8391436528075825} | train loss {'Reaction outcome loss': 0.8121460285263988, 'Total loss': 0.8121460285263988}
2022-11-23 01:53:03,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:03,665 INFO:     Epoch: 35
2022-11-23 01:53:04,476 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8417795632373203, 'Total loss': 0.8417795632373203} | train loss {'Reaction outcome loss': 0.8088505056946866, 'Total loss': 0.8088505056946866}
2022-11-23 01:53:04,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:04,476 INFO:     Epoch: 36
2022-11-23 01:53:05,269 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8593388050794601, 'Total loss': 0.8593388050794601} | train loss {'Reaction outcome loss': 0.8205508943270092, 'Total loss': 0.8205508943270092}
2022-11-23 01:53:05,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:05,269 INFO:     Epoch: 37
2022-11-23 01:53:06,052 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8391305147246881, 'Total loss': 0.8391305147246881} | train loss {'Reaction outcome loss': 0.8082825517364842, 'Total loss': 0.8082825517364842}
2022-11-23 01:53:06,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:06,052 INFO:     Epoch: 38
2022-11-23 01:53:06,815 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8549773286689412, 'Total loss': 0.8549773286689412} | train loss {'Reaction outcome loss': 0.8088650339045506, 'Total loss': 0.8088650339045506}
2022-11-23 01:53:06,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:06,815 INFO:     Epoch: 39
2022-11-23 01:53:07,600 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8520740257068113, 'Total loss': 0.8520740257068113} | train loss {'Reaction outcome loss': 0.8089516586228179, 'Total loss': 0.8089516586228179}
2022-11-23 01:53:07,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:07,600 INFO:     Epoch: 40
2022-11-23 01:53:08,438 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8485835201360963, 'Total loss': 0.8485835201360963} | train loss {'Reaction outcome loss': 0.8087663769963299, 'Total loss': 0.8087663769963299}
2022-11-23 01:53:08,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:08,438 INFO:     Epoch: 41
2022-11-23 01:53:09,241 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8476192030039701, 'Total loss': 0.8476192030039701} | train loss {'Reaction outcome loss': 0.8094010338609517, 'Total loss': 0.8094010338609517}
2022-11-23 01:53:09,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:09,242 INFO:     Epoch: 42
2022-11-23 01:53:10,059 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8796161596070636, 'Total loss': 0.8796161596070636} | train loss {'Reaction outcome loss': 0.8097840747852557, 'Total loss': 0.8097840747852557}
2022-11-23 01:53:10,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:10,060 INFO:     Epoch: 43
2022-11-23 01:53:10,847 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8340638422153213, 'Total loss': 0.8340638422153213} | train loss {'Reaction outcome loss': 0.8131102612053576, 'Total loss': 0.8131102612053576}
2022-11-23 01:53:10,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:10,847 INFO:     Epoch: 44
2022-11-23 01:53:11,681 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8447487943551757, 'Total loss': 0.8447487943551757} | train loss {'Reaction outcome loss': 0.8074032110482575, 'Total loss': 0.8074032110482575}
2022-11-23 01:53:11,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:11,681 INFO:     Epoch: 45
2022-11-23 01:53:12,503 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.850347376005216, 'Total loss': 0.850347376005216} | train loss {'Reaction outcome loss': 0.8112498224988157, 'Total loss': 0.8112498224988157}
2022-11-23 01:53:12,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:12,503 INFO:     Epoch: 46
2022-11-23 01:53:13,296 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8760414570569992, 'Total loss': 0.8760414570569992} | train loss {'Reaction outcome loss': 0.8071576098078176, 'Total loss': 0.8071576098078176}
2022-11-23 01:53:13,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:13,296 INFO:     Epoch: 47
2022-11-23 01:53:14,135 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8555681542916731, 'Total loss': 0.8555681542916731} | train loss {'Reaction outcome loss': 0.8051646984057871, 'Total loss': 0.8051646984057871}
2022-11-23 01:53:14,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:14,135 INFO:     Epoch: 48
2022-11-23 01:53:14,958 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8380895812403072, 'Total loss': 0.8380895812403072} | train loss {'Reaction outcome loss': 0.8136243964979041, 'Total loss': 0.8136243964979041}
2022-11-23 01:53:14,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:14,958 INFO:     Epoch: 49
2022-11-23 01:53:15,800 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8569914759560064, 'Total loss': 0.8569914759560064} | train loss {'Reaction outcome loss': 0.8125221379372755, 'Total loss': 0.8125221379372755}
2022-11-23 01:53:15,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:15,801 INFO:     Epoch: 50
2022-11-23 01:53:16,589 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8551526218652725, 'Total loss': 0.8551526218652725} | train loss {'Reaction outcome loss': 0.8142660811603794, 'Total loss': 0.8142660811603794}
2022-11-23 01:53:16,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:16,589 INFO:     Epoch: 51
2022-11-23 01:53:17,384 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.833213409916921, 'Total loss': 0.833213409916921} | train loss {'Reaction outcome loss': 0.8193685434125213, 'Total loss': 0.8193685434125213}
2022-11-23 01:53:17,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:17,384 INFO:     Epoch: 52
2022-11-23 01:53:18,241 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8318724171681837, 'Total loss': 0.8318724171681837} | train loss {'Reaction outcome loss': 0.8057868950038787, 'Total loss': 0.8057868950038787}
2022-11-23 01:53:18,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:18,242 INFO:     Epoch: 53
2022-11-23 01:53:19,026 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8347318707541986, 'Total loss': 0.8347318707541986} | train loss {'Reaction outcome loss': 0.8071025871796164, 'Total loss': 0.8071025871796164}
2022-11-23 01:53:19,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:19,026 INFO:     Epoch: 54
2022-11-23 01:53:19,807 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.831383386796171, 'Total loss': 0.831383386796171} | train loss {'Reaction outcome loss': 0.8090296303664866, 'Total loss': 0.8090296303664866}
2022-11-23 01:53:19,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:19,807 INFO:     Epoch: 55
2022-11-23 01:53:20,616 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8412628973072226, 'Total loss': 0.8412628973072226} | train loss {'Reaction outcome loss': 0.816210808782925, 'Total loss': 0.816210808782925}
2022-11-23 01:53:20,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:20,616 INFO:     Epoch: 56
2022-11-23 01:53:21,444 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8430317897688259, 'Total loss': 0.8430317897688259} | train loss {'Reaction outcome loss': 0.8121303860475177, 'Total loss': 0.8121303860475177}
2022-11-23 01:53:21,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:21,445 INFO:     Epoch: 57
2022-11-23 01:53:22,270 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8406839770349589, 'Total loss': 0.8406839770349589} | train loss {'Reaction outcome loss': 0.8150209003855825, 'Total loss': 0.8150209003855825}
2022-11-23 01:53:22,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:22,271 INFO:     Epoch: 58
2022-11-23 01:53:23,095 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8479821688749574, 'Total loss': 0.8479821688749574} | train loss {'Reaction outcome loss': 0.8090819326730875, 'Total loss': 0.8090819326730875}
2022-11-23 01:53:23,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:23,095 INFO:     Epoch: 59
2022-11-23 01:53:23,908 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.826681336895986, 'Total loss': 0.826681336895986} | train loss {'Reaction outcome loss': 0.80992639740469, 'Total loss': 0.80992639740469}
2022-11-23 01:53:23,909 INFO:     Found new best model at epoch 59
2022-11-23 01:53:23,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:23,909 INFO:     Epoch: 60
2022-11-23 01:53:24,702 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8439513207836584, 'Total loss': 0.8439513207836584} | train loss {'Reaction outcome loss': 0.8084017121598788, 'Total loss': 0.8084017121598788}
2022-11-23 01:53:24,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:24,702 INFO:     Epoch: 61
2022-11-23 01:53:25,533 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8434059592810544, 'Total loss': 0.8434059592810544} | train loss {'Reaction outcome loss': 0.812713226688053, 'Total loss': 0.812713226688053}
2022-11-23 01:53:25,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:25,533 INFO:     Epoch: 62
2022-11-23 01:53:26,340 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8543368550864133, 'Total loss': 0.8543368550864133} | train loss {'Reaction outcome loss': 0.807483360472961, 'Total loss': 0.807483360472961}
2022-11-23 01:53:26,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:26,340 INFO:     Epoch: 63
2022-11-23 01:53:27,173 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8303711759773168, 'Total loss': 0.8303711759773168} | train loss {'Reaction outcome loss': 0.8178780426380605, 'Total loss': 0.8178780426380605}
2022-11-23 01:53:27,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:27,173 INFO:     Epoch: 64
2022-11-23 01:53:27,995 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8400219435041602, 'Total loss': 0.8400219435041602} | train loss {'Reaction outcome loss': 0.8180884423284878, 'Total loss': 0.8180884423284878}
2022-11-23 01:53:27,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:27,996 INFO:     Epoch: 65
2022-11-23 01:53:28,804 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8276915523138914, 'Total loss': 0.8276915523138914} | train loss {'Reaction outcome loss': 0.8091612396693906, 'Total loss': 0.8091612396693906}
2022-11-23 01:53:28,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:28,804 INFO:     Epoch: 66
2022-11-23 01:53:29,619 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.849474426697601, 'Total loss': 0.849474426697601} | train loss {'Reaction outcome loss': 0.8122723299240776, 'Total loss': 0.8122723299240776}
2022-11-23 01:53:29,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:29,620 INFO:     Epoch: 67
2022-11-23 01:53:30,415 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8352250836112283, 'Total loss': 0.8352250836112283} | train loss {'Reaction outcome loss': 0.8058300300045051, 'Total loss': 0.8058300300045051}
2022-11-23 01:53:30,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:30,415 INFO:     Epoch: 68
2022-11-23 01:53:31,235 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8378977782346986, 'Total loss': 0.8378977782346986} | train loss {'Reaction outcome loss': 0.8124281538401538, 'Total loss': 0.8124281538401538}
2022-11-23 01:53:31,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:31,235 INFO:     Epoch: 69
2022-11-23 01:53:32,079 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.843740505928343, 'Total loss': 0.843740505928343} | train loss {'Reaction outcome loss': 0.8100539302295037, 'Total loss': 0.8100539302295037}
2022-11-23 01:53:32,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:32,079 INFO:     Epoch: 70
2022-11-23 01:53:32,871 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8362403525547548, 'Total loss': 0.8362403525547548} | train loss {'Reaction outcome loss': 0.8103007145738794, 'Total loss': 0.8103007145738794}
2022-11-23 01:53:32,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:32,871 INFO:     Epoch: 71
2022-11-23 01:53:33,672 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.82707634026354, 'Total loss': 0.82707634026354} | train loss {'Reaction outcome loss': 0.8120624404928463, 'Total loss': 0.8120624404928463}
2022-11-23 01:53:33,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:33,672 INFO:     Epoch: 72
2022-11-23 01:53:34,510 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8238803398880091, 'Total loss': 0.8238803398880091} | train loss {'Reaction outcome loss': 0.8191149675170419, 'Total loss': 0.8191149675170419}
2022-11-23 01:53:34,510 INFO:     Found new best model at epoch 72
2022-11-23 01:53:34,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:34,511 INFO:     Epoch: 73
2022-11-23 01:53:35,308 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8524826724420894, 'Total loss': 0.8524826724420894} | train loss {'Reaction outcome loss': 0.8080823047441027, 'Total loss': 0.8080823047441027}
2022-11-23 01:53:35,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:35,308 INFO:     Epoch: 74
2022-11-23 01:53:36,060 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.833256449889053, 'Total loss': 0.833256449889053} | train loss {'Reaction outcome loss': 0.8131466626155714, 'Total loss': 0.8131466626155714}
2022-11-23 01:53:36,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:36,060 INFO:     Epoch: 75
2022-11-23 01:53:36,885 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8306779617613013, 'Total loss': 0.8306779617613013} | train loss {'Reaction outcome loss': 0.8075431651673336, 'Total loss': 0.8075431651673336}
2022-11-23 01:53:36,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:36,886 INFO:     Epoch: 76
2022-11-23 01:53:37,673 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8307972171089866, 'Total loss': 0.8307972171089866} | train loss {'Reaction outcome loss': 0.8111340798105788, 'Total loss': 0.8111340798105788}
2022-11-23 01:53:37,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:37,673 INFO:     Epoch: 77
2022-11-23 01:53:38,467 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8424984921108593, 'Total loss': 0.8424984921108593} | train loss {'Reaction outcome loss': 0.8004496071246351, 'Total loss': 0.8004496071246351}
2022-11-23 01:53:38,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:38,468 INFO:     Epoch: 78
2022-11-23 01:53:39,261 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8352003463289954, 'Total loss': 0.8352003463289954} | train loss {'Reaction outcome loss': 0.81288179706948, 'Total loss': 0.81288179706948}
2022-11-23 01:53:39,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:39,261 INFO:     Epoch: 79
2022-11-23 01:53:40,065 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8486290032213385, 'Total loss': 0.8486290032213385} | train loss {'Reaction outcome loss': 0.8219434497086143, 'Total loss': 0.8219434497086143}
2022-11-23 01:53:40,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:40,066 INFO:     Epoch: 80
2022-11-23 01:53:40,824 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8503968390551481, 'Total loss': 0.8503968390551481} | train loss {'Reaction outcome loss': 0.804123694476811, 'Total loss': 0.804123694476811}
2022-11-23 01:53:40,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:40,824 INFO:     Epoch: 81
2022-11-23 01:53:41,590 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8262777389450506, 'Total loss': 0.8262777389450506} | train loss {'Reaction outcome loss': 0.8143658528202459, 'Total loss': 0.8143658528202459}
2022-11-23 01:53:41,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:41,590 INFO:     Epoch: 82
2022-11-23 01:53:42,387 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8284955031492494, 'Total loss': 0.8284955031492494} | train loss {'Reaction outcome loss': 0.809659502404904, 'Total loss': 0.809659502404904}
2022-11-23 01:53:42,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:42,387 INFO:     Epoch: 83
2022-11-23 01:53:43,147 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.82669863443483, 'Total loss': 0.82669863443483} | train loss {'Reaction outcome loss': 0.8061691190791034, 'Total loss': 0.8061691190791034}
2022-11-23 01:53:43,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:43,148 INFO:     Epoch: 84
2022-11-23 01:53:44,000 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8462470851161263, 'Total loss': 0.8462470851161263} | train loss {'Reaction outcome loss': 0.8101662341882343, 'Total loss': 0.8101662341882343}
2022-11-23 01:53:44,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:44,000 INFO:     Epoch: 85
2022-11-23 01:53:44,780 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8341462835669518, 'Total loss': 0.8341462835669518} | train loss {'Reaction outcome loss': 0.8140863378038291, 'Total loss': 0.8140863378038291}
2022-11-23 01:53:44,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:44,780 INFO:     Epoch: 86
2022-11-23 01:53:45,583 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.839490068229762, 'Total loss': 0.839490068229762} | train loss {'Reaction outcome loss': 0.8101771980644721, 'Total loss': 0.8101771980644721}
2022-11-23 01:53:45,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:45,584 INFO:     Epoch: 87
2022-11-23 01:53:46,383 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8169641684402119, 'Total loss': 0.8169641684402119} | train loss {'Reaction outcome loss': 0.8119762001732583, 'Total loss': 0.8119762001732583}
2022-11-23 01:53:46,383 INFO:     Found new best model at epoch 87
2022-11-23 01:53:46,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:46,384 INFO:     Epoch: 88
2022-11-23 01:53:47,198 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8512466129931536, 'Total loss': 0.8512466129931536} | train loss {'Reaction outcome loss': 0.8137338113205635, 'Total loss': 0.8137338113205635}
2022-11-23 01:53:47,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:47,199 INFO:     Epoch: 89
2022-11-23 01:53:48,037 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8387946594845165, 'Total loss': 0.8387946594845165} | train loss {'Reaction outcome loss': 0.8098960983367102, 'Total loss': 0.8098960983367102}
2022-11-23 01:53:48,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:48,038 INFO:     Epoch: 90
2022-11-23 01:53:48,854 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.878690780563788, 'Total loss': 0.878690780563788} | train loss {'Reaction outcome loss': 0.8187294544478659, 'Total loss': 0.8187294544478659}
2022-11-23 01:53:48,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:48,855 INFO:     Epoch: 91
2022-11-23 01:53:49,629 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8367219777269796, 'Total loss': 0.8367219777269796} | train loss {'Reaction outcome loss': 0.8132852472757038, 'Total loss': 0.8132852472757038}
2022-11-23 01:53:49,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:49,629 INFO:     Epoch: 92
2022-11-23 01:53:50,450 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.849292133342136, 'Total loss': 0.849292133342136} | train loss {'Reaction outcome loss': 0.8181721373849552, 'Total loss': 0.8181721373849552}
2022-11-23 01:53:50,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:50,451 INFO:     Epoch: 93
2022-11-23 01:53:51,233 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8289101509885355, 'Total loss': 0.8289101509885355} | train loss {'Reaction outcome loss': 0.8173866142869478, 'Total loss': 0.8173866142869478}
2022-11-23 01:53:51,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:51,234 INFO:     Epoch: 94
2022-11-23 01:53:52,048 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8478440527211536, 'Total loss': 0.8478440527211536} | train loss {'Reaction outcome loss': 0.8077290740452314, 'Total loss': 0.8077290740452314}
2022-11-23 01:53:52,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:52,049 INFO:     Epoch: 95
2022-11-23 01:53:52,846 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8348927822980013, 'Total loss': 0.8348927822980013} | train loss {'Reaction outcome loss': 0.8095166171610597, 'Total loss': 0.8095166171610597}
2022-11-23 01:53:52,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:52,846 INFO:     Epoch: 96
2022-11-23 01:53:53,651 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8312887772917747, 'Total loss': 0.8312887772917747} | train loss {'Reaction outcome loss': 0.8101352863466209, 'Total loss': 0.8101352863466209}
2022-11-23 01:53:53,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:53,651 INFO:     Epoch: 97
2022-11-23 01:53:54,464 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8349743830886754, 'Total loss': 0.8349743830886754} | train loss {'Reaction outcome loss': 0.8065331201804312, 'Total loss': 0.8065331201804312}
2022-11-23 01:53:54,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:54,465 INFO:     Epoch: 98
2022-11-23 01:53:55,318 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8310962217775258, 'Total loss': 0.8310962217775258} | train loss {'Reaction outcome loss': 0.8100169811412873, 'Total loss': 0.8100169811412873}
2022-11-23 01:53:55,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:55,319 INFO:     Epoch: 99
2022-11-23 01:53:56,092 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8302453356710348, 'Total loss': 0.8302453356710348} | train loss {'Reaction outcome loss': 0.8102794453682687, 'Total loss': 0.8102794453682687}
2022-11-23 01:53:56,092 INFO:     Best model found after epoch 88 of 100.
2022-11-23 01:53:56,092 INFO:   Done with stage: TRAINING
2022-11-23 01:53:56,092 INFO:   Starting stage: EVALUATION
2022-11-23 01:53:56,217 INFO:   Done with stage: EVALUATION
2022-11-23 01:53:56,217 INFO:   Leaving out SEQ value Fold_8
2022-11-23 01:53:56,230 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:53:56,231 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:53:56,903 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:53:56,903 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:53:56,975 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:53:56,975 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:53:56,975 INFO:     No hyperparam tuning for this model
2022-11-23 01:53:56,975 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:53:56,975 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:53:56,976 INFO:     None feature selector for col prot
2022-11-23 01:53:56,976 INFO:     None feature selector for col prot
2022-11-23 01:53:56,976 INFO:     None feature selector for col prot
2022-11-23 01:53:56,977 INFO:     None feature selector for col chem
2022-11-23 01:53:56,977 INFO:     None feature selector for col chem
2022-11-23 01:53:56,977 INFO:     None feature selector for col chem
2022-11-23 01:53:56,977 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:53:56,977 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:53:56,979 INFO:     Number of params in model 168571
2022-11-23 01:53:56,982 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:53:56,982 INFO:   Starting stage: TRAINING
2022-11-23 01:53:57,040 INFO:     Val loss before train {'Reaction outcome loss': 1.011906771497293, 'Total loss': 1.011906771497293}
2022-11-23 01:53:57,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:57,040 INFO:     Epoch: 0
2022-11-23 01:53:57,851 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8144745013930581, 'Total loss': 0.8144745013930581} | train loss {'Reaction outcome loss': 0.8783830400676497, 'Total loss': 0.8783830400676497}
2022-11-23 01:53:57,851 INFO:     Found new best model at epoch 0
2022-11-23 01:53:57,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:57,852 INFO:     Epoch: 1
2022-11-23 01:53:58,680 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8209780102426355, 'Total loss': 0.8209780102426355} | train loss {'Reaction outcome loss': 0.8511810801442592, 'Total loss': 0.8511810801442592}
2022-11-23 01:53:58,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:58,681 INFO:     Epoch: 2
2022-11-23 01:53:59,481 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8172944824803959, 'Total loss': 0.8172944824803959} | train loss {'Reaction outcome loss': 0.8432183221222893, 'Total loss': 0.8432183221222893}
2022-11-23 01:53:59,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:53:59,481 INFO:     Epoch: 3
2022-11-23 01:54:00,312 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.791988617317243, 'Total loss': 0.791988617317243} | train loss {'Reaction outcome loss': 0.8304724156135513, 'Total loss': 0.8304724156135513}
2022-11-23 01:54:00,312 INFO:     Found new best model at epoch 3
2022-11-23 01:54:00,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:00,313 INFO:     Epoch: 4
2022-11-23 01:54:01,109 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7938006642189893, 'Total loss': 0.7938006642189893} | train loss {'Reaction outcome loss': 0.834292326603205, 'Total loss': 0.834292326603205}
2022-11-23 01:54:01,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:01,110 INFO:     Epoch: 5
2022-11-23 01:54:01,920 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7981409105387601, 'Total loss': 0.7981409105387601} | train loss {'Reaction outcome loss': 0.8296865569728036, 'Total loss': 0.8296865569728036}
2022-11-23 01:54:01,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:01,920 INFO:     Epoch: 6
2022-11-23 01:54:02,743 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7934720421379263, 'Total loss': 0.7934720421379263} | train loss {'Reaction outcome loss': 0.8291546293804722, 'Total loss': 0.8291546293804722}
2022-11-23 01:54:02,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:02,744 INFO:     Epoch: 7
2022-11-23 01:54:03,501 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8079539848999544, 'Total loss': 0.8079539848999544} | train loss {'Reaction outcome loss': 0.8258858266617021, 'Total loss': 0.8258858266617021}
2022-11-23 01:54:03,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:03,502 INFO:     Epoch: 8
2022-11-23 01:54:04,305 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8038944080471992, 'Total loss': 0.8038944080471992} | train loss {'Reaction outcome loss': 0.8271534083591353, 'Total loss': 0.8271534083591353}
2022-11-23 01:54:04,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:04,305 INFO:     Epoch: 9
2022-11-23 01:54:05,104 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8241607235236601, 'Total loss': 0.8241607235236601} | train loss {'Reaction outcome loss': 0.8185962365279275, 'Total loss': 0.8185962365279275}
2022-11-23 01:54:05,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:05,105 INFO:     Epoch: 10
2022-11-23 01:54:05,879 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8098212880167094, 'Total loss': 0.8098212880167094} | train loss {'Reaction outcome loss': 0.831061909035329, 'Total loss': 0.831061909035329}
2022-11-23 01:54:05,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:05,880 INFO:     Epoch: 11
2022-11-23 01:54:06,717 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.789065030488101, 'Total loss': 0.789065030488101} | train loss {'Reaction outcome loss': 0.8204036091844882, 'Total loss': 0.8204036091844882}
2022-11-23 01:54:06,718 INFO:     Found new best model at epoch 11
2022-11-23 01:54:06,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:06,718 INFO:     Epoch: 12
2022-11-23 01:54:07,534 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7855792479081587, 'Total loss': 0.7855792479081587} | train loss {'Reaction outcome loss': 0.8227996727631938, 'Total loss': 0.8227996727631938}
2022-11-23 01:54:07,534 INFO:     Found new best model at epoch 12
2022-11-23 01:54:07,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:07,535 INFO:     Epoch: 13
2022-11-23 01:54:08,360 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.789221892980012, 'Total loss': 0.789221892980012} | train loss {'Reaction outcome loss': 0.8221149158573919, 'Total loss': 0.8221149158573919}
2022-11-23 01:54:08,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:08,361 INFO:     Epoch: 14
2022-11-23 01:54:09,162 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7792730636217378, 'Total loss': 0.7792730636217378} | train loss {'Reaction outcome loss': 0.8208476871011718, 'Total loss': 0.8208476871011718}
2022-11-23 01:54:09,162 INFO:     Found new best model at epoch 14
2022-11-23 01:54:09,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:09,163 INFO:     Epoch: 15
2022-11-23 01:54:10,006 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7823490385304798, 'Total loss': 0.7823490385304798} | train loss {'Reaction outcome loss': 0.8167169898027374, 'Total loss': 0.8167169898027374}
2022-11-23 01:54:10,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:10,006 INFO:     Epoch: 16
2022-11-23 01:54:10,795 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.809966778890653, 'Total loss': 0.809966778890653} | train loss {'Reaction outcome loss': 0.8165085689435082, 'Total loss': 0.8165085689435082}
2022-11-23 01:54:10,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:10,797 INFO:     Epoch: 17
2022-11-23 01:54:11,602 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7883046919649298, 'Total loss': 0.7883046919649298} | train loss {'Reaction outcome loss': 0.8221356609175282, 'Total loss': 0.8221356609175282}
2022-11-23 01:54:11,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:11,602 INFO:     Epoch: 18
2022-11-23 01:54:12,443 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8307296423749491, 'Total loss': 0.8307296423749491} | train loss {'Reaction outcome loss': 0.820223901300661, 'Total loss': 0.820223901300661}
2022-11-23 01:54:12,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:12,443 INFO:     Epoch: 19
2022-11-23 01:54:13,271 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8003458976745605, 'Total loss': 0.8003458976745605} | train loss {'Reaction outcome loss': 0.8106422799248849, 'Total loss': 0.8106422799248849}
2022-11-23 01:54:13,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:13,271 INFO:     Epoch: 20
2022-11-23 01:54:14,079 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7816593260927633, 'Total loss': 0.7816593260927633} | train loss {'Reaction outcome loss': 0.8164905854050191, 'Total loss': 0.8164905854050191}
2022-11-23 01:54:14,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:14,079 INFO:     Epoch: 21
2022-11-23 01:54:14,949 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8021869815208695, 'Total loss': 0.8021869815208695} | train loss {'Reaction outcome loss': 0.8155858739008827, 'Total loss': 0.8155858739008827}
2022-11-23 01:54:14,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:14,950 INFO:     Epoch: 22
2022-11-23 01:54:15,749 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7932280464605852, 'Total loss': 0.7932280464605852} | train loss {'Reaction outcome loss': 0.8160322873342422, 'Total loss': 0.8160322873342422}
2022-11-23 01:54:15,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:15,749 INFO:     Epoch: 23
2022-11-23 01:54:16,569 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.808370253579183, 'Total loss': 0.808370253579183} | train loss {'Reaction outcome loss': 0.8126936285726486, 'Total loss': 0.8126936285726486}
2022-11-23 01:54:16,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:16,569 INFO:     Epoch: 24
2022-11-23 01:54:17,353 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7918312109329484, 'Total loss': 0.7918312109329484} | train loss {'Reaction outcome loss': 0.8182578565132234, 'Total loss': 0.8182578565132234}
2022-11-23 01:54:17,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:17,354 INFO:     Epoch: 25
2022-11-23 01:54:18,128 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8163573809645392, 'Total loss': 0.8163573809645392} | train loss {'Reaction outcome loss': 0.812787015171301, 'Total loss': 0.812787015171301}
2022-11-23 01:54:18,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:18,128 INFO:     Epoch: 26
2022-11-23 01:54:18,890 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7865404459563169, 'Total loss': 0.7865404459563169} | train loss {'Reaction outcome loss': 0.8180504690014547, 'Total loss': 0.8180504690014547}
2022-11-23 01:54:18,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:18,890 INFO:     Epoch: 27
2022-11-23 01:54:19,692 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8035861633040688, 'Total loss': 0.8035861633040688} | train loss {'Reaction outcome loss': 0.8137507711447054, 'Total loss': 0.8137507711447054}
2022-11-23 01:54:19,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:19,693 INFO:     Epoch: 28
2022-11-23 01:54:20,502 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8095948669043455, 'Total loss': 0.8095948669043455} | train loss {'Reaction outcome loss': 0.8126870080107643, 'Total loss': 0.8126870080107643}
2022-11-23 01:54:20,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:20,503 INFO:     Epoch: 29
2022-11-23 01:54:21,313 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7846390970728614, 'Total loss': 0.7846390970728614} | train loss {'Reaction outcome loss': 0.8124041784434549, 'Total loss': 0.8124041784434549}
2022-11-23 01:54:21,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:21,313 INFO:     Epoch: 30
2022-11-23 01:54:22,151 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.793441000987183, 'Total loss': 0.793441000987183} | train loss {'Reaction outcome loss': 0.815622090932823, 'Total loss': 0.815622090932823}
2022-11-23 01:54:22,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:22,151 INFO:     Epoch: 31
2022-11-23 01:54:22,984 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7788746980103579, 'Total loss': 0.7788746980103579} | train loss {'Reaction outcome loss': 0.8133127405758827, 'Total loss': 0.8133127405758827}
2022-11-23 01:54:22,985 INFO:     Found new best model at epoch 31
2022-11-23 01:54:22,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:22,986 INFO:     Epoch: 32
2022-11-23 01:54:23,801 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7956656231121584, 'Total loss': 0.7956656231121584} | train loss {'Reaction outcome loss': 0.8155701183263333, 'Total loss': 0.8155701183263333}
2022-11-23 01:54:23,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:23,802 INFO:     Epoch: 33
2022-11-23 01:54:24,602 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8145677230574868, 'Total loss': 0.8145677230574868} | train loss {'Reaction outcome loss': 0.8179681864717314, 'Total loss': 0.8179681864717314}
2022-11-23 01:54:24,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:24,602 INFO:     Epoch: 34
2022-11-23 01:54:25,445 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7924341369758953, 'Total loss': 0.7924341369758953} | train loss {'Reaction outcome loss': 0.8164781557936822, 'Total loss': 0.8164781557936822}
2022-11-23 01:54:25,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:25,445 INFO:     Epoch: 35
2022-11-23 01:54:26,246 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8230986222624779, 'Total loss': 0.8230986222624779} | train loss {'Reaction outcome loss': 0.8163923324356156, 'Total loss': 0.8163923324356156}
2022-11-23 01:54:26,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:26,246 INFO:     Epoch: 36
2022-11-23 01:54:27,002 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8271079876206138, 'Total loss': 0.8271079876206138} | train loss {'Reaction outcome loss': 0.8185998745743306, 'Total loss': 0.8185998745743306}
2022-11-23 01:54:27,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:27,003 INFO:     Epoch: 37
2022-11-23 01:54:27,817 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7976957085457715, 'Total loss': 0.7976957085457715} | train loss {'Reaction outcome loss': 0.8177492577702768, 'Total loss': 0.8177492577702768}
2022-11-23 01:54:27,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:27,817 INFO:     Epoch: 38
2022-11-23 01:54:28,629 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7785154574296691, 'Total loss': 0.7785154574296691} | train loss {'Reaction outcome loss': 0.811697737674319, 'Total loss': 0.811697737674319}
2022-11-23 01:54:28,630 INFO:     Found new best model at epoch 38
2022-11-23 01:54:28,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:28,630 INFO:     Epoch: 39
2022-11-23 01:54:29,432 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7886850346218456, 'Total loss': 0.7886850346218456} | train loss {'Reaction outcome loss': 0.81476347436828, 'Total loss': 0.81476347436828}
2022-11-23 01:54:29,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:29,433 INFO:     Epoch: 40
2022-11-23 01:54:30,232 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7948703061450612, 'Total loss': 0.7948703061450612} | train loss {'Reaction outcome loss': 0.81818532102531, 'Total loss': 0.81818532102531}
2022-11-23 01:54:30,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:30,234 INFO:     Epoch: 41
2022-11-23 01:54:31,062 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7971918460997668, 'Total loss': 0.7971918460997668} | train loss {'Reaction outcome loss': 0.8126718430749832, 'Total loss': 0.8126718430749832}
2022-11-23 01:54:31,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:31,062 INFO:     Epoch: 42
2022-11-23 01:54:31,875 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7995528348467567, 'Total loss': 0.7995528348467567} | train loss {'Reaction outcome loss': 0.8159606276500609, 'Total loss': 0.8159606276500609}
2022-11-23 01:54:31,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:31,875 INFO:     Epoch: 43
2022-11-23 01:54:32,658 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7879657562483441, 'Total loss': 0.7879657562483441} | train loss {'Reaction outcome loss': 0.8189272975489017, 'Total loss': 0.8189272975489017}
2022-11-23 01:54:32,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:32,659 INFO:     Epoch: 44
2022-11-23 01:54:33,519 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.797943577170372, 'Total loss': 0.797943577170372} | train loss {'Reaction outcome loss': 0.8112924783941238, 'Total loss': 0.8112924783941238}
2022-11-23 01:54:33,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:33,520 INFO:     Epoch: 45
2022-11-23 01:54:34,361 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.800072504715486, 'Total loss': 0.800072504715486} | train loss {'Reaction outcome loss': 0.8146467192639266, 'Total loss': 0.8146467192639266}
2022-11-23 01:54:34,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:34,362 INFO:     Epoch: 46
2022-11-23 01:54:35,185 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7998269389976155, 'Total loss': 0.7998269389976155} | train loss {'Reaction outcome loss': 0.8238679288375762, 'Total loss': 0.8238679288375762}
2022-11-23 01:54:35,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:35,185 INFO:     Epoch: 47
2022-11-23 01:54:36,008 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7946099015799436, 'Total loss': 0.7946099015799436} | train loss {'Reaction outcome loss': 0.8144864963908349, 'Total loss': 0.8144864963908349}
2022-11-23 01:54:36,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:36,008 INFO:     Epoch: 48
2022-11-23 01:54:36,814 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7900217202576724, 'Total loss': 0.7900217202576724} | train loss {'Reaction outcome loss': 0.8119737751060917, 'Total loss': 0.8119737751060917}
2022-11-23 01:54:36,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:36,814 INFO:     Epoch: 49
2022-11-23 01:54:37,601 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7899972938678481, 'Total loss': 0.7899972938678481} | train loss {'Reaction outcome loss': 0.8150668403794689, 'Total loss': 0.8150668403794689}
2022-11-23 01:54:37,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:37,601 INFO:     Epoch: 50
2022-11-23 01:54:38,393 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7856622419574044, 'Total loss': 0.7856622419574044} | train loss {'Reaction outcome loss': 0.814952959937434, 'Total loss': 0.814952959937434}
2022-11-23 01:54:38,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:38,393 INFO:     Epoch: 51
2022-11-23 01:54:39,185 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7985423637384718, 'Total loss': 0.7985423637384718} | train loss {'Reaction outcome loss': 0.8165146738531128, 'Total loss': 0.8165146738531128}
2022-11-23 01:54:39,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:39,185 INFO:     Epoch: 52
2022-11-23 01:54:40,025 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8144637976180423, 'Total loss': 0.8144637976180423} | train loss {'Reaction outcome loss': 0.814316893657369, 'Total loss': 0.814316893657369}
2022-11-23 01:54:40,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:40,026 INFO:     Epoch: 53
2022-11-23 01:54:40,822 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7832454930652272, 'Total loss': 0.7832454930652272} | train loss {'Reaction outcome loss': 0.8168020332532544, 'Total loss': 0.8168020332532544}
2022-11-23 01:54:40,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:40,822 INFO:     Epoch: 54
2022-11-23 01:54:41,649 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7896141802722757, 'Total loss': 0.7896141802722757} | train loss {'Reaction outcome loss': 0.8134938619069515, 'Total loss': 0.8134938619069515}
2022-11-23 01:54:41,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:41,649 INFO:     Epoch: 55
2022-11-23 01:54:42,443 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7932314615358006, 'Total loss': 0.7932314615358006} | train loss {'Reaction outcome loss': 0.815878844549579, 'Total loss': 0.815878844549579}
2022-11-23 01:54:42,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:42,444 INFO:     Epoch: 56
2022-11-23 01:54:43,217 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7830685133283789, 'Total loss': 0.7830685133283789} | train loss {'Reaction outcome loss': 0.8156469513572031, 'Total loss': 0.8156469513572031}
2022-11-23 01:54:43,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:43,218 INFO:     Epoch: 57
2022-11-23 01:54:44,024 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7965468127619136, 'Total loss': 0.7965468127619136} | train loss {'Reaction outcome loss': 0.8083259329920814, 'Total loss': 0.8083259329920814}
2022-11-23 01:54:44,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:44,024 INFO:     Epoch: 58
2022-11-23 01:54:44,840 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7952706901864572, 'Total loss': 0.7952706901864572} | train loss {'Reaction outcome loss': 0.8106045589571998, 'Total loss': 0.8106045589571998}
2022-11-23 01:54:44,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:44,840 INFO:     Epoch: 59
2022-11-23 01:54:45,640 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8277855373241685, 'Total loss': 0.8277855373241685} | train loss {'Reaction outcome loss': 0.8182276779365155, 'Total loss': 0.8182276779365155}
2022-11-23 01:54:45,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:45,640 INFO:     Epoch: 60
2022-11-23 01:54:46,448 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7839238332076506, 'Total loss': 0.7839238332076506} | train loss {'Reaction outcome loss': 0.810554095453793, 'Total loss': 0.810554095453793}
2022-11-23 01:54:46,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:46,449 INFO:     Epoch: 61
2022-11-23 01:54:47,252 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8070338009433313, 'Total loss': 0.8070338009433313} | train loss {'Reaction outcome loss': 0.8167601784150447, 'Total loss': 0.8167601784150447}
2022-11-23 01:54:47,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:47,252 INFO:     Epoch: 62
2022-11-23 01:54:48,078 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7917847999117591, 'Total loss': 0.7917847999117591} | train loss {'Reaction outcome loss': 0.8140200656508246, 'Total loss': 0.8140200656508246}
2022-11-23 01:54:48,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:48,078 INFO:     Epoch: 63
2022-11-23 01:54:48,901 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7901753458109769, 'Total loss': 0.7901753458109769} | train loss {'Reaction outcome loss': 0.8132429615624489, 'Total loss': 0.8132429615624489}
2022-11-23 01:54:48,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:48,902 INFO:     Epoch: 64
2022-11-23 01:54:49,735 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7978711419484832, 'Total loss': 0.7978711419484832} | train loss {'Reaction outcome loss': 0.8144439264170585, 'Total loss': 0.8144439264170585}
2022-11-23 01:54:49,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:49,736 INFO:     Epoch: 65
2022-11-23 01:54:50,550 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7897669821977615, 'Total loss': 0.7897669821977615} | train loss {'Reaction outcome loss': 0.8118859748205831, 'Total loss': 0.8118859748205831}
2022-11-23 01:54:50,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:50,550 INFO:     Epoch: 66
2022-11-23 01:54:51,327 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8015252311121334, 'Total loss': 0.8015252311121334} | train loss {'Reaction outcome loss': 0.8150050459850219, 'Total loss': 0.8150050459850219}
2022-11-23 01:54:51,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:51,327 INFO:     Epoch: 67
2022-11-23 01:54:52,130 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8102242106741125, 'Total loss': 0.8102242106741125} | train loss {'Reaction outcome loss': 0.8153228471356053, 'Total loss': 0.8153228471356053}
2022-11-23 01:54:52,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:52,131 INFO:     Epoch: 68
2022-11-23 01:54:52,961 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7871552482247353, 'Total loss': 0.7871552482247353} | train loss {'Reaction outcome loss': 0.8189519458720761, 'Total loss': 0.8189519458720761}
2022-11-23 01:54:52,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:52,961 INFO:     Epoch: 69
2022-11-23 01:54:53,779 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7889749800617044, 'Total loss': 0.7889749800617044} | train loss {'Reaction outcome loss': 0.811686398281205, 'Total loss': 0.811686398281205}
2022-11-23 01:54:53,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:53,780 INFO:     Epoch: 70
2022-11-23 01:54:54,592 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7819662845947526, 'Total loss': 0.7819662845947526} | train loss {'Reaction outcome loss': 0.8160941022177858, 'Total loss': 0.8160941022177858}
2022-11-23 01:54:54,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:54,593 INFO:     Epoch: 71
2022-11-23 01:54:55,395 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.786466509103775, 'Total loss': 0.786466509103775} | train loss {'Reaction outcome loss': 0.8140837730419251, 'Total loss': 0.8140837730419251}
2022-11-23 01:54:55,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:55,395 INFO:     Epoch: 72
2022-11-23 01:54:56,233 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7865939296104691, 'Total loss': 0.7865939296104691} | train loss {'Reaction outcome loss': 0.8124642648523853, 'Total loss': 0.8124642648523853}
2022-11-23 01:54:56,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:56,233 INFO:     Epoch: 73
2022-11-23 01:54:57,063 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7875505936416712, 'Total loss': 0.7875505936416712} | train loss {'Reaction outcome loss': 0.8151693010041791, 'Total loss': 0.8151693010041791}
2022-11-23 01:54:57,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:57,063 INFO:     Epoch: 74
2022-11-23 01:54:57,846 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8030875155871565, 'Total loss': 0.8030875155871565} | train loss {'Reaction outcome loss': 0.8136329304787421, 'Total loss': 0.8136329304787421}
2022-11-23 01:54:57,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:57,846 INFO:     Epoch: 75
2022-11-23 01:54:58,656 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7897303334691308, 'Total loss': 0.7897303334691308} | train loss {'Reaction outcome loss': 0.8152569064930562, 'Total loss': 0.8152569064930562}
2022-11-23 01:54:58,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:58,656 INFO:     Epoch: 76
2022-11-23 01:54:59,442 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7834752581336282, 'Total loss': 0.7834752581336282} | train loss {'Reaction outcome loss': 0.8153747105069699, 'Total loss': 0.8153747105069699}
2022-11-23 01:54:59,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:54:59,442 INFO:     Epoch: 77
2022-11-23 01:55:00,234 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7821783795952797, 'Total loss': 0.7821783795952797} | train loss {'Reaction outcome loss': 0.8145982222932, 'Total loss': 0.8145982222932}
2022-11-23 01:55:00,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:00,234 INFO:     Epoch: 78
2022-11-23 01:55:01,031 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.78207201781598, 'Total loss': 0.78207201781598} | train loss {'Reaction outcome loss': 0.8114215803122328, 'Total loss': 0.8114215803122328}
2022-11-23 01:55:01,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:01,032 INFO:     Epoch: 79
2022-11-23 01:55:01,858 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7997669475999746, 'Total loss': 0.7997669475999746} | train loss {'Reaction outcome loss': 0.8128164551190792, 'Total loss': 0.8128164551190792}
2022-11-23 01:55:01,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:01,858 INFO:     Epoch: 80
2022-11-23 01:55:02,705 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7908624471588568, 'Total loss': 0.7908624471588568} | train loss {'Reaction outcome loss': 0.8133489469126347, 'Total loss': 0.8133489469126347}
2022-11-23 01:55:02,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:02,705 INFO:     Epoch: 81
2022-11-23 01:55:03,523 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7877622842788696, 'Total loss': 0.7877622842788696} | train loss {'Reaction outcome loss': 0.8159285301883374, 'Total loss': 0.8159285301883374}
2022-11-23 01:55:03,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:03,523 INFO:     Epoch: 82
2022-11-23 01:55:04,319 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.820677555420182, 'Total loss': 0.820677555420182} | train loss {'Reaction outcome loss': 0.8135851948491989, 'Total loss': 0.8135851948491989}
2022-11-23 01:55:04,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:04,319 INFO:     Epoch: 83
2022-11-23 01:55:05,103 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.814721056683497, 'Total loss': 0.814721056683497} | train loss {'Reaction outcome loss': 0.8140044999459097, 'Total loss': 0.8140044999459097}
2022-11-23 01:55:05,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:05,103 INFO:     Epoch: 84
2022-11-23 01:55:05,913 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7918773130937056, 'Total loss': 0.7918773130937056} | train loss {'Reaction outcome loss': 0.8121565788263275, 'Total loss': 0.8121565788263275}
2022-11-23 01:55:05,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:05,913 INFO:     Epoch: 85
2022-11-23 01:55:06,710 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7802156934683974, 'Total loss': 0.7802156934683974} | train loss {'Reaction outcome loss': 0.8112915622130517, 'Total loss': 0.8112915622130517}
2022-11-23 01:55:06,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:06,711 INFO:     Epoch: 86
2022-11-23 01:55:07,501 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7856807126240297, 'Total loss': 0.7856807126240297} | train loss {'Reaction outcome loss': 0.8119106326372393, 'Total loss': 0.8119106326372393}
2022-11-23 01:55:07,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:07,501 INFO:     Epoch: 87
2022-11-23 01:55:08,292 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7961074357683008, 'Total loss': 0.7961074357683008} | train loss {'Reaction outcome loss': 0.8140202013234938, 'Total loss': 0.8140202013234938}
2022-11-23 01:55:08,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:08,292 INFO:     Epoch: 88
2022-11-23 01:55:09,086 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8151725523851134, 'Total loss': 0.8151725523851134} | train loss {'Reaction outcome loss': 0.8143858097253307, 'Total loss': 0.8143858097253307}
2022-11-23 01:55:09,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:09,087 INFO:     Epoch: 89
2022-11-23 01:55:09,840 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7776297310536558, 'Total loss': 0.7776297310536558} | train loss {'Reaction outcome loss': 0.8159952559057744, 'Total loss': 0.8159952559057744}
2022-11-23 01:55:09,840 INFO:     Found new best model at epoch 89
2022-11-23 01:55:09,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:09,841 INFO:     Epoch: 90
2022-11-23 01:55:10,648 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7906926237046719, 'Total loss': 0.7906926237046719} | train loss {'Reaction outcome loss': 0.8150311639953044, 'Total loss': 0.8150311639953044}
2022-11-23 01:55:10,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:10,648 INFO:     Epoch: 91
2022-11-23 01:55:11,486 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7886748747392134, 'Total loss': 0.7886748747392134} | train loss {'Reaction outcome loss': 0.8133816956993072, 'Total loss': 0.8133816956993072}
2022-11-23 01:55:11,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:11,486 INFO:     Epoch: 92
2022-11-23 01:55:12,294 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7797589965841987, 'Total loss': 0.7797589965841987} | train loss {'Reaction outcome loss': 0.8116039226372396, 'Total loss': 0.8116039226372396}
2022-11-23 01:55:12,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:12,294 INFO:     Epoch: 93
2022-11-23 01:55:13,093 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.823516578159549, 'Total loss': 0.823516578159549} | train loss {'Reaction outcome loss': 0.8084439070474717, 'Total loss': 0.8084439070474717}
2022-11-23 01:55:13,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:13,094 INFO:     Epoch: 94
2022-11-23 01:55:13,882 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8085669631307776, 'Total loss': 0.8085669631307776} | train loss {'Reaction outcome loss': 0.8168356690195299, 'Total loss': 0.8168356690195299}
2022-11-23 01:55:13,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:13,882 INFO:     Epoch: 95
2022-11-23 01:55:14,633 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7939443655989387, 'Total loss': 0.7939443655989387} | train loss {'Reaction outcome loss': 0.8104655319644559, 'Total loss': 0.8104655319644559}
2022-11-23 01:55:14,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:14,634 INFO:     Epoch: 96
2022-11-23 01:55:15,436 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.794573765586723, 'Total loss': 0.794573765586723} | train loss {'Reaction outcome loss': 0.8129410444488449, 'Total loss': 0.8129410444488449}
2022-11-23 01:55:15,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:15,436 INFO:     Epoch: 97
2022-11-23 01:55:16,282 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7910163802179423, 'Total loss': 0.7910163802179423} | train loss {'Reaction outcome loss': 0.8192567563345355, 'Total loss': 0.8192567563345355}
2022-11-23 01:55:16,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:16,283 INFO:     Epoch: 98
2022-11-23 01:55:17,079 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8003696176138791, 'Total loss': 0.8003696176138791} | train loss {'Reaction outcome loss': 0.810141556205288, 'Total loss': 0.810141556205288}
2022-11-23 01:55:17,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:17,079 INFO:     Epoch: 99
2022-11-23 01:55:17,908 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7804419689557769, 'Total loss': 0.7804419689557769} | train loss {'Reaction outcome loss': 0.814879193781845, 'Total loss': 0.814879193781845}
2022-11-23 01:55:17,909 INFO:     Best model found after epoch 90 of 100.
2022-11-23 01:55:17,909 INFO:   Done with stage: TRAINING
2022-11-23 01:55:17,909 INFO:   Starting stage: EVALUATION
2022-11-23 01:55:18,028 INFO:   Done with stage: EVALUATION
2022-11-23 01:55:18,028 INFO:   Leaving out SEQ value Fold_9
2022-11-23 01:55:18,041 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:55:18,041 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:55:18,716 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:55:18,716 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:55:18,790 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:55:18,790 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:55:18,790 INFO:     No hyperparam tuning for this model
2022-11-23 01:55:18,790 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:55:18,790 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:55:18,791 INFO:     None feature selector for col prot
2022-11-23 01:55:18,791 INFO:     None feature selector for col prot
2022-11-23 01:55:18,791 INFO:     None feature selector for col prot
2022-11-23 01:55:18,792 INFO:     None feature selector for col chem
2022-11-23 01:55:18,792 INFO:     None feature selector for col chem
2022-11-23 01:55:18,792 INFO:     None feature selector for col chem
2022-11-23 01:55:18,792 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:55:18,792 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:55:18,794 INFO:     Number of params in model 168571
2022-11-23 01:55:18,797 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:55:18,797 INFO:   Starting stage: TRAINING
2022-11-23 01:55:18,855 INFO:     Val loss before train {'Reaction outcome loss': 0.9267619780518792, 'Total loss': 0.9267619780518792}
2022-11-23 01:55:18,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:18,855 INFO:     Epoch: 0
2022-11-23 01:55:19,660 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7579150823029605, 'Total loss': 0.7579150823029605} | train loss {'Reaction outcome loss': 0.8905267041296728, 'Total loss': 0.8905267041296728}
2022-11-23 01:55:19,660 INFO:     Found new best model at epoch 0
2022-11-23 01:55:19,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:19,661 INFO:     Epoch: 1
2022-11-23 01:55:20,473 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7565811276435852, 'Total loss': 0.7565811276435852} | train loss {'Reaction outcome loss': 0.8510304536790617, 'Total loss': 0.8510304536790617}
2022-11-23 01:55:20,473 INFO:     Found new best model at epoch 1
2022-11-23 01:55:20,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:20,474 INFO:     Epoch: 2
2022-11-23 01:55:21,312 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7725234898653898, 'Total loss': 0.7725234898653898} | train loss {'Reaction outcome loss': 0.8477209673052833, 'Total loss': 0.8477209673052833}
2022-11-23 01:55:21,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:21,312 INFO:     Epoch: 3
2022-11-23 01:55:22,153 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7645192979411646, 'Total loss': 0.7645192979411646} | train loss {'Reaction outcome loss': 0.8482115439349606, 'Total loss': 0.8482115439349606}
2022-11-23 01:55:22,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:22,153 INFO:     Epoch: 4
2022-11-23 01:55:22,954 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7390735806389288, 'Total loss': 0.7390735806389288} | train loss {'Reaction outcome loss': 0.8431983908578273, 'Total loss': 0.8431983908578273}
2022-11-23 01:55:22,955 INFO:     Found new best model at epoch 4
2022-11-23 01:55:22,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:22,955 INFO:     Epoch: 5
2022-11-23 01:55:23,751 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7387087128379128, 'Total loss': 0.7387087128379128} | train loss {'Reaction outcome loss': 0.8323198399476467, 'Total loss': 0.8323198399476467}
2022-11-23 01:55:23,751 INFO:     Found new best model at epoch 5
2022-11-23 01:55:23,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:23,752 INFO:     Epoch: 6
2022-11-23 01:55:24,570 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7370418195020069, 'Total loss': 0.7370418195020069} | train loss {'Reaction outcome loss': 0.8332588896155357, 'Total loss': 0.8332588896155357}
2022-11-23 01:55:24,570 INFO:     Found new best model at epoch 6
2022-11-23 01:55:24,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:24,571 INFO:     Epoch: 7
2022-11-23 01:55:25,398 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7605345344001596, 'Total loss': 0.7605345344001596} | train loss {'Reaction outcome loss': 0.8316186090871212, 'Total loss': 0.8316186090871212}
2022-11-23 01:55:25,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:25,400 INFO:     Epoch: 8
2022-11-23 01:55:26,186 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7695533761923964, 'Total loss': 0.7695533761923964} | train loss {'Reaction outcome loss': 0.8302872277075245, 'Total loss': 0.8302872277075245}
2022-11-23 01:55:26,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:26,186 INFO:     Epoch: 9
2022-11-23 01:55:27,003 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7513879747553305, 'Total loss': 0.7513879747553305} | train loss {'Reaction outcome loss': 0.8315018437081768, 'Total loss': 0.8315018437081768}
2022-11-23 01:55:27,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:27,004 INFO:     Epoch: 10
2022-11-23 01:55:27,884 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.734422160143202, 'Total loss': 0.734422160143202} | train loss {'Reaction outcome loss': 0.8314177485242966, 'Total loss': 0.8314177485242966}
2022-11-23 01:55:27,884 INFO:     Found new best model at epoch 10
2022-11-23 01:55:27,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:27,885 INFO:     Epoch: 11
2022-11-23 01:55:28,696 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7709933052008803, 'Total loss': 0.7709933052008803} | train loss {'Reaction outcome loss': 0.8276013981911444, 'Total loss': 0.8276013981911444}
2022-11-23 01:55:28,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:28,696 INFO:     Epoch: 12
2022-11-23 01:55:29,497 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7500903619961306, 'Total loss': 0.7500903619961306} | train loss {'Reaction outcome loss': 0.8278630175177129, 'Total loss': 0.8278630175177129}
2022-11-23 01:55:29,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:29,498 INFO:     Epoch: 13
2022-11-23 01:55:30,283 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7433129372921857, 'Total loss': 0.7433129372921857} | train loss {'Reaction outcome loss': 0.829677883054941, 'Total loss': 0.829677883054941}
2022-11-23 01:55:30,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:30,284 INFO:     Epoch: 14
2022-11-23 01:55:31,090 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7304364991458979, 'Total loss': 0.7304364991458979} | train loss {'Reaction outcome loss': 0.8291449713851174, 'Total loss': 0.8291449713851174}
2022-11-23 01:55:31,090 INFO:     Found new best model at epoch 14
2022-11-23 01:55:31,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:31,091 INFO:     Epoch: 15
2022-11-23 01:55:31,918 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7359734895554456, 'Total loss': 0.7359734895554456} | train loss {'Reaction outcome loss': 0.8256338653304884, 'Total loss': 0.8256338653304884}
2022-11-23 01:55:31,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:31,919 INFO:     Epoch: 16
2022-11-23 01:55:32,722 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7727084302089431, 'Total loss': 0.7727084302089431} | train loss {'Reaction outcome loss': 0.8280854809188074, 'Total loss': 0.8280854809188074}
2022-11-23 01:55:32,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:32,722 INFO:     Epoch: 17
2022-11-23 01:55:33,557 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7448411766778339, 'Total loss': 0.7448411766778339} | train loss {'Reaction outcome loss': 0.8284274063283398, 'Total loss': 0.8284274063283398}
2022-11-23 01:55:33,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:33,557 INFO:     Epoch: 18
2022-11-23 01:55:34,363 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7384096682071686, 'Total loss': 0.7384096682071686} | train loss {'Reaction outcome loss': 0.8300657455599115, 'Total loss': 0.8300657455599115}
2022-11-23 01:55:34,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:34,363 INFO:     Epoch: 19
2022-11-23 01:55:35,172 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7340149120850996, 'Total loss': 0.7340149120850996} | train loss {'Reaction outcome loss': 0.8273593217374817, 'Total loss': 0.8273593217374817}
2022-11-23 01:55:35,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:35,173 INFO:     Epoch: 20
2022-11-23 01:55:35,979 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7370257059281523, 'Total loss': 0.7370257059281523} | train loss {'Reaction outcome loss': 0.8290027706853805, 'Total loss': 0.8290027706853805}
2022-11-23 01:55:35,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:35,979 INFO:     Epoch: 21
2022-11-23 01:55:36,770 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7371213229542429, 'Total loss': 0.7371213229542429} | train loss {'Reaction outcome loss': 0.8264217787692624, 'Total loss': 0.8264217787692624}
2022-11-23 01:55:36,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:36,770 INFO:     Epoch: 22
2022-11-23 01:55:37,619 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7364412769675255, 'Total loss': 0.7364412769675255} | train loss {'Reaction outcome loss': 0.8288631328651982, 'Total loss': 0.8288631328651982}
2022-11-23 01:55:37,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:37,619 INFO:     Epoch: 23
2022-11-23 01:55:38,463 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7523809955878691, 'Total loss': 0.7523809955878691} | train loss {'Reaction outcome loss': 0.8236390432763484, 'Total loss': 0.8236390432763484}
2022-11-23 01:55:38,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:38,463 INFO:     Epoch: 24
2022-11-23 01:55:39,304 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7394573085687377, 'Total loss': 0.7394573085687377} | train loss {'Reaction outcome loss': 0.8286204596440638, 'Total loss': 0.8286204596440638}
2022-11-23 01:55:39,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:39,304 INFO:     Epoch: 25
2022-11-23 01:55:40,101 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7469175959175284, 'Total loss': 0.7469175959175284} | train loss {'Reaction outcome loss': 0.8241655672750166, 'Total loss': 0.8241655672750166}
2022-11-23 01:55:40,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:40,102 INFO:     Epoch: 26
2022-11-23 01:55:40,896 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7492858435619961, 'Total loss': 0.7492858435619961} | train loss {'Reaction outcome loss': 0.8235325437159308, 'Total loss': 0.8235325437159308}
2022-11-23 01:55:40,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:40,896 INFO:     Epoch: 27
2022-11-23 01:55:41,752 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7300506444139914, 'Total loss': 0.7300506444139914} | train loss {'Reaction outcome loss': 0.8213040813082649, 'Total loss': 0.8213040813082649}
2022-11-23 01:55:41,752 INFO:     Found new best model at epoch 27
2022-11-23 01:55:41,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:41,753 INFO:     Epoch: 28
2022-11-23 01:55:42,636 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7461562359874899, 'Total loss': 0.7461562359874899} | train loss {'Reaction outcome loss': 0.8234853037903386, 'Total loss': 0.8234853037903386}
2022-11-23 01:55:42,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:42,637 INFO:     Epoch: 29
2022-11-23 01:55:43,508 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7335388822989031, 'Total loss': 0.7335388822989031} | train loss {'Reaction outcome loss': 0.824733578630032, 'Total loss': 0.824733578630032}
2022-11-23 01:55:43,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:43,508 INFO:     Epoch: 30
2022-11-23 01:55:44,300 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7306605834852565, 'Total loss': 0.7306605834852565} | train loss {'Reaction outcome loss': 0.8266129046678543, 'Total loss': 0.8266129046678543}
2022-11-23 01:55:44,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:44,302 INFO:     Epoch: 31
2022-11-23 01:55:45,153 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.734006601978432, 'Total loss': 0.734006601978432} | train loss {'Reaction outcome loss': 0.832031074911356, 'Total loss': 0.832031074911356}
2022-11-23 01:55:45,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:45,153 INFO:     Epoch: 32
2022-11-23 01:55:45,914 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7373996519229629, 'Total loss': 0.7373996519229629} | train loss {'Reaction outcome loss': 0.8298082771080155, 'Total loss': 0.8298082771080155}
2022-11-23 01:55:45,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:45,914 INFO:     Epoch: 33
2022-11-23 01:55:46,716 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7295600541613319, 'Total loss': 0.7295600541613319} | train loss {'Reaction outcome loss': 0.8209477374630589, 'Total loss': 0.8209477374630589}
2022-11-23 01:55:46,716 INFO:     Found new best model at epoch 33
2022-11-23 01:55:46,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:46,717 INFO:     Epoch: 34
2022-11-23 01:55:47,532 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7298244515603239, 'Total loss': 0.7298244515603239} | train loss {'Reaction outcome loss': 0.8242960860051455, 'Total loss': 0.8242960860051455}
2022-11-23 01:55:47,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:47,532 INFO:     Epoch: 35
2022-11-23 01:55:48,393 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7362517037174918, 'Total loss': 0.7362517037174918} | train loss {'Reaction outcome loss': 0.8207320025370967, 'Total loss': 0.8207320025370967}
2022-11-23 01:55:48,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:48,393 INFO:     Epoch: 36
2022-11-23 01:55:49,222 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7341791790994731, 'Total loss': 0.7341791790994731} | train loss {'Reaction outcome loss': 0.8248143770521686, 'Total loss': 0.8248143770521686}
2022-11-23 01:55:49,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:49,222 INFO:     Epoch: 37
2022-11-23 01:55:50,040 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7412926060232249, 'Total loss': 0.7412926060232249} | train loss {'Reaction outcome loss': 0.819664667330442, 'Total loss': 0.819664667330442}
2022-11-23 01:55:50,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:50,040 INFO:     Epoch: 38
2022-11-23 01:55:50,834 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7337088910016146, 'Total loss': 0.7337088910016146} | train loss {'Reaction outcome loss': 0.8254398059460425, 'Total loss': 0.8254398059460425}
2022-11-23 01:55:50,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:50,834 INFO:     Epoch: 39
2022-11-23 01:55:51,673 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7344443161379207, 'Total loss': 0.7344443161379207} | train loss {'Reaction outcome loss': 0.8204368332461003, 'Total loss': 0.8204368332461003}
2022-11-23 01:55:51,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:51,673 INFO:     Epoch: 40
2022-11-23 01:55:52,511 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7440300820903345, 'Total loss': 0.7440300820903345} | train loss {'Reaction outcome loss': 0.8253493789703615, 'Total loss': 0.8253493789703615}
2022-11-23 01:55:52,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:52,511 INFO:     Epoch: 41
2022-11-23 01:55:53,337 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7406811944463036, 'Total loss': 0.7406811944463036} | train loss {'Reaction outcome loss': 0.8241514964930473, 'Total loss': 0.8241514964930473}
2022-11-23 01:55:53,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:53,337 INFO:     Epoch: 42
2022-11-23 01:55:54,144 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7365078655156222, 'Total loss': 0.7365078655156222} | train loss {'Reaction outcome loss': 0.82289518620218, 'Total loss': 0.82289518620218}
2022-11-23 01:55:54,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:54,145 INFO:     Epoch: 43
2022-11-23 01:55:54,948 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.755655131556771, 'Total loss': 0.755655131556771} | train loss {'Reaction outcome loss': 0.8218746286246085, 'Total loss': 0.8218746286246085}
2022-11-23 01:55:54,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:54,948 INFO:     Epoch: 44
2022-11-23 01:55:55,733 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7451531893827699, 'Total loss': 0.7451531893827699} | train loss {'Reaction outcome loss': 0.8237871335398766, 'Total loss': 0.8237871335398766}
2022-11-23 01:55:55,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:55,733 INFO:     Epoch: 45
2022-11-23 01:55:56,504 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7417063557288863, 'Total loss': 0.7417063557288863} | train loss {'Reaction outcome loss': 0.8234009033729953, 'Total loss': 0.8234009033729953}
2022-11-23 01:55:56,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:56,506 INFO:     Epoch: 46
2022-11-23 01:55:57,297 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7361033816229213, 'Total loss': 0.7361033816229213} | train loss {'Reaction outcome loss': 0.8223450236743496, 'Total loss': 0.8223450236743496}
2022-11-23 01:55:57,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:57,297 INFO:     Epoch: 47
2022-11-23 01:55:58,082 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7265660004182295, 'Total loss': 0.7265660004182295} | train loss {'Reaction outcome loss': 0.825546377248341, 'Total loss': 0.825546377248341}
2022-11-23 01:55:58,083 INFO:     Found new best model at epoch 47
2022-11-23 01:55:58,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:58,083 INFO:     Epoch: 48
2022-11-23 01:55:58,890 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7282968136397275, 'Total loss': 0.7282968136397275} | train loss {'Reaction outcome loss': 0.8266888767961533, 'Total loss': 0.8266888767961533}
2022-11-23 01:55:58,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:58,890 INFO:     Epoch: 49
2022-11-23 01:55:59,799 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7411540055816824, 'Total loss': 0.7411540055816824} | train loss {'Reaction outcome loss': 0.8229803011542366, 'Total loss': 0.8229803011542366}
2022-11-23 01:55:59,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:55:59,799 INFO:     Epoch: 50
2022-11-23 01:56:00,684 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7357379990545186, 'Total loss': 0.7357379990545186} | train loss {'Reaction outcome loss': 0.825762597183066, 'Total loss': 0.825762597183066}
2022-11-23 01:56:00,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:00,684 INFO:     Epoch: 51
2022-11-23 01:56:01,566 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.750409104607322, 'Total loss': 0.750409104607322} | train loss {'Reaction outcome loss': 0.8186299209633181, 'Total loss': 0.8186299209633181}
2022-11-23 01:56:01,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:01,566 INFO:     Epoch: 52
2022-11-23 01:56:02,487 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7496173503724012, 'Total loss': 0.7496173503724012} | train loss {'Reaction outcome loss': 0.8252462184717578, 'Total loss': 0.8252462184717578}
2022-11-23 01:56:02,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:02,488 INFO:     Epoch: 53
2022-11-23 01:56:03,382 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7425607442855835, 'Total loss': 0.7425607442855835} | train loss {'Reaction outcome loss': 0.8281502905151537, 'Total loss': 0.8281502905151537}
2022-11-23 01:56:03,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:03,383 INFO:     Epoch: 54
2022-11-23 01:56:04,229 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7244738787412643, 'Total loss': 0.7244738787412643} | train loss {'Reaction outcome loss': 0.8228701115135224, 'Total loss': 0.8228701115135224}
2022-11-23 01:56:04,229 INFO:     Found new best model at epoch 54
2022-11-23 01:56:04,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:04,230 INFO:     Epoch: 55
2022-11-23 01:56:05,037 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7660657729614865, 'Total loss': 0.7660657729614865} | train loss {'Reaction outcome loss': 0.8235711360410336, 'Total loss': 0.8235711360410336}
2022-11-23 01:56:05,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:05,038 INFO:     Epoch: 56
2022-11-23 01:56:05,888 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7682289223779332, 'Total loss': 0.7682289223779332} | train loss {'Reaction outcome loss': 0.8264579398016776, 'Total loss': 0.8264579398016776}
2022-11-23 01:56:05,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:05,889 INFO:     Epoch: 57
2022-11-23 01:56:06,766 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7453134832057086, 'Total loss': 0.7453134832057086} | train loss {'Reaction outcome loss': 0.8236863509781899, 'Total loss': 0.8236863509781899}
2022-11-23 01:56:06,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:06,766 INFO:     Epoch: 58
2022-11-23 01:56:07,587 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7464422759684649, 'Total loss': 0.7464422759684649} | train loss {'Reaction outcome loss': 0.8209214299436538, 'Total loss': 0.8209214299436538}
2022-11-23 01:56:07,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:07,588 INFO:     Epoch: 59
2022-11-23 01:56:08,439 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7486774643713777, 'Total loss': 0.7486774643713777} | train loss {'Reaction outcome loss': 0.8243390217183098, 'Total loss': 0.8243390217183098}
2022-11-23 01:56:08,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:08,440 INFO:     Epoch: 60
2022-11-23 01:56:09,295 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7615086761387911, 'Total loss': 0.7615086761387911} | train loss {'Reaction outcome loss': 0.8234721979787273, 'Total loss': 0.8234721979787273}
2022-11-23 01:56:09,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:09,295 INFO:     Epoch: 61
2022-11-23 01:56:10,150 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7380901338024572, 'Total loss': 0.7380901338024572} | train loss {'Reaction outcome loss': 0.8227481458696627, 'Total loss': 0.8227481458696627}
2022-11-23 01:56:10,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:10,150 INFO:     Epoch: 62
2022-11-23 01:56:10,955 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7521511106328531, 'Total loss': 0.7521511106328531} | train loss {'Reaction outcome loss': 0.8282344220506568, 'Total loss': 0.8282344220506568}
2022-11-23 01:56:10,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:10,955 INFO:     Epoch: 63
2022-11-23 01:56:11,732 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.733007510277358, 'Total loss': 0.733007510277358} | train loss {'Reaction outcome loss': 0.822152583589477, 'Total loss': 0.822152583589477}
2022-11-23 01:56:11,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:11,732 INFO:     Epoch: 64
2022-11-23 01:56:12,564 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7624771913344209, 'Total loss': 0.7624771913344209} | train loss {'Reaction outcome loss': 0.8230423528340555, 'Total loss': 0.8230423528340555}
2022-11-23 01:56:12,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:12,564 INFO:     Epoch: 65
2022-11-23 01:56:13,397 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7366309044035998, 'Total loss': 0.7366309044035998} | train loss {'Reaction outcome loss': 0.8198343241407026, 'Total loss': 0.8198343241407026}
2022-11-23 01:56:13,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:13,398 INFO:     Epoch: 66
2022-11-23 01:56:14,191 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7236568534916098, 'Total loss': 0.7236568534916098} | train loss {'Reaction outcome loss': 0.821662696859529, 'Total loss': 0.821662696859529}
2022-11-23 01:56:14,191 INFO:     Found new best model at epoch 66
2022-11-23 01:56:14,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:14,192 INFO:     Epoch: 67
2022-11-23 01:56:15,003 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7638396986506202, 'Total loss': 0.7638396986506202} | train loss {'Reaction outcome loss': 0.8219869571828073, 'Total loss': 0.8219869571828073}
2022-11-23 01:56:15,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:15,004 INFO:     Epoch: 68
2022-11-23 01:56:15,851 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7384242767637427, 'Total loss': 0.7384242767637427} | train loss {'Reaction outcome loss': 0.8247441422314413, 'Total loss': 0.8247441422314413}
2022-11-23 01:56:15,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:15,852 INFO:     Epoch: 69
2022-11-23 01:56:16,685 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.754940768534487, 'Total loss': 0.754940768534487} | train loss {'Reaction outcome loss': 0.8262841032157021, 'Total loss': 0.8262841032157021}
2022-11-23 01:56:16,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:16,685 INFO:     Epoch: 70
2022-11-23 01:56:17,504 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7362133054570719, 'Total loss': 0.7362133054570719} | train loss {'Reaction outcome loss': 0.8247752015388781, 'Total loss': 0.8247752015388781}
2022-11-23 01:56:17,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:17,504 INFO:     Epoch: 71
2022-11-23 01:56:18,292 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7573187344453551, 'Total loss': 0.7573187344453551} | train loss {'Reaction outcome loss': 0.8241704516112804, 'Total loss': 0.8241704516112804}
2022-11-23 01:56:18,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:18,292 INFO:     Epoch: 72
2022-11-23 01:56:19,121 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7327530472116037, 'Total loss': 0.7327530472116037} | train loss {'Reaction outcome loss': 0.8226323586798483, 'Total loss': 0.8226323586798483}
2022-11-23 01:56:19,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:19,122 INFO:     Epoch: 73
2022-11-23 01:56:19,914 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7331117974086241, 'Total loss': 0.7331117974086241} | train loss {'Reaction outcome loss': 0.829342067842522, 'Total loss': 0.829342067842522}
2022-11-23 01:56:19,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:19,914 INFO:     Epoch: 74
2022-11-23 01:56:20,726 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7262671014124696, 'Total loss': 0.7262671014124696} | train loss {'Reaction outcome loss': 0.8221192923524687, 'Total loss': 0.8221192923524687}
2022-11-23 01:56:20,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:20,727 INFO:     Epoch: 75
2022-11-23 01:56:21,545 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7327695299278606, 'Total loss': 0.7327695299278606} | train loss {'Reaction outcome loss': 0.8211253525749329, 'Total loss': 0.8211253525749329}
2022-11-23 01:56:21,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:21,545 INFO:     Epoch: 76
2022-11-23 01:56:22,351 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7271780398758975, 'Total loss': 0.7271780398758975} | train loss {'Reaction outcome loss': 0.8223576037393462, 'Total loss': 0.8223576037393462}
2022-11-23 01:56:22,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:22,351 INFO:     Epoch: 77
2022-11-23 01:56:23,162 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7534664117477157, 'Total loss': 0.7534664117477157} | train loss {'Reaction outcome loss': 0.8260518609275741, 'Total loss': 0.8260518609275741}
2022-11-23 01:56:23,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:23,162 INFO:     Epoch: 78
2022-11-23 01:56:23,944 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7608945518732071, 'Total loss': 0.7608945518732071} | train loss {'Reaction outcome loss': 0.8261942017462945, 'Total loss': 0.8261942017462945}
2022-11-23 01:56:23,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:23,945 INFO:     Epoch: 79
2022-11-23 01:56:24,758 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.747203453020616, 'Total loss': 0.747203453020616} | train loss {'Reaction outcome loss': 0.8216752050624739, 'Total loss': 0.8216752050624739}
2022-11-23 01:56:24,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:24,758 INFO:     Epoch: 80
2022-11-23 01:56:25,557 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7452401125972922, 'Total loss': 0.7452401125972922} | train loss {'Reaction outcome loss': 0.820228923652922, 'Total loss': 0.820228923652922}
2022-11-23 01:56:25,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:25,557 INFO:     Epoch: 81
2022-11-23 01:56:26,361 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.739904680035331, 'Total loss': 0.739904680035331} | train loss {'Reaction outcome loss': 0.8265123729023242, 'Total loss': 0.8265123729023242}
2022-11-23 01:56:26,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:26,362 INFO:     Epoch: 82
2022-11-23 01:56:27,187 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.758714192292907, 'Total loss': 0.758714192292907} | train loss {'Reaction outcome loss': 0.8195079311488136, 'Total loss': 0.8195079311488136}
2022-11-23 01:56:27,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:27,188 INFO:     Epoch: 83
2022-11-23 01:56:27,990 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7333726598457857, 'Total loss': 0.7333726598457857} | train loss {'Reaction outcome loss': 0.8226756637375201, 'Total loss': 0.8226756637375201}
2022-11-23 01:56:27,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:27,990 INFO:     Epoch: 84
2022-11-23 01:56:28,803 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7417067357084968, 'Total loss': 0.7417067357084968} | train loss {'Reaction outcome loss': 0.8244311811943208, 'Total loss': 0.8244311811943208}
2022-11-23 01:56:28,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:28,803 INFO:     Epoch: 85
2022-11-23 01:56:29,614 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7366180203177712, 'Total loss': 0.7366180203177712} | train loss {'Reaction outcome loss': 0.8257117456486148, 'Total loss': 0.8257117456486148}
2022-11-23 01:56:29,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:29,615 INFO:     Epoch: 86
2022-11-23 01:56:30,434 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.734811583025889, 'Total loss': 0.734811583025889} | train loss {'Reaction outcome loss': 0.8197320365617352, 'Total loss': 0.8197320365617352}
2022-11-23 01:56:30,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:30,434 INFO:     Epoch: 87
2022-11-23 01:56:31,247 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7576298510486429, 'Total loss': 0.7576298510486429} | train loss {'Reaction outcome loss': 0.823806615245919, 'Total loss': 0.823806615245919}
2022-11-23 01:56:31,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:31,248 INFO:     Epoch: 88
2022-11-23 01:56:32,056 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7796387035738338, 'Total loss': 0.7796387035738338} | train loss {'Reaction outcome loss': 0.8235980438128594, 'Total loss': 0.8235980438128594}
2022-11-23 01:56:32,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:32,056 INFO:     Epoch: 89
2022-11-23 01:56:32,863 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7505996891043403, 'Total loss': 0.7505996891043403} | train loss {'Reaction outcome loss': 0.8216249912736877, 'Total loss': 0.8216249912736877}
2022-11-23 01:56:32,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:32,863 INFO:     Epoch: 90
2022-11-23 01:56:33,688 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7580961747602983, 'Total loss': 0.7580961747602983} | train loss {'Reaction outcome loss': 0.8269393909121713, 'Total loss': 0.8269393909121713}
2022-11-23 01:56:33,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:33,689 INFO:     Epoch: 91
2022-11-23 01:56:34,536 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7250193919647824, 'Total loss': 0.7250193919647824} | train loss {'Reaction outcome loss': 0.8219001985966198, 'Total loss': 0.8219001985966198}
2022-11-23 01:56:34,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:34,536 INFO:     Epoch: 92
2022-11-23 01:56:35,356 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7307401197877798, 'Total loss': 0.7307401197877798} | train loss {'Reaction outcome loss': 0.8260387754248034, 'Total loss': 0.8260387754248034}
2022-11-23 01:56:35,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:35,357 INFO:     Epoch: 93
2022-11-23 01:56:36,186 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7287695936181329, 'Total loss': 0.7287695936181329} | train loss {'Reaction outcome loss': 0.8233341572265471, 'Total loss': 0.8233341572265471}
2022-11-23 01:56:36,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:36,186 INFO:     Epoch: 94
2022-11-23 01:56:37,020 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.734759500080889, 'Total loss': 0.734759500080889} | train loss {'Reaction outcome loss': 0.8188915485816617, 'Total loss': 0.8188915485816617}
2022-11-23 01:56:37,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:37,021 INFO:     Epoch: 95
2022-11-23 01:56:37,861 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7318739992651072, 'Total loss': 0.7318739992651072} | train loss {'Reaction outcome loss': 0.8272333220849114, 'Total loss': 0.8272333220849114}
2022-11-23 01:56:37,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:37,861 INFO:     Epoch: 96
2022-11-23 01:56:38,679 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7264190322973512, 'Total loss': 0.7264190322973512} | train loss {'Reaction outcome loss': 0.8241104735962806, 'Total loss': 0.8241104735962806}
2022-11-23 01:56:38,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:38,680 INFO:     Epoch: 97
2022-11-23 01:56:39,492 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7392665987665002, 'Total loss': 0.7392665987665002} | train loss {'Reaction outcome loss': 0.8206811303332928, 'Total loss': 0.8206811303332928}
2022-11-23 01:56:39,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:39,492 INFO:     Epoch: 98
2022-11-23 01:56:40,370 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7319075993516229, 'Total loss': 0.7319075993516229} | train loss {'Reaction outcome loss': 0.8266003274869534, 'Total loss': 0.8266003274869534}
2022-11-23 01:56:40,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:40,370 INFO:     Epoch: 99
2022-11-23 01:56:41,155 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.745211205699227, 'Total loss': 0.745211205699227} | train loss {'Reaction outcome loss': 0.8237724047034017, 'Total loss': 0.8237724047034017}
2022-11-23 01:56:41,155 INFO:     Best model found after epoch 67 of 100.
2022-11-23 01:56:41,155 INFO:   Done with stage: TRAINING
2022-11-23 01:56:41,156 INFO:   Starting stage: EVALUATION
2022-11-23 01:56:41,274 INFO:   Done with stage: EVALUATION
2022-11-23 01:56:41,282 INFO:   Leaving out SEQ value Fold_0
2022-11-23 01:56:41,296 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:56:41,296 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:56:41,970 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:56:41,970 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:56:42,043 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:56:42,043 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:56:42,043 INFO:     No hyperparam tuning for this model
2022-11-23 01:56:42,043 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:56:42,043 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:56:42,044 INFO:     None feature selector for col prot
2022-11-23 01:56:42,044 INFO:     None feature selector for col prot
2022-11-23 01:56:42,044 INFO:     None feature selector for col prot
2022-11-23 01:56:42,045 INFO:     None feature selector for col chem
2022-11-23 01:56:42,045 INFO:     None feature selector for col chem
2022-11-23 01:56:42,045 INFO:     None feature selector for col chem
2022-11-23 01:56:42,045 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:56:42,045 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:56:42,046 INFO:     Number of params in model 168571
2022-11-23 01:56:42,050 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:56:42,050 INFO:   Starting stage: TRAINING
2022-11-23 01:56:42,107 INFO:     Val loss before train {'Reaction outcome loss': 1.0006985664367676, 'Total loss': 1.0006985664367676}
2022-11-23 01:56:42,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:42,108 INFO:     Epoch: 0
2022-11-23 01:56:42,913 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8290232541886243, 'Total loss': 0.8290232541886243} | train loss {'Reaction outcome loss': 0.8717577969541355, 'Total loss': 0.8717577969541355}
2022-11-23 01:56:42,913 INFO:     Found new best model at epoch 0
2022-11-23 01:56:42,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:42,914 INFO:     Epoch: 1
2022-11-23 01:56:43,733 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8035062866454775, 'Total loss': 0.8035062866454775} | train loss {'Reaction outcome loss': 0.8375475466251373, 'Total loss': 0.8375475466251373}
2022-11-23 01:56:43,733 INFO:     Found new best model at epoch 1
2022-11-23 01:56:43,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:43,734 INFO:     Epoch: 2
2022-11-23 01:56:44,521 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8277239406650717, 'Total loss': 0.8277239406650717} | train loss {'Reaction outcome loss': 0.8341740892857922, 'Total loss': 0.8341740892857922}
2022-11-23 01:56:44,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:44,522 INFO:     Epoch: 3
2022-11-23 01:56:45,327 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8171763487837531, 'Total loss': 0.8171763487837531} | train loss {'Reaction outcome loss': 0.8302284578887784, 'Total loss': 0.8302284578887784}
2022-11-23 01:56:45,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:45,327 INFO:     Epoch: 4
2022-11-23 01:56:46,128 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7920149612155828, 'Total loss': 0.7920149612155828} | train loss {'Reaction outcome loss': 0.8211220235240703, 'Total loss': 0.8211220235240703}
2022-11-23 01:56:46,129 INFO:     Found new best model at epoch 4
2022-11-23 01:56:46,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:46,130 INFO:     Epoch: 5
2022-11-23 01:56:46,992 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7799879238009453, 'Total loss': 0.7799879238009453} | train loss {'Reaction outcome loss': 0.8180103939406725, 'Total loss': 0.8180103939406725}
2022-11-23 01:56:46,992 INFO:     Found new best model at epoch 5
2022-11-23 01:56:46,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:46,993 INFO:     Epoch: 6
2022-11-23 01:56:47,829 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7837799834934148, 'Total loss': 0.7837799834934148} | train loss {'Reaction outcome loss': 0.8126753509044647, 'Total loss': 0.8126753509044647}
2022-11-23 01:56:47,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:47,829 INFO:     Epoch: 7
2022-11-23 01:56:48,667 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8270462107929316, 'Total loss': 0.8270462107929316} | train loss {'Reaction outcome loss': 0.8134086681871998, 'Total loss': 0.8134086681871998}
2022-11-23 01:56:48,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:48,667 INFO:     Epoch: 8
2022-11-23 01:56:49,485 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8032473075118932, 'Total loss': 0.8032473075118932} | train loss {'Reaction outcome loss': 0.8125932017151191, 'Total loss': 0.8125932017151191}
2022-11-23 01:56:49,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:49,485 INFO:     Epoch: 9
2022-11-23 01:56:50,257 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7837811423973604, 'Total loss': 0.7837811423973604} | train loss {'Reaction outcome loss': 0.8102268870995969, 'Total loss': 0.8102268870995969}
2022-11-23 01:56:50,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:50,257 INFO:     Epoch: 10
2022-11-23 01:56:51,053 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8620424094525251, 'Total loss': 0.8620424094525251} | train loss {'Reaction outcome loss': 0.812673838406193, 'Total loss': 0.812673838406193}
2022-11-23 01:56:51,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:51,053 INFO:     Epoch: 11
2022-11-23 01:56:51,860 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7921627495776523, 'Total loss': 0.7921627495776523} | train loss {'Reaction outcome loss': 0.8132959450994219, 'Total loss': 0.8132959450994219}
2022-11-23 01:56:51,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:51,860 INFO:     Epoch: 12
2022-11-23 01:56:52,663 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7951775342226028, 'Total loss': 0.7951775342226028} | train loss {'Reaction outcome loss': 0.81343179235653, 'Total loss': 0.81343179235653}
2022-11-23 01:56:52,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:52,664 INFO:     Epoch: 13
2022-11-23 01:56:53,455 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8005937513979998, 'Total loss': 0.8005937513979998} | train loss {'Reaction outcome loss': 0.8131564978434115, 'Total loss': 0.8131564978434115}
2022-11-23 01:56:53,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:53,455 INFO:     Epoch: 14
2022-11-23 01:56:54,260 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7667691477320411, 'Total loss': 0.7667691477320411} | train loss {'Reaction outcome loss': 0.8106042587027258, 'Total loss': 0.8106042587027258}
2022-11-23 01:56:54,260 INFO:     Found new best model at epoch 14
2022-11-23 01:56:54,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:54,261 INFO:     Epoch: 15
2022-11-23 01:56:55,096 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7765363072129813, 'Total loss': 0.7765363072129813} | train loss {'Reaction outcome loss': 0.8069409927543328, 'Total loss': 0.8069409927543328}
2022-11-23 01:56:55,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:55,097 INFO:     Epoch: 16
2022-11-23 01:56:55,890 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7794112224470485, 'Total loss': 0.7794112224470485} | train loss {'Reaction outcome loss': 0.8035581862439914, 'Total loss': 0.8035581862439914}
2022-11-23 01:56:55,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:55,890 INFO:     Epoch: 17
2022-11-23 01:56:56,692 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.772747511213476, 'Total loss': 0.772747511213476} | train loss {'Reaction outcome loss': 0.8130813784745274, 'Total loss': 0.8130813784745274}
2022-11-23 01:56:56,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:56,692 INFO:     Epoch: 18
2022-11-23 01:56:57,571 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7857727774164893, 'Total loss': 0.7857727774164893} | train loss {'Reaction outcome loss': 0.8079917908931266, 'Total loss': 0.8079917908931266}
2022-11-23 01:56:57,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:57,571 INFO:     Epoch: 19
2022-11-23 01:56:58,396 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7886607775633986, 'Total loss': 0.7886607775633986} | train loss {'Reaction outcome loss': 0.811470710623021, 'Total loss': 0.811470710623021}
2022-11-23 01:56:58,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:58,396 INFO:     Epoch: 20
2022-11-23 01:56:59,259 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7785150056535547, 'Total loss': 0.7785150056535547} | train loss {'Reaction outcome loss': 0.8082289755344391, 'Total loss': 0.8082289755344391}
2022-11-23 01:56:59,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:56:59,261 INFO:     Epoch: 21
2022-11-23 01:57:00,186 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7853318513794378, 'Total loss': 0.7853318513794378} | train loss {'Reaction outcome loss': 0.8046537784897552, 'Total loss': 0.8046537784897552}
2022-11-23 01:57:00,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:00,187 INFO:     Epoch: 22
2022-11-23 01:57:01,042 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7896293137561191, 'Total loss': 0.7896293137561191} | train loss {'Reaction outcome loss': 0.803176159883032, 'Total loss': 0.803176159883032}
2022-11-23 01:57:01,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:01,042 INFO:     Epoch: 23
2022-11-23 01:57:01,898 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7811019393530759, 'Total loss': 0.7811019393530759} | train loss {'Reaction outcome loss': 0.8055136948215719, 'Total loss': 0.8055136948215719}
2022-11-23 01:57:01,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:01,899 INFO:     Epoch: 24
2022-11-23 01:57:02,747 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8011809722943739, 'Total loss': 0.8011809722943739} | train loss {'Reaction outcome loss': 0.8060242002107659, 'Total loss': 0.8060242002107659}
2022-11-23 01:57:02,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:02,747 INFO:     Epoch: 25
2022-11-23 01:57:03,670 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7690509794787928, 'Total loss': 0.7690509794787928} | train loss {'Reaction outcome loss': 0.803420149550146, 'Total loss': 0.803420149550146}
2022-11-23 01:57:03,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:03,670 INFO:     Epoch: 26
2022-11-23 01:57:04,606 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7955276376821778, 'Total loss': 0.7955276376821778} | train loss {'Reaction outcome loss': 0.804071243685119, 'Total loss': 0.804071243685119}
2022-11-23 01:57:04,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:04,606 INFO:     Epoch: 27
2022-11-23 01:57:05,515 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8071752701970664, 'Total loss': 0.8071752701970664} | train loss {'Reaction outcome loss': 0.8047976941478495, 'Total loss': 0.8047976941478495}
2022-11-23 01:57:05,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:05,516 INFO:     Epoch: 28
2022-11-23 01:57:06,404 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7884021577509966, 'Total loss': 0.7884021577509966} | train loss {'Reaction outcome loss': 0.8084908243344755, 'Total loss': 0.8084908243344755}
2022-11-23 01:57:06,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:06,404 INFO:     Epoch: 29
2022-11-23 01:57:07,348 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8173733807422898, 'Total loss': 0.8173733807422898} | train loss {'Reaction outcome loss': 0.8004002568673114, 'Total loss': 0.8004002568673114}
2022-11-23 01:57:07,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:07,348 INFO:     Epoch: 30
2022-11-23 01:57:08,215 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7784632566300306, 'Total loss': 0.7784632566300306} | train loss {'Reaction outcome loss': 0.8023390206755424, 'Total loss': 0.8023390206755424}
2022-11-23 01:57:08,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:08,215 INFO:     Epoch: 31
2022-11-23 01:57:09,118 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.770074570720846, 'Total loss': 0.770074570720846} | train loss {'Reaction outcome loss': 0.8075190106216742, 'Total loss': 0.8075190106216742}
2022-11-23 01:57:09,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:09,118 INFO:     Epoch: 32
2022-11-23 01:57:10,022 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7760926871137186, 'Total loss': 0.7760926871137186} | train loss {'Reaction outcome loss': 0.8034410672528404, 'Total loss': 0.8034410672528404}
2022-11-23 01:57:10,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:10,022 INFO:     Epoch: 33
2022-11-23 01:57:10,958 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.788478512655605, 'Total loss': 0.788478512655605} | train loss {'Reaction outcome loss': 0.8107626916194449, 'Total loss': 0.8107626916194449}
2022-11-23 01:57:10,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:10,959 INFO:     Epoch: 34
2022-11-23 01:57:11,923 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8070429543202574, 'Total loss': 0.8070429543202574} | train loss {'Reaction outcome loss': 0.8037973830894548, 'Total loss': 0.8037973830894548}
2022-11-23 01:57:11,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:11,923 INFO:     Epoch: 35
2022-11-23 01:57:12,807 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7731897129931233, 'Total loss': 0.7731897129931233} | train loss {'Reaction outcome loss': 0.8098384027578392, 'Total loss': 0.8098384027578392}
2022-11-23 01:57:12,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:12,808 INFO:     Epoch: 36
2022-11-23 01:57:13,678 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7813369624994018, 'Total loss': 0.7813369624994018} | train loss {'Reaction outcome loss': 0.804741536354532, 'Total loss': 0.804741536354532}
2022-11-23 01:57:13,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:13,678 INFO:     Epoch: 37
2022-11-23 01:57:14,616 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7758908881382509, 'Total loss': 0.7758908881382509} | train loss {'Reaction outcome loss': 0.8079803218646925, 'Total loss': 0.8079803218646925}
2022-11-23 01:57:14,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:14,616 INFO:     Epoch: 38
2022-11-23 01:57:15,550 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.776127351955934, 'Total loss': 0.776127351955934} | train loss {'Reaction outcome loss': 0.802311046999328, 'Total loss': 0.802311046999328}
2022-11-23 01:57:15,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:15,550 INFO:     Epoch: 39
2022-11-23 01:57:16,455 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8083051375367425, 'Total loss': 0.8083051375367425} | train loss {'Reaction outcome loss': 0.8036393588902999, 'Total loss': 0.8036393588902999}
2022-11-23 01:57:16,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:16,455 INFO:     Epoch: 40
2022-11-23 01:57:17,329 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7861976237459616, 'Total loss': 0.7861976237459616} | train loss {'Reaction outcome loss': 0.8044603902466443, 'Total loss': 0.8044603902466443}
2022-11-23 01:57:17,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:17,329 INFO:     Epoch: 41
2022-11-23 01:57:18,203 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7899649725718931, 'Total loss': 0.7899649725718931} | train loss {'Reaction outcome loss': 0.8090620965373759, 'Total loss': 0.8090620965373759}
2022-11-23 01:57:18,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:18,204 INFO:     Epoch: 42
2022-11-23 01:57:19,124 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7774537249722264, 'Total loss': 0.7774537249722264} | train loss {'Reaction outcome loss': 0.8026675905500139, 'Total loss': 0.8026675905500139}
2022-11-23 01:57:19,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:19,125 INFO:     Epoch: 43
2022-11-23 01:57:19,973 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7988121191209013, 'Total loss': 0.7988121191209013} | train loss {'Reaction outcome loss': 0.8024997758622072, 'Total loss': 0.8024997758622072}
2022-11-23 01:57:19,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:19,973 INFO:     Epoch: 44
2022-11-23 01:57:20,833 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7700919339602644, 'Total loss': 0.7700919339602644} | train loss {'Reaction outcome loss': 0.8030535258808914, 'Total loss': 0.8030535258808914}
2022-11-23 01:57:20,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:20,833 INFO:     Epoch: 45
2022-11-23 01:57:21,701 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7632207836617123, 'Total loss': 0.7632207836617123} | train loss {'Reaction outcome loss': 0.8021636686762985, 'Total loss': 0.8021636686762985}
2022-11-23 01:57:21,701 INFO:     Found new best model at epoch 45
2022-11-23 01:57:21,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:21,702 INFO:     Epoch: 46
2022-11-23 01:57:22,632 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7723380076614293, 'Total loss': 0.7723380076614293} | train loss {'Reaction outcome loss': 0.8079602590629033, 'Total loss': 0.8079602590629033}
2022-11-23 01:57:22,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:22,633 INFO:     Epoch: 47
2022-11-23 01:57:23,566 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7968489744446494, 'Total loss': 0.7968489744446494} | train loss {'Reaction outcome loss': 0.8042924541599896, 'Total loss': 0.8042924541599896}
2022-11-23 01:57:23,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:23,567 INFO:     Epoch: 48
2022-11-23 01:57:24,484 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7879366034811194, 'Total loss': 0.7879366034811194} | train loss {'Reaction outcome loss': 0.7987956304939425, 'Total loss': 0.7987956304939425}
2022-11-23 01:57:24,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:24,484 INFO:     Epoch: 49
2022-11-23 01:57:25,333 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7796705412593755, 'Total loss': 0.7796705412593755} | train loss {'Reaction outcome loss': 0.8040365090175551, 'Total loss': 0.8040365090175551}
2022-11-23 01:57:25,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:25,334 INFO:     Epoch: 50
2022-11-23 01:57:26,167 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7968040928244591, 'Total loss': 0.7968040928244591} | train loss {'Reaction outcome loss': 0.8018276855653647, 'Total loss': 0.8018276855653647}
2022-11-23 01:57:26,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:26,168 INFO:     Epoch: 51
2022-11-23 01:57:27,002 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7936467934738506, 'Total loss': 0.7936467934738506} | train loss {'Reaction outcome loss': 0.8031664894551647, 'Total loss': 0.8031664894551647}
2022-11-23 01:57:27,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:27,002 INFO:     Epoch: 52
2022-11-23 01:57:27,831 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7780517868020318, 'Total loss': 0.7780517868020318} | train loss {'Reaction outcome loss': 0.8028112055087576, 'Total loss': 0.8028112055087576}
2022-11-23 01:57:27,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:27,832 INFO:     Epoch: 53
2022-11-23 01:57:28,733 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.783122677017342, 'Total loss': 0.783122677017342} | train loss {'Reaction outcome loss': 0.8014933004671213, 'Total loss': 0.8014933004671213}
2022-11-23 01:57:28,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:28,734 INFO:     Epoch: 54
2022-11-23 01:57:29,571 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8035156659104608, 'Total loss': 0.8035156659104608} | train loss {'Reaction outcome loss': 0.8020143611090523, 'Total loss': 0.8020143611090523}
2022-11-23 01:57:29,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:29,571 INFO:     Epoch: 55
2022-11-23 01:57:30,483 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7981471304189075, 'Total loss': 0.7981471304189075} | train loss {'Reaction outcome loss': 0.8034173439960091, 'Total loss': 0.8034173439960091}
2022-11-23 01:57:30,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:30,484 INFO:     Epoch: 56
2022-11-23 01:57:31,351 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7963342341509733, 'Total loss': 0.7963342341509733} | train loss {'Reaction outcome loss': 0.8064113044008917, 'Total loss': 0.8064113044008917}
2022-11-23 01:57:31,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:31,351 INFO:     Epoch: 57
2022-11-23 01:57:32,242 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7945142997936769, 'Total loss': 0.7945142997936769} | train loss {'Reaction outcome loss': 0.8008718079450179, 'Total loss': 0.8008718079450179}
2022-11-23 01:57:32,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:32,242 INFO:     Epoch: 58
2022-11-23 01:57:33,133 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7785241813822226, 'Total loss': 0.7785241813822226} | train loss {'Reaction outcome loss': 0.8045133981169487, 'Total loss': 0.8045133981169487}
2022-11-23 01:57:33,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:33,133 INFO:     Epoch: 59
2022-11-23 01:57:34,020 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8001400083303452, 'Total loss': 0.8001400083303452} | train loss {'Reaction outcome loss': 0.8004380661614087, 'Total loss': 0.8004380661614087}
2022-11-23 01:57:34,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:34,020 INFO:     Epoch: 60
2022-11-23 01:57:34,887 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7864583425901153, 'Total loss': 0.7864583425901153} | train loss {'Reaction outcome loss': 0.8000233414221783, 'Total loss': 0.8000233414221783}
2022-11-23 01:57:34,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:34,888 INFO:     Epoch: 61
2022-11-23 01:57:35,727 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8164239803498442, 'Total loss': 0.8164239803498442} | train loss {'Reaction outcome loss': 0.8038153907474206, 'Total loss': 0.8038153907474206}
2022-11-23 01:57:35,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:35,728 INFO:     Epoch: 62
2022-11-23 01:57:36,615 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7703573886643756, 'Total loss': 0.7703573886643756} | train loss {'Reaction outcome loss': 0.8012108829556679, 'Total loss': 0.8012108829556679}
2022-11-23 01:57:36,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:36,616 INFO:     Epoch: 63
2022-11-23 01:57:37,474 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.804840505800464, 'Total loss': 0.804840505800464} | train loss {'Reaction outcome loss': 0.8026766333044791, 'Total loss': 0.8026766333044791}
2022-11-23 01:57:37,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:37,475 INFO:     Epoch: 64
2022-11-23 01:57:38,355 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.782019514251839, 'Total loss': 0.782019514251839} | train loss {'Reaction outcome loss': 0.802412834824348, 'Total loss': 0.802412834824348}
2022-11-23 01:57:38,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:38,355 INFO:     Epoch: 65
2022-11-23 01:57:39,257 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7895784520290114, 'Total loss': 0.7895784520290114} | train loss {'Reaction outcome loss': 0.8025549556527819, 'Total loss': 0.8025549556527819}
2022-11-23 01:57:39,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:39,257 INFO:     Epoch: 66
2022-11-23 01:57:40,096 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.776003167710521, 'Total loss': 0.776003167710521} | train loss {'Reaction outcome loss': 0.8018201736771331, 'Total loss': 0.8018201736771331}
2022-11-23 01:57:40,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:40,097 INFO:     Epoch: 67
2022-11-23 01:57:40,927 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.813298413021998, 'Total loss': 0.813298413021998} | train loss {'Reaction outcome loss': 0.8003958899147656, 'Total loss': 0.8003958899147656}
2022-11-23 01:57:40,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:40,928 INFO:     Epoch: 68
2022-11-23 01:57:41,794 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7809797274795446, 'Total loss': 0.7809797274795446} | train loss {'Reaction outcome loss': 0.8030095049313136, 'Total loss': 0.8030095049313136}
2022-11-23 01:57:41,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:41,795 INFO:     Epoch: 69
2022-11-23 01:57:42,692 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8040474964813753, 'Total loss': 0.8040474964813753} | train loss {'Reaction outcome loss': 0.8012652052908528, 'Total loss': 0.8012652052908528}
2022-11-23 01:57:42,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:42,693 INFO:     Epoch: 70
2022-11-23 01:57:43,543 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7921636314554648, 'Total loss': 0.7921636314554648} | train loss {'Reaction outcome loss': 0.8057814329254384, 'Total loss': 0.8057814329254384}
2022-11-23 01:57:43,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:43,543 INFO:     Epoch: 71
2022-11-23 01:57:44,408 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7782676714387807, 'Total loss': 0.7782676714387807} | train loss {'Reaction outcome loss': 0.7997372438712996, 'Total loss': 0.7997372438712996}
2022-11-23 01:57:44,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:44,408 INFO:     Epoch: 72
2022-11-23 01:57:45,287 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7658192603425547, 'Total loss': 0.7658192603425547} | train loss {'Reaction outcome loss': 0.8009363502872233, 'Total loss': 0.8009363502872233}
2022-11-23 01:57:45,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:45,287 INFO:     Epoch: 73
2022-11-23 01:57:46,159 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7582639431242238, 'Total loss': 0.7582639431242238} | train loss {'Reaction outcome loss': 0.8002601454452593, 'Total loss': 0.8002601454452593}
2022-11-23 01:57:46,160 INFO:     Found new best model at epoch 73
2022-11-23 01:57:46,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:46,160 INFO:     Epoch: 74
2022-11-23 01:57:46,998 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7867242287505757, 'Total loss': 0.7867242287505757} | train loss {'Reaction outcome loss': 0.8063704611087332, 'Total loss': 0.8063704611087332}
2022-11-23 01:57:46,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:46,998 INFO:     Epoch: 75
2022-11-23 01:57:47,903 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7911538915200667, 'Total loss': 0.7911538915200667} | train loss {'Reaction outcome loss': 0.8043685913085937, 'Total loss': 0.8043685913085937}
2022-11-23 01:57:47,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:47,904 INFO:     Epoch: 76
2022-11-23 01:57:48,781 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7989080754870718, 'Total loss': 0.7989080754870718} | train loss {'Reaction outcome loss': 0.7988287191001736, 'Total loss': 0.7988287191001736}
2022-11-23 01:57:48,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:48,782 INFO:     Epoch: 77
2022-11-23 01:57:49,638 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7769127423790368, 'Total loss': 0.7769127423790368} | train loss {'Reaction outcome loss': 0.8038746489554035, 'Total loss': 0.8038746489554035}
2022-11-23 01:57:49,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:49,638 INFO:     Epoch: 78
2022-11-23 01:57:50,534 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7792096165093508, 'Total loss': 0.7792096165093508} | train loss {'Reaction outcome loss': 0.7986040657880354, 'Total loss': 0.7986040657880354}
2022-11-23 01:57:50,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:50,534 INFO:     Epoch: 79
2022-11-23 01:57:51,386 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7719374600459229, 'Total loss': 0.7719374600459229} | train loss {'Reaction outcome loss': 0.7995428709351287, 'Total loss': 0.7995428709351287}
2022-11-23 01:57:51,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:51,387 INFO:     Epoch: 80
2022-11-23 01:57:52,231 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7978637462312524, 'Total loss': 0.7978637462312524} | train loss {'Reaction outcome loss': 0.8048472150247924, 'Total loss': 0.8048472150247924}
2022-11-23 01:57:52,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:52,231 INFO:     Epoch: 81
2022-11-23 01:57:53,132 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7890423624352976, 'Total loss': 0.7890423624352976} | train loss {'Reaction outcome loss': 0.8028690743203066, 'Total loss': 0.8028690743203066}
2022-11-23 01:57:53,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:53,133 INFO:     Epoch: 82
2022-11-23 01:57:53,988 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7686529159545898, 'Total loss': 0.7686529159545898} | train loss {'Reaction outcome loss': 0.8022579686982291, 'Total loss': 0.8022579686982291}
2022-11-23 01:57:53,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:53,988 INFO:     Epoch: 83
2022-11-23 01:57:54,856 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8121807250109586, 'Total loss': 0.8121807250109586} | train loss {'Reaction outcome loss': 0.8052055900194207, 'Total loss': 0.8052055900194207}
2022-11-23 01:57:54,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:54,857 INFO:     Epoch: 84
2022-11-23 01:57:55,747 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7757743888280608, 'Total loss': 0.7757743888280608} | train loss {'Reaction outcome loss': 0.7982256349252195, 'Total loss': 0.7982256349252195}
2022-11-23 01:57:55,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:55,748 INFO:     Epoch: 85
2022-11-23 01:57:56,595 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7776896167885173, 'Total loss': 0.7776896167885173} | train loss {'Reaction outcome loss': 0.8026787166692773, 'Total loss': 0.8026787166692773}
2022-11-23 01:57:56,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:56,595 INFO:     Epoch: 86
2022-11-23 01:57:57,473 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7661473006010056, 'Total loss': 0.7661473006010056} | train loss {'Reaction outcome loss': 0.7993842866955971, 'Total loss': 0.7993842866955971}
2022-11-23 01:57:57,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:57,474 INFO:     Epoch: 87
2022-11-23 01:57:58,347 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7852582416751168, 'Total loss': 0.7852582416751168} | train loss {'Reaction outcome loss': 0.7961708312131921, 'Total loss': 0.7961708312131921}
2022-11-23 01:57:58,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:58,347 INFO:     Epoch: 88
2022-11-23 01:57:59,257 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7707504040815614, 'Total loss': 0.7707504040815614} | train loss {'Reaction outcome loss': 0.8010394338442355, 'Total loss': 0.8010394338442355}
2022-11-23 01:57:59,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:57:59,257 INFO:     Epoch: 89
2022-11-23 01:58:00,158 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7974538362839005, 'Total loss': 0.7974538362839005} | train loss {'Reaction outcome loss': 0.8002323406083244, 'Total loss': 0.8002323406083244}
2022-11-23 01:58:00,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:00,158 INFO:     Epoch: 90
2022-11-23 01:58:00,993 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7902908677404578, 'Total loss': 0.7902908677404578} | train loss {'Reaction outcome loss': 0.8051300539045918, 'Total loss': 0.8051300539045918}
2022-11-23 01:58:00,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:00,995 INFO:     Epoch: 91
2022-11-23 01:58:01,879 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7826677885922518, 'Total loss': 0.7826677885922518} | train loss {'Reaction outcome loss': 0.8034339982636121, 'Total loss': 0.8034339982636121}
2022-11-23 01:58:01,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:01,879 INFO:     Epoch: 92
2022-11-23 01:58:02,715 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7821077900854024, 'Total loss': 0.7821077900854024} | train loss {'Reaction outcome loss': 0.7997487833305281, 'Total loss': 0.7997487833305281}
2022-11-23 01:58:02,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:02,715 INFO:     Epoch: 93
2022-11-23 01:58:03,551 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7915589206598022, 'Total loss': 0.7915589206598022} | train loss {'Reaction outcome loss': 0.7959605100203534, 'Total loss': 0.7959605100203534}
2022-11-23 01:58:03,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:03,552 INFO:     Epoch: 94
2022-11-23 01:58:04,388 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8146449053152041, 'Total loss': 0.8146449053152041} | train loss {'Reaction outcome loss': 0.8057470175684714, 'Total loss': 0.8057470175684714}
2022-11-23 01:58:04,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:04,388 INFO:     Epoch: 95
2022-11-23 01:58:05,242 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8102879490364682, 'Total loss': 0.8102879490364682} | train loss {'Reaction outcome loss': 0.7999768490694007, 'Total loss': 0.7999768490694007}
2022-11-23 01:58:05,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:05,243 INFO:     Epoch: 96
2022-11-23 01:58:06,107 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.777117448774251, 'Total loss': 0.777117448774251} | train loss {'Reaction outcome loss': 0.8052356897568216, 'Total loss': 0.8052356897568216}
2022-11-23 01:58:06,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:06,108 INFO:     Epoch: 97
2022-11-23 01:58:06,941 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7971448735757307, 'Total loss': 0.7971448735757307} | train loss {'Reaction outcome loss': 0.8030600484536619, 'Total loss': 0.8030600484536619}
2022-11-23 01:58:06,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:06,941 INFO:     Epoch: 98
2022-11-23 01:58:07,789 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7912236452102661, 'Total loss': 0.7912236452102661} | train loss {'Reaction outcome loss': 0.801899012375851, 'Total loss': 0.801899012375851}
2022-11-23 01:58:07,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:07,790 INFO:     Epoch: 99
2022-11-23 01:58:08,615 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8010596619410948, 'Total loss': 0.8010596619410948} | train loss {'Reaction outcome loss': 0.801883263490638, 'Total loss': 0.801883263490638}
2022-11-23 01:58:08,615 INFO:     Best model found after epoch 74 of 100.
2022-11-23 01:58:08,615 INFO:   Done with stage: TRAINING
2022-11-23 01:58:08,615 INFO:   Starting stage: EVALUATION
2022-11-23 01:58:08,765 INFO:   Done with stage: EVALUATION
2022-11-23 01:58:08,765 INFO:   Leaving out SEQ value Fold_1
2022-11-23 01:58:08,778 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:58:08,778 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:58:09,450 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:58:09,451 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:58:09,528 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:58:09,528 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:58:09,528 INFO:     No hyperparam tuning for this model
2022-11-23 01:58:09,528 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:58:09,528 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:58:09,529 INFO:     None feature selector for col prot
2022-11-23 01:58:09,529 INFO:     None feature selector for col prot
2022-11-23 01:58:09,529 INFO:     None feature selector for col prot
2022-11-23 01:58:09,530 INFO:     None feature selector for col chem
2022-11-23 01:58:09,530 INFO:     None feature selector for col chem
2022-11-23 01:58:09,530 INFO:     None feature selector for col chem
2022-11-23 01:58:09,530 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:58:09,530 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:58:09,532 INFO:     Number of params in model 168571
2022-11-23 01:58:09,535 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:58:09,535 INFO:   Starting stage: TRAINING
2022-11-23 01:58:09,594 INFO:     Val loss before train {'Reaction outcome loss': 1.0543904345143924, 'Total loss': 1.0543904345143924}
2022-11-23 01:58:09,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:09,594 INFO:     Epoch: 0
2022-11-23 01:58:10,420 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8492262837561694, 'Total loss': 0.8492262837561694} | train loss {'Reaction outcome loss': 0.8756750069102462, 'Total loss': 0.8756750069102462}
2022-11-23 01:58:10,421 INFO:     Found new best model at epoch 0
2022-11-23 01:58:10,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:10,422 INFO:     Epoch: 1
2022-11-23 01:58:11,379 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.868140574883331, 'Total loss': 0.868140574883331} | train loss {'Reaction outcome loss': 0.8460139921733312, 'Total loss': 0.8460139921733312}
2022-11-23 01:58:11,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:11,379 INFO:     Epoch: 2
2022-11-23 01:58:12,195 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.828978914428841, 'Total loss': 0.828978914428841} | train loss {'Reaction outcome loss': 0.8429514692754162, 'Total loss': 0.8429514692754162}
2022-11-23 01:58:12,195 INFO:     Found new best model at epoch 2
2022-11-23 01:58:12,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:12,196 INFO:     Epoch: 3
2022-11-23 01:58:13,130 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8621967150406404, 'Total loss': 0.8621967150406404} | train loss {'Reaction outcome loss': 0.8361010934625354, 'Total loss': 0.8361010934625354}
2022-11-23 01:58:13,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:13,130 INFO:     Epoch: 4
2022-11-23 01:58:13,944 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8357373814691197, 'Total loss': 0.8357373814691197} | train loss {'Reaction outcome loss': 0.8350459731355006, 'Total loss': 0.8350459731355006}
2022-11-23 01:58:13,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:13,944 INFO:     Epoch: 5
2022-11-23 01:58:14,770 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.827856036749753, 'Total loss': 0.827856036749753} | train loss {'Reaction outcome loss': 0.8287693479839636, 'Total loss': 0.8287693479839636}
2022-11-23 01:58:14,770 INFO:     Found new best model at epoch 5
2022-11-23 01:58:14,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:14,771 INFO:     Epoch: 6
2022-11-23 01:58:15,594 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8390354852784764, 'Total loss': 0.8390354852784764} | train loss {'Reaction outcome loss': 0.8245078310674551, 'Total loss': 0.8245078310674551}
2022-11-23 01:58:15,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:15,594 INFO:     Epoch: 7
2022-11-23 01:58:16,429 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8054595223881982, 'Total loss': 0.8054595223881982} | train loss {'Reaction outcome loss': 0.8266704975342264, 'Total loss': 0.8266704975342264}
2022-11-23 01:58:16,429 INFO:     Found new best model at epoch 7
2022-11-23 01:58:16,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:16,430 INFO:     Epoch: 8
2022-11-23 01:58:17,234 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8021664809096943, 'Total loss': 0.8021664809096943} | train loss {'Reaction outcome loss': 0.8173840919319464, 'Total loss': 0.8173840919319464}
2022-11-23 01:58:17,234 INFO:     Found new best model at epoch 8
2022-11-23 01:58:17,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:17,235 INFO:     Epoch: 9
2022-11-23 01:58:18,069 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8158038827505979, 'Total loss': 0.8158038827505979} | train loss {'Reaction outcome loss': 0.8183009637861836, 'Total loss': 0.8183009637861836}
2022-11-23 01:58:18,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:18,069 INFO:     Epoch: 10
2022-11-23 01:58:18,873 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8132158423011954, 'Total loss': 0.8132158423011954} | train loss {'Reaction outcome loss': 0.8202038275952241, 'Total loss': 0.8202038275952241}
2022-11-23 01:58:18,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:18,873 INFO:     Epoch: 11
2022-11-23 01:58:19,716 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8270186599005352, 'Total loss': 0.8270186599005352} | train loss {'Reaction outcome loss': 0.8163334565503256, 'Total loss': 0.8163334565503256}
2022-11-23 01:58:19,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:19,717 INFO:     Epoch: 12
2022-11-23 01:58:20,565 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8137362734837965, 'Total loss': 0.8137362734837965} | train loss {'Reaction outcome loss': 0.8191351956250716, 'Total loss': 0.8191351956250716}
2022-11-23 01:58:20,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:20,566 INFO:     Epoch: 13
2022-11-23 01:58:21,344 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8312613618644801, 'Total loss': 0.8312613618644801} | train loss {'Reaction outcome loss': 0.8184054507284748, 'Total loss': 0.8184054507284748}
2022-11-23 01:58:21,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:21,345 INFO:     Epoch: 14
2022-11-23 01:58:22,162 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.816985319961201, 'Total loss': 0.816985319961201} | train loss {'Reaction outcome loss': 0.8098356592411897, 'Total loss': 0.8098356592411897}
2022-11-23 01:58:22,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:22,162 INFO:     Epoch: 15
2022-11-23 01:58:22,982 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8100741051814773, 'Total loss': 0.8100741051814773} | train loss {'Reaction outcome loss': 0.8152067879024817, 'Total loss': 0.8152067879024817}
2022-11-23 01:58:22,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:22,983 INFO:     Epoch: 16
2022-11-23 01:58:23,787 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8131967518817295, 'Total loss': 0.8131967518817295} | train loss {'Reaction outcome loss': 0.8167690269801081, 'Total loss': 0.8167690269801081}
2022-11-23 01:58:23,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:23,787 INFO:     Epoch: 17
2022-11-23 01:58:24,586 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8440334844318303, 'Total loss': 0.8440334844318303} | train loss {'Reaction outcome loss': 0.8120966113343531, 'Total loss': 0.8120966113343531}
2022-11-23 01:58:24,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:24,586 INFO:     Epoch: 18
2022-11-23 01:58:25,419 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8221966244957664, 'Total loss': 0.8221966244957664} | train loss {'Reaction outcome loss': 0.8131768449228637, 'Total loss': 0.8131768449228637}
2022-11-23 01:58:25,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:25,419 INFO:     Epoch: 19
2022-11-23 01:58:26,262 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8227204003117301, 'Total loss': 0.8227204003117301} | train loss {'Reaction outcome loss': 0.8164345633010475, 'Total loss': 0.8164345633010475}
2022-11-23 01:58:26,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:26,262 INFO:     Epoch: 20
2022-11-23 01:58:27,089 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8142613992094994, 'Total loss': 0.8142613992094994} | train loss {'Reaction outcome loss': 0.8095859936305455, 'Total loss': 0.8095859936305455}
2022-11-23 01:58:27,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:27,089 INFO:     Epoch: 21
2022-11-23 01:58:27,919 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.810950980945067, 'Total loss': 0.810950980945067} | train loss {'Reaction outcome loss': 0.8135406465554724, 'Total loss': 0.8135406465554724}
2022-11-23 01:58:27,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:27,920 INFO:     Epoch: 22
2022-11-23 01:58:28,784 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8092761967669834, 'Total loss': 0.8092761967669834} | train loss {'Reaction outcome loss': 0.8132826042418577, 'Total loss': 0.8132826042418577}
2022-11-23 01:58:28,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:28,784 INFO:     Epoch: 23
2022-11-23 01:58:29,598 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8066316091201522, 'Total loss': 0.8066316091201522} | train loss {'Reaction outcome loss': 0.8114842699498547, 'Total loss': 0.8114842699498547}
2022-11-23 01:58:29,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:29,598 INFO:     Epoch: 24
2022-11-23 01:58:30,411 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.804278202354908, 'Total loss': 0.804278202354908} | train loss {'Reaction outcome loss': 0.811391353850462, 'Total loss': 0.811391353850462}
2022-11-23 01:58:30,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:30,411 INFO:     Epoch: 25
2022-11-23 01:58:31,210 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8299328793178905, 'Total loss': 0.8299328793178905} | train loss {'Reaction outcome loss': 0.8106521449526962, 'Total loss': 0.8106521449526962}
2022-11-23 01:58:31,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:31,210 INFO:     Epoch: 26
2022-11-23 01:58:31,983 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8036767786199396, 'Total loss': 0.8036767786199396} | train loss {'Reaction outcome loss': 0.8106814836969181, 'Total loss': 0.8106814836969181}
2022-11-23 01:58:31,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:31,983 INFO:     Epoch: 27
2022-11-23 01:58:32,771 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8176029493862932, 'Total loss': 0.8176029493862932} | train loss {'Reaction outcome loss': 0.8091262448807152, 'Total loss': 0.8091262448807152}
2022-11-23 01:58:32,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:32,773 INFO:     Epoch: 28
2022-11-23 01:58:33,562 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7991036085242574, 'Total loss': 0.7991036085242574} | train loss {'Reaction outcome loss': 0.8105053012468377, 'Total loss': 0.8105053012468377}
2022-11-23 01:58:33,562 INFO:     Found new best model at epoch 28
2022-11-23 01:58:33,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:33,563 INFO:     Epoch: 29
2022-11-23 01:58:34,372 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8351106630130247, 'Total loss': 0.8351106630130247} | train loss {'Reaction outcome loss': 0.8128593817049143, 'Total loss': 0.8128593817049143}
2022-11-23 01:58:34,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:34,373 INFO:     Epoch: 30
2022-11-23 01:58:35,159 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8281340897083282, 'Total loss': 0.8281340897083282} | train loss {'Reaction outcome loss': 0.813748265164239, 'Total loss': 0.813748265164239}
2022-11-23 01:58:35,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:35,159 INFO:     Epoch: 31
2022-11-23 01:58:35,978 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8169711062853987, 'Total loss': 0.8169711062853987} | train loss {'Reaction outcome loss': 0.808810082990296, 'Total loss': 0.808810082990296}
2022-11-23 01:58:35,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:35,979 INFO:     Epoch: 32
2022-11-23 01:58:36,864 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8261504329063676, 'Total loss': 0.8261504329063676} | train loss {'Reaction outcome loss': 0.80922268166834, 'Total loss': 0.80922268166834}
2022-11-23 01:58:36,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:36,864 INFO:     Epoch: 33
2022-11-23 01:58:37,684 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7990031323649667, 'Total loss': 0.7990031323649667} | train loss {'Reaction outcome loss': 0.813669700646887, 'Total loss': 0.813669700646887}
2022-11-23 01:58:37,685 INFO:     Found new best model at epoch 33
2022-11-23 01:58:37,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:37,686 INFO:     Epoch: 34
2022-11-23 01:58:38,505 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7994490001689304, 'Total loss': 0.7994490001689304} | train loss {'Reaction outcome loss': 0.8139428552316159, 'Total loss': 0.8139428552316159}
2022-11-23 01:58:38,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:38,505 INFO:     Epoch: 35
2022-11-23 01:58:39,316 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8223453252152964, 'Total loss': 0.8223453252152964} | train loss {'Reaction outcome loss': 0.8110955295514087, 'Total loss': 0.8110955295514087}
2022-11-23 01:58:39,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:39,317 INFO:     Epoch: 36
2022-11-23 01:58:40,137 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8043531308119948, 'Total loss': 0.8043531308119948} | train loss {'Reaction outcome loss': 0.8125108462207171, 'Total loss': 0.8125108462207171}
2022-11-23 01:58:40,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:40,138 INFO:     Epoch: 37
2022-11-23 01:58:40,944 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8069158643484116, 'Total loss': 0.8069158643484116} | train loss {'Reaction outcome loss': 0.8133938273605035, 'Total loss': 0.8133938273605035}
2022-11-23 01:58:40,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:40,944 INFO:     Epoch: 38
2022-11-23 01:58:41,733 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8333834809335795, 'Total loss': 0.8333834809335795} | train loss {'Reaction outcome loss': 0.8085745632648468, 'Total loss': 0.8085745632648468}
2022-11-23 01:58:41,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:41,733 INFO:     Epoch: 39
2022-11-23 01:58:42,569 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8118419999426062, 'Total loss': 0.8118419999426062} | train loss {'Reaction outcome loss': 0.8121497210191221, 'Total loss': 0.8121497210191221}
2022-11-23 01:58:42,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:42,570 INFO:     Epoch: 40
2022-11-23 01:58:43,366 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8527056107466872, 'Total loss': 0.8527056107466872} | train loss {'Reaction outcome loss': 0.8096399220885063, 'Total loss': 0.8096399220885063}
2022-11-23 01:58:43,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:43,366 INFO:     Epoch: 41
2022-11-23 01:58:44,175 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8128881637345661, 'Total loss': 0.8128881637345661} | train loss {'Reaction outcome loss': 0.8125049491317905, 'Total loss': 0.8125049491317905}
2022-11-23 01:58:44,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:44,175 INFO:     Epoch: 42
2022-11-23 01:58:44,996 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8062261336229064, 'Total loss': 0.8062261336229064} | train loss {'Reaction outcome loss': 0.8130002799082775, 'Total loss': 0.8130002799082775}
2022-11-23 01:58:44,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:44,996 INFO:     Epoch: 43
2022-11-23 01:58:45,796 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8029110330072317, 'Total loss': 0.8029110330072317} | train loss {'Reaction outcome loss': 0.8094574688648691, 'Total loss': 0.8094574688648691}
2022-11-23 01:58:45,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:45,796 INFO:     Epoch: 44
2022-11-23 01:58:46,585 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7903975573453036, 'Total loss': 0.7903975573453036} | train loss {'Reaction outcome loss': 0.8065361116613661, 'Total loss': 0.8065361116613661}
2022-11-23 01:58:46,585 INFO:     Found new best model at epoch 44
2022-11-23 01:58:46,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:46,586 INFO:     Epoch: 45
2022-11-23 01:58:47,351 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8021669800985943, 'Total loss': 0.8021669800985943} | train loss {'Reaction outcome loss': 0.8092514967431828, 'Total loss': 0.8092514967431828}
2022-11-23 01:58:47,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:47,352 INFO:     Epoch: 46
2022-11-23 01:58:48,172 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8113036047328602, 'Total loss': 0.8113036047328602} | train loss {'Reaction outcome loss': 0.8100447966127979, 'Total loss': 0.8100447966127979}
2022-11-23 01:58:48,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:48,172 INFO:     Epoch: 47
2022-11-23 01:58:48,946 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8043227344751358, 'Total loss': 0.8043227344751358} | train loss {'Reaction outcome loss': 0.811427498228696, 'Total loss': 0.811427498228696}
2022-11-23 01:58:48,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:48,946 INFO:     Epoch: 48
2022-11-23 01:58:49,757 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8010139892047102, 'Total loss': 0.8010139892047102} | train loss {'Reaction outcome loss': 0.8117502020329845, 'Total loss': 0.8117502020329845}
2022-11-23 01:58:49,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:49,758 INFO:     Epoch: 49
2022-11-23 01:58:50,574 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7962052754380486, 'Total loss': 0.7962052754380486} | train loss {'Reaction outcome loss': 0.8086803267196733, 'Total loss': 0.8086803267196733}
2022-11-23 01:58:50,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:50,575 INFO:     Epoch: 50
2022-11-23 01:58:51,355 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.80894585698843, 'Total loss': 0.80894585698843} | train loss {'Reaction outcome loss': 0.8130701759640051, 'Total loss': 0.8130701759640051}
2022-11-23 01:58:51,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:51,356 INFO:     Epoch: 51
2022-11-23 01:58:52,111 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8286844139749353, 'Total loss': 0.8286844139749353} | train loss {'Reaction outcome loss': 0.8064923026123826, 'Total loss': 0.8064923026123826}
2022-11-23 01:58:52,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:52,111 INFO:     Epoch: 52
2022-11-23 01:58:52,933 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8056868314743042, 'Total loss': 0.8056868314743042} | train loss {'Reaction outcome loss': 0.807791778627707, 'Total loss': 0.807791778627707}
2022-11-23 01:58:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:52,933 INFO:     Epoch: 53
2022-11-23 01:58:53,695 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8009333339604464, 'Total loss': 0.8009333339604464} | train loss {'Reaction outcome loss': 0.809904938449665, 'Total loss': 0.809904938449665}
2022-11-23 01:58:53,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:53,695 INFO:     Epoch: 54
2022-11-23 01:58:54,522 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8220596543767236, 'Total loss': 0.8220596543767236} | train loss {'Reaction outcome loss': 0.8095009030128012, 'Total loss': 0.8095009030128012}
2022-11-23 01:58:54,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:54,522 INFO:     Epoch: 55
2022-11-23 01:58:55,316 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.821392918174917, 'Total loss': 0.821392918174917} | train loss {'Reaction outcome loss': 0.8102299350256823, 'Total loss': 0.8102299350256823}
2022-11-23 01:58:55,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:55,316 INFO:     Epoch: 56
2022-11-23 01:58:56,131 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8080215853723612, 'Total loss': 0.8080215853723612} | train loss {'Reaction outcome loss': 0.8101273309211342, 'Total loss': 0.8101273309211342}
2022-11-23 01:58:56,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:56,131 INFO:     Epoch: 57
2022-11-23 01:58:56,898 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8306149156256155, 'Total loss': 0.8306149156256155} | train loss {'Reaction outcome loss': 0.8115739242154725, 'Total loss': 0.8115739242154725}
2022-11-23 01:58:56,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:56,898 INFO:     Epoch: 58
2022-11-23 01:58:57,676 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8162479089065031, 'Total loss': 0.8162479089065031} | train loss {'Reaction outcome loss': 0.8084105794527092, 'Total loss': 0.8084105794527092}
2022-11-23 01:58:57,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:57,676 INFO:     Epoch: 59
2022-11-23 01:58:58,464 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7981850975616411, 'Total loss': 0.7981850975616411} | train loss {'Reaction outcome loss': 0.8078899094036647, 'Total loss': 0.8078899094036647}
2022-11-23 01:58:58,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:58,465 INFO:     Epoch: 60
2022-11-23 01:58:59,239 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8130471557378769, 'Total loss': 0.8130471557378769} | train loss {'Reaction outcome loss': 0.809113628158764, 'Total loss': 0.809113628158764}
2022-11-23 01:58:59,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:59,239 INFO:     Epoch: 61
2022-11-23 01:58:59,998 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7908858155662363, 'Total loss': 0.7908858155662363} | train loss {'Reaction outcome loss': 0.8103296889334309, 'Total loss': 0.8103296889334309}
2022-11-23 01:58:59,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:58:59,998 INFO:     Epoch: 62
2022-11-23 01:59:00,814 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8182162059979006, 'Total loss': 0.8182162059979006} | train loss {'Reaction outcome loss': 0.8062130783285414, 'Total loss': 0.8062130783285414}
2022-11-23 01:59:00,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:00,814 INFO:     Epoch: 63
2022-11-23 01:59:01,598 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8181684125553478, 'Total loss': 0.8181684125553478} | train loss {'Reaction outcome loss': 0.8130938495908465, 'Total loss': 0.8130938495908465}
2022-11-23 01:59:01,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:01,598 INFO:     Epoch: 64
2022-11-23 01:59:02,402 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8189343363046646, 'Total loss': 0.8189343363046646} | train loss {'Reaction outcome loss': 0.8088600737707955, 'Total loss': 0.8088600737707955}
2022-11-23 01:59:02,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:02,403 INFO:     Epoch: 65
2022-11-23 01:59:03,222 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8305963657119058, 'Total loss': 0.8305963657119058} | train loss {'Reaction outcome loss': 0.8065110589776721, 'Total loss': 0.8065110589776721}
2022-11-23 01:59:03,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:03,222 INFO:     Epoch: 66
2022-11-23 01:59:04,027 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8130711235783317, 'Total loss': 0.8130711235783317} | train loss {'Reaction outcome loss': 0.8128502157269691, 'Total loss': 0.8128502157269691}
2022-11-23 01:59:04,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:04,028 INFO:     Epoch: 67
2022-11-23 01:59:04,853 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7954356243664568, 'Total loss': 0.7954356243664568} | train loss {'Reaction outcome loss': 0.8131588342238446, 'Total loss': 0.8131588342238446}
2022-11-23 01:59:04,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:04,853 INFO:     Epoch: 68
2022-11-23 01:59:05,691 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8137020143595609, 'Total loss': 0.8137020143595609} | train loss {'Reaction outcome loss': 0.8130511479718344, 'Total loss': 0.8130511479718344}
2022-11-23 01:59:05,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:05,692 INFO:     Epoch: 69
2022-11-23 01:59:06,472 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8248010088096965, 'Total loss': 0.8248010088096965} | train loss {'Reaction outcome loss': 0.8146442826913327, 'Total loss': 0.8146442826913327}
2022-11-23 01:59:06,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:06,472 INFO:     Epoch: 70
2022-11-23 01:59:07,307 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8410906358198686, 'Total loss': 0.8410906358198686} | train loss {'Reaction outcome loss': 0.8079377698655031, 'Total loss': 0.8079377698655031}
2022-11-23 01:59:07,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:07,307 INFO:     Epoch: 71
2022-11-23 01:59:08,054 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8373641954226927, 'Total loss': 0.8373641954226927} | train loss {'Reaction outcome loss': 0.8116254226285584, 'Total loss': 0.8116254226285584}
2022-11-23 01:59:08,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:08,054 INFO:     Epoch: 72
2022-11-23 01:59:08,806 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7976465320045297, 'Total loss': 0.7976465320045297} | train loss {'Reaction outcome loss': 0.8082712920344606, 'Total loss': 0.8082712920344606}
2022-11-23 01:59:08,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:08,806 INFO:     Epoch: 73
2022-11-23 01:59:09,624 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7965678552334959, 'Total loss': 0.7965678552334959} | train loss {'Reaction outcome loss': 0.8123087108135223, 'Total loss': 0.8123087108135223}
2022-11-23 01:59:09,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:09,625 INFO:     Epoch: 74
2022-11-23 01:59:10,405 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7855138914151625, 'Total loss': 0.7855138914151625} | train loss {'Reaction outcome loss': 0.810329985253665, 'Total loss': 0.810329985253665}
2022-11-23 01:59:10,406 INFO:     Found new best model at epoch 74
2022-11-23 01:59:10,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:10,407 INFO:     Epoch: 75
2022-11-23 01:59:11,201 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8051079613241282, 'Total loss': 0.8051079613241282} | train loss {'Reaction outcome loss': 0.8149037935295883, 'Total loss': 0.8149037935295883}
2022-11-23 01:59:11,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:11,202 INFO:     Epoch: 76
2022-11-23 01:59:11,978 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8033206029371782, 'Total loss': 0.8033206029371782} | train loss {'Reaction outcome loss': 0.8078192348382911, 'Total loss': 0.8078192348382911}
2022-11-23 01:59:11,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:11,978 INFO:     Epoch: 77
2022-11-23 01:59:12,743 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8070530654354529, 'Total loss': 0.8070530654354529} | train loss {'Reaction outcome loss': 0.8130173934965718, 'Total loss': 0.8130173934965718}
2022-11-23 01:59:12,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:12,744 INFO:     Epoch: 78
2022-11-23 01:59:13,501 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8229239962317727, 'Total loss': 0.8229239962317727} | train loss {'Reaction outcome loss': 0.8111538463709306, 'Total loss': 0.8111538463709306}
2022-11-23 01:59:13,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:13,501 INFO:     Epoch: 79
2022-11-23 01:59:14,287 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8128660036758943, 'Total loss': 0.8128660036758943} | train loss {'Reaction outcome loss': 0.8051609334897022, 'Total loss': 0.8051609334897022}
2022-11-23 01:59:14,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:14,287 INFO:     Epoch: 80
2022-11-23 01:59:15,059 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8066553107716821, 'Total loss': 0.8066553107716821} | train loss {'Reaction outcome loss': 0.8145224115070031, 'Total loss': 0.8145224115070031}
2022-11-23 01:59:15,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:15,059 INFO:     Epoch: 81
2022-11-23 01:59:15,889 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8044355884194374, 'Total loss': 0.8044355884194374} | train loss {'Reaction outcome loss': 0.8105666318718268, 'Total loss': 0.8105666318718268}
2022-11-23 01:59:15,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:15,889 INFO:     Epoch: 82
2022-11-23 01:59:16,780 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8122342283075507, 'Total loss': 0.8122342283075507} | train loss {'Reaction outcome loss': 0.8084755076437581, 'Total loss': 0.8084755076437581}
2022-11-23 01:59:16,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:16,781 INFO:     Epoch: 83
2022-11-23 01:59:17,564 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7906362742862918, 'Total loss': 0.7906362742862918} | train loss {'Reaction outcome loss': 0.8075239072040635, 'Total loss': 0.8075239072040635}
2022-11-23 01:59:17,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:17,565 INFO:     Epoch: 84
2022-11-23 01:59:18,475 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8065179891207002, 'Total loss': 0.8065179891207002} | train loss {'Reaction outcome loss': 0.8098675466313654, 'Total loss': 0.8098675466313654}
2022-11-23 01:59:18,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:18,475 INFO:     Epoch: 85
2022-11-23 01:59:19,231 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8304605849764564, 'Total loss': 0.8304605849764564} | train loss {'Reaction outcome loss': 0.8151972847325462, 'Total loss': 0.8151972847325462}
2022-11-23 01:59:19,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:19,232 INFO:     Epoch: 86
2022-11-23 01:59:20,046 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8122637488625266, 'Total loss': 0.8122637488625266} | train loss {'Reaction outcome loss': 0.8106932249604439, 'Total loss': 0.8106932249604439}
2022-11-23 01:59:20,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:20,047 INFO:     Epoch: 87
2022-11-23 01:59:20,865 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7979625876654278, 'Total loss': 0.7979625876654278} | train loss {'Reaction outcome loss': 0.8115251418279141, 'Total loss': 0.8115251418279141}
2022-11-23 01:59:20,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:20,865 INFO:     Epoch: 88
2022-11-23 01:59:21,632 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8183357674967159, 'Total loss': 0.8183357674967159} | train loss {'Reaction outcome loss': 0.8133009537142151, 'Total loss': 0.8133009537142151}
2022-11-23 01:59:21,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:21,632 INFO:     Epoch: 89
2022-11-23 01:59:22,402 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8044317662715912, 'Total loss': 0.8044317662715912} | train loss {'Reaction outcome loss': 0.8074120464373608, 'Total loss': 0.8074120464373608}
2022-11-23 01:59:22,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:22,403 INFO:     Epoch: 90
2022-11-23 01:59:23,206 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8374842398545959, 'Total loss': 0.8374842398545959} | train loss {'Reaction outcome loss': 0.8116270842600842, 'Total loss': 0.8116270842600842}
2022-11-23 01:59:23,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:23,208 INFO:     Epoch: 91
2022-11-23 01:59:24,019 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8127165700901638, 'Total loss': 0.8127165700901638} | train loss {'Reaction outcome loss': 0.8132381809001066, 'Total loss': 0.8132381809001066}
2022-11-23 01:59:24,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:24,019 INFO:     Epoch: 92
2022-11-23 01:59:24,822 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8145134923132983, 'Total loss': 0.8145134923132983} | train loss {'Reaction outcome loss': 0.8127656806488426, 'Total loss': 0.8127656806488426}
2022-11-23 01:59:24,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:24,822 INFO:     Epoch: 93
2022-11-23 01:59:25,646 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8081256049600515, 'Total loss': 0.8081256049600515} | train loss {'Reaction outcome loss': 0.8107742768161151, 'Total loss': 0.8107742768161151}
2022-11-23 01:59:25,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:25,646 INFO:     Epoch: 94
2022-11-23 01:59:26,434 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.800640365278179, 'Total loss': 0.800640365278179} | train loss {'Reaction outcome loss': 0.8102815407879499, 'Total loss': 0.8102815407879499}
2022-11-23 01:59:26,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:26,435 INFO:     Epoch: 95
2022-11-23 01:59:27,189 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8149085654453798, 'Total loss': 0.8149085654453798} | train loss {'Reaction outcome loss': 0.8118886506070896, 'Total loss': 0.8118886506070896}
2022-11-23 01:59:27,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:27,189 INFO:     Epoch: 96
2022-11-23 01:59:27,978 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8189175386320461, 'Total loss': 0.8189175386320461} | train loss {'Reaction outcome loss': 0.8110372062848539, 'Total loss': 0.8110372062848539}
2022-11-23 01:59:27,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:27,979 INFO:     Epoch: 97
2022-11-23 01:59:28,786 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8122864419763739, 'Total loss': 0.8122864419763739} | train loss {'Reaction outcome loss': 0.8078110029502791, 'Total loss': 0.8078110029502791}
2022-11-23 01:59:28,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:28,787 INFO:     Epoch: 98
2022-11-23 01:59:29,609 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7900211767039516, 'Total loss': 0.7900211767039516} | train loss {'Reaction outcome loss': 0.814032673470828, 'Total loss': 0.814032673470828}
2022-11-23 01:59:29,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:29,609 INFO:     Epoch: 99
2022-11-23 01:59:30,418 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8030424890193072, 'Total loss': 0.8030424890193072} | train loss {'Reaction outcome loss': 0.8112757413971181, 'Total loss': 0.8112757413971181}
2022-11-23 01:59:30,419 INFO:     Best model found after epoch 75 of 100.
2022-11-23 01:59:30,419 INFO:   Done with stage: TRAINING
2022-11-23 01:59:30,419 INFO:   Starting stage: EVALUATION
2022-11-23 01:59:30,550 INFO:   Done with stage: EVALUATION
2022-11-23 01:59:30,550 INFO:   Leaving out SEQ value Fold_2
2022-11-23 01:59:30,563 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 01:59:30,563 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:59:31,228 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:59:31,228 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:59:31,300 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:59:31,300 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:59:31,300 INFO:     No hyperparam tuning for this model
2022-11-23 01:59:31,300 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:59:31,300 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:59:31,301 INFO:     None feature selector for col prot
2022-11-23 01:59:31,301 INFO:     None feature selector for col prot
2022-11-23 01:59:31,301 INFO:     None feature selector for col prot
2022-11-23 01:59:31,302 INFO:     None feature selector for col chem
2022-11-23 01:59:31,302 INFO:     None feature selector for col chem
2022-11-23 01:59:31,302 INFO:     None feature selector for col chem
2022-11-23 01:59:31,302 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:59:31,302 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:59:31,304 INFO:     Number of params in model 168571
2022-11-23 01:59:31,307 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:59:31,307 INFO:   Starting stage: TRAINING
2022-11-23 01:59:31,364 INFO:     Val loss before train {'Reaction outcome loss': 1.000649162503176, 'Total loss': 1.000649162503176}
2022-11-23 01:59:31,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:31,364 INFO:     Epoch: 0
2022-11-23 01:59:32,160 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.807421876247539, 'Total loss': 0.807421876247539} | train loss {'Reaction outcome loss': 0.8929589374876413, 'Total loss': 0.8929589374876413}
2022-11-23 01:59:32,160 INFO:     Found new best model at epoch 0
2022-11-23 01:59:32,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:32,161 INFO:     Epoch: 1
2022-11-23 01:59:32,975 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8215446583060331, 'Total loss': 0.8215446583060331} | train loss {'Reaction outcome loss': 0.8608649895816552, 'Total loss': 0.8608649895816552}
2022-11-23 01:59:32,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:32,975 INFO:     Epoch: 2
2022-11-23 01:59:33,744 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7917008781155874, 'Total loss': 0.7917008781155874} | train loss {'Reaction outcome loss': 0.8557927549862471, 'Total loss': 0.8557927549862471}
2022-11-23 01:59:33,744 INFO:     Found new best model at epoch 2
2022-11-23 01:59:33,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:33,745 INFO:     Epoch: 3
2022-11-23 01:59:34,524 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7982116695060286, 'Total loss': 0.7982116695060286} | train loss {'Reaction outcome loss': 0.8542123937704524, 'Total loss': 0.8542123937704524}
2022-11-23 01:59:34,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:34,524 INFO:     Epoch: 4
2022-11-23 01:59:35,298 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7945301733737768, 'Total loss': 0.7945301733737768} | train loss {'Reaction outcome loss': 0.84489151542304, 'Total loss': 0.84489151542304}
2022-11-23 01:59:35,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:35,299 INFO:     Epoch: 5
2022-11-23 01:59:36,060 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8304415178853412, 'Total loss': 0.8304415178853412} | train loss {'Reaction outcome loss': 0.8391693593537222, 'Total loss': 0.8391693593537222}
2022-11-23 01:59:36,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:36,060 INFO:     Epoch: 6
2022-11-23 01:59:36,847 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8231865541879521, 'Total loss': 0.8231865541879521} | train loss {'Reaction outcome loss': 0.8400543966009969, 'Total loss': 0.8400543966009969}
2022-11-23 01:59:36,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:36,847 INFO:     Epoch: 7
2022-11-23 01:59:37,664 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.790776715722195, 'Total loss': 0.790776715722195} | train loss {'Reaction outcome loss': 0.8381466163230724, 'Total loss': 0.8381466163230724}
2022-11-23 01:59:37,664 INFO:     Found new best model at epoch 7
2022-11-23 01:59:37,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:37,665 INFO:     Epoch: 8
2022-11-23 01:59:38,475 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8241760980251224, 'Total loss': 0.8241760980251224} | train loss {'Reaction outcome loss': 0.8303844993476008, 'Total loss': 0.8303844993476008}
2022-11-23 01:59:38,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:38,475 INFO:     Epoch: 9
2022-11-23 01:59:39,305 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7906016852966574, 'Total loss': 0.7906016852966574} | train loss {'Reaction outcome loss': 0.8345383315301332, 'Total loss': 0.8345383315301332}
2022-11-23 01:59:39,305 INFO:     Found new best model at epoch 9
2022-11-23 01:59:39,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:39,306 INFO:     Epoch: 10
2022-11-23 01:59:40,134 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8087985529456028, 'Total loss': 0.8087985529456028} | train loss {'Reaction outcome loss': 0.8338638042084506, 'Total loss': 0.8338638042084506}
2022-11-23 01:59:40,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:40,135 INFO:     Epoch: 11
2022-11-23 01:59:40,930 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8043657610582751, 'Total loss': 0.8043657610582751} | train loss {'Reaction outcome loss': 0.8321764626708187, 'Total loss': 0.8321764626708187}
2022-11-23 01:59:40,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:40,930 INFO:     Epoch: 12
2022-11-23 01:59:41,749 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7838621444480364, 'Total loss': 0.7838621444480364} | train loss {'Reaction outcome loss': 0.8339173533633107, 'Total loss': 0.8339173533633107}
2022-11-23 01:59:41,750 INFO:     Found new best model at epoch 12
2022-11-23 01:59:41,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:41,751 INFO:     Epoch: 13
2022-11-23 01:59:42,504 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7932962123737779, 'Total loss': 0.7932962123737779} | train loss {'Reaction outcome loss': 0.8304887307716198, 'Total loss': 0.8304887307716198}
2022-11-23 01:59:42,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:42,504 INFO:     Epoch: 14
2022-11-23 01:59:43,323 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7874979626300723, 'Total loss': 0.7874979626300723} | train loss {'Reaction outcome loss': 0.8254036414818685, 'Total loss': 0.8254036414818685}
2022-11-23 01:59:43,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:43,323 INFO:     Epoch: 15
2022-11-23 01:59:44,105 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7891064452570539, 'Total loss': 0.7891064452570539} | train loss {'Reaction outcome loss': 0.82666535736596, 'Total loss': 0.82666535736596}
2022-11-23 01:59:44,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:44,106 INFO:     Epoch: 16
2022-11-23 01:59:44,902 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7894719430180483, 'Total loss': 0.7894719430180483} | train loss {'Reaction outcome loss': 0.8278982329075454, 'Total loss': 0.8278982329075454}
2022-11-23 01:59:44,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:44,902 INFO:     Epoch: 17
2022-11-23 01:59:45,743 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7755731177884478, 'Total loss': 0.7755731177884478} | train loss {'Reaction outcome loss': 0.829286412381735, 'Total loss': 0.829286412381735}
2022-11-23 01:59:45,743 INFO:     Found new best model at epoch 17
2022-11-23 01:59:45,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:45,744 INFO:     Epoch: 18
2022-11-23 01:59:46,517 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7842239973156951, 'Total loss': 0.7842239973156951} | train loss {'Reaction outcome loss': 0.8242506531418347, 'Total loss': 0.8242506531418347}
2022-11-23 01:59:46,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:46,518 INFO:     Epoch: 19
2022-11-23 01:59:47,280 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7915738723998846, 'Total loss': 0.7915738723998846} | train loss {'Reaction outcome loss': 0.8265646493337193, 'Total loss': 0.8265646493337193}
2022-11-23 01:59:47,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:47,281 INFO:     Epoch: 20
2022-11-23 01:59:48,063 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7821370993935784, 'Total loss': 0.7821370993935784} | train loss {'Reaction outcome loss': 0.8308289278237546, 'Total loss': 0.8308289278237546}
2022-11-23 01:59:48,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:48,063 INFO:     Epoch: 21
2022-11-23 01:59:48,816 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7889099800309469, 'Total loss': 0.7889099800309469} | train loss {'Reaction outcome loss': 0.8204726283667517, 'Total loss': 0.8204726283667517}
2022-11-23 01:59:48,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:48,816 INFO:     Epoch: 22
2022-11-23 01:59:49,578 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8118254029473593, 'Total loss': 0.8118254029473593} | train loss {'Reaction outcome loss': 0.8281818506170492, 'Total loss': 0.8281818506170492}
2022-11-23 01:59:49,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:49,578 INFO:     Epoch: 23
2022-11-23 01:59:50,354 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.791613357011662, 'Total loss': 0.791613357011662} | train loss {'Reaction outcome loss': 0.824197102399146, 'Total loss': 0.824197102399146}
2022-11-23 01:59:50,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:50,355 INFO:     Epoch: 24
2022-11-23 01:59:51,140 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7823543777299482, 'Total loss': 0.7823543777299482} | train loss {'Reaction outcome loss': 0.8224956939210657, 'Total loss': 0.8224956939210657}
2022-11-23 01:59:51,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:51,140 INFO:     Epoch: 25
2022-11-23 01:59:51,937 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7812462532243063, 'Total loss': 0.7812462532243063} | train loss {'Reaction outcome loss': 0.8184832253905593, 'Total loss': 0.8184832253905593}
2022-11-23 01:59:51,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:51,937 INFO:     Epoch: 26
2022-11-23 01:59:52,746 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7965795051219852, 'Total loss': 0.7965795051219852} | train loss {'Reaction outcome loss': 0.8215089959443592, 'Total loss': 0.8215089959443592}
2022-11-23 01:59:52,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:52,747 INFO:     Epoch: 27
2022-11-23 01:59:53,535 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.782348383997762, 'Total loss': 0.782348383997762} | train loss {'Reaction outcome loss': 0.8213357539450536, 'Total loss': 0.8213357539450536}
2022-11-23 01:59:53,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:53,535 INFO:     Epoch: 28
2022-11-23 01:59:54,335 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7947904724021291, 'Total loss': 0.7947904724021291} | train loss {'Reaction outcome loss': 0.8226532674715167, 'Total loss': 0.8226532674715167}
2022-11-23 01:59:54,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:54,336 INFO:     Epoch: 29
2022-11-23 01:59:55,108 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7839751479237579, 'Total loss': 0.7839751479237579} | train loss {'Reaction outcome loss': 0.8210596554592008, 'Total loss': 0.8210596554592008}
2022-11-23 01:59:55,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:55,109 INFO:     Epoch: 30
2022-11-23 01:59:55,890 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7708160509896833, 'Total loss': 0.7708160509896833} | train loss {'Reaction outcome loss': 0.818289047748339, 'Total loss': 0.818289047748339}
2022-11-23 01:59:55,891 INFO:     Found new best model at epoch 30
2022-11-23 01:59:55,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:55,891 INFO:     Epoch: 31
2022-11-23 01:59:56,698 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7768757634384688, 'Total loss': 0.7768757634384688} | train loss {'Reaction outcome loss': 0.8233678851459847, 'Total loss': 0.8233678851459847}
2022-11-23 01:59:56,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:56,698 INFO:     Epoch: 32
2022-11-23 01:59:57,495 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7787961592507917, 'Total loss': 0.7787961592507917} | train loss {'Reaction outcome loss': 0.8192237586271568, 'Total loss': 0.8192237586271568}
2022-11-23 01:59:57,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:57,495 INFO:     Epoch: 33
2022-11-23 01:59:58,330 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7932418979877649, 'Total loss': 0.7932418979877649} | train loss {'Reaction outcome loss': 0.8174073086654554, 'Total loss': 0.8174073086654554}
2022-11-23 01:59:58,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:58,331 INFO:     Epoch: 34
2022-11-23 01:59:59,123 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7861308143582455, 'Total loss': 0.7861308143582455} | train loss {'Reaction outcome loss': 0.8161682206831995, 'Total loss': 0.8161682206831995}
2022-11-23 01:59:59,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:59,123 INFO:     Epoch: 35
2022-11-23 01:59:59,923 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7891627051109491, 'Total loss': 0.7891627051109491} | train loss {'Reaction outcome loss': 0.8193634702045409, 'Total loss': 0.8193634702045409}
2022-11-23 01:59:59,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:59:59,924 INFO:     Epoch: 36
2022-11-23 02:00:00,749 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7845676707666974, 'Total loss': 0.7845676707666974} | train loss {'Reaction outcome loss': 0.8165624892858209, 'Total loss': 0.8165624892858209}
2022-11-23 02:00:00,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:00,749 INFO:     Epoch: 37
2022-11-23 02:00:01,548 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7944988261821658, 'Total loss': 0.7944988261821658} | train loss {'Reaction outcome loss': 0.8253683176685552, 'Total loss': 0.8253683176685552}
2022-11-23 02:00:01,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:01,548 INFO:     Epoch: 38
2022-11-23 02:00:02,326 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7866557025632193, 'Total loss': 0.7866557025632193} | train loss {'Reaction outcome loss': 0.8149810994013411, 'Total loss': 0.8149810994013411}
2022-11-23 02:00:02,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:02,326 INFO:     Epoch: 39
2022-11-23 02:00:03,102 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7737393822780875, 'Total loss': 0.7737393822780875} | train loss {'Reaction outcome loss': 0.8160919217301197, 'Total loss': 0.8160919217301197}
2022-11-23 02:00:03,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:03,103 INFO:     Epoch: 40
2022-11-23 02:00:03,910 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7876334204230198, 'Total loss': 0.7876334204230198} | train loss {'Reaction outcome loss': 0.8206937888362369, 'Total loss': 0.8206937888362369}
2022-11-23 02:00:03,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:03,910 INFO:     Epoch: 41
2022-11-23 02:00:04,695 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7833890478278316, 'Total loss': 0.7833890478278316} | train loss {'Reaction outcome loss': 0.813451350834526, 'Total loss': 0.813451350834526}
2022-11-23 02:00:04,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:04,696 INFO:     Epoch: 42
2022-11-23 02:00:05,529 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7699618159338485, 'Total loss': 0.7699618159338485} | train loss {'Reaction outcome loss': 0.8146857974714921, 'Total loss': 0.8146857974714921}
2022-11-23 02:00:05,529 INFO:     Found new best model at epoch 42
2022-11-23 02:00:05,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:05,530 INFO:     Epoch: 43
2022-11-23 02:00:06,354 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7688121844169705, 'Total loss': 0.7688121844169705} | train loss {'Reaction outcome loss': 0.8151885760856457, 'Total loss': 0.8151885760856457}
2022-11-23 02:00:06,356 INFO:     Found new best model at epoch 43
2022-11-23 02:00:06,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:06,357 INFO:     Epoch: 44
2022-11-23 02:00:07,115 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7791163443132888, 'Total loss': 0.7791163443132888} | train loss {'Reaction outcome loss': 0.8078716222624309, 'Total loss': 0.8078716222624309}
2022-11-23 02:00:07,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:07,115 INFO:     Epoch: 45
2022-11-23 02:00:07,932 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.775756087414054, 'Total loss': 0.775756087414054} | train loss {'Reaction outcome loss': 0.8116279940624707, 'Total loss': 0.8116279940624707}
2022-11-23 02:00:07,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:07,932 INFO:     Epoch: 46
2022-11-23 02:00:08,750 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7697281102801479, 'Total loss': 0.7697281102801479} | train loss {'Reaction outcome loss': 0.8101578218037965, 'Total loss': 0.8101578218037965}
2022-11-23 02:00:08,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:08,750 INFO:     Epoch: 47
2022-11-23 02:00:09,508 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7804443434227345, 'Total loss': 0.7804443434227345} | train loss {'Reaction outcome loss': 0.8075606545708218, 'Total loss': 0.8075606545708218}
2022-11-23 02:00:09,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:09,508 INFO:     Epoch: 48
2022-11-23 02:00:10,332 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7608876408532609, 'Total loss': 0.7608876408532609} | train loss {'Reaction outcome loss': 0.8066343080069198, 'Total loss': 0.8066343080069198}
2022-11-23 02:00:10,332 INFO:     Found new best model at epoch 48
2022-11-23 02:00:10,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:10,333 INFO:     Epoch: 49
2022-11-23 02:00:11,111 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7738883654738582, 'Total loss': 0.7738883654738582} | train loss {'Reaction outcome loss': 0.8038939845855119, 'Total loss': 0.8038939845855119}
2022-11-23 02:00:11,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:11,111 INFO:     Epoch: 50
2022-11-23 02:00:11,889 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7953095900457959, 'Total loss': 0.7953095900457959} | train loss {'Reaction outcome loss': 0.8104608821087196, 'Total loss': 0.8104608821087196}
2022-11-23 02:00:11,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:11,889 INFO:     Epoch: 51
2022-11-23 02:00:12,667 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7557488056116326, 'Total loss': 0.7557488056116326} | train loss {'Reaction outcome loss': 0.8017376285107409, 'Total loss': 0.8017376285107409}
2022-11-23 02:00:12,668 INFO:     Found new best model at epoch 51
2022-11-23 02:00:12,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:12,668 INFO:     Epoch: 52
2022-11-23 02:00:13,451 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7767108013463575, 'Total loss': 0.7767108013463575} | train loss {'Reaction outcome loss': 0.8012925811478349, 'Total loss': 0.8012925811478349}
2022-11-23 02:00:13,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:13,451 INFO:     Epoch: 53
2022-11-23 02:00:14,219 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7645427141078683, 'Total loss': 0.7645427141078683} | train loss {'Reaction outcome loss': 0.8048196775747127, 'Total loss': 0.8048196775747127}
2022-11-23 02:00:14,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:14,219 INFO:     Epoch: 54
2022-11-23 02:00:14,968 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7514757902123207, 'Total loss': 0.7514757902123207} | train loss {'Reaction outcome loss': 0.8002579858312842, 'Total loss': 0.8002579858312842}
2022-11-23 02:00:14,968 INFO:     Found new best model at epoch 54
2022-11-23 02:00:14,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:14,969 INFO:     Epoch: 55
2022-11-23 02:00:15,761 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7646606315013974, 'Total loss': 0.7646606315013974} | train loss {'Reaction outcome loss': 0.7911353150352103, 'Total loss': 0.7911353150352103}
2022-11-23 02:00:15,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:15,762 INFO:     Epoch: 56
2022-11-23 02:00:16,547 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8135785945626193, 'Total loss': 0.8135785945626193} | train loss {'Reaction outcome loss': 0.7940507836517741, 'Total loss': 0.7940507836517741}
2022-11-23 02:00:16,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:16,548 INFO:     Epoch: 57
2022-11-23 02:00:17,352 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7479081930116166, 'Total loss': 0.7479081930116166} | train loss {'Reaction outcome loss': 0.7885769827932608, 'Total loss': 0.7885769827932608}
2022-11-23 02:00:17,352 INFO:     Found new best model at epoch 57
2022-11-23 02:00:17,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:17,353 INFO:     Epoch: 58
2022-11-23 02:00:18,180 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7698610341826151, 'Total loss': 0.7698610341826151} | train loss {'Reaction outcome loss': 0.7871735265753308, 'Total loss': 0.7871735265753308}
2022-11-23 02:00:18,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:18,180 INFO:     Epoch: 59
2022-11-23 02:00:18,940 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7825296250886695, 'Total loss': 0.7825296250886695} | train loss {'Reaction outcome loss': 0.7942572383851302, 'Total loss': 0.7942572383851302}
2022-11-23 02:00:18,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:18,941 INFO:     Epoch: 60
2022-11-23 02:00:19,702 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7646009159642596, 'Total loss': 0.7646009159642596} | train loss {'Reaction outcome loss': 0.7785462259513433, 'Total loss': 0.7785462259513433}
2022-11-23 02:00:19,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:19,702 INFO:     Epoch: 61
2022-11-23 02:00:20,507 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7719593332257382, 'Total loss': 0.7719593332257382} | train loss {'Reaction outcome loss': 0.7733004915176845, 'Total loss': 0.7733004915176845}
2022-11-23 02:00:20,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:20,507 INFO:     Epoch: 62
2022-11-23 02:00:21,316 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7451539566350538, 'Total loss': 0.7451539566350538} | train loss {'Reaction outcome loss': 0.7714328290131248, 'Total loss': 0.7714328290131248}
2022-11-23 02:00:21,316 INFO:     Found new best model at epoch 62
2022-11-23 02:00:21,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:21,317 INFO:     Epoch: 63
2022-11-23 02:00:22,122 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7683072097079698, 'Total loss': 0.7683072097079698} | train loss {'Reaction outcome loss': 0.7621773795270529, 'Total loss': 0.7621773795270529}
2022-11-23 02:00:22,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:22,122 INFO:     Epoch: 64
2022-11-23 02:00:22,899 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7295218227907668, 'Total loss': 0.7295218227907668} | train loss {'Reaction outcome loss': 0.7537899750177978, 'Total loss': 0.7537899750177978}
2022-11-23 02:00:22,899 INFO:     Found new best model at epoch 64
2022-11-23 02:00:22,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:22,900 INFO:     Epoch: 65
2022-11-23 02:00:23,836 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7280426240244577, 'Total loss': 0.7280426240244577} | train loss {'Reaction outcome loss': 0.7441113702342158, 'Total loss': 0.7441113702342158}
2022-11-23 02:00:23,836 INFO:     Found new best model at epoch 65
2022-11-23 02:00:23,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:23,836 INFO:     Epoch: 66
2022-11-23 02:00:24,634 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.6980059493419736, 'Total loss': 0.6980059493419736} | train loss {'Reaction outcome loss': 0.7322872250539357, 'Total loss': 0.7322872250539357}
2022-11-23 02:00:24,634 INFO:     Found new best model at epoch 66
2022-11-23 02:00:24,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:24,635 INFO:     Epoch: 67
2022-11-23 02:00:25,443 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.677336183398269, 'Total loss': 0.677336183398269} | train loss {'Reaction outcome loss': 0.7137802229797254, 'Total loss': 0.7137802229797254}
2022-11-23 02:00:25,444 INFO:     Found new best model at epoch 67
2022-11-23 02:00:25,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:25,445 INFO:     Epoch: 68
2022-11-23 02:00:26,277 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.744227338668912, 'Total loss': 0.744227338668912} | train loss {'Reaction outcome loss': 0.7077870653545271, 'Total loss': 0.7077870653545271}
2022-11-23 02:00:26,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:26,277 INFO:     Epoch: 69
2022-11-23 02:00:27,088 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.6626469215681386, 'Total loss': 0.6626469215681386} | train loss {'Reaction outcome loss': 0.6840816280636631, 'Total loss': 0.6840816280636631}
2022-11-23 02:00:27,088 INFO:     Found new best model at epoch 69
2022-11-23 02:00:27,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:27,089 INFO:     Epoch: 70
2022-11-23 02:00:27,870 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.6177731398926225, 'Total loss': 0.6177731398926225} | train loss {'Reaction outcome loss': 0.6565117049412649, 'Total loss': 0.6565117049412649}
2022-11-23 02:00:27,870 INFO:     Found new best model at epoch 70
2022-11-23 02:00:27,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:27,871 INFO:     Epoch: 71
2022-11-23 02:00:28,677 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6059109804242157, 'Total loss': 0.6059109804242157} | train loss {'Reaction outcome loss': 0.6467061891052567, 'Total loss': 0.6467061891052567}
2022-11-23 02:00:28,678 INFO:     Found new best model at epoch 71
2022-11-23 02:00:28,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:28,678 INFO:     Epoch: 72
2022-11-23 02:00:29,479 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6433751340522322, 'Total loss': 0.6433751340522322} | train loss {'Reaction outcome loss': 0.6324549741188034, 'Total loss': 0.6324549741188034}
2022-11-23 02:00:29,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:29,479 INFO:     Epoch: 73
2022-11-23 02:00:30,282 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7280186851357304, 'Total loss': 0.7280186851357304} | train loss {'Reaction outcome loss': 0.6265303739270226, 'Total loss': 0.6265303739270226}
2022-11-23 02:00:30,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:30,282 INFO:     Epoch: 74
2022-11-23 02:00:31,117 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5937281521253808, 'Total loss': 0.5937281521253808} | train loss {'Reaction outcome loss': 0.607785695156113, 'Total loss': 0.607785695156113}
2022-11-23 02:00:31,118 INFO:     Found new best model at epoch 74
2022-11-23 02:00:31,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:31,118 INFO:     Epoch: 75
2022-11-23 02:00:31,893 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5954322821872179, 'Total loss': 0.5954322821872179} | train loss {'Reaction outcome loss': 0.6056205787863888, 'Total loss': 0.6056205787863888}
2022-11-23 02:00:31,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:31,893 INFO:     Epoch: 76
2022-11-23 02:00:32,700 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5994046018567196, 'Total loss': 0.5994046018567196} | train loss {'Reaction outcome loss': 0.6077355093887595, 'Total loss': 0.6077355093887595}
2022-11-23 02:00:32,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:32,700 INFO:     Epoch: 77
2022-11-23 02:00:33,503 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5521703372861064, 'Total loss': 0.5521703372861064} | train loss {'Reaction outcome loss': 0.5858277374359427, 'Total loss': 0.5858277374359427}
2022-11-23 02:00:33,504 INFO:     Found new best model at epoch 77
2022-11-23 02:00:33,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:33,504 INFO:     Epoch: 78
2022-11-23 02:00:34,314 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5530096763788268, 'Total loss': 0.5530096763788268} | train loss {'Reaction outcome loss': 0.5998245204081301, 'Total loss': 0.5998245204081301}
2022-11-23 02:00:34,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:34,314 INFO:     Epoch: 79
2022-11-23 02:00:35,112 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6210131465002547, 'Total loss': 0.6210131465002547} | train loss {'Reaction outcome loss': 0.5886586926511077, 'Total loss': 0.5886586926511077}
2022-11-23 02:00:35,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:35,113 INFO:     Epoch: 80
2022-11-23 02:00:35,920 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5706364917893743, 'Total loss': 0.5706364917893743} | train loss {'Reaction outcome loss': 0.5887933777736836, 'Total loss': 0.5887933777736836}
2022-11-23 02:00:35,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:35,920 INFO:     Epoch: 81
2022-11-23 02:00:36,705 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6091025818225949, 'Total loss': 0.6091025818225949} | train loss {'Reaction outcome loss': 0.5752657162117176, 'Total loss': 0.5752657162117176}
2022-11-23 02:00:36,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:36,705 INFO:     Epoch: 82
2022-11-23 02:00:37,506 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.585783051196919, 'Total loss': 0.585783051196919} | train loss {'Reaction outcome loss': 0.5851486813215936, 'Total loss': 0.5851486813215936}
2022-11-23 02:00:37,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:37,508 INFO:     Epoch: 83
2022-11-23 02:00:38,350 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5434465616248375, 'Total loss': 0.5434465616248375} | train loss {'Reaction outcome loss': 0.5667553258235337, 'Total loss': 0.5667553258235337}
2022-11-23 02:00:38,351 INFO:     Found new best model at epoch 83
2022-11-23 02:00:38,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:38,352 INFO:     Epoch: 84
2022-11-23 02:00:39,162 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5351308206486147, 'Total loss': 0.5351308206486147} | train loss {'Reaction outcome loss': 0.5853537740033181, 'Total loss': 0.5853537740033181}
2022-11-23 02:00:39,162 INFO:     Found new best model at epoch 84
2022-11-23 02:00:39,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:39,164 INFO:     Epoch: 85
2022-11-23 02:00:39,975 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5364595239245614, 'Total loss': 0.5364595239245614} | train loss {'Reaction outcome loss': 0.5610586486634661, 'Total loss': 0.5610586486634661}
2022-11-23 02:00:39,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:39,976 INFO:     Epoch: 86
2022-11-23 02:00:40,799 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.593889674128488, 'Total loss': 0.593889674128488} | train loss {'Reaction outcome loss': 0.582236148233785, 'Total loss': 0.582236148233785}
2022-11-23 02:00:40,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:40,799 INFO:     Epoch: 87
2022-11-23 02:00:41,587 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5757725370484729, 'Total loss': 0.5757725370484729} | train loss {'Reaction outcome loss': 0.5716744167272185, 'Total loss': 0.5716744167272185}
2022-11-23 02:00:41,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:41,587 INFO:     Epoch: 88
2022-11-23 02:00:42,361 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5601749087488929, 'Total loss': 0.5601749087488929} | train loss {'Reaction outcome loss': 0.5867138898885641, 'Total loss': 0.5867138898885641}
2022-11-23 02:00:42,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:42,361 INFO:     Epoch: 89
2022-11-23 02:00:43,165 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.553628025013347, 'Total loss': 0.553628025013347} | train loss {'Reaction outcome loss': 0.5783486250849044, 'Total loss': 0.5783486250849044}
2022-11-23 02:00:43,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:43,166 INFO:     Epoch: 90
2022-11-23 02:00:44,027 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5486686700998351, 'Total loss': 0.5486686700998351} | train loss {'Reaction outcome loss': 0.5703652581719102, 'Total loss': 0.5703652581719102}
2022-11-23 02:00:44,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:44,028 INFO:     Epoch: 91
2022-11-23 02:00:44,819 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5432690735473189, 'Total loss': 0.5432690735473189} | train loss {'Reaction outcome loss': 0.5749444312980918, 'Total loss': 0.5749444312980918}
2022-11-23 02:00:44,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:44,819 INFO:     Epoch: 92
2022-11-23 02:00:45,620 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5259341119333755, 'Total loss': 0.5259341119333755} | train loss {'Reaction outcome loss': 0.5750591776287947, 'Total loss': 0.5750591776287947}
2022-11-23 02:00:45,620 INFO:     Found new best model at epoch 92
2022-11-23 02:00:45,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:45,620 INFO:     Epoch: 93
2022-11-23 02:00:46,399 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5486332198908163, 'Total loss': 0.5486332198908163} | train loss {'Reaction outcome loss': 0.5920096690781781, 'Total loss': 0.5920096690781781}
2022-11-23 02:00:46,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:46,400 INFO:     Epoch: 94
2022-11-23 02:00:47,146 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5740196680606797, 'Total loss': 0.5740196680606797} | train loss {'Reaction outcome loss': 0.58117665869535, 'Total loss': 0.58117665869535}
2022-11-23 02:00:47,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:47,147 INFO:     Epoch: 95
2022-11-23 02:00:47,963 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5619963781778202, 'Total loss': 0.5619963781778202} | train loss {'Reaction outcome loss': 0.5746701235165361, 'Total loss': 0.5746701235165361}
2022-11-23 02:00:47,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:47,963 INFO:     Epoch: 96
2022-11-23 02:00:48,717 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5536327511072159, 'Total loss': 0.5536327511072159} | train loss {'Reaction outcome loss': 0.578577996399559, 'Total loss': 0.578577996399559}
2022-11-23 02:00:48,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:48,717 INFO:     Epoch: 97
2022-11-23 02:00:49,528 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5331314559592757, 'Total loss': 0.5331314559592757} | train loss {'Reaction outcome loss': 0.5733465786840095, 'Total loss': 0.5733465786840095}
2022-11-23 02:00:49,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:49,529 INFO:     Epoch: 98
2022-11-23 02:00:50,318 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5405479572540106, 'Total loss': 0.5405479572540106} | train loss {'Reaction outcome loss': 0.5853413589543006, 'Total loss': 0.5853413589543006}
2022-11-23 02:00:50,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:50,319 INFO:     Epoch: 99
2022-11-23 02:00:51,135 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.559889356064242, 'Total loss': 0.559889356064242} | train loss {'Reaction outcome loss': 0.5695921121562113, 'Total loss': 0.5695921121562113}
2022-11-23 02:00:51,135 INFO:     Best model found after epoch 93 of 100.
2022-11-23 02:00:51,135 INFO:   Done with stage: TRAINING
2022-11-23 02:00:51,135 INFO:   Starting stage: EVALUATION
2022-11-23 02:00:51,271 INFO:   Done with stage: EVALUATION
2022-11-23 02:00:51,271 INFO:   Leaving out SEQ value Fold_3
2022-11-23 02:00:51,284 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 02:00:51,284 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:00:51,950 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:00:51,950 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:00:52,022 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:00:52,023 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:00:52,023 INFO:     No hyperparam tuning for this model
2022-11-23 02:00:52,023 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:00:52,023 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:00:52,024 INFO:     None feature selector for col prot
2022-11-23 02:00:52,024 INFO:     None feature selector for col prot
2022-11-23 02:00:52,024 INFO:     None feature selector for col prot
2022-11-23 02:00:52,025 INFO:     None feature selector for col chem
2022-11-23 02:00:52,025 INFO:     None feature selector for col chem
2022-11-23 02:00:52,025 INFO:     None feature selector for col chem
2022-11-23 02:00:52,025 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:00:52,025 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:00:52,026 INFO:     Number of params in model 168571
2022-11-23 02:00:52,030 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:00:52,030 INFO:   Starting stage: TRAINING
2022-11-23 02:00:52,087 INFO:     Val loss before train {'Reaction outcome loss': 0.9986220279405283, 'Total loss': 0.9986220279405283}
2022-11-23 02:00:52,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:52,087 INFO:     Epoch: 0
2022-11-23 02:00:52,884 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8350003403286601, 'Total loss': 0.8350003403286601} | train loss {'Reaction outcome loss': 0.8746247739821184, 'Total loss': 0.8746247739821184}
2022-11-23 02:00:52,884 INFO:     Found new best model at epoch 0
2022-11-23 02:00:52,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:52,885 INFO:     Epoch: 1
2022-11-23 02:00:53,666 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8112144789030385, 'Total loss': 0.8112144789030385} | train loss {'Reaction outcome loss': 0.8479310733373048, 'Total loss': 0.8479310733373048}
2022-11-23 02:00:53,666 INFO:     Found new best model at epoch 1
2022-11-23 02:00:53,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:53,667 INFO:     Epoch: 2
2022-11-23 02:00:54,487 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.805630880732869, 'Total loss': 0.805630880732869} | train loss {'Reaction outcome loss': 0.8286923188410822, 'Total loss': 0.8286923188410822}
2022-11-23 02:00:54,487 INFO:     Found new best model at epoch 2
2022-11-23 02:00:54,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:54,488 INFO:     Epoch: 3
2022-11-23 02:00:55,284 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7982677810413893, 'Total loss': 0.7982677810413893} | train loss {'Reaction outcome loss': 0.8255107579905478, 'Total loss': 0.8255107579905478}
2022-11-23 02:00:55,284 INFO:     Found new best model at epoch 3
2022-11-23 02:00:55,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:55,285 INFO:     Epoch: 4
2022-11-23 02:00:56,091 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.798580872458081, 'Total loss': 0.798580872458081} | train loss {'Reaction outcome loss': 0.8211308191912096, 'Total loss': 0.8211308191912096}
2022-11-23 02:00:56,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:56,092 INFO:     Epoch: 5
2022-11-23 02:00:56,897 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7896535063898841, 'Total loss': 0.7896535063898841} | train loss {'Reaction outcome loss': 0.8238176053664723, 'Total loss': 0.8238176053664723}
2022-11-23 02:00:56,898 INFO:     Found new best model at epoch 5
2022-11-23 02:00:56,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:56,898 INFO:     Epoch: 6
2022-11-23 02:00:57,695 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8110351666461589, 'Total loss': 0.8110351666461589} | train loss {'Reaction outcome loss': 0.8155411641861572, 'Total loss': 0.8155411641861572}
2022-11-23 02:00:57,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:57,695 INFO:     Epoch: 7
2022-11-23 02:00:58,494 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7806497826132663, 'Total loss': 0.7806497826132663} | train loss {'Reaction outcome loss': 0.8135594737822892, 'Total loss': 0.8135594737822892}
2022-11-23 02:00:58,495 INFO:     Found new best model at epoch 7
2022-11-23 02:00:58,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:58,496 INFO:     Epoch: 8
2022-11-23 02:00:59,287 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7980364831381066, 'Total loss': 0.7980364831381066} | train loss {'Reaction outcome loss': 0.815391192426447, 'Total loss': 0.815391192426447}
2022-11-23 02:00:59,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:00:59,287 INFO:     Epoch: 9
2022-11-23 02:01:00,070 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7803557847821435, 'Total loss': 0.7803557847821435} | train loss {'Reaction outcome loss': 0.8157378133447444, 'Total loss': 0.8157378133447444}
2022-11-23 02:01:00,070 INFO:     Found new best model at epoch 9
2022-11-23 02:01:00,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:00,071 INFO:     Epoch: 10
2022-11-23 02:01:00,881 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7838161109491836, 'Total loss': 0.7838161109491836} | train loss {'Reaction outcome loss': 0.8130852774274154, 'Total loss': 0.8130852774274154}
2022-11-23 02:01:00,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:00,881 INFO:     Epoch: 11
2022-11-23 02:01:01,740 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7807433480440185, 'Total loss': 0.7807433480440185} | train loss {'Reaction outcome loss': 0.8179773226624629, 'Total loss': 0.8179773226624629}
2022-11-23 02:01:01,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:01,740 INFO:     Epoch: 12
2022-11-23 02:01:02,583 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7786135832930721, 'Total loss': 0.7786135832930721} | train loss {'Reaction outcome loss': 0.8108131147798945, 'Total loss': 0.8108131147798945}
2022-11-23 02:01:02,583 INFO:     Found new best model at epoch 12
2022-11-23 02:01:02,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:02,584 INFO:     Epoch: 13
2022-11-23 02:01:03,425 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7844829094964404, 'Total loss': 0.7844829094964404} | train loss {'Reaction outcome loss': 0.8151828901933842, 'Total loss': 0.8151828901933842}
2022-11-23 02:01:03,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:03,425 INFO:     Epoch: 14
2022-11-23 02:01:04,251 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7871105275874914, 'Total loss': 0.7871105275874914} | train loss {'Reaction outcome loss': 0.814520147125252, 'Total loss': 0.814520147125252}
2022-11-23 02:01:04,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:04,251 INFO:     Epoch: 15
2022-11-23 02:01:05,044 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7759263342203095, 'Total loss': 0.7759263342203095} | train loss {'Reaction outcome loss': 0.8130462685080825, 'Total loss': 0.8130462685080825}
2022-11-23 02:01:05,044 INFO:     Found new best model at epoch 15
2022-11-23 02:01:05,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:05,045 INFO:     Epoch: 16
2022-11-23 02:01:05,834 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7806376204934231, 'Total loss': 0.7806376204934231} | train loss {'Reaction outcome loss': 0.8120811115034291, 'Total loss': 0.8120811115034291}
2022-11-23 02:01:05,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:05,834 INFO:     Epoch: 17
2022-11-23 02:01:06,613 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7955192410668661, 'Total loss': 0.7955192410668661} | train loss {'Reaction outcome loss': 0.8128796416472216, 'Total loss': 0.8128796416472216}
2022-11-23 02:01:06,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:06,614 INFO:     Epoch: 18
2022-11-23 02:01:07,388 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8370717403500579, 'Total loss': 0.8370717403500579} | train loss {'Reaction outcome loss': 0.8151800435830335, 'Total loss': 0.8151800435830335}
2022-11-23 02:01:07,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:07,388 INFO:     Epoch: 19
2022-11-23 02:01:08,193 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7841689240100772, 'Total loss': 0.7841689240100772} | train loss {'Reaction outcome loss': 0.8144285432139381, 'Total loss': 0.8144285432139381}
2022-11-23 02:01:08,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:08,194 INFO:     Epoch: 20
2022-11-23 02:01:08,996 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7844341397285461, 'Total loss': 0.7844341397285461} | train loss {'Reaction outcome loss': 0.8110316934399917, 'Total loss': 0.8110316934399917}
2022-11-23 02:01:08,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:08,996 INFO:     Epoch: 21
2022-11-23 02:01:09,791 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7935884220655575, 'Total loss': 0.7935884220655575} | train loss {'Reaction outcome loss': 0.8069296567166437, 'Total loss': 0.8069296567166437}
2022-11-23 02:01:09,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:09,791 INFO:     Epoch: 22
2022-11-23 02:01:10,605 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7853204850540605, 'Total loss': 0.7853204850540605} | train loss {'Reaction outcome loss': 0.8132298939296456, 'Total loss': 0.8132298939296456}
2022-11-23 02:01:10,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:10,606 INFO:     Epoch: 23
2022-11-23 02:01:11,450 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7786559892255206, 'Total loss': 0.7786559892255206} | train loss {'Reaction outcome loss': 0.8092206342787039, 'Total loss': 0.8092206342787039}
2022-11-23 02:01:11,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:11,451 INFO:     Epoch: 24
2022-11-23 02:01:12,256 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.796339980391569, 'Total loss': 0.796339980391569} | train loss {'Reaction outcome loss': 0.806555550362243, 'Total loss': 0.806555550362243}
2022-11-23 02:01:12,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:12,256 INFO:     Epoch: 25
2022-11-23 02:01:13,056 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7916585297085518, 'Total loss': 0.7916585297085518} | train loss {'Reaction outcome loss': 0.8103346182186095, 'Total loss': 0.8103346182186095}
2022-11-23 02:01:13,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:13,056 INFO:     Epoch: 26
2022-11-23 02:01:13,859 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7852274186389391, 'Total loss': 0.7852274186389391} | train loss {'Reaction outcome loss': 0.8099208494923154, 'Total loss': 0.8099208494923154}
2022-11-23 02:01:13,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:13,859 INFO:     Epoch: 27
2022-11-23 02:01:14,638 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7990353842114293, 'Total loss': 0.7990353842114293} | train loss {'Reaction outcome loss': 0.8134657398599093, 'Total loss': 0.8134657398599093}
2022-11-23 02:01:14,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:14,639 INFO:     Epoch: 28
2022-11-23 02:01:15,413 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.799544564513273, 'Total loss': 0.799544564513273} | train loss {'Reaction outcome loss': 0.8082855948414959, 'Total loss': 0.8082855948414959}
2022-11-23 02:01:15,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:15,413 INFO:     Epoch: 29
2022-11-23 02:01:16,190 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8100848516752553, 'Total loss': 0.8100848516752553} | train loss {'Reaction outcome loss': 0.8111515779231415, 'Total loss': 0.8111515779231415}
2022-11-23 02:01:16,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:16,190 INFO:     Epoch: 30
2022-11-23 02:01:17,020 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.781233046637025, 'Total loss': 0.781233046637025} | train loss {'Reaction outcome loss': 0.8066126740858203, 'Total loss': 0.8066126740858203}
2022-11-23 02:01:17,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:17,020 INFO:     Epoch: 31
2022-11-23 02:01:17,822 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.790434061094772, 'Total loss': 0.790434061094772} | train loss {'Reaction outcome loss': 0.8078038169712317, 'Total loss': 0.8078038169712317}
2022-11-23 02:01:17,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:17,822 INFO:     Epoch: 32
2022-11-23 02:01:18,648 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7755916402783505, 'Total loss': 0.7755916402783505} | train loss {'Reaction outcome loss': 0.8046292452538599, 'Total loss': 0.8046292452538599}
2022-11-23 02:01:18,648 INFO:     Found new best model at epoch 32
2022-11-23 02:01:18,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:18,649 INFO:     Epoch: 33
2022-11-23 02:01:19,459 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7921267193417216, 'Total loss': 0.7921267193417216} | train loss {'Reaction outcome loss': 0.8077533091189432, 'Total loss': 0.8077533091189432}
2022-11-23 02:01:19,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:19,459 INFO:     Epoch: 34
2022-11-23 02:01:20,315 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7913890134456546, 'Total loss': 0.7913890134456546} | train loss {'Reaction outcome loss': 0.8069915233454743, 'Total loss': 0.8069915233454743}
2022-11-23 02:01:20,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:20,315 INFO:     Epoch: 35
2022-11-23 02:01:21,076 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7810608197090237, 'Total loss': 0.7810608197090237} | train loss {'Reaction outcome loss': 0.809774823853227, 'Total loss': 0.809774823853227}
2022-11-23 02:01:21,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:21,077 INFO:     Epoch: 36
2022-11-23 02:01:21,856 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7847597952498946, 'Total loss': 0.7847597952498946} | train loss {'Reaction outcome loss': 0.806868036140184, 'Total loss': 0.806868036140184}
2022-11-23 02:01:21,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:21,857 INFO:     Epoch: 37
2022-11-23 02:01:22,645 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7898073854834534, 'Total loss': 0.7898073854834534} | train loss {'Reaction outcome loss': 0.8084111135514056, 'Total loss': 0.8084111135514056}
2022-11-23 02:01:22,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:22,645 INFO:     Epoch: 38
2022-11-23 02:01:23,421 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7754066683525263, 'Total loss': 0.7754066683525263} | train loss {'Reaction outcome loss': 0.807612130265744, 'Total loss': 0.807612130265744}
2022-11-23 02:01:23,421 INFO:     Found new best model at epoch 38
2022-11-23 02:01:23,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:23,422 INFO:     Epoch: 39
2022-11-23 02:01:24,243 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7952879632628241, 'Total loss': 0.7952879632628241} | train loss {'Reaction outcome loss': 0.8095370697193458, 'Total loss': 0.8095370697193458}
2022-11-23 02:01:24,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:24,243 INFO:     Epoch: 40
2022-11-23 02:01:25,040 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7880959732587948, 'Total loss': 0.7880959732587948} | train loss {'Reaction outcome loss': 0.8063263883356189, 'Total loss': 0.8063263883356189}
2022-11-23 02:01:25,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:25,040 INFO:     Epoch: 41
2022-11-23 02:01:25,873 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7971283793449402, 'Total loss': 0.7971283793449402} | train loss {'Reaction outcome loss': 0.8109749814525979, 'Total loss': 0.8109749814525979}
2022-11-23 02:01:25,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:25,873 INFO:     Epoch: 42
2022-11-23 02:01:26,733 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7767489566359409, 'Total loss': 0.7767489566359409} | train loss {'Reaction outcome loss': 0.8107751441783593, 'Total loss': 0.8107751441783593}
2022-11-23 02:01:26,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:26,734 INFO:     Epoch: 43
2022-11-23 02:01:27,494 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7922722919042721, 'Total loss': 0.7922722919042721} | train loss {'Reaction outcome loss': 0.8090014126701434, 'Total loss': 0.8090014126701434}
2022-11-23 02:01:27,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:27,494 INFO:     Epoch: 44
2022-11-23 02:01:28,305 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7690504955690961, 'Total loss': 0.7690504955690961} | train loss {'Reaction outcome loss': 0.8077586737812542, 'Total loss': 0.8077586737812542}
2022-11-23 02:01:28,305 INFO:     Found new best model at epoch 44
2022-11-23 02:01:28,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:28,306 INFO:     Epoch: 45
2022-11-23 02:01:29,100 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7899317062178324, 'Total loss': 0.7899317062178324} | train loss {'Reaction outcome loss': 0.8093226958737999, 'Total loss': 0.8093226958737999}
2022-11-23 02:01:29,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:29,100 INFO:     Epoch: 46
2022-11-23 02:01:29,926 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7793221709340118, 'Total loss': 0.7793221709340118} | train loss {'Reaction outcome loss': 0.8070864378184569, 'Total loss': 0.8070864378184569}
2022-11-23 02:01:29,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:29,927 INFO:     Epoch: 47
2022-11-23 02:01:30,742 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.773174796686616, 'Total loss': 0.773174796686616} | train loss {'Reaction outcome loss': 0.8067369944736605, 'Total loss': 0.8067369944736605}
2022-11-23 02:01:30,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:30,743 INFO:     Epoch: 48
2022-11-23 02:01:31,584 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7937732727028602, 'Total loss': 0.7937732727028602} | train loss {'Reaction outcome loss': 0.8111956509166076, 'Total loss': 0.8111956509166076}
2022-11-23 02:01:31,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:31,584 INFO:     Epoch: 49
2022-11-23 02:01:32,371 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7951577278070672, 'Total loss': 0.7951577278070672} | train loss {'Reaction outcome loss': 0.8062784709647054, 'Total loss': 0.8062784709647054}
2022-11-23 02:01:32,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:32,371 INFO:     Epoch: 50
2022-11-23 02:01:33,171 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7791102798872216, 'Total loss': 0.7791102798872216} | train loss {'Reaction outcome loss': 0.807670104576916, 'Total loss': 0.807670104576916}
2022-11-23 02:01:33,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:33,172 INFO:     Epoch: 51
2022-11-23 02:01:34,007 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7851694032203319, 'Total loss': 0.7851694032203319} | train loss {'Reaction outcome loss': 0.8089302179754757, 'Total loss': 0.8089302179754757}
2022-11-23 02:01:34,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:34,007 INFO:     Epoch: 52
2022-11-23 02:01:34,762 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7957172754199006, 'Total loss': 0.7957172754199006} | train loss {'Reaction outcome loss': 0.806399610931756, 'Total loss': 0.806399610931756}
2022-11-23 02:01:34,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:34,762 INFO:     Epoch: 53
2022-11-23 02:01:35,536 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7802963651889978, 'Total loss': 0.7802963651889978} | train loss {'Reaction outcome loss': 0.8034416014542345, 'Total loss': 0.8034416014542345}
2022-11-23 02:01:35,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:35,536 INFO:     Epoch: 54
2022-11-23 02:01:36,324 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7825542563615844, 'Total loss': 0.7825542563615844} | train loss {'Reaction outcome loss': 0.8092762306332588, 'Total loss': 0.8092762306332588}
2022-11-23 02:01:36,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:36,324 INFO:     Epoch: 55
2022-11-23 02:01:37,154 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7795251642548761, 'Total loss': 0.7795251642548761} | train loss {'Reaction outcome loss': 0.8091450216340237, 'Total loss': 0.8091450216340237}
2022-11-23 02:01:37,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:37,154 INFO:     Epoch: 56
2022-11-23 02:01:37,961 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7919706133909004, 'Total loss': 0.7919706133909004} | train loss {'Reaction outcome loss': 0.8070422282717267, 'Total loss': 0.8070422282717267}
2022-11-23 02:01:37,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:37,962 INFO:     Epoch: 57
2022-11-23 02:01:38,761 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7862648603528045, 'Total loss': 0.7862648603528045} | train loss {'Reaction outcome loss': 0.8089823975670533, 'Total loss': 0.8089823975670533}
2022-11-23 02:01:38,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:38,763 INFO:     Epoch: 58
2022-11-23 02:01:39,556 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7728502189004144, 'Total loss': 0.7728502189004144} | train loss {'Reaction outcome loss': 0.8080090681304697, 'Total loss': 0.8080090681304697}
2022-11-23 02:01:39,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:39,556 INFO:     Epoch: 59
2022-11-23 02:01:40,331 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7836122228655704, 'Total loss': 0.7836122228655704} | train loss {'Reaction outcome loss': 0.807302222266549, 'Total loss': 0.807302222266549}
2022-11-23 02:01:40,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:40,331 INFO:     Epoch: 60
2022-11-23 02:01:41,132 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7862780905047129, 'Total loss': 0.7862780905047129} | train loss {'Reaction outcome loss': 0.8063081969491771, 'Total loss': 0.8063081969491771}
2022-11-23 02:01:41,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:41,133 INFO:     Epoch: 61
2022-11-23 02:01:41,927 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.787056889644889, 'Total loss': 0.787056889644889} | train loss {'Reaction outcome loss': 0.8056527925807921, 'Total loss': 0.8056527925807921}
2022-11-23 02:01:41,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:41,927 INFO:     Epoch: 62
2022-11-23 02:01:42,716 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7924053239267926, 'Total loss': 0.7924053239267926} | train loss {'Reaction outcome loss': 0.8107346612654749, 'Total loss': 0.8107346612654749}
2022-11-23 02:01:42,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:42,717 INFO:     Epoch: 63
2022-11-23 02:01:43,497 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7829601237940234, 'Total loss': 0.7829601237940234} | train loss {'Reaction outcome loss': 0.8105218139339666, 'Total loss': 0.8105218139339666}
2022-11-23 02:01:43,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:43,498 INFO:     Epoch: 64
2022-11-23 02:01:44,269 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8025539357994877, 'Total loss': 0.8025539357994877} | train loss {'Reaction outcome loss': 0.8038676050109942, 'Total loss': 0.8038676050109942}
2022-11-23 02:01:44,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:44,270 INFO:     Epoch: 65
2022-11-23 02:01:45,042 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7963077460610589, 'Total loss': 0.7963077460610589} | train loss {'Reaction outcome loss': 0.8038468270516786, 'Total loss': 0.8038468270516786}
2022-11-23 02:01:45,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:45,043 INFO:     Epoch: 66
2022-11-23 02:01:45,839 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7776065413341966, 'Total loss': 0.7776065413341966} | train loss {'Reaction outcome loss': 0.8060586794477994, 'Total loss': 0.8060586794477994}
2022-11-23 02:01:45,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:45,839 INFO:     Epoch: 67
2022-11-23 02:01:46,595 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7869593903075817, 'Total loss': 0.7869593903075817} | train loss {'Reaction outcome loss': 0.8026933494161387, 'Total loss': 0.8026933494161387}
2022-11-23 02:01:46,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:46,596 INFO:     Epoch: 68
2022-11-23 02:01:47,336 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7860206642816233, 'Total loss': 0.7860206642816233} | train loss {'Reaction outcome loss': 0.8086506618095226, 'Total loss': 0.8086506618095226}
2022-11-23 02:01:47,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:47,337 INFO:     Epoch: 69
2022-11-23 02:01:48,173 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8003260756647864, 'Total loss': 0.8003260756647864} | train loss {'Reaction outcome loss': 0.8133508140434984, 'Total loss': 0.8133508140434984}
2022-11-23 02:01:48,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:48,173 INFO:     Epoch: 70
2022-11-23 02:01:49,011 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8059095671010572, 'Total loss': 0.8059095671010572} | train loss {'Reaction outcome loss': 0.8084955061556863, 'Total loss': 0.8084955061556863}
2022-11-23 02:01:49,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:49,011 INFO:     Epoch: 71
2022-11-23 02:01:49,832 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7860438102899596, 'Total loss': 0.7860438102899596} | train loss {'Reaction outcome loss': 0.8073949626967555, 'Total loss': 0.8073949626967555}
2022-11-23 02:01:49,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:49,832 INFO:     Epoch: 72
2022-11-23 02:01:50,619 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7793804102165754, 'Total loss': 0.7793804102165754} | train loss {'Reaction outcome loss': 0.8086705796542715, 'Total loss': 0.8086705796542715}
2022-11-23 02:01:50,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:50,619 INFO:     Epoch: 73
2022-11-23 02:01:51,444 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7771173861137656, 'Total loss': 0.7771173861137656} | train loss {'Reaction outcome loss': 0.8057537748188269, 'Total loss': 0.8057537748188269}
2022-11-23 02:01:51,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:51,444 INFO:     Epoch: 74
2022-11-23 02:01:52,252 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8078967443732328, 'Total loss': 0.8078967443732328} | train loss {'Reaction outcome loss': 0.8055274402264689, 'Total loss': 0.8055274402264689}
2022-11-23 02:01:52,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:52,252 INFO:     Epoch: 75
2022-11-23 02:01:53,096 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7750521551731021, 'Total loss': 0.7750521551731021} | train loss {'Reaction outcome loss': 0.8109613997770138, 'Total loss': 0.8109613997770138}
2022-11-23 02:01:53,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:53,096 INFO:     Epoch: 76
2022-11-23 02:01:53,910 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7891416487305664, 'Total loss': 0.7891416487305664} | train loss {'Reaction outcome loss': 0.8059658799015108, 'Total loss': 0.8059658799015108}
2022-11-23 02:01:53,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:53,910 INFO:     Epoch: 77
2022-11-23 02:01:54,726 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7852587346420732, 'Total loss': 0.7852587346420732} | train loss {'Reaction outcome loss': 0.8046777173876762, 'Total loss': 0.8046777173876762}
2022-11-23 02:01:54,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:54,727 INFO:     Epoch: 78
2022-11-23 02:01:55,531 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7891194952088733, 'Total loss': 0.7891194952088733} | train loss {'Reaction outcome loss': 0.8112517904307022, 'Total loss': 0.8112517904307022}
2022-11-23 02:01:55,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:55,531 INFO:     Epoch: 79
2022-11-23 02:01:56,346 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7735559898753499, 'Total loss': 0.7735559898753499} | train loss {'Reaction outcome loss': 0.8083096224753583, 'Total loss': 0.8083096224753583}
2022-11-23 02:01:56,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:56,346 INFO:     Epoch: 80
2022-11-23 02:01:57,167 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7900533107824104, 'Total loss': 0.7900533107824104} | train loss {'Reaction outcome loss': 0.806738905975076, 'Total loss': 0.806738905975076}
2022-11-23 02:01:57,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:57,168 INFO:     Epoch: 81
2022-11-23 02:01:58,024 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7933559646440107, 'Total loss': 0.7933559646440107} | train loss {'Reaction outcome loss': 0.8094850291849159, 'Total loss': 0.8094850291849159}
2022-11-23 02:01:58,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:58,024 INFO:     Epoch: 82
2022-11-23 02:01:58,957 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7892740521320077, 'Total loss': 0.7892740521320077} | train loss {'Reaction outcome loss': 0.8052510230756197, 'Total loss': 0.8052510230756197}
2022-11-23 02:01:58,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:58,957 INFO:     Epoch: 83
2022-11-23 02:01:59,809 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7943960164868554, 'Total loss': 0.7943960164868554} | train loss {'Reaction outcome loss': 0.8009423833401477, 'Total loss': 0.8009423833401477}
2022-11-23 02:01:59,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:01:59,809 INFO:     Epoch: 84
2022-11-23 02:02:00,641 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8015952054844346, 'Total loss': 0.8015952054844346} | train loss {'Reaction outcome loss': 0.8076137945544525, 'Total loss': 0.8076137945544525}
2022-11-23 02:02:00,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:00,641 INFO:     Epoch: 85
2022-11-23 02:02:01,549 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7859316828639008, 'Total loss': 0.7859316828639008} | train loss {'Reaction outcome loss': 0.8053079027621473, 'Total loss': 0.8053079027621473}
2022-11-23 02:02:01,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:01,550 INFO:     Epoch: 86
2022-11-23 02:02:02,460 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7775473871896433, 'Total loss': 0.7775473871896433} | train loss {'Reaction outcome loss': 0.8093708147768115, 'Total loss': 0.8093708147768115}
2022-11-23 02:02:02,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:02,460 INFO:     Epoch: 87
2022-11-23 02:02:03,404 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7761750075706216, 'Total loss': 0.7761750075706216} | train loss {'Reaction outcome loss': 0.8064182575364582, 'Total loss': 0.8064182575364582}
2022-11-23 02:02:03,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:03,405 INFO:     Epoch: 88
2022-11-23 02:02:04,294 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8132101526094038, 'Total loss': 0.8132101526094038} | train loss {'Reaction outcome loss': 0.8055919280550519, 'Total loss': 0.8055919280550519}
2022-11-23 02:02:04,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:04,294 INFO:     Epoch: 89
2022-11-23 02:02:05,192 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7778580459051354, 'Total loss': 0.7778580459051354} | train loss {'Reaction outcome loss': 0.8100540276433601, 'Total loss': 0.8100540276433601}
2022-11-23 02:02:05,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:05,192 INFO:     Epoch: 90
2022-11-23 02:02:06,077 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7769004855045053, 'Total loss': 0.7769004855045053} | train loss {'Reaction outcome loss': 0.8104259261830908, 'Total loss': 0.8104259261830908}
2022-11-23 02:02:06,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:06,078 INFO:     Epoch: 91
2022-11-23 02:02:06,999 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7806949164978293, 'Total loss': 0.7806949164978293} | train loss {'Reaction outcome loss': 0.8102248065540048, 'Total loss': 0.8102248065540048}
2022-11-23 02:02:06,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:06,999 INFO:     Epoch: 92
2022-11-23 02:02:07,889 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7824231122815332, 'Total loss': 0.7824231122815332} | train loss {'Reaction outcome loss': 0.8053437144052787, 'Total loss': 0.8053437144052787}
2022-11-23 02:02:07,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:07,889 INFO:     Epoch: 93
2022-11-23 02:02:08,800 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7708488848320273, 'Total loss': 0.7708488848320273} | train loss {'Reaction outcome loss': 0.8061443534298022, 'Total loss': 0.8061443534298022}
2022-11-23 02:02:08,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:08,800 INFO:     Epoch: 94
2022-11-23 02:02:09,714 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8007855810398279, 'Total loss': 0.8007855810398279} | train loss {'Reaction outcome loss': 0.8034422641894856, 'Total loss': 0.8034422641894856}
2022-11-23 02:02:09,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:09,714 INFO:     Epoch: 95
2022-11-23 02:02:10,640 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7948883231296096, 'Total loss': 0.7948883231296096} | train loss {'Reaction outcome loss': 0.8065704517677182, 'Total loss': 0.8065704517677182}
2022-11-23 02:02:10,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:10,641 INFO:     Epoch: 96
2022-11-23 02:02:11,639 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7772425787393437, 'Total loss': 0.7772425787393437} | train loss {'Reaction outcome loss': 0.8069449150171436, 'Total loss': 0.8069449150171436}
2022-11-23 02:02:11,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:11,639 INFO:     Epoch: 97
2022-11-23 02:02:12,510 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7809478224709977, 'Total loss': 0.7809478224709977} | train loss {'Reaction outcome loss': 0.8054649243589307, 'Total loss': 0.8054649243589307}
2022-11-23 02:02:12,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:12,510 INFO:     Epoch: 98
2022-11-23 02:02:13,464 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7791253896646722, 'Total loss': 0.7791253896646722} | train loss {'Reaction outcome loss': 0.8090674348297666, 'Total loss': 0.8090674348297666}
2022-11-23 02:02:13,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:13,464 INFO:     Epoch: 99
2022-11-23 02:02:14,328 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7691648027231527, 'Total loss': 0.7691648027231527} | train loss {'Reaction outcome loss': 0.8084613923899463, 'Total loss': 0.8084613923899463}
2022-11-23 02:02:14,329 INFO:     Best model found after epoch 45 of 100.
2022-11-23 02:02:14,329 INFO:   Done with stage: TRAINING
2022-11-23 02:02:14,329 INFO:   Starting stage: EVALUATION
2022-11-23 02:02:14,465 INFO:   Done with stage: EVALUATION
2022-11-23 02:02:14,466 INFO:   Leaving out SEQ value Fold_4
2022-11-23 02:02:14,479 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:02:14,479 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:02:15,170 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:02:15,170 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:02:15,257 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:02:15,257 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:02:15,257 INFO:     No hyperparam tuning for this model
2022-11-23 02:02:15,257 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:02:15,257 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:02:15,258 INFO:     None feature selector for col prot
2022-11-23 02:02:15,258 INFO:     None feature selector for col prot
2022-11-23 02:02:15,258 INFO:     None feature selector for col prot
2022-11-23 02:02:15,259 INFO:     None feature selector for col chem
2022-11-23 02:02:15,259 INFO:     None feature selector for col chem
2022-11-23 02:02:15,259 INFO:     None feature selector for col chem
2022-11-23 02:02:15,259 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:02:15,259 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:02:15,261 INFO:     Number of params in model 168571
2022-11-23 02:02:15,265 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:02:15,265 INFO:   Starting stage: TRAINING
2022-11-23 02:02:15,327 INFO:     Val loss before train {'Reaction outcome loss': 0.9759522364898161, 'Total loss': 0.9759522364898161}
2022-11-23 02:02:15,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:15,328 INFO:     Epoch: 0
2022-11-23 02:02:16,237 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.84978732873093, 'Total loss': 0.84978732873093} | train loss {'Reaction outcome loss': 0.8818915511673762, 'Total loss': 0.8818915511673762}
2022-11-23 02:02:16,237 INFO:     Found new best model at epoch 0
2022-11-23 02:02:16,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:16,238 INFO:     Epoch: 1
2022-11-23 02:02:17,130 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8396176445213231, 'Total loss': 0.8396176445213231} | train loss {'Reaction outcome loss': 0.8528918336760177, 'Total loss': 0.8528918336760177}
2022-11-23 02:02:17,131 INFO:     Found new best model at epoch 1
2022-11-23 02:02:17,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:17,133 INFO:     Epoch: 2
2022-11-23 02:02:17,985 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8280132832852277, 'Total loss': 0.8280132832852277} | train loss {'Reaction outcome loss': 0.8519897575561817, 'Total loss': 0.8519897575561817}
2022-11-23 02:02:17,986 INFO:     Found new best model at epoch 2
2022-11-23 02:02:17,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:17,986 INFO:     Epoch: 3
2022-11-23 02:02:18,910 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8366083949804306, 'Total loss': 0.8366083949804306} | train loss {'Reaction outcome loss': 0.8466887471646916, 'Total loss': 0.8466887471646916}
2022-11-23 02:02:18,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:18,911 INFO:     Epoch: 4
2022-11-23 02:02:19,868 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.821411404420029, 'Total loss': 0.821411404420029} | train loss {'Reaction outcome loss': 0.8312503176963764, 'Total loss': 0.8312503176963764}
2022-11-23 02:02:19,868 INFO:     Found new best model at epoch 4
2022-11-23 02:02:19,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:19,869 INFO:     Epoch: 5
2022-11-23 02:02:20,784 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8342687826264988, 'Total loss': 0.8342687826264988} | train loss {'Reaction outcome loss': 0.8350357622028846, 'Total loss': 0.8350357622028846}
2022-11-23 02:02:20,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:20,784 INFO:     Epoch: 6
2022-11-23 02:02:21,649 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8347170380028811, 'Total loss': 0.8347170380028811} | train loss {'Reaction outcome loss': 0.8307662563104379, 'Total loss': 0.8307662563104379}
2022-11-23 02:02:21,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:21,649 INFO:     Epoch: 7
2022-11-23 02:02:22,547 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8228903060609644, 'Total loss': 0.8228903060609644} | train loss {'Reaction outcome loss': 0.8289859212844478, 'Total loss': 0.8289859212844478}
2022-11-23 02:02:22,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:22,547 INFO:     Epoch: 8
2022-11-23 02:02:23,478 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8169074641032652, 'Total loss': 0.8169074641032652} | train loss {'Reaction outcome loss': 0.8281513795196286, 'Total loss': 0.8281513795196286}
2022-11-23 02:02:23,479 INFO:     Found new best model at epoch 8
2022-11-23 02:02:23,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:23,480 INFO:     Epoch: 9
2022-11-23 02:02:24,342 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8135221675038338, 'Total loss': 0.8135221675038338} | train loss {'Reaction outcome loss': 0.8231865558547047, 'Total loss': 0.8231865558547047}
2022-11-23 02:02:24,342 INFO:     Found new best model at epoch 9
2022-11-23 02:02:24,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:24,343 INFO:     Epoch: 10
2022-11-23 02:02:25,197 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8334159918806769, 'Total loss': 0.8334159918806769} | train loss {'Reaction outcome loss': 0.8252798056433558, 'Total loss': 0.8252798056433558}
2022-11-23 02:02:25,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:25,197 INFO:     Epoch: 11
2022-11-23 02:02:26,086 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8188134350559928, 'Total loss': 0.8188134350559928} | train loss {'Reaction outcome loss': 0.817689421809154, 'Total loss': 0.817689421809154}
2022-11-23 02:02:26,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:26,087 INFO:     Epoch: 12
2022-11-23 02:02:26,940 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8186217201027003, 'Total loss': 0.8186217201027003} | train loss {'Reaction outcome loss': 0.8253454841100253, 'Total loss': 0.8253454841100253}
2022-11-23 02:02:26,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:26,940 INFO:     Epoch: 13
2022-11-23 02:02:27,776 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8202109451998364, 'Total loss': 0.8202109451998364} | train loss {'Reaction outcome loss': 0.8200308164121651, 'Total loss': 0.8200308164121651}
2022-11-23 02:02:27,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:27,777 INFO:     Epoch: 14
2022-11-23 02:02:28,624 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8351554044268348, 'Total loss': 0.8351554044268348} | train loss {'Reaction outcome loss': 0.8134921667305565, 'Total loss': 0.8134921667305565}
2022-11-23 02:02:28,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:28,624 INFO:     Epoch: 15
2022-11-23 02:02:29,449 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8182073452255942, 'Total loss': 0.8182073452255942} | train loss {'Reaction outcome loss': 0.8173941229639748, 'Total loss': 0.8173941229639748}
2022-11-23 02:02:29,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:29,450 INFO:     Epoch: 16
2022-11-23 02:02:30,308 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8140756298195232, 'Total loss': 0.8140756298195232} | train loss {'Reaction outcome loss': 0.8164671640466099, 'Total loss': 0.8164671640466099}
2022-11-23 02:02:30,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:30,308 INFO:     Epoch: 17
2022-11-23 02:02:31,190 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8072593008930032, 'Total loss': 0.8072593008930032} | train loss {'Reaction outcome loss': 0.8135567604288881, 'Total loss': 0.8135567604288881}
2022-11-23 02:02:31,190 INFO:     Found new best model at epoch 17
2022-11-23 02:02:31,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:31,191 INFO:     Epoch: 18
2022-11-23 02:02:32,182 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8022715923461047, 'Total loss': 0.8022715923461047} | train loss {'Reaction outcome loss': 0.8125243151960103, 'Total loss': 0.8125243151960103}
2022-11-23 02:02:32,183 INFO:     Found new best model at epoch 18
2022-11-23 02:02:32,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:32,184 INFO:     Epoch: 19
2022-11-23 02:02:33,060 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8448840759017251, 'Total loss': 0.8448840759017251} | train loss {'Reaction outcome loss': 0.8169902056334954, 'Total loss': 0.8169902056334954}
2022-11-23 02:02:33,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:33,060 INFO:     Epoch: 20
2022-11-23 02:02:33,874 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8312814106995409, 'Total loss': 0.8312814106995409} | train loss {'Reaction outcome loss': 0.819531389696878, 'Total loss': 0.819531389696878}
2022-11-23 02:02:33,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:33,874 INFO:     Epoch: 21
2022-11-23 02:02:34,767 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8186831704594872, 'Total loss': 0.8186831704594872} | train loss {'Reaction outcome loss': 0.810905570594164, 'Total loss': 0.810905570594164}
2022-11-23 02:02:34,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:34,768 INFO:     Epoch: 22
2022-11-23 02:02:35,642 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8387771221724424, 'Total loss': 0.8387771221724424} | train loss {'Reaction outcome loss': 0.8082874172370926, 'Total loss': 0.8082874172370926}
2022-11-23 02:02:35,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:35,642 INFO:     Epoch: 23
2022-11-23 02:02:36,470 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8060567433183844, 'Total loss': 0.8060567433183844} | train loss {'Reaction outcome loss': 0.817304923225511, 'Total loss': 0.817304923225511}
2022-11-23 02:02:36,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:36,470 INFO:     Epoch: 24
2022-11-23 02:02:37,354 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8369155885143713, 'Total loss': 0.8369155885143713} | train loss {'Reaction outcome loss': 0.8047857200689161, 'Total loss': 0.8047857200689161}
2022-11-23 02:02:37,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:37,354 INFO:     Epoch: 25
2022-11-23 02:02:38,202 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8081878152760592, 'Total loss': 0.8081878152760592} | train loss {'Reaction outcome loss': 0.812463707045505, 'Total loss': 0.812463707045505}
2022-11-23 02:02:38,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:38,202 INFO:     Epoch: 26
2022-11-23 02:02:39,046 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8220806893977252, 'Total loss': 0.8220806893977252} | train loss {'Reaction outcome loss': 0.8076901167993121, 'Total loss': 0.8076901167993121}
2022-11-23 02:02:39,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:39,046 INFO:     Epoch: 27
2022-11-23 02:02:39,886 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.812908495014364, 'Total loss': 0.812908495014364} | train loss {'Reaction outcome loss': 0.8121915121792782, 'Total loss': 0.8121915121792782}
2022-11-23 02:02:39,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:39,886 INFO:     Epoch: 28
2022-11-23 02:02:40,733 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7995813827623021, 'Total loss': 0.7995813827623021} | train loss {'Reaction outcome loss': 0.8020276767522218, 'Total loss': 0.8020276767522218}
2022-11-23 02:02:40,734 INFO:     Found new best model at epoch 28
2022-11-23 02:02:40,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:40,735 INFO:     Epoch: 29
2022-11-23 02:02:41,590 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8089659789746458, 'Total loss': 0.8089659789746458} | train loss {'Reaction outcome loss': 0.8121392561597862, 'Total loss': 0.8121392561597862}
2022-11-23 02:02:41,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:41,590 INFO:     Epoch: 30
2022-11-23 02:02:42,435 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8038774633949454, 'Total loss': 0.8038774633949454} | train loss {'Reaction outcome loss': 0.8074701708639681, 'Total loss': 0.8074701708639681}
2022-11-23 02:02:42,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:42,435 INFO:     Epoch: 31
2022-11-23 02:02:43,261 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8226600966670297, 'Total loss': 0.8226600966670297} | train loss {'Reaction outcome loss': 0.8053685554608643, 'Total loss': 0.8053685554608643}
2022-11-23 02:02:43,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:43,261 INFO:     Epoch: 32
2022-11-23 02:02:44,082 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8086528361520984, 'Total loss': 0.8086528361520984} | train loss {'Reaction outcome loss': 0.8124885706283785, 'Total loss': 0.8124885706283785}
2022-11-23 02:02:44,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:44,082 INFO:     Epoch: 33
2022-11-23 02:02:44,912 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8118512257933617, 'Total loss': 0.8118512257933617} | train loss {'Reaction outcome loss': 0.8045844093025455, 'Total loss': 0.8045844093025455}
2022-11-23 02:02:44,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:44,913 INFO:     Epoch: 34
2022-11-23 02:02:45,785 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8185389441522685, 'Total loss': 0.8185389441522685} | train loss {'Reaction outcome loss': 0.8073802002769733, 'Total loss': 0.8073802002769733}
2022-11-23 02:02:45,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:45,786 INFO:     Epoch: 35
2022-11-23 02:02:46,675 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8119797740470279, 'Total loss': 0.8119797740470279} | train loss {'Reaction outcome loss': 0.8086145610703148, 'Total loss': 0.8086145610703148}
2022-11-23 02:02:46,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:46,675 INFO:     Epoch: 36
2022-11-23 02:02:47,550 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8179811740463431, 'Total loss': 0.8179811740463431} | train loss {'Reaction outcome loss': 0.8025062259754189, 'Total loss': 0.8025062259754189}
2022-11-23 02:02:47,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:47,551 INFO:     Epoch: 37
2022-11-23 02:02:48,420 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8989332223480399, 'Total loss': 0.8989332223480399} | train loss {'Reaction outcome loss': 0.8036042555623691, 'Total loss': 0.8036042555623691}
2022-11-23 02:02:48,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:48,420 INFO:     Epoch: 38
2022-11-23 02:02:49,268 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8136215223507448, 'Total loss': 0.8136215223507448} | train loss {'Reaction outcome loss': 0.8131162404772724, 'Total loss': 0.8131162404772724}
2022-11-23 02:02:49,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:49,268 INFO:     Epoch: 39
2022-11-23 02:02:50,127 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8092263415455818, 'Total loss': 0.8092263415455818} | train loss {'Reaction outcome loss': 0.8021456880970039, 'Total loss': 0.8021456880970039}
2022-11-23 02:02:50,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:50,127 INFO:     Epoch: 40
2022-11-23 02:02:51,037 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8122685612602667, 'Total loss': 0.8122685612602667} | train loss {'Reaction outcome loss': 0.8045144542026134, 'Total loss': 0.8045144542026134}
2022-11-23 02:02:51,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:51,038 INFO:     Epoch: 41
2022-11-23 02:02:51,904 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8084872229532762, 'Total loss': 0.8084872229532762} | train loss {'Reaction outcome loss': 0.80621152911109, 'Total loss': 0.80621152911109}
2022-11-23 02:02:51,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:51,904 INFO:     Epoch: 42
2022-11-23 02:02:52,784 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8055359802462838, 'Total loss': 0.8055359802462838} | train loss {'Reaction outcome loss': 0.8137498195113441, 'Total loss': 0.8137498195113441}
2022-11-23 02:02:52,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:52,784 INFO:     Epoch: 43
2022-11-23 02:02:53,674 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7956554984504526, 'Total loss': 0.7956554984504526} | train loss {'Reaction outcome loss': 0.8000283805947555, 'Total loss': 0.8000283805947555}
2022-11-23 02:02:53,674 INFO:     Found new best model at epoch 43
2022-11-23 02:02:53,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:53,676 INFO:     Epoch: 44
2022-11-23 02:02:54,575 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8012053485621106, 'Total loss': 0.8012053485621106} | train loss {'Reaction outcome loss': 0.8019788803359275, 'Total loss': 0.8019788803359275}
2022-11-23 02:02:54,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:54,576 INFO:     Epoch: 45
2022-11-23 02:02:55,458 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7968534170226618, 'Total loss': 0.7968534170226618} | train loss {'Reaction outcome loss': 0.8004211083672911, 'Total loss': 0.8004211083672911}
2022-11-23 02:02:55,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:55,458 INFO:     Epoch: 46
2022-11-23 02:02:56,371 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8057088208469477, 'Total loss': 0.8057088208469477} | train loss {'Reaction outcome loss': 0.7986315754261094, 'Total loss': 0.7986315754261094}
2022-11-23 02:02:56,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:56,372 INFO:     Epoch: 47
2022-11-23 02:02:57,216 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8093384382399645, 'Total loss': 0.8093384382399645} | train loss {'Reaction outcome loss': 0.8103811775865825, 'Total loss': 0.8103811775865825}
2022-11-23 02:02:57,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:57,216 INFO:     Epoch: 48
2022-11-23 02:02:58,094 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8050670014186339, 'Total loss': 0.8050670014186339} | train loss {'Reaction outcome loss': 0.8022983216563699, 'Total loss': 0.8022983216563699}
2022-11-23 02:02:58,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:58,094 INFO:     Epoch: 49
2022-11-23 02:02:59,144 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8095588277686726, 'Total loss': 0.8095588277686726} | train loss {'Reaction outcome loss': 0.8029840991564607, 'Total loss': 0.8029840991564607}
2022-11-23 02:02:59,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:02:59,144 INFO:     Epoch: 50
2022-11-23 02:03:00,196 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8012868836522102, 'Total loss': 0.8012868836522102} | train loss {'Reaction outcome loss': 0.8008078889325563, 'Total loss': 0.8008078889325563}
2022-11-23 02:03:00,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:00,198 INFO:     Epoch: 51
2022-11-23 02:03:01,283 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.811919164928523, 'Total loss': 0.811919164928523} | train loss {'Reaction outcome loss': 0.8012471213514506, 'Total loss': 0.8012471213514506}
2022-11-23 02:03:01,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:01,284 INFO:     Epoch: 52
2022-11-23 02:03:02,342 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7996580255302516, 'Total loss': 0.7996580255302516} | train loss {'Reaction outcome loss': 0.799915507978756, 'Total loss': 0.799915507978756}
2022-11-23 02:03:02,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:02,342 INFO:     Epoch: 53
2022-11-23 02:03:03,398 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8037251220508055, 'Total loss': 0.8037251220508055} | train loss {'Reaction outcome loss': 0.7964570552472644, 'Total loss': 0.7964570552472644}
2022-11-23 02:03:03,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:03,398 INFO:     Epoch: 54
2022-11-23 02:03:04,430 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8018986291506074, 'Total loss': 0.8018986291506074} | train loss {'Reaction outcome loss': 0.7957231278271086, 'Total loss': 0.7957231278271086}
2022-11-23 02:03:04,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:04,430 INFO:     Epoch: 55
2022-11-23 02:03:05,473 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8105541542172432, 'Total loss': 0.8105541542172432} | train loss {'Reaction outcome loss': 0.7965428447916441, 'Total loss': 0.7965428447916441}
2022-11-23 02:03:05,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:05,474 INFO:     Epoch: 56
2022-11-23 02:03:06,499 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8022155660119924, 'Total loss': 0.8022155660119924} | train loss {'Reaction outcome loss': 0.7947133611812283, 'Total loss': 0.7947133611812283}
2022-11-23 02:03:06,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:06,499 INFO:     Epoch: 57
2022-11-23 02:03:07,551 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8128220262852582, 'Total loss': 0.8128220262852582} | train loss {'Reaction outcome loss': 0.79714151589494, 'Total loss': 0.79714151589494}
2022-11-23 02:03:07,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:07,551 INFO:     Epoch: 58
2022-11-23 02:03:08,561 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.822201819582419, 'Total loss': 0.822201819582419} | train loss {'Reaction outcome loss': 0.7956709293460074, 'Total loss': 0.7956709293460074}
2022-11-23 02:03:08,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:08,562 INFO:     Epoch: 59
2022-11-23 02:03:09,583 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7915330813689665, 'Total loss': 0.7915330813689665} | train loss {'Reaction outcome loss': 0.7975367244016304, 'Total loss': 0.7975367244016304}
2022-11-23 02:03:09,584 INFO:     Found new best model at epoch 59
2022-11-23 02:03:09,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:09,585 INFO:     Epoch: 60
2022-11-23 02:03:10,648 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7888706014914946, 'Total loss': 0.7888706014914946} | train loss {'Reaction outcome loss': 0.808074883845171, 'Total loss': 0.808074883845171}
2022-11-23 02:03:10,648 INFO:     Found new best model at epoch 60
2022-11-23 02:03:10,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:10,650 INFO:     Epoch: 61
2022-11-23 02:03:11,687 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7893766916610978, 'Total loss': 0.7893766916610978} | train loss {'Reaction outcome loss': 0.7994418216017094, 'Total loss': 0.7994418216017094}
2022-11-23 02:03:11,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:11,688 INFO:     Epoch: 62
2022-11-23 02:03:12,729 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8132104887203737, 'Total loss': 0.8132104887203737} | train loss {'Reaction outcome loss': 0.7987976103176472, 'Total loss': 0.7987976103176472}
2022-11-23 02:03:12,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:12,731 INFO:     Epoch: 63
2022-11-23 02:03:13,783 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7983173098076474, 'Total loss': 0.7983173098076474} | train loss {'Reaction outcome loss': 0.7916443623632554, 'Total loss': 0.7916443623632554}
2022-11-23 02:03:13,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:13,783 INFO:     Epoch: 64
2022-11-23 02:03:14,845 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8634401593695987, 'Total loss': 0.8634401593695987} | train loss {'Reaction outcome loss': 0.7899648457886237, 'Total loss': 0.7899648457886237}
2022-11-23 02:03:14,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:14,845 INFO:     Epoch: 65
2022-11-23 02:03:15,833 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.793497162786397, 'Total loss': 0.793497162786397} | train loss {'Reaction outcome loss': 0.8020735802920723, 'Total loss': 0.8020735802920723}
2022-11-23 02:03:15,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:15,833 INFO:     Epoch: 66
2022-11-23 02:03:16,757 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8208948631178249, 'Total loss': 0.8208948631178249} | train loss {'Reaction outcome loss': 0.7944746975172386, 'Total loss': 0.7944746975172386}
2022-11-23 02:03:16,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:16,758 INFO:     Epoch: 67
2022-11-23 02:03:17,781 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8039667484435168, 'Total loss': 0.8039667484435168} | train loss {'Reaction outcome loss': 0.7948629311945757, 'Total loss': 0.7948629311945757}
2022-11-23 02:03:17,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:17,782 INFO:     Epoch: 68
2022-11-23 02:03:18,818 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7920451231978156, 'Total loss': 0.7920451231978156} | train loss {'Reaction outcome loss': 0.7917113960211576, 'Total loss': 0.7917113960211576}
2022-11-23 02:03:18,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:18,819 INFO:     Epoch: 69
2022-11-23 02:03:19,894 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7889471501111984, 'Total loss': 0.7889471501111984} | train loss {'Reaction outcome loss': 0.7909866801881598, 'Total loss': 0.7909866801881598}
2022-11-23 02:03:19,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:19,895 INFO:     Epoch: 70
2022-11-23 02:03:20,952 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8114829686554995, 'Total loss': 0.8114829686554995} | train loss {'Reaction outcome loss': 0.7911085950037245, 'Total loss': 0.7911085950037245}
2022-11-23 02:03:20,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:20,953 INFO:     Epoch: 71
2022-11-23 02:03:21,974 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8049183569171212, 'Total loss': 0.8049183569171212} | train loss {'Reaction outcome loss': 0.796945235989837, 'Total loss': 0.796945235989837}
2022-11-23 02:03:21,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:21,974 INFO:     Epoch: 72
2022-11-23 02:03:23,026 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.809251916679469, 'Total loss': 0.809251916679469} | train loss {'Reaction outcome loss': 0.7856445982298146, 'Total loss': 0.7856445982298146}
2022-11-23 02:03:23,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:23,027 INFO:     Epoch: 73
2022-11-23 02:03:24,054 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7968355186960914, 'Total loss': 0.7968355186960914} | train loss {'Reaction outcome loss': 0.7880611438228775, 'Total loss': 0.7880611438228775}
2022-11-23 02:03:24,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:24,054 INFO:     Epoch: 74
2022-11-23 02:03:24,890 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7855168350718238, 'Total loss': 0.7855168350718238} | train loss {'Reaction outcome loss': 0.7812569462336026, 'Total loss': 0.7812569462336026}
2022-11-23 02:03:24,890 INFO:     Found new best model at epoch 74
2022-11-23 02:03:24,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:24,891 INFO:     Epoch: 75
2022-11-23 02:03:25,681 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8165008330887015, 'Total loss': 0.8165008330887015} | train loss {'Reaction outcome loss': 0.7842601671483111, 'Total loss': 0.7842601671483111}
2022-11-23 02:03:25,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:25,681 INFO:     Epoch: 76
2022-11-23 02:03:26,465 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7848489833149043, 'Total loss': 0.7848489833149043} | train loss {'Reaction outcome loss': 0.7818840335496524, 'Total loss': 0.7818840335496524}
2022-11-23 02:03:26,466 INFO:     Found new best model at epoch 76
2022-11-23 02:03:26,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:26,466 INFO:     Epoch: 77
2022-11-23 02:03:27,252 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7929264618591829, 'Total loss': 0.7929264618591829} | train loss {'Reaction outcome loss': 0.780331198261817, 'Total loss': 0.780331198261817}
2022-11-23 02:03:27,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:27,252 INFO:     Epoch: 78
2022-11-23 02:03:28,027 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.792760929600759, 'Total loss': 0.792760929600759} | train loss {'Reaction outcome loss': 0.7830470331043367, 'Total loss': 0.7830470331043367}
2022-11-23 02:03:28,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:28,028 INFO:     Epoch: 79
2022-11-23 02:03:28,866 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7897679406133565, 'Total loss': 0.7897679406133565} | train loss {'Reaction outcome loss': 0.778226168170149, 'Total loss': 0.778226168170149}
2022-11-23 02:03:28,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:28,866 INFO:     Epoch: 80
2022-11-23 02:03:29,667 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7926127517765219, 'Total loss': 0.7926127517765219} | train loss {'Reaction outcome loss': 0.7748184076204956, 'Total loss': 0.7748184076204956}
2022-11-23 02:03:29,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:29,667 INFO:     Epoch: 81
2022-11-23 02:03:30,420 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8605829775333405, 'Total loss': 0.8605829775333405} | train loss {'Reaction outcome loss': 0.7801339356040182, 'Total loss': 0.7801339356040182}
2022-11-23 02:03:30,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:30,420 INFO:     Epoch: 82
2022-11-23 02:03:31,203 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7846769365397367, 'Total loss': 0.7846769365397367} | train loss {'Reaction outcome loss': 0.7809988934742776, 'Total loss': 0.7809988934742776}
2022-11-23 02:03:31,206 INFO:     Found new best model at epoch 82
2022-11-23 02:03:31,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:31,207 INFO:     Epoch: 83
2022-11-23 02:03:31,981 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7714801600033586, 'Total loss': 0.7714801600033586} | train loss {'Reaction outcome loss': 0.7679927987216214, 'Total loss': 0.7679927987216214}
2022-11-23 02:03:31,981 INFO:     Found new best model at epoch 83
2022-11-23 02:03:31,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:31,982 INFO:     Epoch: 84
2022-11-23 02:03:32,781 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8149035423994064, 'Total loss': 0.8149035423994064} | train loss {'Reaction outcome loss': 0.7677206298117696, 'Total loss': 0.7677206298117696}
2022-11-23 02:03:32,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:32,781 INFO:     Epoch: 85
2022-11-23 02:03:33,564 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7797790278087963, 'Total loss': 0.7797790278087963} | train loss {'Reaction outcome loss': 0.7737514065344807, 'Total loss': 0.7737514065344807}
2022-11-23 02:03:33,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:33,564 INFO:     Epoch: 86
2022-11-23 02:03:34,342 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7811187106099996, 'Total loss': 0.7811187106099996} | train loss {'Reaction outcome loss': 0.7720975585070698, 'Total loss': 0.7720975585070698}
2022-11-23 02:03:34,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:34,343 INFO:     Epoch: 87
2022-11-23 02:03:35,135 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.770549938082695, 'Total loss': 0.770549938082695} | train loss {'Reaction outcome loss': 0.7543068933281821, 'Total loss': 0.7543068933281821}
2022-11-23 02:03:35,135 INFO:     Found new best model at epoch 87
2022-11-23 02:03:35,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:35,136 INFO:     Epoch: 88
2022-11-23 02:03:35,922 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7562414726073091, 'Total loss': 0.7562414726073091} | train loss {'Reaction outcome loss': 0.7535178295755194, 'Total loss': 0.7535178295755194}
2022-11-23 02:03:35,922 INFO:     Found new best model at epoch 88
2022-11-23 02:03:35,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:35,923 INFO:     Epoch: 89
2022-11-23 02:03:36,748 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7421994649551131, 'Total loss': 0.7421994649551131} | train loss {'Reaction outcome loss': 0.7404273391629641, 'Total loss': 0.7404273391629641}
2022-11-23 02:03:36,749 INFO:     Found new best model at epoch 89
2022-11-23 02:03:36,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:36,750 INFO:     Epoch: 90
2022-11-23 02:03:37,622 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7673747166991234, 'Total loss': 0.7673747166991234} | train loss {'Reaction outcome loss': 0.7510241565675388, 'Total loss': 0.7510241565675388}
2022-11-23 02:03:37,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:37,623 INFO:     Epoch: 91
2022-11-23 02:03:38,472 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.740075217729265, 'Total loss': 0.740075217729265} | train loss {'Reaction outcome loss': 0.7434747214259406, 'Total loss': 0.7434747214259406}
2022-11-23 02:03:38,472 INFO:     Found new best model at epoch 91
2022-11-23 02:03:38,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:38,473 INFO:     Epoch: 92
2022-11-23 02:03:39,302 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7427538240497763, 'Total loss': 0.7427538240497763} | train loss {'Reaction outcome loss': 0.728486782746759, 'Total loss': 0.728486782746759}
2022-11-23 02:03:39,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:39,302 INFO:     Epoch: 93
2022-11-23 02:03:40,155 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7378969815644351, 'Total loss': 0.7378969815644351} | train loss {'Reaction outcome loss': 0.7048679453279325, 'Total loss': 0.7048679453279325}
2022-11-23 02:03:40,155 INFO:     Found new best model at epoch 93
2022-11-23 02:03:40,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:40,156 INFO:     Epoch: 94
2022-11-23 02:03:40,976 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7324475388635289, 'Total loss': 0.7324475388635289} | train loss {'Reaction outcome loss': 0.6971073125541843, 'Total loss': 0.6971073125541843}
2022-11-23 02:03:40,976 INFO:     Found new best model at epoch 94
2022-11-23 02:03:40,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:40,977 INFO:     Epoch: 95
2022-11-23 02:03:41,800 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8790372522039847, 'Total loss': 0.8790372522039847} | train loss {'Reaction outcome loss': 0.6777368688631636, 'Total loss': 0.6777368688631636}
2022-11-23 02:03:41,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:41,800 INFO:     Epoch: 96
2022-11-23 02:03:42,572 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.687064762819897, 'Total loss': 0.687064762819897} | train loss {'Reaction outcome loss': 0.7075401644716378, 'Total loss': 0.7075401644716378}
2022-11-23 02:03:42,572 INFO:     Found new best model at epoch 96
2022-11-23 02:03:42,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:42,573 INFO:     Epoch: 97
2022-11-23 02:03:43,381 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6366288065910339, 'Total loss': 0.6366288065910339} | train loss {'Reaction outcome loss': 0.6642294700449778, 'Total loss': 0.6642294700449778}
2022-11-23 02:03:43,382 INFO:     Found new best model at epoch 97
2022-11-23 02:03:43,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:43,383 INFO:     Epoch: 98
2022-11-23 02:03:44,158 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.788170878182758, 'Total loss': 0.788170878182758} | train loss {'Reaction outcome loss': 0.648387490013833, 'Total loss': 0.648387490013833}
2022-11-23 02:03:44,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:44,158 INFO:     Epoch: 99
2022-11-23 02:03:45,002 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6544039466164329, 'Total loss': 0.6544039466164329} | train loss {'Reaction outcome loss': 0.6311269390664482, 'Total loss': 0.6311269390664482}
2022-11-23 02:03:45,002 INFO:     Best model found after epoch 98 of 100.
2022-11-23 02:03:45,002 INFO:   Done with stage: TRAINING
2022-11-23 02:03:45,002 INFO:   Starting stage: EVALUATION
2022-11-23 02:03:45,127 INFO:   Done with stage: EVALUATION
2022-11-23 02:03:45,128 INFO:   Leaving out SEQ value Fold_5
2022-11-23 02:03:45,141 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:03:45,141 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:03:45,828 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:03:45,829 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:03:45,902 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:03:45,902 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:03:45,902 INFO:     No hyperparam tuning for this model
2022-11-23 02:03:45,902 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:03:45,903 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:03:45,903 INFO:     None feature selector for col prot
2022-11-23 02:03:45,904 INFO:     None feature selector for col prot
2022-11-23 02:03:45,904 INFO:     None feature selector for col prot
2022-11-23 02:03:45,904 INFO:     None feature selector for col chem
2022-11-23 02:03:45,905 INFO:     None feature selector for col chem
2022-11-23 02:03:45,905 INFO:     None feature selector for col chem
2022-11-23 02:03:45,905 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:03:45,905 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:03:45,906 INFO:     Number of params in model 168571
2022-11-23 02:03:45,910 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:03:45,910 INFO:   Starting stage: TRAINING
2022-11-23 02:03:45,968 INFO:     Val loss before train {'Reaction outcome loss': 1.0202456766908818, 'Total loss': 1.0202456766908818}
2022-11-23 02:03:45,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:45,968 INFO:     Epoch: 0
2022-11-23 02:03:46,752 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8241900666193529, 'Total loss': 0.8241900666193529} | train loss {'Reaction outcome loss': 0.8777614313098583, 'Total loss': 0.8777614313098583}
2022-11-23 02:03:46,752 INFO:     Found new best model at epoch 0
2022-11-23 02:03:46,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:46,753 INFO:     Epoch: 1
2022-11-23 02:03:47,530 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8675172281536189, 'Total loss': 0.8675172281536189} | train loss {'Reaction outcome loss': 0.8512806190773543, 'Total loss': 0.8512806190773543}
2022-11-23 02:03:47,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:47,530 INFO:     Epoch: 2
2022-11-23 02:03:48,337 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8361543444069949, 'Total loss': 0.8361543444069949} | train loss {'Reaction outcome loss': 0.8452293952466988, 'Total loss': 0.8452293952466988}
2022-11-23 02:03:48,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:48,337 INFO:     Epoch: 3
2022-11-23 02:03:49,150 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8389449546282942, 'Total loss': 0.8389449546282942} | train loss {'Reaction outcome loss': 0.8430325448935331, 'Total loss': 0.8430325448935331}
2022-11-23 02:03:49,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:49,150 INFO:     Epoch: 4
2022-11-23 02:03:49,979 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8185627934607592, 'Total loss': 0.8185627934607592} | train loss {'Reaction outcome loss': 0.8424047304068499, 'Total loss': 0.8424047304068499}
2022-11-23 02:03:49,980 INFO:     Found new best model at epoch 4
2022-11-23 02:03:49,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:49,981 INFO:     Epoch: 5
2022-11-23 02:03:50,810 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7986874370412393, 'Total loss': 0.7986874370412393} | train loss {'Reaction outcome loss': 0.8325945848395467, 'Total loss': 0.8325945848395467}
2022-11-23 02:03:50,810 INFO:     Found new best model at epoch 5
2022-11-23 02:03:50,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:50,811 INFO:     Epoch: 6
2022-11-23 02:03:51,783 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8520294658162377, 'Total loss': 0.8520294658162377} | train loss {'Reaction outcome loss': 0.8339741220961698, 'Total loss': 0.8339741220961698}
2022-11-23 02:03:51,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:51,783 INFO:     Epoch: 7
2022-11-23 02:03:53,347 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.843486336144534, 'Total loss': 0.843486336144534} | train loss {'Reaction outcome loss': 0.8286911891660227, 'Total loss': 0.8286911891660227}
2022-11-23 02:03:53,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:53,347 INFO:     Epoch: 8
2022-11-23 02:03:56,856 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8111408826979724, 'Total loss': 0.8111408826979724} | train loss {'Reaction outcome loss': 0.8347409661964849, 'Total loss': 0.8347409661964849}
2022-11-23 02:03:56,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:03:56,856 INFO:     Epoch: 9
2022-11-23 02:04:00,776 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8121731721542098, 'Total loss': 0.8121731721542098} | train loss {'Reaction outcome loss': 0.8348345056719143, 'Total loss': 0.8348345056719143}
2022-11-23 02:04:00,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:00,776 INFO:     Epoch: 10
2022-11-23 02:04:02,820 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.80826732177626, 'Total loss': 0.80826732177626} | train loss {'Reaction outcome loss': 0.8369330258263268, 'Total loss': 0.8369330258263268}
2022-11-23 02:04:02,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:02,821 INFO:     Epoch: 11
2022-11-23 02:04:05,910 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8201812390576709, 'Total loss': 0.8201812390576709} | train loss {'Reaction outcome loss': 0.827422410852996, 'Total loss': 0.827422410852996}
2022-11-23 02:04:05,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:05,911 INFO:     Epoch: 12
2022-11-23 02:04:07,207 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8017106516794725, 'Total loss': 0.8017106516794725} | train loss {'Reaction outcome loss': 0.8228724019579318, 'Total loss': 0.8228724019579318}
2022-11-23 02:04:07,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:07,208 INFO:     Epoch: 13
2022-11-23 02:04:07,952 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8335114182396368, 'Total loss': 0.8335114182396368} | train loss {'Reaction outcome loss': 0.8237068397313477, 'Total loss': 0.8237068397313477}
2022-11-23 02:04:07,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:07,952 INFO:     Epoch: 14
2022-11-23 02:04:08,763 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8047726059501822, 'Total loss': 0.8047726059501822} | train loss {'Reaction outcome loss': 0.8244563710351704, 'Total loss': 0.8244563710351704}
2022-11-23 02:04:08,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:08,763 INFO:     Epoch: 15
2022-11-23 02:04:09,587 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8161577555266294, 'Total loss': 0.8161577555266294} | train loss {'Reaction outcome loss': 0.8194648905200996, 'Total loss': 0.8194648905200996}
2022-11-23 02:04:09,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:09,587 INFO:     Epoch: 16
2022-11-23 02:04:10,386 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8101882230151783, 'Total loss': 0.8101882230151783} | train loss {'Reaction outcome loss': 0.8206908915056149, 'Total loss': 0.8206908915056149}
2022-11-23 02:04:10,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:10,387 INFO:     Epoch: 17
2022-11-23 02:04:11,202 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8213828246701848, 'Total loss': 0.8213828246701848} | train loss {'Reaction outcome loss': 0.8171064985184534, 'Total loss': 0.8171064985184534}
2022-11-23 02:04:11,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:11,202 INFO:     Epoch: 18
2022-11-23 02:04:12,065 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8475224429910834, 'Total loss': 0.8475224429910834} | train loss {'Reaction outcome loss': 0.814970539769663, 'Total loss': 0.814970539769663}
2022-11-23 02:04:12,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:12,066 INFO:     Epoch: 19
2022-11-23 02:04:12,867 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7984008565545082, 'Total loss': 0.7984008565545082} | train loss {'Reaction outcome loss': 0.819214759748957, 'Total loss': 0.819214759748957}
2022-11-23 02:04:12,868 INFO:     Found new best model at epoch 19
2022-11-23 02:04:12,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:12,869 INFO:     Epoch: 20
2022-11-23 02:04:13,722 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8049581592733209, 'Total loss': 0.8049581592733209} | train loss {'Reaction outcome loss': 0.8217637835726564, 'Total loss': 0.8217637835726564}
2022-11-23 02:04:13,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:13,723 INFO:     Epoch: 21
2022-11-23 02:04:14,544 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.825172750109976, 'Total loss': 0.825172750109976} | train loss {'Reaction outcome loss': 0.8218745133172163, 'Total loss': 0.8218745133172163}
2022-11-23 02:04:14,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:14,544 INFO:     Epoch: 22
2022-11-23 02:04:15,394 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7873367646878416, 'Total loss': 0.7873367646878416} | train loss {'Reaction outcome loss': 0.8170181853085877, 'Total loss': 0.8170181853085877}
2022-11-23 02:04:15,394 INFO:     Found new best model at epoch 22
2022-11-23 02:04:15,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:15,395 INFO:     Epoch: 23
2022-11-23 02:04:16,213 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8204794187437404, 'Total loss': 0.8204794187437404} | train loss {'Reaction outcome loss': 0.820799167098304, 'Total loss': 0.820799167098304}
2022-11-23 02:04:16,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:16,213 INFO:     Epoch: 24
2022-11-23 02:04:17,046 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8338650356639515, 'Total loss': 0.8338650356639515} | train loss {'Reaction outcome loss': 0.8154330411058689, 'Total loss': 0.8154330411058689}
2022-11-23 02:04:17,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:17,047 INFO:     Epoch: 25
2022-11-23 02:04:17,878 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8040872812271118, 'Total loss': 0.8040872812271118} | train loss {'Reaction outcome loss': 0.8201086582683841, 'Total loss': 0.8201086582683841}
2022-11-23 02:04:17,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:17,879 INFO:     Epoch: 26
2022-11-23 02:04:18,685 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8157213526693258, 'Total loss': 0.8157213526693258} | train loss {'Reaction outcome loss': 0.8156054881420213, 'Total loss': 0.8156054881420213}
2022-11-23 02:04:18,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:18,685 INFO:     Epoch: 27
2022-11-23 02:04:19,524 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8323815776543184, 'Total loss': 0.8323815776543184} | train loss {'Reaction outcome loss': 0.8214492459408185, 'Total loss': 0.8214492459408185}
2022-11-23 02:04:19,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:19,525 INFO:     Epoch: 28
2022-11-23 02:04:20,358 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8344914201985706, 'Total loss': 0.8344914201985706} | train loss {'Reaction outcome loss': 0.8199929067269269, 'Total loss': 0.8199929067269269}
2022-11-23 02:04:20,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:20,360 INFO:     Epoch: 29
2022-11-23 02:04:21,219 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8244809095155109, 'Total loss': 0.8244809095155109} | train loss {'Reaction outcome loss': 0.817908105821262, 'Total loss': 0.817908105821262}
2022-11-23 02:04:21,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:21,219 INFO:     Epoch: 30
2022-11-23 02:04:22,039 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8187691034241156, 'Total loss': 0.8187691034241156} | train loss {'Reaction outcome loss': 0.8145254013026774, 'Total loss': 0.8145254013026774}
2022-11-23 02:04:22,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:22,039 INFO:     Epoch: 31
2022-11-23 02:04:22,827 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7999233020977541, 'Total loss': 0.7999233020977541} | train loss {'Reaction outcome loss': 0.820468129416709, 'Total loss': 0.820468129416709}
2022-11-23 02:04:22,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:22,827 INFO:     Epoch: 32
2022-11-23 02:04:23,657 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7967620647766374, 'Total loss': 0.7967620647766374} | train loss {'Reaction outcome loss': 0.8187197043224868, 'Total loss': 0.8187197043224868}
2022-11-23 02:04:23,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:23,657 INFO:     Epoch: 33
2022-11-23 02:04:24,440 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8043832358988848, 'Total loss': 0.8043832358988848} | train loss {'Reaction outcome loss': 0.8247486295005088, 'Total loss': 0.8247486295005088}
2022-11-23 02:04:24,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:24,440 INFO:     Epoch: 34
2022-11-23 02:04:25,238 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8219653327356685, 'Total loss': 0.8219653327356685} | train loss {'Reaction outcome loss': 0.8210210521452823, 'Total loss': 0.8210210521452823}
2022-11-23 02:04:25,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:25,238 INFO:     Epoch: 35
2022-11-23 02:04:26,006 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7946359237486665, 'Total loss': 0.7946359237486665} | train loss {'Reaction outcome loss': 0.8140365519986944, 'Total loss': 0.8140365519986944}
2022-11-23 02:04:26,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:26,006 INFO:     Epoch: 36
2022-11-23 02:04:26,768 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8079933436079458, 'Total loss': 0.8079933436079458} | train loss {'Reaction outcome loss': 0.8217809770995306, 'Total loss': 0.8217809770995306}
2022-11-23 02:04:26,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:26,769 INFO:     Epoch: 37
2022-11-23 02:04:27,554 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8029356869784269, 'Total loss': 0.8029356869784269} | train loss {'Reaction outcome loss': 0.8217687344985453, 'Total loss': 0.8217687344985453}
2022-11-23 02:04:27,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:27,554 INFO:     Epoch: 38
2022-11-23 02:04:28,385 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.819266598333012, 'Total loss': 0.819266598333012} | train loss {'Reaction outcome loss': 0.821821482919971, 'Total loss': 0.821821482919971}
2022-11-23 02:04:28,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:28,385 INFO:     Epoch: 39
2022-11-23 02:04:29,193 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8374983749606393, 'Total loss': 0.8374983749606393} | train loss {'Reaction outcome loss': 0.8157310250558352, 'Total loss': 0.8157310250558352}
2022-11-23 02:04:29,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:29,193 INFO:     Epoch: 40
2022-11-23 02:04:30,026 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8118873218243773, 'Total loss': 0.8118873218243773} | train loss {'Reaction outcome loss': 0.8190450203201549, 'Total loss': 0.8190450203201549}
2022-11-23 02:04:30,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:30,027 INFO:     Epoch: 41
2022-11-23 02:04:30,825 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8088777315887538, 'Total loss': 0.8088777315887538} | train loss {'Reaction outcome loss': 0.8147949301128686, 'Total loss': 0.8147949301128686}
2022-11-23 02:04:30,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:30,825 INFO:     Epoch: 42
2022-11-23 02:04:31,619 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7862609536810354, 'Total loss': 0.7862609536810354} | train loss {'Reaction outcome loss': 0.8190393621622309, 'Total loss': 0.8190393621622309}
2022-11-23 02:04:31,619 INFO:     Found new best model at epoch 42
2022-11-23 02:04:31,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:31,620 INFO:     Epoch: 43
2022-11-23 02:04:32,423 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7781858119097623, 'Total loss': 0.7781858119097623} | train loss {'Reaction outcome loss': 0.8161687684445246, 'Total loss': 0.8161687684445246}
2022-11-23 02:04:32,424 INFO:     Found new best model at epoch 43
2022-11-23 02:04:32,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:32,425 INFO:     Epoch: 44
2022-11-23 02:04:33,198 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8015104694799944, 'Total loss': 0.8015104694799944} | train loss {'Reaction outcome loss': 0.8233247967625437, 'Total loss': 0.8233247967625437}
2022-11-23 02:04:33,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:33,198 INFO:     Epoch: 45
2022-11-23 02:04:33,979 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8160838396711783, 'Total loss': 0.8160838396711783} | train loss {'Reaction outcome loss': 0.819336333858822, 'Total loss': 0.819336333858822}
2022-11-23 02:04:33,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:33,979 INFO:     Epoch: 46
2022-11-23 02:04:34,760 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8071351986039769, 'Total loss': 0.8071351986039769} | train loss {'Reaction outcome loss': 0.8205014657877717, 'Total loss': 0.8205014657877717}
2022-11-23 02:04:34,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:34,760 INFO:     Epoch: 47
2022-11-23 02:04:35,569 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8151391507549719, 'Total loss': 0.8151391507549719} | train loss {'Reaction outcome loss': 0.8160881879117324, 'Total loss': 0.8160881879117324}
2022-11-23 02:04:35,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:35,569 INFO:     Epoch: 48
2022-11-23 02:04:36,365 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8113409666852518, 'Total loss': 0.8113409666852518} | train loss {'Reaction outcome loss': 0.8147555333882691, 'Total loss': 0.8147555333882691}
2022-11-23 02:04:36,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:36,365 INFO:     Epoch: 49
2022-11-23 02:04:37,140 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8538584302772175, 'Total loss': 0.8538584302772175} | train loss {'Reaction outcome loss': 0.82611737692887, 'Total loss': 0.82611737692887}
2022-11-23 02:04:37,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:37,140 INFO:     Epoch: 50
2022-11-23 02:04:37,944 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8074856170199134, 'Total loss': 0.8074856170199134} | train loss {'Reaction outcome loss': 0.8216179773090821, 'Total loss': 0.8216179773090821}
2022-11-23 02:04:37,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:37,944 INFO:     Epoch: 51
2022-11-23 02:04:38,753 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7945254776965488, 'Total loss': 0.7945254776965488} | train loss {'Reaction outcome loss': 0.814961024382819, 'Total loss': 0.814961024382819}
2022-11-23 02:04:38,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:38,753 INFO:     Epoch: 52
2022-11-23 02:04:39,529 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8359083126891743, 'Total loss': 0.8359083126891743} | train loss {'Reaction outcome loss': 0.8168692968876256, 'Total loss': 0.8168692968876256}
2022-11-23 02:04:39,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:39,530 INFO:     Epoch: 53
2022-11-23 02:04:40,300 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8510876243764703, 'Total loss': 0.8510876243764703} | train loss {'Reaction outcome loss': 0.8171004749653552, 'Total loss': 0.8171004749653552}
2022-11-23 02:04:40,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:40,300 INFO:     Epoch: 54
2022-11-23 02:04:41,056 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8013158589601517, 'Total loss': 0.8013158589601517} | train loss {'Reaction outcome loss': 0.8153348518045325, 'Total loss': 0.8153348518045325}
2022-11-23 02:04:41,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:41,056 INFO:     Epoch: 55
2022-11-23 02:04:41,825 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7991628877141259, 'Total loss': 0.7991628877141259} | train loss {'Reaction outcome loss': 0.8195367225027277, 'Total loss': 0.8195367225027277}
2022-11-23 02:04:41,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:41,826 INFO:     Epoch: 56
2022-11-23 02:04:42,652 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8096705119718205, 'Total loss': 0.8096705119718205} | train loss {'Reaction outcome loss': 0.8178123256214235, 'Total loss': 0.8178123256214235}
2022-11-23 02:04:42,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:42,653 INFO:     Epoch: 57
2022-11-23 02:04:43,580 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8222098824652758, 'Total loss': 0.8222098824652758} | train loss {'Reaction outcome loss': 0.8167585203280816, 'Total loss': 0.8167585203280816}
2022-11-23 02:04:43,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:43,580 INFO:     Epoch: 58
2022-11-23 02:04:44,357 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8273639286106284, 'Total loss': 0.8273639286106284} | train loss {'Reaction outcome loss': 0.8159200279909348, 'Total loss': 0.8159200279909348}
2022-11-23 02:04:44,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:44,358 INFO:     Epoch: 59
2022-11-23 02:04:45,193 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.816576554693959, 'Total loss': 0.816576554693959} | train loss {'Reaction outcome loss': 0.8156491896884162, 'Total loss': 0.8156491896884162}
2022-11-23 02:04:45,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:45,194 INFO:     Epoch: 60
2022-11-23 02:04:46,028 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8503962402993982, 'Total loss': 0.8503962402993982} | train loss {'Reaction outcome loss': 0.8190370503707454, 'Total loss': 0.8190370503707454}
2022-11-23 02:04:46,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:46,028 INFO:     Epoch: 61
2022-11-23 02:04:46,794 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.798394961790605, 'Total loss': 0.798394961790605} | train loss {'Reaction outcome loss': 0.821517276468306, 'Total loss': 0.821517276468306}
2022-11-23 02:04:46,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:46,794 INFO:     Epoch: 62
2022-11-23 02:04:47,570 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8430275388739326, 'Total loss': 0.8430275388739326} | train loss {'Reaction outcome loss': 0.8175176990176984, 'Total loss': 0.8175176990176984}
2022-11-23 02:04:47,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:47,570 INFO:     Epoch: 63
2022-11-23 02:04:48,350 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8022183003750715, 'Total loss': 0.8022183003750715} | train loss {'Reaction outcome loss': 0.8198382253588935, 'Total loss': 0.8198382253588935}
2022-11-23 02:04:48,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:48,350 INFO:     Epoch: 64
2022-11-23 02:04:49,150 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7974458526481282, 'Total loss': 0.7974458526481282} | train loss {'Reaction outcome loss': 0.8113164987399993, 'Total loss': 0.8113164987399993}
2022-11-23 02:04:49,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:49,151 INFO:     Epoch: 65
2022-11-23 02:04:49,945 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8028821091760289, 'Total loss': 0.8028821091760289} | train loss {'Reaction outcome loss': 0.813221388801872, 'Total loss': 0.813221388801872}
2022-11-23 02:04:49,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:49,948 INFO:     Epoch: 66
2022-11-23 02:04:50,747 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7923961566253142, 'Total loss': 0.7923961566253142} | train loss {'Reaction outcome loss': 0.8164007512905337, 'Total loss': 0.8164007512905337}
2022-11-23 02:04:50,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:50,747 INFO:     Epoch: 67
2022-11-23 02:04:51,548 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7925120226361535, 'Total loss': 0.7925120226361535} | train loss {'Reaction outcome loss': 0.8186131021995776, 'Total loss': 0.8186131021995776}
2022-11-23 02:04:51,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:51,549 INFO:     Epoch: 68
2022-11-23 02:04:52,314 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8052397681908174, 'Total loss': 0.8052397681908174} | train loss {'Reaction outcome loss': 0.8102631226543956, 'Total loss': 0.8102631226543956}
2022-11-23 02:04:52,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:52,314 INFO:     Epoch: 69
2022-11-23 02:04:53,122 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8084449923851273, 'Total loss': 0.8084449923851273} | train loss {'Reaction outcome loss': 0.8098024054456819, 'Total loss': 0.8098024054456819}
2022-11-23 02:04:53,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:53,123 INFO:     Epoch: 70
2022-11-23 02:04:53,949 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8085951100696217, 'Total loss': 0.8085951100696217} | train loss {'Reaction outcome loss': 0.8124985943740679, 'Total loss': 0.8124985943740679}
2022-11-23 02:04:53,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:53,949 INFO:     Epoch: 71
2022-11-23 02:04:54,741 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8101589462973855, 'Total loss': 0.8101589462973855} | train loss {'Reaction outcome loss': 0.8184788749526869, 'Total loss': 0.8184788749526869}
2022-11-23 02:04:54,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:54,741 INFO:     Epoch: 72
2022-11-23 02:04:55,578 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8050529645247892, 'Total loss': 0.8050529645247892} | train loss {'Reaction outcome loss': 0.8149276274418541, 'Total loss': 0.8149276274418541}
2022-11-23 02:04:55,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:55,579 INFO:     Epoch: 73
2022-11-23 02:04:56,381 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7976838898929682, 'Total loss': 0.7976838898929682} | train loss {'Reaction outcome loss': 0.8221404915637816, 'Total loss': 0.8221404915637816}
2022-11-23 02:04:56,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:56,381 INFO:     Epoch: 74
2022-11-23 02:04:57,189 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7932553243908015, 'Total loss': 0.7932553243908015} | train loss {'Reaction outcome loss': 0.8221522619125814, 'Total loss': 0.8221522619125814}
2022-11-23 02:04:57,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:57,189 INFO:     Epoch: 75
2022-11-23 02:04:58,023 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.796056720343503, 'Total loss': 0.796056720343503} | train loss {'Reaction outcome loss': 0.8114632164177141, 'Total loss': 0.8114632164177141}
2022-11-23 02:04:58,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:58,023 INFO:     Epoch: 76
2022-11-23 02:04:58,812 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8052166239781813, 'Total loss': 0.8052166239781813} | train loss {'Reaction outcome loss': 0.8119223068358927, 'Total loss': 0.8119223068358927}
2022-11-23 02:04:58,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:58,812 INFO:     Epoch: 77
2022-11-23 02:04:59,660 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8098528920249506, 'Total loss': 0.8098528920249506} | train loss {'Reaction outcome loss': 0.8088855839933944, 'Total loss': 0.8088855839933944}
2022-11-23 02:04:59,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:04:59,660 INFO:     Epoch: 78
2022-11-23 02:05:00,498 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7915714566003192, 'Total loss': 0.7915714566003192} | train loss {'Reaction outcome loss': 0.8180509374933205, 'Total loss': 0.8180509374933205}
2022-11-23 02:05:00,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:00,500 INFO:     Epoch: 79
2022-11-23 02:05:01,291 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8254287703470751, 'Total loss': 0.8254287703470751} | train loss {'Reaction outcome loss': 0.8108311809358085, 'Total loss': 0.8108311809358085}
2022-11-23 02:05:01,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:01,291 INFO:     Epoch: 80
2022-11-23 02:05:02,070 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8537732125683264, 'Total loss': 0.8537732125683264} | train loss {'Reaction outcome loss': 0.8161756607443698, 'Total loss': 0.8161756607443698}
2022-11-23 02:05:02,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:02,071 INFO:     Epoch: 81
2022-11-23 02:05:02,873 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8256592967293479, 'Total loss': 0.8256592967293479} | train loss {'Reaction outcome loss': 0.8246966210695413, 'Total loss': 0.8246966210695413}
2022-11-23 02:05:02,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:02,874 INFO:     Epoch: 82
2022-11-23 02:05:03,683 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.808116773312742, 'Total loss': 0.808116773312742} | train loss {'Reaction outcome loss': 0.8176365191878577, 'Total loss': 0.8176365191878577}
2022-11-23 02:05:03,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:03,683 INFO:     Epoch: 83
2022-11-23 02:05:04,489 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8303961171345278, 'Total loss': 0.8303961171345278} | train loss {'Reaction outcome loss': 0.8096779251267553, 'Total loss': 0.8096779251267553}
2022-11-23 02:05:04,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:04,489 INFO:     Epoch: 84
2022-11-23 02:05:05,302 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8059376796538179, 'Total loss': 0.8059376796538179} | train loss {'Reaction outcome loss': 0.8135879503087959, 'Total loss': 0.8135879503087959}
2022-11-23 02:05:05,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:05,302 INFO:     Epoch: 85
2022-11-23 02:05:06,113 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8148742683909156, 'Total loss': 0.8148742683909156} | train loss {'Reaction outcome loss': 0.8167253552902083, 'Total loss': 0.8167253552902083}
2022-11-23 02:05:06,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:06,115 INFO:     Epoch: 86
2022-11-23 02:05:06,950 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7953130792487751, 'Total loss': 0.7953130792487751} | train loss {'Reaction outcome loss': 0.8151947468639869, 'Total loss': 0.8151947468639869}
2022-11-23 02:05:06,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:06,950 INFO:     Epoch: 87
2022-11-23 02:05:07,772 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7957973331212997, 'Total loss': 0.7957973331212997} | train loss {'Reaction outcome loss': 0.8153464018333296, 'Total loss': 0.8153464018333296}
2022-11-23 02:05:07,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:07,772 INFO:     Epoch: 88
2022-11-23 02:05:08,621 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.81392790986733, 'Total loss': 0.81392790986733} | train loss {'Reaction outcome loss': 0.8204785280140788, 'Total loss': 0.8204785280140788}
2022-11-23 02:05:08,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:08,621 INFO:     Epoch: 89
2022-11-23 02:05:09,455 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7974946268580176, 'Total loss': 0.7974946268580176} | train loss {'Reaction outcome loss': 0.8153648564690038, 'Total loss': 0.8153648564690038}
2022-11-23 02:05:09,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:09,456 INFO:     Epoch: 90
2022-11-23 02:05:10,228 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7970742312344637, 'Total loss': 0.7970742312344637} | train loss {'Reaction outcome loss': 0.8117014096092116, 'Total loss': 0.8117014096092116}
2022-11-23 02:05:10,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:10,229 INFO:     Epoch: 91
2022-11-23 02:05:11,019 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8189459659836509, 'Total loss': 0.8189459659836509} | train loss {'Reaction outcome loss': 0.8135068592453293, 'Total loss': 0.8135068592453293}
2022-11-23 02:05:11,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:11,019 INFO:     Epoch: 92
2022-11-23 02:05:11,835 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.830576944080266, 'Total loss': 0.830576944080266} | train loss {'Reaction outcome loss': 0.8168132267741539, 'Total loss': 0.8168132267741539}
2022-11-23 02:05:11,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:11,836 INFO:     Epoch: 93
2022-11-23 02:05:12,665 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7854150120507587, 'Total loss': 0.7854150120507587} | train loss {'Reaction outcome loss': 0.8131597994370499, 'Total loss': 0.8131597994370499}
2022-11-23 02:05:12,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:12,665 INFO:     Epoch: 94
2022-11-23 02:05:13,458 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.800618053837256, 'Total loss': 0.800618053837256} | train loss {'Reaction outcome loss': 0.8120002692286302, 'Total loss': 0.8120002692286302}
2022-11-23 02:05:13,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:13,459 INFO:     Epoch: 95
2022-11-23 02:05:14,255 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7991164746609601, 'Total loss': 0.7991164746609601} | train loss {'Reaction outcome loss': 0.8208285482064915, 'Total loss': 0.8208285482064915}
2022-11-23 02:05:14,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:14,255 INFO:     Epoch: 96
2022-11-23 02:05:15,044 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8378654203631661, 'Total loss': 0.8378654203631661} | train loss {'Reaction outcome loss': 0.8100064570604548, 'Total loss': 0.8100064570604548}
2022-11-23 02:05:15,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:15,045 INFO:     Epoch: 97
2022-11-23 02:05:15,886 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8321464623917233, 'Total loss': 0.8321464623917233} | train loss {'Reaction outcome loss': 0.8116039029258465, 'Total loss': 0.8116039029258465}
2022-11-23 02:05:15,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:15,887 INFO:     Epoch: 98
2022-11-23 02:05:16,742 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8361935981295325, 'Total loss': 0.8361935981295325} | train loss {'Reaction outcome loss': 0.815291197917722, 'Total loss': 0.815291197917722}
2022-11-23 02:05:16,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:16,742 INFO:     Epoch: 99
2022-11-23 02:05:17,567 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7901262207464739, 'Total loss': 0.7901262207464739} | train loss {'Reaction outcome loss': 0.8081005363449877, 'Total loss': 0.8081005363449877}
2022-11-23 02:05:17,568 INFO:     Best model found after epoch 44 of 100.
2022-11-23 02:05:17,568 INFO:   Done with stage: TRAINING
2022-11-23 02:05:17,568 INFO:   Starting stage: EVALUATION
2022-11-23 02:05:17,693 INFO:   Done with stage: EVALUATION
2022-11-23 02:05:17,695 INFO:   Leaving out SEQ value Fold_6
2022-11-23 02:05:17,708 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:05:17,708 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:05:18,387 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:05:18,388 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:05:18,461 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:05:18,461 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:05:18,461 INFO:     No hyperparam tuning for this model
2022-11-23 02:05:18,461 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:05:18,461 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:05:18,462 INFO:     None feature selector for col prot
2022-11-23 02:05:18,462 INFO:     None feature selector for col prot
2022-11-23 02:05:18,462 INFO:     None feature selector for col prot
2022-11-23 02:05:18,463 INFO:     None feature selector for col chem
2022-11-23 02:05:18,463 INFO:     None feature selector for col chem
2022-11-23 02:05:18,464 INFO:     None feature selector for col chem
2022-11-23 02:05:18,464 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:05:18,464 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:05:18,465 INFO:     Number of params in model 168571
2022-11-23 02:05:18,469 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:05:18,469 INFO:   Starting stage: TRAINING
2022-11-23 02:05:18,527 INFO:     Val loss before train {'Reaction outcome loss': 1.0106230486523022, 'Total loss': 1.0106230486523022}
2022-11-23 02:05:18,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:18,527 INFO:     Epoch: 0
2022-11-23 02:05:19,350 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8744613541798159, 'Total loss': 0.8744613541798159} | train loss {'Reaction outcome loss': 0.8789105248307029, 'Total loss': 0.8789105248307029}
2022-11-23 02:05:19,350 INFO:     Found new best model at epoch 0
2022-11-23 02:05:19,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:19,351 INFO:     Epoch: 1
2022-11-23 02:05:20,144 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8270692303776741, 'Total loss': 0.8270692303776741} | train loss {'Reaction outcome loss': 0.8511594187828803, 'Total loss': 0.8511594187828803}
2022-11-23 02:05:20,144 INFO:     Found new best model at epoch 1
2022-11-23 02:05:20,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:20,145 INFO:     Epoch: 2
2022-11-23 02:05:20,926 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8544441563161936, 'Total loss': 0.8544441563161936} | train loss {'Reaction outcome loss': 0.8478486396131977, 'Total loss': 0.8478486396131977}
2022-11-23 02:05:20,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:20,926 INFO:     Epoch: 3
2022-11-23 02:05:21,772 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8487912944772027, 'Total loss': 0.8487912944772027} | train loss {'Reaction outcome loss': 0.8458783000467285, 'Total loss': 0.8458783000467285}
2022-11-23 02:05:21,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:21,773 INFO:     Epoch: 4
2022-11-23 02:05:22,600 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8200267350131815, 'Total loss': 0.8200267350131815} | train loss {'Reaction outcome loss': 0.8416542219779184, 'Total loss': 0.8416542219779184}
2022-11-23 02:05:22,600 INFO:     Found new best model at epoch 4
2022-11-23 02:05:22,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:22,601 INFO:     Epoch: 5
2022-11-23 02:05:23,411 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8275815695524216, 'Total loss': 0.8275815695524216} | train loss {'Reaction outcome loss': 0.8318864969957259, 'Total loss': 0.8318864969957259}
2022-11-23 02:05:23,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:23,413 INFO:     Epoch: 6
2022-11-23 02:05:24,221 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8361559205434539, 'Total loss': 0.8361559205434539} | train loss {'Reaction outcome loss': 0.8338496169495967, 'Total loss': 0.8338496169495967}
2022-11-23 02:05:24,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:24,221 INFO:     Epoch: 7
2022-11-23 02:05:25,092 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8147255480289459, 'Total loss': 0.8147255480289459} | train loss {'Reaction outcome loss': 0.8396155180469635, 'Total loss': 0.8396155180469635}
2022-11-23 02:05:25,092 INFO:     Found new best model at epoch 7
2022-11-23 02:05:25,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:25,093 INFO:     Epoch: 8
2022-11-23 02:05:25,977 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8143111589280042, 'Total loss': 0.8143111589280042} | train loss {'Reaction outcome loss': 0.8280918023759319, 'Total loss': 0.8280918023759319}
2022-11-23 02:05:25,978 INFO:     Found new best model at epoch 8
2022-11-23 02:05:25,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:25,979 INFO:     Epoch: 9
2022-11-23 02:05:26,755 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8337895680557598, 'Total loss': 0.8337895680557598} | train loss {'Reaction outcome loss': 0.8239056936675503, 'Total loss': 0.8239056936675503}
2022-11-23 02:05:26,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:26,756 INFO:     Epoch: 10
2022-11-23 02:05:27,572 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8292288224805485, 'Total loss': 0.8292288224805485} | train loss {'Reaction outcome loss': 0.8257249361805378, 'Total loss': 0.8257249361805378}
2022-11-23 02:05:27,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:27,572 INFO:     Epoch: 11
2022-11-23 02:05:28,354 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8251550414345481, 'Total loss': 0.8251550414345481} | train loss {'Reaction outcome loss': 0.8262716907887689, 'Total loss': 0.8262716907887689}
2022-11-23 02:05:28,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:28,354 INFO:     Epoch: 12
2022-11-23 02:05:29,164 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8394658077846874, 'Total loss': 0.8394658077846874} | train loss {'Reaction outcome loss': 0.826955423840592, 'Total loss': 0.826955423840592}
2022-11-23 02:05:29,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:29,165 INFO:     Epoch: 13
2022-11-23 02:05:30,000 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8304688043215058, 'Total loss': 0.8304688043215058} | train loss {'Reaction outcome loss': 0.8273559343670646, 'Total loss': 0.8273559343670646}
2022-11-23 02:05:30,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:30,000 INFO:     Epoch: 14
2022-11-23 02:05:30,822 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8259403204376047, 'Total loss': 0.8259403204376047} | train loss {'Reaction outcome loss': 0.8188004825384386, 'Total loss': 0.8188004825384386}
2022-11-23 02:05:30,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:30,822 INFO:     Epoch: 15
2022-11-23 02:05:31,658 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8097023537213152, 'Total loss': 0.8097023537213152} | train loss {'Reaction outcome loss': 0.8252950617142262, 'Total loss': 0.8252950617142262}
2022-11-23 02:05:31,658 INFO:     Found new best model at epoch 15
2022-11-23 02:05:31,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:31,659 INFO:     Epoch: 16
2022-11-23 02:05:32,487 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8118537434122779, 'Total loss': 0.8118537434122779} | train loss {'Reaction outcome loss': 0.8226068043300221, 'Total loss': 0.8226068043300221}
2022-11-23 02:05:32,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:32,487 INFO:     Epoch: 17
2022-11-23 02:05:33,260 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8114262209697203, 'Total loss': 0.8114262209697203} | train loss {'Reaction outcome loss': 0.8241152065175195, 'Total loss': 0.8241152065175195}
2022-11-23 02:05:33,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:33,260 INFO:     Epoch: 18
2022-11-23 02:05:34,054 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8302055597305298, 'Total loss': 0.8302055597305298} | train loss {'Reaction outcome loss': 0.8277433652791285, 'Total loss': 0.8277433652791285}
2022-11-23 02:05:34,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:34,054 INFO:     Epoch: 19
2022-11-23 02:05:35,270 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8108812888914888, 'Total loss': 0.8108812888914888} | train loss {'Reaction outcome loss': 0.8179069612055055, 'Total loss': 0.8179069612055055}
2022-11-23 02:05:35,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:35,274 INFO:     Epoch: 20
2022-11-23 02:05:36,525 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8457867604765025, 'Total loss': 0.8457867604765025} | train loss {'Reaction outcome loss': 0.8293279528377517, 'Total loss': 0.8293279528377517}
2022-11-23 02:05:36,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:36,527 INFO:     Epoch: 21
2022-11-23 02:05:37,804 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8237643837928772, 'Total loss': 0.8237643837928772} | train loss {'Reaction outcome loss': 0.8224308274445995, 'Total loss': 0.8224308274445995}
2022-11-23 02:05:37,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:37,805 INFO:     Epoch: 22
2022-11-23 02:05:39,087 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8197460526769812, 'Total loss': 0.8197460526769812} | train loss {'Reaction outcome loss': 0.8229487862798476, 'Total loss': 0.8229487862798476}
2022-11-23 02:05:39,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:39,087 INFO:     Epoch: 23
2022-11-23 02:05:40,407 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8313318274237893, 'Total loss': 0.8313318274237893} | train loss {'Reaction outcome loss': 0.8200889967622296, 'Total loss': 0.8200889967622296}
2022-11-23 02:05:40,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:40,409 INFO:     Epoch: 24
2022-11-23 02:05:41,438 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8308539343151179, 'Total loss': 0.8308539343151179} | train loss {'Reaction outcome loss': 0.8235702115681863, 'Total loss': 0.8235702115681863}
2022-11-23 02:05:41,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:41,439 INFO:     Epoch: 25
2022-11-23 02:05:42,480 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8165429959242995, 'Total loss': 0.8165429959242995} | train loss {'Reaction outcome loss': 0.8199736579291282, 'Total loss': 0.8199736579291282}
2022-11-23 02:05:42,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:42,481 INFO:     Epoch: 26
2022-11-23 02:05:43,526 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8234038332646544, 'Total loss': 0.8234038332646544} | train loss {'Reaction outcome loss': 0.8199575214136031, 'Total loss': 0.8199575214136031}
2022-11-23 02:05:43,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:43,526 INFO:     Epoch: 27
2022-11-23 02:05:44,572 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8177357045086947, 'Total loss': 0.8177357045086947} | train loss {'Reaction outcome loss': 0.8186644416662955, 'Total loss': 0.8186644416662955}
2022-11-23 02:05:44,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:44,572 INFO:     Epoch: 28
2022-11-23 02:05:45,603 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8129688183015044, 'Total loss': 0.8129688183015044} | train loss {'Reaction outcome loss': 0.8225331304054107, 'Total loss': 0.8225331304054107}
2022-11-23 02:05:45,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:45,605 INFO:     Epoch: 29
2022-11-23 02:05:46,652 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8274767927148126, 'Total loss': 0.8274767927148126} | train loss {'Reaction outcome loss': 0.8175668426819386, 'Total loss': 0.8175668426819386}
2022-11-23 02:05:46,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:46,654 INFO:     Epoch: 30
2022-11-23 02:05:47,693 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8106577877293933, 'Total loss': 0.8106577877293933} | train loss {'Reaction outcome loss': 0.8210770838683651, 'Total loss': 0.8210770838683651}
2022-11-23 02:05:47,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:47,694 INFO:     Epoch: 31
2022-11-23 02:05:49,093 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8285910460081968, 'Total loss': 0.8285910460081968} | train loss {'Reaction outcome loss': 0.8250664764594647, 'Total loss': 0.8250664764594647}
2022-11-23 02:05:49,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:49,093 INFO:     Epoch: 32
2022-11-23 02:05:50,275 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8188826096328822, 'Total loss': 0.8188826096328822} | train loss {'Reaction outcome loss': 0.8156256881212035, 'Total loss': 0.8156256881212035}
2022-11-23 02:05:50,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:50,276 INFO:     Epoch: 33
2022-11-23 02:05:51,450 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.829908391291445, 'Total loss': 0.829908391291445} | train loss {'Reaction outcome loss': 0.8186947785077556, 'Total loss': 0.8186947785077556}
2022-11-23 02:05:51,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:51,451 INFO:     Epoch: 34
2022-11-23 02:05:52,502 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8096360875801607, 'Total loss': 0.8096360875801607} | train loss {'Reaction outcome loss': 0.8221650360332381, 'Total loss': 0.8221650360332381}
2022-11-23 02:05:52,505 INFO:     Found new best model at epoch 34
2022-11-23 02:05:52,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:52,507 INFO:     Epoch: 35
2022-11-23 02:05:53,557 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8147694624283097, 'Total loss': 0.8147694624283097} | train loss {'Reaction outcome loss': 0.8244444254425264, 'Total loss': 0.8244444254425264}
2022-11-23 02:05:53,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:53,559 INFO:     Epoch: 36
2022-11-23 02:05:54,579 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8230798671191389, 'Total loss': 0.8230798671191389} | train loss {'Reaction outcome loss': 0.8195486447263148, 'Total loss': 0.8195486447263148}
2022-11-23 02:05:54,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:54,580 INFO:     Epoch: 37
2022-11-23 02:05:55,615 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8099571391940117, 'Total loss': 0.8099571391940117} | train loss {'Reaction outcome loss': 0.8197300178149054, 'Total loss': 0.8197300178149054}
2022-11-23 02:05:55,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:55,617 INFO:     Epoch: 38
2022-11-23 02:05:56,656 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8148677985776555, 'Total loss': 0.8148677985776555} | train loss {'Reaction outcome loss': 0.8189299867278145, 'Total loss': 0.8189299867278145}
2022-11-23 02:05:56,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:56,656 INFO:     Epoch: 39
2022-11-23 02:05:57,772 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8403029922734607, 'Total loss': 0.8403029922734607} | train loss {'Reaction outcome loss': 0.8190150092686376, 'Total loss': 0.8190150092686376}
2022-11-23 02:05:57,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:57,775 INFO:     Epoch: 40
2022-11-23 02:05:58,797 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8073721460320733, 'Total loss': 0.8073721460320733} | train loss {'Reaction outcome loss': 0.8218983134194728, 'Total loss': 0.8218983134194728}
2022-11-23 02:05:58,797 INFO:     Found new best model at epoch 40
2022-11-23 02:05:58,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:58,800 INFO:     Epoch: 41
2022-11-23 02:05:59,979 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8098610422827981, 'Total loss': 0.8098610422827981} | train loss {'Reaction outcome loss': 0.8164277408392199, 'Total loss': 0.8164277408392199}
2022-11-23 02:05:59,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:05:59,980 INFO:     Epoch: 42
2022-11-23 02:06:00,998 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8044929870150306, 'Total loss': 0.8044929870150306} | train loss {'Reaction outcome loss': 0.8201903462890656, 'Total loss': 0.8201903462890656}
2022-11-23 02:06:00,999 INFO:     Found new best model at epoch 42
2022-11-23 02:06:01,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:01,001 INFO:     Epoch: 43
2022-11-23 02:06:02,052 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8452349257740107, 'Total loss': 0.8452349257740107} | train loss {'Reaction outcome loss': 0.8206235085043215, 'Total loss': 0.8206235085043215}
2022-11-23 02:06:02,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:02,053 INFO:     Epoch: 44
2022-11-23 02:06:03,086 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8483530431985855, 'Total loss': 0.8483530431985855} | train loss {'Reaction outcome loss': 0.8182449844335357, 'Total loss': 0.8182449844335357}
2022-11-23 02:06:03,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:03,088 INFO:     Epoch: 45
2022-11-23 02:06:04,155 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8286544714461673, 'Total loss': 0.8286544714461673} | train loss {'Reaction outcome loss': 0.8203957679290925, 'Total loss': 0.8203957679290925}
2022-11-23 02:06:04,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:04,156 INFO:     Epoch: 46
2022-11-23 02:06:05,290 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8155825368382714, 'Total loss': 0.8155825368382714} | train loss {'Reaction outcome loss': 0.8201474433224047, 'Total loss': 0.8201474433224047}
2022-11-23 02:06:05,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:05,290 INFO:     Epoch: 47
2022-11-23 02:06:06,703 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8155779323794625, 'Total loss': 0.8155779323794625} | train loss {'Reaction outcome loss': 0.8168126181248696, 'Total loss': 0.8168126181248696}
2022-11-23 02:06:06,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:06,704 INFO:     Epoch: 48
2022-11-23 02:06:08,112 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8354980457912792, 'Total loss': 0.8354980457912792} | train loss {'Reaction outcome loss': 0.8198879725269733, 'Total loss': 0.8198879725269733}
2022-11-23 02:06:08,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:08,116 INFO:     Epoch: 49
2022-11-23 02:06:09,413 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8216980844736099, 'Total loss': 0.8216980844736099} | train loss {'Reaction outcome loss': 0.8233109057670639, 'Total loss': 0.8233109057670639}
2022-11-23 02:06:09,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:09,414 INFO:     Epoch: 50
2022-11-23 02:06:10,511 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8162098188291896, 'Total loss': 0.8162098188291896} | train loss {'Reaction outcome loss': 0.8180181546316992, 'Total loss': 0.8180181546316992}
2022-11-23 02:06:10,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:10,512 INFO:     Epoch: 51
2022-11-23 02:06:11,919 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8385418436743997, 'Total loss': 0.8385418436743997} | train loss {'Reaction outcome loss': 0.815871209507027, 'Total loss': 0.815871209507027}
2022-11-23 02:06:11,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:11,921 INFO:     Epoch: 52
2022-11-23 02:06:13,270 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8059765750711615, 'Total loss': 0.8059765750711615} | train loss {'Reaction outcome loss': 0.8190117046958015, 'Total loss': 0.8190117046958015}
2022-11-23 02:06:13,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:13,271 INFO:     Epoch: 53
2022-11-23 02:06:14,594 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8064052083275535, 'Total loss': 0.8064052083275535} | train loss {'Reaction outcome loss': 0.8191073000911744, 'Total loss': 0.8191073000911744}
2022-11-23 02:06:14,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:14,597 INFO:     Epoch: 54
2022-11-23 02:06:15,914 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.812024784359065, 'Total loss': 0.812024784359065} | train loss {'Reaction outcome loss': 0.8211006833420645, 'Total loss': 0.8211006833420645}
2022-11-23 02:06:15,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:15,914 INFO:     Epoch: 55
2022-11-23 02:06:17,167 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8087855306538668, 'Total loss': 0.8087855306538668} | train loss {'Reaction outcome loss': 0.8197140412465218, 'Total loss': 0.8197140412465218}
2022-11-23 02:06:17,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:17,167 INFO:     Epoch: 56
2022-11-23 02:06:18,408 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8141033168543469, 'Total loss': 0.8141033168543469} | train loss {'Reaction outcome loss': 0.8170096273383787, 'Total loss': 0.8170096273383787}
2022-11-23 02:06:18,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:18,410 INFO:     Epoch: 57
2022-11-23 02:06:19,693 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7989233325828206, 'Total loss': 0.7989233325828206} | train loss {'Reaction outcome loss': 0.8172881987787062, 'Total loss': 0.8172881987787062}
2022-11-23 02:06:19,699 INFO:     Found new best model at epoch 57
2022-11-23 02:06:19,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:19,702 INFO:     Epoch: 58
2022-11-23 02:06:21,067 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8048547966913744, 'Total loss': 0.8048547966913744} | train loss {'Reaction outcome loss': 0.8160230756526993, 'Total loss': 0.8160230756526993}
2022-11-23 02:06:21,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:21,069 INFO:     Epoch: 59
2022-11-23 02:06:22,354 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8167796195908026, 'Total loss': 0.8167796195908026} | train loss {'Reaction outcome loss': 0.8146430852432405, 'Total loss': 0.8146430852432405}
2022-11-23 02:06:22,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:22,355 INFO:     Epoch: 60
2022-11-23 02:06:23,656 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8031629323959351, 'Total loss': 0.8031629323959351} | train loss {'Reaction outcome loss': 0.8187159662765842, 'Total loss': 0.8187159662765842}
2022-11-23 02:06:23,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:23,658 INFO:     Epoch: 61
2022-11-23 02:06:24,992 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8129541819745844, 'Total loss': 0.8129541819745844} | train loss {'Reaction outcome loss': 0.8186409564748887, 'Total loss': 0.8186409564748887}
2022-11-23 02:06:24,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:24,995 INFO:     Epoch: 62
2022-11-23 02:06:26,361 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8109506863084707, 'Total loss': 0.8109506863084707} | train loss {'Reaction outcome loss': 0.8185874621473974, 'Total loss': 0.8185874621473974}
2022-11-23 02:06:26,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:26,362 INFO:     Epoch: 63
2022-11-23 02:06:27,713 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8203150738369335, 'Total loss': 0.8203150738369335} | train loss {'Reaction outcome loss': 0.8187359438067482, 'Total loss': 0.8187359438067482}
2022-11-23 02:06:27,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:27,713 INFO:     Epoch: 64
2022-11-23 02:06:29,044 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8095746771855787, 'Total loss': 0.8095746771855787} | train loss {'Reaction outcome loss': 0.8189262166138618, 'Total loss': 0.8189262166138618}
2022-11-23 02:06:29,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:29,045 INFO:     Epoch: 65
2022-11-23 02:06:30,278 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8199666454033419, 'Total loss': 0.8199666454033419} | train loss {'Reaction outcome loss': 0.8193363618225821, 'Total loss': 0.8193363618225821}
2022-11-23 02:06:30,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:30,279 INFO:     Epoch: 66
2022-11-23 02:06:31,367 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8030444038185206, 'Total loss': 0.8030444038185206} | train loss {'Reaction outcome loss': 0.8171615254494452, 'Total loss': 0.8171615254494452}
2022-11-23 02:06:31,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:31,369 INFO:     Epoch: 67
2022-11-23 02:06:32,417 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8075885027647018, 'Total loss': 0.8075885027647018} | train loss {'Reaction outcome loss': 0.8157174566820744, 'Total loss': 0.8157174566820744}
2022-11-23 02:06:32,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:32,417 INFO:     Epoch: 68
2022-11-23 02:06:33,464 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8087351457639174, 'Total loss': 0.8087351457639174} | train loss {'Reaction outcome loss': 0.8170333918063871, 'Total loss': 0.8170333918063871}
2022-11-23 02:06:33,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:33,464 INFO:     Epoch: 69
2022-11-23 02:06:34,512 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8172857050191272, 'Total loss': 0.8172857050191272} | train loss {'Reaction outcome loss': 0.8212750704298096, 'Total loss': 0.8212750704298096}
2022-11-23 02:06:34,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:34,514 INFO:     Epoch: 70
2022-11-23 02:06:35,655 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8117723925547167, 'Total loss': 0.8117723925547167} | train loss {'Reaction outcome loss': 0.8166842595223458, 'Total loss': 0.8166842595223458}
2022-11-23 02:06:35,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:35,656 INFO:     Epoch: 71
2022-11-23 02:06:36,872 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8216850513761694, 'Total loss': 0.8216850513761694} | train loss {'Reaction outcome loss': 0.815158254196567, 'Total loss': 0.815158254196567}
2022-11-23 02:06:36,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:36,875 INFO:     Epoch: 72
2022-11-23 02:06:37,909 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.811072398993102, 'Total loss': 0.811072398993102} | train loss {'Reaction outcome loss': 0.8163477738778437, 'Total loss': 0.8163477738778437}
2022-11-23 02:06:37,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:37,910 INFO:     Epoch: 73
2022-11-23 02:06:38,947 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8126396530053832, 'Total loss': 0.8126396530053832} | train loss {'Reaction outcome loss': 0.8195651486035316, 'Total loss': 0.8195651486035316}
2022-11-23 02:06:38,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:38,949 INFO:     Epoch: 74
2022-11-23 02:06:39,990 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8220612088387663, 'Total loss': 0.8220612088387663} | train loss {'Reaction outcome loss': 0.8180703505152657, 'Total loss': 0.8180703505152657}
2022-11-23 02:06:39,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:39,992 INFO:     Epoch: 75
2022-11-23 02:06:41,036 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8333881239999424, 'Total loss': 0.8333881239999424} | train loss {'Reaction outcome loss': 0.8204587119961938, 'Total loss': 0.8204587119961938}
2022-11-23 02:06:41,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:41,037 INFO:     Epoch: 76
2022-11-23 02:06:42,206 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8440484418110414, 'Total loss': 0.8440484418110414} | train loss {'Reaction outcome loss': 0.8158208816762893, 'Total loss': 0.8158208816762893}
2022-11-23 02:06:42,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:42,209 INFO:     Epoch: 77
2022-11-23 02:06:43,515 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8046502951871265, 'Total loss': 0.8046502951871265} | train loss {'Reaction outcome loss': 0.8192884139716625, 'Total loss': 0.8192884139716625}
2022-11-23 02:06:43,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:43,516 INFO:     Epoch: 78
2022-11-23 02:06:44,811 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8084278905933554, 'Total loss': 0.8084278905933554} | train loss {'Reaction outcome loss': 0.8181771405281559, 'Total loss': 0.8181771405281559}
2022-11-23 02:06:44,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:44,812 INFO:     Epoch: 79
2022-11-23 02:06:46,142 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8095550239086151, 'Total loss': 0.8095550239086151} | train loss {'Reaction outcome loss': 0.816158995873505, 'Total loss': 0.816158995873505}
2022-11-23 02:06:46,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:46,142 INFO:     Epoch: 80
2022-11-23 02:06:47,499 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8114071237769994, 'Total loss': 0.8114071237769994} | train loss {'Reaction outcome loss': 0.8182435149867688, 'Total loss': 0.8182435149867688}
2022-11-23 02:06:47,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:47,501 INFO:     Epoch: 81
2022-11-23 02:06:48,752 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8145416277376089, 'Total loss': 0.8145416277376089} | train loss {'Reaction outcome loss': 0.8128820202283321, 'Total loss': 0.8128820202283321}
2022-11-23 02:06:48,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:48,753 INFO:     Epoch: 82
2022-11-23 02:06:49,868 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8223676437681372, 'Total loss': 0.8223676437681372} | train loss {'Reaction outcome loss': 0.8133979171754853, 'Total loss': 0.8133979171754853}
2022-11-23 02:06:49,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:49,868 INFO:     Epoch: 83
2022-11-23 02:06:50,953 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8038139532912861, 'Total loss': 0.8038139532912861} | train loss {'Reaction outcome loss': 0.8147527499785346, 'Total loss': 0.8147527499785346}
2022-11-23 02:06:50,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:50,954 INFO:     Epoch: 84
2022-11-23 02:06:52,023 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8123726099729538, 'Total loss': 0.8123726099729538} | train loss {'Reaction outcome loss': 0.8173332960615235, 'Total loss': 0.8173332960615235}
2022-11-23 02:06:52,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:52,024 INFO:     Epoch: 85
2022-11-23 02:06:53,063 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7999371845613826, 'Total loss': 0.7999371845613826} | train loss {'Reaction outcome loss': 0.8209774888330891, 'Total loss': 0.8209774888330891}
2022-11-23 02:06:53,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:53,065 INFO:     Epoch: 86
2022-11-23 02:06:54,108 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7993271499872208, 'Total loss': 0.7993271499872208} | train loss {'Reaction outcome loss': 0.8149294056479008, 'Total loss': 0.8149294056479008}
2022-11-23 02:06:54,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:54,108 INFO:     Epoch: 87
2022-11-23 02:06:55,447 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8022859204899181, 'Total loss': 0.8022859204899181} | train loss {'Reaction outcome loss': 0.8144092567024692, 'Total loss': 0.8144092567024692}
2022-11-23 02:06:55,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:55,447 INFO:     Epoch: 88
2022-11-23 02:06:56,506 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8150349279696291, 'Total loss': 0.8150349279696291} | train loss {'Reaction outcome loss': 0.8152607202289566, 'Total loss': 0.8152607202289566}
2022-11-23 02:06:56,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:56,506 INFO:     Epoch: 89
2022-11-23 02:06:57,547 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8108670156110417, 'Total loss': 0.8108670156110417} | train loss {'Reaction outcome loss': 0.821582424905031, 'Total loss': 0.821582424905031}
2022-11-23 02:06:57,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:57,547 INFO:     Epoch: 90
2022-11-23 02:06:58,602 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8222979964180426, 'Total loss': 0.8222979964180426} | train loss {'Reaction outcome loss': 0.8157210692522987, 'Total loss': 0.8157210692522987}
2022-11-23 02:06:58,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:58,605 INFO:     Epoch: 91
2022-11-23 02:06:59,633 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8326846591450952, 'Total loss': 0.8326846591450952} | train loss {'Reaction outcome loss': 0.8160192658824306, 'Total loss': 0.8160192658824306}
2022-11-23 02:06:59,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:06:59,634 INFO:     Epoch: 92
2022-11-23 02:07:00,773 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8262332677841187, 'Total loss': 0.8262332677841187} | train loss {'Reaction outcome loss': 0.8217543313099492, 'Total loss': 0.8217543313099492}
2022-11-23 02:07:00,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:00,773 INFO:     Epoch: 93
2022-11-23 02:07:02,275 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8278337581591173, 'Total loss': 0.8278337581591173} | train loss {'Reaction outcome loss': 0.8198127727354726, 'Total loss': 0.8198127727354726}
2022-11-23 02:07:02,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:02,276 INFO:     Epoch: 94
2022-11-23 02:07:03,770 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8176622106270357, 'Total loss': 0.8176622106270357} | train loss {'Reaction outcome loss': 0.8182659396721471, 'Total loss': 0.8182659396721471}
2022-11-23 02:07:03,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:03,773 INFO:     Epoch: 95
2022-11-23 02:07:05,244 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8043645654212345, 'Total loss': 0.8043645654212345} | train loss {'Reaction outcome loss': 0.8137471853725372, 'Total loss': 0.8137471853725372}
2022-11-23 02:07:05,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:05,246 INFO:     Epoch: 96
2022-11-23 02:07:06,718 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8261520781300284, 'Total loss': 0.8261520781300284} | train loss {'Reaction outcome loss': 0.8156769890939036, 'Total loss': 0.8156769890939036}
2022-11-23 02:07:06,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:06,719 INFO:     Epoch: 97
2022-11-23 02:07:08,193 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.809959502382712, 'Total loss': 0.809959502382712} | train loss {'Reaction outcome loss': 0.8189801195215795, 'Total loss': 0.8189801195215795}
2022-11-23 02:07:08,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:08,194 INFO:     Epoch: 98
2022-11-23 02:07:09,633 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8037991171533411, 'Total loss': 0.8037991171533411} | train loss {'Reaction outcome loss': 0.8172051947443716, 'Total loss': 0.8172051947443716}
2022-11-23 02:07:09,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:09,636 INFO:     Epoch: 99
2022-11-23 02:07:11,067 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.820656610483473, 'Total loss': 0.820656610483473} | train loss {'Reaction outcome loss': 0.813955481734968, 'Total loss': 0.813955481734968}
2022-11-23 02:07:11,068 INFO:     Best model found after epoch 58 of 100.
2022-11-23 02:07:11,069 INFO:   Done with stage: TRAINING
2022-11-23 02:07:11,069 INFO:   Starting stage: EVALUATION
2022-11-23 02:07:11,329 INFO:   Done with stage: EVALUATION
2022-11-23 02:07:11,330 INFO:   Leaving out SEQ value Fold_7
2022-11-23 02:07:11,358 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:07:11,359 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:07:12,507 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:07:12,508 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:07:12,700 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:07:12,700 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:07:12,701 INFO:     No hyperparam tuning for this model
2022-11-23 02:07:12,701 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:07:12,701 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:07:12,703 INFO:     None feature selector for col prot
2022-11-23 02:07:12,703 INFO:     None feature selector for col prot
2022-11-23 02:07:12,703 INFO:     None feature selector for col prot
2022-11-23 02:07:12,704 INFO:     None feature selector for col chem
2022-11-23 02:07:12,705 INFO:     None feature selector for col chem
2022-11-23 02:07:12,705 INFO:     None feature selector for col chem
2022-11-23 02:07:12,705 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:07:12,705 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:07:12,708 INFO:     Number of params in model 168571
2022-11-23 02:07:12,714 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:07:12,715 INFO:   Starting stage: TRAINING
2022-11-23 02:07:12,828 INFO:     Val loss before train {'Reaction outcome loss': 1.068090027028864, 'Total loss': 1.068090027028864}
2022-11-23 02:07:12,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:12,830 INFO:     Epoch: 0
2022-11-23 02:07:14,365 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8988507864150134, 'Total loss': 0.8988507864150134} | train loss {'Reaction outcome loss': 0.8807709652089304, 'Total loss': 0.8807709652089304}
2022-11-23 02:07:14,365 INFO:     Found new best model at epoch 0
2022-11-23 02:07:14,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:14,367 INFO:     Epoch: 1
2022-11-23 02:07:15,837 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9275858117775484, 'Total loss': 0.9275858117775484} | train loss {'Reaction outcome loss': 0.8442747329752291, 'Total loss': 0.8442747329752291}
2022-11-23 02:07:15,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:15,840 INFO:     Epoch: 2
2022-11-23 02:07:17,268 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8742978559298948, 'Total loss': 0.8742978559298948} | train loss {'Reaction outcome loss': 0.8417743545386099, 'Total loss': 0.8417743545386099}
2022-11-23 02:07:17,268 INFO:     Found new best model at epoch 2
2022-11-23 02:07:17,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:17,269 INFO:     Epoch: 3
2022-11-23 02:07:18,482 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8671356148340486, 'Total loss': 0.8671356148340486} | train loss {'Reaction outcome loss': 0.8256226119495207, 'Total loss': 0.8256226119495207}
2022-11-23 02:07:18,483 INFO:     Found new best model at epoch 3
2022-11-23 02:07:18,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:18,485 INFO:     Epoch: 4
2022-11-23 02:07:19,710 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8706335140900179, 'Total loss': 0.8706335140900179} | train loss {'Reaction outcome loss': 0.8281944117719128, 'Total loss': 0.8281944117719128}
2022-11-23 02:07:19,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:19,710 INFO:     Epoch: 5
2022-11-23 02:07:20,917 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8662879128347744, 'Total loss': 0.8662879128347744} | train loss {'Reaction outcome loss': 0.8208140383564657, 'Total loss': 0.8208140383564657}
2022-11-23 02:07:20,918 INFO:     Found new best model at epoch 5
2022-11-23 02:07:20,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:20,920 INFO:     Epoch: 6
2022-11-23 02:07:22,118 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8667174279689789, 'Total loss': 0.8667174279689789} | train loss {'Reaction outcome loss': 0.8201257924158727, 'Total loss': 0.8201257924158727}
2022-11-23 02:07:22,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:22,120 INFO:     Epoch: 7
2022-11-23 02:07:23,569 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8589511344378645, 'Total loss': 0.8589511344378645} | train loss {'Reaction outcome loss': 0.8219802338750132, 'Total loss': 0.8219802338750132}
2022-11-23 02:07:23,569 INFO:     Found new best model at epoch 7
2022-11-23 02:07:23,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:23,571 INFO:     Epoch: 8
2022-11-23 02:07:25,007 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8552306389266794, 'Total loss': 0.8552306389266794} | train loss {'Reaction outcome loss': 0.8227037793445972, 'Total loss': 0.8227037793445972}
2022-11-23 02:07:25,008 INFO:     Found new best model at epoch 8
2022-11-23 02:07:25,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:25,011 INFO:     Epoch: 9
2022-11-23 02:07:26,438 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8690499731085517, 'Total loss': 0.8690499731085517} | train loss {'Reaction outcome loss': 0.8137586285029689, 'Total loss': 0.8137586285029689}
2022-11-23 02:07:26,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:26,440 INFO:     Epoch: 10
2022-11-23 02:07:27,888 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8633611412210898, 'Total loss': 0.8633611412210898} | train loss {'Reaction outcome loss': 0.820109120059398, 'Total loss': 0.820109120059398}
2022-11-23 02:07:27,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:27,892 INFO:     Epoch: 11
2022-11-23 02:07:29,349 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8719118156216361, 'Total loss': 0.8719118156216361} | train loss {'Reaction outcome loss': 0.8149059591514449, 'Total loss': 0.8149059591514449}
2022-11-23 02:07:29,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:29,351 INFO:     Epoch: 12
2022-11-23 02:07:30,859 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8463737788525495, 'Total loss': 0.8463737788525495} | train loss {'Reaction outcome loss': 0.8123371750116348, 'Total loss': 0.8123371750116348}
2022-11-23 02:07:30,860 INFO:     Found new best model at epoch 12
2022-11-23 02:07:30,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:30,863 INFO:     Epoch: 13
2022-11-23 02:07:32,292 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8730846162546765, 'Total loss': 0.8730846162546765} | train loss {'Reaction outcome loss': 0.809893248783004, 'Total loss': 0.809893248783004}
2022-11-23 02:07:32,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:32,292 INFO:     Epoch: 14
2022-11-23 02:07:33,563 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8814503184773705, 'Total loss': 0.8814503184773705} | train loss {'Reaction outcome loss': 0.8124885905173517, 'Total loss': 0.8124885905173517}
2022-11-23 02:07:33,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:33,566 INFO:     Epoch: 15
2022-11-23 02:07:34,727 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8581820529970255, 'Total loss': 0.8581820529970255} | train loss {'Reaction outcome loss': 0.8073516736828512, 'Total loss': 0.8073516736828512}
2022-11-23 02:07:34,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:34,729 INFO:     Epoch: 16
2022-11-23 02:07:35,882 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.846325237642635, 'Total loss': 0.846325237642635} | train loss {'Reaction outcome loss': 0.8125719656386683, 'Total loss': 0.8125719656386683}
2022-11-23 02:07:35,882 INFO:     Found new best model at epoch 16
2022-11-23 02:07:35,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:35,883 INFO:     Epoch: 17
2022-11-23 02:07:37,055 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8496987602927468, 'Total loss': 0.8496987602927468} | train loss {'Reaction outcome loss': 0.8146804357247968, 'Total loss': 0.8146804357247968}
2022-11-23 02:07:37,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:37,057 INFO:     Epoch: 18
2022-11-23 02:07:38,229 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8637126196514476, 'Total loss': 0.8637126196514476} | train loss {'Reaction outcome loss': 0.8066878812688012, 'Total loss': 0.8066878812688012}
2022-11-23 02:07:38,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:38,229 INFO:     Epoch: 19
2022-11-23 02:07:39,398 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8669031106612899, 'Total loss': 0.8669031106612899} | train loss {'Reaction outcome loss': 0.8087809894594454, 'Total loss': 0.8087809894594454}
2022-11-23 02:07:39,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:39,399 INFO:     Epoch: 20
2022-11-23 02:07:40,565 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8685131012038751, 'Total loss': 0.8685131012038751} | train loss {'Reaction outcome loss': 0.8064041727733228, 'Total loss': 0.8064041727733228}
2022-11-23 02:07:40,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:40,566 INFO:     Epoch: 21
2022-11-23 02:07:41,757 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8571112765507265, 'Total loss': 0.8571112765507265} | train loss {'Reaction outcome loss': 0.8123358348684926, 'Total loss': 0.8123358348684926}
2022-11-23 02:07:41,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:41,758 INFO:     Epoch: 22
2022-11-23 02:07:42,919 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8508369387550787, 'Total loss': 0.8508369387550787} | train loss {'Reaction outcome loss': 0.8088025066160387, 'Total loss': 0.8088025066160387}
2022-11-23 02:07:42,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:42,919 INFO:     Epoch: 23
2022-11-23 02:07:44,080 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8832915181463415, 'Total loss': 0.8832915181463415} | train loss {'Reaction outcome loss': 0.805602633123917, 'Total loss': 0.805602633123917}
2022-11-23 02:07:44,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:44,080 INFO:     Epoch: 24
2022-11-23 02:07:45,229 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8606194352561777, 'Total loss': 0.8606194352561777} | train loss {'Reaction outcome loss': 0.806300479678377, 'Total loss': 0.806300479678377}
2022-11-23 02:07:45,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:45,237 INFO:     Epoch: 25
2022-11-23 02:07:46,382 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8523047647692941, 'Total loss': 0.8523047647692941} | train loss {'Reaction outcome loss': 0.807744272654095, 'Total loss': 0.807744272654095}
2022-11-23 02:07:46,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:46,382 INFO:     Epoch: 26
2022-11-23 02:07:47,553 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8857948861338876, 'Total loss': 0.8857948861338876} | train loss {'Reaction outcome loss': 0.8076624336742586, 'Total loss': 0.8076624336742586}
2022-11-23 02:07:47,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:47,555 INFO:     Epoch: 27
2022-11-23 02:07:48,770 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8496188968420029, 'Total loss': 0.8496188968420029} | train loss {'Reaction outcome loss': 0.8049703014473761, 'Total loss': 0.8049703014473761}
2022-11-23 02:07:48,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:48,770 INFO:     Epoch: 28
2022-11-23 02:07:49,960 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8520760421048511, 'Total loss': 0.8520760421048511} | train loss {'Reaction outcome loss': 0.8026551547790727, 'Total loss': 0.8026551547790727}
2022-11-23 02:07:49,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:49,961 INFO:     Epoch: 29
2022-11-23 02:07:51,244 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8613863438367844, 'Total loss': 0.8613863438367844} | train loss {'Reaction outcome loss': 0.804751077366452, 'Total loss': 0.804751077366452}
2022-11-23 02:07:51,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:51,246 INFO:     Epoch: 30
2022-11-23 02:07:52,651 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8669227544556964, 'Total loss': 0.8669227544556964} | train loss {'Reaction outcome loss': 0.803847328128834, 'Total loss': 0.803847328128834}
2022-11-23 02:07:52,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:52,652 INFO:     Epoch: 31
2022-11-23 02:07:53,935 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8507872697981921, 'Total loss': 0.8507872697981921} | train loss {'Reaction outcome loss': 0.8052716415014959, 'Total loss': 0.8052716415014959}
2022-11-23 02:07:53,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:53,935 INFO:     Epoch: 32
2022-11-23 02:07:55,091 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8593538891185414, 'Total loss': 0.8593538891185414} | train loss {'Reaction outcome loss': 0.804687584600141, 'Total loss': 0.804687584600141}
2022-11-23 02:07:55,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:55,092 INFO:     Epoch: 33
2022-11-23 02:07:56,507 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8655370785431429, 'Total loss': 0.8655370785431429} | train loss {'Reaction outcome loss': 0.8079731607389066, 'Total loss': 0.8079731607389066}
2022-11-23 02:07:56,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:56,509 INFO:     Epoch: 34
2022-11-23 02:07:57,970 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8440530489791523, 'Total loss': 0.8440530489791523} | train loss {'Reaction outcome loss': 0.8080361469859078, 'Total loss': 0.8080361469859078}
2022-11-23 02:07:57,971 INFO:     Found new best model at epoch 34
2022-11-23 02:07:57,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:57,975 INFO:     Epoch: 35
2022-11-23 02:07:59,411 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8684684017842467, 'Total loss': 0.8684684017842467} | train loss {'Reaction outcome loss': 0.801491335515053, 'Total loss': 0.801491335515053}
2022-11-23 02:07:59,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:07:59,413 INFO:     Epoch: 36
2022-11-23 02:08:00,871 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.845571914857084, 'Total loss': 0.845571914857084} | train loss {'Reaction outcome loss': 0.8084041656505677, 'Total loss': 0.8084041656505677}
2022-11-23 02:08:00,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:00,872 INFO:     Epoch: 37
2022-11-23 02:08:02,225 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8510399934920397, 'Total loss': 0.8510399934920397} | train loss {'Reaction outcome loss': 0.8040713402292421, 'Total loss': 0.8040713402292421}
2022-11-23 02:08:02,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:02,227 INFO:     Epoch: 38
2022-11-23 02:08:03,658 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8496700498190793, 'Total loss': 0.8496700498190793} | train loss {'Reaction outcome loss': 0.8040039037023822, 'Total loss': 0.8040039037023822}
2022-11-23 02:08:03,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:03,659 INFO:     Epoch: 39
2022-11-23 02:08:04,990 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8558044745163484, 'Total loss': 0.8558044745163484} | train loss {'Reaction outcome loss': 0.8077965741676669, 'Total loss': 0.8077965741676669}
2022-11-23 02:08:04,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:04,990 INFO:     Epoch: 40
2022-11-23 02:08:06,125 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8557414818893779, 'Total loss': 0.8557414818893779} | train loss {'Reaction outcome loss': 0.8074994849101189, 'Total loss': 0.8074994849101189}
2022-11-23 02:08:06,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:06,126 INFO:     Epoch: 41
2022-11-23 02:08:07,633 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8729344254190271, 'Total loss': 0.8729344254190271} | train loss {'Reaction outcome loss': 0.8030856547336425, 'Total loss': 0.8030856547336425}
2022-11-23 02:08:07,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:07,635 INFO:     Epoch: 42
2022-11-23 02:08:08,979 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8517756184393709, 'Total loss': 0.8517756184393709} | train loss {'Reaction outcome loss': 0.8016699153569437, 'Total loss': 0.8016699153569437}
2022-11-23 02:08:08,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:08,980 INFO:     Epoch: 43
2022-11-23 02:08:10,108 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8492557975378904, 'Total loss': 0.8492557975378904} | train loss {'Reaction outcome loss': 0.8050157992589858, 'Total loss': 0.8050157992589858}
2022-11-23 02:08:10,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:10,110 INFO:     Epoch: 44
2022-11-23 02:08:11,286 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8497341559691862, 'Total loss': 0.8497341559691862} | train loss {'Reaction outcome loss': 0.798187420493172, 'Total loss': 0.798187420493172}
2022-11-23 02:08:11,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:11,287 INFO:     Epoch: 45
2022-11-23 02:08:12,436 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8365778780796311, 'Total loss': 0.8365778780796311} | train loss {'Reaction outcome loss': 0.802074781829311, 'Total loss': 0.802074781829311}
2022-11-23 02:08:12,437 INFO:     Found new best model at epoch 45
2022-11-23 02:08:12,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:12,439 INFO:     Epoch: 46
2022-11-23 02:08:13,569 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8440607400103048, 'Total loss': 0.8440607400103048} | train loss {'Reaction outcome loss': 0.8026512094563053, 'Total loss': 0.8026512094563053}
2022-11-23 02:08:13,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:13,569 INFO:     Epoch: 47
2022-11-23 02:08:14,656 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8364264599301598, 'Total loss': 0.8364264599301598} | train loss {'Reaction outcome loss': 0.8058905189316119, 'Total loss': 0.8058905189316119}
2022-11-23 02:08:14,657 INFO:     Found new best model at epoch 47
2022-11-23 02:08:14,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:14,659 INFO:     Epoch: 48
2022-11-23 02:08:15,710 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8498249514536425, 'Total loss': 0.8498249514536425} | train loss {'Reaction outcome loss': 0.8018141030784576, 'Total loss': 0.8018141030784576}
2022-11-23 02:08:15,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:15,712 INFO:     Epoch: 49
2022-11-23 02:08:16,758 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8416999470103871, 'Total loss': 0.8416999470103871} | train loss {'Reaction outcome loss': 0.8059744534473265, 'Total loss': 0.8059744534473265}
2022-11-23 02:08:16,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:16,759 INFO:     Epoch: 50
2022-11-23 02:08:18,014 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8416599800640886, 'Total loss': 0.8416599800640886} | train loss {'Reaction outcome loss': 0.79938781429683, 'Total loss': 0.79938781429683}
2022-11-23 02:08:18,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:18,015 INFO:     Epoch: 51
2022-11-23 02:08:19,334 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8525817543268204, 'Total loss': 0.8525817543268204} | train loss {'Reaction outcome loss': 0.8081482796659393, 'Total loss': 0.8081482796659393}
2022-11-23 02:08:19,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:19,336 INFO:     Epoch: 52
2022-11-23 02:08:20,647 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8747125552459196, 'Total loss': 0.8747125552459196} | train loss {'Reaction outcome loss': 0.8037303553954247, 'Total loss': 0.8037303553954247}
2022-11-23 02:08:20,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:20,648 INFO:     Epoch: 53
2022-11-23 02:08:21,962 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.854229293086312, 'Total loss': 0.854229293086312} | train loss {'Reaction outcome loss': 0.7996601891373435, 'Total loss': 0.7996601891373435}
2022-11-23 02:08:21,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:21,964 INFO:     Epoch: 54
2022-11-23 02:08:23,260 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8800555149262602, 'Total loss': 0.8800555149262602} | train loss {'Reaction outcome loss': 0.8029519390434988, 'Total loss': 0.8029519390434988}
2022-11-23 02:08:23,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:23,262 INFO:     Epoch: 55
2022-11-23 02:08:24,495 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8460738421841101, 'Total loss': 0.8460738421841101} | train loss {'Reaction outcome loss': 0.7967845219517907, 'Total loss': 0.7967845219517907}
2022-11-23 02:08:24,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:24,497 INFO:     Epoch: 56
2022-11-23 02:08:25,790 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8391547785563902, 'Total loss': 0.8391547785563902} | train loss {'Reaction outcome loss': 0.8036409776297307, 'Total loss': 0.8036409776297307}
2022-11-23 02:08:25,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:25,791 INFO:     Epoch: 57
2022-11-23 02:08:27,194 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8409325792030855, 'Total loss': 0.8409325792030855} | train loss {'Reaction outcome loss': 0.8021220389393068, 'Total loss': 0.8021220389393068}
2022-11-23 02:08:27,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:27,195 INFO:     Epoch: 58
2022-11-23 02:08:28,560 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8474672958254814, 'Total loss': 0.8474672958254814} | train loss {'Reaction outcome loss': 0.8048599357566526, 'Total loss': 0.8048599357566526}
2022-11-23 02:08:28,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:28,560 INFO:     Epoch: 59
2022-11-23 02:08:29,869 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8382257832722231, 'Total loss': 0.8382257832722231} | train loss {'Reaction outcome loss': 0.8013112244586791, 'Total loss': 0.8013112244586791}
2022-11-23 02:08:29,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:29,871 INFO:     Epoch: 60
2022-11-23 02:08:31,210 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8783246102658185, 'Total loss': 0.8783246102658185} | train loss {'Reaction outcome loss': 0.8041911157629182, 'Total loss': 0.8041911157629182}
2022-11-23 02:08:31,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:31,212 INFO:     Epoch: 61
2022-11-23 02:08:32,500 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8363413851369511, 'Total loss': 0.8363413851369511} | train loss {'Reaction outcome loss': 0.8012067841426018, 'Total loss': 0.8012067841426018}
2022-11-23 02:08:32,500 INFO:     Found new best model at epoch 61
2022-11-23 02:08:32,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:32,501 INFO:     Epoch: 62
2022-11-23 02:08:33,730 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8327108635143801, 'Total loss': 0.8327108635143801} | train loss {'Reaction outcome loss': 0.8022508672889201, 'Total loss': 0.8022508672889201}
2022-11-23 02:08:33,730 INFO:     Found new best model at epoch 62
2022-11-23 02:08:33,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:33,732 INFO:     Epoch: 63
2022-11-23 02:08:34,993 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8662120659242977, 'Total loss': 0.8662120659242977} | train loss {'Reaction outcome loss': 0.7999395085198264, 'Total loss': 0.7999395085198264}
2022-11-23 02:08:34,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:34,994 INFO:     Epoch: 64
2022-11-23 02:08:36,443 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8533607640049674, 'Total loss': 0.8533607640049674} | train loss {'Reaction outcome loss': 0.8058721264523845, 'Total loss': 0.8058721264523845}
2022-11-23 02:08:36,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:36,444 INFO:     Epoch: 65
2022-11-23 02:08:37,921 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.854617870666764, 'Total loss': 0.854617870666764} | train loss {'Reaction outcome loss': 0.799839989792916, 'Total loss': 0.799839989792916}
2022-11-23 02:08:37,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:37,923 INFO:     Epoch: 66
2022-11-23 02:08:39,446 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8538720526478507, 'Total loss': 0.8538720526478507} | train loss {'Reaction outcome loss': 0.8039740150974642, 'Total loss': 0.8039740150974642}
2022-11-23 02:08:39,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:39,448 INFO:     Epoch: 67
2022-11-23 02:08:40,851 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8767726001414385, 'Total loss': 0.8767726001414385} | train loss {'Reaction outcome loss': 0.8014589358241327, 'Total loss': 0.8014589358241327}
2022-11-23 02:08:40,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:40,853 INFO:     Epoch: 68
2022-11-23 02:08:42,225 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8471715897321701, 'Total loss': 0.8471715897321701} | train loss {'Reaction outcome loss': 0.8007581214750966, 'Total loss': 0.8007581214750966}
2022-11-23 02:08:42,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:42,228 INFO:     Epoch: 69
2022-11-23 02:08:43,542 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8566899949854071, 'Total loss': 0.8566899949854071} | train loss {'Reaction outcome loss': 0.8012497395036682, 'Total loss': 0.8012497395036682}
2022-11-23 02:08:43,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:43,544 INFO:     Epoch: 70
2022-11-23 02:08:44,845 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8549722988497127, 'Total loss': 0.8549722988497127} | train loss {'Reaction outcome loss': 0.8045591267366563, 'Total loss': 0.8045591267366563}
2022-11-23 02:08:44,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:44,846 INFO:     Epoch: 71
2022-11-23 02:08:46,043 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8406469490040432, 'Total loss': 0.8406469490040432} | train loss {'Reaction outcome loss': 0.801326299987493, 'Total loss': 0.801326299987493}
2022-11-23 02:08:46,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:46,045 INFO:     Epoch: 72
2022-11-23 02:08:47,338 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8479134399782527, 'Total loss': 0.8479134399782527} | train loss {'Reaction outcome loss': 0.8052256168617357, 'Total loss': 0.8052256168617357}
2022-11-23 02:08:47,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:47,339 INFO:     Epoch: 73
2022-11-23 02:08:48,749 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8458795845508575, 'Total loss': 0.8458795845508575} | train loss {'Reaction outcome loss': 0.8020900427814452, 'Total loss': 0.8020900427814452}
2022-11-23 02:08:48,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:48,750 INFO:     Epoch: 74
2022-11-23 02:08:50,144 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8593175986951048, 'Total loss': 0.8593175986951048} | train loss {'Reaction outcome loss': 0.8013452694060341, 'Total loss': 0.8013452694060341}
2022-11-23 02:08:50,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:50,144 INFO:     Epoch: 75
2022-11-23 02:08:51,377 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8491767969998446, 'Total loss': 0.8491767969998446} | train loss {'Reaction outcome loss': 0.7995630884843488, 'Total loss': 0.7995630884843488}
2022-11-23 02:08:51,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:51,378 INFO:     Epoch: 76
2022-11-23 02:08:52,483 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8468195782466368, 'Total loss': 0.8468195782466368} | train loss {'Reaction outcome loss': 0.8053210680523226, 'Total loss': 0.8053210680523226}
2022-11-23 02:08:52,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:52,485 INFO:     Epoch: 77
2022-11-23 02:08:53,537 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.841807334260507, 'Total loss': 0.841807334260507} | train loss {'Reaction outcome loss': 0.807696383085943, 'Total loss': 0.807696383085943}
2022-11-23 02:08:53,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:53,537 INFO:     Epoch: 78
2022-11-23 02:08:54,645 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8559506061402234, 'Total loss': 0.8559506061402234} | train loss {'Reaction outcome loss': 0.8027375896851863, 'Total loss': 0.8027375896851863}
2022-11-23 02:08:54,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:54,647 INFO:     Epoch: 79
2022-11-23 02:08:55,971 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8661912083625793, 'Total loss': 0.8661912083625793} | train loss {'Reaction outcome loss': 0.8027163435134196, 'Total loss': 0.8027163435134196}
2022-11-23 02:08:55,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:55,973 INFO:     Epoch: 80
2022-11-23 02:08:57,412 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.842452616176822, 'Total loss': 0.842452616176822} | train loss {'Reaction outcome loss': 0.804486351748628, 'Total loss': 0.804486351748628}
2022-11-23 02:08:57,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:57,415 INFO:     Epoch: 81
2022-11-23 02:08:58,833 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8653726002032106, 'Total loss': 0.8653726002032106} | train loss {'Reaction outcome loss': 0.8010686449706554, 'Total loss': 0.8010686449706554}
2022-11-23 02:08:58,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:08:58,835 INFO:     Epoch: 82
2022-11-23 02:09:00,175 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8661235489628532, 'Total loss': 0.8661235489628532} | train loss {'Reaction outcome loss': 0.8028834176159674, 'Total loss': 0.8028834176159674}
2022-11-23 02:09:00,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:00,177 INFO:     Epoch: 83
2022-11-23 02:09:01,435 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8481637266549197, 'Total loss': 0.8481637266549197} | train loss {'Reaction outcome loss': 0.8008821767664724, 'Total loss': 0.8008821767664724}
2022-11-23 02:09:01,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:01,436 INFO:     Epoch: 84
2022-11-23 02:09:02,877 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8499845943667672, 'Total loss': 0.8499845943667672} | train loss {'Reaction outcome loss': 0.8058273464200958, 'Total loss': 0.8058273464200958}
2022-11-23 02:09:02,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:02,879 INFO:     Epoch: 85
2022-11-23 02:09:04,325 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.853847053240646, 'Total loss': 0.853847053240646} | train loss {'Reaction outcome loss': 0.8023587358334372, 'Total loss': 0.8023587358334372}
2022-11-23 02:09:04,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:04,325 INFO:     Epoch: 86
2022-11-23 02:09:05,691 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8420431153340773, 'Total loss': 0.8420431153340773} | train loss {'Reaction outcome loss': 0.8039735439083269, 'Total loss': 0.8039735439083269}
2022-11-23 02:09:05,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:05,692 INFO:     Epoch: 87
2022-11-23 02:09:06,903 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.85095053775744, 'Total loss': 0.85095053775744} | train loss {'Reaction outcome loss': 0.7998482822891204, 'Total loss': 0.7998482822891204}
2022-11-23 02:09:06,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:06,904 INFO:     Epoch: 88
2022-11-23 02:09:08,600 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8493807512250814, 'Total loss': 0.8493807512250814} | train loss {'Reaction outcome loss': 0.7983401966912131, 'Total loss': 0.7983401966912131}
2022-11-23 02:09:08,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:08,601 INFO:     Epoch: 89
2022-11-23 02:09:09,769 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.869401255114512, 'Total loss': 0.869401255114512} | train loss {'Reaction outcome loss': 0.8041465122613215, 'Total loss': 0.8041465122613215}
2022-11-23 02:09:09,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:09,770 INFO:     Epoch: 90
2022-11-23 02:09:10,939 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8420788666064088, 'Total loss': 0.8420788666064088} | train loss {'Reaction outcome loss': 0.7996741136716258, 'Total loss': 0.7996741136716258}
2022-11-23 02:09:10,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:10,940 INFO:     Epoch: 91
2022-11-23 02:09:12,272 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8514772592620417, 'Total loss': 0.8514772592620417} | train loss {'Reaction outcome loss': 0.8031551012348744, 'Total loss': 0.8031551012348744}
2022-11-23 02:09:12,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:12,274 INFO:     Epoch: 92
2022-11-23 02:09:13,615 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8801192742857066, 'Total loss': 0.8801192742857066} | train loss {'Reaction outcome loss': 0.806215793014534, 'Total loss': 0.806215793014534}
2022-11-23 02:09:13,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:13,617 INFO:     Epoch: 93
2022-11-23 02:09:14,966 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8877383050593463, 'Total loss': 0.8877383050593463} | train loss {'Reaction outcome loss': 0.8023055204220356, 'Total loss': 0.8023055204220356}
2022-11-23 02:09:14,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:14,967 INFO:     Epoch: 94
2022-11-23 02:09:16,350 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8696087341416966, 'Total loss': 0.8696087341416966} | train loss {'Reaction outcome loss': 0.796619481136722, 'Total loss': 0.796619481136722}
2022-11-23 02:09:16,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:16,352 INFO:     Epoch: 95
2022-11-23 02:09:17,698 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8366449041800066, 'Total loss': 0.8366449041800066} | train loss {'Reaction outcome loss': 0.8050271404847023, 'Total loss': 0.8050271404847023}
2022-11-23 02:09:17,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:17,699 INFO:     Epoch: 96
2022-11-23 02:09:19,067 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8517259332266721, 'Total loss': 0.8517259332266721} | train loss {'Reaction outcome loss': 0.8019712844923619, 'Total loss': 0.8019712844923619}
2022-11-23 02:09:19,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:19,069 INFO:     Epoch: 97
2022-11-23 02:09:20,366 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8502441664988344, 'Total loss': 0.8502441664988344} | train loss {'Reaction outcome loss': 0.8087115433187254, 'Total loss': 0.8087115433187254}
2022-11-23 02:09:20,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:20,366 INFO:     Epoch: 98
2022-11-23 02:09:21,502 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8683073385195299, 'Total loss': 0.8683073385195299} | train loss {'Reaction outcome loss': 0.7994043686457218, 'Total loss': 0.7994043686457218}
2022-11-23 02:09:21,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:21,503 INFO:     Epoch: 99
2022-11-23 02:09:22,654 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8383343761617487, 'Total loss': 0.8383343761617487} | train loss {'Reaction outcome loss': 0.8050404964916168, 'Total loss': 0.8050404964916168}
2022-11-23 02:09:22,655 INFO:     Best model found after epoch 63 of 100.
2022-11-23 02:09:22,655 INFO:   Done with stage: TRAINING
2022-11-23 02:09:22,655 INFO:   Starting stage: EVALUATION
2022-11-23 02:09:22,848 INFO:   Done with stage: EVALUATION
2022-11-23 02:09:22,849 INFO:   Leaving out SEQ value Fold_8
2022-11-23 02:09:22,872 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:09:22,873 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:09:23,823 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:09:23,824 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:09:23,948 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:09:23,948 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:09:23,949 INFO:     No hyperparam tuning for this model
2022-11-23 02:09:23,950 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:09:23,950 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:09:23,952 INFO:     None feature selector for col prot
2022-11-23 02:09:23,952 INFO:     None feature selector for col prot
2022-11-23 02:09:23,952 INFO:     None feature selector for col prot
2022-11-23 02:09:23,954 INFO:     None feature selector for col chem
2022-11-23 02:09:23,954 INFO:     None feature selector for col chem
2022-11-23 02:09:23,955 INFO:     None feature selector for col chem
2022-11-23 02:09:23,955 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:09:23,955 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:09:23,958 INFO:     Number of params in model 168571
2022-11-23 02:09:23,964 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:09:23,965 INFO:   Starting stage: TRAINING
2022-11-23 02:09:24,054 INFO:     Val loss before train {'Reaction outcome loss': 0.9692828133702278, 'Total loss': 0.9692828133702278}
2022-11-23 02:09:24,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:24,055 INFO:     Epoch: 0
2022-11-23 02:09:25,244 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8391287509690631, 'Total loss': 0.8391287509690631} | train loss {'Reaction outcome loss': 0.8760659137838765, 'Total loss': 0.8760659137838765}
2022-11-23 02:09:25,244 INFO:     Found new best model at epoch 0
2022-11-23 02:09:25,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:25,246 INFO:     Epoch: 1
2022-11-23 02:09:26,496 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8078899424184453, 'Total loss': 0.8078899424184453} | train loss {'Reaction outcome loss': 0.851271919152032, 'Total loss': 0.851271919152032}
2022-11-23 02:09:26,497 INFO:     Found new best model at epoch 1
2022-11-23 02:09:26,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:26,500 INFO:     Epoch: 2
2022-11-23 02:09:27,666 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7953957197341052, 'Total loss': 0.7953957197341052} | train loss {'Reaction outcome loss': 0.8488584984893258, 'Total loss': 0.8488584984893258}
2022-11-23 02:09:27,667 INFO:     Found new best model at epoch 2
2022-11-23 02:09:27,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:27,669 INFO:     Epoch: 3
2022-11-23 02:09:28,820 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8223333616148342, 'Total loss': 0.8223333616148342} | train loss {'Reaction outcome loss': 0.8395643060506597, 'Total loss': 0.8395643060506597}
2022-11-23 02:09:28,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:28,820 INFO:     Epoch: 4
2022-11-23 02:09:30,169 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8136318854310296, 'Total loss': 0.8136318854310296} | train loss {'Reaction outcome loss': 0.8323305173200152, 'Total loss': 0.8323305173200152}
2022-11-23 02:09:30,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:30,171 INFO:     Epoch: 5
2022-11-23 02:09:31,610 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7741065662015568, 'Total loss': 0.7741065662015568} | train loss {'Reaction outcome loss': 0.8324767515847558, 'Total loss': 0.8324767515847558}
2022-11-23 02:09:31,610 INFO:     Found new best model at epoch 5
2022-11-23 02:09:31,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:31,612 INFO:     Epoch: 6
2022-11-23 02:09:32,904 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8095391189510172, 'Total loss': 0.8095391189510172} | train loss {'Reaction outcome loss': 0.8222132383841976, 'Total loss': 0.8222132383841976}
2022-11-23 02:09:32,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:32,906 INFO:     Epoch: 7
2022-11-23 02:09:34,220 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7831794768571854, 'Total loss': 0.7831794768571854} | train loss {'Reaction outcome loss': 0.8303308961121177, 'Total loss': 0.8303308961121177}
2022-11-23 02:09:34,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:34,221 INFO:     Epoch: 8
2022-11-23 02:09:35,345 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7841147970069539, 'Total loss': 0.7841147970069539} | train loss {'Reaction outcome loss': 0.8256329296812838, 'Total loss': 0.8256329296812838}
2022-11-23 02:09:35,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:35,346 INFO:     Epoch: 9
2022-11-23 02:09:36,464 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.794558821754022, 'Total loss': 0.794558821754022} | train loss {'Reaction outcome loss': 0.8231543365277743, 'Total loss': 0.8231543365277743}
2022-11-23 02:09:36,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:36,465 INFO:     Epoch: 10
2022-11-23 02:09:37,577 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8003523302349177, 'Total loss': 0.8003523302349177} | train loss {'Reaction outcome loss': 0.825435492764359, 'Total loss': 0.825435492764359}
2022-11-23 02:09:37,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:37,577 INFO:     Epoch: 11
2022-11-23 02:09:38,679 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7969497889280319, 'Total loss': 0.7969497889280319} | train loss {'Reaction outcome loss': 0.8232647446003037, 'Total loss': 0.8232647446003037}
2022-11-23 02:09:38,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:38,680 INFO:     Epoch: 12
2022-11-23 02:09:39,777 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7885746210813522, 'Total loss': 0.7885746210813522} | train loss {'Reaction outcome loss': 0.8265325932608925, 'Total loss': 0.8265325932608925}
2022-11-23 02:09:39,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:39,777 INFO:     Epoch: 13
2022-11-23 02:09:40,886 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7885613346641714, 'Total loss': 0.7885613346641714} | train loss {'Reaction outcome loss': 0.8233818566268273, 'Total loss': 0.8233818566268273}
2022-11-23 02:09:40,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:40,886 INFO:     Epoch: 14
2022-11-23 02:09:41,999 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7844549437815492, 'Total loss': 0.7844549437815492} | train loss {'Reaction outcome loss': 0.821695058451973, 'Total loss': 0.821695058451973}
2022-11-23 02:09:41,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:42,000 INFO:     Epoch: 15
2022-11-23 02:09:43,106 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7899511273611676, 'Total loss': 0.7899511273611676} | train loss {'Reaction outcome loss': 0.8201173423272878, 'Total loss': 0.8201173423272878}
2022-11-23 02:09:43,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:43,107 INFO:     Epoch: 16
2022-11-23 02:09:44,337 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7774262137033723, 'Total loss': 0.7774262137033723} | train loss {'Reaction outcome loss': 0.8169518433481093, 'Total loss': 0.8169518433481093}
2022-11-23 02:09:44,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:44,338 INFO:     Epoch: 17
2022-11-23 02:09:45,515 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7849457270719788, 'Total loss': 0.7849457270719788} | train loss {'Reaction outcome loss': 0.819666836621911, 'Total loss': 0.819666836621911}
2022-11-23 02:09:45,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:45,516 INFO:     Epoch: 18
2022-11-23 02:09:46,668 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7716666053641926, 'Total loss': 0.7716666053641926} | train loss {'Reaction outcome loss': 0.8217440845090368, 'Total loss': 0.8217440845090368}
2022-11-23 02:09:46,668 INFO:     Found new best model at epoch 18
2022-11-23 02:09:46,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:46,669 INFO:     Epoch: 19
2022-11-23 02:09:47,756 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7896293997764587, 'Total loss': 0.7896293997764587} | train loss {'Reaction outcome loss': 0.8215549531494558, 'Total loss': 0.8215549531494558}
2022-11-23 02:09:47,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:47,757 INFO:     Epoch: 20
2022-11-23 02:09:48,852 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7914831733161752, 'Total loss': 0.7914831733161752} | train loss {'Reaction outcome loss': 0.8255207247820943, 'Total loss': 0.8255207247820943}
2022-11-23 02:09:48,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:48,853 INFO:     Epoch: 21
2022-11-23 02:09:49,934 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8085512735626914, 'Total loss': 0.8085512735626914} | train loss {'Reaction outcome loss': 0.8264876207118093, 'Total loss': 0.8264876207118093}
2022-11-23 02:09:49,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:49,936 INFO:     Epoch: 22
2022-11-23 02:09:51,007 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7821321040391922, 'Total loss': 0.7821321040391922} | train loss {'Reaction outcome loss': 0.8240543025949223, 'Total loss': 0.8240543025949223}
2022-11-23 02:09:51,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:51,008 INFO:     Epoch: 23
2022-11-23 02:09:52,052 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7881913672793995, 'Total loss': 0.7881913672793995} | train loss {'Reaction outcome loss': 0.8151399232597969, 'Total loss': 0.8151399232597969}
2022-11-23 02:09:52,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:52,054 INFO:     Epoch: 24
2022-11-23 02:09:53,086 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7788753882050514, 'Total loss': 0.7788753882050514} | train loss {'Reaction outcome loss': 0.8191736668710284, 'Total loss': 0.8191736668710284}
2022-11-23 02:09:53,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:53,087 INFO:     Epoch: 25
2022-11-23 02:09:54,150 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7821339551698078, 'Total loss': 0.7821339551698078} | train loss {'Reaction outcome loss': 0.8272128438177379, 'Total loss': 0.8272128438177379}
2022-11-23 02:09:54,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:54,152 INFO:     Epoch: 26
2022-11-23 02:09:55,221 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7925211380828511, 'Total loss': 0.7925211380828511} | train loss {'Reaction outcome loss': 0.8225842965276617, 'Total loss': 0.8225842965276617}
2022-11-23 02:09:55,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:55,223 INFO:     Epoch: 27
2022-11-23 02:09:56,327 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7781364294615659, 'Total loss': 0.7781364294615659} | train loss {'Reaction outcome loss': 0.8283737246324177, 'Total loss': 0.8283737246324177}
2022-11-23 02:09:56,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:56,328 INFO:     Epoch: 28
2022-11-23 02:09:57,389 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7840729477730665, 'Total loss': 0.7840729477730665} | train loss {'Reaction outcome loss': 0.8178730233297175, 'Total loss': 0.8178730233297175}
2022-11-23 02:09:57,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:57,390 INFO:     Epoch: 29
2022-11-23 02:09:58,502 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7758691568266262, 'Total loss': 0.7758691568266262} | train loss {'Reaction outcome loss': 0.8165158237281599, 'Total loss': 0.8165158237281599}
2022-11-23 02:09:58,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:58,504 INFO:     Epoch: 30
2022-11-23 02:09:59,583 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.801887571811676, 'Total loss': 0.801887571811676} | train loss {'Reaction outcome loss': 0.8211505192252788, 'Total loss': 0.8211505192252788}
2022-11-23 02:09:59,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:09:59,584 INFO:     Epoch: 31
2022-11-23 02:10:00,638 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.788665662434968, 'Total loss': 0.788665662434968} | train loss {'Reaction outcome loss': 0.819202341290138, 'Total loss': 0.819202341290138}
2022-11-23 02:10:00,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:00,638 INFO:     Epoch: 32
2022-11-23 02:10:01,700 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7769878560846503, 'Total loss': 0.7769878560846503} | train loss {'Reaction outcome loss': 0.8203465464385414, 'Total loss': 0.8203465464385414}
2022-11-23 02:10:01,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:01,700 INFO:     Epoch: 33
2022-11-23 02:10:02,755 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.769566995176402, 'Total loss': 0.769566995176402} | train loss {'Reaction outcome loss': 0.8204124685723772, 'Total loss': 0.8204124685723772}
2022-11-23 02:10:02,756 INFO:     Found new best model at epoch 33
2022-11-23 02:10:02,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:02,758 INFO:     Epoch: 34
2022-11-23 02:10:03,840 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8005410480228338, 'Total loss': 0.8005410480228338} | train loss {'Reaction outcome loss': 0.8143745758514173, 'Total loss': 0.8143745758514173}
2022-11-23 02:10:03,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:03,841 INFO:     Epoch: 35
2022-11-23 02:10:04,912 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7877182513475418, 'Total loss': 0.7877182513475418} | train loss {'Reaction outcome loss': 0.8218495521226875, 'Total loss': 0.8218495521226875}
2022-11-23 02:10:04,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:04,918 INFO:     Epoch: 36
2022-11-23 02:10:06,098 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7818196334622123, 'Total loss': 0.7818196334622123} | train loss {'Reaction outcome loss': 0.8216838215285467, 'Total loss': 0.8216838215285467}
2022-11-23 02:10:06,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:06,100 INFO:     Epoch: 37
2022-11-23 02:10:07,174 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7840469533746893, 'Total loss': 0.7840469533746893} | train loss {'Reaction outcome loss': 0.8174802840721269, 'Total loss': 0.8174802840721269}
2022-11-23 02:10:07,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:07,174 INFO:     Epoch: 38
2022-11-23 02:10:08,301 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7848087291825901, 'Total loss': 0.7848087291825901} | train loss {'Reaction outcome loss': 0.8236509381759505, 'Total loss': 0.8236509381759505}
2022-11-23 02:10:08,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:08,302 INFO:     Epoch: 39
2022-11-23 02:10:09,372 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.805579037828879, 'Total loss': 0.805579037828879} | train loss {'Reaction outcome loss': 0.8270859124689449, 'Total loss': 0.8270859124689449}
2022-11-23 02:10:09,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:09,373 INFO:     Epoch: 40
2022-11-23 02:10:10,423 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7840670008550991, 'Total loss': 0.7840670008550991} | train loss {'Reaction outcome loss': 0.8316435536392305, 'Total loss': 0.8316435536392305}
2022-11-23 02:10:10,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:10,424 INFO:     Epoch: 41
2022-11-23 02:10:11,481 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.781968086280606, 'Total loss': 0.781968086280606} | train loss {'Reaction outcome loss': 0.8245312838177932, 'Total loss': 0.8245312838177932}
2022-11-23 02:10:11,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:11,481 INFO:     Epoch: 42
2022-11-23 02:10:12,536 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8115675848993388, 'Total loss': 0.8115675848993388} | train loss {'Reaction outcome loss': 0.8269380637508655, 'Total loss': 0.8269380637508655}
2022-11-23 02:10:12,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:12,536 INFO:     Epoch: 43
2022-11-23 02:10:13,581 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7738370698961344, 'Total loss': 0.7738370698961344} | train loss {'Reaction outcome loss': 0.8264214316843009, 'Total loss': 0.8264214316843009}
2022-11-23 02:10:13,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:13,581 INFO:     Epoch: 44
2022-11-23 02:10:15,061 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7890831496227871, 'Total loss': 0.7890831496227871} | train loss {'Reaction outcome loss': 0.8225592859843482, 'Total loss': 0.8225592859843482}
2022-11-23 02:10:15,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:15,062 INFO:     Epoch: 45
2022-11-23 02:10:16,095 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7884661175987937, 'Total loss': 0.7884661175987937} | train loss {'Reaction outcome loss': 0.8173997004022483, 'Total loss': 0.8173997004022483}
2022-11-23 02:10:16,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:16,095 INFO:     Epoch: 46
2022-11-23 02:10:17,206 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7896140569990332, 'Total loss': 0.7896140569990332} | train loss {'Reaction outcome loss': 0.8201577976527001, 'Total loss': 0.8201577976527001}
2022-11-23 02:10:17,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:17,209 INFO:     Epoch: 47
2022-11-23 02:10:18,449 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7830579727888107, 'Total loss': 0.7830579727888107} | train loss {'Reaction outcome loss': 0.8207875551723758, 'Total loss': 0.8207875551723758}
2022-11-23 02:10:18,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:18,451 INFO:     Epoch: 48
2022-11-23 02:10:19,731 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7929664281281558, 'Total loss': 0.7929664281281558} | train loss {'Reaction outcome loss': 0.8215992623253873, 'Total loss': 0.8215992623253873}
2022-11-23 02:10:19,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:19,733 INFO:     Epoch: 49
2022-11-23 02:10:20,939 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8046048026193272, 'Total loss': 0.8046048026193272} | train loss {'Reaction outcome loss': 0.8235021500211013, 'Total loss': 0.8235021500211013}
2022-11-23 02:10:20,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:20,940 INFO:     Epoch: 50
2022-11-23 02:10:22,303 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.782382642003623, 'Total loss': 0.782382642003623} | train loss {'Reaction outcome loss': 0.8191535775719384, 'Total loss': 0.8191535775719384}
2022-11-23 02:10:22,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:22,305 INFO:     Epoch: 51
2022-11-23 02:10:23,398 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7939998412674124, 'Total loss': 0.7939998412674124} | train loss {'Reaction outcome loss': 0.816394546857247, 'Total loss': 0.816394546857247}
2022-11-23 02:10:23,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:23,398 INFO:     Epoch: 52
2022-11-23 02:10:24,454 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7768533839420839, 'Total loss': 0.7768533839420839} | train loss {'Reaction outcome loss': 0.8229928405178704, 'Total loss': 0.8229928405178704}
2022-11-23 02:10:24,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:24,454 INFO:     Epoch: 53
2022-11-23 02:10:25,483 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7819140939549967, 'Total loss': 0.7819140939549967} | train loss {'Reaction outcome loss': 0.819039648602366, 'Total loss': 0.819039648602366}
2022-11-23 02:10:25,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:25,484 INFO:     Epoch: 54
2022-11-23 02:10:26,670 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8095546994696964, 'Total loss': 0.8095546994696964} | train loss {'Reaction outcome loss': 0.8167396426683495, 'Total loss': 0.8167396426683495}
2022-11-23 02:10:26,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:26,670 INFO:     Epoch: 55
2022-11-23 02:10:28,075 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.783465869047425, 'Total loss': 0.783465869047425} | train loss {'Reaction outcome loss': 0.822850094753721, 'Total loss': 0.822850094753721}
2022-11-23 02:10:28,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:28,075 INFO:     Epoch: 56
2022-11-23 02:10:29,345 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7826243391768499, 'Total loss': 0.7826243391768499} | train loss {'Reaction outcome loss': 0.8241409642493677, 'Total loss': 0.8241409642493677}
2022-11-23 02:10:29,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:29,347 INFO:     Epoch: 57
2022-11-23 02:10:30,628 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.78404316035184, 'Total loss': 0.78404316035184} | train loss {'Reaction outcome loss': 0.8226092210424091, 'Total loss': 0.8226092210424091}
2022-11-23 02:10:30,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:30,629 INFO:     Epoch: 58
2022-11-23 02:10:31,909 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8170687305656347, 'Total loss': 0.8170687305656347} | train loss {'Reaction outcome loss': 0.8308382354043273, 'Total loss': 0.8308382354043273}
2022-11-23 02:10:31,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:31,909 INFO:     Epoch: 59
2022-11-23 02:10:32,953 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7817531268705021, 'Total loss': 0.7817531268705021} | train loss {'Reaction outcome loss': 0.8314011854681409, 'Total loss': 0.8314011854681409}
2022-11-23 02:10:32,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:32,954 INFO:     Epoch: 60
2022-11-23 02:10:34,014 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7871122854677114, 'Total loss': 0.7871122854677114} | train loss {'Reaction outcome loss': 0.8200540336278769, 'Total loss': 0.8200540336278769}
2022-11-23 02:10:34,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:34,016 INFO:     Epoch: 61
2022-11-23 02:10:35,068 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7942566790364005, 'Total loss': 0.7942566790364005} | train loss {'Reaction outcome loss': 0.8203182990251765, 'Total loss': 0.8203182990251765}
2022-11-23 02:10:35,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:35,069 INFO:     Epoch: 62
2022-11-23 02:10:36,310 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7818152504888448, 'Total loss': 0.7818152504888448} | train loss {'Reaction outcome loss': 0.8238500409763352, 'Total loss': 0.8238500409763352}
2022-11-23 02:10:36,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:36,312 INFO:     Epoch: 63
2022-11-23 02:10:37,380 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7876133024692535, 'Total loss': 0.7876133024692535} | train loss {'Reaction outcome loss': 0.8184844512447171, 'Total loss': 0.8184844512447171}
2022-11-23 02:10:37,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:37,381 INFO:     Epoch: 64
2022-11-23 02:10:38,667 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7766035382043232, 'Total loss': 0.7766035382043232} | train loss {'Reaction outcome loss': 0.8198815791713081, 'Total loss': 0.8198815791713081}
2022-11-23 02:10:38,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:38,667 INFO:     Epoch: 65
2022-11-23 02:10:39,998 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7785420587117021, 'Total loss': 0.7785420587117021} | train loss {'Reaction outcome loss': 0.8209880648957573, 'Total loss': 0.8209880648957573}
2022-11-23 02:10:39,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:39,998 INFO:     Epoch: 66
2022-11-23 02:10:41,207 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7735316787253727, 'Total loss': 0.7735316787253727} | train loss {'Reaction outcome loss': 0.8265607075893927, 'Total loss': 0.8265607075893927}
2022-11-23 02:10:41,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:41,208 INFO:     Epoch: 67
2022-11-23 02:10:42,448 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8231271403757009, 'Total loss': 0.8231271403757009} | train loss {'Reaction outcome loss': 0.8139176302955218, 'Total loss': 0.8139176302955218}
2022-11-23 02:10:42,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:42,450 INFO:     Epoch: 68
2022-11-23 02:10:43,714 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7792122939770872, 'Total loss': 0.7792122939770872} | train loss {'Reaction outcome loss': 0.8239875023181622, 'Total loss': 0.8239875023181622}
2022-11-23 02:10:43,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:43,714 INFO:     Epoch: 69
2022-11-23 02:10:44,980 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7973084043372761, 'Total loss': 0.7973084043372761} | train loss {'Reaction outcome loss': 0.8182577346017968, 'Total loss': 0.8182577346017968}
2022-11-23 02:10:44,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:44,982 INFO:     Epoch: 70
2022-11-23 02:10:46,134 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7920914244922724, 'Total loss': 0.7920914244922724} | train loss {'Reaction outcome loss': 0.8256902656695138, 'Total loss': 0.8256902656695138}
2022-11-23 02:10:46,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:46,135 INFO:     Epoch: 71
2022-11-23 02:10:47,192 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7876267636364157, 'Total loss': 0.7876267636364157} | train loss {'Reaction outcome loss': 0.8266679589082355, 'Total loss': 0.8266679589082355}
2022-11-23 02:10:47,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:47,193 INFO:     Epoch: 72
2022-11-23 02:10:48,273 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7835669842633334, 'Total loss': 0.7835669842633334} | train loss {'Reaction outcome loss': 0.8164014134571137, 'Total loss': 0.8164014134571137}
2022-11-23 02:10:48,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:48,274 INFO:     Epoch: 73
2022-11-23 02:10:49,481 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7886552587151527, 'Total loss': 0.7886552587151527} | train loss {'Reaction outcome loss': 0.8200667607880797, 'Total loss': 0.8200667607880797}
2022-11-23 02:10:49,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:49,482 INFO:     Epoch: 74
2022-11-23 02:10:50,668 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8021374981511723, 'Total loss': 0.8021374981511723} | train loss {'Reaction outcome loss': 0.824596539079419, 'Total loss': 0.824596539079419}
2022-11-23 02:10:50,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:50,669 INFO:     Epoch: 75
2022-11-23 02:10:51,722 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8056071089072661, 'Total loss': 0.8056071089072661} | train loss {'Reaction outcome loss': 0.8229849330085491, 'Total loss': 0.8229849330085491}
2022-11-23 02:10:51,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:51,723 INFO:     Epoch: 76
2022-11-23 02:10:52,797 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7753563604571603, 'Total loss': 0.7753563604571603} | train loss {'Reaction outcome loss': 0.8261348951442039, 'Total loss': 0.8261348951442039}
2022-11-23 02:10:52,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:52,797 INFO:     Epoch: 77
2022-11-23 02:10:53,860 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8052694973620501, 'Total loss': 0.8052694973620501} | train loss {'Reaction outcome loss': 0.824830508304511, 'Total loss': 0.824830508304511}
2022-11-23 02:10:53,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:53,861 INFO:     Epoch: 78
2022-11-23 02:10:54,911 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7878342108293013, 'Total loss': 0.7878342108293013} | train loss {'Reaction outcome loss': 0.8191593986773781, 'Total loss': 0.8191593986773781}
2022-11-23 02:10:54,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:54,912 INFO:     Epoch: 79
2022-11-23 02:10:55,967 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7865308611230417, 'Total loss': 0.7865308611230417} | train loss {'Reaction outcome loss': 0.816820835114008, 'Total loss': 0.816820835114008}
2022-11-23 02:10:55,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:55,969 INFO:     Epoch: 80
2022-11-23 02:10:57,009 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7809129770506512, 'Total loss': 0.7809129770506512} | train loss {'Reaction outcome loss': 0.8153050930393853, 'Total loss': 0.8153050930393853}
2022-11-23 02:10:57,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:57,010 INFO:     Epoch: 81
2022-11-23 02:10:58,055 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7881027697162195, 'Total loss': 0.7881027697162195} | train loss {'Reaction outcome loss': 0.8154410064401414, 'Total loss': 0.8154410064401414}
2022-11-23 02:10:58,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:58,056 INFO:     Epoch: 82
2022-11-23 02:10:59,091 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7811472246592696, 'Total loss': 0.7811472246592696} | train loss {'Reaction outcome loss': 0.8198531581624316, 'Total loss': 0.8198531581624316}
2022-11-23 02:10:59,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:10:59,092 INFO:     Epoch: 83
2022-11-23 02:11:00,204 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7935517626729879, 'Total loss': 0.7935517626729879} | train loss {'Reaction outcome loss': 0.8172884178065095, 'Total loss': 0.8172884178065095}
2022-11-23 02:11:00,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:00,204 INFO:     Epoch: 84
2022-11-23 02:11:01,308 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7741807489232584, 'Total loss': 0.7741807489232584} | train loss {'Reaction outcome loss': 0.8203765617811728, 'Total loss': 0.8203765617811728}
2022-11-23 02:11:01,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:01,310 INFO:     Epoch: 85
2022-11-23 02:11:02,467 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7792905487797477, 'Total loss': 0.7792905487797477} | train loss {'Reaction outcome loss': 0.8205990739438215, 'Total loss': 0.8205990739438215}
2022-11-23 02:11:02,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:02,469 INFO:     Epoch: 86
2022-11-23 02:11:03,629 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7657380408861421, 'Total loss': 0.7657380408861421} | train loss {'Reaction outcome loss': 0.8246727607510833, 'Total loss': 0.8246727607510833}
2022-11-23 02:11:03,630 INFO:     Found new best model at epoch 86
2022-11-23 02:11:03,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:03,632 INFO:     Epoch: 87
2022-11-23 02:11:05,053 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7841075204990127, 'Total loss': 0.7841075204990127} | train loss {'Reaction outcome loss': 0.8187215995149091, 'Total loss': 0.8187215995149091}
2022-11-23 02:11:05,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:05,053 INFO:     Epoch: 88
2022-11-23 02:11:06,452 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7914919805797663, 'Total loss': 0.7914919805797663} | train loss {'Reaction outcome loss': 0.8198752605963332, 'Total loss': 0.8198752605963332}
2022-11-23 02:11:06,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:06,453 INFO:     Epoch: 89
2022-11-23 02:11:07,752 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7754558846354485, 'Total loss': 0.7754558846354485} | train loss {'Reaction outcome loss': 0.8177390425100259, 'Total loss': 0.8177390425100259}
2022-11-23 02:11:07,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:07,754 INFO:     Epoch: 90
2022-11-23 02:11:08,987 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7954150092872706, 'Total loss': 0.7954150092872706} | train loss {'Reaction outcome loss': 0.8142429258417987, 'Total loss': 0.8142429258417987}
2022-11-23 02:11:08,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:08,989 INFO:     Epoch: 91
2022-11-23 02:11:10,242 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7798116471279751, 'Total loss': 0.7798116471279751} | train loss {'Reaction outcome loss': 0.8197190808622461, 'Total loss': 0.8197190808622461}
2022-11-23 02:11:10,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:10,242 INFO:     Epoch: 92
2022-11-23 02:11:11,410 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7680009898136962, 'Total loss': 0.7680009898136962} | train loss {'Reaction outcome loss': 0.8208442498073887, 'Total loss': 0.8208442498073887}
2022-11-23 02:11:11,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:11,411 INFO:     Epoch: 93
2022-11-23 02:11:12,699 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7915071465752341, 'Total loss': 0.7915071465752341} | train loss {'Reaction outcome loss': 0.8160652641342719, 'Total loss': 0.8160652641342719}
2022-11-23 02:11:12,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:12,699 INFO:     Epoch: 94
2022-11-23 02:11:14,004 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7834342826496471, 'Total loss': 0.7834342826496471} | train loss {'Reaction outcome loss': 0.821275017160153, 'Total loss': 0.821275017160153}
2022-11-23 02:11:14,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:14,005 INFO:     Epoch: 95
2022-11-23 02:11:15,218 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7794326354156841, 'Total loss': 0.7794326354156841} | train loss {'Reaction outcome loss': 0.8362136078990905, 'Total loss': 0.8362136078990905}
2022-11-23 02:11:15,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:15,218 INFO:     Epoch: 96
2022-11-23 02:11:16,364 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7919109111482446, 'Total loss': 0.7919109111482446} | train loss {'Reaction outcome loss': 0.8221693959253037, 'Total loss': 0.8221693959253037}
2022-11-23 02:11:16,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:16,364 INFO:     Epoch: 97
2022-11-23 02:11:17,428 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7858557850122452, 'Total loss': 0.7858557850122452} | train loss {'Reaction outcome loss': 0.8194235854061992, 'Total loss': 0.8194235854061992}
2022-11-23 02:11:17,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:17,430 INFO:     Epoch: 98
2022-11-23 02:11:18,502 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7723393345421011, 'Total loss': 0.7723393345421011} | train loss {'Reaction outcome loss': 0.8244174969823737, 'Total loss': 0.8244174969823737}
2022-11-23 02:11:18,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:18,503 INFO:     Epoch: 99
2022-11-23 02:11:19,569 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7798197045922279, 'Total loss': 0.7798197045922279} | train loss {'Reaction outcome loss': 0.8152193624963645, 'Total loss': 0.8152193624963645}
2022-11-23 02:11:19,570 INFO:     Best model found after epoch 87 of 100.
2022-11-23 02:11:19,570 INFO:   Done with stage: TRAINING
2022-11-23 02:11:19,571 INFO:   Starting stage: EVALUATION
2022-11-23 02:11:19,775 INFO:   Done with stage: EVALUATION
2022-11-23 02:11:19,776 INFO:   Leaving out SEQ value Fold_9
2022-11-23 02:11:19,810 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:11:19,811 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:11:21,077 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:11:21,078 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:11:21,261 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:11:21,262 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:11:21,262 INFO:     No hyperparam tuning for this model
2022-11-23 02:11:21,262 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:11:21,262 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:11:21,263 INFO:     None feature selector for col prot
2022-11-23 02:11:21,263 INFO:     None feature selector for col prot
2022-11-23 02:11:21,264 INFO:     None feature selector for col prot
2022-11-23 02:11:21,265 INFO:     None feature selector for col chem
2022-11-23 02:11:21,266 INFO:     None feature selector for col chem
2022-11-23 02:11:21,266 INFO:     None feature selector for col chem
2022-11-23 02:11:21,266 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:11:21,267 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:11:21,269 INFO:     Number of params in model 168571
2022-11-23 02:11:21,276 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:11:21,276 INFO:   Starting stage: TRAINING
2022-11-23 02:11:21,359 INFO:     Val loss before train {'Reaction outcome loss': 1.0073560029268265, 'Total loss': 1.0073560029268265}
2022-11-23 02:11:21,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:21,359 INFO:     Epoch: 0
2022-11-23 02:11:22,559 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8855924944985997, 'Total loss': 0.8855924944985997} | train loss {'Reaction outcome loss': 0.8946406299527357, 'Total loss': 0.8946406299527357}
2022-11-23 02:11:22,559 INFO:     Found new best model at epoch 0
2022-11-23 02:11:22,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:22,561 INFO:     Epoch: 1
2022-11-23 02:11:23,672 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8771339858120138, 'Total loss': 0.8771339858120138} | train loss {'Reaction outcome loss': 0.8746789516466349, 'Total loss': 0.8746789516466349}
2022-11-23 02:11:23,672 INFO:     Found new best model at epoch 1
2022-11-23 02:11:23,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:23,674 INFO:     Epoch: 2
2022-11-23 02:11:24,950 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8718694191087376, 'Total loss': 0.8718694191087376} | train loss {'Reaction outcome loss': 0.8606259920577771, 'Total loss': 0.8606259920577771}
2022-11-23 02:11:24,951 INFO:     Found new best model at epoch 2
2022-11-23 02:11:24,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:24,954 INFO:     Epoch: 3
2022-11-23 02:11:26,286 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8434686532074754, 'Total loss': 0.8434686532074754} | train loss {'Reaction outcome loss': 0.8607178755134706, 'Total loss': 0.8607178755134706}
2022-11-23 02:11:26,287 INFO:     Found new best model at epoch 3
2022-11-23 02:11:26,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:26,289 INFO:     Epoch: 4
2022-11-23 02:11:27,360 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8373538452115926, 'Total loss': 0.8373538452115926} | train loss {'Reaction outcome loss': 0.8580684605759648, 'Total loss': 0.8580684605759648}
2022-11-23 02:11:27,360 INFO:     Found new best model at epoch 4
2022-11-23 02:11:27,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:27,362 INFO:     Epoch: 5
2022-11-23 02:11:28,631 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8581745448437604, 'Total loss': 0.8581745448437604} | train loss {'Reaction outcome loss': 0.8462239446849958, 'Total loss': 0.8462239446849958}
2022-11-23 02:11:28,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:28,633 INFO:     Epoch: 6
2022-11-23 02:11:29,959 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8480927260084585, 'Total loss': 0.8480927260084585} | train loss {'Reaction outcome loss': 0.8539704780588265, 'Total loss': 0.8539704780588265}
2022-11-23 02:11:29,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:29,959 INFO:     Epoch: 7
2022-11-23 02:11:31,274 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8737401603297754, 'Total loss': 0.8737401603297754} | train loss {'Reaction outcome loss': 0.853598731852736, 'Total loss': 0.853598731852736}
2022-11-23 02:11:31,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:31,274 INFO:     Epoch: 8
2022-11-23 02:11:32,522 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8587683893062852, 'Total loss': 0.8587683893062852} | train loss {'Reaction outcome loss': 0.8558567957839502, 'Total loss': 0.8558567957839502}
2022-11-23 02:11:32,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:32,524 INFO:     Epoch: 9
2022-11-23 02:11:33,668 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8691024739633907, 'Total loss': 0.8691024739633907} | train loss {'Reaction outcome loss': 0.8508557299612022, 'Total loss': 0.8508557299612022}
2022-11-23 02:11:33,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:33,668 INFO:     Epoch: 10
2022-11-23 02:11:34,730 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8533679538152434, 'Total loss': 0.8533679538152434} | train loss {'Reaction outcome loss': 0.8474982695782233, 'Total loss': 0.8474982695782233}
2022-11-23 02:11:34,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:34,731 INFO:     Epoch: 11
2022-11-23 02:11:36,010 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8418647159229625, 'Total loss': 0.8418647159229625} | train loss {'Reaction outcome loss': 0.8429662731856953, 'Total loss': 0.8429662731856953}
2022-11-23 02:11:36,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:36,011 INFO:     Epoch: 12
2022-11-23 02:11:37,309 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8483741357922554, 'Total loss': 0.8483741357922554} | train loss {'Reaction outcome loss': 0.8444805627892374, 'Total loss': 0.8444805627892374}
2022-11-23 02:11:37,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:37,309 INFO:     Epoch: 13
2022-11-23 02:11:38,370 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8541938371279023, 'Total loss': 0.8541938371279023} | train loss {'Reaction outcome loss': 0.8445686655729888, 'Total loss': 0.8445686655729888}
2022-11-23 02:11:38,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:38,370 INFO:     Epoch: 14
2022-11-23 02:11:39,419 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8616928586905653, 'Total loss': 0.8616928586905653} | train loss {'Reaction outcome loss': 0.8392488396903763, 'Total loss': 0.8392488396903763}
2022-11-23 02:11:39,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:39,420 INFO:     Epoch: 15
2022-11-23 02:11:40,454 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8466268039562486, 'Total loss': 0.8466268039562486} | train loss {'Reaction outcome loss': 0.8435506598669508, 'Total loss': 0.8435506598669508}
2022-11-23 02:11:40,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:40,456 INFO:     Epoch: 16
2022-11-23 02:11:41,481 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8570782874118198, 'Total loss': 0.8570782874118198} | train loss {'Reaction outcome loss': 0.8396835313876149, 'Total loss': 0.8396835313876149}
2022-11-23 02:11:41,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:41,481 INFO:     Epoch: 17
2022-11-23 02:11:42,527 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8475109345533631, 'Total loss': 0.8475109345533631} | train loss {'Reaction outcome loss': 0.8492936700703162, 'Total loss': 0.8492936700703162}
2022-11-23 02:11:42,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:42,529 INFO:     Epoch: 18
2022-11-23 02:11:43,556 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8605813099579378, 'Total loss': 0.8605813099579378} | train loss {'Reaction outcome loss': 0.8377821802911971, 'Total loss': 0.8377821802911971}
2022-11-23 02:11:43,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:43,556 INFO:     Epoch: 19
2022-11-23 02:11:44,579 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8458791510625319, 'Total loss': 0.8458791510625319} | train loss {'Reaction outcome loss': 0.8508895074548991, 'Total loss': 0.8508895074548991}
2022-11-23 02:11:44,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:44,580 INFO:     Epoch: 20
2022-11-23 02:11:45,660 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8459917171434923, 'Total loss': 0.8459917171434923} | train loss {'Reaction outcome loss': 0.8334002041367263, 'Total loss': 0.8334002041367263}
2022-11-23 02:11:45,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:45,662 INFO:     Epoch: 21
2022-11-23 02:11:46,705 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8330856663259593, 'Total loss': 0.8330856663259593} | train loss {'Reaction outcome loss': 0.8435399367017784, 'Total loss': 0.8435399367017784}
2022-11-23 02:11:46,705 INFO:     Found new best model at epoch 21
2022-11-23 02:11:46,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:46,707 INFO:     Epoch: 22
2022-11-23 02:11:47,762 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8358989276669242, 'Total loss': 0.8358989276669242} | train loss {'Reaction outcome loss': 0.8387859000368156, 'Total loss': 0.8387859000368156}
2022-11-23 02:11:47,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:47,763 INFO:     Epoch: 23
2022-11-23 02:11:48,929 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8327866731719538, 'Total loss': 0.8327866731719538} | train loss {'Reaction outcome loss': 0.8368178558977026, 'Total loss': 0.8368178558977026}
2022-11-23 02:11:48,929 INFO:     Found new best model at epoch 23
2022-11-23 02:11:48,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:48,931 INFO:     Epoch: 24
2022-11-23 02:11:50,193 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8411066955463453, 'Total loss': 0.8411066955463453} | train loss {'Reaction outcome loss': 0.8512730263022759, 'Total loss': 0.8512730263022759}
2022-11-23 02:11:50,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:50,194 INFO:     Epoch: 25
2022-11-23 02:11:51,447 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.844503488052975, 'Total loss': 0.844503488052975} | train loss {'Reaction outcome loss': 0.8328493716806052, 'Total loss': 0.8328493716806052}
2022-11-23 02:11:51,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:51,449 INFO:     Epoch: 26
2022-11-23 02:11:52,675 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8512172448364171, 'Total loss': 0.8512172448364171} | train loss {'Reaction outcome loss': 0.8341766352112959, 'Total loss': 0.8341766352112959}
2022-11-23 02:11:52,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:52,676 INFO:     Epoch: 27
2022-11-23 02:11:53,908 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8320542275905609, 'Total loss': 0.8320542275905609} | train loss {'Reaction outcome loss': 0.8356435499210589, 'Total loss': 0.8356435499210589}
2022-11-23 02:11:53,909 INFO:     Found new best model at epoch 27
2022-11-23 02:11:53,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:53,912 INFO:     Epoch: 28
2022-11-23 02:11:55,098 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8383238816803152, 'Total loss': 0.8383238816803152} | train loss {'Reaction outcome loss': 0.8415335445751545, 'Total loss': 0.8415335445751545}
2022-11-23 02:11:55,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:55,099 INFO:     Epoch: 29
2022-11-23 02:11:56,155 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8523258377205242, 'Total loss': 0.8523258377205242} | train loss {'Reaction outcome loss': 0.8390961264671102, 'Total loss': 0.8390961264671102}
2022-11-23 02:11:56,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:56,156 INFO:     Epoch: 30
2022-11-23 02:11:57,274 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8446831445802342, 'Total loss': 0.8446831445802342} | train loss {'Reaction outcome loss': 0.8371352501485029, 'Total loss': 0.8371352501485029}
2022-11-23 02:11:57,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:57,274 INFO:     Epoch: 31
2022-11-23 02:11:58,436 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8299623111432249, 'Total loss': 0.8299623111432249} | train loss {'Reaction outcome loss': 0.8417022190837242, 'Total loss': 0.8417022190837242}
2022-11-23 02:11:58,437 INFO:     Found new best model at epoch 31
2022-11-23 02:11:58,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:58,438 INFO:     Epoch: 32
2022-11-23 02:11:59,652 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8511283343488519, 'Total loss': 0.8511283343488519} | train loss {'Reaction outcome loss': 0.8366552051986277, 'Total loss': 0.8366552051986277}
2022-11-23 02:11:59,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:11:59,654 INFO:     Epoch: 33
2022-11-23 02:12:01,079 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.846376509829001, 'Total loss': 0.846376509829001} | train loss {'Reaction outcome loss': 0.8442888960905885, 'Total loss': 0.8442888960905885}
2022-11-23 02:12:01,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:01,081 INFO:     Epoch: 34
2022-11-23 02:12:02,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8538093519481745, 'Total loss': 0.8538093519481745} | train loss {'Reaction outcome loss': 0.8328813039942792, 'Total loss': 0.8328813039942792}
2022-11-23 02:12:02,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:02,529 INFO:     Epoch: 35
2022-11-23 02:12:04,002 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8247655968774449, 'Total loss': 0.8247655968774449} | train loss {'Reaction outcome loss': 0.8411018628823129, 'Total loss': 0.8411018628823129}
2022-11-23 02:12:04,005 INFO:     Found new best model at epoch 35
2022-11-23 02:12:04,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:04,008 INFO:     Epoch: 36
2022-11-23 02:12:05,441 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8302116678519682, 'Total loss': 0.8302116678519682} | train loss {'Reaction outcome loss': 0.8388336037817271, 'Total loss': 0.8388336037817271}
2022-11-23 02:12:05,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:05,442 INFO:     Epoch: 37
2022-11-23 02:12:06,914 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8510666638612747, 'Total loss': 0.8510666638612747} | train loss {'Reaction outcome loss': 0.8368772658922894, 'Total loss': 0.8368772658922894}
2022-11-23 02:12:06,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:06,916 INFO:     Epoch: 38
2022-11-23 02:12:08,165 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8391618864102797, 'Total loss': 0.8391618864102797} | train loss {'Reaction outcome loss': 0.832980928211077, 'Total loss': 0.832980928211077}
2022-11-23 02:12:08,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:08,165 INFO:     Epoch: 39
2022-11-23 02:12:09,563 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8440823812376369, 'Total loss': 0.8440823812376369} | train loss {'Reaction outcome loss': 0.8440249330601711, 'Total loss': 0.8440249330601711}
2022-11-23 02:12:09,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:09,563 INFO:     Epoch: 40
2022-11-23 02:12:10,795 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8531460585919294, 'Total loss': 0.8531460585919294} | train loss {'Reaction outcome loss': 0.8389354734587283, 'Total loss': 0.8389354734587283}
2022-11-23 02:12:10,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:10,798 INFO:     Epoch: 41
2022-11-23 02:12:11,969 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8681563213467598, 'Total loss': 0.8681563213467598} | train loss {'Reaction outcome loss': 0.8312899714961708, 'Total loss': 0.8312899714961708}
2022-11-23 02:12:11,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:11,970 INFO:     Epoch: 42
2022-11-23 02:12:13,170 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8443818945776332, 'Total loss': 0.8443818945776332} | train loss {'Reaction outcome loss': 0.8384509399110972, 'Total loss': 0.8384509399110972}
2022-11-23 02:12:13,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:13,170 INFO:     Epoch: 43
2022-11-23 02:12:14,368 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8335402336987582, 'Total loss': 0.8335402336987582} | train loss {'Reaction outcome loss': 0.8448762030977952, 'Total loss': 0.8448762030977952}
2022-11-23 02:12:14,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:14,369 INFO:     Epoch: 44
2022-11-23 02:12:15,656 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8390797457911752, 'Total loss': 0.8390797457911752} | train loss {'Reaction outcome loss': 0.8360664796250069, 'Total loss': 0.8360664796250069}
2022-11-23 02:12:15,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:15,658 INFO:     Epoch: 45
2022-11-23 02:12:16,968 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.832702865654772, 'Total loss': 0.832702865654772} | train loss {'Reaction outcome loss': 0.8327861191169453, 'Total loss': 0.8327861191169453}
2022-11-23 02:12:16,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:16,969 INFO:     Epoch: 46
2022-11-23 02:12:18,193 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8349589746106755, 'Total loss': 0.8349589746106755} | train loss {'Reaction outcome loss': 0.824882809691101, 'Total loss': 0.824882809691101}
2022-11-23 02:12:18,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:18,194 INFO:     Epoch: 47
2022-11-23 02:12:19,368 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8331216736273332, 'Total loss': 0.8331216736273332} | train loss {'Reaction outcome loss': 0.8276728998854576, 'Total loss': 0.8276728998854576}
2022-11-23 02:12:19,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:19,368 INFO:     Epoch: 48
2022-11-23 02:12:20,534 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8445444093509153, 'Total loss': 0.8445444093509153} | train loss {'Reaction outcome loss': 0.8422980216833261, 'Total loss': 0.8422980216833261}
2022-11-23 02:12:20,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:20,535 INFO:     Epoch: 49
2022-11-23 02:12:21,830 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8351305953480981, 'Total loss': 0.8351305953480981} | train loss {'Reaction outcome loss': 0.8354943535829845, 'Total loss': 0.8354943535829845}
2022-11-23 02:12:21,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:21,831 INFO:     Epoch: 50
2022-11-23 02:12:22,995 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8335281204093586, 'Total loss': 0.8335281204093586} | train loss {'Reaction outcome loss': 0.8323279498559744, 'Total loss': 0.8323279498559744}
2022-11-23 02:12:22,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:22,996 INFO:     Epoch: 51
2022-11-23 02:12:24,353 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8596984540874307, 'Total loss': 0.8596984540874307} | train loss {'Reaction outcome loss': 0.8266515899524998, 'Total loss': 0.8266515899524998}
2022-11-23 02:12:24,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:24,355 INFO:     Epoch: 52
2022-11-23 02:12:25,760 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8454696061936292, 'Total loss': 0.8454696061936292} | train loss {'Reaction outcome loss': 0.8366546843216004, 'Total loss': 0.8366546843216004}
2022-11-23 02:12:25,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:25,761 INFO:     Epoch: 53
2022-11-23 02:12:27,154 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8669091483408754, 'Total loss': 0.8669091483408754} | train loss {'Reaction outcome loss': 0.8349282258917928, 'Total loss': 0.8349282258917928}
2022-11-23 02:12:27,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:27,154 INFO:     Epoch: 54
2022-11-23 02:12:28,273 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8400002548640425, 'Total loss': 0.8400002548640425} | train loss {'Reaction outcome loss': 0.8357830063292855, 'Total loss': 0.8357830063292855}
2022-11-23 02:12:28,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:28,273 INFO:     Epoch: 55
2022-11-23 02:12:29,504 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8498852727088061, 'Total loss': 0.8498852727088061} | train loss {'Reaction outcome loss': 0.8273861130722139, 'Total loss': 0.8273861130722139}
2022-11-23 02:12:29,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:29,505 INFO:     Epoch: 56
2022-11-23 02:12:30,680 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8443083681843497, 'Total loss': 0.8443083681843497} | train loss {'Reaction outcome loss': 0.8282277104086601, 'Total loss': 0.8282277104086601}
2022-11-23 02:12:30,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:30,680 INFO:     Epoch: 57
2022-11-23 02:12:32,081 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8487222966822711, 'Total loss': 0.8487222966822711} | train loss {'Reaction outcome loss': 0.8319289144430204, 'Total loss': 0.8319289144430204}
2022-11-23 02:12:32,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:32,083 INFO:     Epoch: 58
2022-11-23 02:12:33,443 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8988512307405472, 'Total loss': 0.8988512307405472} | train loss {'Reaction outcome loss': 0.8314052308619264, 'Total loss': 0.8314052308619264}
2022-11-23 02:12:33,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:33,445 INFO:     Epoch: 59
2022-11-23 02:12:34,596 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8377603217959404, 'Total loss': 0.8377603217959404} | train loss {'Reaction outcome loss': 0.8320988584988513, 'Total loss': 0.8320988584988513}
2022-11-23 02:12:34,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:34,598 INFO:     Epoch: 60
2022-11-23 02:12:35,744 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8309720517559485, 'Total loss': 0.8309720517559485} | train loss {'Reaction outcome loss': 0.8376899567934183, 'Total loss': 0.8376899567934183}
2022-11-23 02:12:35,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:35,746 INFO:     Epoch: 61
2022-11-23 02:12:36,900 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8469316722317175, 'Total loss': 0.8469316722317175} | train loss {'Reaction outcome loss': 0.8346985194847168, 'Total loss': 0.8346985194847168}
2022-11-23 02:12:36,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:36,901 INFO:     Epoch: 62
2022-11-23 02:12:38,037 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8303001821041107, 'Total loss': 0.8303001821041107} | train loss {'Reaction outcome loss': 0.8256399278276363, 'Total loss': 0.8256399278276363}
2022-11-23 02:12:38,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:38,038 INFO:     Epoch: 63
2022-11-23 02:12:39,403 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8446611294692213, 'Total loss': 0.8446611294692213} | train loss {'Reaction outcome loss': 0.8299984019777553, 'Total loss': 0.8299984019777553}
2022-11-23 02:12:39,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:39,404 INFO:     Epoch: 64
2022-11-23 02:12:40,806 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8322991464625705, 'Total loss': 0.8322991464625705} | train loss {'Reaction outcome loss': 0.8431886905118039, 'Total loss': 0.8431886905118039}
2022-11-23 02:12:40,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:40,808 INFO:     Epoch: 65
2022-11-23 02:12:42,085 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8471214398741722, 'Total loss': 0.8471214398741722} | train loss {'Reaction outcome loss': 0.835278887256437, 'Total loss': 0.835278887256437}
2022-11-23 02:12:42,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:42,087 INFO:     Epoch: 66
2022-11-23 02:12:43,519 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8275959065014665, 'Total loss': 0.8275959065014665} | train loss {'Reaction outcome loss': 0.8438523077530417, 'Total loss': 0.8438523077530417}
2022-11-23 02:12:43,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:43,520 INFO:     Epoch: 67
2022-11-23 02:12:44,992 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8527790578928861, 'Total loss': 0.8527790578928861} | train loss {'Reaction outcome loss': 0.8387364215455074, 'Total loss': 0.8387364215455074}
2022-11-23 02:12:44,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:44,994 INFO:     Epoch: 68
2022-11-23 02:12:46,320 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8322512412613089, 'Total loss': 0.8322512412613089} | train loss {'Reaction outcome loss': 0.8307754222439369, 'Total loss': 0.8307754222439369}
2022-11-23 02:12:46,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:46,322 INFO:     Epoch: 69
2022-11-23 02:12:47,609 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8144556145099077, 'Total loss': 0.8144556145099077} | train loss {'Reaction outcome loss': 0.8346742671510952, 'Total loss': 0.8346742671510952}
2022-11-23 02:12:47,609 INFO:     Found new best model at epoch 69
2022-11-23 02:12:47,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:47,610 INFO:     Epoch: 70
2022-11-23 02:12:48,791 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8324460380456664, 'Total loss': 0.8324460380456664} | train loss {'Reaction outcome loss': 0.8278102117028796, 'Total loss': 0.8278102117028796}
2022-11-23 02:12:48,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:48,792 INFO:     Epoch: 71
2022-11-23 02:12:50,045 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8528492044318806, 'Total loss': 0.8528492044318806} | train loss {'Reaction outcome loss': 0.831022344137493, 'Total loss': 0.831022344137493}
2022-11-23 02:12:50,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:50,046 INFO:     Epoch: 72
2022-11-23 02:12:51,402 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8340745344758034, 'Total loss': 0.8340745344758034} | train loss {'Reaction outcome loss': 0.8297939516513454, 'Total loss': 0.8297939516513454}
2022-11-23 02:12:51,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:51,404 INFO:     Epoch: 73
2022-11-23 02:12:52,663 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8264033421874046, 'Total loss': 0.8264033421874046} | train loss {'Reaction outcome loss': 0.8317743539810181, 'Total loss': 0.8317743539810181}
2022-11-23 02:12:52,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:52,664 INFO:     Epoch: 74
2022-11-23 02:12:53,926 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8270693617788228, 'Total loss': 0.8270693617788228} | train loss {'Reaction outcome loss': 0.8325897586731775, 'Total loss': 0.8325897586731775}
2022-11-23 02:12:53,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:53,927 INFO:     Epoch: 75
2022-11-23 02:12:55,329 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8424535197290507, 'Total loss': 0.8424535197290507} | train loss {'Reaction outcome loss': 0.8271883414824482, 'Total loss': 0.8271883414824482}
2022-11-23 02:12:55,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:55,333 INFO:     Epoch: 76
2022-11-23 02:12:56,716 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8344722261483019, 'Total loss': 0.8344722261483019} | train loss {'Reaction outcome loss': 0.8271741016432341, 'Total loss': 0.8271741016432341}
2022-11-23 02:12:56,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:56,717 INFO:     Epoch: 77
2022-11-23 02:12:58,049 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8233719305558638, 'Total loss': 0.8233719305558638} | train loss {'Reaction outcome loss': 0.8338610095533765, 'Total loss': 0.8338610095533765}
2022-11-23 02:12:58,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:58,050 INFO:     Epoch: 78
2022-11-23 02:12:59,372 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8237295658750967, 'Total loss': 0.8237295658750967} | train loss {'Reaction outcome loss': 0.8289941071498732, 'Total loss': 0.8289941071498732}
2022-11-23 02:12:59,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:12:59,374 INFO:     Epoch: 79
2022-11-23 02:13:00,768 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8396342301910574, 'Total loss': 0.8396342301910574} | train loss {'Reaction outcome loss': 0.8359593314680493, 'Total loss': 0.8359593314680493}
2022-11-23 02:13:00,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:00,769 INFO:     Epoch: 80
2022-11-23 02:13:02,162 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8419996073300188, 'Total loss': 0.8419996073300188} | train loss {'Reaction outcome loss': 0.8272862323080963, 'Total loss': 0.8272862323080963}
2022-11-23 02:13:02,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:02,164 INFO:     Epoch: 81
2022-11-23 02:13:03,393 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8343092135407708, 'Total loss': 0.8343092135407708} | train loss {'Reaction outcome loss': 0.8261503390515381, 'Total loss': 0.8261503390515381}
2022-11-23 02:13:03,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:03,393 INFO:     Epoch: 82
2022-11-23 02:13:04,533 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8230991620909084, 'Total loss': 0.8230991620909084} | train loss {'Reaction outcome loss': 0.826440470059391, 'Total loss': 0.826440470059391}
2022-11-23 02:13:04,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:04,533 INFO:     Epoch: 83
2022-11-23 02:13:05,670 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8438299081542275, 'Total loss': 0.8438299081542275} | train loss {'Reaction outcome loss': 0.8262412094394205, 'Total loss': 0.8262412094394205}
2022-11-23 02:13:05,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:05,672 INFO:     Epoch: 84
2022-11-23 02:13:06,895 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8203539848327637, 'Total loss': 0.8203539848327637} | train loss {'Reaction outcome loss': 0.8296627981460046, 'Total loss': 0.8296627981460046}
2022-11-23 02:13:06,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:06,896 INFO:     Epoch: 85
2022-11-23 02:13:07,992 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8358017788691954, 'Total loss': 0.8358017788691954} | train loss {'Reaction outcome loss': 0.82699819069039, 'Total loss': 0.82699819069039}
2022-11-23 02:13:07,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:07,993 INFO:     Epoch: 86
2022-11-23 02:13:09,101 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8222443190487948, 'Total loss': 0.8222443190487948} | train loss {'Reaction outcome loss': 0.8292230355594805, 'Total loss': 0.8292230355594805}
2022-11-23 02:13:09,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:09,103 INFO:     Epoch: 87
2022-11-23 02:13:10,391 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8463507450439713, 'Total loss': 0.8463507450439713} | train loss {'Reaction outcome loss': 0.8294170731867132, 'Total loss': 0.8294170731867132}
2022-11-23 02:13:10,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:10,392 INFO:     Epoch: 88
2022-11-23 02:13:11,682 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8300872038711201, 'Total loss': 0.8300872038711201} | train loss {'Reaction outcome loss': 0.831001111249692, 'Total loss': 0.831001111249692}
2022-11-23 02:13:11,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:11,682 INFO:     Epoch: 89
2022-11-23 02:13:12,919 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8526797497814352, 'Total loss': 0.8526797497814352} | train loss {'Reaction outcome loss': 0.8330263511130684, 'Total loss': 0.8330263511130684}
2022-11-23 02:13:12,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:12,922 INFO:     Epoch: 90
2022-11-23 02:13:14,146 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8474986553192139, 'Total loss': 0.8474986553192139} | train loss {'Reaction outcome loss': 0.8392814484685056, 'Total loss': 0.8392814484685056}
2022-11-23 02:13:14,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:14,147 INFO:     Epoch: 91
2022-11-23 02:13:15,440 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8309964564713564, 'Total loss': 0.8309964564713564} | train loss {'Reaction outcome loss': 0.8321247733073679, 'Total loss': 0.8321247733073679}
2022-11-23 02:13:15,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:15,441 INFO:     Epoch: 92
2022-11-23 02:13:16,662 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8304538537155498, 'Total loss': 0.8304538537155498} | train loss {'Reaction outcome loss': 0.8364269896316142, 'Total loss': 0.8364269896316142}
2022-11-23 02:13:16,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:16,664 INFO:     Epoch: 93
2022-11-23 02:13:17,902 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8354156721721996, 'Total loss': 0.8354156721721996} | train loss {'Reaction outcome loss': 0.8325753030989335, 'Total loss': 0.8325753030989335}
2022-11-23 02:13:17,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:17,902 INFO:     Epoch: 94
2022-11-23 02:13:18,994 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8338937529108741, 'Total loss': 0.8338937529108741} | train loss {'Reaction outcome loss': 0.8344654671335028, 'Total loss': 0.8344654671335028}
2022-11-23 02:13:18,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:18,994 INFO:     Epoch: 95
2022-11-23 02:13:20,076 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8531220162456686, 'Total loss': 0.8531220162456686} | train loss {'Reaction outcome loss': 0.8306491472400152, 'Total loss': 0.8306491472400152}
2022-11-23 02:13:20,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:20,077 INFO:     Epoch: 96
2022-11-23 02:13:21,176 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8222364282066171, 'Total loss': 0.8222364282066171} | train loss {'Reaction outcome loss': 0.8341438585688711, 'Total loss': 0.8341438585688711}
2022-11-23 02:13:21,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:21,176 INFO:     Epoch: 97
2022-11-23 02:13:22,320 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8363773822784424, 'Total loss': 0.8363773822784424} | train loss {'Reaction outcome loss': 0.8315377371755206, 'Total loss': 0.8315377371755206}
2022-11-23 02:13:22,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:22,320 INFO:     Epoch: 98
2022-11-23 02:13:23,388 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8288635144179518, 'Total loss': 0.8288635144179518} | train loss {'Reaction outcome loss': 0.8311741359320729, 'Total loss': 0.8311741359320729}
2022-11-23 02:13:23,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:23,389 INFO:     Epoch: 99
2022-11-23 02:13:24,414 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8299068388613787, 'Total loss': 0.8299068388613787} | train loss {'Reaction outcome loss': 0.83174318931846, 'Total loss': 0.83174318931846}
2022-11-23 02:13:24,414 INFO:     Best model found after epoch 70 of 100.
2022-11-23 02:13:24,415 INFO:   Done with stage: TRAINING
2022-11-23 02:13:24,416 INFO:   Starting stage: EVALUATION
2022-11-23 02:13:24,610 INFO:   Done with stage: EVALUATION
2022-11-23 02:13:24,621 INFO:   Leaving out SEQ value Fold_0
2022-11-23 02:13:24,643 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 02:13:24,644 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:13:25,661 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:13:25,663 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:13:25,791 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:13:25,792 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:13:25,792 INFO:     No hyperparam tuning for this model
2022-11-23 02:13:25,792 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:13:25,793 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:13:25,794 INFO:     None feature selector for col prot
2022-11-23 02:13:25,795 INFO:     None feature selector for col prot
2022-11-23 02:13:25,795 INFO:     None feature selector for col prot
2022-11-23 02:13:25,797 INFO:     None feature selector for col chem
2022-11-23 02:13:25,797 INFO:     None feature selector for col chem
2022-11-23 02:13:25,797 INFO:     None feature selector for col chem
2022-11-23 02:13:25,798 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:13:25,798 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:13:25,801 INFO:     Number of params in model 168571
2022-11-23 02:13:25,807 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:13:25,807 INFO:   Starting stage: TRAINING
2022-11-23 02:13:25,915 INFO:     Val loss before train {'Reaction outcome loss': 0.9627079218626022, 'Total loss': 0.9627079218626022}
2022-11-23 02:13:25,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:25,915 INFO:     Epoch: 0
2022-11-23 02:13:27,044 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8161372921683572, 'Total loss': 0.8161372921683572} | train loss {'Reaction outcome loss': 0.8858436319292808, 'Total loss': 0.8858436319292808}
2022-11-23 02:13:27,044 INFO:     Found new best model at epoch 0
2022-11-23 02:13:27,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:27,046 INFO:     Epoch: 1
2022-11-23 02:13:28,057 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7951985353773291, 'Total loss': 0.7951985353773291} | train loss {'Reaction outcome loss': 0.8581757252313653, 'Total loss': 0.8581757252313653}
2022-11-23 02:13:28,058 INFO:     Found new best model at epoch 1
2022-11-23 02:13:28,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:28,059 INFO:     Epoch: 2
2022-11-23 02:13:29,154 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8041006936268373, 'Total loss': 0.8041006936268373} | train loss {'Reaction outcome loss': 0.8504629296915872, 'Total loss': 0.8504629296915872}
2022-11-23 02:13:29,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:29,154 INFO:     Epoch: 3
2022-11-23 02:13:30,393 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7989058569073677, 'Total loss': 0.7989058569073677} | train loss {'Reaction outcome loss': 0.8460457581646589, 'Total loss': 0.8460457581646589}
2022-11-23 02:13:30,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:30,393 INFO:     Epoch: 4
2022-11-23 02:13:31,595 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7922721051357009, 'Total loss': 0.7922721051357009} | train loss {'Reaction outcome loss': 0.8408451982906886, 'Total loss': 0.8408451982906886}
2022-11-23 02:13:31,595 INFO:     Found new best model at epoch 4
2022-11-23 02:13:31,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:31,597 INFO:     Epoch: 5
2022-11-23 02:13:32,857 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7948127978227355, 'Total loss': 0.7948127978227355} | train loss {'Reaction outcome loss': 0.8358023246940302, 'Total loss': 0.8358023246940302}
2022-11-23 02:13:32,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:32,859 INFO:     Epoch: 6
2022-11-23 02:13:34,374 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7728314772248268, 'Total loss': 0.7728314772248268} | train loss {'Reaction outcome loss': 0.8321741247663692, 'Total loss': 0.8321741247663692}
2022-11-23 02:13:34,375 INFO:     Found new best model at epoch 6
2022-11-23 02:13:34,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:34,376 INFO:     Epoch: 7
2022-11-23 02:13:35,471 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.791984656994993, 'Total loss': 0.791984656994993} | train loss {'Reaction outcome loss': 0.830785150917209, 'Total loss': 0.830785150917209}
2022-11-23 02:13:35,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:35,472 INFO:     Epoch: 8
2022-11-23 02:13:36,521 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8081557547504251, 'Total loss': 0.8081557547504251} | train loss {'Reaction outcome loss': 0.8207451547895159, 'Total loss': 0.8207451547895159}
2022-11-23 02:13:36,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:36,521 INFO:     Epoch: 9
2022-11-23 02:13:37,884 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7864156351848082, 'Total loss': 0.7864156351848082} | train loss {'Reaction outcome loss': 0.8327881352025636, 'Total loss': 0.8327881352025636}
2022-11-23 02:13:37,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:37,886 INFO:     Epoch: 10
2022-11-23 02:13:38,955 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7683209790424868, 'Total loss': 0.7683209790424868} | train loss {'Reaction outcome loss': 0.824796219139683, 'Total loss': 0.824796219139683}
2022-11-23 02:13:38,955 INFO:     Found new best model at epoch 10
2022-11-23 02:13:38,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:38,957 INFO:     Epoch: 11
2022-11-23 02:13:39,966 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7788939706303857, 'Total loss': 0.7788939706303857} | train loss {'Reaction outcome loss': 0.8230488530227116, 'Total loss': 0.8230488530227116}
2022-11-23 02:13:39,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:39,967 INFO:     Epoch: 12
2022-11-23 02:13:41,132 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7632086676630107, 'Total loss': 0.7632086676630107} | train loss {'Reaction outcome loss': 0.8271755898789483, 'Total loss': 0.8271755898789483}
2022-11-23 02:13:41,132 INFO:     Found new best model at epoch 12
2022-11-23 02:13:41,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:41,134 INFO:     Epoch: 13
2022-11-23 02:13:42,449 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7956127260218967, 'Total loss': 0.7956127260218967} | train loss {'Reaction outcome loss': 0.8253567325825594, 'Total loss': 0.8253567325825594}
2022-11-23 02:13:42,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:42,450 INFO:     Epoch: 14
2022-11-23 02:13:43,766 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7832614901390943, 'Total loss': 0.7832614901390943} | train loss {'Reaction outcome loss': 0.8217493294453134, 'Total loss': 0.8217493294453134}
2022-11-23 02:13:43,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:43,767 INFO:     Epoch: 15
2022-11-23 02:13:44,895 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.78372634337707, 'Total loss': 0.78372634337707} | train loss {'Reaction outcome loss': 0.8252800520585508, 'Total loss': 0.8252800520585508}
2022-11-23 02:13:44,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:44,898 INFO:     Epoch: 16
2022-11-23 02:13:45,914 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7772404551506042, 'Total loss': 0.7772404551506042} | train loss {'Reaction outcome loss': 0.8249203979969024, 'Total loss': 0.8249203979969024}
2022-11-23 02:13:45,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:45,916 INFO:     Epoch: 17
2022-11-23 02:13:46,959 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7795696360143748, 'Total loss': 0.7795696360143748} | train loss {'Reaction outcome loss': 0.8259303335024386, 'Total loss': 0.8259303335024386}
2022-11-23 02:13:46,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:46,959 INFO:     Epoch: 18
2022-11-23 02:13:48,006 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.779785233465108, 'Total loss': 0.779785233465108} | train loss {'Reaction outcome loss': 0.8226344221708726, 'Total loss': 0.8226344221708726}
2022-11-23 02:13:48,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:48,007 INFO:     Epoch: 19
2022-11-23 02:13:49,085 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7989662133834579, 'Total loss': 0.7989662133834579} | train loss {'Reaction outcome loss': 0.8241103029980952, 'Total loss': 0.8241103029980952}
2022-11-23 02:13:49,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:49,087 INFO:     Epoch: 20
2022-11-23 02:13:50,390 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7816682938825, 'Total loss': 0.7816682938825} | train loss {'Reaction outcome loss': 0.8233241891374393, 'Total loss': 0.8233241891374393}
2022-11-23 02:13:50,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:50,391 INFO:     Epoch: 21
2022-11-23 02:13:51,500 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7700760178267956, 'Total loss': 0.7700760178267956} | train loss {'Reaction outcome loss': 0.8203409147505858, 'Total loss': 0.8203409147505858}
2022-11-23 02:13:51,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:51,501 INFO:     Epoch: 22
2022-11-23 02:13:52,594 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7851439822803844, 'Total loss': 0.7851439822803844} | train loss {'Reaction outcome loss': 0.8231218558184955, 'Total loss': 0.8231218558184955}
2022-11-23 02:13:52,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:52,595 INFO:     Epoch: 23
2022-11-23 02:13:53,619 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7812487110495567, 'Total loss': 0.7812487110495567} | train loss {'Reaction outcome loss': 0.8244373735116453, 'Total loss': 0.8244373735116453}
2022-11-23 02:13:53,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:53,619 INFO:     Epoch: 24
2022-11-23 02:13:54,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7881082804365591, 'Total loss': 0.7881082804365591} | train loss {'Reaction outcome loss': 0.8210837943213326, 'Total loss': 0.8210837943213326}
2022-11-23 02:13:54,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:54,478 INFO:     Epoch: 25
2022-11-23 02:13:55,285 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7832331882620399, 'Total loss': 0.7832331882620399} | train loss {'Reaction outcome loss': 0.8212021472502727, 'Total loss': 0.8212021472502727}
2022-11-23 02:13:55,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:55,286 INFO:     Epoch: 26
2022-11-23 02:13:56,103 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7784885154529051, 'Total loss': 0.7784885154529051} | train loss {'Reaction outcome loss': 0.8208418083434202, 'Total loss': 0.8208418083434202}
2022-11-23 02:13:56,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:56,104 INFO:     Epoch: 27
2022-11-23 02:13:56,873 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7730615267699416, 'Total loss': 0.7730615267699416} | train loss {'Reaction outcome loss': 0.8232129550710017, 'Total loss': 0.8232129550710017}
2022-11-23 02:13:56,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:56,874 INFO:     Epoch: 28
2022-11-23 02:13:57,705 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8034614121372049, 'Total loss': 0.8034614121372049} | train loss {'Reaction outcome loss': 0.8207223393479172, 'Total loss': 0.8207223393479172}
2022-11-23 02:13:57,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:57,706 INFO:     Epoch: 29
2022-11-23 02:13:58,506 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7809639606963504, 'Total loss': 0.7809639606963504} | train loss {'Reaction outcome loss': 0.8284527729968636, 'Total loss': 0.8284527729968636}
2022-11-23 02:13:58,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:58,507 INFO:     Epoch: 30
2022-11-23 02:13:59,268 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8011811470443552, 'Total loss': 0.8011811470443552} | train loss {'Reaction outcome loss': 0.8220921735374295, 'Total loss': 0.8220921735374295}
2022-11-23 02:13:59,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:13:59,268 INFO:     Epoch: 31
2022-11-23 02:14:00,060 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.77888734029098, 'Total loss': 0.77888734029098} | train loss {'Reaction outcome loss': 0.8237351334824854, 'Total loss': 0.8237351334824854}
2022-11-23 02:14:00,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:00,061 INFO:     Epoch: 32
2022-11-23 02:14:00,868 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7779928669333458, 'Total loss': 0.7779928669333458} | train loss {'Reaction outcome loss': 0.8197767330675709, 'Total loss': 0.8197767330675709}
2022-11-23 02:14:00,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:00,869 INFO:     Epoch: 33
2022-11-23 02:14:01,722 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7603789588267152, 'Total loss': 0.7603789588267152} | train loss {'Reaction outcome loss': 0.8225715878058453, 'Total loss': 0.8225715878058453}
2022-11-23 02:14:01,722 INFO:     Found new best model at epoch 33
2022-11-23 02:14:01,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:01,723 INFO:     Epoch: 34
2022-11-23 02:14:02,541 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8098802905191075, 'Total loss': 0.8098802905191075} | train loss {'Reaction outcome loss': 0.8222767551334537, 'Total loss': 0.8222767551334537}
2022-11-23 02:14:02,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:02,541 INFO:     Epoch: 35
2022-11-23 02:14:03,366 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7930851599032228, 'Total loss': 0.7930851599032228} | train loss {'Reaction outcome loss': 0.8213656570230211, 'Total loss': 0.8213656570230211}
2022-11-23 02:14:03,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:03,366 INFO:     Epoch: 36
2022-11-23 02:14:04,214 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7726642557165839, 'Total loss': 0.7726642557165839} | train loss {'Reaction outcome loss': 0.8242552852144047, 'Total loss': 0.8242552852144047}
2022-11-23 02:14:04,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:04,215 INFO:     Epoch: 37
2022-11-23 02:14:05,027 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7882075912573121, 'Total loss': 0.7882075912573121} | train loss {'Reaction outcome loss': 0.8232057160260726, 'Total loss': 0.8232057160260726}
2022-11-23 02:14:05,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:05,027 INFO:     Epoch: 38
2022-11-23 02:14:05,798 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7933116860010407, 'Total loss': 0.7933116860010407} | train loss {'Reaction outcome loss': 0.8167013394589326, 'Total loss': 0.8167013394589326}
2022-11-23 02:14:05,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:05,799 INFO:     Epoch: 39
2022-11-23 02:14:06,622 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7796785181218927, 'Total loss': 0.7796785181218927} | train loss {'Reaction outcome loss': 0.8159610107236979, 'Total loss': 0.8159610107236979}
2022-11-23 02:14:06,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:06,622 INFO:     Epoch: 40
2022-11-23 02:14:07,451 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7689159349961714, 'Total loss': 0.7689159349961714} | train loss {'Reaction outcome loss': 0.8194467727018863, 'Total loss': 0.8194467727018863}
2022-11-23 02:14:07,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:07,452 INFO:     Epoch: 41
2022-11-23 02:14:08,278 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7789455462585796, 'Total loss': 0.7789455462585796} | train loss {'Reaction outcome loss': 0.8203753551658319, 'Total loss': 0.8203753551658319}
2022-11-23 02:14:08,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:08,280 INFO:     Epoch: 42
2022-11-23 02:14:09,107 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7994001832875338, 'Total loss': 0.7994001832875338} | train loss {'Reaction outcome loss': 0.8260175988382222, 'Total loss': 0.8260175988382222}
2022-11-23 02:14:09,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:09,107 INFO:     Epoch: 43
2022-11-23 02:14:09,879 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7977596562017094, 'Total loss': 0.7977596562017094} | train loss {'Reaction outcome loss': 0.8198234060589148, 'Total loss': 0.8198234060589148}
2022-11-23 02:14:09,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:09,879 INFO:     Epoch: 44
2022-11-23 02:14:10,668 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8102957579222593, 'Total loss': 0.8102957579222593} | train loss {'Reaction outcome loss': 0.8229003660532893, 'Total loss': 0.8229003660532893}
2022-11-23 02:14:10,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:10,668 INFO:     Epoch: 45
2022-11-23 02:14:11,484 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7881311151114377, 'Total loss': 0.7881311151114377} | train loss {'Reaction outcome loss': 0.8189536229688295, 'Total loss': 0.8189536229688295}
2022-11-23 02:14:11,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:11,485 INFO:     Epoch: 46
2022-11-23 02:14:12,259 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.794043515893546, 'Total loss': 0.794043515893546} | train loss {'Reaction outcome loss': 0.818651076725551, 'Total loss': 0.818651076725551}
2022-11-23 02:14:12,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:12,260 INFO:     Epoch: 47
2022-11-23 02:14:13,030 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7755277569998394, 'Total loss': 0.7755277569998394} | train loss {'Reaction outcome loss': 0.8280852803162166, 'Total loss': 0.8280852803162166}
2022-11-23 02:14:13,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:13,030 INFO:     Epoch: 48
2022-11-23 02:14:13,844 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7815181524916128, 'Total loss': 0.7815181524916128} | train loss {'Reaction outcome loss': 0.8188203415092157, 'Total loss': 0.8188203415092157}
2022-11-23 02:14:13,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:13,844 INFO:     Epoch: 49
2022-11-23 02:14:14,664 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.767026737332344, 'Total loss': 0.767026737332344} | train loss {'Reaction outcome loss': 0.8227463669922888, 'Total loss': 0.8227463669922888}
2022-11-23 02:14:14,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:14,665 INFO:     Epoch: 50
2022-11-23 02:14:15,470 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.791561714627526, 'Total loss': 0.791561714627526} | train loss {'Reaction outcome loss': 0.8183106058714341, 'Total loss': 0.8183106058714341}
2022-11-23 02:14:15,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:15,470 INFO:     Epoch: 51
2022-11-23 02:14:16,244 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.779575339095159, 'Total loss': 0.779575339095159} | train loss {'Reaction outcome loss': 0.8190992102331045, 'Total loss': 0.8190992102331045}
2022-11-23 02:14:16,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:16,244 INFO:     Epoch: 52
2022-11-23 02:14:17,064 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7931238988583739, 'Total loss': 0.7931238988583739} | train loss {'Reaction outcome loss': 0.8209324754014307, 'Total loss': 0.8209324754014307}
2022-11-23 02:14:17,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:17,065 INFO:     Epoch: 53
2022-11-23 02:14:17,864 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7859100983901457, 'Total loss': 0.7859100983901457} | train loss {'Reaction outcome loss': 0.8234168139647464, 'Total loss': 0.8234168139647464}
2022-11-23 02:14:17,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:17,865 INFO:     Epoch: 54
2022-11-23 02:14:18,655 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.794247182932767, 'Total loss': 0.794247182932767} | train loss {'Reaction outcome loss': 0.8190635847802065, 'Total loss': 0.8190635847802065}
2022-11-23 02:14:18,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:18,655 INFO:     Epoch: 55
2022-11-23 02:14:19,410 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7823869030583989, 'Total loss': 0.7823869030583989} | train loss {'Reaction outcome loss': 0.8195905641633637, 'Total loss': 0.8195905641633637}
2022-11-23 02:14:19,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:19,410 INFO:     Epoch: 56
2022-11-23 02:14:20,190 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7794597758488222, 'Total loss': 0.7794597758488222} | train loss {'Reaction outcome loss': 0.8199751738382846, 'Total loss': 0.8199751738382846}
2022-11-23 02:14:20,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:20,190 INFO:     Epoch: 57
2022-11-23 02:14:20,967 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7933891998095945, 'Total loss': 0.7933891998095945} | train loss {'Reaction outcome loss': 0.8199068118114861, 'Total loss': 0.8199068118114861}
2022-11-23 02:14:20,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:20,967 INFO:     Epoch: 58
2022-11-23 02:14:21,758 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7627630592747168, 'Total loss': 0.7627630592747168} | train loss {'Reaction outcome loss': 0.8183115292568596, 'Total loss': 0.8183115292568596}
2022-11-23 02:14:21,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:21,758 INFO:     Epoch: 59
2022-11-23 02:14:22,573 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.773941345512867, 'Total loss': 0.773941345512867} | train loss {'Reaction outcome loss': 0.8198010201356849, 'Total loss': 0.8198010201356849}
2022-11-23 02:14:22,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:22,574 INFO:     Epoch: 60
2022-11-23 02:14:23,432 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7798681079664014, 'Total loss': 0.7798681079664014} | train loss {'Reaction outcome loss': 0.8165442345093707, 'Total loss': 0.8165442345093707}
2022-11-23 02:14:23,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:23,433 INFO:     Epoch: 61
2022-11-23 02:14:24,236 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7855419557202946, 'Total loss': 0.7855419557202946} | train loss {'Reaction outcome loss': 0.8199413657188416, 'Total loss': 0.8199413657188416}
2022-11-23 02:14:24,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:24,237 INFO:     Epoch: 62
2022-11-23 02:14:25,040 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7900823232802477, 'Total loss': 0.7900823232802477} | train loss {'Reaction outcome loss': 0.8165480287707582, 'Total loss': 0.8165480287707582}
2022-11-23 02:14:25,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:25,041 INFO:     Epoch: 63
2022-11-23 02:14:25,878 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7885104207829996, 'Total loss': 0.7885104207829996} | train loss {'Reaction outcome loss': 0.8190163561276027, 'Total loss': 0.8190163561276027}
2022-11-23 02:14:25,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:25,878 INFO:     Epoch: 64
2022-11-23 02:14:26,631 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7685467810793356, 'Total loss': 0.7685467810793356} | train loss {'Reaction outcome loss': 0.8184314828746173, 'Total loss': 0.8184314828746173}
2022-11-23 02:14:26,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:26,632 INFO:     Epoch: 65
2022-11-23 02:14:27,377 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7914719324220311, 'Total loss': 0.7914719324220311} | train loss {'Reaction outcome loss': 0.82018545148324, 'Total loss': 0.82018545148324}
2022-11-23 02:14:27,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:27,381 INFO:     Epoch: 66
2022-11-23 02:14:28,216 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7797358361157504, 'Total loss': 0.7797358361157504} | train loss {'Reaction outcome loss': 0.8189053497752364, 'Total loss': 0.8189053497752364}
2022-11-23 02:14:28,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:28,216 INFO:     Epoch: 67
2022-11-23 02:14:28,987 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7757418623024767, 'Total loss': 0.7757418623024767} | train loss {'Reaction outcome loss': 0.8154751939432962, 'Total loss': 0.8154751939432962}
2022-11-23 02:14:28,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:28,988 INFO:     Epoch: 68
2022-11-23 02:14:29,798 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7874554937536066, 'Total loss': 0.7874554937536066} | train loss {'Reaction outcome loss': 0.8219795101759385, 'Total loss': 0.8219795101759385}
2022-11-23 02:14:29,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:29,799 INFO:     Epoch: 69
2022-11-23 02:14:30,612 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7899883673949675, 'Total loss': 0.7899883673949675} | train loss {'Reaction outcome loss': 0.8192953129203953, 'Total loss': 0.8192953129203953}
2022-11-23 02:14:30,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:30,612 INFO:     Epoch: 70
2022-11-23 02:14:31,421 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7989863468842073, 'Total loss': 0.7989863468842073} | train loss {'Reaction outcome loss': 0.8174865774962367, 'Total loss': 0.8174865774962367}
2022-11-23 02:14:31,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:31,421 INFO:     Epoch: 71
2022-11-23 02:14:32,247 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7762225717306137, 'Total loss': 0.7762225717306137} | train loss {'Reaction outcome loss': 0.8216737305631443, 'Total loss': 0.8216737305631443}
2022-11-23 02:14:32,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:32,248 INFO:     Epoch: 72
2022-11-23 02:14:33,045 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7677646489305929, 'Total loss': 0.7677646489305929} | train loss {'Reaction outcome loss': 0.8153502392525576, 'Total loss': 0.8153502392525576}
2022-11-23 02:14:33,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:33,045 INFO:     Epoch: 73
2022-11-23 02:14:33,815 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7953620519150387, 'Total loss': 0.7953620519150387} | train loss {'Reaction outcome loss': 0.8216289939929028, 'Total loss': 0.8216289939929028}
2022-11-23 02:14:33,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:33,815 INFO:     Epoch: 74
2022-11-23 02:14:34,587 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7855460826646198, 'Total loss': 0.7855460826646198} | train loss {'Reaction outcome loss': 0.8242790400981903, 'Total loss': 0.8242790400981903}
2022-11-23 02:14:34,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:34,587 INFO:     Epoch: 75
2022-11-23 02:14:35,415 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7724156332286921, 'Total loss': 0.7724156332286921} | train loss {'Reaction outcome loss': 0.81646431854793, 'Total loss': 0.81646431854793}
2022-11-23 02:14:35,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:35,415 INFO:     Epoch: 76
2022-11-23 02:14:36,280 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7922680215402083, 'Total loss': 0.7922680215402083} | train loss {'Reaction outcome loss': 0.8178759705655428, 'Total loss': 0.8178759705655428}
2022-11-23 02:14:36,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:36,281 INFO:     Epoch: 77
2022-11-23 02:14:37,091 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7705876251513307, 'Total loss': 0.7705876251513307} | train loss {'Reaction outcome loss': 0.8158611956907779, 'Total loss': 0.8158611956907779}
2022-11-23 02:14:37,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:37,091 INFO:     Epoch: 78
2022-11-23 02:14:37,917 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.77530656687238, 'Total loss': 0.77530656687238} | train loss {'Reaction outcome loss': 0.8173575880576153, 'Total loss': 0.8173575880576153}
2022-11-23 02:14:37,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:37,918 INFO:     Epoch: 79
2022-11-23 02:14:38,738 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7747046155008402, 'Total loss': 0.7747046155008402} | train loss {'Reaction outcome loss': 0.8213551593070127, 'Total loss': 0.8213551593070127}
2022-11-23 02:14:38,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:38,739 INFO:     Epoch: 80
2022-11-23 02:14:39,569 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7840361574834044, 'Total loss': 0.7840361574834044} | train loss {'Reaction outcome loss': 0.8191939949989319, 'Total loss': 0.8191939949989319}
2022-11-23 02:14:39,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:39,570 INFO:     Epoch: 81
2022-11-23 02:14:40,339 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7786604206670414, 'Total loss': 0.7786604206670414} | train loss {'Reaction outcome loss': 0.8175660932550625, 'Total loss': 0.8175660932550625}
2022-11-23 02:14:40,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:40,339 INFO:     Epoch: 82
2022-11-23 02:14:41,189 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7833748676560142, 'Total loss': 0.7833748676560142} | train loss {'Reaction outcome loss': 0.8193156996551825, 'Total loss': 0.8193156996551825}
2022-11-23 02:14:41,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:41,189 INFO:     Epoch: 83
2022-11-23 02:14:41,971 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.778845185583288, 'Total loss': 0.778845185583288} | train loss {'Reaction outcome loss': 0.822541549376079, 'Total loss': 0.822541549376079}
2022-11-23 02:14:41,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:41,972 INFO:     Epoch: 84
2022-11-23 02:14:42,826 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8022058152339675, 'Total loss': 0.8022058152339675} | train loss {'Reaction outcome loss': 0.8196973034313747, 'Total loss': 0.8196973034313747}
2022-11-23 02:14:42,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:42,827 INFO:     Epoch: 85
2022-11-23 02:14:43,630 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7781845859505914, 'Total loss': 0.7781845859505914} | train loss {'Reaction outcome loss': 0.8229094538153434, 'Total loss': 0.8229094538153434}
2022-11-23 02:14:43,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:43,631 INFO:     Epoch: 86
2022-11-23 02:14:44,424 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7886572446335446, 'Total loss': 0.7886572446335446} | train loss {'Reaction outcome loss': 0.8167992083393798, 'Total loss': 0.8167992083393798}
2022-11-23 02:14:44,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:44,424 INFO:     Epoch: 87
2022-11-23 02:14:45,250 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7903234051032499, 'Total loss': 0.7903234051032499} | train loss {'Reaction outcome loss': 0.8188644969949916, 'Total loss': 0.8188644969949916}
2022-11-23 02:14:45,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:45,250 INFO:     Epoch: 88
2022-11-23 02:14:46,053 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7716827903958884, 'Total loss': 0.7716827903958884} | train loss {'Reaction outcome loss': 0.8228316854457466, 'Total loss': 0.8228316854457466}
2022-11-23 02:14:46,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:46,054 INFO:     Epoch: 89
2022-11-23 02:14:46,887 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7782383628866889, 'Total loss': 0.7782383628866889} | train loss {'Reaction outcome loss': 0.8239763186902416, 'Total loss': 0.8239763186902416}
2022-11-23 02:14:46,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:46,888 INFO:     Epoch: 90
2022-11-23 02:14:47,707 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7720498300411485, 'Total loss': 0.7720498300411485} | train loss {'Reaction outcome loss': 0.8183157058394686, 'Total loss': 0.8183157058394686}
2022-11-23 02:14:47,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:47,707 INFO:     Epoch: 91
2022-11-23 02:14:48,525 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7999565526843071, 'Total loss': 0.7999565526843071} | train loss {'Reaction outcome loss': 0.8186908186698446, 'Total loss': 0.8186908186698446}
2022-11-23 02:14:48,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:48,525 INFO:     Epoch: 92
2022-11-23 02:14:49,394 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7945327352393757, 'Total loss': 0.7945327352393757} | train loss {'Reaction outcome loss': 0.8187338073642887, 'Total loss': 0.8187338073642887}
2022-11-23 02:14:49,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:49,395 INFO:     Epoch: 93
2022-11-23 02:14:50,166 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7834218510172584, 'Total loss': 0.7834218510172584} | train loss {'Reaction outcome loss': 0.8211988059841857, 'Total loss': 0.8211988059841857}
2022-11-23 02:14:50,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:50,167 INFO:     Epoch: 94
2022-11-23 02:14:50,979 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7843179377642545, 'Total loss': 0.7843179377642545} | train loss {'Reaction outcome loss': 0.8142078825405665, 'Total loss': 0.8142078825405665}
2022-11-23 02:14:50,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:50,979 INFO:     Epoch: 95
2022-11-23 02:14:51,837 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7718612781979821, 'Total loss': 0.7718612781979821} | train loss {'Reaction outcome loss': 0.8220564641514603, 'Total loss': 0.8220564641514603}
2022-11-23 02:14:51,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:51,838 INFO:     Epoch: 96
2022-11-23 02:14:52,666 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7703941450877623, 'Total loss': 0.7703941450877623} | train loss {'Reaction outcome loss': 0.8211096292855788, 'Total loss': 0.8211096292855788}
2022-11-23 02:14:52,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:52,666 INFO:     Epoch: 97
2022-11-23 02:14:53,494 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7782238667661493, 'Total loss': 0.7782238667661493} | train loss {'Reaction outcome loss': 0.8171091679407626, 'Total loss': 0.8171091679407626}
2022-11-23 02:14:53,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:53,494 INFO:     Epoch: 98
2022-11-23 02:14:54,294 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.786081200973554, 'Total loss': 0.786081200973554} | train loss {'Reaction outcome loss': 0.818833685286191, 'Total loss': 0.818833685286191}
2022-11-23 02:14:54,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:54,294 INFO:     Epoch: 99
2022-11-23 02:14:55,088 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.780686043202877, 'Total loss': 0.780686043202877} | train loss {'Reaction outcome loss': 0.8208488442459885, 'Total loss': 0.8208488442459885}
2022-11-23 02:14:55,088 INFO:     Best model found after epoch 34 of 100.
2022-11-23 02:14:55,088 INFO:   Done with stage: TRAINING
2022-11-23 02:14:55,088 INFO:   Starting stage: EVALUATION
2022-11-23 02:14:55,221 INFO:   Done with stage: EVALUATION
2022-11-23 02:14:55,221 INFO:   Leaving out SEQ value Fold_1
2022-11-23 02:14:55,239 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 02:14:55,239 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:14:55,897 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:14:55,897 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:14:55,969 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:14:55,969 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:14:55,969 INFO:     No hyperparam tuning for this model
2022-11-23 02:14:55,969 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:14:55,969 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:14:55,970 INFO:     None feature selector for col prot
2022-11-23 02:14:55,970 INFO:     None feature selector for col prot
2022-11-23 02:14:55,971 INFO:     None feature selector for col prot
2022-11-23 02:14:55,971 INFO:     None feature selector for col chem
2022-11-23 02:14:55,971 INFO:     None feature selector for col chem
2022-11-23 02:14:55,972 INFO:     None feature selector for col chem
2022-11-23 02:14:55,972 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:14:55,972 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:14:55,973 INFO:     Number of params in model 168571
2022-11-23 02:14:55,977 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:14:55,977 INFO:   Starting stage: TRAINING
2022-11-23 02:14:56,034 INFO:     Val loss before train {'Reaction outcome loss': 0.9550594091415405, 'Total loss': 0.9550594091415405}
2022-11-23 02:14:56,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:56,035 INFO:     Epoch: 0
2022-11-23 02:14:56,816 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7754347504571427, 'Total loss': 0.7754347504571427} | train loss {'Reaction outcome loss': 0.8797177196037574, 'Total loss': 0.8797177196037574}
2022-11-23 02:14:56,816 INFO:     Found new best model at epoch 0
2022-11-23 02:14:56,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:56,818 INFO:     Epoch: 1
2022-11-23 02:14:57,636 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7753544498321622, 'Total loss': 0.7753544498321622} | train loss {'Reaction outcome loss': 0.8491075465180835, 'Total loss': 0.8491075465180835}
2022-11-23 02:14:57,636 INFO:     Found new best model at epoch 1
2022-11-23 02:14:57,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:57,637 INFO:     Epoch: 2
2022-11-23 02:14:58,404 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7912977684375851, 'Total loss': 0.7912977684375851} | train loss {'Reaction outcome loss': 0.8458117807253462, 'Total loss': 0.8458117807253462}
2022-11-23 02:14:58,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:58,405 INFO:     Epoch: 3
2022-11-23 02:14:59,154 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.764476674240689, 'Total loss': 0.764476674240689} | train loss {'Reaction outcome loss': 0.8439942280777165, 'Total loss': 0.8439942280777165}
2022-11-23 02:14:59,155 INFO:     Found new best model at epoch 3
2022-11-23 02:14:59,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:59,155 INFO:     Epoch: 4
2022-11-23 02:14:59,990 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7657080174878587, 'Total loss': 0.7657080174878587} | train loss {'Reaction outcome loss': 0.8357791509784636, 'Total loss': 0.8357791509784636}
2022-11-23 02:14:59,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:14:59,990 INFO:     Epoch: 5
2022-11-23 02:15:00,772 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7579929690028346, 'Total loss': 0.7579929690028346} | train loss {'Reaction outcome loss': 0.8349995208812542, 'Total loss': 0.8349995208812542}
2022-11-23 02:15:00,772 INFO:     Found new best model at epoch 5
2022-11-23 02:15:00,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:00,773 INFO:     Epoch: 6
2022-11-23 02:15:01,541 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7685851482457893, 'Total loss': 0.7685851482457893} | train loss {'Reaction outcome loss': 0.8338353026841507, 'Total loss': 0.8338353026841507}
2022-11-23 02:15:01,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:01,541 INFO:     Epoch: 7
2022-11-23 02:15:02,318 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7571873872779137, 'Total loss': 0.7571873872779137} | train loss {'Reaction outcome loss': 0.8322096205637103, 'Total loss': 0.8322096205637103}
2022-11-23 02:15:02,318 INFO:     Found new best model at epoch 7
2022-11-23 02:15:02,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:02,320 INFO:     Epoch: 8
2022-11-23 02:15:03,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7542537249797998, 'Total loss': 0.7542537249797998} | train loss {'Reaction outcome loss': 0.8245144695287845, 'Total loss': 0.8245144695287845}
2022-11-23 02:15:03,104 INFO:     Found new best model at epoch 8
2022-11-23 02:15:03,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:03,106 INFO:     Epoch: 9
2022-11-23 02:15:03,916 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7598541919575181, 'Total loss': 0.7598541919575181} | train loss {'Reaction outcome loss': 0.829298158405257, 'Total loss': 0.829298158405257}
2022-11-23 02:15:03,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:03,917 INFO:     Epoch: 10
2022-11-23 02:15:04,687 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7561423043872035, 'Total loss': 0.7561423043872035} | train loss {'Reaction outcome loss': 0.8307896466528784, 'Total loss': 0.8307896466528784}
2022-11-23 02:15:04,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:04,687 INFO:     Epoch: 11
2022-11-23 02:15:05,469 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7589086023874061, 'Total loss': 0.7589086023874061} | train loss {'Reaction outcome loss': 0.8243108182901242, 'Total loss': 0.8243108182901242}
2022-11-23 02:15:05,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:05,469 INFO:     Epoch: 12
2022-11-23 02:15:06,274 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7725801384726236, 'Total loss': 0.7725801384726236} | train loss {'Reaction outcome loss': 0.8295446773532962, 'Total loss': 0.8295446773532962}
2022-11-23 02:15:06,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:06,275 INFO:     Epoch: 13
2022-11-23 02:15:07,056 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7490082771279091, 'Total loss': 0.7490082771279091} | train loss {'Reaction outcome loss': 0.8233406486325576, 'Total loss': 0.8233406486325576}
2022-11-23 02:15:07,056 INFO:     Found new best model at epoch 13
2022-11-23 02:15:07,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:07,057 INFO:     Epoch: 14
2022-11-23 02:15:07,882 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7608662594196408, 'Total loss': 0.7608662594196408} | train loss {'Reaction outcome loss': 0.8245043671521984, 'Total loss': 0.8245043671521984}
2022-11-23 02:15:07,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:07,882 INFO:     Epoch: 15
2022-11-23 02:15:08,667 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7531370804753414, 'Total loss': 0.7531370804753414} | train loss {'Reaction outcome loss': 0.8191348007712208, 'Total loss': 0.8191348007712208}
2022-11-23 02:15:08,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:08,667 INFO:     Epoch: 16
2022-11-23 02:15:09,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7518463862496753, 'Total loss': 0.7518463862496753} | train loss {'Reaction outcome loss': 0.8217055942924296, 'Total loss': 0.8217055942924296}
2022-11-23 02:15:09,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:09,467 INFO:     Epoch: 17
2022-11-23 02:15:10,291 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.751720763916193, 'Total loss': 0.751720763916193} | train loss {'Reaction outcome loss': 0.8236255518114958, 'Total loss': 0.8236255518114958}
2022-11-23 02:15:10,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:10,292 INFO:     Epoch: 18
2022-11-23 02:15:11,122 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7516985701960187, 'Total loss': 0.7516985701960187} | train loss {'Reaction outcome loss': 0.8264571337914858, 'Total loss': 0.8264571337914858}
2022-11-23 02:15:11,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:11,122 INFO:     Epoch: 19
2022-11-23 02:15:11,927 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7538526099781657, 'Total loss': 0.7538526099781657} | train loss {'Reaction outcome loss': 0.8203934029233261, 'Total loss': 0.8203934029233261}
2022-11-23 02:15:11,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:11,927 INFO:     Epoch: 20
2022-11-23 02:15:12,740 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.750809871180113, 'Total loss': 0.750809871180113} | train loss {'Reaction outcome loss': 0.8209250025817605, 'Total loss': 0.8209250025817605}
2022-11-23 02:15:12,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:12,740 INFO:     Epoch: 21
2022-11-23 02:15:13,570 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.742922727451768, 'Total loss': 0.742922727451768} | train loss {'Reaction outcome loss': 0.8204560616954428, 'Total loss': 0.8204560616954428}
2022-11-23 02:15:13,570 INFO:     Found new best model at epoch 21
2022-11-23 02:15:13,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:13,571 INFO:     Epoch: 22
2022-11-23 02:15:14,368 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7664256740448087, 'Total loss': 0.7664256740448087} | train loss {'Reaction outcome loss': 0.8245528418509687, 'Total loss': 0.8245528418509687}
2022-11-23 02:15:14,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:14,368 INFO:     Epoch: 23
2022-11-23 02:15:15,184 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7773968722931174, 'Total loss': 0.7773968722931174} | train loss {'Reaction outcome loss': 0.8255436016155071, 'Total loss': 0.8255436016155071}
2022-11-23 02:15:15,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:15,185 INFO:     Epoch: 24
2022-11-23 02:15:15,995 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7772114464016848, 'Total loss': 0.7772114464016848} | train loss {'Reaction outcome loss': 0.8216464401024287, 'Total loss': 0.8216464401024287}
2022-11-23 02:15:15,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:15,995 INFO:     Epoch: 25
2022-11-23 02:15:16,754 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7525051589622054, 'Total loss': 0.7525051589622054} | train loss {'Reaction outcome loss': 0.8183594711247038, 'Total loss': 0.8183594711247038}
2022-11-23 02:15:16,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:16,759 INFO:     Epoch: 26
2022-11-23 02:15:17,554 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7517610816068427, 'Total loss': 0.7517610816068427} | train loss {'Reaction outcome loss': 0.821477478278465, 'Total loss': 0.821477478278465}
2022-11-23 02:15:17,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:17,554 INFO:     Epoch: 27
2022-11-23 02:15:18,375 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.761256102905717, 'Total loss': 0.761256102905717} | train loss {'Reaction outcome loss': 0.8182785471931833, 'Total loss': 0.8182785471931833}
2022-11-23 02:15:18,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:18,376 INFO:     Epoch: 28
2022-11-23 02:15:19,168 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7495304671830909, 'Total loss': 0.7495304671830909} | train loss {'Reaction outcome loss': 0.8233922964236775, 'Total loss': 0.8233922964236775}
2022-11-23 02:15:19,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:19,168 INFO:     Epoch: 29
2022-11-23 02:15:19,983 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7611887912417568, 'Total loss': 0.7611887912417568} | train loss {'Reaction outcome loss': 0.8261510987506538, 'Total loss': 0.8261510987506538}
2022-11-23 02:15:19,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:19,984 INFO:     Epoch: 30
2022-11-23 02:15:20,811 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7679056927215221, 'Total loss': 0.7679056927215221} | train loss {'Reaction outcome loss': 0.8228582104698556, 'Total loss': 0.8228582104698556}
2022-11-23 02:15:20,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:20,811 INFO:     Epoch: 31
2022-11-23 02:15:21,620 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7451400860797527, 'Total loss': 0.7451400860797527} | train loss {'Reaction outcome loss': 0.8196866555047817, 'Total loss': 0.8196866555047817}
2022-11-23 02:15:21,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:21,620 INFO:     Epoch: 32
2022-11-23 02:15:22,430 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7589760803899099, 'Total loss': 0.7589760803899099} | train loss {'Reaction outcome loss': 0.8241302803403041, 'Total loss': 0.8241302803403041}
2022-11-23 02:15:22,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:22,430 INFO:     Epoch: 33
2022-11-23 02:15:23,190 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7564426819945491, 'Total loss': 0.7564426819945491} | train loss {'Reaction outcome loss': 0.8217686911831137, 'Total loss': 0.8217686911831137}
2022-11-23 02:15:23,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:23,190 INFO:     Epoch: 34
2022-11-23 02:15:23,965 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7458852571110393, 'Total loss': 0.7458852571110393} | train loss {'Reaction outcome loss': 0.8210838871901153, 'Total loss': 0.8210838871901153}
2022-11-23 02:15:23,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:23,965 INFO:     Epoch: 35
2022-11-23 02:15:24,801 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7498352499895318, 'Total loss': 0.7498352499895318} | train loss {'Reaction outcome loss': 0.8232050799444074, 'Total loss': 0.8232050799444074}
2022-11-23 02:15:24,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:24,801 INFO:     Epoch: 36
2022-11-23 02:15:25,561 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7543078702549602, 'Total loss': 0.7543078702549602} | train loss {'Reaction outcome loss': 0.8181849740079192, 'Total loss': 0.8181849740079192}
2022-11-23 02:15:25,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:25,561 INFO:     Epoch: 37
2022-11-23 02:15:26,334 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7630189158195673, 'Total loss': 0.7630189158195673} | train loss {'Reaction outcome loss': 0.8215301321422468, 'Total loss': 0.8215301321422468}
2022-11-23 02:15:26,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:26,334 INFO:     Epoch: 38
2022-11-23 02:15:27,122 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7547774093095646, 'Total loss': 0.7547774093095646} | train loss {'Reaction outcome loss': 0.8238480297512696, 'Total loss': 0.8238480297512696}
2022-11-23 02:15:27,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:27,122 INFO:     Epoch: 39
2022-11-23 02:15:27,938 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7605034840661425, 'Total loss': 0.7605034840661425} | train loss {'Reaction outcome loss': 0.8256319433939262, 'Total loss': 0.8256319433939262}
2022-11-23 02:15:27,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:27,938 INFO:     Epoch: 40
2022-11-23 02:15:28,728 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7488846342230953, 'Total loss': 0.7488846342230953} | train loss {'Reaction outcome loss': 0.8229181020230544, 'Total loss': 0.8229181020230544}
2022-11-23 02:15:28,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:28,728 INFO:     Epoch: 41
2022-11-23 02:15:29,523 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7683365310347358, 'Total loss': 0.7683365310347358} | train loss {'Reaction outcome loss': 0.8229304400623821, 'Total loss': 0.8229304400623821}
2022-11-23 02:15:29,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:29,524 INFO:     Epoch: 42
2022-11-23 02:15:30,339 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7667112038579098, 'Total loss': 0.7667112038579098} | train loss {'Reaction outcome loss': 0.8211232415232502, 'Total loss': 0.8211232415232502}
2022-11-23 02:15:30,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:30,339 INFO:     Epoch: 43
2022-11-23 02:15:31,153 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7558579236962074, 'Total loss': 0.7558579236962074} | train loss {'Reaction outcome loss': 0.8204872798724253, 'Total loss': 0.8204872798724253}
2022-11-23 02:15:31,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:31,153 INFO:     Epoch: 44
2022-11-23 02:15:32,007 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7738397495691166, 'Total loss': 0.7738397495691166} | train loss {'Reaction outcome loss': 0.8158936087713867, 'Total loss': 0.8158936087713867}
2022-11-23 02:15:32,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:32,008 INFO:     Epoch: 45
2022-11-23 02:15:32,797 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7474181998607724, 'Total loss': 0.7474181998607724} | train loss {'Reaction outcome loss': 0.823573536804465, 'Total loss': 0.823573536804465}
2022-11-23 02:15:32,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:32,797 INFO:     Epoch: 46
2022-11-23 02:15:33,616 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7824995961300162, 'Total loss': 0.7824995961300162} | train loss {'Reaction outcome loss': 0.8178759863386389, 'Total loss': 0.8178759863386389}
2022-11-23 02:15:33,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:33,616 INFO:     Epoch: 47
2022-11-23 02:15:34,437 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7527749358221542, 'Total loss': 0.7527749358221542} | train loss {'Reaction outcome loss': 0.8203505422981059, 'Total loss': 0.8203505422981059}
2022-11-23 02:15:34,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:34,437 INFO:     Epoch: 48
2022-11-23 02:15:35,268 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7701016733812731, 'Total loss': 0.7701016733812731} | train loss {'Reaction outcome loss': 0.8267723866662041, 'Total loss': 0.8267723866662041}
2022-11-23 02:15:35,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:35,269 INFO:     Epoch: 49
2022-11-23 02:15:36,039 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7513682246208191, 'Total loss': 0.7513682246208191} | train loss {'Reaction outcome loss': 0.8206584932374172, 'Total loss': 0.8206584932374172}
2022-11-23 02:15:36,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:36,039 INFO:     Epoch: 50
2022-11-23 02:15:36,836 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.75541960361392, 'Total loss': 0.75541960361392} | train loss {'Reaction outcome loss': 0.8213894501572749, 'Total loss': 0.8213894501572749}
2022-11-23 02:15:36,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:36,836 INFO:     Epoch: 51
2022-11-23 02:15:37,648 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7722766399383545, 'Total loss': 0.7722766399383545} | train loss {'Reaction outcome loss': 0.8179847475935201, 'Total loss': 0.8179847475935201}
2022-11-23 02:15:37,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:37,649 INFO:     Epoch: 52
2022-11-23 02:15:38,455 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7499166477558225, 'Total loss': 0.7499166477558225} | train loss {'Reaction outcome loss': 0.8196946439928696, 'Total loss': 0.8196946439928696}
2022-11-23 02:15:38,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:38,455 INFO:     Epoch: 53
2022-11-23 02:15:39,289 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7622836377731589, 'Total loss': 0.7622836377731589} | train loss {'Reaction outcome loss': 0.8195631333061906, 'Total loss': 0.8195631333061906}
2022-11-23 02:15:39,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:39,290 INFO:     Epoch: 54
2022-11-23 02:15:40,106 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7742950472720834, 'Total loss': 0.7742950472720834} | train loss {'Reaction outcome loss': 0.8213059193775302, 'Total loss': 0.8213059193775302}
2022-11-23 02:15:40,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:40,107 INFO:     Epoch: 55
2022-11-23 02:15:40,938 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7662834220154341, 'Total loss': 0.7662834220154341} | train loss {'Reaction outcome loss': 0.8233379855996272, 'Total loss': 0.8233379855996272}
2022-11-23 02:15:40,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:40,938 INFO:     Epoch: 56
2022-11-23 02:15:41,765 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7572209585544675, 'Total loss': 0.7572209585544675} | train loss {'Reaction outcome loss': 0.8203552453244318, 'Total loss': 0.8203552453244318}
2022-11-23 02:15:41,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:41,766 INFO:     Epoch: 57
2022-11-23 02:15:42,623 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7835522190082905, 'Total loss': 0.7835522190082905} | train loss {'Reaction outcome loss': 0.8224676283168011, 'Total loss': 0.8224676283168011}
2022-11-23 02:15:42,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:42,623 INFO:     Epoch: 58
2022-11-23 02:15:43,394 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7579009921051735, 'Total loss': 0.7579009921051735} | train loss {'Reaction outcome loss': 0.8241951976154671, 'Total loss': 0.8241951976154671}
2022-11-23 02:15:43,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:43,394 INFO:     Epoch: 59
2022-11-23 02:15:44,186 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7389145597468975, 'Total loss': 0.7389145597468975} | train loss {'Reaction outcome loss': 0.8191471058325689, 'Total loss': 0.8191471058325689}
2022-11-23 02:15:44,186 INFO:     Found new best model at epoch 59
2022-11-23 02:15:44,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:44,187 INFO:     Epoch: 60
2022-11-23 02:15:45,048 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7622598520545072, 'Total loss': 0.7622598520545072} | train loss {'Reaction outcome loss': 0.8190788842859815, 'Total loss': 0.8190788842859815}
2022-11-23 02:15:45,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:45,049 INFO:     Epoch: 61
2022-11-23 02:15:45,883 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7523868929508121, 'Total loss': 0.7523868929508121} | train loss {'Reaction outcome loss': 0.8189094701751334, 'Total loss': 0.8189094701751334}
2022-11-23 02:15:45,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:45,883 INFO:     Epoch: 62
2022-11-23 02:15:46,701 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7639069564120714, 'Total loss': 0.7639069564120714} | train loss {'Reaction outcome loss': 0.8194092994586366, 'Total loss': 0.8194092994586366}
2022-11-23 02:15:46,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:46,701 INFO:     Epoch: 63
2022-11-23 02:15:47,610 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7462405895077905, 'Total loss': 0.7462405895077905} | train loss {'Reaction outcome loss': 0.8194944543428109, 'Total loss': 0.8194944543428109}
2022-11-23 02:15:47,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:47,610 INFO:     Epoch: 64
2022-11-23 02:15:48,388 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7448360157567401, 'Total loss': 0.7448360157567401} | train loss {'Reaction outcome loss': 0.8200145159832767, 'Total loss': 0.8200145159832767}
2022-11-23 02:15:48,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:48,389 INFO:     Epoch: 65
2022-11-23 02:15:49,180 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7419056518133297, 'Total loss': 0.7419056518133297} | train loss {'Reaction outcome loss': 0.8163224004331182, 'Total loss': 0.8163224004331182}
2022-11-23 02:15:49,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:49,180 INFO:     Epoch: 66
2022-11-23 02:15:50,004 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7562670208687006, 'Total loss': 0.7562670208687006} | train loss {'Reaction outcome loss': 0.8175384002875109, 'Total loss': 0.8175384002875109}
2022-11-23 02:15:50,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:50,005 INFO:     Epoch: 67
2022-11-23 02:15:50,801 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7435569874075956, 'Total loss': 0.7435569874075956} | train loss {'Reaction outcome loss': 0.8205477305855907, 'Total loss': 0.8205477305855907}
2022-11-23 02:15:50,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:50,801 INFO:     Epoch: 68
2022-11-23 02:15:51,602 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7443556473698727, 'Total loss': 0.7443556473698727} | train loss {'Reaction outcome loss': 0.8170796785442556, 'Total loss': 0.8170796785442556}
2022-11-23 02:15:51,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:51,603 INFO:     Epoch: 69
2022-11-23 02:15:52,405 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7713899265888126, 'Total loss': 0.7713899265888126} | train loss {'Reaction outcome loss': 0.8203894813529781, 'Total loss': 0.8203894813529781}
2022-11-23 02:15:52,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:52,405 INFO:     Epoch: 70
2022-11-23 02:15:53,236 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7566581902115844, 'Total loss': 0.7566581902115844} | train loss {'Reaction outcome loss': 0.818123383844485, 'Total loss': 0.818123383844485}
2022-11-23 02:15:53,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:53,236 INFO:     Epoch: 71
2022-11-23 02:15:54,097 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7461250057054121, 'Total loss': 0.7461250057054121} | train loss {'Reaction outcome loss': 0.8180104622342548, 'Total loss': 0.8180104622342548}
2022-11-23 02:15:54,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:54,097 INFO:     Epoch: 72
2022-11-23 02:15:54,867 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7527322103810865, 'Total loss': 0.7527322103810865} | train loss {'Reaction outcome loss': 0.8156703693456338, 'Total loss': 0.8156703693456338}
2022-11-23 02:15:54,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:54,867 INFO:     Epoch: 73
2022-11-23 02:15:55,702 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7541946387568186, 'Total loss': 0.7541946387568186} | train loss {'Reaction outcome loss': 0.8202049623503059, 'Total loss': 0.8202049623503059}
2022-11-23 02:15:55,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:55,702 INFO:     Epoch: 74
2022-11-23 02:15:56,490 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.752530935891839, 'Total loss': 0.752530935891839} | train loss {'Reaction outcome loss': 0.8210881709075365, 'Total loss': 0.8210881709075365}
2022-11-23 02:15:56,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:56,490 INFO:     Epoch: 75
2022-11-23 02:15:57,279 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7533630437629167, 'Total loss': 0.7533630437629167} | train loss {'Reaction outcome loss': 0.8193386177547642, 'Total loss': 0.8193386177547642}
2022-11-23 02:15:57,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:57,280 INFO:     Epoch: 76
2022-11-23 02:15:58,126 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7466508073862209, 'Total loss': 0.7466508073862209} | train loss {'Reaction outcome loss': 0.8197225443408137, 'Total loss': 0.8197225443408137}
2022-11-23 02:15:58,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:58,127 INFO:     Epoch: 77
2022-11-23 02:15:58,953 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7757443161897881, 'Total loss': 0.7757443161897881} | train loss {'Reaction outcome loss': 0.8189170508355391, 'Total loss': 0.8189170508355391}
2022-11-23 02:15:58,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:58,954 INFO:     Epoch: 78
2022-11-23 02:15:59,814 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7529455617416737, 'Total loss': 0.7529455617416737} | train loss {'Reaction outcome loss': 0.8205179859135971, 'Total loss': 0.8205179859135971}
2022-11-23 02:15:59,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:15:59,815 INFO:     Epoch: 79
2022-11-23 02:16:00,612 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7563430271869482, 'Total loss': 0.7563430271869482} | train loss {'Reaction outcome loss': 0.8206438657934548, 'Total loss': 0.8206438657934548}
2022-11-23 02:16:00,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:00,613 INFO:     Epoch: 80
2022-11-23 02:16:01,453 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7631708799406539, 'Total loss': 0.7631708799406539} | train loss {'Reaction outcome loss': 0.8222611784690717, 'Total loss': 0.8222611784690717}
2022-11-23 02:16:01,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:01,453 INFO:     Epoch: 81
2022-11-23 02:16:02,281 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7512754499912262, 'Total loss': 0.7512754499912262} | train loss {'Reaction outcome loss': 0.8215036122281043, 'Total loss': 0.8215036122281043}
2022-11-23 02:16:02,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:02,282 INFO:     Epoch: 82
2022-11-23 02:16:03,072 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7662644178368324, 'Total loss': 0.7662644178368324} | train loss {'Reaction outcome loss': 0.8185696644616909, 'Total loss': 0.8185696644616909}
2022-11-23 02:16:03,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:03,073 INFO:     Epoch: 83
2022-11-23 02:16:03,917 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7603698733241059, 'Total loss': 0.7603698733241059} | train loss {'Reaction outcome loss': 0.8203243986993539, 'Total loss': 0.8203243986993539}
2022-11-23 02:16:03,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:03,917 INFO:     Epoch: 84
2022-11-23 02:16:04,762 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.769904202500055, 'Total loss': 0.769904202500055} | train loss {'Reaction outcome loss': 0.8199414576663345, 'Total loss': 0.8199414576663345}
2022-11-23 02:16:04,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:04,762 INFO:     Epoch: 85
2022-11-23 02:16:05,620 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7736490438150805, 'Total loss': 0.7736490438150805} | train loss {'Reaction outcome loss': 0.8209148563566755, 'Total loss': 0.8209148563566755}
2022-11-23 02:16:05,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:05,621 INFO:     Epoch: 86
2022-11-23 02:16:06,499 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8040494350499885, 'Total loss': 0.8040494350499885} | train loss {'Reaction outcome loss': 0.8197988250949344, 'Total loss': 0.8197988250949344}
2022-11-23 02:16:06,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:06,499 INFO:     Epoch: 87
2022-11-23 02:16:07,337 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7567261686158735, 'Total loss': 0.7567261686158735} | train loss {'Reaction outcome loss': 0.8228111197469664, 'Total loss': 0.8228111197469664}
2022-11-23 02:16:07,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:07,337 INFO:     Epoch: 88
2022-11-23 02:16:08,134 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7575097680091858, 'Total loss': 0.7575097680091858} | train loss {'Reaction outcome loss': 0.8277568833016958, 'Total loss': 0.8277568833016958}
2022-11-23 02:16:08,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:08,135 INFO:     Epoch: 89
2022-11-23 02:16:08,955 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7554930545562921, 'Total loss': 0.7554930545562921} | train loss {'Reaction outcome loss': 0.8197394598458634, 'Total loss': 0.8197394598458634}
2022-11-23 02:16:08,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:08,956 INFO:     Epoch: 90
2022-11-23 02:16:09,747 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7727683297423429, 'Total loss': 0.7727683297423429} | train loss {'Reaction outcome loss': 0.8230995798452956, 'Total loss': 0.8230995798452956}
2022-11-23 02:16:09,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:09,747 INFO:     Epoch: 91
2022-11-23 02:16:10,514 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7482601147751475, 'Total loss': 0.7482601147751475} | train loss {'Reaction outcome loss': 0.8181323792602195, 'Total loss': 0.8181323792602195}
2022-11-23 02:16:10,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:10,514 INFO:     Epoch: 92
2022-11-23 02:16:11,327 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7772519318170326, 'Total loss': 0.7772519318170326} | train loss {'Reaction outcome loss': 0.8212465394715793, 'Total loss': 0.8212465394715793}
2022-11-23 02:16:11,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:11,328 INFO:     Epoch: 93
2022-11-23 02:16:12,158 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7531483672385992, 'Total loss': 0.7531483672385992} | train loss {'Reaction outcome loss': 0.8194080467839711, 'Total loss': 0.8194080467839711}
2022-11-23 02:16:12,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:12,158 INFO:     Epoch: 94
2022-11-23 02:16:12,928 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7696174521778905, 'Total loss': 0.7696174521778905} | train loss {'Reaction outcome loss': 0.819144280474694, 'Total loss': 0.819144280474694}
2022-11-23 02:16:12,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:12,929 INFO:     Epoch: 95
2022-11-23 02:16:13,713 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7546380009762076, 'Total loss': 0.7546380009762076} | train loss {'Reaction outcome loss': 0.8235308509625372, 'Total loss': 0.8235308509625372}
2022-11-23 02:16:13,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:13,714 INFO:     Epoch: 96
2022-11-23 02:16:14,510 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7481419430222622, 'Total loss': 0.7481419430222622} | train loss {'Reaction outcome loss': 0.818608852194958, 'Total loss': 0.818608852194958}
2022-11-23 02:16:14,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:14,510 INFO:     Epoch: 97
2022-11-23 02:16:15,275 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.759611982245778, 'Total loss': 0.759611982245778} | train loss {'Reaction outcome loss': 0.8204772054660515, 'Total loss': 0.8204772054660515}
2022-11-23 02:16:15,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:15,276 INFO:     Epoch: 98
2022-11-23 02:16:16,062 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.762008820162263, 'Total loss': 0.762008820162263} | train loss {'Reaction outcome loss': 0.8151885448176353, 'Total loss': 0.8151885448176353}
2022-11-23 02:16:16,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:16,062 INFO:     Epoch: 99
2022-11-23 02:16:16,856 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.749141652916753, 'Total loss': 0.749141652916753} | train loss {'Reaction outcome loss': 0.8182493953919802, 'Total loss': 0.8182493953919802}
2022-11-23 02:16:16,856 INFO:     Best model found after epoch 60 of 100.
2022-11-23 02:16:16,856 INFO:   Done with stage: TRAINING
2022-11-23 02:16:16,856 INFO:   Starting stage: EVALUATION
2022-11-23 02:16:16,994 INFO:   Done with stage: EVALUATION
2022-11-23 02:16:16,994 INFO:   Leaving out SEQ value Fold_2
2022-11-23 02:16:17,007 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-23 02:16:17,007 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:16:17,668 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:16:17,668 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:16:17,740 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:16:17,740 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:16:17,740 INFO:     No hyperparam tuning for this model
2022-11-23 02:16:17,740 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:16:17,740 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:16:17,741 INFO:     None feature selector for col prot
2022-11-23 02:16:17,741 INFO:     None feature selector for col prot
2022-11-23 02:16:17,741 INFO:     None feature selector for col prot
2022-11-23 02:16:17,742 INFO:     None feature selector for col chem
2022-11-23 02:16:17,742 INFO:     None feature selector for col chem
2022-11-23 02:16:17,742 INFO:     None feature selector for col chem
2022-11-23 02:16:17,742 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:16:17,742 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:16:17,744 INFO:     Number of params in model 168571
2022-11-23 02:16:17,747 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:16:17,747 INFO:   Starting stage: TRAINING
2022-11-23 02:16:17,803 INFO:     Val loss before train {'Reaction outcome loss': 0.998527372992316, 'Total loss': 0.998527372992316}
2022-11-23 02:16:17,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:17,803 INFO:     Epoch: 0
2022-11-23 02:16:18,544 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8151815547499546, 'Total loss': 0.8151815547499546} | train loss {'Reaction outcome loss': 0.8733339870172273, 'Total loss': 0.8733339870172273}
2022-11-23 02:16:18,544 INFO:     Found new best model at epoch 0
2022-11-23 02:16:18,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:18,545 INFO:     Epoch: 1
2022-11-23 02:16:19,333 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8191073703211408, 'Total loss': 0.8191073703211408} | train loss {'Reaction outcome loss': 0.8516118300795065, 'Total loss': 0.8516118300795065}
2022-11-23 02:16:19,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:19,334 INFO:     Epoch: 2
2022-11-23 02:16:20,140 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7992762105409489, 'Total loss': 0.7992762105409489} | train loss {'Reaction outcome loss': 0.8411768707350938, 'Total loss': 0.8411768707350938}
2022-11-23 02:16:20,140 INFO:     Found new best model at epoch 2
2022-11-23 02:16:20,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:20,142 INFO:     Epoch: 3
2022-11-23 02:16:20,933 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8108678765075151, 'Total loss': 0.8108678765075151} | train loss {'Reaction outcome loss': 0.8380903801555005, 'Total loss': 0.8380903801555005}
2022-11-23 02:16:20,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:20,934 INFO:     Epoch: 4
2022-11-23 02:16:21,719 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8173435739306516, 'Total loss': 0.8173435739306516} | train loss {'Reaction outcome loss': 0.8309559281225558, 'Total loss': 0.8309559281225558}
2022-11-23 02:16:21,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:21,719 INFO:     Epoch: 5
2022-11-23 02:16:22,529 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8033931629602299, 'Total loss': 0.8033931629602299} | train loss {'Reaction outcome loss': 0.824519324327202, 'Total loss': 0.824519324327202}
2022-11-23 02:16:22,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:22,529 INFO:     Epoch: 6
2022-11-23 02:16:23,301 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8218093694642533, 'Total loss': 0.8218093694642533} | train loss {'Reaction outcome loss': 0.8248128568439327, 'Total loss': 0.8248128568439327}
2022-11-23 02:16:23,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:23,302 INFO:     Epoch: 7
2022-11-23 02:16:24,060 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.814820796251297, 'Total loss': 0.814820796251297} | train loss {'Reaction outcome loss': 0.8274725388597559, 'Total loss': 0.8274725388597559}
2022-11-23 02:16:24,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:24,060 INFO:     Epoch: 8
2022-11-23 02:16:24,859 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8005039414694143, 'Total loss': 0.8005039414694143} | train loss {'Reaction outcome loss': 0.8264990190174354, 'Total loss': 0.8264990190174354}
2022-11-23 02:16:24,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:24,859 INFO:     Epoch: 9
2022-11-23 02:16:25,641 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8384940083636794, 'Total loss': 0.8384940083636794} | train loss {'Reaction outcome loss': 0.821576430228512, 'Total loss': 0.821576430228512}
2022-11-23 02:16:25,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:25,642 INFO:     Epoch: 10
2022-11-23 02:16:26,408 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8117198569830074, 'Total loss': 0.8117198569830074} | train loss {'Reaction outcome loss': 0.8183439063682477, 'Total loss': 0.8183439063682477}
2022-11-23 02:16:26,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:26,408 INFO:     Epoch: 11
2022-11-23 02:16:27,161 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8069183493769446, 'Total loss': 0.8069183493769446} | train loss {'Reaction outcome loss': 0.8229858210547961, 'Total loss': 0.8229858210547961}
2022-11-23 02:16:27,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:27,161 INFO:     Epoch: 12
2022-11-23 02:16:27,928 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8028980902461118, 'Total loss': 0.8028980902461118} | train loss {'Reaction outcome loss': 0.8251378238201141, 'Total loss': 0.8251378238201141}
2022-11-23 02:16:27,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:27,929 INFO:     Epoch: 13
2022-11-23 02:16:28,695 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8059861216434213, 'Total loss': 0.8059861216434213} | train loss {'Reaction outcome loss': 0.8170265043959205, 'Total loss': 0.8170265043959205}
2022-11-23 02:16:28,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:28,695 INFO:     Epoch: 14
2022-11-23 02:16:29,489 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7899644527324411, 'Total loss': 0.7899644527324411} | train loss {'Reaction outcome loss': 0.8159724688579025, 'Total loss': 0.8159724688579025}
2022-11-23 02:16:29,489 INFO:     Found new best model at epoch 14
2022-11-23 02:16:29,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:29,490 INFO:     Epoch: 15
2022-11-23 02:16:30,333 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.802275339531344, 'Total loss': 0.802275339531344} | train loss {'Reaction outcome loss': 0.8157799951578855, 'Total loss': 0.8157799951578855}
2022-11-23 02:16:30,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:30,334 INFO:     Epoch: 16
2022-11-23 02:16:31,129 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8080030776733576, 'Total loss': 0.8080030776733576} | train loss {'Reaction outcome loss': 0.8151053485801681, 'Total loss': 0.8151053485801681}
2022-11-23 02:16:31,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:31,130 INFO:     Epoch: 17
2022-11-23 02:16:31,881 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8008406328600507, 'Total loss': 0.8008406328600507} | train loss {'Reaction outcome loss': 0.8167519516660353, 'Total loss': 0.8167519516660353}
2022-11-23 02:16:31,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:31,882 INFO:     Epoch: 18
2022-11-23 02:16:32,659 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7943107263986454, 'Total loss': 0.7943107263986454} | train loss {'Reaction outcome loss': 0.8171871207623815, 'Total loss': 0.8171871207623815}
2022-11-23 02:16:32,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:32,659 INFO:     Epoch: 19
2022-11-23 02:16:33,494 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7888246026150015, 'Total loss': 0.7888246026150015} | train loss {'Reaction outcome loss': 0.8132798779648518, 'Total loss': 0.8132798779648518}
2022-11-23 02:16:33,494 INFO:     Found new best model at epoch 19
2022-11-23 02:16:33,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:33,495 INFO:     Epoch: 20
2022-11-23 02:16:34,326 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7958855531936468, 'Total loss': 0.7958855531936468} | train loss {'Reaction outcome loss': 0.8165259927879145, 'Total loss': 0.8165259927879145}
2022-11-23 02:16:34,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:34,327 INFO:     Epoch: 21
2022-11-23 02:16:35,148 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7911350186481032, 'Total loss': 0.7911350186481032} | train loss {'Reaction outcome loss': 0.8151438135669065, 'Total loss': 0.8151438135669065}
2022-11-23 02:16:35,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:35,148 INFO:     Epoch: 22
2022-11-23 02:16:35,959 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7949808330036873, 'Total loss': 0.7949808330036873} | train loss {'Reaction outcome loss': 0.8157403424934104, 'Total loss': 0.8157403424934104}
2022-11-23 02:16:35,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:35,959 INFO:     Epoch: 23
2022-11-23 02:16:36,744 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7897313403528791, 'Total loss': 0.7897313403528791} | train loss {'Reaction outcome loss': 0.8147681334627018, 'Total loss': 0.8147681334627018}
2022-11-23 02:16:36,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:36,744 INFO:     Epoch: 24
2022-11-23 02:16:37,504 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7971585448398146, 'Total loss': 0.7971585448398146} | train loss {'Reaction outcome loss': 0.8139493848070686, 'Total loss': 0.8139493848070686}
2022-11-23 02:16:37,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:37,504 INFO:     Epoch: 25
2022-11-23 02:16:38,305 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7887338302856268, 'Total loss': 0.7887338302856268} | train loss {'Reaction outcome loss': 0.8190462466620614, 'Total loss': 0.8190462466620614}
2022-11-23 02:16:38,305 INFO:     Found new best model at epoch 25
2022-11-23 02:16:38,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:38,306 INFO:     Epoch: 26
2022-11-23 02:16:39,101 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8123499889706456, 'Total loss': 0.8123499889706456} | train loss {'Reaction outcome loss': 0.8145677785814545, 'Total loss': 0.8145677785814545}
2022-11-23 02:16:39,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:39,101 INFO:     Epoch: 27
2022-11-23 02:16:39,885 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8004419942234837, 'Total loss': 0.8004419942234837} | train loss {'Reaction outcome loss': 0.8128540011835687, 'Total loss': 0.8128540011835687}
2022-11-23 02:16:39,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:39,886 INFO:     Epoch: 28
2022-11-23 02:16:40,698 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8016680118649505, 'Total loss': 0.8016680118649505} | train loss {'Reaction outcome loss': 0.8144764448880168, 'Total loss': 0.8144764448880168}
2022-11-23 02:16:40,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:40,698 INFO:     Epoch: 29
2022-11-23 02:16:41,463 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8220390060613322, 'Total loss': 0.8220390060613322} | train loss {'Reaction outcome loss': 0.8168694196659841, 'Total loss': 0.8168694196659841}
2022-11-23 02:16:41,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:41,463 INFO:     Epoch: 30
2022-11-23 02:16:42,226 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8105164468288422, 'Total loss': 0.8105164468288422} | train loss {'Reaction outcome loss': 0.8114726483331296, 'Total loss': 0.8114726483331296}
2022-11-23 02:16:42,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:42,226 INFO:     Epoch: 31
2022-11-23 02:16:43,009 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7974873219811639, 'Total loss': 0.7974873219811639} | train loss {'Reaction outcome loss': 0.8167713396097898, 'Total loss': 0.8167713396097898}
2022-11-23 02:16:43,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:43,010 INFO:     Epoch: 32
2022-11-23 02:16:43,829 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7920577034007671, 'Total loss': 0.7920577034007671} | train loss {'Reaction outcome loss': 0.8134182821575997, 'Total loss': 0.8134182821575997}
2022-11-23 02:16:43,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:43,831 INFO:     Epoch: 33
2022-11-23 02:16:44,647 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7938063498153243, 'Total loss': 0.7938063498153243} | train loss {'Reaction outcome loss': 0.8164342961929463, 'Total loss': 0.8164342961929463}
2022-11-23 02:16:44,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:44,648 INFO:     Epoch: 34
2022-11-23 02:16:45,449 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8212261525697486, 'Total loss': 0.8212261525697486} | train loss {'Reaction outcome loss': 0.8102279659897211, 'Total loss': 0.8102279659897211}
2022-11-23 02:16:45,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:45,449 INFO:     Epoch: 35
2022-11-23 02:16:46,277 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7999618323736413, 'Total loss': 0.7999618323736413} | train loss {'Reaction outcome loss': 0.8098292954940609, 'Total loss': 0.8098292954940609}
2022-11-23 02:16:46,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:46,278 INFO:     Epoch: 36
2022-11-23 02:16:47,057 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8022828628850538, 'Total loss': 0.8022828628850538} | train loss {'Reaction outcome loss': 0.8162040389123767, 'Total loss': 0.8162040389123767}
2022-11-23 02:16:47,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:47,057 INFO:     Epoch: 37
2022-11-23 02:16:47,829 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8031153789786405, 'Total loss': 0.8031153789786405} | train loss {'Reaction outcome loss': 0.8107142409179436, 'Total loss': 0.8107142409179436}
2022-11-23 02:16:47,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:47,829 INFO:     Epoch: 38
2022-11-23 02:16:48,667 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7778051398521246, 'Total loss': 0.7778051398521246} | train loss {'Reaction outcome loss': 0.8044223997573303, 'Total loss': 0.8044223997573303}
2022-11-23 02:16:48,667 INFO:     Found new best model at epoch 38
2022-11-23 02:16:48,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:48,668 INFO:     Epoch: 39
2022-11-23 02:16:49,527 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7929378422193749, 'Total loss': 0.7929378422193749} | train loss {'Reaction outcome loss': 0.8094311388431753, 'Total loss': 0.8094311388431753}
2022-11-23 02:16:49,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:49,528 INFO:     Epoch: 40
2022-11-23 02:16:50,345 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7833659018194953, 'Total loss': 0.7833659018194953} | train loss {'Reaction outcome loss': 0.8132445310614237, 'Total loss': 0.8132445310614237}
2022-11-23 02:16:50,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:50,346 INFO:     Epoch: 41
2022-11-23 02:16:51,153 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7891273595565973, 'Total loss': 0.7891273595565973} | train loss {'Reaction outcome loss': 0.8098738723331027, 'Total loss': 0.8098738723331027}
2022-11-23 02:16:51,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:51,153 INFO:     Epoch: 42
2022-11-23 02:16:51,960 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7971713140953419, 'Total loss': 0.7971713140953419} | train loss {'Reaction outcome loss': 0.8101209077079601, 'Total loss': 0.8101209077079601}
2022-11-23 02:16:51,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:51,961 INFO:     Epoch: 43
2022-11-23 02:16:52,906 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7824805663075558, 'Total loss': 0.7824805663075558} | train loss {'Reaction outcome loss': 0.8110347126491766, 'Total loss': 0.8110347126491766}
2022-11-23 02:16:52,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:52,906 INFO:     Epoch: 44
2022-11-23 02:16:53,713 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.813011646270752, 'Total loss': 0.813011646270752} | train loss {'Reaction outcome loss': 0.8057405672691487, 'Total loss': 0.8057405672691487}
2022-11-23 02:16:53,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:53,714 INFO:     Epoch: 45
2022-11-23 02:16:54,497 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8323817405589792, 'Total loss': 0.8323817405589792} | train loss {'Reaction outcome loss': 0.8086111045791289, 'Total loss': 0.8086111045791289}
2022-11-23 02:16:54,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:54,497 INFO:     Epoch: 46
2022-11-23 02:16:55,312 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7935903016910997, 'Total loss': 0.7935903016910997} | train loss {'Reaction outcome loss': 0.8143408697083163, 'Total loss': 0.8143408697083163}
2022-11-23 02:16:55,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:55,312 INFO:     Epoch: 47
2022-11-23 02:16:56,085 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7906731928503791, 'Total loss': 0.7906731928503791} | train loss {'Reaction outcome loss': 0.8077732903476605, 'Total loss': 0.8077732903476605}
2022-11-23 02:16:56,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:56,085 INFO:     Epoch: 48
2022-11-23 02:16:56,901 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7861360179823499, 'Total loss': 0.7861360179823499} | train loss {'Reaction outcome loss': 0.8100728005048179, 'Total loss': 0.8100728005048179}
2022-11-23 02:16:56,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:56,901 INFO:     Epoch: 49
2022-11-23 02:16:57,678 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8042031983996547, 'Total loss': 0.8042031983996547} | train loss {'Reaction outcome loss': 0.8135372332829998, 'Total loss': 0.8135372332829998}
2022-11-23 02:16:57,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:57,678 INFO:     Epoch: 50
2022-11-23 02:16:58,444 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7823861421540727, 'Total loss': 0.7823861421540727} | train loss {'Reaction outcome loss': 0.8067515840746248, 'Total loss': 0.8067515840746248}
2022-11-23 02:16:58,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:58,445 INFO:     Epoch: 51
2022-11-23 02:16:59,192 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.801098053538522, 'Total loss': 0.801098053538522} | train loss {'Reaction outcome loss': 0.8076412120964301, 'Total loss': 0.8076412120964301}
2022-11-23 02:16:59,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:16:59,193 INFO:     Epoch: 52
2022-11-23 02:17:00,060 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7931856526884922, 'Total loss': 0.7931856526884922} | train loss {'Reaction outcome loss': 0.8070667270770289, 'Total loss': 0.8070667270770289}
2022-11-23 02:17:00,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:00,060 INFO:     Epoch: 53
2022-11-23 02:17:00,948 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7812129751194355, 'Total loss': 0.7812129751194355} | train loss {'Reaction outcome loss': 0.8088165291052296, 'Total loss': 0.8088165291052296}
2022-11-23 02:17:00,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:00,949 INFO:     Epoch: 54
2022-11-23 02:17:01,838 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.797655719657277, 'Total loss': 0.797655719657277} | train loss {'Reaction outcome loss': 0.8060464256830177, 'Total loss': 0.8060464256830177}
2022-11-23 02:17:01,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:01,838 INFO:     Epoch: 55
2022-11-23 02:17:02,708 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7981971834981164, 'Total loss': 0.7981971834981164} | train loss {'Reaction outcome loss': 0.8114513044739947, 'Total loss': 0.8114513044739947}
2022-11-23 02:17:02,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:02,709 INFO:     Epoch: 56
2022-11-23 02:17:03,574 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7913967495740846, 'Total loss': 0.7913967495740846} | train loss {'Reaction outcome loss': 0.8076968459190165, 'Total loss': 0.8076968459190165}
2022-11-23 02:17:03,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:03,575 INFO:     Epoch: 57
2022-11-23 02:17:04,402 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8004315481629483, 'Total loss': 0.8004315481629483} | train loss {'Reaction outcome loss': 0.8050175233142366, 'Total loss': 0.8050175233142366}
2022-11-23 02:17:04,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:04,402 INFO:     Epoch: 58
2022-11-23 02:17:05,218 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7863118600013644, 'Total loss': 0.7863118600013644} | train loss {'Reaction outcome loss': 0.8079006657188321, 'Total loss': 0.8079006657188321}
2022-11-23 02:17:05,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:05,218 INFO:     Epoch: 59
2022-11-23 02:17:06,121 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.814176760440649, 'Total loss': 0.814176760440649} | train loss {'Reaction outcome loss': 0.8059615221779042, 'Total loss': 0.8059615221779042}
2022-11-23 02:17:06,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:06,121 INFO:     Epoch: 60
2022-11-23 02:17:07,047 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7901083078495291, 'Total loss': 0.7901083078495291} | train loss {'Reaction outcome loss': 0.8064082519998276, 'Total loss': 0.8064082519998276}
2022-11-23 02:17:07,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:07,048 INFO:     Epoch: 61
2022-11-23 02:17:07,953 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7788857782995978, 'Total loss': 0.7788857782995978} | train loss {'Reaction outcome loss': 0.8140488542279098, 'Total loss': 0.8140488542279098}
2022-11-23 02:17:07,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:07,953 INFO:     Epoch: 62
2022-11-23 02:17:08,843 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7870306109273156, 'Total loss': 0.7870306109273156} | train loss {'Reaction outcome loss': 0.8067869873939718, 'Total loss': 0.8067869873939718}
2022-11-23 02:17:08,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:08,843 INFO:     Epoch: 63
2022-11-23 02:17:09,726 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7847397369007731, 'Total loss': 0.7847397369007731} | train loss {'Reaction outcome loss': 0.8043919145570371, 'Total loss': 0.8043919145570371}
2022-11-23 02:17:09,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:09,726 INFO:     Epoch: 64
2022-11-23 02:17:10,657 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.812335378901903, 'Total loss': 0.812335378901903} | train loss {'Reaction outcome loss': 0.8090902290962361, 'Total loss': 0.8090902290962361}
2022-11-23 02:17:10,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:10,657 INFO:     Epoch: 65
2022-11-23 02:17:11,585 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8265766383603562, 'Total loss': 0.8265766383603562} | train loss {'Reaction outcome loss': 0.8087707684363847, 'Total loss': 0.8087707684363847}
2022-11-23 02:17:11,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:11,586 INFO:     Epoch: 66
2022-11-23 02:17:12,554 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7767150228799775, 'Total loss': 0.7767150228799775} | train loss {'Reaction outcome loss': 0.8105546001789501, 'Total loss': 0.8105546001789501}
2022-11-23 02:17:12,554 INFO:     Found new best model at epoch 66
2022-11-23 02:17:12,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:12,555 INFO:     Epoch: 67
2022-11-23 02:17:13,456 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7974676954191785, 'Total loss': 0.7974676954191785} | train loss {'Reaction outcome loss': 0.8097124319262956, 'Total loss': 0.8097124319262956}
2022-11-23 02:17:13,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:13,456 INFO:     Epoch: 68
2022-11-23 02:17:14,396 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7934121988540472, 'Total loss': 0.7934121988540472} | train loss {'Reaction outcome loss': 0.8081366802439277, 'Total loss': 0.8081366802439277}
2022-11-23 02:17:14,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:14,398 INFO:     Epoch: 69
2022-11-23 02:17:15,350 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8017181158065796, 'Total loss': 0.8017181158065796} | train loss {'Reaction outcome loss': 0.8141734904222527, 'Total loss': 0.8141734904222527}
2022-11-23 02:17:15,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:15,351 INFO:     Epoch: 70
2022-11-23 02:17:16,239 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7822202908438306, 'Total loss': 0.7822202908438306} | train loss {'Reaction outcome loss': 0.812065890909713, 'Total loss': 0.812065890909713}
2022-11-23 02:17:16,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:16,239 INFO:     Epoch: 71
2022-11-23 02:17:17,140 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8060584865337195, 'Total loss': 0.8060584865337195} | train loss {'Reaction outcome loss': 0.8056089403452696, 'Total loss': 0.8056089403452696}
2022-11-23 02:17:17,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:17,140 INFO:     Epoch: 72
2022-11-23 02:17:18,036 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8108620546584906, 'Total loss': 0.8108620546584906} | train loss {'Reaction outcome loss': 0.8106445641919909, 'Total loss': 0.8106445641919909}
2022-11-23 02:17:18,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:18,036 INFO:     Epoch: 73
2022-11-23 02:17:18,895 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7923065742780996, 'Total loss': 0.7923065742780996} | train loss {'Reaction outcome loss': 0.8054786785639854, 'Total loss': 0.8054786785639854}
2022-11-23 02:17:18,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:18,895 INFO:     Epoch: 74
2022-11-23 02:17:19,742 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7936485326567362, 'Total loss': 0.7936485326567362} | train loss {'Reaction outcome loss': 0.8050818113387858, 'Total loss': 0.8050818113387858}
2022-11-23 02:17:19,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:19,742 INFO:     Epoch: 75
2022-11-23 02:17:20,591 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.78597483870595, 'Total loss': 0.78597483870595} | train loss {'Reaction outcome loss': 0.801303032371733, 'Total loss': 0.801303032371733}
2022-11-23 02:17:20,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:20,595 INFO:     Epoch: 76
2022-11-23 02:17:21,438 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.812208040509113, 'Total loss': 0.812208040509113} | train loss {'Reaction outcome loss': 0.8104356593555875, 'Total loss': 0.8104356593555875}
2022-11-23 02:17:21,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:21,438 INFO:     Epoch: 77
2022-11-23 02:17:22,270 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8058471139087233, 'Total loss': 0.8058471139087233} | train loss {'Reaction outcome loss': 0.8021430163471787, 'Total loss': 0.8021430163471787}
2022-11-23 02:17:22,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:22,270 INFO:     Epoch: 78
2022-11-23 02:17:23,146 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8170074564079906, 'Total loss': 0.8170074564079906} | train loss {'Reaction outcome loss': 0.8076523405043676, 'Total loss': 0.8076523405043676}
2022-11-23 02:17:23,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:23,147 INFO:     Epoch: 79
2022-11-23 02:17:24,016 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.79740341388902, 'Total loss': 0.79740341388902} | train loss {'Reaction outcome loss': 0.8023319528917227, 'Total loss': 0.8023319528917227}
2022-11-23 02:17:24,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:24,016 INFO:     Epoch: 80
2022-11-23 02:17:24,887 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7935910114022189, 'Total loss': 0.7935910114022189} | train loss {'Reaction outcome loss': 0.8098744250864649, 'Total loss': 0.8098744250864649}
2022-11-23 02:17:24,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:24,889 INFO:     Epoch: 81
2022-11-23 02:17:25,713 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8154579449531644, 'Total loss': 0.8154579449531644} | train loss {'Reaction outcome loss': 0.8086948716100842, 'Total loss': 0.8086948716100842}
2022-11-23 02:17:25,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:25,713 INFO:     Epoch: 82
2022-11-23 02:17:26,544 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8053807824157005, 'Total loss': 0.8053807824157005} | train loss {'Reaction outcome loss': 0.8054073596442187, 'Total loss': 0.8054073596442187}
2022-11-23 02:17:26,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:26,544 INFO:     Epoch: 83
2022-11-23 02:17:27,440 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7788314375766489, 'Total loss': 0.7788314375766489} | train loss {'Reaction outcome loss': 0.8061968694007936, 'Total loss': 0.8061968694007936}
2022-11-23 02:17:27,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:27,441 INFO:     Epoch: 84
2022-11-23 02:17:28,340 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7825682107792344, 'Total loss': 0.7825682107792344} | train loss {'Reaction outcome loss': 0.8045815553194211, 'Total loss': 0.8045815553194211}
2022-11-23 02:17:28,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:28,341 INFO:     Epoch: 85
2022-11-23 02:17:29,185 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7862542084483213, 'Total loss': 0.7862542084483213} | train loss {'Reaction outcome loss': 0.8076975937978721, 'Total loss': 0.8076975937978721}
2022-11-23 02:17:29,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:29,186 INFO:     Epoch: 86
2022-11-23 02:17:30,024 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8084634916726933, 'Total loss': 0.8084634916726933} | train loss {'Reaction outcome loss': 0.8052482398939721, 'Total loss': 0.8052482398939721}
2022-11-23 02:17:30,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:30,026 INFO:     Epoch: 87
2022-11-23 02:17:30,842 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7923759714115498, 'Total loss': 0.7923759714115498} | train loss {'Reaction outcome loss': 0.8065760127065603, 'Total loss': 0.8065760127065603}
2022-11-23 02:17:30,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:30,842 INFO:     Epoch: 88
2022-11-23 02:17:31,628 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7852110502331756, 'Total loss': 0.7852110502331756} | train loss {'Reaction outcome loss': 0.8076530892417264, 'Total loss': 0.8076530892417264}
2022-11-23 02:17:31,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:31,628 INFO:     Epoch: 89
2022-11-23 02:17:32,443 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7976980431135311, 'Total loss': 0.7976980431135311} | train loss {'Reaction outcome loss': 0.8124926214110214, 'Total loss': 0.8124926214110214}
2022-11-23 02:17:32,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:32,444 INFO:     Epoch: 90
2022-11-23 02:17:33,288 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7854968122271604, 'Total loss': 0.7854968122271604} | train loss {'Reaction outcome loss': 0.8033641422236407, 'Total loss': 0.8033641422236407}
2022-11-23 02:17:33,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:33,288 INFO:     Epoch: 91
2022-11-23 02:17:34,152 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7900322592535685, 'Total loss': 0.7900322592535685} | train loss {'Reaction outcome loss': 0.8037493509765515, 'Total loss': 0.8037493509765515}
2022-11-23 02:17:34,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:34,152 INFO:     Epoch: 92
2022-11-23 02:17:34,986 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7874423327834107, 'Total loss': 0.7874423327834107} | train loss {'Reaction outcome loss': 0.8143081332675715, 'Total loss': 0.8143081332675715}
2022-11-23 02:17:34,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:34,988 INFO:     Epoch: 93
2022-11-23 02:17:35,841 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7926485413728759, 'Total loss': 0.7926485413728759} | train loss {'Reaction outcome loss': 0.8069043315241857, 'Total loss': 0.8069043315241857}
2022-11-23 02:17:35,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:35,841 INFO:     Epoch: 94
2022-11-23 02:17:36,662 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7910535453363906, 'Total loss': 0.7910535453363906} | train loss {'Reaction outcome loss': 0.8079579505655501, 'Total loss': 0.8079579505655501}
2022-11-23 02:17:36,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:36,663 INFO:     Epoch: 95
2022-11-23 02:17:37,463 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.795794660268828, 'Total loss': 0.795794660268828} | train loss {'Reaction outcome loss': 0.8006367066514836, 'Total loss': 0.8006367066514836}
2022-11-23 02:17:37,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:37,463 INFO:     Epoch: 96
2022-11-23 02:17:38,341 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7793622619883959, 'Total loss': 0.7793622619883959} | train loss {'Reaction outcome loss': 0.7996988833686451, 'Total loss': 0.7996988833686451}
2022-11-23 02:17:38,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:38,342 INFO:     Epoch: 97
2022-11-23 02:17:39,183 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8293175919111385, 'Total loss': 0.8293175919111385} | train loss {'Reaction outcome loss': 0.8054188975581417, 'Total loss': 0.8054188975581417}
2022-11-23 02:17:39,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:39,183 INFO:     Epoch: 98
2022-11-23 02:17:40,010 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7961857748586078, 'Total loss': 0.7961857748586078} | train loss {'Reaction outcome loss': 0.8032498360906609, 'Total loss': 0.8032498360906609}
2022-11-23 02:17:40,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:40,010 INFO:     Epoch: 99
2022-11-23 02:17:40,838 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7804405703101047, 'Total loss': 0.7804405703101047} | train loss {'Reaction outcome loss': 0.8031773317007371, 'Total loss': 0.8031773317007371}
2022-11-23 02:17:40,840 INFO:     Best model found after epoch 67 of 100.
2022-11-23 02:17:40,840 INFO:   Done with stage: TRAINING
2022-11-23 02:17:40,840 INFO:   Starting stage: EVALUATION
2022-11-23 02:17:40,983 INFO:   Done with stage: EVALUATION
2022-11-23 02:17:40,983 INFO:   Leaving out SEQ value Fold_3
2022-11-23 02:17:40,997 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 02:17:40,997 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:17:41,677 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:17:41,677 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:17:41,752 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:17:41,752 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:17:41,752 INFO:     No hyperparam tuning for this model
2022-11-23 02:17:41,753 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:17:41,753 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:17:41,754 INFO:     None feature selector for col prot
2022-11-23 02:17:41,754 INFO:     None feature selector for col prot
2022-11-23 02:17:41,754 INFO:     None feature selector for col prot
2022-11-23 02:17:41,755 INFO:     None feature selector for col chem
2022-11-23 02:17:41,755 INFO:     None feature selector for col chem
2022-11-23 02:17:41,755 INFO:     None feature selector for col chem
2022-11-23 02:17:41,755 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:17:41,755 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:17:41,757 INFO:     Number of params in model 168571
2022-11-23 02:17:41,760 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:17:41,760 INFO:   Starting stage: TRAINING
2022-11-23 02:17:41,820 INFO:     Val loss before train {'Reaction outcome loss': 1.0599756701426073, 'Total loss': 1.0599756701426073}
2022-11-23 02:17:41,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:41,820 INFO:     Epoch: 0
2022-11-23 02:17:42,708 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9185246540741487, 'Total loss': 0.9185246540741487} | train loss {'Reaction outcome loss': 0.8619308683336998, 'Total loss': 0.8619308683336998}
2022-11-23 02:17:42,708 INFO:     Found new best model at epoch 0
2022-11-23 02:17:42,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:42,709 INFO:     Epoch: 1
2022-11-23 02:17:43,563 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8954652629115365, 'Total loss': 0.8954652629115365} | train loss {'Reaction outcome loss': 0.8367841496759532, 'Total loss': 0.8367841496759532}
2022-11-23 02:17:43,563 INFO:     Found new best model at epoch 1
2022-11-23 02:17:43,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:43,564 INFO:     Epoch: 2
2022-11-23 02:17:44,438 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8632667100226338, 'Total loss': 0.8632667100226338} | train loss {'Reaction outcome loss': 0.8276525758967108, 'Total loss': 0.8276525758967108}
2022-11-23 02:17:44,438 INFO:     Found new best model at epoch 2
2022-11-23 02:17:44,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:44,439 INFO:     Epoch: 3
2022-11-23 02:17:45,314 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8861025490544059, 'Total loss': 0.8861025490544059} | train loss {'Reaction outcome loss': 0.8280283359848724, 'Total loss': 0.8280283359848724}
2022-11-23 02:17:45,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:45,315 INFO:     Epoch: 4
2022-11-23 02:17:46,179 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8830253820527684, 'Total loss': 0.8830253820527684} | train loss {'Reaction outcome loss': 0.8224272894616029, 'Total loss': 0.8224272894616029}
2022-11-23 02:17:46,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:46,179 INFO:     Epoch: 5
2022-11-23 02:17:46,966 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8609976020048965, 'Total loss': 0.8609976020048965} | train loss {'Reaction outcome loss': 0.8211073443597677, 'Total loss': 0.8211073443597677}
2022-11-23 02:17:46,967 INFO:     Found new best model at epoch 5
2022-11-23 02:17:46,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:46,968 INFO:     Epoch: 6
2022-11-23 02:17:47,802 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8807042261416261, 'Total loss': 0.8807042261416261} | train loss {'Reaction outcome loss': 0.8166754565676865, 'Total loss': 0.8166754565676865}
2022-11-23 02:17:47,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:47,802 INFO:     Epoch: 7
2022-11-23 02:17:48,683 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8647178066047755, 'Total loss': 0.8647178066047755} | train loss {'Reaction outcome loss': 0.8138293677446794, 'Total loss': 0.8138293677446794}
2022-11-23 02:17:48,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:48,684 INFO:     Epoch: 8
2022-11-23 02:17:49,566 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8815725262869488, 'Total loss': 0.8815725262869488} | train loss {'Reaction outcome loss': 0.8133358511389518, 'Total loss': 0.8133358511389518}
2022-11-23 02:17:49,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:49,566 INFO:     Epoch: 9
2022-11-23 02:17:50,442 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.9009147421880201, 'Total loss': 0.9009147421880201} | train loss {'Reaction outcome loss': 0.811928921451374, 'Total loss': 0.811928921451374}
2022-11-23 02:17:50,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:50,443 INFO:     Epoch: 10
2022-11-23 02:17:51,307 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8688119317997586, 'Total loss': 0.8688119317997586} | train loss {'Reaction outcome loss': 0.8105110847220129, 'Total loss': 0.8105110847220129}
2022-11-23 02:17:51,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:51,307 INFO:     Epoch: 11
2022-11-23 02:17:52,134 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8800444819710471, 'Total loss': 0.8800444819710471} | train loss {'Reaction outcome loss': 0.8121632335137348, 'Total loss': 0.8121632335137348}
2022-11-23 02:17:52,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:52,135 INFO:     Epoch: 12
2022-11-23 02:17:52,979 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8707825849679384, 'Total loss': 0.8707825849679384} | train loss {'Reaction outcome loss': 0.8036539852619171, 'Total loss': 0.8036539852619171}
2022-11-23 02:17:52,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:52,980 INFO:     Epoch: 13
2022-11-23 02:17:53,820 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8602845743298531, 'Total loss': 0.8602845743298531} | train loss {'Reaction outcome loss': 0.8142623015812465, 'Total loss': 0.8142623015812465}
2022-11-23 02:17:53,820 INFO:     Found new best model at epoch 13
2022-11-23 02:17:53,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:53,821 INFO:     Epoch: 14
2022-11-23 02:17:54,664 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8662740832025354, 'Total loss': 0.8662740832025354} | train loss {'Reaction outcome loss': 0.8091918213026864, 'Total loss': 0.8091918213026864}
2022-11-23 02:17:54,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:54,665 INFO:     Epoch: 15
2022-11-23 02:17:55,476 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8650696406310255, 'Total loss': 0.8650696406310255} | train loss {'Reaction outcome loss': 0.8097041659209193, 'Total loss': 0.8097041659209193}
2022-11-23 02:17:55,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:55,477 INFO:     Epoch: 16
2022-11-23 02:17:56,456 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8663171096281572, 'Total loss': 0.8663171096281572} | train loss {'Reaction outcome loss': 0.8104049846834066, 'Total loss': 0.8104049846834066}
2022-11-23 02:17:56,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:56,457 INFO:     Epoch: 17
2022-11-23 02:17:57,308 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8543629013001919, 'Total loss': 0.8543629013001919} | train loss {'Reaction outcome loss': 0.8060440294596614, 'Total loss': 0.8060440294596614}
2022-11-23 02:17:57,308 INFO:     Found new best model at epoch 17
2022-11-23 02:17:57,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:57,310 INFO:     Epoch: 18
2022-11-23 02:17:58,218 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8834440261125565, 'Total loss': 0.8834440261125565} | train loss {'Reaction outcome loss': 0.8064003078304991, 'Total loss': 0.8064003078304991}
2022-11-23 02:17:58,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:58,220 INFO:     Epoch: 19
2022-11-23 02:17:59,227 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8663372207771648, 'Total loss': 0.8663372207771648} | train loss {'Reaction outcome loss': 0.8029936685854074, 'Total loss': 0.8029936685854074}
2022-11-23 02:17:59,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:17:59,227 INFO:     Epoch: 20
2022-11-23 02:18:00,110 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8724995770237662, 'Total loss': 0.8724995770237662} | train loss {'Reaction outcome loss': 0.8080491670540401, 'Total loss': 0.8080491670540401}
2022-11-23 02:18:00,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:00,111 INFO:     Epoch: 21
2022-11-23 02:18:01,028 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.9184801131486893, 'Total loss': 0.9184801131486893} | train loss {'Reaction outcome loss': 0.807972043509386, 'Total loss': 0.807972043509386}
2022-11-23 02:18:01,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:01,028 INFO:     Epoch: 22
2022-11-23 02:18:01,916 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8828855874863538, 'Total loss': 0.8828855874863538} | train loss {'Reaction outcome loss': 0.8090052541421384, 'Total loss': 0.8090052541421384}
2022-11-23 02:18:01,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:01,916 INFO:     Epoch: 23
2022-11-23 02:18:02,769 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8761514940045096, 'Total loss': 0.8761514940045096} | train loss {'Reaction outcome loss': 0.8062506167256103, 'Total loss': 0.8062506167256103}
2022-11-23 02:18:02,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:02,770 INFO:     Epoch: 24
2022-11-23 02:18:03,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8730942823670127, 'Total loss': 0.8730942823670127} | train loss {'Reaction outcome loss': 0.8045442972864424, 'Total loss': 0.8045442972864424}
2022-11-23 02:18:03,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:03,609 INFO:     Epoch: 25
2022-11-23 02:18:04,468 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8807462562214244, 'Total loss': 0.8807462562214244} | train loss {'Reaction outcome loss': 0.8088958972570848, 'Total loss': 0.8088958972570848}
2022-11-23 02:18:04,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:04,469 INFO:     Epoch: 26
2022-11-23 02:18:05,309 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8671395981853659, 'Total loss': 0.8671395981853659} | train loss {'Reaction outcome loss': 0.8056331781708465, 'Total loss': 0.8056331781708465}
2022-11-23 02:18:05,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:05,309 INFO:     Epoch: 27
2022-11-23 02:18:06,155 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8840531639077447, 'Total loss': 0.8840531639077447} | train loss {'Reaction outcome loss': 0.8044042354943801, 'Total loss': 0.8044042354943801}
2022-11-23 02:18:06,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:06,155 INFO:     Epoch: 28
2022-11-23 02:18:07,018 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8914198218421503, 'Total loss': 0.8914198218421503} | train loss {'Reaction outcome loss': 0.805964158019241, 'Total loss': 0.805964158019241}
2022-11-23 02:18:07,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:07,018 INFO:     Epoch: 29
2022-11-23 02:18:07,798 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8671766445040703, 'Total loss': 0.8671766445040703} | train loss {'Reaction outcome loss': 0.8048693920884814, 'Total loss': 0.8048693920884814}
2022-11-23 02:18:07,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:07,799 INFO:     Epoch: 30
2022-11-23 02:18:08,646 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8708407553759488, 'Total loss': 0.8708407553759488} | train loss {'Reaction outcome loss': 0.8059320554441335, 'Total loss': 0.8059320554441335}
2022-11-23 02:18:08,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:08,646 INFO:     Epoch: 31
2022-11-23 02:18:09,489 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8993564586747776, 'Total loss': 0.8993564586747776} | train loss {'Reaction outcome loss': 0.8059953912180298, 'Total loss': 0.8059953912180298}
2022-11-23 02:18:09,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:09,491 INFO:     Epoch: 32
2022-11-23 02:18:10,293 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.9124816629019651, 'Total loss': 0.9124816629019651} | train loss {'Reaction outcome loss': 0.8047359742680374, 'Total loss': 0.8047359742680374}
2022-11-23 02:18:10,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:10,293 INFO:     Epoch: 33
2022-11-23 02:18:11,105 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8648552298545837, 'Total loss': 0.8648552298545837} | train loss {'Reaction outcome loss': 0.8048342400667619, 'Total loss': 0.8048342400667619}
2022-11-23 02:18:11,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:11,105 INFO:     Epoch: 34
2022-11-23 02:18:11,977 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8688818405974995, 'Total loss': 0.8688818405974995} | train loss {'Reaction outcome loss': 0.8097480491716035, 'Total loss': 0.8097480491716035}
2022-11-23 02:18:11,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:11,977 INFO:     Epoch: 35
2022-11-23 02:18:12,764 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8765295039523732, 'Total loss': 0.8765295039523732} | train loss {'Reaction outcome loss': 0.8017266178617672, 'Total loss': 0.8017266178617672}
2022-11-23 02:18:12,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:12,764 INFO:     Epoch: 36
2022-11-23 02:18:13,556 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8714286894960837, 'Total loss': 0.8714286894960837} | train loss {'Reaction outcome loss': 0.8058235724361575, 'Total loss': 0.8058235724361575}
2022-11-23 02:18:13,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:13,557 INFO:     Epoch: 37
2022-11-23 02:18:14,379 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8558239682831548, 'Total loss': 0.8558239682831548} | train loss {'Reaction outcome loss': 0.8027478255787674, 'Total loss': 0.8027478255787674}
2022-11-23 02:18:14,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:14,380 INFO:     Epoch: 38
2022-11-23 02:18:15,214 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.9006237956610593, 'Total loss': 0.9006237956610593} | train loss {'Reaction outcome loss': 0.8083589567213643, 'Total loss': 0.8083589567213643}
2022-11-23 02:18:15,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:15,215 INFO:     Epoch: 39
2022-11-23 02:18:16,020 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8936301781372591, 'Total loss': 0.8936301781372591} | train loss {'Reaction outcome loss': 0.8050122702608303, 'Total loss': 0.8050122702608303}
2022-11-23 02:18:16,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:16,021 INFO:     Epoch: 40
2022-11-23 02:18:16,771 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8798688812689348, 'Total loss': 0.8798688812689348} | train loss {'Reaction outcome loss': 0.8037388790626915, 'Total loss': 0.8037388790626915}
2022-11-23 02:18:16,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:16,771 INFO:     Epoch: 41
2022-11-23 02:18:17,558 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8714349296959963, 'Total loss': 0.8714349296959963} | train loss {'Reaction outcome loss': 0.8056457559673154, 'Total loss': 0.8056457559673154}
2022-11-23 02:18:17,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:17,558 INFO:     Epoch: 42
2022-11-23 02:18:18,365 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8696922490542586, 'Total loss': 0.8696922490542586} | train loss {'Reaction outcome loss': 0.8067798799397994, 'Total loss': 0.8067798799397994}
2022-11-23 02:18:18,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:18,365 INFO:     Epoch: 43
2022-11-23 02:18:19,202 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8733884279023517, 'Total loss': 0.8733884279023517} | train loss {'Reaction outcome loss': 0.8051722420721638, 'Total loss': 0.8051722420721638}
2022-11-23 02:18:19,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:19,202 INFO:     Epoch: 44
2022-11-23 02:18:20,044 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.859969012439251, 'Total loss': 0.859969012439251} | train loss {'Reaction outcome loss': 0.8060831117386721, 'Total loss': 0.8060831117386721}
2022-11-23 02:18:20,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:20,044 INFO:     Epoch: 45
2022-11-23 02:18:20,847 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8520487533374266, 'Total loss': 0.8520487533374266} | train loss {'Reaction outcome loss': 0.8039613869725442, 'Total loss': 0.8039613869725442}
2022-11-23 02:18:20,847 INFO:     Found new best model at epoch 45
2022-11-23 02:18:20,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:20,848 INFO:     Epoch: 46
2022-11-23 02:18:21,675 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8492026593197476, 'Total loss': 0.8492026593197476} | train loss {'Reaction outcome loss': 0.8069249962057387, 'Total loss': 0.8069249962057387}
2022-11-23 02:18:21,676 INFO:     Found new best model at epoch 46
2022-11-23 02:18:21,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:21,677 INFO:     Epoch: 47
2022-11-23 02:18:22,561 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.880092167718844, 'Total loss': 0.880092167718844} | train loss {'Reaction outcome loss': 0.8029777115705062, 'Total loss': 0.8029777115705062}
2022-11-23 02:18:22,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:22,562 INFO:     Epoch: 48
2022-11-23 02:18:23,420 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8729192384264686, 'Total loss': 0.8729192384264686} | train loss {'Reaction outcome loss': 0.805617230279105, 'Total loss': 0.805617230279105}
2022-11-23 02:18:23,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:23,420 INFO:     Epoch: 49
2022-11-23 02:18:24,220 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8702914240685377, 'Total loss': 0.8702914240685377} | train loss {'Reaction outcome loss': 0.8066155954283111, 'Total loss': 0.8066155954283111}
2022-11-23 02:18:24,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:24,220 INFO:     Epoch: 50
2022-11-23 02:18:25,081 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8851061395623467, 'Total loss': 0.8851061395623467} | train loss {'Reaction outcome loss': 0.8069590182936921, 'Total loss': 0.8069590182936921}
2022-11-23 02:18:25,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:25,082 INFO:     Epoch: 51
2022-11-23 02:18:25,868 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8690059252760627, 'Total loss': 0.8690059252760627} | train loss {'Reaction outcome loss': 0.7995534396901423, 'Total loss': 0.7995534396901423}
2022-11-23 02:18:25,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:25,869 INFO:     Epoch: 52
2022-11-23 02:18:26,664 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.847489440982992, 'Total loss': 0.847489440982992} | train loss {'Reaction outcome loss': 0.8026132269781463, 'Total loss': 0.8026132269781463}
2022-11-23 02:18:26,665 INFO:     Found new best model at epoch 52
2022-11-23 02:18:26,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:26,667 INFO:     Epoch: 53
2022-11-23 02:18:27,474 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8507121389901097, 'Total loss': 0.8507121389901097} | train loss {'Reaction outcome loss': 0.8060795231741302, 'Total loss': 0.8060795231741302}
2022-11-23 02:18:27,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:27,475 INFO:     Epoch: 54
2022-11-23 02:18:28,250 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8556702529842203, 'Total loss': 0.8556702529842203} | train loss {'Reaction outcome loss': 0.804020410532854, 'Total loss': 0.804020410532854}
2022-11-23 02:18:28,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:28,251 INFO:     Epoch: 55
2022-11-23 02:18:29,053 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8662242808125236, 'Total loss': 0.8662242808125236} | train loss {'Reaction outcome loss': 0.8046765668051583, 'Total loss': 0.8046765668051583}
2022-11-23 02:18:29,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:29,054 INFO:     Epoch: 56
2022-11-23 02:18:29,852 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8779358735138719, 'Total loss': 0.8779358735138719} | train loss {'Reaction outcome loss': 0.8060741337586422, 'Total loss': 0.8060741337586422}
2022-11-23 02:18:29,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:29,852 INFO:     Epoch: 57
2022-11-23 02:18:30,684 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8915801583365961, 'Total loss': 0.8915801583365961} | train loss {'Reaction outcome loss': 0.8034751393357101, 'Total loss': 0.8034751393357101}
2022-11-23 02:18:30,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:30,685 INFO:     Epoch: 58
2022-11-23 02:18:31,535 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8686102493242784, 'Total loss': 0.8686102493242784} | train loss {'Reaction outcome loss': 0.7999354586309316, 'Total loss': 0.7999354586309316}
2022-11-23 02:18:31,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:31,535 INFO:     Epoch: 59
2022-11-23 02:18:32,375 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8583570244637403, 'Total loss': 0.8583570244637403} | train loss {'Reaction outcome loss': 0.8039880225853044, 'Total loss': 0.8039880225853044}
2022-11-23 02:18:32,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:32,377 INFO:     Epoch: 60
2022-11-23 02:18:33,234 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.9102526848966425, 'Total loss': 0.9102526848966425} | train loss {'Reaction outcome loss': 0.8064097436106935, 'Total loss': 0.8064097436106935}
2022-11-23 02:18:33,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:33,234 INFO:     Epoch: 61
2022-11-23 02:18:34,054 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8727764175696806, 'Total loss': 0.8727764175696806} | train loss {'Reaction outcome loss': 0.8021978285847878, 'Total loss': 0.8021978285847878}
2022-11-23 02:18:34,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:34,055 INFO:     Epoch: 62
2022-11-23 02:18:34,848 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8550461544231935, 'Total loss': 0.8550461544231935} | train loss {'Reaction outcome loss': 0.8076757985718396, 'Total loss': 0.8076757985718396}
2022-11-23 02:18:34,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:34,848 INFO:     Epoch: 63
2022-11-23 02:18:35,632 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8805808607827533, 'Total loss': 0.8805808607827533} | train loss {'Reaction outcome loss': 0.8060257613658905, 'Total loss': 0.8060257613658905}
2022-11-23 02:18:35,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:35,632 INFO:     Epoch: 64
2022-11-23 02:18:36,427 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8601870306513526, 'Total loss': 0.8601870306513526} | train loss {'Reaction outcome loss': 0.8031739260469164, 'Total loss': 0.8031739260469164}
2022-11-23 02:18:36,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:36,428 INFO:     Epoch: 65
2022-11-23 02:18:37,214 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8900551077994433, 'Total loss': 0.8900551077994433} | train loss {'Reaction outcome loss': 0.8032148083861993, 'Total loss': 0.8032148083861993}
2022-11-23 02:18:37,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:37,214 INFO:     Epoch: 66
2022-11-23 02:18:37,958 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8994446003978903, 'Total loss': 0.8994446003978903} | train loss {'Reaction outcome loss': 0.8087573152415607, 'Total loss': 0.8087573152415607}
2022-11-23 02:18:37,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:37,959 INFO:     Epoch: 67
2022-11-23 02:18:38,736 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8921759047291495, 'Total loss': 0.8921759047291495} | train loss {'Reaction outcome loss': 0.810772722594592, 'Total loss': 0.810772722594592}
2022-11-23 02:18:38,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:38,737 INFO:     Epoch: 68
2022-11-23 02:18:39,501 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8718990222974257, 'Total loss': 0.8718990222974257} | train loss {'Reaction outcome loss': 0.804829556479746, 'Total loss': 0.804829556479746}
2022-11-23 02:18:39,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:39,501 INFO:     Epoch: 69
2022-11-23 02:18:40,309 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8934692686254327, 'Total loss': 0.8934692686254327} | train loss {'Reaction outcome loss': 0.8030169594044588, 'Total loss': 0.8030169594044588}
2022-11-23 02:18:40,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:40,309 INFO:     Epoch: 70
2022-11-23 02:18:41,112 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8845188590613279, 'Total loss': 0.8845188590613279} | train loss {'Reaction outcome loss': 0.8058337980387162, 'Total loss': 0.8058337980387162}
2022-11-23 02:18:41,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:41,112 INFO:     Epoch: 71
2022-11-23 02:18:41,923 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8686987493525852, 'Total loss': 0.8686987493525852} | train loss {'Reaction outcome loss': 0.808264208934745, 'Total loss': 0.808264208934745}
2022-11-23 02:18:41,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:41,923 INFO:     Epoch: 72
2022-11-23 02:18:42,713 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8544029424136336, 'Total loss': 0.8544029424136336} | train loss {'Reaction outcome loss': 0.8069283231180542, 'Total loss': 0.8069283231180542}
2022-11-23 02:18:42,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:42,714 INFO:     Epoch: 73
2022-11-23 02:18:43,502 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8684199493039738, 'Total loss': 0.8684199493039738} | train loss {'Reaction outcome loss': 0.8040417693099197, 'Total loss': 0.8040417693099197}
2022-11-23 02:18:43,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:43,503 INFO:     Epoch: 74
2022-11-23 02:18:44,334 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8675177151506598, 'Total loss': 0.8675177151506598} | train loss {'Reaction outcome loss': 0.8052256870026491, 'Total loss': 0.8052256870026491}
2022-11-23 02:18:44,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:44,335 INFO:     Epoch: 75
2022-11-23 02:18:45,180 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8620195761322975, 'Total loss': 0.8620195761322975} | train loss {'Reaction outcome loss': 0.7996458158201101, 'Total loss': 0.7996458158201101}
2022-11-23 02:18:45,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:45,180 INFO:     Epoch: 76
2022-11-23 02:18:45,998 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8896086290478706, 'Total loss': 0.8896086290478706} | train loss {'Reaction outcome loss': 0.8022936035175713, 'Total loss': 0.8022936035175713}
2022-11-23 02:18:45,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:45,999 INFO:     Epoch: 77
2022-11-23 02:18:46,754 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8885155086490241, 'Total loss': 0.8885155086490241} | train loss {'Reaction outcome loss': 0.805056706983216, 'Total loss': 0.805056706983216}
2022-11-23 02:18:46,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:46,755 INFO:     Epoch: 78
2022-11-23 02:18:47,519 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8747119869698178, 'Total loss': 0.8747119869698178} | train loss {'Reaction outcome loss': 0.8044513564936969, 'Total loss': 0.8044513564936969}
2022-11-23 02:18:47,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:47,519 INFO:     Epoch: 79
2022-11-23 02:18:48,309 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8690184991468083, 'Total loss': 0.8690184991468083} | train loss {'Reaction outcome loss': 0.8058074564349894, 'Total loss': 0.8058074564349894}
2022-11-23 02:18:48,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:48,310 INFO:     Epoch: 80
2022-11-23 02:18:49,093 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8847957666624676, 'Total loss': 0.8847957666624676} | train loss {'Reaction outcome loss': 0.8050776209150042, 'Total loss': 0.8050776209150042}
2022-11-23 02:18:49,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:49,093 INFO:     Epoch: 81
2022-11-23 02:18:49,850 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.9539177749644626, 'Total loss': 0.9539177749644626} | train loss {'Reaction outcome loss': 0.8014815523916361, 'Total loss': 0.8014815523916361}
2022-11-23 02:18:49,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:49,854 INFO:     Epoch: 82
2022-11-23 02:18:50,665 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8698962303725156, 'Total loss': 0.8698962303725156} | train loss {'Reaction outcome loss': 0.8060125548012402, 'Total loss': 0.8060125548012402}
2022-11-23 02:18:50,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:50,665 INFO:     Epoch: 83
2022-11-23 02:18:51,432 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.892186471007087, 'Total loss': 0.892186471007087} | train loss {'Reaction outcome loss': 0.8034813473419268, 'Total loss': 0.8034813473419268}
2022-11-23 02:18:51,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:51,432 INFO:     Epoch: 84
2022-11-23 02:18:52,259 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8691425160928206, 'Total loss': 0.8691425160928206} | train loss {'Reaction outcome loss': 0.8043718617789599, 'Total loss': 0.8043718617789599}
2022-11-23 02:18:52,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:52,259 INFO:     Epoch: 85
2022-11-23 02:18:53,015 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8536091609434648, 'Total loss': 0.8536091609434648} | train loss {'Reaction outcome loss': 0.8057040188993726, 'Total loss': 0.8057040188993726}
2022-11-23 02:18:53,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:53,015 INFO:     Epoch: 86
2022-11-23 02:18:53,791 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8599451929330826, 'Total loss': 0.8599451929330826} | train loss {'Reaction outcome loss': 0.8074642489151079, 'Total loss': 0.8074642489151079}
2022-11-23 02:18:53,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:53,792 INFO:     Epoch: 87
2022-11-23 02:18:54,594 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8628121489150957, 'Total loss': 0.8628121489150957} | train loss {'Reaction outcome loss': 0.8048017647801613, 'Total loss': 0.8048017647801613}
2022-11-23 02:18:54,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:54,594 INFO:     Epoch: 88
2022-11-23 02:18:55,438 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8878819373520938, 'Total loss': 0.8878819373520938} | train loss {'Reaction outcome loss': 0.8042786066629448, 'Total loss': 0.8042786066629448}
2022-11-23 02:18:55,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:55,439 INFO:     Epoch: 89
2022-11-23 02:18:56,300 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8852567462758585, 'Total loss': 0.8852567462758585} | train loss {'Reaction outcome loss': 0.8062604567226098, 'Total loss': 0.8062604567226098}
2022-11-23 02:18:56,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:56,301 INFO:     Epoch: 90
2022-11-23 02:18:57,111 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8924033425071023, 'Total loss': 0.8924033425071023} | train loss {'Reaction outcome loss': 0.8113808054096845, 'Total loss': 0.8113808054096845}
2022-11-23 02:18:57,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:57,112 INFO:     Epoch: 91
2022-11-23 02:18:57,871 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.85212023623965, 'Total loss': 0.85212023623965} | train loss {'Reaction outcome loss': 0.8043833017349243, 'Total loss': 0.8043833017349243}
2022-11-23 02:18:57,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:57,871 INFO:     Epoch: 92
2022-11-23 02:18:58,690 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8627704239704392, 'Total loss': 0.8627704239704392} | train loss {'Reaction outcome loss': 0.8035071032387869, 'Total loss': 0.8035071032387869}
2022-11-23 02:18:58,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:58,691 INFO:     Epoch: 93
2022-11-23 02:18:59,481 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8599044030362909, 'Total loss': 0.8599044030362909} | train loss {'Reaction outcome loss': 0.7999707321731412, 'Total loss': 0.7999707321731412}
2022-11-23 02:18:59,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:18:59,481 INFO:     Epoch: 94
2022-11-23 02:19:00,303 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8794471045786684, 'Total loss': 0.8794471045786684} | train loss {'Reaction outcome loss': 0.8081614159807867, 'Total loss': 0.8081614159807867}
2022-11-23 02:19:00,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:00,303 INFO:     Epoch: 95
2022-11-23 02:19:01,118 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8746817409992218, 'Total loss': 0.8746817409992218} | train loss {'Reaction outcome loss': 0.8029103283979455, 'Total loss': 0.8029103283979455}
2022-11-23 02:19:01,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:01,118 INFO:     Epoch: 96
2022-11-23 02:19:02,005 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8706536008553072, 'Total loss': 0.8706536008553072} | train loss {'Reaction outcome loss': 0.8065265636054837, 'Total loss': 0.8065265636054837}
2022-11-23 02:19:02,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:02,005 INFO:     Epoch: 97
2022-11-23 02:19:02,791 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8690065904097124, 'Total loss': 0.8690065904097124} | train loss {'Reaction outcome loss': 0.8083870884107084, 'Total loss': 0.8083870884107084}
2022-11-23 02:19:02,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:02,791 INFO:     Epoch: 98
2022-11-23 02:19:03,579 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8653651482679627, 'Total loss': 0.8653651482679627} | train loss {'Reaction outcome loss': 0.804256112234933, 'Total loss': 0.804256112234933}
2022-11-23 02:19:03,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:03,580 INFO:     Epoch: 99
2022-11-23 02:19:04,462 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8959497931328687, 'Total loss': 0.8959497931328687} | train loss {'Reaction outcome loss': 0.8014617438219032, 'Total loss': 0.8014617438219032}
2022-11-23 02:19:04,462 INFO:     Best model found after epoch 53 of 100.
2022-11-23 02:19:04,462 INFO:   Done with stage: TRAINING
2022-11-23 02:19:04,462 INFO:   Starting stage: EVALUATION
2022-11-23 02:19:04,593 INFO:   Done with stage: EVALUATION
2022-11-23 02:19:04,593 INFO:   Leaving out SEQ value Fold_4
2022-11-23 02:19:04,606 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:19:04,606 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:19:05,299 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:19:05,299 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:19:05,376 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:19:05,376 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:19:05,376 INFO:     No hyperparam tuning for this model
2022-11-23 02:19:05,376 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:19:05,376 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:19:05,377 INFO:     None feature selector for col prot
2022-11-23 02:19:05,377 INFO:     None feature selector for col prot
2022-11-23 02:19:05,377 INFO:     None feature selector for col prot
2022-11-23 02:19:05,378 INFO:     None feature selector for col chem
2022-11-23 02:19:05,378 INFO:     None feature selector for col chem
2022-11-23 02:19:05,378 INFO:     None feature selector for col chem
2022-11-23 02:19:05,378 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:19:05,378 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:19:05,380 INFO:     Number of params in model 168571
2022-11-23 02:19:05,383 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:19:05,383 INFO:   Starting stage: TRAINING
2022-11-23 02:19:05,444 INFO:     Val loss before train {'Reaction outcome loss': 1.0159817175431685, 'Total loss': 1.0159817175431685}
2022-11-23 02:19:05,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:05,444 INFO:     Epoch: 0
2022-11-23 02:19:06,265 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8645756149833853, 'Total loss': 0.8645756149833853} | train loss {'Reaction outcome loss': 0.8941663376265957, 'Total loss': 0.8941663376265957}
2022-11-23 02:19:06,265 INFO:     Found new best model at epoch 0
2022-11-23 02:19:06,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:06,266 INFO:     Epoch: 1
2022-11-23 02:19:07,093 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8770260363817215, 'Total loss': 0.8770260363817215} | train loss {'Reaction outcome loss': 0.8591011570345971, 'Total loss': 0.8591011570345971}
2022-11-23 02:19:07,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:07,093 INFO:     Epoch: 2
2022-11-23 02:19:07,890 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8381545970385725, 'Total loss': 0.8381545970385725} | train loss {'Reaction outcome loss': 0.8526752949241669, 'Total loss': 0.8526752949241669}
2022-11-23 02:19:07,890 INFO:     Found new best model at epoch 2
2022-11-23 02:19:07,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:07,891 INFO:     Epoch: 3
2022-11-23 02:19:08,671 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8393660390918906, 'Total loss': 0.8393660390918906} | train loss {'Reaction outcome loss': 0.8462929868650052, 'Total loss': 0.8462929868650052}
2022-11-23 02:19:08,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:08,672 INFO:     Epoch: 4
2022-11-23 02:19:09,498 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8328643231229349, 'Total loss': 0.8328643231229349} | train loss {'Reaction outcome loss': 0.8481609338233548, 'Total loss': 0.8481609338233548}
2022-11-23 02:19:09,498 INFO:     Found new best model at epoch 4
2022-11-23 02:19:09,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:09,499 INFO:     Epoch: 5
2022-11-23 02:19:10,373 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.838748312131925, 'Total loss': 0.838748312131925} | train loss {'Reaction outcome loss': 0.8408397044385633, 'Total loss': 0.8408397044385633}
2022-11-23 02:19:10,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:10,373 INFO:     Epoch: 6
2022-11-23 02:19:11,207 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8296583999286998, 'Total loss': 0.8296583999286998} | train loss {'Reaction outcome loss': 0.8375973470749394, 'Total loss': 0.8375973470749394}
2022-11-23 02:19:11,207 INFO:     Found new best model at epoch 6
2022-11-23 02:19:11,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:11,208 INFO:     Epoch: 7
2022-11-23 02:19:11,976 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8622586178508672, 'Total loss': 0.8622586178508672} | train loss {'Reaction outcome loss': 0.8342911531367609, 'Total loss': 0.8342911531367609}
2022-11-23 02:19:11,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:11,976 INFO:     Epoch: 8
2022-11-23 02:19:12,793 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8145257173614069, 'Total loss': 0.8145257173614069} | train loss {'Reaction outcome loss': 0.8379552927949736, 'Total loss': 0.8379552927949736}
2022-11-23 02:19:12,794 INFO:     Found new best model at epoch 8
2022-11-23 02:19:12,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:12,795 INFO:     Epoch: 9
2022-11-23 02:19:13,597 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8175364624370228, 'Total loss': 0.8175364624370228} | train loss {'Reaction outcome loss': 0.8317636717711726, 'Total loss': 0.8317636717711726}
2022-11-23 02:19:13,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:13,598 INFO:     Epoch: 10
2022-11-23 02:19:14,387 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.832764365456321, 'Total loss': 0.832764365456321} | train loss {'Reaction outcome loss': 0.8305241586940904, 'Total loss': 0.8305241586940904}
2022-11-23 02:19:14,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:14,388 INFO:     Epoch: 11
2022-11-23 02:19:15,211 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8454380611127074, 'Total loss': 0.8454380611127074} | train loss {'Reaction outcome loss': 0.8331204262231627, 'Total loss': 0.8331204262231627}
2022-11-23 02:19:15,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:15,211 INFO:     Epoch: 12
2022-11-23 02:19:16,025 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8182701231403784, 'Total loss': 0.8182701231403784} | train loss {'Reaction outcome loss': 0.8326415344471892, 'Total loss': 0.8326415344471892}
2022-11-23 02:19:16,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:16,025 INFO:     Epoch: 13
2022-11-23 02:19:16,836 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8308182277462699, 'Total loss': 0.8308182277462699} | train loss {'Reaction outcome loss': 0.8275393211553174, 'Total loss': 0.8275393211553174}
2022-11-23 02:19:16,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:16,836 INFO:     Epoch: 14
2022-11-23 02:19:17,686 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8351368375799872, 'Total loss': 0.8351368375799872} | train loss {'Reaction outcome loss': 0.8287748833817821, 'Total loss': 0.8287748833817821}
2022-11-23 02:19:17,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:17,686 INFO:     Epoch: 15
2022-11-23 02:19:18,523 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8202356113628908, 'Total loss': 0.8202356113628908} | train loss {'Reaction outcome loss': 0.8336862221119865, 'Total loss': 0.8336862221119865}
2022-11-23 02:19:18,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:18,523 INFO:     Epoch: 16
2022-11-23 02:19:19,372 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8329902467402545, 'Total loss': 0.8329902467402545} | train loss {'Reaction outcome loss': 0.8335054221172487, 'Total loss': 0.8335054221172487}
2022-11-23 02:19:19,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:19,372 INFO:     Epoch: 17
2022-11-23 02:19:20,186 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8456573669206012, 'Total loss': 0.8456573669206012} | train loss {'Reaction outcome loss': 0.8301161469951752, 'Total loss': 0.8301161469951752}
2022-11-23 02:19:20,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:20,186 INFO:     Epoch: 18
2022-11-23 02:19:21,046 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8259997367858887, 'Total loss': 0.8259997367858887} | train loss {'Reaction outcome loss': 0.8284359808650709, 'Total loss': 0.8284359808650709}
2022-11-23 02:19:21,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:21,047 INFO:     Epoch: 19
2022-11-23 02:19:21,845 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8692229904911735, 'Total loss': 0.8692229904911735} | train loss {'Reaction outcome loss': 0.8286314716021861, 'Total loss': 0.8286314716021861}
2022-11-23 02:19:21,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:21,845 INFO:     Epoch: 20
2022-11-23 02:19:22,639 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8178777938539331, 'Total loss': 0.8178777938539331} | train loss {'Reaction outcome loss': 0.8309400035969673, 'Total loss': 0.8309400035969673}
2022-11-23 02:19:22,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:22,640 INFO:     Epoch: 21
2022-11-23 02:19:23,428 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8266650180925023, 'Total loss': 0.8266650180925023} | train loss {'Reaction outcome loss': 0.824891478664452, 'Total loss': 0.824891478664452}
2022-11-23 02:19:23,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:23,429 INFO:     Epoch: 22
2022-11-23 02:19:24,241 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.835666451941837, 'Total loss': 0.835666451941837} | train loss {'Reaction outcome loss': 0.8287155909403678, 'Total loss': 0.8287155909403678}
2022-11-23 02:19:24,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:24,242 INFO:     Epoch: 23
2022-11-23 02:19:25,097 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8112780749797821, 'Total loss': 0.8112780749797821} | train loss {'Reaction outcome loss': 0.827372137216791, 'Total loss': 0.827372137216791}
2022-11-23 02:19:25,097 INFO:     Found new best model at epoch 23
2022-11-23 02:19:25,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:25,098 INFO:     Epoch: 24
2022-11-23 02:19:25,919 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8201973235065286, 'Total loss': 0.8201973235065286} | train loss {'Reaction outcome loss': 0.8227156506430718, 'Total loss': 0.8227156506430718}
2022-11-23 02:19:25,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:25,919 INFO:     Epoch: 25
2022-11-23 02:19:26,755 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8217301124876196, 'Total loss': 0.8217301124876196} | train loss {'Reaction outcome loss': 0.8242037132863076, 'Total loss': 0.8242037132863076}
2022-11-23 02:19:26,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:26,755 INFO:     Epoch: 26
2022-11-23 02:19:27,608 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8207122764804147, 'Total loss': 0.8207122764804147} | train loss {'Reaction outcome loss': 0.8302807181833252, 'Total loss': 0.8302807181833252}
2022-11-23 02:19:27,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:27,609 INFO:     Epoch: 27
2022-11-23 02:19:28,492 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8271898857571862, 'Total loss': 0.8271898857571862} | train loss {'Reaction outcome loss': 0.8295126528509201, 'Total loss': 0.8295126528509201}
2022-11-23 02:19:28,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:28,493 INFO:     Epoch: 28
2022-11-23 02:19:29,328 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8252605944871902, 'Total loss': 0.8252605944871902} | train loss {'Reaction outcome loss': 0.8255961047064874, 'Total loss': 0.8255961047064874}
2022-11-23 02:19:29,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:29,328 INFO:     Epoch: 29
2022-11-23 02:19:30,157 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8254653377966448, 'Total loss': 0.8254653377966448} | train loss {'Reaction outcome loss': 0.8286547838680206, 'Total loss': 0.8286547838680206}
2022-11-23 02:19:30,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:30,158 INFO:     Epoch: 30
2022-11-23 02:19:31,002 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8294700180942362, 'Total loss': 0.8294700180942362} | train loss {'Reaction outcome loss': 0.8255153508676637, 'Total loss': 0.8255153508676637}
2022-11-23 02:19:31,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:31,003 INFO:     Epoch: 31
2022-11-23 02:19:31,803 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.818737618625164, 'Total loss': 0.818737618625164} | train loss {'Reaction outcome loss': 0.8301168352125152, 'Total loss': 0.8301168352125152}
2022-11-23 02:19:31,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:31,804 INFO:     Epoch: 32
2022-11-23 02:19:32,634 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8180628777904944, 'Total loss': 0.8180628777904944} | train loss {'Reaction outcome loss': 0.828500147908926, 'Total loss': 0.828500147908926}
2022-11-23 02:19:32,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:32,635 INFO:     Epoch: 33
2022-11-23 02:19:33,455 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8241152126680721, 'Total loss': 0.8241152126680721} | train loss {'Reaction outcome loss': 0.8248917545762754, 'Total loss': 0.8248917545762754}
2022-11-23 02:19:33,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:33,456 INFO:     Epoch: 34
2022-11-23 02:19:34,253 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8355832878838886, 'Total loss': 0.8355832878838886} | train loss {'Reaction outcome loss': 0.8255542127355453, 'Total loss': 0.8255542127355453}
2022-11-23 02:19:34,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:34,253 INFO:     Epoch: 35
2022-11-23 02:19:35,053 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8186000341718848, 'Total loss': 0.8186000341718848} | train loss {'Reaction outcome loss': 0.8275190451212467, 'Total loss': 0.8275190451212467}
2022-11-23 02:19:35,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:35,053 INFO:     Epoch: 36
2022-11-23 02:19:35,854 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8163771134885874, 'Total loss': 0.8163771134885874} | train loss {'Reaction outcome loss': 0.8245620999124742, 'Total loss': 0.8245620999124742}
2022-11-23 02:19:35,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:35,855 INFO:     Epoch: 37
2022-11-23 02:19:36,711 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8309310877865012, 'Total loss': 0.8309310877865012} | train loss {'Reaction outcome loss': 0.8266161213959416, 'Total loss': 0.8266161213959416}
2022-11-23 02:19:36,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:36,712 INFO:     Epoch: 38
2022-11-23 02:19:37,516 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.858091147785837, 'Total loss': 0.858091147785837} | train loss {'Reaction outcome loss': 0.8243936266629927, 'Total loss': 0.8243936266629927}
2022-11-23 02:19:37,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:37,516 INFO:     Epoch: 39
2022-11-23 02:19:38,317 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8177990181879564, 'Total loss': 0.8177990181879564} | train loss {'Reaction outcome loss': 0.8324820494219181, 'Total loss': 0.8324820494219181}
2022-11-23 02:19:38,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:38,317 INFO:     Epoch: 40
2022-11-23 02:19:39,150 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8229617943817918, 'Total loss': 0.8229617943817918} | train loss {'Reaction outcome loss': 0.8252503093211881, 'Total loss': 0.8252503093211881}
2022-11-23 02:19:39,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:39,151 INFO:     Epoch: 41
2022-11-23 02:19:39,937 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8388640867038206, 'Total loss': 0.8388640867038206} | train loss {'Reaction outcome loss': 0.8252984766037234, 'Total loss': 0.8252984766037234}
2022-11-23 02:19:39,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:39,938 INFO:     Epoch: 42
2022-11-23 02:19:40,718 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.80983531949195, 'Total loss': 0.80983531949195} | train loss {'Reaction outcome loss': 0.8254683334981242, 'Total loss': 0.8254683334981242}
2022-11-23 02:19:40,719 INFO:     Found new best model at epoch 42
2022-11-23 02:19:40,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:40,719 INFO:     Epoch: 43
2022-11-23 02:19:41,472 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8312597518617456, 'Total loss': 0.8312597518617456} | train loss {'Reaction outcome loss': 0.8233016027558234, 'Total loss': 0.8233016027558234}
2022-11-23 02:19:41,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:41,473 INFO:     Epoch: 44
2022-11-23 02:19:42,281 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8070629015564919, 'Total loss': 0.8070629015564919} | train loss {'Reaction outcome loss': 0.8299089844428724, 'Total loss': 0.8299089844428724}
2022-11-23 02:19:42,281 INFO:     Found new best model at epoch 44
2022-11-23 02:19:42,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:42,282 INFO:     Epoch: 45
2022-11-23 02:19:43,096 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8362821015444669, 'Total loss': 0.8362821015444669} | train loss {'Reaction outcome loss': 0.8245640543680037, 'Total loss': 0.8245640543680037}
2022-11-23 02:19:43,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:43,097 INFO:     Epoch: 46
2022-11-23 02:19:43,905 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8209814564748243, 'Total loss': 0.8209814564748243} | train loss {'Reaction outcome loss': 0.8262488998232349, 'Total loss': 0.8262488998232349}
2022-11-23 02:19:43,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:43,905 INFO:     Epoch: 47
2022-11-23 02:19:44,750 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8053939857266166, 'Total loss': 0.8053939857266166} | train loss {'Reaction outcome loss': 0.8208774337845464, 'Total loss': 0.8208774337845464}
2022-11-23 02:19:44,750 INFO:     Found new best model at epoch 47
2022-11-23 02:19:44,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:44,751 INFO:     Epoch: 48
2022-11-23 02:19:45,561 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8833875398744236, 'Total loss': 0.8833875398744236} | train loss {'Reaction outcome loss': 0.8266635021615413, 'Total loss': 0.8266635021615413}
2022-11-23 02:19:45,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:45,561 INFO:     Epoch: 49
2022-11-23 02:19:46,347 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8285152085802772, 'Total loss': 0.8285152085802772} | train loss {'Reaction outcome loss': 0.8228308000872212, 'Total loss': 0.8228308000872212}
2022-11-23 02:19:46,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:46,347 INFO:     Epoch: 50
2022-11-23 02:19:47,185 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8293865451758559, 'Total loss': 0.8293865451758559} | train loss {'Reaction outcome loss': 0.831360217484255, 'Total loss': 0.831360217484255}
2022-11-23 02:19:47,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:47,185 INFO:     Epoch: 51
2022-11-23 02:19:48,028 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8391213295134631, 'Total loss': 0.8391213295134631} | train loss {'Reaction outcome loss': 0.8208944775885151, 'Total loss': 0.8208944775885151}
2022-11-23 02:19:48,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:48,028 INFO:     Epoch: 52
2022-11-23 02:19:48,845 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8070215379649942, 'Total loss': 0.8070215379649942} | train loss {'Reaction outcome loss': 0.8272001700055215, 'Total loss': 0.8272001700055215}
2022-11-23 02:19:48,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:48,845 INFO:     Epoch: 53
2022-11-23 02:19:49,675 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8136548054489222, 'Total loss': 0.8136548054489222} | train loss {'Reaction outcome loss': 0.8200221101362859, 'Total loss': 0.8200221101362859}
2022-11-23 02:19:49,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:49,675 INFO:     Epoch: 54
2022-11-23 02:19:50,499 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8202130564234473, 'Total loss': 0.8202130564234473} | train loss {'Reaction outcome loss': 0.8282819961107546, 'Total loss': 0.8282819961107546}
2022-11-23 02:19:50,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:50,499 INFO:     Epoch: 55
2022-11-23 02:19:51,324 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8309149173173037, 'Total loss': 0.8309149173173037} | train loss {'Reaction outcome loss': 0.8200467936694622, 'Total loss': 0.8200467936694622}
2022-11-23 02:19:51,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:51,324 INFO:     Epoch: 56
2022-11-23 02:19:52,146 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.79870500957424, 'Total loss': 0.79870500957424} | train loss {'Reaction outcome loss': 0.8280215119161913, 'Total loss': 0.8280215119161913}
2022-11-23 02:19:52,148 INFO:     Found new best model at epoch 56
2022-11-23 02:19:52,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:52,149 INFO:     Epoch: 57
2022-11-23 02:19:52,971 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8250138055194508, 'Total loss': 0.8250138055194508} | train loss {'Reaction outcome loss': 0.8194602839648724, 'Total loss': 0.8194602839648724}
2022-11-23 02:19:52,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:52,972 INFO:     Epoch: 58
2022-11-23 02:19:53,808 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8046477728269317, 'Total loss': 0.8046477728269317} | train loss {'Reaction outcome loss': 0.8201016181659314, 'Total loss': 0.8201016181659314}
2022-11-23 02:19:53,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:53,809 INFO:     Epoch: 59
2022-11-23 02:19:54,598 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8418011577291922, 'Total loss': 0.8418011577291922} | train loss {'Reaction outcome loss': 0.8272632142949489, 'Total loss': 0.8272632142949489}
2022-11-23 02:19:54,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:54,598 INFO:     Epoch: 60
2022-11-23 02:19:55,415 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8064877986907959, 'Total loss': 0.8064877986907959} | train loss {'Reaction outcome loss': 0.8227306257092184, 'Total loss': 0.8227306257092184}
2022-11-23 02:19:55,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:55,415 INFO:     Epoch: 61
2022-11-23 02:19:56,310 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8186545737765052, 'Total loss': 0.8186545737765052} | train loss {'Reaction outcome loss': 0.8223058671480225, 'Total loss': 0.8223058671480225}
2022-11-23 02:19:56,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:56,310 INFO:     Epoch: 62
2022-11-23 02:19:57,152 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8164583193984899, 'Total loss': 0.8164583193984899} | train loss {'Reaction outcome loss': 0.8220127691184321, 'Total loss': 0.8220127691184321}
2022-11-23 02:19:57,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:57,153 INFO:     Epoch: 63
2022-11-23 02:19:58,011 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8156956908377734, 'Total loss': 0.8156956908377734} | train loss {'Reaction outcome loss': 0.8220854184079555, 'Total loss': 0.8220854184079555}
2022-11-23 02:19:58,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:58,012 INFO:     Epoch: 64
2022-11-23 02:19:58,860 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8125062706795606, 'Total loss': 0.8125062706795606} | train loss {'Reaction outcome loss': 0.8222951099516884, 'Total loss': 0.8222951099516884}
2022-11-23 02:19:58,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:58,861 INFO:     Epoch: 65
2022-11-23 02:19:59,693 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8130120011893186, 'Total loss': 0.8130120011893186} | train loss {'Reaction outcome loss': 0.8180780648704498, 'Total loss': 0.8180780648704498}
2022-11-23 02:19:59,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:19:59,693 INFO:     Epoch: 66
2022-11-23 02:20:00,559 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8116557435555891, 'Total loss': 0.8116557435555891} | train loss {'Reaction outcome loss': 0.823679531533872, 'Total loss': 0.823679531533872}
2022-11-23 02:20:00,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:00,560 INFO:     Epoch: 67
2022-11-23 02:20:01,393 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.82896788418293, 'Total loss': 0.82896788418293} | train loss {'Reaction outcome loss': 0.825146165586287, 'Total loss': 0.825146165586287}
2022-11-23 02:20:01,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:01,393 INFO:     Epoch: 68
2022-11-23 02:20:02,197 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8193858469074423, 'Total loss': 0.8193858469074423} | train loss {'Reaction outcome loss': 0.8206901713725059, 'Total loss': 0.8206901713725059}
2022-11-23 02:20:02,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:02,197 INFO:     Epoch: 69
2022-11-23 02:20:03,055 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8130240711298856, 'Total loss': 0.8130240711298856} | train loss {'Reaction outcome loss': 0.8302650174065944, 'Total loss': 0.8302650174065944}
2022-11-23 02:20:03,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:03,056 INFO:     Epoch: 70
2022-11-23 02:20:03,861 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8078454360365868, 'Total loss': 0.8078454360365868} | train loss {'Reaction outcome loss': 0.8197979183206635, 'Total loss': 0.8197979183206635}
2022-11-23 02:20:03,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:03,862 INFO:     Epoch: 71
2022-11-23 02:20:04,700 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8462453579360788, 'Total loss': 0.8462453579360788} | train loss {'Reaction outcome loss': 0.8215154272414023, 'Total loss': 0.8215154272414023}
2022-11-23 02:20:04,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:04,700 INFO:     Epoch: 72
2022-11-23 02:20:05,511 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8365152843973853, 'Total loss': 0.8365152843973853} | train loss {'Reaction outcome loss': 0.8194922404664178, 'Total loss': 0.8194922404664178}
2022-11-23 02:20:05,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:05,511 INFO:     Epoch: 73
2022-11-23 02:20:06,368 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8184502626007254, 'Total loss': 0.8184502626007254} | train loss {'Reaction outcome loss': 0.8250246403678771, 'Total loss': 0.8250246403678771}
2022-11-23 02:20:06,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:06,368 INFO:     Epoch: 74
2022-11-23 02:20:07,213 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8681170520457354, 'Total loss': 0.8681170520457354} | train loss {'Reaction outcome loss': 0.8236348574921009, 'Total loss': 0.8236348574921009}
2022-11-23 02:20:07,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:07,213 INFO:     Epoch: 75
2022-11-23 02:20:08,141 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8098445033485239, 'Total loss': 0.8098445033485239} | train loss {'Reaction outcome loss': 0.8250730698627811, 'Total loss': 0.8250730698627811}
2022-11-23 02:20:08,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:08,141 INFO:     Epoch: 76
2022-11-23 02:20:08,923 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.810174054720185, 'Total loss': 0.810174054720185} | train loss {'Reaction outcome loss': 0.8285909863489289, 'Total loss': 0.8285909863489289}
2022-11-23 02:20:08,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:08,924 INFO:     Epoch: 77
2022-11-23 02:20:09,849 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.817813478410244, 'Total loss': 0.817813478410244} | train loss {'Reaction outcome loss': 0.8232663932346529, 'Total loss': 0.8232663932346529}
2022-11-23 02:20:09,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:09,849 INFO:     Epoch: 78
2022-11-23 02:20:10,694 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.813768748532642, 'Total loss': 0.813768748532642} | train loss {'Reaction outcome loss': 0.8223699410596201, 'Total loss': 0.8223699410596201}
2022-11-23 02:20:10,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:10,694 INFO:     Epoch: 79
2022-11-23 02:20:11,553 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.812897418032993, 'Total loss': 0.812897418032993} | train loss {'Reaction outcome loss': 0.8223195890745809, 'Total loss': 0.8223195890745809}
2022-11-23 02:20:11,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:11,554 INFO:     Epoch: 80
2022-11-23 02:20:12,412 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8125608902085911, 'Total loss': 0.8125608902085911} | train loss {'Reaction outcome loss': 0.826336516848495, 'Total loss': 0.826336516848495}
2022-11-23 02:20:12,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:12,412 INFO:     Epoch: 81
2022-11-23 02:20:13,239 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8180774220011451, 'Total loss': 0.8180774220011451} | train loss {'Reaction outcome loss': 0.8247639077805704, 'Total loss': 0.8247639077805704}
2022-11-23 02:20:13,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:13,240 INFO:     Epoch: 82
2022-11-23 02:20:14,019 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8288635178045793, 'Total loss': 0.8288635178045793} | train loss {'Reaction outcome loss': 0.8238333171654132, 'Total loss': 0.8238333171654132}
2022-11-23 02:20:14,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:14,019 INFO:     Epoch: 83
2022-11-23 02:20:14,782 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8223382722247731, 'Total loss': 0.8223382722247731} | train loss {'Reaction outcome loss': 0.8242682394000792, 'Total loss': 0.8242682394000792}
2022-11-23 02:20:14,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:14,782 INFO:     Epoch: 84
2022-11-23 02:20:15,574 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8141901459206234, 'Total loss': 0.8141901459206234} | train loss {'Reaction outcome loss': 0.8258056385863212, 'Total loss': 0.8258056385863212}
2022-11-23 02:20:15,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:15,574 INFO:     Epoch: 85
2022-11-23 02:20:16,398 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8229571621526371, 'Total loss': 0.8229571621526371} | train loss {'Reaction outcome loss': 0.8212603125120362, 'Total loss': 0.8212603125120362}
2022-11-23 02:20:16,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:16,398 INFO:     Epoch: 86
2022-11-23 02:20:17,176 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8124678791923956, 'Total loss': 0.8124678791923956} | train loss {'Reaction outcome loss': 0.8170512217667795, 'Total loss': 0.8170512217667795}
2022-11-23 02:20:17,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:17,176 INFO:     Epoch: 87
2022-11-23 02:20:17,949 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8156145336953077, 'Total loss': 0.8156145336953077} | train loss {'Reaction outcome loss': 0.8259836237036413, 'Total loss': 0.8259836237036413}
2022-11-23 02:20:17,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:17,949 INFO:     Epoch: 88
2022-11-23 02:20:18,743 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8312229338017377, 'Total loss': 0.8312229338017377} | train loss {'Reaction outcome loss': 0.8210507473878322, 'Total loss': 0.8210507473878322}
2022-11-23 02:20:18,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:18,743 INFO:     Epoch: 89
2022-11-23 02:20:19,507 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8075803802772001, 'Total loss': 0.8075803802772001} | train loss {'Reaction outcome loss': 0.8229721954032299, 'Total loss': 0.8229721954032299}
2022-11-23 02:20:19,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:19,507 INFO:     Epoch: 90
2022-11-23 02:20:20,327 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.831419589844617, 'Total loss': 0.831419589844617} | train loss {'Reaction outcome loss': 0.8238230851148406, 'Total loss': 0.8238230851148406}
2022-11-23 02:20:20,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:20,328 INFO:     Epoch: 91
2022-11-23 02:20:21,156 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8088346807794138, 'Total loss': 0.8088346807794138} | train loss {'Reaction outcome loss': 0.8232430920245186, 'Total loss': 0.8232430920245186}
2022-11-23 02:20:21,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:21,156 INFO:     Epoch: 92
2022-11-23 02:20:21,972 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8288157108155164, 'Total loss': 0.8288157108155164} | train loss {'Reaction outcome loss': 0.8178773693019344, 'Total loss': 0.8178773693019344}
2022-11-23 02:20:21,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:21,973 INFO:     Epoch: 93
2022-11-23 02:20:22,808 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8289622217416763, 'Total loss': 0.8289622217416763} | train loss {'Reaction outcome loss': 0.817819852261774, 'Total loss': 0.817819852261774}
2022-11-23 02:20:22,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:22,809 INFO:     Epoch: 94
2022-11-23 02:20:23,660 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8095119412649762, 'Total loss': 0.8095119412649762} | train loss {'Reaction outcome loss': 0.819118530519547, 'Total loss': 0.819118530519547}
2022-11-23 02:20:23,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:23,661 INFO:     Epoch: 95
2022-11-23 02:20:24,477 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8212983418594707, 'Total loss': 0.8212983418594707} | train loss {'Reaction outcome loss': 0.8176482858196381, 'Total loss': 0.8176482858196381}
2022-11-23 02:20:24,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:24,477 INFO:     Epoch: 96
2022-11-23 02:20:25,328 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8059571642767299, 'Total loss': 0.8059571642767299} | train loss {'Reaction outcome loss': 0.8244251652110007, 'Total loss': 0.8244251652110007}
2022-11-23 02:20:25,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:25,328 INFO:     Epoch: 97
2022-11-23 02:20:26,138 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8162740821188147, 'Total loss': 0.8162740821188147} | train loss {'Reaction outcome loss': 0.8255361406312834, 'Total loss': 0.8255361406312834}
2022-11-23 02:20:26,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:26,138 INFO:     Epoch: 98
2022-11-23 02:20:26,993 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8147728253494609, 'Total loss': 0.8147728253494609} | train loss {'Reaction outcome loss': 0.8176713030665151, 'Total loss': 0.8176713030665151}
2022-11-23 02:20:26,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:26,994 INFO:     Epoch: 99
2022-11-23 02:20:27,815 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8089116872711615, 'Total loss': 0.8089116872711615} | train loss {'Reaction outcome loss': 0.8192162267383067, 'Total loss': 0.8192162267383067}
2022-11-23 02:20:27,815 INFO:     Best model found after epoch 57 of 100.
2022-11-23 02:20:27,815 INFO:   Done with stage: TRAINING
2022-11-23 02:20:27,815 INFO:   Starting stage: EVALUATION
2022-11-23 02:20:27,934 INFO:   Done with stage: EVALUATION
2022-11-23 02:20:27,934 INFO:   Leaving out SEQ value Fold_5
2022-11-23 02:20:27,947 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:20:27,947 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:20:28,619 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:20:28,619 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:20:28,692 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:20:28,692 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:20:28,692 INFO:     No hyperparam tuning for this model
2022-11-23 02:20:28,692 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:20:28,692 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:20:28,693 INFO:     None feature selector for col prot
2022-11-23 02:20:28,693 INFO:     None feature selector for col prot
2022-11-23 02:20:28,693 INFO:     None feature selector for col prot
2022-11-23 02:20:28,694 INFO:     None feature selector for col chem
2022-11-23 02:20:28,694 INFO:     None feature selector for col chem
2022-11-23 02:20:28,694 INFO:     None feature selector for col chem
2022-11-23 02:20:28,694 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:20:28,694 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:20:28,696 INFO:     Number of params in model 168571
2022-11-23 02:20:28,699 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:20:28,699 INFO:   Starting stage: TRAINING
2022-11-23 02:20:28,757 INFO:     Val loss before train {'Reaction outcome loss': 0.9216356074268167, 'Total loss': 0.9216356074268167}
2022-11-23 02:20:28,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:28,758 INFO:     Epoch: 0
2022-11-23 02:20:29,606 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7573053545572541, 'Total loss': 0.7573053545572541} | train loss {'Reaction outcome loss': 0.8821401528773769, 'Total loss': 0.8821401528773769}
2022-11-23 02:20:29,607 INFO:     Found new best model at epoch 0
2022-11-23 02:20:29,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:29,608 INFO:     Epoch: 1
2022-11-23 02:20:30,432 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7664088850671594, 'Total loss': 0.7664088850671594} | train loss {'Reaction outcome loss': 0.8475677095834286, 'Total loss': 0.8475677095834286}
2022-11-23 02:20:30,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:30,432 INFO:     Epoch: 2
2022-11-23 02:20:31,249 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7764576924118128, 'Total loss': 0.7764576924118128} | train loss {'Reaction outcome loss': 0.8432788798405279, 'Total loss': 0.8432788798405279}
2022-11-23 02:20:31,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:31,249 INFO:     Epoch: 3
2022-11-23 02:20:32,104 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7423639080741189, 'Total loss': 0.7423639080741189} | train loss {'Reaction outcome loss': 0.8424767142822666, 'Total loss': 0.8424767142822666}
2022-11-23 02:20:32,104 INFO:     Found new best model at epoch 3
2022-11-23 02:20:32,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:32,105 INFO:     Epoch: 4
2022-11-23 02:20:32,932 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7825951122424819, 'Total loss': 0.7825951122424819} | train loss {'Reaction outcome loss': 0.837620772781872, 'Total loss': 0.837620772781872}
2022-11-23 02:20:32,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:32,932 INFO:     Epoch: 5
2022-11-23 02:20:33,745 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7503698901696638, 'Total loss': 0.7503698901696638} | train loss {'Reaction outcome loss': 0.8282727172538158, 'Total loss': 0.8282727172538158}
2022-11-23 02:20:33,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:33,745 INFO:     Epoch: 6
2022-11-23 02:20:34,569 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7447445324876092, 'Total loss': 0.7447445324876092} | train loss {'Reaction outcome loss': 0.8302208045797963, 'Total loss': 0.8302208045797963}
2022-11-23 02:20:34,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:34,569 INFO:     Epoch: 7
2022-11-23 02:20:35,405 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7598169283433394, 'Total loss': 0.7598169283433394} | train loss {'Reaction outcome loss': 0.8241968353188807, 'Total loss': 0.8241968353188807}
2022-11-23 02:20:35,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:35,405 INFO:     Epoch: 8
2022-11-23 02:20:36,194 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7278233902020887, 'Total loss': 0.7278233902020887} | train loss {'Reaction outcome loss': 0.8255431101687493, 'Total loss': 0.8255431101687493}
2022-11-23 02:20:36,194 INFO:     Found new best model at epoch 8
2022-11-23 02:20:36,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:36,195 INFO:     Epoch: 9
2022-11-23 02:20:37,029 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7609802315180952, 'Total loss': 0.7609802315180952} | train loss {'Reaction outcome loss': 0.8270941057032154, 'Total loss': 0.8270941057032154}
2022-11-23 02:20:37,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:37,029 INFO:     Epoch: 10
2022-11-23 02:20:37,874 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7362764965404164, 'Total loss': 0.7362764965404164} | train loss {'Reaction outcome loss': 0.820845804147182, 'Total loss': 0.820845804147182}
2022-11-23 02:20:37,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:37,874 INFO:     Epoch: 11
2022-11-23 02:20:38,727 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7289192961020903, 'Total loss': 0.7289192961020903} | train loss {'Reaction outcome loss': 0.8197738302330817, 'Total loss': 0.8197738302330817}
2022-11-23 02:20:38,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:38,728 INFO:     Epoch: 12
2022-11-23 02:20:39,545 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7480864328416911, 'Total loss': 0.7480864328416911} | train loss {'Reaction outcome loss': 0.8159228905795082, 'Total loss': 0.8159228905795082}
2022-11-23 02:20:39,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:39,545 INFO:     Epoch: 13
2022-11-23 02:20:40,373 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7462220280007883, 'Total loss': 0.7462220280007883} | train loss {'Reaction outcome loss': 0.8218510146102598, 'Total loss': 0.8218510146102598}
2022-11-23 02:20:40,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:40,373 INFO:     Epoch: 14
2022-11-23 02:20:41,156 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7311134040355682, 'Total loss': 0.7311134040355682} | train loss {'Reaction outcome loss': 0.8187992983768063, 'Total loss': 0.8187992983768063}
2022-11-23 02:20:41,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:41,156 INFO:     Epoch: 15
2022-11-23 02:20:42,007 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7534817565571178, 'Total loss': 0.7534817565571178} | train loss {'Reaction outcome loss': 0.8176091326580893, 'Total loss': 0.8176091326580893}
2022-11-23 02:20:42,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:42,009 INFO:     Epoch: 16
2022-11-23 02:20:42,863 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7485824457623742, 'Total loss': 0.7485824457623742} | train loss {'Reaction outcome loss': 0.8202452672825705, 'Total loss': 0.8202452672825705}
2022-11-23 02:20:42,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:42,863 INFO:     Epoch: 17
2022-11-23 02:20:43,684 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7257260016419671, 'Total loss': 0.7257260016419671} | train loss {'Reaction outcome loss': 0.8218212173350395, 'Total loss': 0.8218212173350395}
2022-11-23 02:20:43,685 INFO:     Found new best model at epoch 17
2022-11-23 02:20:43,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:43,686 INFO:     Epoch: 18
2022-11-23 02:20:44,517 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7260567010803656, 'Total loss': 0.7260567010803656} | train loss {'Reaction outcome loss': 0.8161071742013577, 'Total loss': 0.8161071742013577}
2022-11-23 02:20:44,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:44,517 INFO:     Epoch: 19
2022-11-23 02:20:45,313 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7336146655407819, 'Total loss': 0.7336146655407819} | train loss {'Reaction outcome loss': 0.8125797969198996, 'Total loss': 0.8125797969198996}
2022-11-23 02:20:45,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:45,314 INFO:     Epoch: 20
2022-11-23 02:20:46,117 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7206872071732174, 'Total loss': 0.7206872071732174} | train loss {'Reaction outcome loss': 0.8185605386332158, 'Total loss': 0.8185605386332158}
2022-11-23 02:20:46,117 INFO:     Found new best model at epoch 20
2022-11-23 02:20:46,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:46,119 INFO:     Epoch: 21
2022-11-23 02:20:46,936 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.736423297361894, 'Total loss': 0.736423297361894} | train loss {'Reaction outcome loss': 0.8159060425335362, 'Total loss': 0.8159060425335362}
2022-11-23 02:20:46,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:46,937 INFO:     Epoch: 22
2022-11-23 02:20:47,773 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7195555384863507, 'Total loss': 0.7195555384863507} | train loss {'Reaction outcome loss': 0.813963774711855, 'Total loss': 0.813963774711855}
2022-11-23 02:20:47,773 INFO:     Found new best model at epoch 22
2022-11-23 02:20:47,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:47,774 INFO:     Epoch: 23
2022-11-23 02:20:48,616 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7418890832500025, 'Total loss': 0.7418890832500025} | train loss {'Reaction outcome loss': 0.8142183043303028, 'Total loss': 0.8142183043303028}
2022-11-23 02:20:48,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:48,616 INFO:     Epoch: 24
2022-11-23 02:20:49,416 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7401560829444365, 'Total loss': 0.7401560829444365} | train loss {'Reaction outcome loss': 0.8127229691993806, 'Total loss': 0.8127229691993806}
2022-11-23 02:20:49,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:49,417 INFO:     Epoch: 25
2022-11-23 02:20:50,270 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7253745448860255, 'Total loss': 0.7253745448860255} | train loss {'Reaction outcome loss': 0.8093011148514286, 'Total loss': 0.8093011148514286}
2022-11-23 02:20:50,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:50,271 INFO:     Epoch: 26
2022-11-23 02:20:51,052 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7487484819509767, 'Total loss': 0.7487484819509767} | train loss {'Reaction outcome loss': 0.813379978941333, 'Total loss': 0.813379978941333}
2022-11-23 02:20:51,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:51,053 INFO:     Epoch: 27
2022-11-23 02:20:51,881 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.738600998439572, 'Total loss': 0.738600998439572} | train loss {'Reaction outcome loss': 0.8162788188745899, 'Total loss': 0.8162788188745899}
2022-11-23 02:20:51,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:51,881 INFO:     Epoch: 28
2022-11-23 02:20:52,679 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7346570844000037, 'Total loss': 0.7346570844000037} | train loss {'Reaction outcome loss': 0.8144780539216534, 'Total loss': 0.8144780539216534}
2022-11-23 02:20:52,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:52,679 INFO:     Epoch: 29
2022-11-23 02:20:53,480 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7432482208717953, 'Total loss': 0.7432482208717953} | train loss {'Reaction outcome loss': 0.8133791102276694, 'Total loss': 0.8133791102276694}
2022-11-23 02:20:53,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:53,480 INFO:     Epoch: 30
2022-11-23 02:20:54,232 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7578777149319649, 'Total loss': 0.7578777149319649} | train loss {'Reaction outcome loss': 0.8115044428456214, 'Total loss': 0.8115044428456214}
2022-11-23 02:20:54,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:54,233 INFO:     Epoch: 31
2022-11-23 02:20:55,062 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7187899161468853, 'Total loss': 0.7187899161468853} | train loss {'Reaction outcome loss': 0.8103448162155766, 'Total loss': 0.8103448162155766}
2022-11-23 02:20:55,062 INFO:     Found new best model at epoch 31
2022-11-23 02:20:55,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:55,063 INFO:     Epoch: 32
2022-11-23 02:20:55,888 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7233668775721029, 'Total loss': 0.7233668775721029} | train loss {'Reaction outcome loss': 0.8091463588418499, 'Total loss': 0.8091463588418499}
2022-11-23 02:20:55,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:55,888 INFO:     Epoch: 33
2022-11-23 02:20:56,701 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7212283719669689, 'Total loss': 0.7212283719669689} | train loss {'Reaction outcome loss': 0.8174615658579334, 'Total loss': 0.8174615658579334}
2022-11-23 02:20:56,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:56,701 INFO:     Epoch: 34
2022-11-23 02:20:57,525 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7354030988433145, 'Total loss': 0.7354030988433145} | train loss {'Reaction outcome loss': 0.8131072611337707, 'Total loss': 0.8131072611337707}
2022-11-23 02:20:57,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:57,525 INFO:     Epoch: 35
2022-11-23 02:20:58,356 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7754645916548643, 'Total loss': 0.7754645916548643} | train loss {'Reaction outcome loss': 0.8088134544030312, 'Total loss': 0.8088134544030312}
2022-11-23 02:20:58,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:58,356 INFO:     Epoch: 36
2022-11-23 02:20:59,217 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7279501164501364, 'Total loss': 0.7279501164501364} | train loss {'Reaction outcome loss': 0.812019039786631, 'Total loss': 0.812019039786631}
2022-11-23 02:20:59,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:20:59,217 INFO:     Epoch: 37
2022-11-23 02:21:00,058 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7390499609437856, 'Total loss': 0.7390499609437856} | train loss {'Reaction outcome loss': 0.8118590139934132, 'Total loss': 0.8118590139934132}
2022-11-23 02:21:00,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:00,059 INFO:     Epoch: 38
2022-11-23 02:21:00,901 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7646567984060808, 'Total loss': 0.7646567984060808} | train loss {'Reaction outcome loss': 0.8124909287979526, 'Total loss': 0.8124909287979526}
2022-11-23 02:21:00,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:00,902 INFO:     Epoch: 39
2022-11-23 02:21:01,795 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.741717397489331, 'Total loss': 0.741717397489331} | train loss {'Reaction outcome loss': 0.8184537178566379, 'Total loss': 0.8184537178566379}
2022-11-23 02:21:01,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:01,795 INFO:     Epoch: 40
2022-11-23 02:21:02,744 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7298343621871688, 'Total loss': 0.7298343621871688} | train loss {'Reaction outcome loss': 0.8134611355921915, 'Total loss': 0.8134611355921915}
2022-11-23 02:21:02,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:02,744 INFO:     Epoch: 41
2022-11-23 02:21:03,676 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7542875429446046, 'Total loss': 0.7542875429446046} | train loss {'Reaction outcome loss': 0.8142781026901738, 'Total loss': 0.8142781026901738}
2022-11-23 02:21:03,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:03,676 INFO:     Epoch: 42
2022-11-23 02:21:04,511 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7348252826116302, 'Total loss': 0.7348252826116302} | train loss {'Reaction outcome loss': 0.8138323759119357, 'Total loss': 0.8138323759119357}
2022-11-23 02:21:04,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:04,511 INFO:     Epoch: 43
2022-11-23 02:21:05,323 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7680771642110564, 'Total loss': 0.7680771642110564} | train loss {'Reaction outcome loss': 0.8135133646428585, 'Total loss': 0.8135133646428585}
2022-11-23 02:21:05,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:05,323 INFO:     Epoch: 44
2022-11-23 02:21:06,165 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7307119247588244, 'Total loss': 0.7307119247588244} | train loss {'Reaction outcome loss': 0.8140796334632943, 'Total loss': 0.8140796334632943}
2022-11-23 02:21:06,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:06,165 INFO:     Epoch: 45
2022-11-23 02:21:07,002 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7530827488411557, 'Total loss': 0.7530827488411557} | train loss {'Reaction outcome loss': 0.8080632859660734, 'Total loss': 0.8080632859660734}
2022-11-23 02:21:07,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:07,002 INFO:     Epoch: 46
2022-11-23 02:21:07,788 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7191560119390488, 'Total loss': 0.7191560119390488} | train loss {'Reaction outcome loss': 0.8134082516114558, 'Total loss': 0.8134082516114558}
2022-11-23 02:21:07,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:07,788 INFO:     Epoch: 47
2022-11-23 02:21:08,605 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7335047545758161, 'Total loss': 0.7335047545758161} | train loss {'Reaction outcome loss': 0.8136019727155086, 'Total loss': 0.8136019727155086}
2022-11-23 02:21:08,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:08,605 INFO:     Epoch: 48
2022-11-23 02:21:09,455 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7217293733900244, 'Total loss': 0.7217293733900244} | train loss {'Reaction outcome loss': 0.8146551537417597, 'Total loss': 0.8146551537417597}
2022-11-23 02:21:09,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:09,456 INFO:     Epoch: 49
2022-11-23 02:21:10,317 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7123845267024908, 'Total loss': 0.7123845267024908} | train loss {'Reaction outcome loss': 0.8129401772973999, 'Total loss': 0.8129401772973999}
2022-11-23 02:21:10,317 INFO:     Found new best model at epoch 49
2022-11-23 02:21:10,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:10,318 INFO:     Epoch: 50
2022-11-23 02:21:11,115 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7335464595393701, 'Total loss': 0.7335464595393701} | train loss {'Reaction outcome loss': 0.8131991359255006, 'Total loss': 0.8131991359255006}
2022-11-23 02:21:11,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:11,115 INFO:     Epoch: 51
2022-11-23 02:21:11,905 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7389729639345949, 'Total loss': 0.7389729639345949} | train loss {'Reaction outcome loss': 0.8094537115145114, 'Total loss': 0.8094537115145114}
2022-11-23 02:21:11,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:11,905 INFO:     Epoch: 52
2022-11-23 02:21:12,834 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.739005675370043, 'Total loss': 0.739005675370043} | train loss {'Reaction outcome loss': 0.811486114417353, 'Total loss': 0.811486114417353}
2022-11-23 02:21:12,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:12,834 INFO:     Epoch: 53
2022-11-23 02:21:13,637 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7485763911496509, 'Total loss': 0.7485763911496509} | train loss {'Reaction outcome loss': 0.8114716492352947, 'Total loss': 0.8114716492352947}
2022-11-23 02:21:13,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:13,638 INFO:     Epoch: 54
2022-11-23 02:21:14,458 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7354692369699478, 'Total loss': 0.7354692369699478} | train loss {'Reaction outcome loss': 0.8152419585854777, 'Total loss': 0.8152419585854777}
2022-11-23 02:21:14,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:14,459 INFO:     Epoch: 55
2022-11-23 02:21:15,378 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7323751144788482, 'Total loss': 0.7323751144788482} | train loss {'Reaction outcome loss': 0.8106710348398455, 'Total loss': 0.8106710348398455}
2022-11-23 02:21:15,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:15,378 INFO:     Epoch: 56
2022-11-23 02:21:16,225 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7393183383074674, 'Total loss': 0.7393183383074674} | train loss {'Reaction outcome loss': 0.8157989317851682, 'Total loss': 0.8157989317851682}
2022-11-23 02:21:16,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:16,225 INFO:     Epoch: 57
2022-11-23 02:21:17,043 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7528284991329367, 'Total loss': 0.7528284991329367} | train loss {'Reaction outcome loss': 0.8095096261991609, 'Total loss': 0.8095096261991609}
2022-11-23 02:21:17,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:17,043 INFO:     Epoch: 58
2022-11-23 02:21:17,832 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7381085042249073, 'Total loss': 0.7381085042249073} | train loss {'Reaction outcome loss': 0.814275007574789, 'Total loss': 0.814275007574789}
2022-11-23 02:21:17,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:17,832 INFO:     Epoch: 59
2022-11-23 02:21:18,634 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7409548610448837, 'Total loss': 0.7409548610448837} | train loss {'Reaction outcome loss': 0.8129405269940053, 'Total loss': 0.8129405269940053}
2022-11-23 02:21:18,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:18,635 INFO:     Epoch: 60
2022-11-23 02:21:19,447 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7289314419031143, 'Total loss': 0.7289314419031143} | train loss {'Reaction outcome loss': 0.8144651562456162, 'Total loss': 0.8144651562456162}
2022-11-23 02:21:19,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:19,447 INFO:     Epoch: 61
2022-11-23 02:21:20,257 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7854601673104546, 'Total loss': 0.7854601673104546} | train loss {'Reaction outcome loss': 0.809763859476774, 'Total loss': 0.809763859476774}
2022-11-23 02:21:20,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:20,257 INFO:     Epoch: 62
2022-11-23 02:21:21,054 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7383062920787118, 'Total loss': 0.7383062920787118} | train loss {'Reaction outcome loss': 0.8118575780141738, 'Total loss': 0.8118575780141738}
2022-11-23 02:21:21,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:21,055 INFO:     Epoch: 63
2022-11-23 02:21:21,862 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7389695563099601, 'Total loss': 0.7389695563099601} | train loss {'Reaction outcome loss': 0.8066036657940957, 'Total loss': 0.8066036657940957}
2022-11-23 02:21:21,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:21,863 INFO:     Epoch: 64
2022-11-23 02:21:22,720 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7563250064849854, 'Total loss': 0.7563250064849854} | train loss {'Reaction outcome loss': 0.8163272805752293, 'Total loss': 0.8163272805752293}
2022-11-23 02:21:22,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:22,720 INFO:     Epoch: 65
2022-11-23 02:21:23,489 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7346041974696246, 'Total loss': 0.7346041974696246} | train loss {'Reaction outcome loss': 0.8121547779488948, 'Total loss': 0.8121547779488948}
2022-11-23 02:21:23,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:23,490 INFO:     Epoch: 66
2022-11-23 02:21:24,257 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.746060739186677, 'Total loss': 0.746060739186677} | train loss {'Reaction outcome loss': 0.8085967224211462, 'Total loss': 0.8085967224211462}
2022-11-23 02:21:24,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:24,257 INFO:     Epoch: 67
2022-11-23 02:21:25,059 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7239087522029877, 'Total loss': 0.7239087522029877} | train loss {'Reaction outcome loss': 0.8140594903980533, 'Total loss': 0.8140594903980533}
2022-11-23 02:21:25,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:25,059 INFO:     Epoch: 68
2022-11-23 02:21:25,858 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.742298505522988, 'Total loss': 0.742298505522988} | train loss {'Reaction outcome loss': 0.8160903452625198, 'Total loss': 0.8160903452625198}
2022-11-23 02:21:25,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:25,859 INFO:     Epoch: 69
2022-11-23 02:21:26,685 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7209702120585875, 'Total loss': 0.7209702120585875} | train loss {'Reaction outcome loss': 0.8130942288666002, 'Total loss': 0.8130942288666002}
2022-11-23 02:21:26,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:26,685 INFO:     Epoch: 70
2022-11-23 02:21:27,512 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7231916575269266, 'Total loss': 0.7231916575269266} | train loss {'Reaction outcome loss': 0.8079953611858429, 'Total loss': 0.8079953611858429}
2022-11-23 02:21:27,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:27,513 INFO:     Epoch: 71
2022-11-23 02:21:28,295 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7247439656745304, 'Total loss': 0.7247439656745304} | train loss {'Reaction outcome loss': 0.8125562098237776, 'Total loss': 0.8125562098237776}
2022-11-23 02:21:28,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:28,296 INFO:     Epoch: 72
2022-11-23 02:21:29,144 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7314761436798356, 'Total loss': 0.7314761436798356} | train loss {'Reaction outcome loss': 0.8094419337088062, 'Total loss': 0.8094419337088062}
2022-11-23 02:21:29,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:29,144 INFO:     Epoch: 73
2022-11-23 02:21:30,009 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.746833854100921, 'Total loss': 0.746833854100921} | train loss {'Reaction outcome loss': 0.8098957312683905, 'Total loss': 0.8098957312683905}
2022-11-23 02:21:30,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:30,009 INFO:     Epoch: 74
2022-11-23 02:21:30,845 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.712895735420964, 'Total loss': 0.712895735420964} | train loss {'Reaction outcome loss': 0.8135670815264026, 'Total loss': 0.8135670815264026}
2022-11-23 02:21:30,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:30,846 INFO:     Epoch: 75
2022-11-23 02:21:31,648 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7596467570825056, 'Total loss': 0.7596467570825056} | train loss {'Reaction outcome loss': 0.8141964974422609, 'Total loss': 0.8141964974422609}
2022-11-23 02:21:31,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:31,650 INFO:     Epoch: 76
2022-11-23 02:21:32,513 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7261534658345309, 'Total loss': 0.7261534658345309} | train loss {'Reaction outcome loss': 0.8139657863686162, 'Total loss': 0.8139657863686162}
2022-11-23 02:21:32,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:32,513 INFO:     Epoch: 77
2022-11-23 02:21:33,306 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7390739382667975, 'Total loss': 0.7390739382667975} | train loss {'Reaction outcome loss': 0.8126123338457076, 'Total loss': 0.8126123338457076}
2022-11-23 02:21:33,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:33,306 INFO:     Epoch: 78
2022-11-23 02:21:34,122 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7269603894515471, 'Total loss': 0.7269603894515471} | train loss {'Reaction outcome loss': 0.8079897828640477, 'Total loss': 0.8079897828640477}
2022-11-23 02:21:34,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:34,122 INFO:     Epoch: 79
2022-11-23 02:21:34,972 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7396485724232413, 'Total loss': 0.7396485724232413} | train loss {'Reaction outcome loss': 0.8124543216920668, 'Total loss': 0.8124543216920668}
2022-11-23 02:21:34,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:34,972 INFO:     Epoch: 80
2022-11-23 02:21:35,784 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7622960474003445, 'Total loss': 0.7622960474003445} | train loss {'Reaction outcome loss': 0.8100815140191586, 'Total loss': 0.8100815140191586}
2022-11-23 02:21:35,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:35,784 INFO:     Epoch: 81
2022-11-23 02:21:36,617 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.745013568889011, 'Total loss': 0.745013568889011} | train loss {'Reaction outcome loss': 0.8127959489582046, 'Total loss': 0.8127959489582046}
2022-11-23 02:21:36,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:36,618 INFO:     Epoch: 82
2022-11-23 02:21:37,487 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7397198345173489, 'Total loss': 0.7397198345173489} | train loss {'Reaction outcome loss': 0.8083593644682439, 'Total loss': 0.8083593644682439}
2022-11-23 02:21:37,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:37,488 INFO:     Epoch: 83
2022-11-23 02:21:38,338 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7381286072460088, 'Total loss': 0.7381286072460088} | train loss {'Reaction outcome loss': 0.8102705812742633, 'Total loss': 0.8102705812742633}
2022-11-23 02:21:38,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:38,338 INFO:     Epoch: 84
2022-11-23 02:21:39,126 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.712515343319286, 'Total loss': 0.712515343319286} | train loss {'Reaction outcome loss': 0.8081998010917056, 'Total loss': 0.8081998010917056}
2022-11-23 02:21:39,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:39,127 INFO:     Epoch: 85
2022-11-23 02:21:39,908 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7267902154814113, 'Total loss': 0.7267902154814113} | train loss {'Reaction outcome loss': 0.8088438087894071, 'Total loss': 0.8088438087894071}
2022-11-23 02:21:39,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:39,909 INFO:     Epoch: 86
2022-11-23 02:21:40,698 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7320874319835142, 'Total loss': 0.7320874319835142} | train loss {'Reaction outcome loss': 0.8150393191364503, 'Total loss': 0.8150393191364503}
2022-11-23 02:21:40,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:40,698 INFO:     Epoch: 87
2022-11-23 02:21:41,491 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7272876846519384, 'Total loss': 0.7272876846519384} | train loss {'Reaction outcome loss': 0.8110278538398205, 'Total loss': 0.8110278538398205}
2022-11-23 02:21:41,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:41,491 INFO:     Epoch: 88
2022-11-23 02:21:42,251 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7336809269406579, 'Total loss': 0.7336809269406579} | train loss {'Reaction outcome loss': 0.8100063042534936, 'Total loss': 0.8100063042534936}
2022-11-23 02:21:42,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:42,252 INFO:     Epoch: 89
2022-11-23 02:21:43,015 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7288709052584388, 'Total loss': 0.7288709052584388} | train loss {'Reaction outcome loss': 0.8067926114364978, 'Total loss': 0.8067926114364978}
2022-11-23 02:21:43,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:43,016 INFO:     Epoch: 90
2022-11-23 02:21:43,795 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7386670877987688, 'Total loss': 0.7386670877987688} | train loss {'Reaction outcome loss': 0.8128882462699567, 'Total loss': 0.8128882462699567}
2022-11-23 02:21:43,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:43,795 INFO:     Epoch: 91
2022-11-23 02:21:44,602 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7819647287780588, 'Total loss': 0.7819647287780588} | train loss {'Reaction outcome loss': 0.8148256840725099, 'Total loss': 0.8148256840725099}
2022-11-23 02:21:44,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:44,602 INFO:     Epoch: 92
2022-11-23 02:21:45,429 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7273730445991863, 'Total loss': 0.7273730445991863} | train loss {'Reaction outcome loss': 0.8148222578869712, 'Total loss': 0.8148222578869712}
2022-11-23 02:21:45,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:45,430 INFO:     Epoch: 93
2022-11-23 02:21:46,257 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7444072182882916, 'Total loss': 0.7444072182882916} | train loss {'Reaction outcome loss': 0.8122291537302155, 'Total loss': 0.8122291537302155}
2022-11-23 02:21:46,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:46,258 INFO:     Epoch: 94
2022-11-23 02:21:47,067 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7336959127675403, 'Total loss': 0.7336959127675403} | train loss {'Reaction outcome loss': 0.8131836837818546, 'Total loss': 0.8131836837818546}
2022-11-23 02:21:47,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:47,067 INFO:     Epoch: 95
2022-11-23 02:21:47,874 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7298048849810254, 'Total loss': 0.7298048849810254} | train loss {'Reaction outcome loss': 0.8168421148532822, 'Total loss': 0.8168421148532822}
2022-11-23 02:21:47,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:47,874 INFO:     Epoch: 96
2022-11-23 02:21:48,750 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7236077399416403, 'Total loss': 0.7236077399416403} | train loss {'Reaction outcome loss': 0.8096950679056106, 'Total loss': 0.8096950679056106}
2022-11-23 02:21:48,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:48,751 INFO:     Epoch: 97
2022-11-23 02:21:49,576 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7433815212412314, 'Total loss': 0.7433815212412314} | train loss {'Reaction outcome loss': 0.8142297617610423, 'Total loss': 0.8142297617610423}
2022-11-23 02:21:49,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:49,576 INFO:     Epoch: 98
2022-11-23 02:21:50,372 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7164736647497524, 'Total loss': 0.7164736647497524} | train loss {'Reaction outcome loss': 0.8128804236410125, 'Total loss': 0.8128804236410125}
2022-11-23 02:21:50,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:50,372 INFO:     Epoch: 99
2022-11-23 02:21:51,161 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7280317903919653, 'Total loss': 0.7280317903919653} | train loss {'Reaction outcome loss': 0.8066969323422639, 'Total loss': 0.8066969323422639}
2022-11-23 02:21:51,161 INFO:     Best model found after epoch 50 of 100.
2022-11-23 02:21:51,161 INFO:   Done with stage: TRAINING
2022-11-23 02:21:51,161 INFO:   Starting stage: EVALUATION
2022-11-23 02:21:51,281 INFO:   Done with stage: EVALUATION
2022-11-23 02:21:51,282 INFO:   Leaving out SEQ value Fold_6
2022-11-23 02:21:51,295 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:21:51,295 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:21:51,971 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:21:51,971 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:21:52,047 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:21:52,047 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:21:52,047 INFO:     No hyperparam tuning for this model
2022-11-23 02:21:52,047 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:21:52,047 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:21:52,048 INFO:     None feature selector for col prot
2022-11-23 02:21:52,048 INFO:     None feature selector for col prot
2022-11-23 02:21:52,048 INFO:     None feature selector for col prot
2022-11-23 02:21:52,049 INFO:     None feature selector for col chem
2022-11-23 02:21:52,049 INFO:     None feature selector for col chem
2022-11-23 02:21:52,049 INFO:     None feature selector for col chem
2022-11-23 02:21:52,049 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:21:52,049 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:21:52,052 INFO:     Number of params in model 168571
2022-11-23 02:21:52,055 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:21:52,055 INFO:   Starting stage: TRAINING
2022-11-23 02:21:52,114 INFO:     Val loss before train {'Reaction outcome loss': 0.9249613921750676, 'Total loss': 0.9249613921750676}
2022-11-23 02:21:52,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:52,114 INFO:     Epoch: 0
2022-11-23 02:21:52,900 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7780573659322478, 'Total loss': 0.7780573659322478} | train loss {'Reaction outcome loss': 0.8874221189368156, 'Total loss': 0.8874221189368156}
2022-11-23 02:21:52,900 INFO:     Found new best model at epoch 0
2022-11-23 02:21:52,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:52,901 INFO:     Epoch: 1
2022-11-23 02:21:53,722 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7721292579715903, 'Total loss': 0.7721292579715903} | train loss {'Reaction outcome loss': 0.8596705858024859, 'Total loss': 0.8596705858024859}
2022-11-23 02:21:53,724 INFO:     Found new best model at epoch 1
2022-11-23 02:21:53,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:53,725 INFO:     Epoch: 2
2022-11-23 02:21:54,524 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7502952482212674, 'Total loss': 0.7502952482212674} | train loss {'Reaction outcome loss': 0.850132639369657, 'Total loss': 0.850132639369657}
2022-11-23 02:21:54,524 INFO:     Found new best model at epoch 2
2022-11-23 02:21:54,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:54,525 INFO:     Epoch: 3
2022-11-23 02:21:55,396 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7459440360015089, 'Total loss': 0.7459440360015089} | train loss {'Reaction outcome loss': 0.846495991272311, 'Total loss': 0.846495991272311}
2022-11-23 02:21:55,396 INFO:     Found new best model at epoch 3
2022-11-23 02:21:55,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:55,397 INFO:     Epoch: 4
2022-11-23 02:21:56,247 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7533859766342423, 'Total loss': 0.7533859766342423} | train loss {'Reaction outcome loss': 0.8425933326925, 'Total loss': 0.8425933326925}
2022-11-23 02:21:56,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:56,247 INFO:     Epoch: 5
2022-11-23 02:21:57,073 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7660463851961222, 'Total loss': 0.7660463851961222} | train loss {'Reaction outcome loss': 0.841833571152341, 'Total loss': 0.841833571152341}
2022-11-23 02:21:57,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:57,073 INFO:     Epoch: 6
2022-11-23 02:21:57,897 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7338492931290106, 'Total loss': 0.7338492931290106} | train loss {'Reaction outcome loss': 0.8335985302204086, 'Total loss': 0.8335985302204086}
2022-11-23 02:21:57,897 INFO:     Found new best model at epoch 6
2022-11-23 02:21:57,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:57,898 INFO:     Epoch: 7
2022-11-23 02:21:58,745 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7484308156100187, 'Total loss': 0.7484308156100187} | train loss {'Reaction outcome loss': 0.8350101508680852, 'Total loss': 0.8350101508680852}
2022-11-23 02:21:58,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:58,745 INFO:     Epoch: 8
2022-11-23 02:21:59,523 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7581278830766678, 'Total loss': 0.7581278830766678} | train loss {'Reaction outcome loss': 0.8363153626841884, 'Total loss': 0.8363153626841884}
2022-11-23 02:21:59,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:21:59,524 INFO:     Epoch: 9
2022-11-23 02:22:00,421 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7506671859459444, 'Total loss': 0.7506671859459444} | train loss {'Reaction outcome loss': 0.8317665777379467, 'Total loss': 0.8317665777379467}
2022-11-23 02:22:00,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:00,422 INFO:     Epoch: 10
2022-11-23 02:22:01,187 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7515308816324581, 'Total loss': 0.7515308816324581} | train loss {'Reaction outcome loss': 0.8312488394158501, 'Total loss': 0.8312488394158501}
2022-11-23 02:22:01,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:01,188 INFO:     Epoch: 11
2022-11-23 02:22:01,961 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7506503090262413, 'Total loss': 0.7506503090262413} | train loss {'Reaction outcome loss': 0.8332701053830885, 'Total loss': 0.8332701053830885}
2022-11-23 02:22:01,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:01,961 INFO:     Epoch: 12
2022-11-23 02:22:02,758 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7460934926163066, 'Total loss': 0.7460934926163066} | train loss {'Reaction outcome loss': 0.8272609100226433, 'Total loss': 0.8272609100226433}
2022-11-23 02:22:02,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:02,758 INFO:     Epoch: 13
2022-11-23 02:22:03,555 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.750300066714937, 'Total loss': 0.750300066714937} | train loss {'Reaction outcome loss': 0.8332466475905911, 'Total loss': 0.8332466475905911}
2022-11-23 02:22:03,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:03,556 INFO:     Epoch: 14
2022-11-23 02:22:04,354 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7325772961432283, 'Total loss': 0.7325772961432283} | train loss {'Reaction outcome loss': 0.8267992134055784, 'Total loss': 0.8267992134055784}
2022-11-23 02:22:04,354 INFO:     Found new best model at epoch 14
2022-11-23 02:22:04,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:04,355 INFO:     Epoch: 15
2022-11-23 02:22:05,118 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7470768297260458, 'Total loss': 0.7470768297260458} | train loss {'Reaction outcome loss': 0.8290402967362634, 'Total loss': 0.8290402967362634}
2022-11-23 02:22:05,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:05,119 INFO:     Epoch: 16
2022-11-23 02:22:05,925 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7426284822550687, 'Total loss': 0.7426284822550687} | train loss {'Reaction outcome loss': 0.8303909224848594, 'Total loss': 0.8303909224848594}
2022-11-23 02:22:05,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:05,926 INFO:     Epoch: 17
2022-11-23 02:22:06,716 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7368751032785936, 'Total loss': 0.7368751032785936} | train loss {'Reaction outcome loss': 0.8327628676929781, 'Total loss': 0.8327628676929781}
2022-11-23 02:22:06,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:06,716 INFO:     Epoch: 18
2022-11-23 02:22:07,573 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7463611723347143, 'Total loss': 0.7463611723347143} | train loss {'Reaction outcome loss': 0.8284399008318302, 'Total loss': 0.8284399008318302}
2022-11-23 02:22:07,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:07,573 INFO:     Epoch: 19
2022-11-23 02:22:08,427 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7260740114883943, 'Total loss': 0.7260740114883943} | train loss {'Reaction outcome loss': 0.8287974993788427, 'Total loss': 0.8287974993788427}
2022-11-23 02:22:08,427 INFO:     Found new best model at epoch 19
2022-11-23 02:22:08,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:08,428 INFO:     Epoch: 20
2022-11-23 02:22:09,309 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7466917071830143, 'Total loss': 0.7466917071830143} | train loss {'Reaction outcome loss': 0.824767459664614, 'Total loss': 0.824767459664614}
2022-11-23 02:22:09,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:09,309 INFO:     Epoch: 21
2022-11-23 02:22:10,153 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7372972375967286, 'Total loss': 0.7372972375967286} | train loss {'Reaction outcome loss': 0.8244263073129039, 'Total loss': 0.8244263073129039}
2022-11-23 02:22:10,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:10,154 INFO:     Epoch: 22
2022-11-23 02:22:11,020 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7605763612823053, 'Total loss': 0.7605763612823053} | train loss {'Reaction outcome loss': 0.8233653022156607, 'Total loss': 0.8233653022156607}
2022-11-23 02:22:11,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:11,020 INFO:     Epoch: 23
2022-11-23 02:22:11,899 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7345056344162334, 'Total loss': 0.7345056344162334} | train loss {'Reaction outcome loss': 0.8269933965657988, 'Total loss': 0.8269933965657988}
2022-11-23 02:22:11,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:11,899 INFO:     Epoch: 24
2022-11-23 02:22:12,855 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7646263268860903, 'Total loss': 0.7646263268860903} | train loss {'Reaction outcome loss': 0.8275413847258014, 'Total loss': 0.8275413847258014}
2022-11-23 02:22:12,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:12,856 INFO:     Epoch: 25
2022-11-23 02:22:13,837 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.730940252203833, 'Total loss': 0.730940252203833} | train loss {'Reaction outcome loss': 0.8260061160450981, 'Total loss': 0.8260061160450981}
2022-11-23 02:22:13,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:13,837 INFO:     Epoch: 26
2022-11-23 02:22:14,788 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7486265633593906, 'Total loss': 0.7486265633593906} | train loss {'Reaction outcome loss': 0.8219168171767266, 'Total loss': 0.8219168171767266}
2022-11-23 02:22:14,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:14,789 INFO:     Epoch: 27
2022-11-23 02:22:15,696 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7259571504863825, 'Total loss': 0.7259571504863825} | train loss {'Reaction outcome loss': 0.823541279762022, 'Total loss': 0.823541279762022}
2022-11-23 02:22:15,696 INFO:     Found new best model at epoch 27
2022-11-23 02:22:15,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:15,697 INFO:     Epoch: 28
2022-11-23 02:22:16,623 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7411733012307774, 'Total loss': 0.7411733012307774} | train loss {'Reaction outcome loss': 0.8252127969697598, 'Total loss': 0.8252127969697598}
2022-11-23 02:22:16,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:16,624 INFO:     Epoch: 29
2022-11-23 02:22:17,539 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7380876337940042, 'Total loss': 0.7380876337940042} | train loss {'Reaction outcome loss': 0.8219206954442686, 'Total loss': 0.8219206954442686}
2022-11-23 02:22:17,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:17,539 INFO:     Epoch: 30
2022-11-23 02:22:18,539 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.73069824075157, 'Total loss': 0.73069824075157} | train loss {'Reaction outcome loss': 0.8239409554629556, 'Total loss': 0.8239409554629556}
2022-11-23 02:22:18,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:18,540 INFO:     Epoch: 31
2022-11-23 02:22:19,467 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7329224768010053, 'Total loss': 0.7329224768010053} | train loss {'Reaction outcome loss': 0.8219728969758556, 'Total loss': 0.8219728969758556}
2022-11-23 02:22:19,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:19,467 INFO:     Epoch: 32
2022-11-23 02:22:20,471 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7357233349572528, 'Total loss': 0.7357233349572528} | train loss {'Reaction outcome loss': 0.8203335454867732, 'Total loss': 0.8203335454867732}
2022-11-23 02:22:20,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:20,472 INFO:     Epoch: 33
2022-11-23 02:22:21,450 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7349620651115071, 'Total loss': 0.7349620651115071} | train loss {'Reaction outcome loss': 0.8190255316515123, 'Total loss': 0.8190255316515123}
2022-11-23 02:22:21,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:21,450 INFO:     Epoch: 34
2022-11-23 02:22:22,381 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7411827743053436, 'Total loss': 0.7411827743053436} | train loss {'Reaction outcome loss': 0.8235682670868212, 'Total loss': 0.8235682670868212}
2022-11-23 02:22:22,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:22,381 INFO:     Epoch: 35
2022-11-23 02:22:23,276 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7468778585845773, 'Total loss': 0.7468778585845773} | train loss {'Reaction outcome loss': 0.8175094848678958, 'Total loss': 0.8175094848678958}
2022-11-23 02:22:23,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:23,276 INFO:     Epoch: 36
2022-11-23 02:22:24,157 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.744467981159687, 'Total loss': 0.744467981159687} | train loss {'Reaction outcome loss': 0.818995667561408, 'Total loss': 0.818995667561408}
2022-11-23 02:22:24,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:24,158 INFO:     Epoch: 37
2022-11-23 02:22:25,055 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7287839867851951, 'Total loss': 0.7287839867851951} | train loss {'Reaction outcome loss': 0.822521782329967, 'Total loss': 0.822521782329967}
2022-11-23 02:22:25,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:25,056 INFO:     Epoch: 38
2022-11-23 02:22:25,915 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7290746508674188, 'Total loss': 0.7290746508674188} | train loss {'Reaction outcome loss': 0.8275155822836584, 'Total loss': 0.8275155822836584}
2022-11-23 02:22:25,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:25,915 INFO:     Epoch: 39
2022-11-23 02:22:26,829 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7504319148984823, 'Total loss': 0.7504319148984823} | train loss {'Reaction outcome loss': 0.8242646002721402, 'Total loss': 0.8242646002721402}
2022-11-23 02:22:26,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:26,830 INFO:     Epoch: 40
2022-11-23 02:22:27,684 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7436536225405607, 'Total loss': 0.7436536225405607} | train loss {'Reaction outcome loss': 0.8178924592512269, 'Total loss': 0.8178924592512269}
2022-11-23 02:22:27,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:27,684 INFO:     Epoch: 41
2022-11-23 02:22:28,558 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7418892729011449, 'Total loss': 0.7418892729011449} | train loss {'Reaction outcome loss': 0.8266102808617777, 'Total loss': 0.8266102808617777}
2022-11-23 02:22:28,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:28,558 INFO:     Epoch: 42
2022-11-23 02:22:29,420 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7320575429634615, 'Total loss': 0.7320575429634615} | train loss {'Reaction outcome loss': 0.8202002187890391, 'Total loss': 0.8202002187890391}
2022-11-23 02:22:29,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:29,420 INFO:     Epoch: 43
2022-11-23 02:22:30,278 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.736372138288888, 'Total loss': 0.736372138288888} | train loss {'Reaction outcome loss': 0.8219822555059387, 'Total loss': 0.8219822555059387}
2022-11-23 02:22:30,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:30,278 INFO:     Epoch: 44
2022-11-23 02:22:31,125 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7454835962165486, 'Total loss': 0.7454835962165486} | train loss {'Reaction outcome loss': 0.8267029674062806, 'Total loss': 0.8267029674062806}
2022-11-23 02:22:31,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:31,126 INFO:     Epoch: 45
2022-11-23 02:22:31,964 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7359355640682307, 'Total loss': 0.7359355640682307} | train loss {'Reaction outcome loss': 0.8227035659215143, 'Total loss': 0.8227035659215143}
2022-11-23 02:22:31,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:31,964 INFO:     Epoch: 46
2022-11-23 02:22:32,838 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.725870667533441, 'Total loss': 0.725870667533441} | train loss {'Reaction outcome loss': 0.8207230315573754, 'Total loss': 0.8207230315573754}
2022-11-23 02:22:32,838 INFO:     Found new best model at epoch 46
2022-11-23 02:22:32,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:32,839 INFO:     Epoch: 47
2022-11-23 02:22:33,711 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7528057572516528, 'Total loss': 0.7528057572516528} | train loss {'Reaction outcome loss': 0.8209263700391015, 'Total loss': 0.8209263700391015}
2022-11-23 02:22:33,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:33,711 INFO:     Epoch: 48
2022-11-23 02:22:34,553 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7328115241094069, 'Total loss': 0.7328115241094069} | train loss {'Reaction outcome loss': 0.8250383966632427, 'Total loss': 0.8250383966632427}
2022-11-23 02:22:34,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:34,553 INFO:     Epoch: 49
2022-11-23 02:22:35,443 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7277649295600978, 'Total loss': 0.7277649295600978} | train loss {'Reaction outcome loss': 0.8234601663725991, 'Total loss': 0.8234601663725991}
2022-11-23 02:22:35,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:35,443 INFO:     Epoch: 50
2022-11-23 02:22:36,301 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7720452418381517, 'Total loss': 0.7720452418381517} | train loss {'Reaction outcome loss': 0.8239704828348852, 'Total loss': 0.8239704828348852}
2022-11-23 02:22:36,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:36,301 INFO:     Epoch: 51
2022-11-23 02:22:37,135 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7511999512260611, 'Total loss': 0.7511999512260611} | train loss {'Reaction outcome loss': 0.8174141341399762, 'Total loss': 0.8174141341399762}
2022-11-23 02:22:37,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:37,135 INFO:     Epoch: 52
2022-11-23 02:22:38,048 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7644872929562222, 'Total loss': 0.7644872929562222} | train loss {'Reaction outcome loss': 0.8213726908208863, 'Total loss': 0.8213726908208863}
2022-11-23 02:22:38,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:38,048 INFO:     Epoch: 53
2022-11-23 02:22:38,898 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7237311791289937, 'Total loss': 0.7237311791289937} | train loss {'Reaction outcome loss': 0.8200721842867713, 'Total loss': 0.8200721842867713}
2022-11-23 02:22:38,898 INFO:     Found new best model at epoch 53
2022-11-23 02:22:38,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:38,899 INFO:     Epoch: 54
2022-11-23 02:22:39,746 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7468056136911566, 'Total loss': 0.7468056136911566} | train loss {'Reaction outcome loss': 0.8155404963800984, 'Total loss': 0.8155404963800984}
2022-11-23 02:22:39,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:39,747 INFO:     Epoch: 55
2022-11-23 02:22:40,651 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7409564060243693, 'Total loss': 0.7409564060243693} | train loss {'Reaction outcome loss': 0.8202580748306166, 'Total loss': 0.8202580748306166}
2022-11-23 02:22:40,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:40,651 INFO:     Epoch: 56
2022-11-23 02:22:41,548 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7267995144833218, 'Total loss': 0.7267995144833218} | train loss {'Reaction outcome loss': 0.8181606860410783, 'Total loss': 0.8181606860410783}
2022-11-23 02:22:41,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:41,548 INFO:     Epoch: 57
2022-11-23 02:22:42,421 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7414293072440408, 'Total loss': 0.7414293072440408} | train loss {'Reaction outcome loss': 0.8255452117131602, 'Total loss': 0.8255452117131602}
2022-11-23 02:22:42,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:42,421 INFO:     Epoch: 58
2022-11-23 02:22:43,287 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.726250334219499, 'Total loss': 0.726250334219499} | train loss {'Reaction outcome loss': 0.8231219715408741, 'Total loss': 0.8231219715408741}
2022-11-23 02:22:43,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:43,288 INFO:     Epoch: 59
2022-11-23 02:22:44,190 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7350614754991098, 'Total loss': 0.7350614754991098} | train loss {'Reaction outcome loss': 0.8187123139298731, 'Total loss': 0.8187123139298731}
2022-11-23 02:22:44,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:44,190 INFO:     Epoch: 60
2022-11-23 02:22:45,049 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7353736026720568, 'Total loss': 0.7353736026720568} | train loss {'Reaction outcome loss': 0.8183305144550339, 'Total loss': 0.8183305144550339}
2022-11-23 02:22:45,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:45,049 INFO:     Epoch: 61
2022-11-23 02:22:45,918 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7477884624492038, 'Total loss': 0.7477884624492038} | train loss {'Reaction outcome loss': 0.8162911977739103, 'Total loss': 0.8162911977739103}
2022-11-23 02:22:45,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:45,918 INFO:     Epoch: 62
2022-11-23 02:22:46,784 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.750688602978533, 'Total loss': 0.750688602978533} | train loss {'Reaction outcome loss': 0.8216875492324752, 'Total loss': 0.8216875492324752}
2022-11-23 02:22:46,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:46,784 INFO:     Epoch: 63
2022-11-23 02:22:47,646 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7284952117638155, 'Total loss': 0.7284952117638155} | train loss {'Reaction outcome loss': 0.8184876788047052, 'Total loss': 0.8184876788047052}
2022-11-23 02:22:47,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:47,647 INFO:     Epoch: 64
2022-11-23 02:22:48,533 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7208958742293444, 'Total loss': 0.7208958742293444} | train loss {'Reaction outcome loss': 0.8179666761669421, 'Total loss': 0.8179666761669421}
2022-11-23 02:22:48,534 INFO:     Found new best model at epoch 64
2022-11-23 02:22:48,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:48,535 INFO:     Epoch: 65
2022-11-23 02:22:49,401 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7280788374218073, 'Total loss': 0.7280788374218073} | train loss {'Reaction outcome loss': 0.8227770964224492, 'Total loss': 0.8227770964224492}
2022-11-23 02:22:49,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:49,401 INFO:     Epoch: 66
2022-11-23 02:22:50,272 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7310647503896193, 'Total loss': 0.7310647503896193} | train loss {'Reaction outcome loss': 0.8182740468652018, 'Total loss': 0.8182740468652018}
2022-11-23 02:22:50,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:50,273 INFO:     Epoch: 67
2022-11-23 02:22:51,182 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.745093123479323, 'Total loss': 0.745093123479323} | train loss {'Reaction outcome loss': 0.8214861081252175, 'Total loss': 0.8214861081252175}
2022-11-23 02:22:51,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:51,182 INFO:     Epoch: 68
2022-11-23 02:22:52,021 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7349320135333322, 'Total loss': 0.7349320135333322} | train loss {'Reaction outcome loss': 0.822333374811757, 'Total loss': 0.822333374811757}
2022-11-23 02:22:52,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:52,021 INFO:     Epoch: 69
2022-11-23 02:22:52,858 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7442319596355612, 'Total loss': 0.7442319596355612} | train loss {'Reaction outcome loss': 0.8213324449475734, 'Total loss': 0.8213324449475734}
2022-11-23 02:22:52,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:52,858 INFO:     Epoch: 70
2022-11-23 02:22:53,743 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.738279901444912, 'Total loss': 0.738279901444912} | train loss {'Reaction outcome loss': 0.8199983225955118, 'Total loss': 0.8199983225955118}
2022-11-23 02:22:53,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:53,743 INFO:     Epoch: 71
2022-11-23 02:22:54,642 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7369068346240304, 'Total loss': 0.7369068346240304} | train loss {'Reaction outcome loss': 0.8210923872407405, 'Total loss': 0.8210923872407405}
2022-11-23 02:22:54,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:54,642 INFO:     Epoch: 72
2022-11-23 02:22:55,556 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7342047420415011, 'Total loss': 0.7342047420415011} | train loss {'Reaction outcome loss': 0.8153755453325087, 'Total loss': 0.8153755453325087}
2022-11-23 02:22:55,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:55,557 INFO:     Epoch: 73
2022-11-23 02:22:56,472 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7282556004144929, 'Total loss': 0.7282556004144929} | train loss {'Reaction outcome loss': 0.8197260465352766, 'Total loss': 0.8197260465352766}
2022-11-23 02:22:56,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:56,473 INFO:     Epoch: 74
2022-11-23 02:22:57,359 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7304147529331121, 'Total loss': 0.7304147529331121} | train loss {'Reaction outcome loss': 0.8209892516174624, 'Total loss': 0.8209892516174624}
2022-11-23 02:22:57,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:57,359 INFO:     Epoch: 75
2022-11-23 02:22:58,205 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7246120829473842, 'Total loss': 0.7246120829473842} | train loss {'Reaction outcome loss': 0.8185209928741378, 'Total loss': 0.8185209928741378}
2022-11-23 02:22:58,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:58,205 INFO:     Epoch: 76
2022-11-23 02:22:59,064 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.743896827779033, 'Total loss': 0.743896827779033} | train loss {'Reaction outcome loss': 0.8216119260797577, 'Total loss': 0.8216119260797577}
2022-11-23 02:22:59,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:59,064 INFO:     Epoch: 77
2022-11-23 02:22:59,928 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7444811104373499, 'Total loss': 0.7444811104373499} | train loss {'Reaction outcome loss': 0.820549073478868, 'Total loss': 0.820549073478868}
2022-11-23 02:22:59,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:22:59,929 INFO:     Epoch: 78
2022-11-23 02:23:00,763 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7384549907662652, 'Total loss': 0.7384549907662652} | train loss {'Reaction outcome loss': 0.8195690440554773, 'Total loss': 0.8195690440554773}
2022-11-23 02:23:00,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:00,763 INFO:     Epoch: 79
2022-11-23 02:23:01,636 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7427322559735992, 'Total loss': 0.7427322559735992} | train loss {'Reaction outcome loss': 0.8239372743954582, 'Total loss': 0.8239372743954582}
2022-11-23 02:23:01,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:01,636 INFO:     Epoch: 80
2022-11-23 02:23:02,523 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7345156642523679, 'Total loss': 0.7345156642523679} | train loss {'Reaction outcome loss': 0.8186833874112175, 'Total loss': 0.8186833874112175}
2022-11-23 02:23:02,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:02,524 INFO:     Epoch: 81
2022-11-23 02:23:03,349 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7374047460881147, 'Total loss': 0.7374047460881147} | train loss {'Reaction outcome loss': 0.8167186640202999, 'Total loss': 0.8167186640202999}
2022-11-23 02:23:03,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:03,349 INFO:     Epoch: 82
2022-11-23 02:23:04,206 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.738797896287658, 'Total loss': 0.738797896287658} | train loss {'Reaction outcome loss': 0.8231360599879296, 'Total loss': 0.8231360599879296}
2022-11-23 02:23:04,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:04,206 INFO:     Epoch: 83
2022-11-23 02:23:05,054 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7313335375352339, 'Total loss': 0.7313335375352339} | train loss {'Reaction outcome loss': 0.8190814382847278, 'Total loss': 0.8190814382847278}
2022-11-23 02:23:05,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:05,055 INFO:     Epoch: 84
2022-11-23 02:23:05,977 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7249975753101435, 'Total loss': 0.7249975753101435} | train loss {'Reaction outcome loss': 0.8205083222879518, 'Total loss': 0.8205083222879518}
2022-11-23 02:23:05,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:05,977 INFO:     Epoch: 85
2022-11-23 02:23:06,873 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7525943734429099, 'Total loss': 0.7525943734429099} | train loss {'Reaction outcome loss': 0.8167300233917851, 'Total loss': 0.8167300233917851}
2022-11-23 02:23:06,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:06,873 INFO:     Epoch: 86
2022-11-23 02:23:07,732 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7301932932301001, 'Total loss': 0.7301932932301001} | train loss {'Reaction outcome loss': 0.817190782918084, 'Total loss': 0.817190782918084}
2022-11-23 02:23:07,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:07,732 INFO:     Epoch: 87
2022-11-23 02:23:08,593 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7478008703751997, 'Total loss': 0.7478008703751997} | train loss {'Reaction outcome loss': 0.8215635613568367, 'Total loss': 0.8215635613568367}
2022-11-23 02:23:08,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:08,593 INFO:     Epoch: 88
2022-11-23 02:23:09,458 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7312648174437609, 'Total loss': 0.7312648174437609} | train loss {'Reaction outcome loss': 0.8180823990654561, 'Total loss': 0.8180823990654561}
2022-11-23 02:23:09,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:09,458 INFO:     Epoch: 89
2022-11-23 02:23:10,314 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7342830882831053, 'Total loss': 0.7342830882831053} | train loss {'Reaction outcome loss': 0.8172457951211161, 'Total loss': 0.8172457951211161}
2022-11-23 02:23:10,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:10,314 INFO:     Epoch: 90
2022-11-23 02:23:11,170 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7381179542704062, 'Total loss': 0.7381179542704062} | train loss {'Reaction outcome loss': 0.8187631030957545, 'Total loss': 0.8187631030957545}
2022-11-23 02:23:11,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:11,171 INFO:     Epoch: 91
2022-11-23 02:23:12,029 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7308262566273863, 'Total loss': 0.7308262566273863} | train loss {'Reaction outcome loss': 0.8174882037264686, 'Total loss': 0.8174882037264686}
2022-11-23 02:23:12,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:12,029 INFO:     Epoch: 92
2022-11-23 02:23:12,865 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7302713814106855, 'Total loss': 0.7302713814106855} | train loss {'Reaction outcome loss': 0.8197912921107584, 'Total loss': 0.8197912921107584}
2022-11-23 02:23:12,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:12,865 INFO:     Epoch: 93
2022-11-23 02:23:13,706 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7358952361074361, 'Total loss': 0.7358952361074361} | train loss {'Reaction outcome loss': 0.8164942956739857, 'Total loss': 0.8164942956739857}
2022-11-23 02:23:13,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:13,706 INFO:     Epoch: 94
2022-11-23 02:23:14,532 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7511150579560887, 'Total loss': 0.7511150579560887} | train loss {'Reaction outcome loss': 0.8202028528096215, 'Total loss': 0.8202028528096215}
2022-11-23 02:23:14,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:14,533 INFO:     Epoch: 95
2022-11-23 02:23:15,359 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7394098490476608, 'Total loss': 0.7394098490476608} | train loss {'Reaction outcome loss': 0.8201377270442824, 'Total loss': 0.8201377270442824}
2022-11-23 02:23:15,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:15,359 INFO:     Epoch: 96
2022-11-23 02:23:16,179 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7274454208937559, 'Total loss': 0.7274454208937559} | train loss {'Reaction outcome loss': 0.818812983651315, 'Total loss': 0.818812983651315}
2022-11-23 02:23:16,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:16,179 INFO:     Epoch: 97
2022-11-23 02:23:17,000 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7319678115573797, 'Total loss': 0.7319678115573797} | train loss {'Reaction outcome loss': 0.8176001676869008, 'Total loss': 0.8176001676869008}
2022-11-23 02:23:17,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:17,000 INFO:     Epoch: 98
2022-11-23 02:23:17,800 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7593012723055753, 'Total loss': 0.7593012723055753} | train loss {'Reaction outcome loss': 0.8190122071293092, 'Total loss': 0.8190122071293092}
2022-11-23 02:23:17,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:17,800 INFO:     Epoch: 99
2022-11-23 02:23:18,635 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7458872612227093, 'Total loss': 0.7458872612227093} | train loss {'Reaction outcome loss': 0.8244155036105264, 'Total loss': 0.8244155036105264}
2022-11-23 02:23:18,635 INFO:     Best model found after epoch 65 of 100.
2022-11-23 02:23:18,636 INFO:   Done with stage: TRAINING
2022-11-23 02:23:18,636 INFO:   Starting stage: EVALUATION
2022-11-23 02:23:18,755 INFO:   Done with stage: EVALUATION
2022-11-23 02:23:18,755 INFO:   Leaving out SEQ value Fold_7
2022-11-23 02:23:18,768 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:23:18,769 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:23:19,448 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:23:19,448 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:23:19,523 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:23:19,523 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:23:19,523 INFO:     No hyperparam tuning for this model
2022-11-23 02:23:19,523 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:23:19,523 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:23:19,524 INFO:     None feature selector for col prot
2022-11-23 02:23:19,524 INFO:     None feature selector for col prot
2022-11-23 02:23:19,524 INFO:     None feature selector for col prot
2022-11-23 02:23:19,525 INFO:     None feature selector for col chem
2022-11-23 02:23:19,525 INFO:     None feature selector for col chem
2022-11-23 02:23:19,525 INFO:     None feature selector for col chem
2022-11-23 02:23:19,525 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:23:19,525 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:23:19,526 INFO:     Number of params in model 168571
2022-11-23 02:23:19,530 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:23:19,530 INFO:   Starting stage: TRAINING
2022-11-23 02:23:19,589 INFO:     Val loss before train {'Reaction outcome loss': 0.9897705363956365, 'Total loss': 0.9897705363956365}
2022-11-23 02:23:19,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:19,589 INFO:     Epoch: 0
2022-11-23 02:23:20,439 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8460281857035377, 'Total loss': 0.8460281857035377} | train loss {'Reaction outcome loss': 0.8807042042814917, 'Total loss': 0.8807042042814917}
2022-11-23 02:23:20,439 INFO:     Found new best model at epoch 0
2022-11-23 02:23:20,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:20,440 INFO:     Epoch: 1
2022-11-23 02:23:21,237 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8416404744440859, 'Total loss': 0.8416404744440859} | train loss {'Reaction outcome loss': 0.8546128770516764, 'Total loss': 0.8546128770516764}
2022-11-23 02:23:21,237 INFO:     Found new best model at epoch 1
2022-11-23 02:23:21,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:21,238 INFO:     Epoch: 2
2022-11-23 02:23:22,062 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8440670106898654, 'Total loss': 0.8440670106898654} | train loss {'Reaction outcome loss': 0.8461084246875779, 'Total loss': 0.8461084246875779}
2022-11-23 02:23:22,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:22,063 INFO:     Epoch: 3
2022-11-23 02:23:22,846 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8788080736994743, 'Total loss': 0.8788080736994743} | train loss {'Reaction outcome loss': 0.8458854881746154, 'Total loss': 0.8458854881746154}
2022-11-23 02:23:22,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:22,846 INFO:     Epoch: 4
2022-11-23 02:23:23,648 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8371308662674644, 'Total loss': 0.8371308662674644} | train loss {'Reaction outcome loss': 0.8390462993373794, 'Total loss': 0.8390462993373794}
2022-11-23 02:23:23,648 INFO:     Found new best model at epoch 4
2022-11-23 02:23:23,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:23,649 INFO:     Epoch: 5
2022-11-23 02:23:24,420 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8231345875696703, 'Total loss': 0.8231345875696703} | train loss {'Reaction outcome loss': 0.8287476924878936, 'Total loss': 0.8287476924878936}
2022-11-23 02:23:24,420 INFO:     Found new best model at epoch 5
2022-11-23 02:23:24,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:24,421 INFO:     Epoch: 6
2022-11-23 02:23:25,230 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8453078527342189, 'Total loss': 0.8453078527342189} | train loss {'Reaction outcome loss': 0.8301478191729514, 'Total loss': 0.8301478191729514}
2022-11-23 02:23:25,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:25,230 INFO:     Epoch: 7
2022-11-23 02:23:26,041 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8253723206845197, 'Total loss': 0.8253723206845197} | train loss {'Reaction outcome loss': 0.8312195938441062, 'Total loss': 0.8312195938441062}
2022-11-23 02:23:26,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:26,042 INFO:     Epoch: 8
2022-11-23 02:23:26,809 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8345859409733252, 'Total loss': 0.8345859409733252} | train loss {'Reaction outcome loss': 0.8294910638322753, 'Total loss': 0.8294910638322753}
2022-11-23 02:23:26,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:26,809 INFO:     Epoch: 9
2022-11-23 02:23:27,572 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8452351025559686, 'Total loss': 0.8452351025559686} | train loss {'Reaction outcome loss': 0.82576451943286, 'Total loss': 0.82576451943286}
2022-11-23 02:23:27,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:27,574 INFO:     Epoch: 10
2022-11-23 02:23:28,367 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8459120433438908, 'Total loss': 0.8459120433438908} | train loss {'Reaction outcome loss': 0.8305975917366243, 'Total loss': 0.8305975917366243}
2022-11-23 02:23:28,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:28,368 INFO:     Epoch: 11
2022-11-23 02:23:29,124 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8453549133105711, 'Total loss': 0.8453549133105711} | train loss {'Reaction outcome loss': 0.8247100839451436, 'Total loss': 0.8247100839451436}
2022-11-23 02:23:29,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:29,125 INFO:     Epoch: 12
2022-11-23 02:23:29,894 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8616479377854954, 'Total loss': 0.8616479377854954} | train loss {'Reaction outcome loss': 0.8219245163904082, 'Total loss': 0.8219245163904082}
2022-11-23 02:23:29,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:29,894 INFO:     Epoch: 13
2022-11-23 02:23:30,685 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8368062661452726, 'Total loss': 0.8368062661452726} | train loss {'Reaction outcome loss': 0.8263552420802655, 'Total loss': 0.8263552420802655}
2022-11-23 02:23:30,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:30,685 INFO:     Epoch: 14
2022-11-23 02:23:31,510 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.810518354177475, 'Total loss': 0.810518354177475} | train loss {'Reaction outcome loss': 0.8218704394755825, 'Total loss': 0.8218704394755825}
2022-11-23 02:23:31,510 INFO:     Found new best model at epoch 14
2022-11-23 02:23:31,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:31,511 INFO:     Epoch: 15
2022-11-23 02:23:32,307 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8168800080364401, 'Total loss': 0.8168800080364401} | train loss {'Reaction outcome loss': 0.8210616221110667, 'Total loss': 0.8210616221110667}
2022-11-23 02:23:32,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:32,307 INFO:     Epoch: 16
2022-11-23 02:23:33,098 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8176550499417565, 'Total loss': 0.8176550499417565} | train loss {'Reaction outcome loss': 0.826410811754965, 'Total loss': 0.826410811754965}
2022-11-23 02:23:33,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:33,099 INFO:     Epoch: 17
2022-11-23 02:23:33,889 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8108557124029506, 'Total loss': 0.8108557124029506} | train loss {'Reaction outcome loss': 0.8239542225435856, 'Total loss': 0.8239542225435856}
2022-11-23 02:23:33,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:33,890 INFO:     Epoch: 18
2022-11-23 02:23:34,717 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8273525122891773, 'Total loss': 0.8273525122891773} | train loss {'Reaction outcome loss': 0.8218133146724393, 'Total loss': 0.8218133146724393}
2022-11-23 02:23:34,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:34,717 INFO:     Epoch: 19
2022-11-23 02:23:35,575 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8289965282786976, 'Total loss': 0.8289965282786976} | train loss {'Reaction outcome loss': 0.8235530451901497, 'Total loss': 0.8235530451901497}
2022-11-23 02:23:35,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:35,575 INFO:     Epoch: 20
2022-11-23 02:23:36,383 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8234622864560648, 'Total loss': 0.8234622864560648} | train loss {'Reaction outcome loss': 0.827515639845402, 'Total loss': 0.827515639845402}
2022-11-23 02:23:36,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:36,384 INFO:     Epoch: 21
2022-11-23 02:23:37,218 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8178416226397861, 'Total loss': 0.8178416226397861} | train loss {'Reaction outcome loss': 0.826002354463262, 'Total loss': 0.826002354463262}
2022-11-23 02:23:37,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:37,218 INFO:     Epoch: 22
2022-11-23 02:23:38,039 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8256896781650457, 'Total loss': 0.8256896781650457} | train loss {'Reaction outcome loss': 0.8174537188343464, 'Total loss': 0.8174537188343464}
2022-11-23 02:23:38,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:38,039 INFO:     Epoch: 23
2022-11-23 02:23:38,901 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8172443238171664, 'Total loss': 0.8172443238171664} | train loss {'Reaction outcome loss': 0.8253309933408615, 'Total loss': 0.8253309933408615}
2022-11-23 02:23:38,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:38,902 INFO:     Epoch: 24
2022-11-23 02:23:39,733 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8347168110988357, 'Total loss': 0.8347168110988357} | train loss {'Reaction outcome loss': 0.8189120822616162, 'Total loss': 0.8189120822616162}
2022-11-23 02:23:39,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:39,734 INFO:     Epoch: 25
2022-11-23 02:23:40,510 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.815525775605982, 'Total loss': 0.815525775605982} | train loss {'Reaction outcome loss': 0.8184283805950996, 'Total loss': 0.8184283805950996}
2022-11-23 02:23:40,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:40,510 INFO:     Epoch: 26
2022-11-23 02:23:41,316 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.816300130025907, 'Total loss': 0.816300130025907} | train loss {'Reaction outcome loss': 0.8188441134989262, 'Total loss': 0.8188441134989262}
2022-11-23 02:23:41,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:41,317 INFO:     Epoch: 27
2022-11-23 02:23:42,118 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8223262883045457, 'Total loss': 0.8223262883045457} | train loss {'Reaction outcome loss': 0.8230746239423752, 'Total loss': 0.8230746239423752}
2022-11-23 02:23:42,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:42,118 INFO:     Epoch: 28
2022-11-23 02:23:42,926 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8129761178385128, 'Total loss': 0.8129761178385128} | train loss {'Reaction outcome loss': 0.8236580986169076, 'Total loss': 0.8236580986169076}
2022-11-23 02:23:42,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:42,926 INFO:     Epoch: 29
2022-11-23 02:23:43,776 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8222096731716936, 'Total loss': 0.8222096731716936} | train loss {'Reaction outcome loss': 0.8229919549438262, 'Total loss': 0.8229919549438262}
2022-11-23 02:23:43,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:43,777 INFO:     Epoch: 30
2022-11-23 02:23:44,575 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8236088942397725, 'Total loss': 0.8236088942397725} | train loss {'Reaction outcome loss': 0.8177143296887798, 'Total loss': 0.8177143296887798}
2022-11-23 02:23:44,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:44,575 INFO:     Epoch: 31
2022-11-23 02:23:45,421 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8154638822783123, 'Total loss': 0.8154638822783123} | train loss {'Reaction outcome loss': 0.8269976701947951, 'Total loss': 0.8269976701947951}
2022-11-23 02:23:45,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:45,422 INFO:     Epoch: 32
2022-11-23 02:23:46,205 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8094899701801214, 'Total loss': 0.8094899701801214} | train loss {'Reaction outcome loss': 0.823583173175012, 'Total loss': 0.823583173175012}
2022-11-23 02:23:46,206 INFO:     Found new best model at epoch 32
2022-11-23 02:23:46,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:46,208 INFO:     Epoch: 33
2022-11-23 02:23:47,039 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8084905946796591, 'Total loss': 0.8084905946796591} | train loss {'Reaction outcome loss': 0.8201941904281417, 'Total loss': 0.8201941904281417}
2022-11-23 02:23:47,039 INFO:     Found new best model at epoch 33
2022-11-23 02:23:47,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:47,040 INFO:     Epoch: 34
2022-11-23 02:23:47,879 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.810653916136785, 'Total loss': 0.810653916136785} | train loss {'Reaction outcome loss': 0.8214861756611255, 'Total loss': 0.8214861756611255}
2022-11-23 02:23:47,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:47,879 INFO:     Epoch: 35
2022-11-23 02:23:48,716 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8335399200970476, 'Total loss': 0.8335399200970476} | train loss {'Reaction outcome loss': 0.8163739457245796, 'Total loss': 0.8163739457245796}
2022-11-23 02:23:48,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:48,716 INFO:     Epoch: 36
2022-11-23 02:23:49,542 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8199336589737372, 'Total loss': 0.8199336589737372} | train loss {'Reaction outcome loss': 0.8208814349866682, 'Total loss': 0.8208814349866682}
2022-11-23 02:23:49,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:49,542 INFO:     Epoch: 37
2022-11-23 02:23:50,377 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8406310352412137, 'Total loss': 0.8406310352412137} | train loss {'Reaction outcome loss': 0.8120077663972494, 'Total loss': 0.8120077663972494}
2022-11-23 02:23:50,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:50,377 INFO:     Epoch: 38
2022-11-23 02:23:51,185 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8155048543756659, 'Total loss': 0.8155048543756659} | train loss {'Reaction outcome loss': 0.8156225981130716, 'Total loss': 0.8156225981130716}
2022-11-23 02:23:51,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:51,185 INFO:     Epoch: 39
2022-11-23 02:23:51,977 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8246493800119921, 'Total loss': 0.8246493800119921} | train loss {'Reaction outcome loss': 0.8127298018624706, 'Total loss': 0.8127298018624706}
2022-11-23 02:23:51,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:51,977 INFO:     Epoch: 40
2022-11-23 02:23:52,789 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8325878808444197, 'Total loss': 0.8325878808444197} | train loss {'Reaction outcome loss': 0.8140779612285476, 'Total loss': 0.8140779612285476}
2022-11-23 02:23:52,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:52,789 INFO:     Epoch: 41
2022-11-23 02:23:53,598 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8442418934269385, 'Total loss': 0.8442418934269385} | train loss {'Reaction outcome loss': 0.8130008345169406, 'Total loss': 0.8130008345169406}
2022-11-23 02:23:53,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:53,598 INFO:     Epoch: 42
2022-11-23 02:23:54,385 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.819636001505635, 'Total loss': 0.819636001505635} | train loss {'Reaction outcome loss': 0.8156380869688526, 'Total loss': 0.8156380869688526}
2022-11-23 02:23:54,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:54,386 INFO:     Epoch: 43
2022-11-23 02:23:55,214 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8241911401802843, 'Total loss': 0.8241911401802843} | train loss {'Reaction outcome loss': 0.8129712960893108, 'Total loss': 0.8129712960893108}
2022-11-23 02:23:55,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:55,215 INFO:     Epoch: 44
2022-11-23 02:23:56,076 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8349842612038959, 'Total loss': 0.8349842612038959} | train loss {'Reaction outcome loss': 0.8107407093048096, 'Total loss': 0.8107407093048096}
2022-11-23 02:23:56,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:56,076 INFO:     Epoch: 45
2022-11-23 02:23:56,907 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8041279458186843, 'Total loss': 0.8041279458186843} | train loss {'Reaction outcome loss': 0.810563889121817, 'Total loss': 0.810563889121817}
2022-11-23 02:23:56,907 INFO:     Found new best model at epoch 45
2022-11-23 02:23:56,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:56,908 INFO:     Epoch: 46
2022-11-23 02:23:57,708 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8085174750198018, 'Total loss': 0.8085174750198018} | train loss {'Reaction outcome loss': 0.8071947165073887, 'Total loss': 0.8071947165073887}
2022-11-23 02:23:57,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:57,709 INFO:     Epoch: 47
2022-11-23 02:23:58,479 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8187445571476762, 'Total loss': 0.8187445571476762} | train loss {'Reaction outcome loss': 0.8157243134994661, 'Total loss': 0.8157243134994661}
2022-11-23 02:23:58,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:58,480 INFO:     Epoch: 48
2022-11-23 02:23:59,290 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8057810948653654, 'Total loss': 0.8057810948653654} | train loss {'Reaction outcome loss': 0.8068910887645137, 'Total loss': 0.8068910887645137}
2022-11-23 02:23:59,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:23:59,290 INFO:     Epoch: 49
2022-11-23 02:24:00,094 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8553736487572844, 'Total loss': 0.8553736487572844} | train loss {'Reaction outcome loss': 0.8052344026584779, 'Total loss': 0.8052344026584779}
2022-11-23 02:24:00,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:00,094 INFO:     Epoch: 50
2022-11-23 02:24:00,934 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8412703858180479, 'Total loss': 0.8412703858180479} | train loss {'Reaction outcome loss': 0.8008926564887646, 'Total loss': 0.8008926564887646}
2022-11-23 02:24:00,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:00,934 INFO:     Epoch: 51
2022-11-23 02:24:01,722 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8371279618956826, 'Total loss': 0.8371279618956826} | train loss {'Reaction outcome loss': 0.798690194023713, 'Total loss': 0.798690194023713}
2022-11-23 02:24:01,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:01,722 INFO:     Epoch: 52
2022-11-23 02:24:02,546 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8306880620392886, 'Total loss': 0.8306880620392886} | train loss {'Reaction outcome loss': 0.8001124268818286, 'Total loss': 0.8001124268818286}
2022-11-23 02:24:02,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:02,546 INFO:     Epoch: 53
2022-11-23 02:24:03,354 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7944650202989578, 'Total loss': 0.7944650202989578} | train loss {'Reaction outcome loss': 0.8074327852697142, 'Total loss': 0.8074327852697142}
2022-11-23 02:24:03,354 INFO:     Found new best model at epoch 53
2022-11-23 02:24:03,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:03,355 INFO:     Epoch: 54
2022-11-23 02:24:04,181 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7939209965142336, 'Total loss': 0.7939209965142336} | train loss {'Reaction outcome loss': 0.7932597528542241, 'Total loss': 0.7932597528542241}
2022-11-23 02:24:04,182 INFO:     Found new best model at epoch 54
2022-11-23 02:24:04,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:04,183 INFO:     Epoch: 55
2022-11-23 02:24:05,022 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8031016953966834, 'Total loss': 0.8031016953966834} | train loss {'Reaction outcome loss': 0.8009833258486563, 'Total loss': 0.8009833258486563}
2022-11-23 02:24:05,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:05,023 INFO:     Epoch: 56
2022-11-23 02:24:05,860 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7826353900811889, 'Total loss': 0.7826353900811889} | train loss {'Reaction outcome loss': 0.792338204359816, 'Total loss': 0.792338204359816}
2022-11-23 02:24:05,860 INFO:     Found new best model at epoch 56
2022-11-23 02:24:05,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:05,861 INFO:     Epoch: 57
2022-11-23 02:24:06,646 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.795816111293706, 'Total loss': 0.795816111293706} | train loss {'Reaction outcome loss': 0.7933107411428806, 'Total loss': 0.7933107411428806}
2022-11-23 02:24:06,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:06,647 INFO:     Epoch: 58
2022-11-23 02:24:07,454 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7927803234620527, 'Total loss': 0.7927803234620527} | train loss {'Reaction outcome loss': 0.7963126704337136, 'Total loss': 0.7963126704337136}
2022-11-23 02:24:07,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:07,455 INFO:     Epoch: 59
2022-11-23 02:24:08,249 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8163245022296906, 'Total loss': 0.8163245022296906} | train loss {'Reaction outcome loss': 0.7876268122946063, 'Total loss': 0.7876268122946063}
2022-11-23 02:24:08,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:08,249 INFO:     Epoch: 60
2022-11-23 02:24:09,032 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7967060438611291, 'Total loss': 0.7967060438611291} | train loss {'Reaction outcome loss': 0.7925083120503733, 'Total loss': 0.7925083120503733}
2022-11-23 02:24:09,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:09,032 INFO:     Epoch: 61
2022-11-23 02:24:09,817 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7960070744156837, 'Total loss': 0.7960070744156837} | train loss {'Reaction outcome loss': 0.7926736252923166, 'Total loss': 0.7926736252923166}
2022-11-23 02:24:09,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:09,818 INFO:     Epoch: 62
2022-11-23 02:24:10,593 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7815490520813249, 'Total loss': 0.7815490520813249} | train loss {'Reaction outcome loss': 0.7896666410228899, 'Total loss': 0.7896666410228899}
2022-11-23 02:24:10,594 INFO:     Found new best model at epoch 62
2022-11-23 02:24:10,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:10,595 INFO:     Epoch: 63
2022-11-23 02:24:11,371 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7898639257658612, 'Total loss': 0.7898639257658612} | train loss {'Reaction outcome loss': 0.7913949966671006, 'Total loss': 0.7913949966671006}
2022-11-23 02:24:11,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:11,372 INFO:     Epoch: 64
2022-11-23 02:24:12,163 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7918947813185778, 'Total loss': 0.7918947813185778} | train loss {'Reaction outcome loss': 0.7813183309570435, 'Total loss': 0.7813183309570435}
2022-11-23 02:24:12,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:12,163 INFO:     Epoch: 65
2022-11-23 02:24:12,963 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8129070414738222, 'Total loss': 0.8129070414738222} | train loss {'Reaction outcome loss': 0.7768455246283162, 'Total loss': 0.7768455246283162}
2022-11-23 02:24:12,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:12,963 INFO:     Epoch: 66
2022-11-23 02:24:13,774 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7913627340035005, 'Total loss': 0.7913627340035005} | train loss {'Reaction outcome loss': 0.7872685379078311, 'Total loss': 0.7872685379078311}
2022-11-23 02:24:13,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:13,774 INFO:     Epoch: 67
2022-11-23 02:24:14,537 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.779382738200101, 'Total loss': 0.779382738200101} | train loss {'Reaction outcome loss': 0.7701296730627937, 'Total loss': 0.7701296730627937}
2022-11-23 02:24:14,537 INFO:     Found new best model at epoch 67
2022-11-23 02:24:14,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:14,538 INFO:     Epoch: 68
2022-11-23 02:24:15,324 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7631889622319828, 'Total loss': 0.7631889622319828} | train loss {'Reaction outcome loss': 0.7767687945836975, 'Total loss': 0.7767687945836975}
2022-11-23 02:24:15,324 INFO:     Found new best model at epoch 68
2022-11-23 02:24:15,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:15,325 INFO:     Epoch: 69
2022-11-23 02:24:16,118 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8095889511433515, 'Total loss': 0.8095889511433515} | train loss {'Reaction outcome loss': 0.7711667997702476, 'Total loss': 0.7711667997702476}
2022-11-23 02:24:16,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:16,119 INFO:     Epoch: 70
2022-11-23 02:24:16,883 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7572974901307713, 'Total loss': 0.7572974901307713} | train loss {'Reaction outcome loss': 0.7711057781932815, 'Total loss': 0.7711057781932815}
2022-11-23 02:24:16,883 INFO:     Found new best model at epoch 70
2022-11-23 02:24:16,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:16,884 INFO:     Epoch: 71
2022-11-23 02:24:17,662 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7589832882989537, 'Total loss': 0.7589832882989537} | train loss {'Reaction outcome loss': 0.764203618250547, 'Total loss': 0.764203618250547}
2022-11-23 02:24:17,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:17,663 INFO:     Epoch: 72
2022-11-23 02:24:18,450 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7547463828867133, 'Total loss': 0.7547463828867133} | train loss {'Reaction outcome loss': 0.7631168682729045, 'Total loss': 0.7631168682729045}
2022-11-23 02:24:18,450 INFO:     Found new best model at epoch 72
2022-11-23 02:24:18,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:18,451 INFO:     Epoch: 73
2022-11-23 02:24:19,254 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7543567073616114, 'Total loss': 0.7543567073616114} | train loss {'Reaction outcome loss': 0.759865929522822, 'Total loss': 0.759865929522822}
2022-11-23 02:24:19,254 INFO:     Found new best model at epoch 73
2022-11-23 02:24:19,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:19,255 INFO:     Epoch: 74
2022-11-23 02:24:20,031 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7744289433414285, 'Total loss': 0.7744289433414285} | train loss {'Reaction outcome loss': 0.7450267542754451, 'Total loss': 0.7450267542754451}
2022-11-23 02:24:20,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:20,032 INFO:     Epoch: 75
2022-11-23 02:24:20,841 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7071701281450011, 'Total loss': 0.7071701281450011} | train loss {'Reaction outcome loss': 0.7300456324892659, 'Total loss': 0.7300456324892659}
2022-11-23 02:24:20,841 INFO:     Found new best model at epoch 75
2022-11-23 02:24:20,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:20,842 INFO:     Epoch: 76
2022-11-23 02:24:21,664 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7032359052788127, 'Total loss': 0.7032359052788127} | train loss {'Reaction outcome loss': 0.7272944089866453, 'Total loss': 0.7272944089866453}
2022-11-23 02:24:21,665 INFO:     Found new best model at epoch 76
2022-11-23 02:24:21,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:21,666 INFO:     Epoch: 77
2022-11-23 02:24:22,454 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7488876228982752, 'Total loss': 0.7488876228982752} | train loss {'Reaction outcome loss': 0.7185108537875837, 'Total loss': 0.7185108537875837}
2022-11-23 02:24:22,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:22,454 INFO:     Epoch: 78
2022-11-23 02:24:23,240 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7122287628325549, 'Total loss': 0.7122287628325549} | train loss {'Reaction outcome loss': 0.6833880665081162, 'Total loss': 0.6833880665081162}
2022-11-23 02:24:23,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:23,240 INFO:     Epoch: 79
2022-11-23 02:24:24,096 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6942457245154814, 'Total loss': 0.6942457245154814} | train loss {'Reaction outcome loss': 0.6837708583522227, 'Total loss': 0.6837708583522227}
2022-11-23 02:24:24,096 INFO:     Found new best model at epoch 79
2022-11-23 02:24:24,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:24,097 INFO:     Epoch: 80
2022-11-23 02:24:24,881 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7229455878788774, 'Total loss': 0.7229455878788774} | train loss {'Reaction outcome loss': 0.6652523202280844, 'Total loss': 0.6652523202280844}
2022-11-23 02:24:24,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:24,881 INFO:     Epoch: 81
2022-11-23 02:24:25,734 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6572370671413161, 'Total loss': 0.6572370671413161} | train loss {'Reaction outcome loss': 0.6502540238922642, 'Total loss': 0.6502540238922642}
2022-11-23 02:24:25,734 INFO:     Found new best model at epoch 81
2022-11-23 02:24:25,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:25,735 INFO:     Epoch: 82
2022-11-23 02:24:26,533 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7019368789412759, 'Total loss': 0.7019368789412759} | train loss {'Reaction outcome loss': 0.657805590079196, 'Total loss': 0.657805590079196}
2022-11-23 02:24:26,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:26,534 INFO:     Epoch: 83
2022-11-23 02:24:27,383 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.6770707328211177, 'Total loss': 0.6770707328211177} | train loss {'Reaction outcome loss': 0.6426926079776979, 'Total loss': 0.6426926079776979}
2022-11-23 02:24:27,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:27,383 INFO:     Epoch: 84
2022-11-23 02:24:28,240 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6160961748524145, 'Total loss': 0.6160961748524145} | train loss {'Reaction outcome loss': 0.634404561211986, 'Total loss': 0.634404561211986}
2022-11-23 02:24:28,241 INFO:     Found new best model at epoch 84
2022-11-23 02:24:28,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:28,242 INFO:     Epoch: 85
2022-11-23 02:24:29,067 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5881575549190695, 'Total loss': 0.5881575549190695} | train loss {'Reaction outcome loss': 0.6177485304013375, 'Total loss': 0.6177485304013375}
2022-11-23 02:24:29,069 INFO:     Found new best model at epoch 85
2022-11-23 02:24:29,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:29,070 INFO:     Epoch: 86
2022-11-23 02:24:29,870 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5820617899298668, 'Total loss': 0.5820617899298668} | train loss {'Reaction outcome loss': 0.6012206740316844, 'Total loss': 0.6012206740316844}
2022-11-23 02:24:29,870 INFO:     Found new best model at epoch 86
2022-11-23 02:24:29,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:29,871 INFO:     Epoch: 87
2022-11-23 02:24:30,666 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6294205073605884, 'Total loss': 0.6294205073605884} | train loss {'Reaction outcome loss': 0.597332100954748, 'Total loss': 0.597332100954748}
2022-11-23 02:24:30,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:30,666 INFO:     Epoch: 88
2022-11-23 02:24:31,462 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.635335387154059, 'Total loss': 0.635335387154059} | train loss {'Reaction outcome loss': 0.5859252860949885, 'Total loss': 0.5859252860949885}
2022-11-23 02:24:31,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:31,463 INFO:     Epoch: 89
2022-11-23 02:24:32,266 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5778261897238818, 'Total loss': 0.5778261897238818} | train loss {'Reaction outcome loss': 0.5886063395488647, 'Total loss': 0.5886063395488647}
2022-11-23 02:24:32,266 INFO:     Found new best model at epoch 89
2022-11-23 02:24:32,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:32,267 INFO:     Epoch: 90
2022-11-23 02:24:33,086 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5834177414124663, 'Total loss': 0.5834177414124663} | train loss {'Reaction outcome loss': 0.590757657924006, 'Total loss': 0.590757657924006}
2022-11-23 02:24:33,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:33,086 INFO:     Epoch: 91
2022-11-23 02:24:33,925 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5540111430666663, 'Total loss': 0.5540111430666663} | train loss {'Reaction outcome loss': 0.5931155459294396, 'Total loss': 0.5931155459294396}
2022-11-23 02:24:33,925 INFO:     Found new best model at epoch 91
2022-11-23 02:24:33,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:33,926 INFO:     Epoch: 92
2022-11-23 02:24:34,714 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.575602962212129, 'Total loss': 0.575602962212129} | train loss {'Reaction outcome loss': 0.5786165508531755, 'Total loss': 0.5786165508531755}
2022-11-23 02:24:34,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:34,714 INFO:     Epoch: 93
2022-11-23 02:24:35,529 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5984674035148188, 'Total loss': 0.5984674035148188} | train loss {'Reaction outcome loss': 0.5802446621800622, 'Total loss': 0.5802446621800622}
2022-11-23 02:24:35,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:35,530 INFO:     Epoch: 94
2022-11-23 02:24:36,308 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.593709565021775, 'Total loss': 0.593709565021775} | train loss {'Reaction outcome loss': 0.5839034806215956, 'Total loss': 0.5839034806215956}
2022-11-23 02:24:36,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:36,308 INFO:     Epoch: 95
2022-11-23 02:24:37,097 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6085084202614698, 'Total loss': 0.6085084202614698} | train loss {'Reaction outcome loss': 0.593548669149318, 'Total loss': 0.593548669149318}
2022-11-23 02:24:37,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:37,097 INFO:     Epoch: 96
2022-11-23 02:24:37,922 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5865368883718144, 'Total loss': 0.5865368883718144} | train loss {'Reaction outcome loss': 0.5737269444451216, 'Total loss': 0.5737269444451216}
2022-11-23 02:24:37,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:37,922 INFO:     Epoch: 97
2022-11-23 02:24:38,734 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5836698832837018, 'Total loss': 0.5836698832837018} | train loss {'Reaction outcome loss': 0.580350273318829, 'Total loss': 0.580350273318829}
2022-11-23 02:24:38,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:38,734 INFO:     Epoch: 98
2022-11-23 02:24:39,555 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5758307284929536, 'Total loss': 0.5758307284929536} | train loss {'Reaction outcome loss': 0.5706588731658074, 'Total loss': 0.5706588731658074}
2022-11-23 02:24:39,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:39,555 INFO:     Epoch: 99
2022-11-23 02:24:40,354 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.584431451829997, 'Total loss': 0.584431451829997} | train loss {'Reaction outcome loss': 0.5722111119257827, 'Total loss': 0.5722111119257827}
2022-11-23 02:24:40,354 INFO:     Best model found after epoch 92 of 100.
2022-11-23 02:24:40,354 INFO:   Done with stage: TRAINING
2022-11-23 02:24:40,355 INFO:   Starting stage: EVALUATION
2022-11-23 02:24:40,473 INFO:   Done with stage: EVALUATION
2022-11-23 02:24:40,473 INFO:   Leaving out SEQ value Fold_8
2022-11-23 02:24:40,486 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 02:24:40,486 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:24:41,162 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:24:41,162 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:24:41,235 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:24:41,235 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:24:41,235 INFO:     No hyperparam tuning for this model
2022-11-23 02:24:41,235 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:24:41,235 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:24:41,236 INFO:     None feature selector for col prot
2022-11-23 02:24:41,236 INFO:     None feature selector for col prot
2022-11-23 02:24:41,236 INFO:     None feature selector for col prot
2022-11-23 02:24:41,237 INFO:     None feature selector for col chem
2022-11-23 02:24:41,237 INFO:     None feature selector for col chem
2022-11-23 02:24:41,237 INFO:     None feature selector for col chem
2022-11-23 02:24:41,237 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:24:41,237 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:24:41,239 INFO:     Number of params in model 168571
2022-11-23 02:24:41,242 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:24:41,242 INFO:   Starting stage: TRAINING
2022-11-23 02:24:41,300 INFO:     Val loss before train {'Reaction outcome loss': 1.0071953535079956, 'Total loss': 1.0071953535079956}
2022-11-23 02:24:41,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:41,300 INFO:     Epoch: 0
2022-11-23 02:24:42,106 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8537579036571763, 'Total loss': 0.8537579036571763} | train loss {'Reaction outcome loss': 0.8776127970948511, 'Total loss': 0.8776127970948511}
2022-11-23 02:24:42,106 INFO:     Found new best model at epoch 0
2022-11-23 02:24:42,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:42,107 INFO:     Epoch: 1
2022-11-23 02:24:42,873 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8341961692680012, 'Total loss': 0.8341961692680012} | train loss {'Reaction outcome loss': 0.8506161043838579, 'Total loss': 0.8506161043838579}
2022-11-23 02:24:42,873 INFO:     Found new best model at epoch 1
2022-11-23 02:24:42,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:42,874 INFO:     Epoch: 2
2022-11-23 02:24:43,731 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8475800054994497, 'Total loss': 0.8475800054994497} | train loss {'Reaction outcome loss': 0.8386282312626742, 'Total loss': 0.8386282312626742}
2022-11-23 02:24:43,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:43,731 INFO:     Epoch: 3
2022-11-23 02:24:44,531 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8598211231556806, 'Total loss': 0.8598211231556806} | train loss {'Reaction outcome loss': 0.8335462607899491, 'Total loss': 0.8335462607899491}
2022-11-23 02:24:44,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:44,531 INFO:     Epoch: 4
2022-11-23 02:24:45,338 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.854197505522858, 'Total loss': 0.854197505522858} | train loss {'Reaction outcome loss': 0.829193207317469, 'Total loss': 0.829193207317469}
2022-11-23 02:24:45,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:45,338 INFO:     Epoch: 5
2022-11-23 02:24:46,114 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8448522903702476, 'Total loss': 0.8448522903702476} | train loss {'Reaction outcome loss': 0.8241974056983481, 'Total loss': 0.8241974056983481}
2022-11-23 02:24:46,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:46,114 INFO:     Epoch: 6
2022-11-23 02:24:46,906 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8253901966593482, 'Total loss': 0.8253901966593482} | train loss {'Reaction outcome loss': 0.8228559715407235, 'Total loss': 0.8228559715407235}
2022-11-23 02:24:46,906 INFO:     Found new best model at epoch 6
2022-11-23 02:24:46,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:46,907 INFO:     Epoch: 7
2022-11-23 02:24:47,709 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8472611904144287, 'Total loss': 0.8472611904144287} | train loss {'Reaction outcome loss': 0.8214776963603739, 'Total loss': 0.8214776963603739}
2022-11-23 02:24:47,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:47,710 INFO:     Epoch: 8
2022-11-23 02:24:48,514 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8749131655151193, 'Total loss': 0.8749131655151193} | train loss {'Reaction outcome loss': 0.8222951946209888, 'Total loss': 0.8222951946209888}
2022-11-23 02:24:48,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:48,514 INFO:     Epoch: 9
2022-11-23 02:24:49,306 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8143172027035193, 'Total loss': 0.8143172027035193} | train loss {'Reaction outcome loss': 0.8204636002073482, 'Total loss': 0.8204636002073482}
2022-11-23 02:24:49,306 INFO:     Found new best model at epoch 9
2022-11-23 02:24:49,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:49,307 INFO:     Epoch: 10
2022-11-23 02:24:50,074 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.830464168028398, 'Total loss': 0.830464168028398} | train loss {'Reaction outcome loss': 0.8220236582415444, 'Total loss': 0.8220236582415444}
2022-11-23 02:24:50,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:50,074 INFO:     Epoch: 11
2022-11-23 02:24:50,876 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8257459205659953, 'Total loss': 0.8257459205659953} | train loss {'Reaction outcome loss': 0.8201811830608212, 'Total loss': 0.8201811830608212}
2022-11-23 02:24:50,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:50,877 INFO:     Epoch: 12
2022-11-23 02:24:51,627 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.845875462347811, 'Total loss': 0.845875462347811} | train loss {'Reaction outcome loss': 0.8160399924735634, 'Total loss': 0.8160399924735634}
2022-11-23 02:24:51,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:51,627 INFO:     Epoch: 13
2022-11-23 02:24:52,437 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8676315383477644, 'Total loss': 0.8676315383477644} | train loss {'Reaction outcome loss': 0.8159922464769713, 'Total loss': 0.8159922464769713}
2022-11-23 02:24:52,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:52,437 INFO:     Epoch: 14
2022-11-23 02:24:53,242 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8258651860735633, 'Total loss': 0.8258651860735633} | train loss {'Reaction outcome loss': 0.8175564622392459, 'Total loss': 0.8175564622392459}
2022-11-23 02:24:53,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:53,242 INFO:     Epoch: 15
2022-11-23 02:24:53,989 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8456186760555614, 'Total loss': 0.8456186760555614} | train loss {'Reaction outcome loss': 0.8188680966289676, 'Total loss': 0.8188680966289676}
2022-11-23 02:24:53,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:53,989 INFO:     Epoch: 16
2022-11-23 02:24:54,745 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8362350111657922, 'Total loss': 0.8362350111657922} | train loss {'Reaction outcome loss': 0.8170990587497244, 'Total loss': 0.8170990587497244}
2022-11-23 02:24:54,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:54,745 INFO:     Epoch: 17
2022-11-23 02:24:55,519 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8331580432978544, 'Total loss': 0.8331580432978544} | train loss {'Reaction outcome loss': 0.8178578258777152, 'Total loss': 0.8178578258777152}
2022-11-23 02:24:55,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:55,519 INFO:     Epoch: 18
2022-11-23 02:24:56,299 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.829102296043526, 'Total loss': 0.829102296043526} | train loss {'Reaction outcome loss': 0.8171987014157431, 'Total loss': 0.8171987014157431}
2022-11-23 02:24:56,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:56,299 INFO:     Epoch: 19
2022-11-23 02:24:57,079 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.827353447675705, 'Total loss': 0.827353447675705} | train loss {'Reaction outcome loss': 0.8161038839087195, 'Total loss': 0.8161038839087195}
2022-11-23 02:24:57,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:57,079 INFO:     Epoch: 20
2022-11-23 02:24:57,855 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8327562456781213, 'Total loss': 0.8327562456781213} | train loss {'Reaction outcome loss': 0.8169854240758079, 'Total loss': 0.8169854240758079}
2022-11-23 02:24:57,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:57,855 INFO:     Epoch: 21
2022-11-23 02:24:58,631 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8302980688485232, 'Total loss': 0.8302980688485232} | train loss {'Reaction outcome loss': 0.8156371464534682, 'Total loss': 0.8156371464534682}
2022-11-23 02:24:58,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:58,632 INFO:     Epoch: 22
2022-11-23 02:24:59,402 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8412226763638583, 'Total loss': 0.8412226763638583} | train loss {'Reaction outcome loss': 0.8167777585739993, 'Total loss': 0.8167777585739993}
2022-11-23 02:24:59,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:24:59,402 INFO:     Epoch: 23
2022-11-23 02:25:00,196 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8671210597861897, 'Total loss': 0.8671210597861897} | train loss {'Reaction outcome loss': 0.8147352174836762, 'Total loss': 0.8147352174836762}
2022-11-23 02:25:00,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:00,197 INFO:     Epoch: 24
2022-11-23 02:25:00,970 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8452398533170874, 'Total loss': 0.8452398533170874} | train loss {'Reaction outcome loss': 0.813145967892238, 'Total loss': 0.813145967892238}
2022-11-23 02:25:00,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:00,971 INFO:     Epoch: 25
2022-11-23 02:25:01,744 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8158704001795162, 'Total loss': 0.8158704001795162} | train loss {'Reaction outcome loss': 0.8194461846838192, 'Total loss': 0.8194461846838192}
2022-11-23 02:25:01,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:01,745 INFO:     Epoch: 26
2022-11-23 02:25:02,506 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8341836834495718, 'Total loss': 0.8341836834495718} | train loss {'Reaction outcome loss': 0.8164325282281759, 'Total loss': 0.8164325282281759}
2022-11-23 02:25:02,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:02,506 INFO:     Epoch: 27
2022-11-23 02:25:03,258 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.829212099313736, 'Total loss': 0.829212099313736} | train loss {'Reaction outcome loss': 0.8154553083740935, 'Total loss': 0.8154553083740935}
2022-11-23 02:25:03,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:03,259 INFO:     Epoch: 28
2022-11-23 02:25:04,026 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8303188011050224, 'Total loss': 0.8303188011050224} | train loss {'Reaction outcome loss': 0.8167995019226658, 'Total loss': 0.8167995019226658}
2022-11-23 02:25:04,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:04,027 INFO:     Epoch: 29
2022-11-23 02:25:04,821 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8161851486021822, 'Total loss': 0.8161851486021822} | train loss {'Reaction outcome loss': 0.8183110924399629, 'Total loss': 0.8183110924399629}
2022-11-23 02:25:04,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:04,821 INFO:     Epoch: 30
2022-11-23 02:25:05,593 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8543771593408152, 'Total loss': 0.8543771593408152} | train loss {'Reaction outcome loss': 0.81539053965588, 'Total loss': 0.81539053965588}
2022-11-23 02:25:05,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:05,593 INFO:     Epoch: 31
2022-11-23 02:25:06,374 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8127506348219785, 'Total loss': 0.8127506348219785} | train loss {'Reaction outcome loss': 0.8160440826902584, 'Total loss': 0.8160440826902584}
2022-11-23 02:25:06,374 INFO:     Found new best model at epoch 31
2022-11-23 02:25:06,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:06,375 INFO:     Epoch: 32
2022-11-23 02:25:07,129 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8190619945526123, 'Total loss': 0.8190619945526123} | train loss {'Reaction outcome loss': 0.8148484593751479, 'Total loss': 0.8148484593751479}
2022-11-23 02:25:07,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:07,130 INFO:     Epoch: 33
2022-11-23 02:25:07,885 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8497390076518059, 'Total loss': 0.8497390076518059} | train loss {'Reaction outcome loss': 0.817057461884557, 'Total loss': 0.817057461884557}
2022-11-23 02:25:07,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:07,885 INFO:     Epoch: 34
2022-11-23 02:25:08,631 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8450598229061473, 'Total loss': 0.8450598229061473} | train loss {'Reaction outcome loss': 0.8184309778164844, 'Total loss': 0.8184309778164844}
2022-11-23 02:25:08,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:08,632 INFO:     Epoch: 35
2022-11-23 02:25:09,403 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.820455673743378, 'Total loss': 0.820455673743378} | train loss {'Reaction outcome loss': 0.8186221595929594, 'Total loss': 0.8186221595929594}
2022-11-23 02:25:09,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:09,404 INFO:     Epoch: 36
2022-11-23 02:25:10,177 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8140945522622629, 'Total loss': 0.8140945522622629} | train loss {'Reaction outcome loss': 0.814947027576213, 'Total loss': 0.814947027576213}
2022-11-23 02:25:10,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:10,177 INFO:     Epoch: 37
2022-11-23 02:25:10,934 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8117199330167337, 'Total loss': 0.8117199330167337} | train loss {'Reaction outcome loss': 0.8150785629846612, 'Total loss': 0.8150785629846612}
2022-11-23 02:25:10,934 INFO:     Found new best model at epoch 37
2022-11-23 02:25:10,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:10,935 INFO:     Epoch: 38
2022-11-23 02:25:11,730 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8315865986726501, 'Total loss': 0.8315865986726501} | train loss {'Reaction outcome loss': 0.8223829112490829, 'Total loss': 0.8223829112490829}
2022-11-23 02:25:11,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:11,731 INFO:     Epoch: 39
2022-11-23 02:25:12,496 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.823175158012997, 'Total loss': 0.823175158012997} | train loss {'Reaction outcome loss': 0.8131710413767367, 'Total loss': 0.8131710413767367}
2022-11-23 02:25:12,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:12,497 INFO:     Epoch: 40
2022-11-23 02:25:13,286 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8259096226908944, 'Total loss': 0.8259096226908944} | train loss {'Reaction outcome loss': 0.816885543842705, 'Total loss': 0.816885543842705}
2022-11-23 02:25:13,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:13,286 INFO:     Epoch: 41
2022-11-23 02:25:14,043 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8276799835942008, 'Total loss': 0.8276799835942008} | train loss {'Reaction outcome loss': 0.8142882800832086, 'Total loss': 0.8142882800832086}
2022-11-23 02:25:14,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:14,043 INFO:     Epoch: 42
2022-11-23 02:25:14,828 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8261049471118234, 'Total loss': 0.8261049471118234} | train loss {'Reaction outcome loss': 0.8170527930162391, 'Total loss': 0.8170527930162391}
2022-11-23 02:25:14,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:14,828 INFO:     Epoch: 43
2022-11-23 02:25:15,596 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8081307594071735, 'Total loss': 0.8081307594071735} | train loss {'Reaction outcome loss': 0.8179339170455933, 'Total loss': 0.8179339170455933}
2022-11-23 02:25:15,597 INFO:     Found new best model at epoch 43
2022-11-23 02:25:15,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:15,598 INFO:     Epoch: 44
2022-11-23 02:25:16,375 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8278661796992476, 'Total loss': 0.8278661796992476} | train loss {'Reaction outcome loss': 0.8189639267872791, 'Total loss': 0.8189639267872791}
2022-11-23 02:25:16,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:16,376 INFO:     Epoch: 45
2022-11-23 02:25:17,153 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8545283106240359, 'Total loss': 0.8545283106240359} | train loss {'Reaction outcome loss': 0.8133776499300587, 'Total loss': 0.8133776499300587}
2022-11-23 02:25:17,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:17,154 INFO:     Epoch: 46
2022-11-23 02:25:17,920 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8269662762230093, 'Total loss': 0.8269662762230093} | train loss {'Reaction outcome loss': 0.814923622048631, 'Total loss': 0.814923622048631}
2022-11-23 02:25:17,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:17,920 INFO:     Epoch: 47
2022-11-23 02:25:18,699 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8465187217701565, 'Total loss': 0.8465187217701565} | train loss {'Reaction outcome loss': 0.817213024655167, 'Total loss': 0.817213024655167}
2022-11-23 02:25:18,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:18,699 INFO:     Epoch: 48
2022-11-23 02:25:19,455 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8449090082537044, 'Total loss': 0.8449090082537044} | train loss {'Reaction outcome loss': 0.8148780754634313, 'Total loss': 0.8148780754634313}
2022-11-23 02:25:19,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:19,456 INFO:     Epoch: 49
2022-11-23 02:25:20,236 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8374159193851731, 'Total loss': 0.8374159193851731} | train loss {'Reaction outcome loss': 0.8107512983740592, 'Total loss': 0.8107512983740592}
2022-11-23 02:25:20,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:20,237 INFO:     Epoch: 50
2022-11-23 02:25:20,997 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8296877531842752, 'Total loss': 0.8296877531842752} | train loss {'Reaction outcome loss': 0.8172311460485264, 'Total loss': 0.8172311460485264}
2022-11-23 02:25:20,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:20,998 INFO:     Epoch: 51
2022-11-23 02:25:21,759 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.816959064792503, 'Total loss': 0.816959064792503} | train loss {'Reaction outcome loss': 0.8160848566464015, 'Total loss': 0.8160848566464015}
2022-11-23 02:25:21,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:21,760 INFO:     Epoch: 52
2022-11-23 02:25:22,541 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8362708406692202, 'Total loss': 0.8362708406692202} | train loss {'Reaction outcome loss': 0.8110347971624258, 'Total loss': 0.8110347971624258}
2022-11-23 02:25:22,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:22,541 INFO:     Epoch: 53
2022-11-23 02:25:23,306 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8157996318557046, 'Total loss': 0.8157996318557046} | train loss {'Reaction outcome loss': 0.8101144778485201, 'Total loss': 0.8101144778485201}
2022-11-23 02:25:23,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:23,306 INFO:     Epoch: 54
2022-11-23 02:25:24,075 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8182708675211127, 'Total loss': 0.8182708675211127} | train loss {'Reaction outcome loss': 0.8138190297447905, 'Total loss': 0.8138190297447905}
2022-11-23 02:25:24,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:24,075 INFO:     Epoch: 55
2022-11-23 02:25:24,868 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8225529586726968, 'Total loss': 0.8225529586726968} | train loss {'Reaction outcome loss': 0.8130464569646485, 'Total loss': 0.8130464569646485}
2022-11-23 02:25:24,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:24,869 INFO:     Epoch: 56
2022-11-23 02:25:25,637 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8102967671372674, 'Total loss': 0.8102967671372674} | train loss {'Reaction outcome loss': 0.8123192508609928, 'Total loss': 0.8123192508609928}
2022-11-23 02:25:25,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:25,637 INFO:     Epoch: 57
2022-11-23 02:25:26,396 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8197568465362896, 'Total loss': 0.8197568465362896} | train loss {'Reaction outcome loss': 0.8160880812576838, 'Total loss': 0.8160880812576838}
2022-11-23 02:25:26,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:26,397 INFO:     Epoch: 58
2022-11-23 02:25:27,154 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8127763779325918, 'Total loss': 0.8127763779325918} | train loss {'Reaction outcome loss': 0.8134334751537868, 'Total loss': 0.8134334751537868}
2022-11-23 02:25:27,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:27,154 INFO:     Epoch: 59
2022-11-23 02:25:27,947 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8382354026490991, 'Total loss': 0.8382354026490991} | train loss {'Reaction outcome loss': 0.8154690112386431, 'Total loss': 0.8154690112386431}
2022-11-23 02:25:27,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:27,947 INFO:     Epoch: 60
2022-11-23 02:25:28,715 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8245526565746828, 'Total loss': 0.8245526565746828} | train loss {'Reaction outcome loss': 0.8181708070696617, 'Total loss': 0.8181708070696617}
2022-11-23 02:25:28,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:28,715 INFO:     Epoch: 61
2022-11-23 02:25:29,485 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8279921141537753, 'Total loss': 0.8279921141537753} | train loss {'Reaction outcome loss': 0.8115131724853905, 'Total loss': 0.8115131724853905}
2022-11-23 02:25:29,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:29,485 INFO:     Epoch: 62
2022-11-23 02:25:30,237 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8317244462668896, 'Total loss': 0.8317244462668896} | train loss {'Reaction outcome loss': 0.8124653883126317, 'Total loss': 0.8124653883126317}
2022-11-23 02:25:30,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:30,238 INFO:     Epoch: 63
2022-11-23 02:25:30,998 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8360626738179814, 'Total loss': 0.8360626738179814} | train loss {'Reaction outcome loss': 0.8209562658047189, 'Total loss': 0.8209562658047189}
2022-11-23 02:25:30,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:30,998 INFO:     Epoch: 64
2022-11-23 02:25:31,747 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8346504555507139, 'Total loss': 0.8346504555507139} | train loss {'Reaction outcome loss': 0.8149027678431296, 'Total loss': 0.8149027678431296}
2022-11-23 02:25:31,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:31,748 INFO:     Epoch: 65
2022-11-23 02:25:32,515 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8519320582801645, 'Total loss': 0.8519320582801645} | train loss {'Reaction outcome loss': 0.8183529372117957, 'Total loss': 0.8183529372117957}
2022-11-23 02:25:32,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:32,515 INFO:     Epoch: 66
2022-11-23 02:25:33,284 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8293401815674522, 'Total loss': 0.8293401815674522} | train loss {'Reaction outcome loss': 0.8156800259132775, 'Total loss': 0.8156800259132775}
2022-11-23 02:25:33,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:33,284 INFO:     Epoch: 67
2022-11-23 02:25:34,065 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8251564705913718, 'Total loss': 0.8251564705913718} | train loss {'Reaction outcome loss': 0.8172245541397406, 'Total loss': 0.8172245541397406}
2022-11-23 02:25:34,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:34,066 INFO:     Epoch: 68
2022-11-23 02:25:34,821 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8292074007066813, 'Total loss': 0.8292074007066813} | train loss {'Reaction outcome loss': 0.8156683924246807, 'Total loss': 0.8156683924246807}
2022-11-23 02:25:34,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:34,821 INFO:     Epoch: 69
2022-11-23 02:25:35,595 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8054904429750009, 'Total loss': 0.8054904429750009} | train loss {'Reaction outcome loss': 0.8142288245716873, 'Total loss': 0.8142288245716873}
2022-11-23 02:25:35,595 INFO:     Found new best model at epoch 69
2022-11-23 02:25:35,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:35,596 INFO:     Epoch: 70
2022-11-23 02:25:36,346 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8270499550483443, 'Total loss': 0.8270499550483443} | train loss {'Reaction outcome loss': 0.8159948220058363, 'Total loss': 0.8159948220058363}
2022-11-23 02:25:36,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:36,346 INFO:     Epoch: 71
2022-11-23 02:25:37,156 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8153991733085025, 'Total loss': 0.8153991733085025} | train loss {'Reaction outcome loss': 0.8134899063986175, 'Total loss': 0.8134899063986175}
2022-11-23 02:25:37,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:37,157 INFO:     Epoch: 72
2022-11-23 02:25:37,944 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8386332480744882, 'Total loss': 0.8386332480744882} | train loss {'Reaction outcome loss': 0.8161290302568552, 'Total loss': 0.8161290302568552}
2022-11-23 02:25:37,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:37,945 INFO:     Epoch: 73
2022-11-23 02:25:38,756 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8283183439211412, 'Total loss': 0.8283183439211412} | train loss {'Reaction outcome loss': 0.8152790827410562, 'Total loss': 0.8152790827410562}
2022-11-23 02:25:38,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:38,757 INFO:     Epoch: 74
2022-11-23 02:25:39,539 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.836643207479607, 'Total loss': 0.836643207479607} | train loss {'Reaction outcome loss': 0.8158570563306614, 'Total loss': 0.8158570563306614}
2022-11-23 02:25:39,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:39,540 INFO:     Epoch: 75
2022-11-23 02:25:40,291 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8326542289419607, 'Total loss': 0.8326542289419607} | train loss {'Reaction outcome loss': 0.8136219064800106, 'Total loss': 0.8136219064800106}
2022-11-23 02:25:40,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:40,291 INFO:     Epoch: 76
2022-11-23 02:25:41,087 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8332720073786649, 'Total loss': 0.8332720073786649} | train loss {'Reaction outcome loss': 0.8091419921845806, 'Total loss': 0.8091419921845806}
2022-11-23 02:25:41,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:41,087 INFO:     Epoch: 77
2022-11-23 02:25:41,881 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8410251208327033, 'Total loss': 0.8410251208327033} | train loss {'Reaction outcome loss': 0.8162747977947702, 'Total loss': 0.8162747977947702}
2022-11-23 02:25:41,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:41,881 INFO:     Epoch: 78
2022-11-23 02:25:42,641 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.882192541252483, 'Total loss': 0.882192541252483} | train loss {'Reaction outcome loss': 0.8141756612427381, 'Total loss': 0.8141756612427381}
2022-11-23 02:25:42,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:42,641 INFO:     Epoch: 79
2022-11-23 02:25:43,411 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8282332393256101, 'Total loss': 0.8282332393256101} | train loss {'Reaction outcome loss': 0.8173515932900565, 'Total loss': 0.8173515932900565}
2022-11-23 02:25:43,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:43,412 INFO:     Epoch: 80
2022-11-23 02:25:44,196 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8122111999175765, 'Total loss': 0.8122111999175765} | train loss {'Reaction outcome loss': 0.8142650710076702, 'Total loss': 0.8142650710076702}
2022-11-23 02:25:44,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:44,196 INFO:     Epoch: 81
2022-11-23 02:25:44,983 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8383533778515729, 'Total loss': 0.8383533778515729} | train loss {'Reaction outcome loss': 0.8122443835346066, 'Total loss': 0.8122443835346066}
2022-11-23 02:25:44,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:44,983 INFO:     Epoch: 82
2022-11-23 02:25:45,785 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8307926817373796, 'Total loss': 0.8307926817373796} | train loss {'Reaction outcome loss': 0.8139260883233985, 'Total loss': 0.8139260883233985}
2022-11-23 02:25:45,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:45,785 INFO:     Epoch: 83
2022-11-23 02:25:46,575 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8172857747836546, 'Total loss': 0.8172857747836546} | train loss {'Reaction outcome loss': 0.8145928436396074, 'Total loss': 0.8145928436396074}
2022-11-23 02:25:46,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:46,575 INFO:     Epoch: 84
2022-11-23 02:25:47,363 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8339907445690848, 'Total loss': 0.8339907445690848} | train loss {'Reaction outcome loss': 0.8193566065661761, 'Total loss': 0.8193566065661761}
2022-11-23 02:25:47,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:47,364 INFO:     Epoch: 85
2022-11-23 02:25:48,144 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8217978125268762, 'Total loss': 0.8217978125268762} | train loss {'Reaction outcome loss': 0.8146685257249949, 'Total loss': 0.8146685257249949}
2022-11-23 02:25:48,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:48,144 INFO:     Epoch: 86
2022-11-23 02:25:48,897 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8277675611051646, 'Total loss': 0.8277675611051646} | train loss {'Reaction outcome loss': 0.8156342585476077, 'Total loss': 0.8156342585476077}
2022-11-23 02:25:48,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:48,897 INFO:     Epoch: 87
2022-11-23 02:25:49,688 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8264507123015143, 'Total loss': 0.8264507123015143} | train loss {'Reaction outcome loss': 0.8162366157891799, 'Total loss': 0.8162366157891799}
2022-11-23 02:25:49,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:49,688 INFO:     Epoch: 88
2022-11-23 02:25:50,467 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8353310471231287, 'Total loss': 0.8353310471231287} | train loss {'Reaction outcome loss': 0.8174593266175718, 'Total loss': 0.8174593266175718}
2022-11-23 02:25:50,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:50,468 INFO:     Epoch: 89
2022-11-23 02:25:51,227 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8213856999169696, 'Total loss': 0.8213856999169696} | train loss {'Reaction outcome loss': 0.8156673864442475, 'Total loss': 0.8156673864442475}
2022-11-23 02:25:51,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:51,228 INFO:     Epoch: 90
2022-11-23 02:25:51,995 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8290477347644892, 'Total loss': 0.8290477347644892} | train loss {'Reaction outcome loss': 0.8167077361320962, 'Total loss': 0.8167077361320962}
2022-11-23 02:25:51,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:51,995 INFO:     Epoch: 91
2022-11-23 02:25:52,778 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.857794580811804, 'Total loss': 0.857794580811804} | train loss {'Reaction outcome loss': 0.8131653879370008, 'Total loss': 0.8131653879370008}
2022-11-23 02:25:52,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:52,779 INFO:     Epoch: 92
2022-11-23 02:25:53,544 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8080776865509424, 'Total loss': 0.8080776865509424} | train loss {'Reaction outcome loss': 0.813260894892167, 'Total loss': 0.813260894892167}
2022-11-23 02:25:53,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:53,545 INFO:     Epoch: 93
2022-11-23 02:25:54,321 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8522321629253301, 'Total loss': 0.8522321629253301} | train loss {'Reaction outcome loss': 0.8136468602686512, 'Total loss': 0.8136468602686512}
2022-11-23 02:25:54,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:54,321 INFO:     Epoch: 94
2022-11-23 02:25:55,100 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8201248266480186, 'Total loss': 0.8201248266480186} | train loss {'Reaction outcome loss': 0.8152321641542474, 'Total loss': 0.8152321641542474}
2022-11-23 02:25:55,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:55,101 INFO:     Epoch: 95
2022-11-23 02:25:55,873 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8249115774577315, 'Total loss': 0.8249115774577315} | train loss {'Reaction outcome loss': 0.8090545411012611, 'Total loss': 0.8090545411012611}
2022-11-23 02:25:55,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:55,873 INFO:     Epoch: 96
2022-11-23 02:25:56,661 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8308930173516273, 'Total loss': 0.8308930173516273} | train loss {'Reaction outcome loss': 0.8146995044484431, 'Total loss': 0.8146995044484431}
2022-11-23 02:25:56,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:56,662 INFO:     Epoch: 97
2022-11-23 02:25:57,423 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8190588395703923, 'Total loss': 0.8190588395703923} | train loss {'Reaction outcome loss': 0.8093777998369567, 'Total loss': 0.8093777998369567}
2022-11-23 02:25:57,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:57,423 INFO:     Epoch: 98
2022-11-23 02:25:58,212 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8837849944829941, 'Total loss': 0.8837849944829941} | train loss {'Reaction outcome loss': 0.8181288946648033, 'Total loss': 0.8181288946648033}
2022-11-23 02:25:58,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:58,212 INFO:     Epoch: 99
2022-11-23 02:25:58,992 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8262917501005259, 'Total loss': 0.8262917501005259} | train loss {'Reaction outcome loss': 0.8138948784798992, 'Total loss': 0.8138948784798992}
2022-11-23 02:25:58,992 INFO:     Best model found after epoch 70 of 100.
2022-11-23 02:25:58,992 INFO:   Done with stage: TRAINING
2022-11-23 02:25:58,992 INFO:   Starting stage: EVALUATION
2022-11-23 02:25:59,124 INFO:   Done with stage: EVALUATION
2022-11-23 02:25:59,124 INFO:   Leaving out SEQ value Fold_9
2022-11-23 02:25:59,137 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:25:59,138 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:25:59,813 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:25:59,813 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:25:59,886 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:25:59,886 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:25:59,886 INFO:     No hyperparam tuning for this model
2022-11-23 02:25:59,886 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:25:59,886 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:25:59,887 INFO:     None feature selector for col prot
2022-11-23 02:25:59,887 INFO:     None feature selector for col prot
2022-11-23 02:25:59,887 INFO:     None feature selector for col prot
2022-11-23 02:25:59,888 INFO:     None feature selector for col chem
2022-11-23 02:25:59,888 INFO:     None feature selector for col chem
2022-11-23 02:25:59,888 INFO:     None feature selector for col chem
2022-11-23 02:25:59,888 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:25:59,888 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:25:59,890 INFO:     Number of params in model 168571
2022-11-23 02:25:59,893 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:25:59,893 INFO:   Starting stage: TRAINING
2022-11-23 02:25:59,951 INFO:     Val loss before train {'Reaction outcome loss': 1.016982232982462, 'Total loss': 1.016982232982462}
2022-11-23 02:25:59,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:25:59,951 INFO:     Epoch: 0
2022-11-23 02:26:00,723 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8956381624395197, 'Total loss': 0.8956381624395197} | train loss {'Reaction outcome loss': 0.8708234338866554, 'Total loss': 0.8708234338866554}
2022-11-23 02:26:00,724 INFO:     Found new best model at epoch 0
2022-11-23 02:26:00,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:00,725 INFO:     Epoch: 1
2022-11-23 02:26:01,507 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8691092133522034, 'Total loss': 0.8691092133522034} | train loss {'Reaction outcome loss': 0.8442155660284676, 'Total loss': 0.8442155660284676}
2022-11-23 02:26:01,507 INFO:     Found new best model at epoch 1
2022-11-23 02:26:01,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:01,508 INFO:     Epoch: 2
2022-11-23 02:26:02,284 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8493680953979492, 'Total loss': 0.8493680953979492} | train loss {'Reaction outcome loss': 0.839305125629371, 'Total loss': 0.839305125629371}
2022-11-23 02:26:02,284 INFO:     Found new best model at epoch 2
2022-11-23 02:26:02,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:02,285 INFO:     Epoch: 3
2022-11-23 02:26:03,070 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8563567684455351, 'Total loss': 0.8563567684455351} | train loss {'Reaction outcome loss': 0.8262911733873339, 'Total loss': 0.8262911733873339}
2022-11-23 02:26:03,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:03,071 INFO:     Epoch: 4
2022-11-23 02:26:03,865 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.872974999926307, 'Total loss': 0.872974999926307} | train loss {'Reaction outcome loss': 0.8260280377710396, 'Total loss': 0.8260280377710396}
2022-11-23 02:26:03,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:03,865 INFO:     Epoch: 5
2022-11-23 02:26:04,678 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8308657543225721, 'Total loss': 0.8308657543225721} | train loss {'Reaction outcome loss': 0.8229715604531137, 'Total loss': 0.8229715604531137}
2022-11-23 02:26:04,679 INFO:     Found new best model at epoch 5
2022-11-23 02:26:04,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:04,679 INFO:     Epoch: 6
2022-11-23 02:26:05,511 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8892567984082482, 'Total loss': 0.8892567984082482} | train loss {'Reaction outcome loss': 0.8186491427694255, 'Total loss': 0.8186491427694255}
2022-11-23 02:26:05,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:05,511 INFO:     Epoch: 7
2022-11-23 02:26:06,358 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8524780842390928, 'Total loss': 0.8524780842390928} | train loss {'Reaction outcome loss': 0.814661546274718, 'Total loss': 0.814661546274718}
2022-11-23 02:26:06,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:06,359 INFO:     Epoch: 8
2022-11-23 02:26:07,180 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8514015518806197, 'Total loss': 0.8514015518806197} | train loss {'Reaction outcome loss': 0.8153911843473612, 'Total loss': 0.8153911843473612}
2022-11-23 02:26:07,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:07,180 INFO:     Epoch: 9
2022-11-23 02:26:07,998 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8411240178075704, 'Total loss': 0.8411240178075704} | train loss {'Reaction outcome loss': 0.8171134070466887, 'Total loss': 0.8171134070466887}
2022-11-23 02:26:07,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:07,998 INFO:     Epoch: 10
2022-11-23 02:26:08,779 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8404140553691171, 'Total loss': 0.8404140553691171} | train loss {'Reaction outcome loss': 0.8204738476015778, 'Total loss': 0.8204738476015778}
2022-11-23 02:26:08,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:08,780 INFO:     Epoch: 11
2022-11-23 02:26:09,555 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8451421870426699, 'Total loss': 0.8451421870426699} | train loss {'Reaction outcome loss': 0.8162768050002666, 'Total loss': 0.8162768050002666}
2022-11-23 02:26:09,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:09,556 INFO:     Epoch: 12
2022-11-23 02:26:10,361 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.843932946974581, 'Total loss': 0.843932946974581} | train loss {'Reaction outcome loss': 0.8178962767124176, 'Total loss': 0.8178962767124176}
2022-11-23 02:26:10,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:10,361 INFO:     Epoch: 13
2022-11-23 02:26:11,156 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.840439304032109, 'Total loss': 0.840439304032109} | train loss {'Reaction outcome loss': 0.8183995963108202, 'Total loss': 0.8183995963108202}
2022-11-23 02:26:11,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:11,156 INFO:     Epoch: 14
2022-11-23 02:26:11,945 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8620874048634009, 'Total loss': 0.8620874048634009} | train loss {'Reaction outcome loss': 0.8141313382548842, 'Total loss': 0.8141313382548842}
2022-11-23 02:26:11,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:11,946 INFO:     Epoch: 15
2022-11-23 02:26:12,723 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8494416285644878, 'Total loss': 0.8494416285644878} | train loss {'Reaction outcome loss': 0.8127793781911796, 'Total loss': 0.8127793781911796}
2022-11-23 02:26:12,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:12,724 INFO:     Epoch: 16
2022-11-23 02:26:13,489 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8629753731868484, 'Total loss': 0.8629753731868484} | train loss {'Reaction outcome loss': 0.8203424251513926, 'Total loss': 0.8203424251513926}
2022-11-23 02:26:13,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:13,489 INFO:     Epoch: 17
2022-11-23 02:26:14,274 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8469110740856691, 'Total loss': 0.8469110740856691} | train loss {'Reaction outcome loss': 0.8161148097109698, 'Total loss': 0.8161148097109698}
2022-11-23 02:26:14,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:14,274 INFO:     Epoch: 18
2022-11-23 02:26:15,073 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8418470905585722, 'Total loss': 0.8418470905585722} | train loss {'Reaction outcome loss': 0.812280686760721, 'Total loss': 0.812280686760721}
2022-11-23 02:26:15,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:15,074 INFO:     Epoch: 19
2022-11-23 02:26:15,872 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8262954672629182, 'Total loss': 0.8262954672629182} | train loss {'Reaction outcome loss': 0.816141351755814, 'Total loss': 0.816141351755814}
2022-11-23 02:26:15,872 INFO:     Found new best model at epoch 19
2022-11-23 02:26:15,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:15,873 INFO:     Epoch: 20
2022-11-23 02:26:16,640 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8439510356296193, 'Total loss': 0.8439510356296193} | train loss {'Reaction outcome loss': 0.8150839372443767, 'Total loss': 0.8150839372443767}
2022-11-23 02:26:16,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:16,641 INFO:     Epoch: 21
2022-11-23 02:26:17,415 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8393650623885068, 'Total loss': 0.8393650623885068} | train loss {'Reaction outcome loss': 0.815362995814698, 'Total loss': 0.815362995814698}
2022-11-23 02:26:17,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:17,415 INFO:     Epoch: 22
2022-11-23 02:26:18,216 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8521138619292866, 'Total loss': 0.8521138619292866} | train loss {'Reaction outcome loss': 0.8178371281517662, 'Total loss': 0.8178371281517662}
2022-11-23 02:26:18,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:18,217 INFO:     Epoch: 23
2022-11-23 02:26:19,008 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8566608076745813, 'Total loss': 0.8566608076745813} | train loss {'Reaction outcome loss': 0.8108133659189046, 'Total loss': 0.8108133659189046}
2022-11-23 02:26:19,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:19,008 INFO:     Epoch: 24
2022-11-23 02:26:19,805 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8574235574765638, 'Total loss': 0.8574235574765638} | train loss {'Reaction outcome loss': 0.8197315576588095, 'Total loss': 0.8197315576588095}
2022-11-23 02:26:19,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:19,805 INFO:     Epoch: 25
2022-11-23 02:26:20,564 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8702253760261969, 'Total loss': 0.8702253760261969} | train loss {'Reaction outcome loss': 0.818278132421285, 'Total loss': 0.818278132421285}
2022-11-23 02:26:20,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:20,565 INFO:     Epoch: 26
2022-11-23 02:26:21,366 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.834474807435816, 'Total loss': 0.834474807435816} | train loss {'Reaction outcome loss': 0.8173042513460282, 'Total loss': 0.8173042513460282}
2022-11-23 02:26:21,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:21,366 INFO:     Epoch: 27
2022-11-23 02:26:22,124 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.9048884998668324, 'Total loss': 0.9048884998668324} | train loss {'Reaction outcome loss': 0.8105483979348712, 'Total loss': 0.8105483979348712}
2022-11-23 02:26:22,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:22,125 INFO:     Epoch: 28
2022-11-23 02:26:22,898 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8290351873094385, 'Total loss': 0.8290351873094385} | train loss {'Reaction outcome loss': 0.813692710596148, 'Total loss': 0.813692710596148}
2022-11-23 02:26:22,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:22,898 INFO:     Epoch: 29
2022-11-23 02:26:23,687 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8453257456421852, 'Total loss': 0.8453257456421852} | train loss {'Reaction outcome loss': 0.8142820103207098, 'Total loss': 0.8142820103207098}
2022-11-23 02:26:23,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:23,687 INFO:     Epoch: 30
2022-11-23 02:26:24,456 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8370294801213525, 'Total loss': 0.8370294801213525} | train loss {'Reaction outcome loss': 0.8088482182759505, 'Total loss': 0.8088482182759505}
2022-11-23 02:26:24,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:24,456 INFO:     Epoch: 31
2022-11-23 02:26:25,251 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8503183383833278, 'Total loss': 0.8503183383833278} | train loss {'Reaction outcome loss': 0.8150975214324983, 'Total loss': 0.8150975214324983}
2022-11-23 02:26:25,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:25,251 INFO:     Epoch: 32
2022-11-23 02:26:26,088 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8407817923209884, 'Total loss': 0.8407817923209884} | train loss {'Reaction outcome loss': 0.8280846842598577, 'Total loss': 0.8280846842598577}
2022-11-23 02:26:26,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:26,089 INFO:     Epoch: 33
2022-11-23 02:26:26,907 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8470662303946235, 'Total loss': 0.8470662303946235} | train loss {'Reaction outcome loss': 0.8097577412360111, 'Total loss': 0.8097577412360111}
2022-11-23 02:26:26,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:26,907 INFO:     Epoch: 34
2022-11-23 02:26:27,725 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8288131268187002, 'Total loss': 0.8288131268187002} | train loss {'Reaction outcome loss': 0.8063112563691158, 'Total loss': 0.8063112563691158}
2022-11-23 02:26:27,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:27,725 INFO:     Epoch: 35
2022-11-23 02:26:28,536 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8666178387674418, 'Total loss': 0.8666178387674418} | train loss {'Reaction outcome loss': 0.8137973841988606, 'Total loss': 0.8137973841988606}
2022-11-23 02:26:28,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:28,537 INFO:     Epoch: 36
2022-11-23 02:26:29,310 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8416903167963028, 'Total loss': 0.8416903167963028} | train loss {'Reaction outcome loss': 0.8150405618343276, 'Total loss': 0.8150405618343276}
2022-11-23 02:26:29,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:29,310 INFO:     Epoch: 37
2022-11-23 02:26:30,159 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8318015580827539, 'Total loss': 0.8318015580827539} | train loss {'Reaction outcome loss': 0.8187440963167893, 'Total loss': 0.8187440963167893}
2022-11-23 02:26:30,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:30,159 INFO:     Epoch: 38
2022-11-23 02:26:30,968 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.85772244496779, 'Total loss': 0.85772244496779} | train loss {'Reaction outcome loss': 0.8079396523987716, 'Total loss': 0.8079396523987716}
2022-11-23 02:26:30,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:30,968 INFO:     Epoch: 39
2022-11-23 02:26:31,790 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.842912373894995, 'Total loss': 0.842912373894995} | train loss {'Reaction outcome loss': 0.8096104390949372, 'Total loss': 0.8096104390949372}
2022-11-23 02:26:31,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:31,790 INFO:     Epoch: 40
2022-11-23 02:26:32,590 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.833091863854365, 'Total loss': 0.833091863854365} | train loss {'Reaction outcome loss': 0.8124708353507857, 'Total loss': 0.8124708353507857}
2022-11-23 02:26:32,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:32,591 INFO:     Epoch: 41
2022-11-23 02:26:33,393 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8408820927143097, 'Total loss': 0.8408820927143097} | train loss {'Reaction outcome loss': 0.8105678275257711, 'Total loss': 0.8105678275257711}
2022-11-23 02:26:33,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:33,393 INFO:     Epoch: 42
2022-11-23 02:26:34,191 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8433190340345557, 'Total loss': 0.8433190340345557} | train loss {'Reaction outcome loss': 0.8075839578502091, 'Total loss': 0.8075839578502091}
2022-11-23 02:26:34,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:34,192 INFO:     Epoch: 43
2022-11-23 02:26:34,972 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8357488973574205, 'Total loss': 0.8357488973574205} | train loss {'Reaction outcome loss': 0.8096422136644361, 'Total loss': 0.8096422136644361}
2022-11-23 02:26:34,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:34,973 INFO:     Epoch: 44
2022-11-23 02:26:35,786 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8383629904551939, 'Total loss': 0.8383629904551939} | train loss {'Reaction outcome loss': 0.8099308949009127, 'Total loss': 0.8099308949009127}
2022-11-23 02:26:35,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:35,786 INFO:     Epoch: 45
2022-11-23 02:26:36,621 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8417638939889994, 'Total loss': 0.8417638939889994} | train loss {'Reaction outcome loss': 0.8104881494634064, 'Total loss': 0.8104881494634064}
2022-11-23 02:26:36,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:36,621 INFO:     Epoch: 46
2022-11-23 02:26:37,506 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8474162640896711, 'Total loss': 0.8474162640896711} | train loss {'Reaction outcome loss': 0.8099097105022143, 'Total loss': 0.8099097105022143}
2022-11-23 02:26:37,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:37,506 INFO:     Epoch: 47
2022-11-23 02:26:38,332 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8348674784329805, 'Total loss': 0.8348674784329805} | train loss {'Reaction outcome loss': 0.8147031618998601, 'Total loss': 0.8147031618998601}
2022-11-23 02:26:38,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:38,333 INFO:     Epoch: 48
2022-11-23 02:26:39,180 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8469435288147493, 'Total loss': 0.8469435288147493} | train loss {'Reaction outcome loss': 0.818795892029156, 'Total loss': 0.818795892029156}
2022-11-23 02:26:39,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:39,180 INFO:     Epoch: 49
2022-11-23 02:26:39,996 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8524798452854156, 'Total loss': 0.8524798452854156} | train loss {'Reaction outcome loss': 0.8098407935517037, 'Total loss': 0.8098407935517037}
2022-11-23 02:26:39,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:39,997 INFO:     Epoch: 50
2022-11-23 02:26:40,846 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8377474810589444, 'Total loss': 0.8377474810589444} | train loss {'Reaction outcome loss': 0.803898975238023, 'Total loss': 0.803898975238023}
2022-11-23 02:26:40,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:40,847 INFO:     Epoch: 51
2022-11-23 02:26:41,676 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8386050442403014, 'Total loss': 0.8386050442403014} | train loss {'Reaction outcome loss': 0.8112099230862581, 'Total loss': 0.8112099230862581}
2022-11-23 02:26:41,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:41,676 INFO:     Epoch: 52
2022-11-23 02:26:42,536 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8286814886060628, 'Total loss': 0.8286814886060628} | train loss {'Reaction outcome loss': 0.808299769032822, 'Total loss': 0.808299769032822}
2022-11-23 02:26:42,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:42,537 INFO:     Epoch: 53
2022-11-23 02:26:43,316 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.837798149748282, 'Total loss': 0.837798149748282} | train loss {'Reaction outcome loss': 0.8122089461759034, 'Total loss': 0.8122089461759034}
2022-11-23 02:26:43,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:43,317 INFO:     Epoch: 54
2022-11-23 02:26:44,111 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8412473540414463, 'Total loss': 0.8412473540414463} | train loss {'Reaction outcome loss': 0.809569689441427, 'Total loss': 0.809569689441427}
2022-11-23 02:26:44,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:44,111 INFO:     Epoch: 55
2022-11-23 02:26:44,912 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8300292925401167, 'Total loss': 0.8300292925401167} | train loss {'Reaction outcome loss': 0.8088233216933394, 'Total loss': 0.8088233216933394}
2022-11-23 02:26:44,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:44,913 INFO:     Epoch: 56
2022-11-23 02:26:45,728 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8411127247593619, 'Total loss': 0.8411127247593619} | train loss {'Reaction outcome loss': 0.8086623271949861, 'Total loss': 0.8086623271949861}
2022-11-23 02:26:45,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:45,728 INFO:     Epoch: 57
2022-11-23 02:26:46,534 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8417714658108625, 'Total loss': 0.8417714658108625} | train loss {'Reaction outcome loss': 0.8060153421120122, 'Total loss': 0.8060153421120122}
2022-11-23 02:26:46,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:46,534 INFO:     Epoch: 58
2022-11-23 02:26:47,381 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8551340008323843, 'Total loss': 0.8551340008323843} | train loss {'Reaction outcome loss': 0.8106364372529482, 'Total loss': 0.8106364372529482}
2022-11-23 02:26:47,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:47,381 INFO:     Epoch: 59
2022-11-23 02:26:48,176 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8403466967019168, 'Total loss': 0.8403466967019168} | train loss {'Reaction outcome loss': 0.8092743736288326, 'Total loss': 0.8092743736288326}
2022-11-23 02:26:48,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:48,176 INFO:     Epoch: 60
2022-11-23 02:26:48,957 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8376037979667837, 'Total loss': 0.8376037979667837} | train loss {'Reaction outcome loss': 0.8091993970185639, 'Total loss': 0.8091993970185639}
2022-11-23 02:26:48,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:48,957 INFO:     Epoch: 61
2022-11-23 02:26:49,793 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8440337750044736, 'Total loss': 0.8440337750044736} | train loss {'Reaction outcome loss': 0.8079578042754277, 'Total loss': 0.8079578042754277}
2022-11-23 02:26:49,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:49,793 INFO:     Epoch: 62
2022-11-23 02:26:50,626 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8846980570392176, 'Total loss': 0.8846980570392176} | train loss {'Reaction outcome loss': 0.8055755878508333, 'Total loss': 0.8055755878508333}
2022-11-23 02:26:50,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:50,626 INFO:     Epoch: 63
2022-11-23 02:26:51,460 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8489673388275233, 'Total loss': 0.8489673388275233} | train loss {'Reaction outcome loss': 0.8152134321961808, 'Total loss': 0.8152134321961808}
2022-11-23 02:26:51,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:51,460 INFO:     Epoch: 64
2022-11-23 02:26:52,228 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8291474370793863, 'Total loss': 0.8291474370793863} | train loss {'Reaction outcome loss': 0.8052998708809919, 'Total loss': 0.8052998708809919}
2022-11-23 02:26:52,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:52,229 INFO:     Epoch: 65
2022-11-23 02:26:53,076 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8372609655965458, 'Total loss': 0.8372609655965458} | train loss {'Reaction outcome loss': 0.8059851191787102, 'Total loss': 0.8059851191787102}
2022-11-23 02:26:53,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:53,077 INFO:     Epoch: 66
2022-11-23 02:26:53,913 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8305663967674429, 'Total loss': 0.8305663967674429} | train loss {'Reaction outcome loss': 0.8080239421442935, 'Total loss': 0.8080239421442935}
2022-11-23 02:26:53,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:53,913 INFO:     Epoch: 67
2022-11-23 02:26:54,731 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8542042232372544, 'Total loss': 0.8542042232372544} | train loss {'Reaction outcome loss': 0.8047685310063575, 'Total loss': 0.8047685310063575}
2022-11-23 02:26:54,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:54,731 INFO:     Epoch: 68
2022-11-23 02:26:55,614 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8545634854923595, 'Total loss': 0.8545634854923595} | train loss {'Reaction outcome loss': 0.8032690008521562, 'Total loss': 0.8032690008521562}
2022-11-23 02:26:55,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:55,614 INFO:     Epoch: 69
2022-11-23 02:26:56,433 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8572221039371057, 'Total loss': 0.8572221039371057} | train loss {'Reaction outcome loss': 0.8095969694104754, 'Total loss': 0.8095969694104754}
2022-11-23 02:26:56,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:56,433 INFO:     Epoch: 70
2022-11-23 02:26:57,321 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8354711884802039, 'Total loss': 0.8354711884802039} | train loss {'Reaction outcome loss': 0.8045841523630899, 'Total loss': 0.8045841523630899}
2022-11-23 02:26:57,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:57,321 INFO:     Epoch: 71
2022-11-23 02:26:58,209 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8512550843032923, 'Total loss': 0.8512550843032923} | train loss {'Reaction outcome loss': 0.8120426246029163, 'Total loss': 0.8120426246029163}
2022-11-23 02:26:58,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:58,209 INFO:     Epoch: 72
2022-11-23 02:26:59,072 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8419989198446274, 'Total loss': 0.8419989198446274} | train loss {'Reaction outcome loss': 0.8054090078301758, 'Total loss': 0.8054090078301758}
2022-11-23 02:26:59,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:59,073 INFO:     Epoch: 73
2022-11-23 02:26:59,968 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8941251980987462, 'Total loss': 0.8941251980987462} | train loss {'Reaction outcome loss': 0.8021923881551998, 'Total loss': 0.8021923881551998}
2022-11-23 02:26:59,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:26:59,969 INFO:     Epoch: 74
2022-11-23 02:27:00,845 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8286887224424969, 'Total loss': 0.8286887224424969} | train loss {'Reaction outcome loss': 0.8083722067597182, 'Total loss': 0.8083722067597182}
2022-11-23 02:27:00,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:00,845 INFO:     Epoch: 75
2022-11-23 02:27:01,733 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8399260301481594, 'Total loss': 0.8399260301481594} | train loss {'Reaction outcome loss': 0.8033447219171987, 'Total loss': 0.8033447219171987}
2022-11-23 02:27:01,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:01,734 INFO:     Epoch: 76
2022-11-23 02:27:02,633 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8640551546757872, 'Total loss': 0.8640551546757872} | train loss {'Reaction outcome loss': 0.8121103734863915, 'Total loss': 0.8121103734863915}
2022-11-23 02:27:02,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:02,634 INFO:     Epoch: 77
2022-11-23 02:27:03,548 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8753281482918696, 'Total loss': 0.8753281482918696} | train loss {'Reaction outcome loss': 0.8055997390737418, 'Total loss': 0.8055997390737418}
2022-11-23 02:27:03,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:03,548 INFO:     Epoch: 78
2022-11-23 02:27:04,458 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8441617197611115, 'Total loss': 0.8441617197611115} | train loss {'Reaction outcome loss': 0.8071313897366466, 'Total loss': 0.8071313897366466}
2022-11-23 02:27:04,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:04,459 INFO:     Epoch: 79
2022-11-23 02:27:05,333 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8432745418765328, 'Total loss': 0.8432745418765328} | train loss {'Reaction outcome loss': 0.7998778602854926, 'Total loss': 0.7998778602854926}
2022-11-23 02:27:05,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:05,334 INFO:     Epoch: 80
2022-11-23 02:27:06,193 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8371748226610097, 'Total loss': 0.8371748226610097} | train loss {'Reaction outcome loss': 0.8085200272289365, 'Total loss': 0.8085200272289365}
2022-11-23 02:27:06,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:06,193 INFO:     Epoch: 81
2022-11-23 02:27:07,095 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8483728509057652, 'Total loss': 0.8483728509057652} | train loss {'Reaction outcome loss': 0.807079519216831, 'Total loss': 0.807079519216831}
2022-11-23 02:27:07,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:07,095 INFO:     Epoch: 82
2022-11-23 02:27:08,032 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8450597064061598, 'Total loss': 0.8450597064061598} | train loss {'Reaction outcome loss': 0.8152135654017028, 'Total loss': 0.8152135654017028}
2022-11-23 02:27:08,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:08,032 INFO:     Epoch: 83
2022-11-23 02:27:08,961 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8464196622371674, 'Total loss': 0.8464196622371674} | train loss {'Reaction outcome loss': 0.8045029131627759, 'Total loss': 0.8045029131627759}
2022-11-23 02:27:08,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:08,962 INFO:     Epoch: 84
2022-11-23 02:27:09,860 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8684037307446654, 'Total loss': 0.8684037307446654} | train loss {'Reaction outcome loss': 0.8028169892094879, 'Total loss': 0.8028169892094879}
2022-11-23 02:27:09,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:09,860 INFO:     Epoch: 85
2022-11-23 02:27:10,781 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8428592417727817, 'Total loss': 0.8428592417727817} | train loss {'Reaction outcome loss': 0.8118760500118317, 'Total loss': 0.8118760500118317}
2022-11-23 02:27:10,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:10,781 INFO:     Epoch: 86
2022-11-23 02:27:11,688 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8432441035454924, 'Total loss': 0.8432441035454924} | train loss {'Reaction outcome loss': 0.8020851574234875, 'Total loss': 0.8020851574234875}
2022-11-23 02:27:11,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:11,689 INFO:     Epoch: 87
2022-11-23 02:27:12,607 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8471973362294111, 'Total loss': 0.8471973362294111} | train loss {'Reaction outcome loss': 0.8054433930740665, 'Total loss': 0.8054433930740665}
2022-11-23 02:27:12,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:12,607 INFO:     Epoch: 88
2022-11-23 02:27:13,484 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8410626859827475, 'Total loss': 0.8410626859827475} | train loss {'Reaction outcome loss': 0.8113850927063329, 'Total loss': 0.8113850927063329}
2022-11-23 02:27:13,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:13,485 INFO:     Epoch: 89
2022-11-23 02:27:14,366 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8367858244614168, 'Total loss': 0.8367858244614168} | train loss {'Reaction outcome loss': 0.8042128004043209, 'Total loss': 0.8042128004043209}
2022-11-23 02:27:14,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:14,366 INFO:     Epoch: 90
2022-11-23 02:27:15,302 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.830756851895289, 'Total loss': 0.830756851895289} | train loss {'Reaction outcome loss': 0.8075350193600905, 'Total loss': 0.8075350193600905}
2022-11-23 02:27:15,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:15,302 INFO:     Epoch: 91
2022-11-23 02:27:16,189 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8259822177616033, 'Total loss': 0.8259822177616033} | train loss {'Reaction outcome loss': 0.8080170965387754, 'Total loss': 0.8080170965387754}
2022-11-23 02:27:16,189 INFO:     Found new best model at epoch 91
2022-11-23 02:27:16,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:16,190 INFO:     Epoch: 92
2022-11-23 02:27:17,088 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8403771072626114, 'Total loss': 0.8403771072626114} | train loss {'Reaction outcome loss': 0.8050186547190554, 'Total loss': 0.8050186547190554}
2022-11-23 02:27:17,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:17,089 INFO:     Epoch: 93
2022-11-23 02:27:17,971 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8770778775215149, 'Total loss': 0.8770778775215149} | train loss {'Reaction outcome loss': 0.8078618942032217, 'Total loss': 0.8078618942032217}
2022-11-23 02:27:17,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:17,971 INFO:     Epoch: 94
2022-11-23 02:27:18,901 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8299596445126967, 'Total loss': 0.8299596445126967} | train loss {'Reaction outcome loss': 0.8049096116411542, 'Total loss': 0.8049096116411542}
2022-11-23 02:27:18,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:18,901 INFO:     Epoch: 95
2022-11-23 02:27:19,845 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8408912535418164, 'Total loss': 0.8408912535418164} | train loss {'Reaction outcome loss': 0.8034783789986059, 'Total loss': 0.8034783789986059}
2022-11-23 02:27:19,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:19,845 INFO:     Epoch: 96
2022-11-23 02:27:20,720 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8334349583495747, 'Total loss': 0.8334349583495747} | train loss {'Reaction outcome loss': 0.8051936494918005, 'Total loss': 0.8051936494918005}
2022-11-23 02:27:20,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:20,720 INFO:     Epoch: 97
2022-11-23 02:27:21,668 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8344792892987077, 'Total loss': 0.8344792892987077} | train loss {'Reaction outcome loss': 0.8062268372489373, 'Total loss': 0.8062268372489373}
2022-11-23 02:27:21,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:21,668 INFO:     Epoch: 98
2022-11-23 02:27:22,530 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8717160644856367, 'Total loss': 0.8717160644856367} | train loss {'Reaction outcome loss': 0.8017460082917802, 'Total loss': 0.8017460082917802}
2022-11-23 02:27:22,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:22,531 INFO:     Epoch: 99
2022-11-23 02:27:23,425 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8508631932464513, 'Total loss': 0.8508631932464513} | train loss {'Reaction outcome loss': 0.8071377871007572, 'Total loss': 0.8071377871007572}
2022-11-23 02:27:23,425 INFO:     Best model found after epoch 92 of 100.
2022-11-23 02:27:23,425 INFO:   Done with stage: TRAINING
2022-11-23 02:27:23,425 INFO:   Starting stage: EVALUATION
2022-11-23 02:27:23,553 INFO:   Done with stage: EVALUATION
2022-11-23 02:27:23,562 INFO:   Leaving out SEQ value Fold_0
2022-11-23 02:27:23,575 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-23 02:27:23,576 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:27:24,254 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:27:24,255 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:27:24,330 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:27:24,330 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:27:24,330 INFO:     No hyperparam tuning for this model
2022-11-23 02:27:24,330 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:27:24,330 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:27:24,331 INFO:     None feature selector for col prot
2022-11-23 02:27:24,331 INFO:     None feature selector for col prot
2022-11-23 02:27:24,331 INFO:     None feature selector for col prot
2022-11-23 02:27:24,332 INFO:     None feature selector for col chem
2022-11-23 02:27:24,332 INFO:     None feature selector for col chem
2022-11-23 02:27:24,333 INFO:     None feature selector for col chem
2022-11-23 02:27:24,333 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:27:24,333 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:27:24,334 INFO:     Number of params in model 168571
2022-11-23 02:27:24,338 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:27:24,338 INFO:   Starting stage: TRAINING
2022-11-23 02:27:24,397 INFO:     Val loss before train {'Reaction outcome loss': 0.9776036891826364, 'Total loss': 0.9776036891826364}
2022-11-23 02:27:24,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:24,398 INFO:     Epoch: 0
2022-11-23 02:27:25,262 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8660873160805813, 'Total loss': 0.8660873160805813} | train loss {'Reaction outcome loss': 0.874621387739731, 'Total loss': 0.874621387739731}
2022-11-23 02:27:25,262 INFO:     Found new best model at epoch 0
2022-11-23 02:27:25,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:25,263 INFO:     Epoch: 1
2022-11-23 02:27:26,097 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.866459592830303, 'Total loss': 0.866459592830303} | train loss {'Reaction outcome loss': 0.8372676360263746, 'Total loss': 0.8372676360263746}
2022-11-23 02:27:26,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:26,097 INFO:     Epoch: 2
2022-11-23 02:27:26,924 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8614872888077137, 'Total loss': 0.8614872888077137} | train loss {'Reaction outcome loss': 0.8342426503881996, 'Total loss': 0.8342426503881996}
2022-11-23 02:27:26,924 INFO:     Found new best model at epoch 2
2022-11-23 02:27:26,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:26,925 INFO:     Epoch: 3
2022-11-23 02:27:27,808 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8361622580262118, 'Total loss': 0.8361622580262118} | train loss {'Reaction outcome loss': 0.823972293010955, 'Total loss': 0.823972293010955}
2022-11-23 02:27:27,808 INFO:     Found new best model at epoch 3
2022-11-23 02:27:27,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:27,809 INFO:     Epoch: 4
2022-11-23 02:27:28,732 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.840209023897038, 'Total loss': 0.840209023897038} | train loss {'Reaction outcome loss': 0.8202363702740689, 'Total loss': 0.8202363702740689}
2022-11-23 02:27:28,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:28,733 INFO:     Epoch: 5
2022-11-23 02:27:29,603 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8413119524024254, 'Total loss': 0.8413119524024254} | train loss {'Reaction outcome loss': 0.8122619228598512, 'Total loss': 0.8122619228598512}
2022-11-23 02:27:29,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:29,603 INFO:     Epoch: 6
2022-11-23 02:27:30,478 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8575706066087235, 'Total loss': 0.8575706066087235} | train loss {'Reaction outcome loss': 0.8132870530272708, 'Total loss': 0.8132870530272708}
2022-11-23 02:27:30,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:30,478 INFO:     Epoch: 7
2022-11-23 02:27:31,319 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8300557275151097, 'Total loss': 0.8300557275151097} | train loss {'Reaction outcome loss': 0.8122692959298813, 'Total loss': 0.8122692959298813}
2022-11-23 02:27:31,319 INFO:     Found new best model at epoch 7
2022-11-23 02:27:31,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:31,320 INFO:     Epoch: 8
2022-11-23 02:27:32,202 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8611088956511298, 'Total loss': 0.8611088956511298} | train loss {'Reaction outcome loss': 0.8109515618394922, 'Total loss': 0.8109515618394922}
2022-11-23 02:27:32,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:32,202 INFO:     Epoch: 9
2022-11-23 02:27:33,055 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8341570482697598, 'Total loss': 0.8341570482697598} | train loss {'Reaction outcome loss': 0.8112075878268897, 'Total loss': 0.8112075878268897}
2022-11-23 02:27:33,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:33,056 INFO:     Epoch: 10
2022-11-23 02:27:33,935 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8379739162533782, 'Total loss': 0.8379739162533782} | train loss {'Reaction outcome loss': 0.8064299586378498, 'Total loss': 0.8064299586378498}
2022-11-23 02:27:33,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:33,935 INFO:     Epoch: 11
2022-11-23 02:27:34,807 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8238682123117669, 'Total loss': 0.8238682123117669} | train loss {'Reaction outcome loss': 0.8030070377966013, 'Total loss': 0.8030070377966013}
2022-11-23 02:27:34,807 INFO:     Found new best model at epoch 11
2022-11-23 02:27:34,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:34,808 INFO:     Epoch: 12
2022-11-23 02:27:35,666 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8360220630501591, 'Total loss': 0.8360220630501591} | train loss {'Reaction outcome loss': 0.8123294269597089, 'Total loss': 0.8123294269597089}
2022-11-23 02:27:35,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:35,666 INFO:     Epoch: 13
2022-11-23 02:27:36,581 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8396163361017094, 'Total loss': 0.8396163361017094} | train loss {'Reaction outcome loss': 0.8107158741587964, 'Total loss': 0.8107158741587964}
2022-11-23 02:27:36,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:36,582 INFO:     Epoch: 14
2022-11-23 02:27:37,446 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8321914991667104, 'Total loss': 0.8321914991667104} | train loss {'Reaction outcome loss': 0.8047459452976415, 'Total loss': 0.8047459452976415}
2022-11-23 02:27:37,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:37,447 INFO:     Epoch: 15
2022-11-23 02:27:38,368 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8480338391869567, 'Total loss': 0.8480338391869567} | train loss {'Reaction outcome loss': 0.8110024249602737, 'Total loss': 0.8110024249602737}
2022-11-23 02:27:38,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:38,368 INFO:     Epoch: 16
2022-11-23 02:27:39,233 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8522145165953525, 'Total loss': 0.8522145165953525} | train loss {'Reaction outcome loss': 0.8087158024065779, 'Total loss': 0.8087158024065779}
2022-11-23 02:27:39,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:39,234 INFO:     Epoch: 17
2022-11-23 02:27:40,110 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8435759516649468, 'Total loss': 0.8435759516649468} | train loss {'Reaction outcome loss': 0.8044546213414934, 'Total loss': 0.8044546213414934}
2022-11-23 02:27:40,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:40,111 INFO:     Epoch: 18
2022-11-23 02:27:40,941 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8232628252617148, 'Total loss': 0.8232628252617148} | train loss {'Reaction outcome loss': 0.8029967385800287, 'Total loss': 0.8029967385800287}
2022-11-23 02:27:40,941 INFO:     Found new best model at epoch 18
2022-11-23 02:27:40,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:40,942 INFO:     Epoch: 19
2022-11-23 02:27:41,775 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.837835988333059, 'Total loss': 0.837835988333059} | train loss {'Reaction outcome loss': 0.8135643849157012, 'Total loss': 0.8135643849157012}
2022-11-23 02:27:41,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:41,776 INFO:     Epoch: 20
2022-11-23 02:27:42,615 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8229532338852106, 'Total loss': 0.8229532338852106} | train loss {'Reaction outcome loss': 0.8007250583956762, 'Total loss': 0.8007250583956762}
2022-11-23 02:27:42,616 INFO:     Found new best model at epoch 20
2022-11-23 02:27:42,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:42,617 INFO:     Epoch: 21
2022-11-23 02:27:43,468 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8348828082860902, 'Total loss': 0.8348828082860902} | train loss {'Reaction outcome loss': 0.8018336773163988, 'Total loss': 0.8018336773163988}
2022-11-23 02:27:43,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:43,468 INFO:     Epoch: 22
2022-11-23 02:27:44,383 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8604617922805077, 'Total loss': 0.8604617922805077} | train loss {'Reaction outcome loss': 0.8066737894658689, 'Total loss': 0.8066737894658689}
2022-11-23 02:27:44,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:44,383 INFO:     Epoch: 23
2022-11-23 02:27:45,218 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8464082299276839, 'Total loss': 0.8464082299276839} | train loss {'Reaction outcome loss': 0.8070756902174695, 'Total loss': 0.8070756902174695}
2022-11-23 02:27:45,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:45,218 INFO:     Epoch: 24
2022-11-23 02:27:46,025 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8318692570508912, 'Total loss': 0.8318692570508912} | train loss {'Reaction outcome loss': 0.8038790143811654, 'Total loss': 0.8038790143811654}
2022-11-23 02:27:46,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:46,025 INFO:     Epoch: 25
2022-11-23 02:27:46,892 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8374247031156407, 'Total loss': 0.8374247031156407} | train loss {'Reaction outcome loss': 0.8035728556138498, 'Total loss': 0.8035728556138498}
2022-11-23 02:27:46,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:46,892 INFO:     Epoch: 26
2022-11-23 02:27:47,718 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8298949571542962, 'Total loss': 0.8298949571542962} | train loss {'Reaction outcome loss': 0.8005668758855435, 'Total loss': 0.8005668758855435}
2022-11-23 02:27:47,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:47,718 INFO:     Epoch: 27
2022-11-23 02:27:48,622 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8900841724040897, 'Total loss': 0.8900841724040897} | train loss {'Reaction outcome loss': 0.8083316131874367, 'Total loss': 0.8083316131874367}
2022-11-23 02:27:48,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:48,622 INFO:     Epoch: 28
2022-11-23 02:27:49,427 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8359577863715416, 'Total loss': 0.8359577863715416} | train loss {'Reaction outcome loss': 0.8032217681898501, 'Total loss': 0.8032217681898501}
2022-11-23 02:27:49,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:49,427 INFO:     Epoch: 29
2022-11-23 02:27:50,265 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.836571080740108, 'Total loss': 0.836571080740108} | train loss {'Reaction outcome loss': 0.8047999776439902, 'Total loss': 0.8047999776439902}
2022-11-23 02:27:50,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:50,265 INFO:     Epoch: 30
2022-11-23 02:27:51,102 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8346289805201597, 'Total loss': 0.8346289805201597} | train loss {'Reaction outcome loss': 0.8012897150261412, 'Total loss': 0.8012897150261412}
2022-11-23 02:27:51,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:51,102 INFO:     Epoch: 31
2022-11-23 02:27:51,919 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8401531743448835, 'Total loss': 0.8401531743448835} | train loss {'Reaction outcome loss': 0.8066161720105159, 'Total loss': 0.8066161720105159}
2022-11-23 02:27:51,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:51,920 INFO:     Epoch: 32
2022-11-23 02:27:52,728 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8308852051579675, 'Total loss': 0.8308852051579675} | train loss {'Reaction outcome loss': 0.8019785181975659, 'Total loss': 0.8019785181975659}
2022-11-23 02:27:52,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:52,729 INFO:     Epoch: 33
2022-11-23 02:27:53,581 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8469383924506432, 'Total loss': 0.8469383924506432} | train loss {'Reaction outcome loss': 0.8013938887987608, 'Total loss': 0.8013938887987608}
2022-11-23 02:27:53,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:53,581 INFO:     Epoch: 34
2022-11-23 02:27:54,443 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8324856986833173, 'Total loss': 0.8324856986833173} | train loss {'Reaction outcome loss': 0.810367823996171, 'Total loss': 0.810367823996171}
2022-11-23 02:27:54,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:54,444 INFO:     Epoch: 35
2022-11-23 02:27:55,306 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8466774363850438, 'Total loss': 0.8466774363850438} | train loss {'Reaction outcome loss': 0.8032349778546227, 'Total loss': 0.8032349778546227}
2022-11-23 02:27:55,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:55,307 INFO:     Epoch: 36
2022-11-23 02:27:56,089 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8362116536428762, 'Total loss': 0.8362116536428762} | train loss {'Reaction outcome loss': 0.8048450007360168, 'Total loss': 0.8048450007360168}
2022-11-23 02:27:56,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:56,089 INFO:     Epoch: 37
2022-11-23 02:27:56,916 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8274799758611724, 'Total loss': 0.8274799758611724} | train loss {'Reaction outcome loss': 0.8024681728072618, 'Total loss': 0.8024681728072618}
2022-11-23 02:27:56,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:56,916 INFO:     Epoch: 38
2022-11-23 02:27:57,775 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8394760336986807, 'Total loss': 0.8394760336986807} | train loss {'Reaction outcome loss': 0.8014777820296739, 'Total loss': 0.8014777820296739}
2022-11-23 02:27:57,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:57,776 INFO:     Epoch: 39
2022-11-23 02:27:58,615 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8663354613060175, 'Total loss': 0.8663354613060175} | train loss {'Reaction outcome loss': 0.8025647572283883, 'Total loss': 0.8025647572283883}
2022-11-23 02:27:58,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:58,616 INFO:     Epoch: 40
2022-11-23 02:27:59,513 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.83000328998233, 'Total loss': 0.83000328998233} | train loss {'Reaction outcome loss': 0.8022138545052014, 'Total loss': 0.8022138545052014}
2022-11-23 02:27:59,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:27:59,513 INFO:     Epoch: 41
2022-11-23 02:28:00,346 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.843450607948525, 'Total loss': 0.843450607948525} | train loss {'Reaction outcome loss': 0.8018557215914314, 'Total loss': 0.8018557215914314}
2022-11-23 02:28:00,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:00,346 INFO:     Epoch: 42
2022-11-23 02:28:01,164 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8623481171075688, 'Total loss': 0.8623481171075688} | train loss {'Reaction outcome loss': 0.8039888382693867, 'Total loss': 0.8039888382693867}
2022-11-23 02:28:01,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:01,164 INFO:     Epoch: 43
2022-11-23 02:28:01,942 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8267602906670681, 'Total loss': 0.8267602906670681} | train loss {'Reaction outcome loss': 0.8037379847632514, 'Total loss': 0.8037379847632514}
2022-11-23 02:28:01,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:01,942 INFO:     Epoch: 44
2022-11-23 02:28:02,732 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8301254233648611, 'Total loss': 0.8301254233648611} | train loss {'Reaction outcome loss': 0.8040237497890927, 'Total loss': 0.8040237497890927}
2022-11-23 02:28:02,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:02,733 INFO:     Epoch: 45
2022-11-23 02:28:03,536 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8350642316563185, 'Total loss': 0.8350642316563185} | train loss {'Reaction outcome loss': 0.8046685000996531, 'Total loss': 0.8046685000996531}
2022-11-23 02:28:03,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:03,536 INFO:     Epoch: 46
2022-11-23 02:28:04,355 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8584177521772163, 'Total loss': 0.8584177521772163} | train loss {'Reaction outcome loss': 0.8015016869262412, 'Total loss': 0.8015016869262412}
2022-11-23 02:28:04,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:04,355 INFO:     Epoch: 47
2022-11-23 02:28:05,153 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8292067529157151, 'Total loss': 0.8292067529157151} | train loss {'Reaction outcome loss': 0.8031365077927279, 'Total loss': 0.8031365077927279}
2022-11-23 02:28:05,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:05,153 INFO:     Epoch: 48
2022-11-23 02:28:05,992 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8325725017591964, 'Total loss': 0.8325725017591964} | train loss {'Reaction outcome loss': 0.8074294819262783, 'Total loss': 0.8074294819262783}
2022-11-23 02:28:05,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:05,992 INFO:     Epoch: 49
2022-11-23 02:28:06,786 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8218267234258874, 'Total loss': 0.8218267234258874} | train loss {'Reaction outcome loss': 0.8014541187404115, 'Total loss': 0.8014541187404115}
2022-11-23 02:28:06,787 INFO:     Found new best model at epoch 49
2022-11-23 02:28:06,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:06,788 INFO:     Epoch: 50
2022-11-23 02:28:07,601 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8290581543778264, 'Total loss': 0.8290581543778264} | train loss {'Reaction outcome loss': 0.8019414379763505, 'Total loss': 0.8019414379763505}
2022-11-23 02:28:07,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:07,601 INFO:     Epoch: 51
2022-11-23 02:28:08,384 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8268859164659367, 'Total loss': 0.8268859164659367} | train loss {'Reaction outcome loss': 0.8046882995730075, 'Total loss': 0.8046882995730075}
2022-11-23 02:28:08,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:08,386 INFO:     Epoch: 52
2022-11-23 02:28:09,172 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8339258425457533, 'Total loss': 0.8339258425457533} | train loss {'Reaction outcome loss': 0.8040675669295307, 'Total loss': 0.8040675669295307}
2022-11-23 02:28:09,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:09,172 INFO:     Epoch: 53
2022-11-23 02:28:09,910 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8286487626474958, 'Total loss': 0.8286487626474958} | train loss {'Reaction outcome loss': 0.8058532894638831, 'Total loss': 0.8058532894638831}
2022-11-23 02:28:09,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:09,911 INFO:     Epoch: 54
2022-11-23 02:28:10,741 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8329274799934653, 'Total loss': 0.8329274799934653} | train loss {'Reaction outcome loss': 0.8003315609178425, 'Total loss': 0.8003315609178425}
2022-11-23 02:28:10,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:10,741 INFO:     Epoch: 55
2022-11-23 02:28:11,529 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8195119319960128, 'Total loss': 0.8195119319960128} | train loss {'Reaction outcome loss': 0.8031018317481617, 'Total loss': 0.8031018317481617}
2022-11-23 02:28:11,529 INFO:     Found new best model at epoch 55
2022-11-23 02:28:11,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:11,530 INFO:     Epoch: 56
2022-11-23 02:28:12,307 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8287170224411543, 'Total loss': 0.8287170224411543} | train loss {'Reaction outcome loss': 0.7983067449596193, 'Total loss': 0.7983067449596193}
2022-11-23 02:28:12,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:12,308 INFO:     Epoch: 57
2022-11-23 02:28:13,073 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8372018073880395, 'Total loss': 0.8372018073880395} | train loss {'Reaction outcome loss': 0.8026669612882559, 'Total loss': 0.8026669612882559}
2022-11-23 02:28:13,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:13,073 INFO:     Epoch: 58
2022-11-23 02:28:13,826 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8416916235934856, 'Total loss': 0.8416916235934856} | train loss {'Reaction outcome loss': 0.8037332572318889, 'Total loss': 0.8037332572318889}
2022-11-23 02:28:13,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:13,826 INFO:     Epoch: 59
2022-11-23 02:28:14,546 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8312724731689276, 'Total loss': 0.8312724731689276} | train loss {'Reaction outcome loss': 0.8008831064887498, 'Total loss': 0.8008831064887498}
2022-11-23 02:28:14,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:14,547 INFO:     Epoch: 60
2022-11-23 02:28:15,305 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8289461981418521, 'Total loss': 0.8289461981418521} | train loss {'Reaction outcome loss': 0.8058374751006625, 'Total loss': 0.8058374751006625}
2022-11-23 02:28:15,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:15,305 INFO:     Epoch: 61
2022-11-23 02:28:16,050 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.827962247438209, 'Total loss': 0.827962247438209} | train loss {'Reaction outcome loss': 0.7999512372929373, 'Total loss': 0.7999512372929373}
2022-11-23 02:28:16,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:16,051 INFO:     Epoch: 62
2022-11-23 02:28:16,815 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.831759172123532, 'Total loss': 0.831759172123532} | train loss {'Reaction outcome loss': 0.8053123235947801, 'Total loss': 0.8053123235947801}
2022-11-23 02:28:16,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:16,816 INFO:     Epoch: 63
2022-11-23 02:28:17,597 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.834972538920336, 'Total loss': 0.834972538920336} | train loss {'Reaction outcome loss': 0.803831112973484, 'Total loss': 0.803831112973484}
2022-11-23 02:28:17,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:17,598 INFO:     Epoch: 64
2022-11-23 02:28:18,376 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8160140223281328, 'Total loss': 0.8160140223281328} | train loss {'Reaction outcome loss': 0.8027703963189459, 'Total loss': 0.8027703963189459}
2022-11-23 02:28:18,376 INFO:     Found new best model at epoch 64
2022-11-23 02:28:18,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:18,377 INFO:     Epoch: 65
2022-11-23 02:28:19,197 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8292743806229081, 'Total loss': 0.8292743806229081} | train loss {'Reaction outcome loss': 0.8024545062348676, 'Total loss': 0.8024545062348676}
2022-11-23 02:28:19,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:19,197 INFO:     Epoch: 66
2022-11-23 02:28:19,970 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8444481145503909, 'Total loss': 0.8444481145503909} | train loss {'Reaction outcome loss': 0.8020004015645863, 'Total loss': 0.8020004015645863}
2022-11-23 02:28:19,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:19,970 INFO:     Epoch: 67
2022-11-23 02:28:20,735 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8294744879700416, 'Total loss': 0.8294744879700416} | train loss {'Reaction outcome loss': 0.8041770786905484, 'Total loss': 0.8041770786905484}
2022-11-23 02:28:20,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:20,735 INFO:     Epoch: 68
2022-11-23 02:28:21,508 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8396434901758681, 'Total loss': 0.8396434901758681} | train loss {'Reaction outcome loss': 0.8014619428925063, 'Total loss': 0.8014619428925063}
2022-11-23 02:28:21,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:21,508 INFO:     Epoch: 69
2022-11-23 02:28:22,259 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8248845013075097, 'Total loss': 0.8248845013075097} | train loss {'Reaction outcome loss': 0.8044532949541822, 'Total loss': 0.8044532949541822}
2022-11-23 02:28:22,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:22,259 INFO:     Epoch: 70
2022-11-23 02:28:23,032 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8268976759078891, 'Total loss': 0.8268976759078891} | train loss {'Reaction outcome loss': 0.800658536423381, 'Total loss': 0.800658536423381}
2022-11-23 02:28:23,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:23,032 INFO:     Epoch: 71
2022-11-23 02:28:23,782 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8335114211537117, 'Total loss': 0.8335114211537117} | train loss {'Reaction outcome loss': 0.8053730338689231, 'Total loss': 0.8053730338689231}
2022-11-23 02:28:23,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:23,782 INFO:     Epoch: 72
2022-11-23 02:28:24,532 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.834246293056843, 'Total loss': 0.834246293056843} | train loss {'Reaction outcome loss': 0.8063108542083223, 'Total loss': 0.8063108542083223}
2022-11-23 02:28:24,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:24,532 INFO:     Epoch: 73
2022-11-23 02:28:25,321 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8341233792693116, 'Total loss': 0.8341233792693116} | train loss {'Reaction outcome loss': 0.801728846972862, 'Total loss': 0.801728846972862}
2022-11-23 02:28:25,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:25,321 INFO:     Epoch: 74
2022-11-23 02:28:26,089 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8369484536869581, 'Total loss': 0.8369484536869581} | train loss {'Reaction outcome loss': 0.8081607623600665, 'Total loss': 0.8081607623600665}
2022-11-23 02:28:26,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:26,089 INFO:     Epoch: 75
2022-11-23 02:28:26,870 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8333886355854744, 'Total loss': 0.8333886355854744} | train loss {'Reaction outcome loss': 0.8030329376091192, 'Total loss': 0.8030329376091192}
2022-11-23 02:28:26,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:26,871 INFO:     Epoch: 76
2022-11-23 02:28:27,675 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8317443229431329, 'Total loss': 0.8317443229431329} | train loss {'Reaction outcome loss': 0.7997279755863143, 'Total loss': 0.7997279755863143}
2022-11-23 02:28:27,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:27,675 INFO:     Epoch: 77
2022-11-23 02:28:28,439 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8337832079377285, 'Total loss': 0.8337832079377285} | train loss {'Reaction outcome loss': 0.8111917578879698, 'Total loss': 0.8111917578879698}
2022-11-23 02:28:28,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:28,439 INFO:     Epoch: 78
2022-11-23 02:28:29,205 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8320040176081103, 'Total loss': 0.8320040176081103} | train loss {'Reaction outcome loss': 0.8047427752135713, 'Total loss': 0.8047427752135713}
2022-11-23 02:28:29,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:29,206 INFO:     Epoch: 79
2022-11-23 02:28:29,993 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8156135227791098, 'Total loss': 0.8156135227791098} | train loss {'Reaction outcome loss': 0.8058514044363312, 'Total loss': 0.8058514044363312}
2022-11-23 02:28:29,993 INFO:     Found new best model at epoch 79
2022-11-23 02:28:29,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:29,994 INFO:     Epoch: 80
2022-11-23 02:28:30,804 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8358833651209987, 'Total loss': 0.8358833651209987} | train loss {'Reaction outcome loss': 0.800343433096085, 'Total loss': 0.800343433096085}
2022-11-23 02:28:30,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:30,805 INFO:     Epoch: 81
2022-11-23 02:28:31,600 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8263681912144949, 'Total loss': 0.8263681912144949} | train loss {'Reaction outcome loss': 0.8039399554700027, 'Total loss': 0.8039399554700027}
2022-11-23 02:28:31,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:31,601 INFO:     Epoch: 82
2022-11-23 02:28:32,417 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8341962771360264, 'Total loss': 0.8341962771360264} | train loss {'Reaction outcome loss': 0.802693911969907, 'Total loss': 0.802693911969907}
2022-11-23 02:28:32,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:32,417 INFO:     Epoch: 83
2022-11-23 02:28:33,219 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8303447393483894, 'Total loss': 0.8303447393483894} | train loss {'Reaction outcome loss': 0.8063795550615208, 'Total loss': 0.8063795550615208}
2022-11-23 02:28:33,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:33,220 INFO:     Epoch: 84
2022-11-23 02:28:33,986 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8412148259406866, 'Total loss': 0.8412148259406866} | train loss {'Reaction outcome loss': 0.8040343085188925, 'Total loss': 0.8040343085188925}
2022-11-23 02:28:33,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:33,987 INFO:     Epoch: 85
2022-11-23 02:28:34,790 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8343259269414947, 'Total loss': 0.8343259269414947} | train loss {'Reaction outcome loss': 0.8047612895690855, 'Total loss': 0.8047612895690855}
2022-11-23 02:28:34,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:34,790 INFO:     Epoch: 86
2022-11-23 02:28:35,610 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8386937393698581, 'Total loss': 0.8386937393698581} | train loss {'Reaction outcome loss': 0.8007751876189385, 'Total loss': 0.8007751876189385}
2022-11-23 02:28:35,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:35,611 INFO:     Epoch: 87
2022-11-23 02:28:36,399 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8311337870220805, 'Total loss': 0.8311337870220805} | train loss {'Reaction outcome loss': 0.8057397118321171, 'Total loss': 0.8057397118321171}
2022-11-23 02:28:36,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:36,400 INFO:     Epoch: 88
2022-11-23 02:28:37,172 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8398636274559553, 'Total loss': 0.8398636274559553} | train loss {'Reaction outcome loss': 0.8024123364392622, 'Total loss': 0.8024123364392622}
2022-11-23 02:28:37,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:37,172 INFO:     Epoch: 89
2022-11-23 02:28:37,927 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8413968890212303, 'Total loss': 0.8413968890212303} | train loss {'Reaction outcome loss': 0.8035077726154171, 'Total loss': 0.8035077726154171}
2022-11-23 02:28:37,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:37,928 INFO:     Epoch: 90
2022-11-23 02:28:38,739 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8450004666350609, 'Total loss': 0.8450004666350609} | train loss {'Reaction outcome loss': 0.8059383424711816, 'Total loss': 0.8059383424711816}
2022-11-23 02:28:38,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:38,739 INFO:     Epoch: 91
2022-11-23 02:28:39,524 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8481433682663496, 'Total loss': 0.8481433682663496} | train loss {'Reaction outcome loss': 0.8032856235288298, 'Total loss': 0.8032856235288298}
2022-11-23 02:28:39,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:39,525 INFO:     Epoch: 92
2022-11-23 02:28:40,305 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8367373042328413, 'Total loss': 0.8367373042328413} | train loss {'Reaction outcome loss': 0.8014466276875248, 'Total loss': 0.8014466276875248}
2022-11-23 02:28:40,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:40,305 INFO:     Epoch: 93
2022-11-23 02:28:41,100 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8384997581326684, 'Total loss': 0.8384997581326684} | train loss {'Reaction outcome loss': 0.8015149010061727, 'Total loss': 0.8015149010061727}
2022-11-23 02:28:41,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:41,101 INFO:     Epoch: 94
2022-11-23 02:28:41,908 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.827835830145104, 'Total loss': 0.827835830145104} | train loss {'Reaction outcome loss': 0.8071799652321349, 'Total loss': 0.8071799652321349}
2022-11-23 02:28:41,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:41,908 INFO:     Epoch: 95
2022-11-23 02:28:42,685 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8338187246821648, 'Total loss': 0.8338187246821648} | train loss {'Reaction outcome loss': 0.8063225971818461, 'Total loss': 0.8063225971818461}
2022-11-23 02:28:42,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:42,685 INFO:     Epoch: 96
2022-11-23 02:28:43,432 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8327496779519458, 'Total loss': 0.8327496779519458} | train loss {'Reaction outcome loss': 0.8056487497478846, 'Total loss': 0.8056487497478846}
2022-11-23 02:28:43,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:43,432 INFO:     Epoch: 97
2022-11-23 02:28:44,279 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8219830172006474, 'Total loss': 0.8219830172006474} | train loss {'Reaction outcome loss': 0.8106208864308189, 'Total loss': 0.8106208864308189}
2022-11-23 02:28:44,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:44,279 INFO:     Epoch: 98
2022-11-23 02:28:45,091 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8300173081630884, 'Total loss': 0.8300173081630884} | train loss {'Reaction outcome loss': 0.8004360592659608, 'Total loss': 0.8004360592659608}
2022-11-23 02:28:45,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:45,091 INFO:     Epoch: 99
2022-11-23 02:28:45,895 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8451584023098613, 'Total loss': 0.8451584023098613} | train loss {'Reaction outcome loss': 0.8035189022497876, 'Total loss': 0.8035189022497876}
2022-11-23 02:28:45,896 INFO:     Best model found after epoch 80 of 100.
2022-11-23 02:28:45,896 INFO:   Done with stage: TRAINING
2022-11-23 02:28:45,896 INFO:   Starting stage: EVALUATION
2022-11-23 02:28:46,038 INFO:   Done with stage: EVALUATION
2022-11-23 02:28:46,038 INFO:   Leaving out SEQ value Fold_1
2022-11-23 02:28:46,051 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 02:28:46,052 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:28:46,716 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:28:46,716 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:28:46,789 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:28:46,789 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:28:46,789 INFO:     No hyperparam tuning for this model
2022-11-23 02:28:46,789 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:28:46,789 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:28:46,790 INFO:     None feature selector for col prot
2022-11-23 02:28:46,791 INFO:     None feature selector for col prot
2022-11-23 02:28:46,791 INFO:     None feature selector for col prot
2022-11-23 02:28:46,791 INFO:     None feature selector for col chem
2022-11-23 02:28:46,792 INFO:     None feature selector for col chem
2022-11-23 02:28:46,792 INFO:     None feature selector for col chem
2022-11-23 02:28:46,792 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:28:46,792 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:28:46,793 INFO:     Number of params in model 168571
2022-11-23 02:28:46,797 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:28:46,797 INFO:   Starting stage: TRAINING
2022-11-23 02:28:46,855 INFO:     Val loss before train {'Reaction outcome loss': 1.0106603123924949, 'Total loss': 1.0106603123924949}
2022-11-23 02:28:46,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:46,855 INFO:     Epoch: 0
2022-11-23 02:28:47,664 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8262008740143343, 'Total loss': 0.8262008740143343} | train loss {'Reaction outcome loss': 0.8876929262462927, 'Total loss': 0.8876929262462927}
2022-11-23 02:28:47,665 INFO:     Found new best model at epoch 0
2022-11-23 02:28:47,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:47,666 INFO:     Epoch: 1
2022-11-23 02:28:48,482 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8267642828551206, 'Total loss': 0.8267642828551206} | train loss {'Reaction outcome loss': 0.8603130013358836, 'Total loss': 0.8603130013358836}
2022-11-23 02:28:48,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:48,483 INFO:     Epoch: 2
2022-11-23 02:28:49,272 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8264532150192694, 'Total loss': 0.8264532150192694} | train loss {'Reaction outcome loss': 0.8536588524069105, 'Total loss': 0.8536588524069105}
2022-11-23 02:28:49,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:49,272 INFO:     Epoch: 3
2022-11-23 02:28:50,079 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8057542104612697, 'Total loss': 0.8057542104612697} | train loss {'Reaction outcome loss': 0.8516483153615679, 'Total loss': 0.8516483153615679}
2022-11-23 02:28:50,079 INFO:     Found new best model at epoch 3
2022-11-23 02:28:50,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:50,080 INFO:     Epoch: 4
2022-11-23 02:28:50,870 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8301888846538283, 'Total loss': 0.8301888846538283} | train loss {'Reaction outcome loss': 0.8391262924184605, 'Total loss': 0.8391262924184605}
2022-11-23 02:28:50,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:50,871 INFO:     Epoch: 5
2022-11-23 02:28:51,658 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8188345574519851, 'Total loss': 0.8188345574519851} | train loss {'Reaction outcome loss': 0.8399580003047477, 'Total loss': 0.8399580003047477}
2022-11-23 02:28:51,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:51,658 INFO:     Epoch: 6
2022-11-23 02:28:52,485 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.80717921866612, 'Total loss': 0.80717921866612} | train loss {'Reaction outcome loss': 0.8369641066813955, 'Total loss': 0.8369641066813955}
2022-11-23 02:28:52,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:52,486 INFO:     Epoch: 7
2022-11-23 02:28:53,286 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8297390870072625, 'Total loss': 0.8297390870072625} | train loss {'Reaction outcome loss': 0.8347874072133278, 'Total loss': 0.8347874072133278}
2022-11-23 02:28:53,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:53,286 INFO:     Epoch: 8
2022-11-23 02:28:54,084 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7984392968091097, 'Total loss': 0.7984392968091097} | train loss {'Reaction outcome loss': 0.8409215466100343, 'Total loss': 0.8409215466100343}
2022-11-23 02:28:54,084 INFO:     Found new best model at epoch 8
2022-11-23 02:28:54,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:54,085 INFO:     Epoch: 9
2022-11-23 02:28:54,854 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8073663718321107, 'Total loss': 0.8073663718321107} | train loss {'Reaction outcome loss': 0.8301124119028753, 'Total loss': 0.8301124119028753}
2022-11-23 02:28:54,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:54,855 INFO:     Epoch: 10
2022-11-23 02:28:55,664 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7941796732219782, 'Total loss': 0.7941796732219782} | train loss {'Reaction outcome loss': 0.8325395131597714, 'Total loss': 0.8325395131597714}
2022-11-23 02:28:55,665 INFO:     Found new best model at epoch 10
2022-11-23 02:28:55,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:55,666 INFO:     Epoch: 11
2022-11-23 02:28:56,451 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.825768422674049, 'Total loss': 0.825768422674049} | train loss {'Reaction outcome loss': 0.8329174802011373, 'Total loss': 0.8329174802011373}
2022-11-23 02:28:56,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:56,451 INFO:     Epoch: 12
2022-11-23 02:28:57,253 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8277333094315096, 'Total loss': 0.8277333094315096} | train loss {'Reaction outcome loss': 0.8303185759758462, 'Total loss': 0.8303185759758462}
2022-11-23 02:28:57,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:57,253 INFO:     Epoch: 13
2022-11-23 02:28:58,102 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7950763749805364, 'Total loss': 0.7950763749805364} | train loss {'Reaction outcome loss': 0.8335031995967943, 'Total loss': 0.8335031995967943}
2022-11-23 02:28:58,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:58,103 INFO:     Epoch: 14
2022-11-23 02:28:58,948 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.79404732178558, 'Total loss': 0.79404732178558} | train loss {'Reaction outcome loss': 0.8314477448560753, 'Total loss': 0.8314477448560753}
2022-11-23 02:28:58,948 INFO:     Found new best model at epoch 14
2022-11-23 02:28:58,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:58,949 INFO:     Epoch: 15
2022-11-23 02:28:59,755 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.782209955833175, 'Total loss': 0.782209955833175} | train loss {'Reaction outcome loss': 0.8266070386584924, 'Total loss': 0.8266070386584924}
2022-11-23 02:28:59,755 INFO:     Found new best model at epoch 15
2022-11-23 02:28:59,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:28:59,756 INFO:     Epoch: 16
2022-11-23 02:29:00,542 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8075475469231606, 'Total loss': 0.8075475469231606} | train loss {'Reaction outcome loss': 0.8315121994943034, 'Total loss': 0.8315121994943034}
2022-11-23 02:29:00,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:00,542 INFO:     Epoch: 17
2022-11-23 02:29:01,350 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7976338111541488, 'Total loss': 0.7976338111541488} | train loss {'Reaction outcome loss': 0.8310516936438425, 'Total loss': 0.8310516936438425}
2022-11-23 02:29:01,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:01,350 INFO:     Epoch: 18
2022-11-23 02:29:02,153 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.828135685487227, 'Total loss': 0.828135685487227} | train loss {'Reaction outcome loss': 0.8276823026793344, 'Total loss': 0.8276823026793344}
2022-11-23 02:29:02,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:02,153 INFO:     Epoch: 19
2022-11-23 02:29:02,952 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8285782730037515, 'Total loss': 0.8285782730037515} | train loss {'Reaction outcome loss': 0.82469827861202, 'Total loss': 0.82469827861202}
2022-11-23 02:29:02,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:02,952 INFO:     Epoch: 20
2022-11-23 02:29:03,756 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.811519281430678, 'Total loss': 0.811519281430678} | train loss {'Reaction outcome loss': 0.8242953527946861, 'Total loss': 0.8242953527946861}
2022-11-23 02:29:03,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:03,757 INFO:     Epoch: 21
2022-11-23 02:29:04,521 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8079760230400346, 'Total loss': 0.8079760230400346} | train loss {'Reaction outcome loss': 0.8298342012629217, 'Total loss': 0.8298342012629217}
2022-11-23 02:29:04,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:04,521 INFO:     Epoch: 22
2022-11-23 02:29:05,345 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8108716234564781, 'Total loss': 0.8108716234564781} | train loss {'Reaction outcome loss': 0.8285174684865134, 'Total loss': 0.8285174684865134}
2022-11-23 02:29:05,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:05,346 INFO:     Epoch: 23
2022-11-23 02:29:06,166 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8071529255671934, 'Total loss': 0.8071529255671934} | train loss {'Reaction outcome loss': 0.8306616578783308, 'Total loss': 0.8306616578783308}
2022-11-23 02:29:06,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:06,166 INFO:     Epoch: 24
2022-11-23 02:29:06,969 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.798945548182184, 'Total loss': 0.798945548182184} | train loss {'Reaction outcome loss': 0.82961012623748, 'Total loss': 0.82961012623748}
2022-11-23 02:29:06,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:06,969 INFO:     Epoch: 25
2022-11-23 02:29:07,726 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8122865706682205, 'Total loss': 0.8122865706682205} | train loss {'Reaction outcome loss': 0.8219765907647658, 'Total loss': 0.8219765907647658}
2022-11-23 02:29:07,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:07,726 INFO:     Epoch: 26
2022-11-23 02:29:08,552 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8275290829214182, 'Total loss': 0.8275290829214182} | train loss {'Reaction outcome loss': 0.8336091388245018, 'Total loss': 0.8336091388245018}
2022-11-23 02:29:08,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:08,553 INFO:     Epoch: 27
2022-11-23 02:29:09,355 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8014409420165148, 'Total loss': 0.8014409420165148} | train loss {'Reaction outcome loss': 0.8272983585085187, 'Total loss': 0.8272983585085187}
2022-11-23 02:29:09,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:09,356 INFO:     Epoch: 28
2022-11-23 02:29:10,146 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8066145195202394, 'Total loss': 0.8066145195202394} | train loss {'Reaction outcome loss': 0.8287892856159988, 'Total loss': 0.8287892856159988}
2022-11-23 02:29:10,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:10,147 INFO:     Epoch: 29
2022-11-23 02:29:10,935 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8116462494839322, 'Total loss': 0.8116462494839322} | train loss {'Reaction outcome loss': 0.828432191877949, 'Total loss': 0.828432191877949}
2022-11-23 02:29:10,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:10,937 INFO:     Epoch: 30
2022-11-23 02:29:11,740 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8122135393998839, 'Total loss': 0.8122135393998839} | train loss {'Reaction outcome loss': 0.8284257919204479, 'Total loss': 0.8284257919204479}
2022-11-23 02:29:11,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:11,740 INFO:     Epoch: 31
2022-11-23 02:29:12,494 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8090685565363277, 'Total loss': 0.8090685565363277} | train loss {'Reaction outcome loss': 0.8280343875593069, 'Total loss': 0.8280343875593069}
2022-11-23 02:29:12,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:12,495 INFO:     Epoch: 32
2022-11-23 02:29:13,288 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8074884096329863, 'Total loss': 0.8074884096329863} | train loss {'Reaction outcome loss': 0.827697660971661, 'Total loss': 0.827697660971661}
2022-11-23 02:29:13,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:13,288 INFO:     Epoch: 33
2022-11-23 02:29:14,112 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8052409988912669, 'Total loss': 0.8052409988912669} | train loss {'Reaction outcome loss': 0.8258480852963973, 'Total loss': 0.8258480852963973}
2022-11-23 02:29:14,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:14,113 INFO:     Epoch: 34
2022-11-23 02:29:14,877 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8118187101049856, 'Total loss': 0.8118187101049856} | train loss {'Reaction outcome loss': 0.8264498859643936, 'Total loss': 0.8264498859643936}
2022-11-23 02:29:14,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:14,878 INFO:     Epoch: 35
2022-11-23 02:29:15,656 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8470136509700255, 'Total loss': 0.8470136509700255} | train loss {'Reaction outcome loss': 0.8283619182450431, 'Total loss': 0.8283619182450431}
2022-11-23 02:29:15,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:15,656 INFO:     Epoch: 36
2022-11-23 02:29:16,419 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7929619472812522, 'Total loss': 0.7929619472812522} | train loss {'Reaction outcome loss': 0.8317054800841273, 'Total loss': 0.8317054800841273}
2022-11-23 02:29:16,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:16,419 INFO:     Epoch: 37
2022-11-23 02:29:17,194 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.806702500039881, 'Total loss': 0.806702500039881} | train loss {'Reaction outcome loss': 0.8268322256146645, 'Total loss': 0.8268322256146645}
2022-11-23 02:29:17,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:17,195 INFO:     Epoch: 38
2022-11-23 02:29:18,060 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8028983453458006, 'Total loss': 0.8028983453458006} | train loss {'Reaction outcome loss': 0.8282715246385458, 'Total loss': 0.8282715246385458}
2022-11-23 02:29:18,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:18,060 INFO:     Epoch: 39
2022-11-23 02:29:18,872 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8083116933703423, 'Total loss': 0.8083116933703423} | train loss {'Reaction outcome loss': 0.8222198712582491, 'Total loss': 0.8222198712582491}
2022-11-23 02:29:18,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:18,872 INFO:     Epoch: 40
2022-11-23 02:29:19,612 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8001709919084202, 'Total loss': 0.8001709919084202} | train loss {'Reaction outcome loss': 0.8244737168964075, 'Total loss': 0.8244737168964075}
2022-11-23 02:29:19,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:19,612 INFO:     Epoch: 41
2022-11-23 02:29:20,412 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7907418270002712, 'Total loss': 0.7907418270002712} | train loss {'Reaction outcome loss': 0.8306927105601953, 'Total loss': 0.8306927105601953}
2022-11-23 02:29:20,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:20,412 INFO:     Epoch: 42
2022-11-23 02:29:21,269 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8224291625348005, 'Total loss': 0.8224291625348005} | train loss {'Reaction outcome loss': 0.8261574964134061, 'Total loss': 0.8261574964134061}
2022-11-23 02:29:21,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:21,269 INFO:     Epoch: 43
2022-11-23 02:29:22,069 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8033785278146918, 'Total loss': 0.8033785278146918} | train loss {'Reaction outcome loss': 0.8322662022649026, 'Total loss': 0.8322662022649026}
2022-11-23 02:29:22,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:22,069 INFO:     Epoch: 44
2022-11-23 02:29:22,884 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8005649318749254, 'Total loss': 0.8005649318749254} | train loss {'Reaction outcome loss': 0.8304332784243993, 'Total loss': 0.8304332784243993}
2022-11-23 02:29:22,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:22,884 INFO:     Epoch: 45
2022-11-23 02:29:23,684 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8084472932598807, 'Total loss': 0.8084472932598807} | train loss {'Reaction outcome loss': 0.8282860512636145, 'Total loss': 0.8282860512636145}
2022-11-23 02:29:23,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:23,684 INFO:     Epoch: 46
2022-11-23 02:29:24,478 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8060180985114791, 'Total loss': 0.8060180985114791} | train loss {'Reaction outcome loss': 0.8289828755417649, 'Total loss': 0.8289828755417649}
2022-11-23 02:29:24,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:24,478 INFO:     Epoch: 47
2022-11-23 02:29:25,244 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.808311247012832, 'Total loss': 0.808311247012832} | train loss {'Reaction outcome loss': 0.8302977735898933, 'Total loss': 0.8302977735898933}
2022-11-23 02:29:25,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:25,244 INFO:     Epoch: 48
2022-11-23 02:29:26,031 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8197383467446674, 'Total loss': 0.8197383467446674} | train loss {'Reaction outcome loss': 0.8218091883221451, 'Total loss': 0.8218091883221451}
2022-11-23 02:29:26,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:26,032 INFO:     Epoch: 49
2022-11-23 02:29:26,843 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.795886982570995, 'Total loss': 0.795886982570995} | train loss {'Reaction outcome loss': 0.8297829135340087, 'Total loss': 0.8297829135340087}
2022-11-23 02:29:26,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:26,843 INFO:     Epoch: 50
2022-11-23 02:29:27,671 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8081118152900175, 'Total loss': 0.8081118152900175} | train loss {'Reaction outcome loss': 0.8248541507185722, 'Total loss': 0.8248541507185722}
2022-11-23 02:29:27,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:27,671 INFO:     Epoch: 51
2022-11-23 02:29:28,489 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7933537905866449, 'Total loss': 0.7933537905866449} | train loss {'Reaction outcome loss': 0.8226114440937431, 'Total loss': 0.8226114440937431}
2022-11-23 02:29:28,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:28,490 INFO:     Epoch: 52
2022-11-23 02:29:29,293 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8047055087306283, 'Total loss': 0.8047055087306283} | train loss {'Reaction outcome loss': 0.82759564774377, 'Total loss': 0.82759564774377}
2022-11-23 02:29:29,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:29,294 INFO:     Epoch: 53
2022-11-23 02:29:30,122 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7856840701265768, 'Total loss': 0.7856840701265768} | train loss {'Reaction outcome loss': 0.8294714319462679, 'Total loss': 0.8294714319462679}
2022-11-23 02:29:30,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:30,123 INFO:     Epoch: 54
2022-11-23 02:29:30,933 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8203355724161322, 'Total loss': 0.8203355724161322} | train loss {'Reaction outcome loss': 0.8277665804843514, 'Total loss': 0.8277665804843514}
2022-11-23 02:29:30,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:30,933 INFO:     Epoch: 55
2022-11-23 02:29:31,712 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7963526011867956, 'Total loss': 0.7963526011867956} | train loss {'Reaction outcome loss': 0.8257022073074263, 'Total loss': 0.8257022073074263}
2022-11-23 02:29:31,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:31,712 INFO:     Epoch: 56
2022-11-23 02:29:32,510 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8035539842464707, 'Total loss': 0.8035539842464707} | train loss {'Reaction outcome loss': 0.8310670379473238, 'Total loss': 0.8310670379473238}
2022-11-23 02:29:32,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:32,510 INFO:     Epoch: 57
2022-11-23 02:29:33,367 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8117055588147857, 'Total loss': 0.8117055588147857} | train loss {'Reaction outcome loss': 0.826844235342376, 'Total loss': 0.826844235342376}
2022-11-23 02:29:33,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:33,367 INFO:     Epoch: 58
2022-11-23 02:29:34,170 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7895978892391379, 'Total loss': 0.7895978892391379} | train loss {'Reaction outcome loss': 0.824517940015209, 'Total loss': 0.824517940015209}
2022-11-23 02:29:34,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:34,170 INFO:     Epoch: 59
2022-11-23 02:29:34,957 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7854127165946093, 'Total loss': 0.7854127165946093} | train loss {'Reaction outcome loss': 0.8219777861419989, 'Total loss': 0.8219777861419989}
2022-11-23 02:29:34,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:34,957 INFO:     Epoch: 60
2022-11-23 02:29:35,796 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8019740452820604, 'Total loss': 0.8019740452820604} | train loss {'Reaction outcome loss': 0.82613124555471, 'Total loss': 0.82613124555471}
2022-11-23 02:29:35,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:35,797 INFO:     Epoch: 61
2022-11-23 02:29:36,627 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.794815098697489, 'Total loss': 0.794815098697489} | train loss {'Reaction outcome loss': 0.828824992204199, 'Total loss': 0.828824992204199}
2022-11-23 02:29:36,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:36,627 INFO:     Epoch: 62
2022-11-23 02:29:37,459 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8007946312427521, 'Total loss': 0.8007946312427521} | train loss {'Reaction outcome loss': 0.8280956518893339, 'Total loss': 0.8280956518893339}
2022-11-23 02:29:37,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:37,459 INFO:     Epoch: 63
2022-11-23 02:29:38,239 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.824829029765996, 'Total loss': 0.824829029765996} | train loss {'Reaction outcome loss': 0.8258113048514542, 'Total loss': 0.8258113048514542}
2022-11-23 02:29:38,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:38,240 INFO:     Epoch: 64
2022-11-23 02:29:39,027 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.804936869577928, 'Total loss': 0.804936869577928} | train loss {'Reaction outcome loss': 0.8310633164279315, 'Total loss': 0.8310633164279315}
2022-11-23 02:29:39,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:39,027 INFO:     Epoch: 65
2022-11-23 02:29:39,836 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8244814676317301, 'Total loss': 0.8244814676317301} | train loss {'Reaction outcome loss': 0.829273354398961, 'Total loss': 0.829273354398961}
2022-11-23 02:29:39,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:39,836 INFO:     Epoch: 66
2022-11-23 02:29:40,690 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8093381876295264, 'Total loss': 0.8093381876295264} | train loss {'Reaction outcome loss': 0.8249361516261587, 'Total loss': 0.8249361516261587}
2022-11-23 02:29:40,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:40,691 INFO:     Epoch: 67
2022-11-23 02:29:41,527 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7880420962517912, 'Total loss': 0.7880420962517912} | train loss {'Reaction outcome loss': 0.8289300388219405, 'Total loss': 0.8289300388219405}
2022-11-23 02:29:41,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:41,529 INFO:     Epoch: 68
2022-11-23 02:29:42,351 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.822026598859917, 'Total loss': 0.822026598859917} | train loss {'Reaction outcome loss': 0.8275964918185253, 'Total loss': 0.8275964918185253}
2022-11-23 02:29:42,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:42,351 INFO:     Epoch: 69
2022-11-23 02:29:43,130 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7809590842913497, 'Total loss': 0.7809590842913497} | train loss {'Reaction outcome loss': 0.8265806188388747, 'Total loss': 0.8265806188388747}
2022-11-23 02:29:43,130 INFO:     Found new best model at epoch 69
2022-11-23 02:29:43,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:43,131 INFO:     Epoch: 70
2022-11-23 02:29:43,934 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7907984426075761, 'Total loss': 0.7907984426075761} | train loss {'Reaction outcome loss': 0.8273340215488356, 'Total loss': 0.8273340215488356}
2022-11-23 02:29:43,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:43,934 INFO:     Epoch: 71
2022-11-23 02:29:44,757 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7975676303560083, 'Total loss': 0.7975676303560083} | train loss {'Reaction outcome loss': 0.8324660190514156, 'Total loss': 0.8324660190514156}
2022-11-23 02:29:44,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:44,757 INFO:     Epoch: 72
2022-11-23 02:29:45,533 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.805576241151853, 'Total loss': 0.805576241151853} | train loss {'Reaction outcome loss': 0.8253661068118349, 'Total loss': 0.8253661068118349}
2022-11-23 02:29:45,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:45,533 INFO:     Epoch: 73
2022-11-23 02:29:46,347 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8153321621092883, 'Total loss': 0.8153321621092883} | train loss {'Reaction outcome loss': 0.8284682417402462, 'Total loss': 0.8284682417402462}
2022-11-23 02:29:46,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:46,347 INFO:     Epoch: 74
2022-11-23 02:29:47,160 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7883934270251881, 'Total loss': 0.7883934270251881} | train loss {'Reaction outcome loss': 0.8274594729043999, 'Total loss': 0.8274594729043999}
2022-11-23 02:29:47,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:47,160 INFO:     Epoch: 75
2022-11-23 02:29:48,009 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8004893172870983, 'Total loss': 0.8004893172870983} | train loss {'Reaction outcome loss': 0.8278721275378247, 'Total loss': 0.8278721275378247}
2022-11-23 02:29:48,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:48,011 INFO:     Epoch: 76
2022-11-23 02:29:48,782 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7956107644872232, 'Total loss': 0.7956107644872232} | train loss {'Reaction outcome loss': 0.8231927802368086, 'Total loss': 0.8231927802368086}
2022-11-23 02:29:48,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:48,782 INFO:     Epoch: 77
2022-11-23 02:29:49,546 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7864794886925004, 'Total loss': 0.7864794886925004} | train loss {'Reaction outcome loss': 0.8286055438372554, 'Total loss': 0.8286055438372554}
2022-11-23 02:29:49,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:49,546 INFO:     Epoch: 78
2022-11-23 02:29:50,301 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7862110673026605, 'Total loss': 0.7862110673026605} | train loss {'Reaction outcome loss': 0.8244895455788593, 'Total loss': 0.8244895455788593}
2022-11-23 02:29:50,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:50,302 INFO:     Epoch: 79
2022-11-23 02:29:51,084 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.788323468782685, 'Total loss': 0.788323468782685} | train loss {'Reaction outcome loss': 0.8265880356029588, 'Total loss': 0.8265880356029588}
2022-11-23 02:29:51,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:51,085 INFO:     Epoch: 80
2022-11-23 02:29:51,823 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.804534927349199, 'Total loss': 0.804534927349199} | train loss {'Reaction outcome loss': 0.83125260034386, 'Total loss': 0.83125260034386}
2022-11-23 02:29:51,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:51,823 INFO:     Epoch: 81
2022-11-23 02:29:52,636 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8461748524145647, 'Total loss': 0.8461748524145647} | train loss {'Reaction outcome loss': 0.8238874524223562, 'Total loss': 0.8238874524223562}
2022-11-23 02:29:52,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:52,636 INFO:     Epoch: 82
2022-11-23 02:29:53,421 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8351151137189432, 'Total loss': 0.8351151137189432} | train loss {'Reaction outcome loss': 0.8358474794699221, 'Total loss': 0.8358474794699221}
2022-11-23 02:29:53,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:53,421 INFO:     Epoch: 83
2022-11-23 02:29:54,187 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8162201927466826, 'Total loss': 0.8162201927466826} | train loss {'Reaction outcome loss': 0.8293588953358787, 'Total loss': 0.8293588953358787}
2022-11-23 02:29:54,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:54,187 INFO:     Epoch: 84
2022-11-23 02:29:54,932 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.782891917635094, 'Total loss': 0.782891917635094} | train loss {'Reaction outcome loss': 0.8293110808547662, 'Total loss': 0.8293110808547662}
2022-11-23 02:29:54,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:54,932 INFO:     Epoch: 85
2022-11-23 02:29:55,675 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8551199100911617, 'Total loss': 0.8551199100911617} | train loss {'Reaction outcome loss': 0.8254065475901778, 'Total loss': 0.8254065475901778}
2022-11-23 02:29:55,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:55,675 INFO:     Epoch: 86
2022-11-23 02:29:56,463 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7939940548755906, 'Total loss': 0.7939940548755906} | train loss {'Reaction outcome loss': 0.8289163164946498, 'Total loss': 0.8289163164946498}
2022-11-23 02:29:56,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:56,463 INFO:     Epoch: 87
2022-11-23 02:29:57,231 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8164109540256587, 'Total loss': 0.8164109540256587} | train loss {'Reaction outcome loss': 0.8243081506417722, 'Total loss': 0.8243081506417722}
2022-11-23 02:29:57,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:57,231 INFO:     Epoch: 88
2022-11-23 02:29:58,022 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8231588480147448, 'Total loss': 0.8231588480147448} | train loss {'Reaction outcome loss': 0.8267744414660395, 'Total loss': 0.8267744414660395}
2022-11-23 02:29:58,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:58,022 INFO:     Epoch: 89
2022-11-23 02:29:58,820 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7887482141906564, 'Total loss': 0.7887482141906564} | train loss {'Reaction outcome loss': 0.8260458390323483, 'Total loss': 0.8260458390323483}
2022-11-23 02:29:58,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:58,820 INFO:     Epoch: 90
2022-11-23 02:29:59,598 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8225795545361259, 'Total loss': 0.8225795545361259} | train loss {'Reaction outcome loss': 0.8265854429225532, 'Total loss': 0.8265854429225532}
2022-11-23 02:29:59,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:29:59,599 INFO:     Epoch: 91
2022-11-23 02:30:00,401 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7734763141382824, 'Total loss': 0.7734763141382824} | train loss {'Reaction outcome loss': 0.829172232807899, 'Total loss': 0.829172232807899}
2022-11-23 02:30:00,402 INFO:     Found new best model at epoch 91
2022-11-23 02:30:00,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:00,404 INFO:     Epoch: 92
2022-11-23 02:30:01,217 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.804543792524121, 'Total loss': 0.804543792524121} | train loss {'Reaction outcome loss': 0.8239543105874743, 'Total loss': 0.8239543105874743}
2022-11-23 02:30:01,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:01,218 INFO:     Epoch: 93
2022-11-23 02:30:02,102 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8193093511191282, 'Total loss': 0.8193093511191282} | train loss {'Reaction outcome loss': 0.8268732034430212, 'Total loss': 0.8268732034430212}
2022-11-23 02:30:02,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:02,103 INFO:     Epoch: 94
2022-11-23 02:30:02,912 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8168158693747087, 'Total loss': 0.8168158693747087} | train loss {'Reaction outcome loss': 0.8266481247483467, 'Total loss': 0.8266481247483467}
2022-11-23 02:30:02,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:02,912 INFO:     Epoch: 95
2022-11-23 02:30:03,737 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7760451192205603, 'Total loss': 0.7760451192205603} | train loss {'Reaction outcome loss': 0.8255453225301237, 'Total loss': 0.8255453225301237}
2022-11-23 02:30:03,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:03,737 INFO:     Epoch: 96
2022-11-23 02:30:04,642 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8019404275850817, 'Total loss': 0.8019404275850817} | train loss {'Reaction outcome loss': 0.8311880867700188, 'Total loss': 0.8311880867700188}
2022-11-23 02:30:04,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:04,642 INFO:     Epoch: 97
2022-11-23 02:30:05,478 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8017564226280559, 'Total loss': 0.8017564226280559} | train loss {'Reaction outcome loss': 0.8253059839715763, 'Total loss': 0.8253059839715763}
2022-11-23 02:30:05,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:05,479 INFO:     Epoch: 98
2022-11-23 02:30:06,333 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7991908307779919, 'Total loss': 0.7991908307779919} | train loss {'Reaction outcome loss': 0.8253816667868167, 'Total loss': 0.8253816667868167}
2022-11-23 02:30:06,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:06,333 INFO:     Epoch: 99
2022-11-23 02:30:07,155 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8209971961649981, 'Total loss': 0.8209971961649981} | train loss {'Reaction outcome loss': 0.8227712269948453, 'Total loss': 0.8227712269948453}
2022-11-23 02:30:07,155 INFO:     Best model found after epoch 92 of 100.
2022-11-23 02:30:07,156 INFO:   Done with stage: TRAINING
2022-11-23 02:30:07,156 INFO:   Starting stage: EVALUATION
2022-11-23 02:30:07,286 INFO:   Done with stage: EVALUATION
2022-11-23 02:30:07,286 INFO:   Leaving out SEQ value Fold_2
2022-11-23 02:30:07,299 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:30:07,300 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:30:07,968 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:30:07,969 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:30:08,041 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:30:08,041 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:30:08,041 INFO:     No hyperparam tuning for this model
2022-11-23 02:30:08,041 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:30:08,041 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:30:08,042 INFO:     None feature selector for col prot
2022-11-23 02:30:08,042 INFO:     None feature selector for col prot
2022-11-23 02:30:08,042 INFO:     None feature selector for col prot
2022-11-23 02:30:08,043 INFO:     None feature selector for col chem
2022-11-23 02:30:08,043 INFO:     None feature selector for col chem
2022-11-23 02:30:08,043 INFO:     None feature selector for col chem
2022-11-23 02:30:08,043 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:30:08,043 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:30:08,045 INFO:     Number of params in model 168571
2022-11-23 02:30:08,048 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:30:08,048 INFO:   Starting stage: TRAINING
2022-11-23 02:30:08,106 INFO:     Val loss before train {'Reaction outcome loss': 1.0122558041052385, 'Total loss': 1.0122558041052385}
2022-11-23 02:30:08,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:08,106 INFO:     Epoch: 0
2022-11-23 02:30:08,939 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8727132637392391, 'Total loss': 0.8727132637392391} | train loss {'Reaction outcome loss': 0.8844188327490077, 'Total loss': 0.8844188327490077}
2022-11-23 02:30:08,939 INFO:     Found new best model at epoch 0
2022-11-23 02:30:08,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:08,940 INFO:     Epoch: 1
2022-11-23 02:30:09,741 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8600268201394514, 'Total loss': 0.8600268201394514} | train loss {'Reaction outcome loss': 0.8553504872659923, 'Total loss': 0.8553504872659923}
2022-11-23 02:30:09,741 INFO:     Found new best model at epoch 1
2022-11-23 02:30:09,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:09,742 INFO:     Epoch: 2
2022-11-23 02:30:10,526 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8490971394560554, 'Total loss': 0.8490971394560554} | train loss {'Reaction outcome loss': 0.8416429728661713, 'Total loss': 0.8416429728661713}
2022-11-23 02:30:10,526 INFO:     Found new best model at epoch 2
2022-11-23 02:30:10,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:10,527 INFO:     Epoch: 3
2022-11-23 02:30:11,343 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8294966396960345, 'Total loss': 0.8294966396960345} | train loss {'Reaction outcome loss': 0.8339943593812857, 'Total loss': 0.8339943593812857}
2022-11-23 02:30:11,343 INFO:     Found new best model at epoch 3
2022-11-23 02:30:11,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:11,344 INFO:     Epoch: 4
2022-11-23 02:30:12,128 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8618335615504872, 'Total loss': 0.8618335615504872} | train loss {'Reaction outcome loss': 0.841743667598678, 'Total loss': 0.841743667598678}
2022-11-23 02:30:12,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:12,128 INFO:     Epoch: 5
2022-11-23 02:30:12,915 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8373332998969338, 'Total loss': 0.8373332998969338} | train loss {'Reaction outcome loss': 0.8312415065553024, 'Total loss': 0.8312415065553024}
2022-11-23 02:30:12,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:12,916 INFO:     Epoch: 6
2022-11-23 02:30:13,738 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8351566777987913, 'Total loss': 0.8351566777987913} | train loss {'Reaction outcome loss': 0.8334022432203717, 'Total loss': 0.8334022432203717}
2022-11-23 02:30:13,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:13,738 INFO:     Epoch: 7
2022-11-23 02:30:14,594 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8388963389125738, 'Total loss': 0.8388963389125738} | train loss {'Reaction outcome loss': 0.8237608139693495, 'Total loss': 0.8237608139693495}
2022-11-23 02:30:14,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:14,594 INFO:     Epoch: 8
2022-11-23 02:30:15,416 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8501480946486647, 'Total loss': 0.8501480946486647} | train loss {'Reaction outcome loss': 0.8253474000253176, 'Total loss': 0.8253474000253176}
2022-11-23 02:30:15,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:15,416 INFO:     Epoch: 9
2022-11-23 02:30:16,226 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8376098769632253, 'Total loss': 0.8376098769632253} | train loss {'Reaction outcome loss': 0.8340135759670242, 'Total loss': 0.8340135759670242}
2022-11-23 02:30:16,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:16,227 INFO:     Epoch: 10
2022-11-23 02:30:17,042 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8382981785319068, 'Total loss': 0.8382981785319068} | train loss {'Reaction outcome loss': 0.8194220404815578, 'Total loss': 0.8194220404815578}
2022-11-23 02:30:17,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:17,043 INFO:     Epoch: 11
2022-11-23 02:30:17,873 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8368092612786726, 'Total loss': 0.8368092612786726} | train loss {'Reaction outcome loss': 0.8170634519897009, 'Total loss': 0.8170634519897009}
2022-11-23 02:30:17,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:17,873 INFO:     Epoch: 12
2022-11-23 02:30:18,672 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8243174972859296, 'Total loss': 0.8243174972859296} | train loss {'Reaction outcome loss': 0.8164215088192268, 'Total loss': 0.8164215088192268}
2022-11-23 02:30:18,672 INFO:     Found new best model at epoch 12
2022-11-23 02:30:18,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:18,673 INFO:     Epoch: 13
2022-11-23 02:30:19,463 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8408098837191408, 'Total loss': 0.8408098837191408} | train loss {'Reaction outcome loss': 0.8203706761844728, 'Total loss': 0.8203706761844728}
2022-11-23 02:30:19,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:19,464 INFO:     Epoch: 14
2022-11-23 02:30:20,268 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8384964581240307, 'Total loss': 0.8384964581240307} | train loss {'Reaction outcome loss': 0.8150123241640296, 'Total loss': 0.8150123241640296}
2022-11-23 02:30:20,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:20,269 INFO:     Epoch: 15
2022-11-23 02:30:21,087 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.827530019662597, 'Total loss': 0.827530019662597} | train loss {'Reaction outcome loss': 0.8220723527163146, 'Total loss': 0.8220723527163146}
2022-11-23 02:30:21,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:21,087 INFO:     Epoch: 16
2022-11-23 02:30:21,914 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8118229467760433, 'Total loss': 0.8118229467760433} | train loss {'Reaction outcome loss': 0.819037391589238, 'Total loss': 0.819037391589238}
2022-11-23 02:30:21,914 INFO:     Found new best model at epoch 16
2022-11-23 02:30:21,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:21,915 INFO:     Epoch: 17
2022-11-23 02:30:22,774 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8280014775016091, 'Total loss': 0.8280014775016091} | train loss {'Reaction outcome loss': 0.8254981235212643, 'Total loss': 0.8254981235212643}
2022-11-23 02:30:22,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:22,774 INFO:     Epoch: 18
2022-11-23 02:30:23,593 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8296111476692286, 'Total loss': 0.8296111476692286} | train loss {'Reaction outcome loss': 0.8170860713792716, 'Total loss': 0.8170860713792716}
2022-11-23 02:30:23,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:23,594 INFO:     Epoch: 19
2022-11-23 02:30:24,408 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8191128698262301, 'Total loss': 0.8191128698262301} | train loss {'Reaction outcome loss': 0.8206662346235654, 'Total loss': 0.8206662346235654}
2022-11-23 02:30:24,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:24,408 INFO:     Epoch: 20
2022-11-23 02:30:25,234 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8194018358534033, 'Total loss': 0.8194018358534033} | train loss {'Reaction outcome loss': 0.8122957721805042, 'Total loss': 0.8122957721805042}
2022-11-23 02:30:25,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:25,234 INFO:     Epoch: 21
2022-11-23 02:30:26,002 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.82311926511201, 'Total loss': 0.82311926511201} | train loss {'Reaction outcome loss': 0.8138305491764053, 'Total loss': 0.8138305491764053}
2022-11-23 02:30:26,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:26,002 INFO:     Epoch: 22
2022-11-23 02:30:26,864 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8300890678709204, 'Total loss': 0.8300890678709204} | train loss {'Reaction outcome loss': 0.8170339027155749, 'Total loss': 0.8170339027155749}
2022-11-23 02:30:26,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:26,865 INFO:     Epoch: 23
2022-11-23 02:30:27,638 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8310977437279441, 'Total loss': 0.8310977437279441} | train loss {'Reaction outcome loss': 0.8211938865512971, 'Total loss': 0.8211938865512971}
2022-11-23 02:30:27,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:27,639 INFO:     Epoch: 24
2022-11-23 02:30:28,488 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.836487583138726, 'Total loss': 0.836487583138726} | train loss {'Reaction outcome loss': 0.8239054256363919, 'Total loss': 0.8239054256363919}
2022-11-23 02:30:28,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:28,489 INFO:     Epoch: 25
2022-11-23 02:30:29,290 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8143498071215369, 'Total loss': 0.8143498071215369} | train loss {'Reaction outcome loss': 0.8312604490079378, 'Total loss': 0.8312604490079378}
2022-11-23 02:30:29,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:29,290 INFO:     Epoch: 26
2022-11-23 02:30:30,123 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8512725606560707, 'Total loss': 0.8512725606560707} | train loss {'Reaction outcome loss': 0.8169899155736452, 'Total loss': 0.8169899155736452}
2022-11-23 02:30:30,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:30,124 INFO:     Epoch: 27
2022-11-23 02:30:30,927 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8257625861601396, 'Total loss': 0.8257625861601396} | train loss {'Reaction outcome loss': 0.8156619366062315, 'Total loss': 0.8156619366062315}
2022-11-23 02:30:30,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:30,928 INFO:     Epoch: 28
2022-11-23 02:30:31,769 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8279550651257689, 'Total loss': 0.8279550651257689} | train loss {'Reaction outcome loss': 0.8135960222738474, 'Total loss': 0.8135960222738474}
2022-11-23 02:30:31,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:31,770 INFO:     Epoch: 29
2022-11-23 02:30:32,545 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8297143402424726, 'Total loss': 0.8297143402424726} | train loss {'Reaction outcome loss': 0.8110301459607808, 'Total loss': 0.8110301459607808}
2022-11-23 02:30:32,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:32,545 INFO:     Epoch: 30
2022-11-23 02:30:33,327 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8196072192354635, 'Total loss': 0.8196072192354635} | train loss {'Reaction outcome loss': 0.8168984775842443, 'Total loss': 0.8168984775842443}
2022-11-23 02:30:33,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:33,327 INFO:     Epoch: 31
2022-11-23 02:30:34,115 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8150161050937392, 'Total loss': 0.8150161050937392} | train loss {'Reaction outcome loss': 0.8223711387348561, 'Total loss': 0.8223711387348561}
2022-11-23 02:30:34,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:34,115 INFO:     Epoch: 32
2022-11-23 02:30:34,878 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8422820249741728, 'Total loss': 0.8422820249741728} | train loss {'Reaction outcome loss': 0.8124129354109165, 'Total loss': 0.8124129354109165}
2022-11-23 02:30:34,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:34,879 INFO:     Epoch: 33
2022-11-23 02:30:35,648 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8246919702399861, 'Total loss': 0.8246919702399861} | train loss {'Reaction outcome loss': 0.8118775737762209, 'Total loss': 0.8118775737762209}
2022-11-23 02:30:35,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:35,648 INFO:     Epoch: 34
2022-11-23 02:30:36,471 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8165982318195429, 'Total loss': 0.8165982318195429} | train loss {'Reaction outcome loss': 0.818994228415161, 'Total loss': 0.818994228415161}
2022-11-23 02:30:36,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:36,471 INFO:     Epoch: 35
2022-11-23 02:30:37,304 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8455684591423381, 'Total loss': 0.8455684591423381} | train loss {'Reaction outcome loss': 0.8207960255474214, 'Total loss': 0.8207960255474214}
2022-11-23 02:30:37,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:37,305 INFO:     Epoch: 36
2022-11-23 02:30:38,085 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8336418846791441, 'Total loss': 0.8336418846791441} | train loss {'Reaction outcome loss': 0.8081499562572371, 'Total loss': 0.8081499562572371}
2022-11-23 02:30:38,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:38,086 INFO:     Epoch: 37
2022-11-23 02:30:38,898 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8181113715876233, 'Total loss': 0.8181113715876233} | train loss {'Reaction outcome loss': 0.8089274028052202, 'Total loss': 0.8089274028052202}
2022-11-23 02:30:38,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:38,898 INFO:     Epoch: 38
2022-11-23 02:30:39,727 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8306245390664447, 'Total loss': 0.8306245390664447} | train loss {'Reaction outcome loss': 0.8167211226364861, 'Total loss': 0.8167211226364861}
2022-11-23 02:30:39,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:39,728 INFO:     Epoch: 39
2022-11-23 02:30:40,576 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8236464438113299, 'Total loss': 0.8236464438113299} | train loss {'Reaction outcome loss': 0.8165221355463329, 'Total loss': 0.8165221355463329}
2022-11-23 02:30:40,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:40,576 INFO:     Epoch: 40
2022-11-23 02:30:41,408 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8159291690046137, 'Total loss': 0.8159291690046137} | train loss {'Reaction outcome loss': 0.8109533439281016, 'Total loss': 0.8109533439281016}
2022-11-23 02:30:41,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:41,409 INFO:     Epoch: 41
2022-11-23 02:30:42,249 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8182317167520523, 'Total loss': 0.8182317167520523} | train loss {'Reaction outcome loss': 0.8083871262758849, 'Total loss': 0.8083871262758849}
2022-11-23 02:30:42,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:42,250 INFO:     Epoch: 42
2022-11-23 02:30:43,052 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.846757714043964, 'Total loss': 0.846757714043964} | train loss {'Reaction outcome loss': 0.8135149990498778, 'Total loss': 0.8135149990498778}
2022-11-23 02:30:43,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:43,053 INFO:     Epoch: 43
2022-11-23 02:30:43,895 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8184852992946451, 'Total loss': 0.8184852992946451} | train loss {'Reaction outcome loss': 0.8136501723998472, 'Total loss': 0.8136501723998472}
2022-11-23 02:30:43,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:43,896 INFO:     Epoch: 44
2022-11-23 02:30:44,694 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8200215196067636, 'Total loss': 0.8200215196067636} | train loss {'Reaction outcome loss': 0.811723809131244, 'Total loss': 0.811723809131244}
2022-11-23 02:30:44,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:44,694 INFO:     Epoch: 45
2022-11-23 02:30:45,462 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8291253271428022, 'Total loss': 0.8291253271428022} | train loss {'Reaction outcome loss': 0.820194338014734, 'Total loss': 0.820194338014734}
2022-11-23 02:30:45,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:45,462 INFO:     Epoch: 46
2022-11-23 02:30:46,237 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8159130147912286, 'Total loss': 0.8159130147912286} | train loss {'Reaction outcome loss': 0.8146212626444665, 'Total loss': 0.8146212626444665}
2022-11-23 02:30:46,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:46,237 INFO:     Epoch: 47
2022-11-23 02:30:47,042 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8462232039733366, 'Total loss': 0.8462232039733366} | train loss {'Reaction outcome loss': 0.8166606905248001, 'Total loss': 0.8166606905248001}
2022-11-23 02:30:47,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:47,042 INFO:     Epoch: 48
2022-11-23 02:30:47,875 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8152138692411509, 'Total loss': 0.8152138692411509} | train loss {'Reaction outcome loss': 0.8167562353677353, 'Total loss': 0.8167562353677353}
2022-11-23 02:30:47,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:47,875 INFO:     Epoch: 49
2022-11-23 02:30:48,658 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8214260637760162, 'Total loss': 0.8214260637760162} | train loss {'Reaction outcome loss': 0.8088281761538162, 'Total loss': 0.8088281761538162}
2022-11-23 02:30:48,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:48,658 INFO:     Epoch: 50
2022-11-23 02:30:49,485 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8427488234910098, 'Total loss': 0.8427488234910098} | train loss {'Reaction outcome loss': 0.8078488766664436, 'Total loss': 0.8078488766664436}
2022-11-23 02:30:49,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:49,485 INFO:     Epoch: 51
2022-11-23 02:30:50,291 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8204026344147596, 'Total loss': 0.8204026344147596} | train loss {'Reaction outcome loss': 0.8142343479612095, 'Total loss': 0.8142343479612095}
2022-11-23 02:30:50,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:50,292 INFO:     Epoch: 52
2022-11-23 02:30:51,112 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8085544624111869, 'Total loss': 0.8085544624111869} | train loss {'Reaction outcome loss': 0.8097093465779475, 'Total loss': 0.8097093465779475}
2022-11-23 02:30:51,112 INFO:     Found new best model at epoch 52
2022-11-23 02:30:51,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:51,113 INFO:     Epoch: 53
2022-11-23 02:30:51,932 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8336529657244682, 'Total loss': 0.8336529657244682} | train loss {'Reaction outcome loss': 0.815215903737767, 'Total loss': 0.815215903737767}
2022-11-23 02:30:51,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:51,932 INFO:     Epoch: 54
2022-11-23 02:30:52,716 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8259052160111341, 'Total loss': 0.8259052160111341} | train loss {'Reaction outcome loss': 0.811963797580858, 'Total loss': 0.811963797580858}
2022-11-23 02:30:52,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:52,716 INFO:     Epoch: 55
2022-11-23 02:30:53,498 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8200968273661353, 'Total loss': 0.8200968273661353} | train loss {'Reaction outcome loss': 0.8144599013482994, 'Total loss': 0.8144599013482994}
2022-11-23 02:30:53,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:53,499 INFO:     Epoch: 56
2022-11-23 02:30:54,305 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8312209113077684, 'Total loss': 0.8312209113077684} | train loss {'Reaction outcome loss': 0.8099103576017295, 'Total loss': 0.8099103576017295}
2022-11-23 02:30:54,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:54,305 INFO:     Epoch: 57
2022-11-23 02:30:55,051 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8155414462089539, 'Total loss': 0.8155414462089539} | train loss {'Reaction outcome loss': 0.8054317595203396, 'Total loss': 0.8054317595203396}
2022-11-23 02:30:55,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:55,052 INFO:     Epoch: 58
2022-11-23 02:30:55,790 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8104393455115232, 'Total loss': 0.8104393455115232} | train loss {'Reaction outcome loss': 0.8091950409325511, 'Total loss': 0.8091950409325511}
2022-11-23 02:30:55,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:55,790 INFO:     Epoch: 59
2022-11-23 02:30:56,578 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8162530680949037, 'Total loss': 0.8162530680949037} | train loss {'Reaction outcome loss': 0.8147712102544452, 'Total loss': 0.8147712102544452}
2022-11-23 02:30:56,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:56,578 INFO:     Epoch: 60
2022-11-23 02:30:57,370 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.818868337707086, 'Total loss': 0.818868337707086} | train loss {'Reaction outcome loss': 0.8131130594714933, 'Total loss': 0.8131130594714933}
2022-11-23 02:30:57,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:57,370 INFO:     Epoch: 61
2022-11-23 02:30:58,186 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8197400034828619, 'Total loss': 0.8197400034828619} | train loss {'Reaction outcome loss': 0.8096625176277238, 'Total loss': 0.8096625176277238}
2022-11-23 02:30:58,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:58,187 INFO:     Epoch: 62
2022-11-23 02:30:59,050 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8450326628305695, 'Total loss': 0.8450326628305695} | train loss {'Reaction outcome loss': 0.8190001287923651, 'Total loss': 0.8190001287923651}
2022-11-23 02:30:59,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:59,051 INFO:     Epoch: 63
2022-11-23 02:30:59,877 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8238528709519993, 'Total loss': 0.8238528709519993} | train loss {'Reaction outcome loss': 0.8235985782706303, 'Total loss': 0.8235985782706303}
2022-11-23 02:30:59,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:30:59,877 INFO:     Epoch: 64
2022-11-23 02:31:00,704 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8268231187354435, 'Total loss': 0.8268231187354435} | train loss {'Reaction outcome loss': 0.807829499968633, 'Total loss': 0.807829499968633}
2022-11-23 02:31:00,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:00,704 INFO:     Epoch: 65
2022-11-23 02:31:01,534 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8083630502223969, 'Total loss': 0.8083630502223969} | train loss {'Reaction outcome loss': 0.8083772789611507, 'Total loss': 0.8083772789611507}
2022-11-23 02:31:01,534 INFO:     Found new best model at epoch 65
2022-11-23 02:31:01,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:01,535 INFO:     Epoch: 66
2022-11-23 02:31:02,332 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8284247449853204, 'Total loss': 0.8284247449853204} | train loss {'Reaction outcome loss': 0.818572512401743, 'Total loss': 0.818572512401743}
2022-11-23 02:31:02,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:02,333 INFO:     Epoch: 67
2022-11-23 02:31:03,181 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8442195911299099, 'Total loss': 0.8442195911299099} | train loss {'Reaction outcome loss': 0.8131015992116349, 'Total loss': 0.8131015992116349}
2022-11-23 02:31:03,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:03,182 INFO:     Epoch: 68
2022-11-23 02:31:04,005 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8311705643480475, 'Total loss': 0.8311705643480475} | train loss {'Reaction outcome loss': 0.8142872993280048, 'Total loss': 0.8142872993280048}
2022-11-23 02:31:04,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:04,005 INFO:     Epoch: 69
2022-11-23 02:31:04,837 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8422231850298968, 'Total loss': 0.8422231850298968} | train loss {'Reaction outcome loss': 0.8178700990522438, 'Total loss': 0.8178700990522438}
2022-11-23 02:31:04,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:04,837 INFO:     Epoch: 70
2022-11-23 02:31:05,680 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8233082965016365, 'Total loss': 0.8233082965016365} | train loss {'Reaction outcome loss': 0.8108076489406076, 'Total loss': 0.8108076489406076}
2022-11-23 02:31:05,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:05,680 INFO:     Epoch: 71
2022-11-23 02:31:06,507 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8242786011912606, 'Total loss': 0.8242786011912606} | train loss {'Reaction outcome loss': 0.823506501884113, 'Total loss': 0.823506501884113}
2022-11-23 02:31:06,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:06,507 INFO:     Epoch: 72
2022-11-23 02:31:07,392 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8404416821219705, 'Total loss': 0.8404416821219705} | train loss {'Reaction outcome loss': 0.8164351051635588, 'Total loss': 0.8164351051635588}
2022-11-23 02:31:07,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:07,393 INFO:     Epoch: 73
2022-11-23 02:31:08,354 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8127575323662974, 'Total loss': 0.8127575323662974} | train loss {'Reaction outcome loss': 0.8085745424183033, 'Total loss': 0.8085745424183033}
2022-11-23 02:31:08,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:08,354 INFO:     Epoch: 74
2022-11-23 02:31:09,212 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.827899460088123, 'Total loss': 0.827899460088123} | train loss {'Reaction outcome loss': 0.8122857394006088, 'Total loss': 0.8122857394006088}
2022-11-23 02:31:09,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:09,212 INFO:     Epoch: 75
2022-11-23 02:31:10,044 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8224155462600968, 'Total loss': 0.8224155462600968} | train loss {'Reaction outcome loss': 0.8076121223117658, 'Total loss': 0.8076121223117658}
2022-11-23 02:31:10,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:10,044 INFO:     Epoch: 76
2022-11-23 02:31:10,863 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8253273916515437, 'Total loss': 0.8253273916515437} | train loss {'Reaction outcome loss': 0.8082849490135787, 'Total loss': 0.8082849490135787}
2022-11-23 02:31:10,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:10,864 INFO:     Epoch: 77
2022-11-23 02:31:11,692 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8236842006444931, 'Total loss': 0.8236842006444931} | train loss {'Reaction outcome loss': 0.8055063584736484, 'Total loss': 0.8055063584736484}
2022-11-23 02:31:11,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:11,692 INFO:     Epoch: 78
2022-11-23 02:31:12,566 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8193718303333629, 'Total loss': 0.8193718303333629} | train loss {'Reaction outcome loss': 0.816766077690279, 'Total loss': 0.816766077690279}
2022-11-23 02:31:12,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:12,566 INFO:     Epoch: 79
2022-11-23 02:31:13,416 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8111411400816657, 'Total loss': 0.8111411400816657} | train loss {'Reaction outcome loss': 0.8125967206018656, 'Total loss': 0.8125967206018656}
2022-11-23 02:31:13,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:13,416 INFO:     Epoch: 80
2022-11-23 02:31:14,223 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8124656094746157, 'Total loss': 0.8124656094746157} | train loss {'Reaction outcome loss': 0.8069100950652288, 'Total loss': 0.8069100950652288}
2022-11-23 02:31:14,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:14,223 INFO:     Epoch: 81
2022-11-23 02:31:15,095 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8100148730657317, 'Total loss': 0.8100148730657317} | train loss {'Reaction outcome loss': 0.8130049353789705, 'Total loss': 0.8130049353789705}
2022-11-23 02:31:15,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:15,096 INFO:     Epoch: 82
2022-11-23 02:31:15,921 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8202903406186537, 'Total loss': 0.8202903406186537} | train loss {'Reaction outcome loss': 0.8189148128273999, 'Total loss': 0.8189148128273999}
2022-11-23 02:31:15,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:15,921 INFO:     Epoch: 83
2022-11-23 02:31:16,770 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8088124543428421, 'Total loss': 0.8088124543428421} | train loss {'Reaction outcome loss': 0.8110136139972007, 'Total loss': 0.8110136139972007}
2022-11-23 02:31:16,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:16,771 INFO:     Epoch: 84
2022-11-23 02:31:17,562 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8051387715068731, 'Total loss': 0.8051387715068731} | train loss {'Reaction outcome loss': 0.8151559417064373, 'Total loss': 0.8151559417064373}
2022-11-23 02:31:17,562 INFO:     Found new best model at epoch 84
2022-11-23 02:31:17,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:17,563 INFO:     Epoch: 85
2022-11-23 02:31:18,390 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8260168724439361, 'Total loss': 0.8260168724439361} | train loss {'Reaction outcome loss': 0.8155713880713652, 'Total loss': 0.8155713880713652}
2022-11-23 02:31:18,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:18,390 INFO:     Epoch: 86
2022-11-23 02:31:19,200 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8342025198719718, 'Total loss': 0.8342025198719718} | train loss {'Reaction outcome loss': 0.8219885503956181, 'Total loss': 0.8219885503956181}
2022-11-23 02:31:19,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:19,200 INFO:     Epoch: 87
2022-11-23 02:31:20,012 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8184308382597837, 'Total loss': 0.8184308382597837} | train loss {'Reaction outcome loss': 0.8133345541925083, 'Total loss': 0.8133345541925083}
2022-11-23 02:31:20,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:20,012 INFO:     Epoch: 88
2022-11-23 02:31:20,843 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.825240627608516, 'Total loss': 0.825240627608516} | train loss {'Reaction outcome loss': 0.8095304383198741, 'Total loss': 0.8095304383198741}
2022-11-23 02:31:20,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:20,844 INFO:     Epoch: 89
2022-11-23 02:31:21,663 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8184860287742182, 'Total loss': 0.8184860287742182} | train loss {'Reaction outcome loss': 0.8182623639763126, 'Total loss': 0.8182623639763126}
2022-11-23 02:31:21,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:21,664 INFO:     Epoch: 90
2022-11-23 02:31:22,478 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.81484155356884, 'Total loss': 0.81484155356884} | train loss {'Reaction outcome loss': 0.8091694209196789, 'Total loss': 0.8091694209196789}
2022-11-23 02:31:22,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:22,479 INFO:     Epoch: 91
2022-11-23 02:31:23,306 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8220435265790332, 'Total loss': 0.8220435265790332} | train loss {'Reaction outcome loss': 0.8058352033920616, 'Total loss': 0.8058352033920616}
2022-11-23 02:31:23,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:23,307 INFO:     Epoch: 92
2022-11-23 02:31:24,138 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8097646378658034, 'Total loss': 0.8097646378658034} | train loss {'Reaction outcome loss': 0.8099724015726252, 'Total loss': 0.8099724015726252}
2022-11-23 02:31:24,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:24,139 INFO:     Epoch: 93
2022-11-23 02:31:24,951 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8263354294679381, 'Total loss': 0.8263354294679381} | train loss {'Reaction outcome loss': 0.8077134226377194, 'Total loss': 0.8077134226377194}
2022-11-23 02:31:24,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:24,951 INFO:     Epoch: 94
2022-11-23 02:31:25,729 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8437157205559991, 'Total loss': 0.8437157205559991} | train loss {'Reaction outcome loss': 0.8058569275506353, 'Total loss': 0.8058569275506353}
2022-11-23 02:31:25,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:25,729 INFO:     Epoch: 95
2022-11-23 02:31:26,560 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8127987425435673, 'Total loss': 0.8127987425435673} | train loss {'Reaction outcome loss': 0.8110068406653308, 'Total loss': 0.8110068406653308}
2022-11-23 02:31:26,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:26,561 INFO:     Epoch: 96
2022-11-23 02:31:27,394 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.817925134843046, 'Total loss': 0.817925134843046} | train loss {'Reaction outcome loss': 0.8175143843237688, 'Total loss': 0.8175143843237688}
2022-11-23 02:31:27,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:27,395 INFO:     Epoch: 97
2022-11-23 02:31:28,205 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8233133351260965, 'Total loss': 0.8233133351260965} | train loss {'Reaction outcome loss': 0.813977454958657, 'Total loss': 0.813977454958657}
2022-11-23 02:31:28,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:28,205 INFO:     Epoch: 98
2022-11-23 02:31:29,042 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8315464332699776, 'Total loss': 0.8315464332699776} | train loss {'Reaction outcome loss': 0.809690416221194, 'Total loss': 0.809690416221194}
2022-11-23 02:31:29,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:29,042 INFO:     Epoch: 99
2022-11-23 02:31:29,850 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8190867900848389, 'Total loss': 0.8190867900848389} | train loss {'Reaction outcome loss': 0.8097052258035915, 'Total loss': 0.8097052258035915}
2022-11-23 02:31:29,850 INFO:     Best model found after epoch 85 of 100.
2022-11-23 02:31:29,850 INFO:   Done with stage: TRAINING
2022-11-23 02:31:29,850 INFO:   Starting stage: EVALUATION
2022-11-23 02:31:29,975 INFO:   Done with stage: EVALUATION
2022-11-23 02:31:29,975 INFO:   Leaving out SEQ value Fold_3
2022-11-23 02:31:29,988 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:31:29,988 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:31:30,659 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:31:30,659 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:31:30,733 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:31:30,733 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:31:30,733 INFO:     No hyperparam tuning for this model
2022-11-23 02:31:30,733 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:31:30,733 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:31:30,734 INFO:     None feature selector for col prot
2022-11-23 02:31:30,734 INFO:     None feature selector for col prot
2022-11-23 02:31:30,735 INFO:     None feature selector for col prot
2022-11-23 02:31:30,735 INFO:     None feature selector for col chem
2022-11-23 02:31:30,735 INFO:     None feature selector for col chem
2022-11-23 02:31:30,736 INFO:     None feature selector for col chem
2022-11-23 02:31:30,736 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:31:30,736 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:31:30,737 INFO:     Number of params in model 168571
2022-11-23 02:31:30,741 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:31:30,741 INFO:   Starting stage: TRAINING
2022-11-23 02:31:30,799 INFO:     Val loss before train {'Reaction outcome loss': 1.0196200026707216, 'Total loss': 1.0196200026707216}
2022-11-23 02:31:30,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:30,800 INFO:     Epoch: 0
2022-11-23 02:31:31,580 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8609976944598284, 'Total loss': 0.8609976944598284} | train loss {'Reaction outcome loss': 0.8752073649211451, 'Total loss': 0.8752073649211451}
2022-11-23 02:31:31,580 INFO:     Found new best model at epoch 0
2022-11-23 02:31:31,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:31,581 INFO:     Epoch: 1
2022-11-23 02:31:32,396 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8701075620271943, 'Total loss': 0.8701075620271943} | train loss {'Reaction outcome loss': 0.8602835079918989, 'Total loss': 0.8602835079918989}
2022-11-23 02:31:32,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:32,396 INFO:     Epoch: 2
2022-11-23 02:31:33,182 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8371031582355499, 'Total loss': 0.8371031582355499} | train loss {'Reaction outcome loss': 0.8505414028158073, 'Total loss': 0.8505414028158073}
2022-11-23 02:31:33,182 INFO:     Found new best model at epoch 2
2022-11-23 02:31:33,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:33,183 INFO:     Epoch: 3
2022-11-23 02:31:34,008 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8466437899253585, 'Total loss': 0.8466437899253585} | train loss {'Reaction outcome loss': 0.8473601821463118, 'Total loss': 0.8473601821463118}
2022-11-23 02:31:34,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:34,009 INFO:     Epoch: 4
2022-11-23 02:31:34,888 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8197634294629097, 'Total loss': 0.8197634294629097} | train loss {'Reaction outcome loss': 0.8421316365240074, 'Total loss': 0.8421316365240074}
2022-11-23 02:31:34,888 INFO:     Found new best model at epoch 4
2022-11-23 02:31:34,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:34,889 INFO:     Epoch: 5
2022-11-23 02:31:35,733 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8518859195438299, 'Total loss': 0.8518859195438299} | train loss {'Reaction outcome loss': 0.837268269074108, 'Total loss': 0.837268269074108}
2022-11-23 02:31:35,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:35,733 INFO:     Epoch: 6
2022-11-23 02:31:36,545 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.845532511445609, 'Total loss': 0.845532511445609} | train loss {'Reaction outcome loss': 0.8352546161002958, 'Total loss': 0.8352546161002958}
2022-11-23 02:31:36,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:36,546 INFO:     Epoch: 7
2022-11-23 02:31:37,327 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8265153081579641, 'Total loss': 0.8265153081579641} | train loss {'Reaction outcome loss': 0.8417408628019727, 'Total loss': 0.8417408628019727}
2022-11-23 02:31:37,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:37,327 INFO:     Epoch: 8
2022-11-23 02:31:38,120 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.81630185788328, 'Total loss': 0.81630185788328} | train loss {'Reaction outcome loss': 0.8356582156801031, 'Total loss': 0.8356582156801031}
2022-11-23 02:31:38,120 INFO:     Found new best model at epoch 8
2022-11-23 02:31:38,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:38,121 INFO:     Epoch: 9
2022-11-23 02:31:38,955 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8374878865751353, 'Total loss': 0.8374878865751353} | train loss {'Reaction outcome loss': 0.8338111534051085, 'Total loss': 0.8338111534051085}
2022-11-23 02:31:38,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:38,955 INFO:     Epoch: 10
2022-11-23 02:31:39,771 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8231000304222107, 'Total loss': 0.8231000304222107} | train loss {'Reaction outcome loss': 0.8354110223079018, 'Total loss': 0.8354110223079018}
2022-11-23 02:31:39,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:39,771 INFO:     Epoch: 11
2022-11-23 02:31:40,592 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8283828564665534, 'Total loss': 0.8283828564665534} | train loss {'Reaction outcome loss': 0.8294187687669206, 'Total loss': 0.8294187687669206}
2022-11-23 02:31:40,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:40,592 INFO:     Epoch: 12
2022-11-23 02:31:41,426 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8316227685321461, 'Total loss': 0.8316227685321461} | train loss {'Reaction outcome loss': 0.8255052478448582, 'Total loss': 0.8255052478448582}
2022-11-23 02:31:41,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:41,426 INFO:     Epoch: 13
2022-11-23 02:31:42,261 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8079568079926751, 'Total loss': 0.8079568079926751} | train loss {'Reaction outcome loss': 0.8258841580707534, 'Total loss': 0.8258841580707534}
2022-11-23 02:31:42,261 INFO:     Found new best model at epoch 13
2022-11-23 02:31:42,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:42,262 INFO:     Epoch: 14
2022-11-23 02:31:43,056 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8519063571637328, 'Total loss': 0.8519063571637328} | train loss {'Reaction outcome loss': 0.8232613853235476, 'Total loss': 0.8232613853235476}
2022-11-23 02:31:43,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:43,056 INFO:     Epoch: 15
2022-11-23 02:31:43,859 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.844317923892628, 'Total loss': 0.844317923892628} | train loss {'Reaction outcome loss': 0.8277751008267344, 'Total loss': 0.8277751008267344}
2022-11-23 02:31:43,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:43,859 INFO:     Epoch: 16
2022-11-23 02:31:44,713 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8237517672506246, 'Total loss': 0.8237517672506246} | train loss {'Reaction outcome loss': 0.8264353620529417, 'Total loss': 0.8264353620529417}
2022-11-23 02:31:44,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:44,713 INFO:     Epoch: 17
2022-11-23 02:31:45,509 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8261924345384944, 'Total loss': 0.8261924345384944} | train loss {'Reaction outcome loss': 0.8201287889528853, 'Total loss': 0.8201287889528853}
2022-11-23 02:31:45,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:45,510 INFO:     Epoch: 18
2022-11-23 02:31:46,372 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8283080648292195, 'Total loss': 0.8283080648292195} | train loss {'Reaction outcome loss': 0.8227799568581677, 'Total loss': 0.8227799568581677}
2022-11-23 02:31:46,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:46,373 INFO:     Epoch: 19
2022-11-23 02:31:47,126 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8406208740039305, 'Total loss': 0.8406208740039305} | train loss {'Reaction outcome loss': 0.822180237726644, 'Total loss': 0.822180237726644}
2022-11-23 02:31:47,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:47,126 INFO:     Epoch: 20
2022-11-23 02:31:47,920 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8431976952336051, 'Total loss': 0.8431976952336051} | train loss {'Reaction outcome loss': 0.8276882445522649, 'Total loss': 0.8276882445522649}
2022-11-23 02:31:47,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:47,920 INFO:     Epoch: 21
2022-11-23 02:31:48,729 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8167020285671408, 'Total loss': 0.8167020285671408} | train loss {'Reaction outcome loss': 0.8239814316936833, 'Total loss': 0.8239814316936833}
2022-11-23 02:31:48,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:48,729 INFO:     Epoch: 22
2022-11-23 02:31:49,565 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.824693194844506, 'Total loss': 0.824693194844506} | train loss {'Reaction outcome loss': 0.8197350561286998, 'Total loss': 0.8197350561286998}
2022-11-23 02:31:49,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:49,565 INFO:     Epoch: 23
2022-11-23 02:31:50,409 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8125722984021361, 'Total loss': 0.8125722984021361} | train loss {'Reaction outcome loss': 0.8204619733669497, 'Total loss': 0.8204619733669497}
2022-11-23 02:31:50,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:50,409 INFO:     Epoch: 24
2022-11-23 02:31:51,215 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8149660737677054, 'Total loss': 0.8149660737677054} | train loss {'Reaction outcome loss': 0.8191356257297974, 'Total loss': 0.8191356257297974}
2022-11-23 02:31:51,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:51,215 INFO:     Epoch: 25
2022-11-23 02:31:52,044 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8149501613595269, 'Total loss': 0.8149501613595269} | train loss {'Reaction outcome loss': 0.8177161771758847, 'Total loss': 0.8177161771758847}
2022-11-23 02:31:52,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:52,045 INFO:     Epoch: 26
2022-11-23 02:31:52,854 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8224428776990284, 'Total loss': 0.8224428776990284} | train loss {'Reaction outcome loss': 0.8208139611159259, 'Total loss': 0.8208139611159259}
2022-11-23 02:31:52,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:52,855 INFO:     Epoch: 27
2022-11-23 02:31:53,684 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8188379420475527, 'Total loss': 0.8188379420475527} | train loss {'Reaction outcome loss': 0.8203542459348918, 'Total loss': 0.8203542459348918}
2022-11-23 02:31:53,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:53,685 INFO:     Epoch: 28
2022-11-23 02:31:54,558 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8429805114865303, 'Total loss': 0.8429805114865303} | train loss {'Reaction outcome loss': 0.8147420953009051, 'Total loss': 0.8147420953009051}
2022-11-23 02:31:54,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:54,558 INFO:     Epoch: 29
2022-11-23 02:31:55,354 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8166483545845206, 'Total loss': 0.8166483545845206} | train loss {'Reaction outcome loss': 0.8148561753483436, 'Total loss': 0.8148561753483436}
2022-11-23 02:31:55,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:55,354 INFO:     Epoch: 30
2022-11-23 02:31:56,207 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8165704980492592, 'Total loss': 0.8165704980492592} | train loss {'Reaction outcome loss': 0.8184252643150839, 'Total loss': 0.8184252643150839}
2022-11-23 02:31:56,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:56,207 INFO:     Epoch: 31
2022-11-23 02:31:57,101 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8205484741113402, 'Total loss': 0.8205484741113402} | train loss {'Reaction outcome loss': 0.8150012384542087, 'Total loss': 0.8150012384542087}
2022-11-23 02:31:57,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:57,102 INFO:     Epoch: 32
2022-11-23 02:31:57,933 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8244515413587744, 'Total loss': 0.8244515413587744} | train loss {'Reaction outcome loss': 0.8150794986288558, 'Total loss': 0.8150794986288558}
2022-11-23 02:31:57,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:57,933 INFO:     Epoch: 33
2022-11-23 02:31:58,728 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8198912563649091, 'Total loss': 0.8198912563649091} | train loss {'Reaction outcome loss': 0.8158047376615316, 'Total loss': 0.8158047376615316}
2022-11-23 02:31:58,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:58,728 INFO:     Epoch: 34
2022-11-23 02:31:59,547 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8316335637461055, 'Total loss': 0.8316335637461055} | train loss {'Reaction outcome loss': 0.8168228192609331, 'Total loss': 0.8168228192609331}
2022-11-23 02:31:59,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:31:59,547 INFO:     Epoch: 35
2022-11-23 02:32:00,406 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8241738832809709, 'Total loss': 0.8241738832809709} | train loss {'Reaction outcome loss': 0.8210956175558963, 'Total loss': 0.8210956175558963}
2022-11-23 02:32:00,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:00,406 INFO:     Epoch: 36
2022-11-23 02:32:01,255 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.822356485507705, 'Total loss': 0.822356485507705} | train loss {'Reaction outcome loss': 0.8181194228681958, 'Total loss': 0.8181194228681958}
2022-11-23 02:32:01,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:01,256 INFO:     Epoch: 37
2022-11-23 02:32:02,121 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8362229588356885, 'Total loss': 0.8362229588356885} | train loss {'Reaction outcome loss': 0.8164075669730723, 'Total loss': 0.8164075669730723}
2022-11-23 02:32:02,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:02,121 INFO:     Epoch: 38
2022-11-23 02:32:03,005 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8396111984144558, 'Total loss': 0.8396111984144558} | train loss {'Reaction outcome loss': 0.8182371286486807, 'Total loss': 0.8182371286486807}
2022-11-23 02:32:03,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:03,005 INFO:     Epoch: 39
2022-11-23 02:32:03,866 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8163992708379572, 'Total loss': 0.8163992708379572} | train loss {'Reaction outcome loss': 0.823830590315676, 'Total loss': 0.823830590315676}
2022-11-23 02:32:03,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:03,866 INFO:     Epoch: 40
2022-11-23 02:32:04,742 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.80867454003204, 'Total loss': 0.80867454003204} | train loss {'Reaction outcome loss': 0.814324342408161, 'Total loss': 0.814324342408161}
2022-11-23 02:32:04,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:04,743 INFO:     Epoch: 41
2022-11-23 02:32:05,595 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8117399933663282, 'Total loss': 0.8117399933663282} | train loss {'Reaction outcome loss': 0.812621056852553, 'Total loss': 0.812621056852553}
2022-11-23 02:32:05,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:05,595 INFO:     Epoch: 42
2022-11-23 02:32:06,471 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8433314839547331, 'Total loss': 0.8433314839547331} | train loss {'Reaction outcome loss': 0.8187595923178592, 'Total loss': 0.8187595923178592}
2022-11-23 02:32:06,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:06,471 INFO:     Epoch: 43
2022-11-23 02:32:07,366 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8156925798817114, 'Total loss': 0.8156925798817114} | train loss {'Reaction outcome loss': 0.8155886624988756, 'Total loss': 0.8155886624988756}
2022-11-23 02:32:07,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:07,367 INFO:     Epoch: 44
2022-11-23 02:32:08,251 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8197763508016412, 'Total loss': 0.8197763508016412} | train loss {'Reaction outcome loss': 0.8124478503398085, 'Total loss': 0.8124478503398085}
2022-11-23 02:32:08,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:08,251 INFO:     Epoch: 45
2022-11-23 02:32:09,136 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8227483122186228, 'Total loss': 0.8227483122186228} | train loss {'Reaction outcome loss': 0.8126781466398162, 'Total loss': 0.8126781466398162}
2022-11-23 02:32:09,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:09,136 INFO:     Epoch: 46
2022-11-23 02:32:10,064 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8217513358051126, 'Total loss': 0.8217513358051126} | train loss {'Reaction outcome loss': 0.8128206943904581, 'Total loss': 0.8128206943904581}
2022-11-23 02:32:10,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:10,064 INFO:     Epoch: 47
2022-11-23 02:32:10,973 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8285864036191594, 'Total loss': 0.8285864036191594} | train loss {'Reaction outcome loss': 0.8090055926367339, 'Total loss': 0.8090055926367339}
2022-11-23 02:32:10,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:10,973 INFO:     Epoch: 48
2022-11-23 02:32:11,851 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8286691355434331, 'Total loss': 0.8286691355434331} | train loss {'Reaction outcome loss': 0.8151089261900558, 'Total loss': 0.8151089261900558}
2022-11-23 02:32:11,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:11,852 INFO:     Epoch: 49
2022-11-23 02:32:12,797 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8274897262454033, 'Total loss': 0.8274897262454033} | train loss {'Reaction outcome loss': 0.8119727934179036, 'Total loss': 0.8119727934179036}
2022-11-23 02:32:12,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:12,797 INFO:     Epoch: 50
2022-11-23 02:32:13,680 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8300446989861402, 'Total loss': 0.8300446989861402} | train loss {'Reaction outcome loss': 0.8212856353535826, 'Total loss': 0.8212856353535826}
2022-11-23 02:32:13,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:13,680 INFO:     Epoch: 51
2022-11-23 02:32:14,533 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8225127641450275, 'Total loss': 0.8225127641450275} | train loss {'Reaction outcome loss': 0.8244434564943738, 'Total loss': 0.8244434564943738}
2022-11-23 02:32:14,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:14,533 INFO:     Epoch: 52
2022-11-23 02:32:15,402 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8138782910325311, 'Total loss': 0.8138782910325311} | train loss {'Reaction outcome loss': 0.8149588644987176, 'Total loss': 0.8149588644987176}
2022-11-23 02:32:15,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:15,402 INFO:     Epoch: 53
2022-11-23 02:32:16,281 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8283871188759804, 'Total loss': 0.8283871188759804} | train loss {'Reaction outcome loss': 0.8216935595278798, 'Total loss': 0.8216935595278798}
2022-11-23 02:32:16,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:16,281 INFO:     Epoch: 54
2022-11-23 02:32:17,172 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8250272863290526, 'Total loss': 0.8250272863290526} | train loss {'Reaction outcome loss': 0.8132995736261128, 'Total loss': 0.8132995736261128}
2022-11-23 02:32:17,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:17,173 INFO:     Epoch: 55
2022-11-23 02:32:18,084 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8084793795238842, 'Total loss': 0.8084793795238842} | train loss {'Reaction outcome loss': 0.8167678233582963, 'Total loss': 0.8167678233582963}
2022-11-23 02:32:18,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:18,084 INFO:     Epoch: 56
2022-11-23 02:32:18,997 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.825822576880455, 'Total loss': 0.825822576880455} | train loss {'Reaction outcome loss': 0.8132017687988667, 'Total loss': 0.8132017687988667}
2022-11-23 02:32:18,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:18,997 INFO:     Epoch: 57
2022-11-23 02:32:19,878 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8071130419319327, 'Total loss': 0.8071130419319327} | train loss {'Reaction outcome loss': 0.8144040960773282, 'Total loss': 0.8144040960773282}
2022-11-23 02:32:19,878 INFO:     Found new best model at epoch 57
2022-11-23 02:32:19,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:19,879 INFO:     Epoch: 58
2022-11-23 02:32:20,780 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8117392997850071, 'Total loss': 0.8117392997850071} | train loss {'Reaction outcome loss': 0.8157933888889035, 'Total loss': 0.8157933888889035}
2022-11-23 02:32:20,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:20,780 INFO:     Epoch: 59
2022-11-23 02:32:21,642 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8770589659159834, 'Total loss': 0.8770589659159834} | train loss {'Reaction outcome loss': 0.8147409245794118, 'Total loss': 0.8147409245794118}
2022-11-23 02:32:21,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:21,643 INFO:     Epoch: 60
2022-11-23 02:32:22,540 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8258167823607271, 'Total loss': 0.8258167823607271} | train loss {'Reaction outcome loss': 0.816594080222763, 'Total loss': 0.816594080222763}
2022-11-23 02:32:22,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:22,540 INFO:     Epoch: 61
2022-11-23 02:32:23,436 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8258732950145548, 'Total loss': 0.8258732950145548} | train loss {'Reaction outcome loss': 0.81455841684631, 'Total loss': 0.81455841684631}
2022-11-23 02:32:23,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:23,438 INFO:     Epoch: 62
2022-11-23 02:32:24,383 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8401992341334169, 'Total loss': 0.8401992341334169} | train loss {'Reaction outcome loss': 0.8184827934151236, 'Total loss': 0.8184827934151236}
2022-11-23 02:32:24,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:24,384 INFO:     Epoch: 63
2022-11-23 02:32:25,266 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8132564195177772, 'Total loss': 0.8132564195177772} | train loss {'Reaction outcome loss': 0.8231315505408082, 'Total loss': 0.8231315505408082}
2022-11-23 02:32:25,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:25,267 INFO:     Epoch: 64
2022-11-23 02:32:26,141 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8115812540054321, 'Total loss': 0.8115812540054321} | train loss {'Reaction outcome loss': 0.8147096765427454, 'Total loss': 0.8147096765427454}
2022-11-23 02:32:26,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:26,142 INFO:     Epoch: 65
2022-11-23 02:32:27,066 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8011325665495612, 'Total loss': 0.8011325665495612} | train loss {'Reaction outcome loss': 0.8347252046289714, 'Total loss': 0.8347252046289714}
2022-11-23 02:32:27,066 INFO:     Found new best model at epoch 65
2022-11-23 02:32:27,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:27,067 INFO:     Epoch: 66
2022-11-23 02:32:27,958 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8259391391819174, 'Total loss': 0.8259391391819174} | train loss {'Reaction outcome loss': 0.8162344899254772, 'Total loss': 0.8162344899254772}
2022-11-23 02:32:27,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:27,958 INFO:     Epoch: 67
2022-11-23 02:32:28,840 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8250673047520898, 'Total loss': 0.8250673047520898} | train loss {'Reaction outcome loss': 0.8123301502302108, 'Total loss': 0.8123301502302108}
2022-11-23 02:32:28,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:28,840 INFO:     Epoch: 68
2022-11-23 02:32:29,747 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8216222829439424, 'Total loss': 0.8216222829439424} | train loss {'Reaction outcome loss': 0.8082243364590865, 'Total loss': 0.8082243364590865}
2022-11-23 02:32:29,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:29,747 INFO:     Epoch: 69
2022-11-23 02:32:30,622 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8148036754944108, 'Total loss': 0.8148036754944108} | train loss {'Reaction outcome loss': 0.8163511932861467, 'Total loss': 0.8163511932861467}
2022-11-23 02:32:30,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:30,622 INFO:     Epoch: 70
2022-11-23 02:32:31,484 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8243087252432649, 'Total loss': 0.8243087252432649} | train loss {'Reaction outcome loss': 0.8133919625147151, 'Total loss': 0.8133919625147151}
2022-11-23 02:32:31,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:31,485 INFO:     Epoch: 71
2022-11-23 02:32:32,313 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8062884353778579, 'Total loss': 0.8062884353778579} | train loss {'Reaction outcome loss': 0.8116057301581148, 'Total loss': 0.8116057301581148}
2022-11-23 02:32:32,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:32,313 INFO:     Epoch: 72
2022-11-23 02:32:33,155 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8268580159003084, 'Total loss': 0.8268580159003084} | train loss {'Reaction outcome loss': 0.8163777405192495, 'Total loss': 0.8163777405192495}
2022-11-23 02:32:33,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:33,155 INFO:     Epoch: 73
2022-11-23 02:32:34,053 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8285069059241902, 'Total loss': 0.8285069059241902} | train loss {'Reaction outcome loss': 0.8188025524862382, 'Total loss': 0.8188025524862382}
2022-11-23 02:32:34,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:34,054 INFO:     Epoch: 74
2022-11-23 02:32:34,929 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8227092217315327, 'Total loss': 0.8227092217315327} | train loss {'Reaction outcome loss': 0.8198533520283486, 'Total loss': 0.8198533520283486}
2022-11-23 02:32:34,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:34,929 INFO:     Epoch: 75
2022-11-23 02:32:35,787 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8527806035496972, 'Total loss': 0.8527806035496972} | train loss {'Reaction outcome loss': 0.8149945703353959, 'Total loss': 0.8149945703353959}
2022-11-23 02:32:35,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:35,788 INFO:     Epoch: 76
2022-11-23 02:32:36,676 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8208218332041394, 'Total loss': 0.8208218332041394} | train loss {'Reaction outcome loss': 0.8153426002876961, 'Total loss': 0.8153426002876961}
2022-11-23 02:32:36,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:36,676 INFO:     Epoch: 77
2022-11-23 02:32:37,578 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8202229731462218, 'Total loss': 0.8202229731462218} | train loss {'Reaction outcome loss': 0.8148445651945677, 'Total loss': 0.8148445651945677}
2022-11-23 02:32:37,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:37,579 INFO:     Epoch: 78
2022-11-23 02:32:38,436 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7999988906085491, 'Total loss': 0.7999988906085491} | train loss {'Reaction outcome loss': 0.8242568940768841, 'Total loss': 0.8242568940768841}
2022-11-23 02:32:38,436 INFO:     Found new best model at epoch 78
2022-11-23 02:32:38,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:38,437 INFO:     Epoch: 79
2022-11-23 02:32:39,304 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8154289018024098, 'Total loss': 0.8154289018024098} | train loss {'Reaction outcome loss': 0.8317520729443322, 'Total loss': 0.8317520729443322}
2022-11-23 02:32:39,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:39,305 INFO:     Epoch: 80
2022-11-23 02:32:40,183 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8102787218310616, 'Total loss': 0.8102787218310616} | train loss {'Reaction outcome loss': 0.8169947611658197, 'Total loss': 0.8169947611658197}
2022-11-23 02:32:40,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:40,183 INFO:     Epoch: 81
2022-11-23 02:32:41,076 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8115376125682484, 'Total loss': 0.8115376125682484} | train loss {'Reaction outcome loss': 0.8269640516173019, 'Total loss': 0.8269640516173019}
2022-11-23 02:32:41,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:41,076 INFO:     Epoch: 82
2022-11-23 02:32:41,927 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8082948916337707, 'Total loss': 0.8082948916337707} | train loss {'Reaction outcome loss': 0.8102439707861497, 'Total loss': 0.8102439707861497}
2022-11-23 02:32:41,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:41,928 INFO:     Epoch: 83
2022-11-23 02:32:42,773 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8188602504405108, 'Total loss': 0.8188602504405108} | train loss {'Reaction outcome loss': 0.8125731685624914, 'Total loss': 0.8125731685624914}
2022-11-23 02:32:42,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:42,773 INFO:     Epoch: 84
2022-11-23 02:32:43,640 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8175432133403692, 'Total loss': 0.8175432133403692} | train loss {'Reaction outcome loss': 0.8138774882036786, 'Total loss': 0.8138774882036786}
2022-11-23 02:32:43,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:43,640 INFO:     Epoch: 85
2022-11-23 02:32:44,516 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8272621807726946, 'Total loss': 0.8272621807726946} | train loss {'Reaction outcome loss': 0.8140925470634028, 'Total loss': 0.8140925470634028}
2022-11-23 02:32:44,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:44,516 INFO:     Epoch: 86
2022-11-23 02:32:45,370 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.839115444232117, 'Total loss': 0.839115444232117} | train loss {'Reaction outcome loss': 0.8132212557773358, 'Total loss': 0.8132212557773358}
2022-11-23 02:32:45,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:45,370 INFO:     Epoch: 87
2022-11-23 02:32:46,266 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8254715163599361, 'Total loss': 0.8254715163599361} | train loss {'Reaction outcome loss': 0.8169521355194601, 'Total loss': 0.8169521355194601}
2022-11-23 02:32:46,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:46,266 INFO:     Epoch: 88
2022-11-23 02:32:47,114 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8114426569505171, 'Total loss': 0.8114426569505171} | train loss {'Reaction outcome loss': 0.8158558937702102, 'Total loss': 0.8158558937702102}
2022-11-23 02:32:47,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:47,115 INFO:     Epoch: 89
2022-11-23 02:32:48,064 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8052886392582547, 'Total loss': 0.8052886392582547} | train loss {'Reaction outcome loss': 0.8117808390122193, 'Total loss': 0.8117808390122193}
2022-11-23 02:32:48,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:48,064 INFO:     Epoch: 90
2022-11-23 02:32:48,916 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8023618331009691, 'Total loss': 0.8023618331009691} | train loss {'Reaction outcome loss': 0.8114006857157718, 'Total loss': 0.8114006857157718}
2022-11-23 02:32:48,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:48,918 INFO:     Epoch: 91
2022-11-23 02:32:49,793 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8167891610752452, 'Total loss': 0.8167891610752452} | train loss {'Reaction outcome loss': 0.8120583765178557, 'Total loss': 0.8120583765178557}
2022-11-23 02:32:49,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:49,793 INFO:     Epoch: 92
2022-11-23 02:32:50,655 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8083374229344454, 'Total loss': 0.8083374229344454} | train loss {'Reaction outcome loss': 0.8162358356149573, 'Total loss': 0.8162358356149573}
2022-11-23 02:32:50,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:50,655 INFO:     Epoch: 93
2022-11-23 02:32:51,516 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8087295896627686, 'Total loss': 0.8087295896627686} | train loss {'Reaction outcome loss': 0.8109159751338997, 'Total loss': 0.8109159751338997}
2022-11-23 02:32:51,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:51,516 INFO:     Epoch: 94
2022-11-23 02:32:52,438 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8360300118272955, 'Total loss': 0.8360300118272955} | train loss {'Reaction outcome loss': 0.811478259411418, 'Total loss': 0.811478259411418}
2022-11-23 02:32:52,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:52,439 INFO:     Epoch: 95
2022-11-23 02:32:53,285 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8067536367611452, 'Total loss': 0.8067536367611452} | train loss {'Reaction outcome loss': 0.8180715346384627, 'Total loss': 0.8180715346384627}
2022-11-23 02:32:53,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:53,285 INFO:     Epoch: 96
2022-11-23 02:32:54,145 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.826592205600305, 'Total loss': 0.826592205600305} | train loss {'Reaction outcome loss': 0.8198547970186844, 'Total loss': 0.8198547970186844}
2022-11-23 02:32:54,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:54,145 INFO:     Epoch: 97
2022-11-23 02:32:55,043 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8256911378015171, 'Total loss': 0.8256911378015171} | train loss {'Reaction outcome loss': 0.8192088532785655, 'Total loss': 0.8192088532785655}
2022-11-23 02:32:55,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:55,044 INFO:     Epoch: 98
2022-11-23 02:32:55,932 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8083116750825535, 'Total loss': 0.8083116750825535} | train loss {'Reaction outcome loss': 0.8149928782391644, 'Total loss': 0.8149928782391644}
2022-11-23 02:32:55,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:55,932 INFO:     Epoch: 99
2022-11-23 02:32:56,802 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8242263997142966, 'Total loss': 0.8242263997142966} | train loss {'Reaction outcome loss': 0.8158262808795883, 'Total loss': 0.8158262808795883}
2022-11-23 02:32:56,802 INFO:     Best model found after epoch 79 of 100.
2022-11-23 02:32:56,802 INFO:   Done with stage: TRAINING
2022-11-23 02:32:56,803 INFO:   Starting stage: EVALUATION
2022-11-23 02:32:56,929 INFO:   Done with stage: EVALUATION
2022-11-23 02:32:56,929 INFO:   Leaving out SEQ value Fold_4
2022-11-23 02:32:56,943 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:32:56,943 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:32:57,635 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:32:57,636 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:32:57,712 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:32:57,712 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:32:57,712 INFO:     No hyperparam tuning for this model
2022-11-23 02:32:57,713 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:32:57,713 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:32:57,714 INFO:     None feature selector for col prot
2022-11-23 02:32:57,714 INFO:     None feature selector for col prot
2022-11-23 02:32:57,714 INFO:     None feature selector for col prot
2022-11-23 02:32:57,714 INFO:     None feature selector for col chem
2022-11-23 02:32:57,715 INFO:     None feature selector for col chem
2022-11-23 02:32:57,715 INFO:     None feature selector for col chem
2022-11-23 02:32:57,715 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:32:57,715 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:32:57,716 INFO:     Number of params in model 168571
2022-11-23 02:32:57,720 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:32:57,720 INFO:   Starting stage: TRAINING
2022-11-23 02:32:57,780 INFO:     Val loss before train {'Reaction outcome loss': 1.0124686749821359, 'Total loss': 1.0124686749821359}
2022-11-23 02:32:57,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:57,781 INFO:     Epoch: 0
2022-11-23 02:32:58,656 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9210898971015756, 'Total loss': 0.9210898971015756} | train loss {'Reaction outcome loss': 0.8790545226825822, 'Total loss': 0.8790545226825822}
2022-11-23 02:32:58,656 INFO:     Found new best model at epoch 0
2022-11-23 02:32:58,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:58,657 INFO:     Epoch: 1
2022-11-23 02:32:59,536 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8654967898672278, 'Total loss': 0.8654967898672278} | train loss {'Reaction outcome loss': 0.846701595691904, 'Total loss': 0.846701595691904}
2022-11-23 02:32:59,536 INFO:     Found new best model at epoch 1
2022-11-23 02:32:59,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:32:59,537 INFO:     Epoch: 2
2022-11-23 02:33:00,437 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8220912109721791, 'Total loss': 0.8220912109721791} | train loss {'Reaction outcome loss': 0.8390233886818732, 'Total loss': 0.8390233886818732}
2022-11-23 02:33:00,437 INFO:     Found new best model at epoch 2
2022-11-23 02:33:00,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:00,438 INFO:     Epoch: 3
2022-11-23 02:33:01,286 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8058935945684259, 'Total loss': 0.8058935945684259} | train loss {'Reaction outcome loss': 0.8341707747069097, 'Total loss': 0.8341707747069097}
2022-11-23 02:33:01,286 INFO:     Found new best model at epoch 3
2022-11-23 02:33:01,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:01,287 INFO:     Epoch: 4
2022-11-23 02:33:02,191 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8080143948847597, 'Total loss': 0.8080143948847597} | train loss {'Reaction outcome loss': 0.8307902745662197, 'Total loss': 0.8307902745662197}
2022-11-23 02:33:02,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:02,191 INFO:     Epoch: 5
2022-11-23 02:33:03,012 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.809305801987648, 'Total loss': 0.809305801987648} | train loss {'Reaction outcome loss': 0.8286858942479857, 'Total loss': 0.8286858942479857}
2022-11-23 02:33:03,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:03,013 INFO:     Epoch: 6
2022-11-23 02:33:03,832 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8136250661178068, 'Total loss': 0.8136250661178068} | train loss {'Reaction outcome loss': 0.8243514601021044, 'Total loss': 0.8243514601021044}
2022-11-23 02:33:03,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:03,832 INFO:     Epoch: 7
2022-11-23 02:33:04,667 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8139868012883447, 'Total loss': 0.8139868012883447} | train loss {'Reaction outcome loss': 0.824282577681926, 'Total loss': 0.824282577681926}
2022-11-23 02:33:04,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:04,667 INFO:     Epoch: 8
2022-11-23 02:33:05,492 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8123560710386797, 'Total loss': 0.8123560710386797} | train loss {'Reaction outcome loss': 0.8263654617532608, 'Total loss': 0.8263654617532608}
2022-11-23 02:33:05,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:05,492 INFO:     Epoch: 9
2022-11-23 02:33:06,318 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7991437939080325, 'Total loss': 0.7991437939080325} | train loss {'Reaction outcome loss': 0.823915365242189, 'Total loss': 0.823915365242189}
2022-11-23 02:33:06,318 INFO:     Found new best model at epoch 9
2022-11-23 02:33:06,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:06,319 INFO:     Epoch: 10
2022-11-23 02:33:07,180 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8126865862445398, 'Total loss': 0.8126865862445398} | train loss {'Reaction outcome loss': 0.8307859751005326, 'Total loss': 0.8307859751005326}
2022-11-23 02:33:07,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:07,181 INFO:     Epoch: 11
2022-11-23 02:33:08,002 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.821227303282781, 'Total loss': 0.821227303282781} | train loss {'Reaction outcome loss': 0.8186746133911994, 'Total loss': 0.8186746133911994}
2022-11-23 02:33:08,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:08,002 INFO:     Epoch: 12
2022-11-23 02:33:08,808 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8087964674288576, 'Total loss': 0.8087964674288576} | train loss {'Reaction outcome loss': 0.8265497825078426, 'Total loss': 0.8265497825078426}
2022-11-23 02:33:08,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:08,809 INFO:     Epoch: 13
2022-11-23 02:33:09,673 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8285556503317573, 'Total loss': 0.8285556503317573} | train loss {'Reaction outcome loss': 0.8183621152514412, 'Total loss': 0.8183621152514412}
2022-11-23 02:33:09,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:09,674 INFO:     Epoch: 14
2022-11-23 02:33:10,455 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8455404910174283, 'Total loss': 0.8455404910174283} | train loss {'Reaction outcome loss': 0.8217080894016451, 'Total loss': 0.8217080894016451}
2022-11-23 02:33:10,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:10,455 INFO:     Epoch: 15
2022-11-23 02:33:11,273 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.803515141660517, 'Total loss': 0.803515141660517} | train loss {'Reaction outcome loss': 0.8184057466926113, 'Total loss': 0.8184057466926113}
2022-11-23 02:33:11,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:11,273 INFO:     Epoch: 16
2022-11-23 02:33:12,085 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8014104190197858, 'Total loss': 0.8014104190197858} | train loss {'Reaction outcome loss': 0.8175873686709711, 'Total loss': 0.8175873686709711}
2022-11-23 02:33:12,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:12,085 INFO:     Epoch: 17
2022-11-23 02:33:12,932 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7973603443665938, 'Total loss': 0.7973603443665938} | train loss {'Reaction outcome loss': 0.8216213987719628, 'Total loss': 0.8216213987719628}
2022-11-23 02:33:12,932 INFO:     Found new best model at epoch 17
2022-11-23 02:33:12,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:12,933 INFO:     Epoch: 18
2022-11-23 02:33:13,789 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7948979687961665, 'Total loss': 0.7948979687961665} | train loss {'Reaction outcome loss': 0.815775981473346, 'Total loss': 0.815775981473346}
2022-11-23 02:33:13,789 INFO:     Found new best model at epoch 18
2022-11-23 02:33:13,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:13,790 INFO:     Epoch: 19
2022-11-23 02:33:14,615 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7973778031089089, 'Total loss': 0.7973778031089089} | train loss {'Reaction outcome loss': 0.8142773551085303, 'Total loss': 0.8142773551085303}
2022-11-23 02:33:14,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:14,616 INFO:     Epoch: 20
2022-11-23 02:33:15,413 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8052989732135426, 'Total loss': 0.8052989732135426} | train loss {'Reaction outcome loss': 0.8172093602197785, 'Total loss': 0.8172093602197785}
2022-11-23 02:33:15,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:15,414 INFO:     Epoch: 21
2022-11-23 02:33:16,201 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8100839026949622, 'Total loss': 0.8100839026949622} | train loss {'Reaction outcome loss': 0.8210838902140817, 'Total loss': 0.8210838902140817}
2022-11-23 02:33:16,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:16,202 INFO:     Epoch: 22
2022-11-23 02:33:17,016 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8148944906213067, 'Total loss': 0.8148944906213067} | train loss {'Reaction outcome loss': 0.8130246238602746, 'Total loss': 0.8130246238602746}
2022-11-23 02:33:17,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:17,017 INFO:     Epoch: 23
2022-11-23 02:33:17,806 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8027136894789609, 'Total loss': 0.8027136894789609} | train loss {'Reaction outcome loss': 0.817134601094069, 'Total loss': 0.817134601094069}
2022-11-23 02:33:17,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:17,806 INFO:     Epoch: 24
2022-11-23 02:33:18,594 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7988106777722185, 'Total loss': 0.7988106777722185} | train loss {'Reaction outcome loss': 0.8158976172487582, 'Total loss': 0.8158976172487582}
2022-11-23 02:33:18,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:18,594 INFO:     Epoch: 25
2022-11-23 02:33:19,374 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7964248514988206, 'Total loss': 0.7964248514988206} | train loss {'Reaction outcome loss': 0.8136032566187843, 'Total loss': 0.8136032566187843}
2022-11-23 02:33:19,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:19,375 INFO:     Epoch: 26
2022-11-23 02:33:20,181 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8022705248811028, 'Total loss': 0.8022705248811028} | train loss {'Reaction outcome loss': 0.8202302268435878, 'Total loss': 0.8202302268435878}
2022-11-23 02:33:20,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:20,181 INFO:     Epoch: 27
2022-11-23 02:33:21,004 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8003094453703273, 'Total loss': 0.8003094453703273} | train loss {'Reaction outcome loss': 0.8190723370400167, 'Total loss': 0.8190723370400167}
2022-11-23 02:33:21,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:21,005 INFO:     Epoch: 28
2022-11-23 02:33:21,827 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7996171855113723, 'Total loss': 0.7996171855113723} | train loss {'Reaction outcome loss': 0.8151364039269186, 'Total loss': 0.8151364039269186}
2022-11-23 02:33:21,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:21,827 INFO:     Epoch: 29
2022-11-23 02:33:22,674 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8018085089596835, 'Total loss': 0.8018085089596835} | train loss {'Reaction outcome loss': 0.8131388079735541, 'Total loss': 0.8131388079735541}
2022-11-23 02:33:22,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:22,675 INFO:     Epoch: 30
2022-11-23 02:33:23,475 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7915067049590024, 'Total loss': 0.7915067049590024} | train loss {'Reaction outcome loss': 0.8170858114477126, 'Total loss': 0.8170858114477126}
2022-11-23 02:33:23,475 INFO:     Found new best model at epoch 30
2022-11-23 02:33:23,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:23,476 INFO:     Epoch: 31
2022-11-23 02:33:24,320 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8093367503447966, 'Total loss': 0.8093367503447966} | train loss {'Reaction outcome loss': 0.8200805785675203, 'Total loss': 0.8200805785675203}
2022-11-23 02:33:24,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:24,321 INFO:     Epoch: 32
2022-11-23 02:33:25,143 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8126493827863173, 'Total loss': 0.8126493827863173} | train loss {'Reaction outcome loss': 0.8126845224009406, 'Total loss': 0.8126845224009406}
2022-11-23 02:33:25,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:25,143 INFO:     Epoch: 33
2022-11-23 02:33:25,945 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8155352209102024, 'Total loss': 0.8155352209102024} | train loss {'Reaction outcome loss': 0.8152670988873127, 'Total loss': 0.8152670988873127}
2022-11-23 02:33:25,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:25,946 INFO:     Epoch: 34
2022-11-23 02:33:26,760 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7972536832094193, 'Total loss': 0.7972536832094193} | train loss {'Reaction outcome loss': 0.8172334912082841, 'Total loss': 0.8172334912082841}
2022-11-23 02:33:26,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:26,760 INFO:     Epoch: 35
2022-11-23 02:33:27,528 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8026673698967154, 'Total loss': 0.8026673698967154} | train loss {'Reaction outcome loss': 0.8162547659970099, 'Total loss': 0.8162547659970099}
2022-11-23 02:33:27,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:27,529 INFO:     Epoch: 36
2022-11-23 02:33:28,314 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.812490392814983, 'Total loss': 0.812490392814983} | train loss {'Reaction outcome loss': 0.8143509769391629, 'Total loss': 0.8143509769391629}
2022-11-23 02:33:28,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:28,314 INFO:     Epoch: 37
2022-11-23 02:33:29,100 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7987223044037819, 'Total loss': 0.7987223044037819} | train loss {'Reaction outcome loss': 0.8136019945865677, 'Total loss': 0.8136019945865677}
2022-11-23 02:33:29,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:29,100 INFO:     Epoch: 38
2022-11-23 02:33:29,919 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8139181279323318, 'Total loss': 0.8139181279323318} | train loss {'Reaction outcome loss': 0.8160350412851379, 'Total loss': 0.8160350412851379}
2022-11-23 02:33:29,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:29,919 INFO:     Epoch: 39
2022-11-23 02:33:30,682 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8175520964644172, 'Total loss': 0.8175520964644172} | train loss {'Reaction outcome loss': 0.8126826537472587, 'Total loss': 0.8126826537472587}
2022-11-23 02:33:30,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:30,682 INFO:     Epoch: 40
2022-11-23 02:33:31,488 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8097773255272345, 'Total loss': 0.8097773255272345} | train loss {'Reaction outcome loss': 0.8203448242237491, 'Total loss': 0.8203448242237491}
2022-11-23 02:33:31,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:31,488 INFO:     Epoch: 41
2022-11-23 02:33:32,266 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8125611428510059, 'Total loss': 0.8125611428510059} | train loss {'Reaction outcome loss': 0.8166350816046039, 'Total loss': 0.8166350816046039}
2022-11-23 02:33:32,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:32,266 INFO:     Epoch: 42
2022-11-23 02:33:33,099 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7906436479904435, 'Total loss': 0.7906436479904435} | train loss {'Reaction outcome loss': 0.8163790445654623, 'Total loss': 0.8163790445654623}
2022-11-23 02:33:33,099 INFO:     Found new best model at epoch 42
2022-11-23 02:33:33,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:33,100 INFO:     Epoch: 43
2022-11-23 02:33:33,900 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7984390055591409, 'Total loss': 0.7984390055591409} | train loss {'Reaction outcome loss': 0.8116639298537085, 'Total loss': 0.8116639298537085}
2022-11-23 02:33:33,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:33,900 INFO:     Epoch: 44
2022-11-23 02:33:34,707 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8157076998190447, 'Total loss': 0.8157076998190447} | train loss {'Reaction outcome loss': 0.8169545325781068, 'Total loss': 0.8169545325781068}
2022-11-23 02:33:34,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:34,707 INFO:     Epoch: 45
2022-11-23 02:33:35,527 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8031148985028267, 'Total loss': 0.8031148985028267} | train loss {'Reaction outcome loss': 0.8127069641505519, 'Total loss': 0.8127069641505519}
2022-11-23 02:33:35,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:35,527 INFO:     Epoch: 46
2022-11-23 02:33:36,321 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7898448008027944, 'Total loss': 0.7898448008027944} | train loss {'Reaction outcome loss': 0.8102595850584968, 'Total loss': 0.8102595850584968}
2022-11-23 02:33:36,322 INFO:     Found new best model at epoch 46
2022-11-23 02:33:36,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:36,323 INFO:     Epoch: 47
2022-11-23 02:33:37,146 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8098270866003904, 'Total loss': 0.8098270866003904} | train loss {'Reaction outcome loss': 0.8135404955715902, 'Total loss': 0.8135404955715902}
2022-11-23 02:33:37,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:37,147 INFO:     Epoch: 48
2022-11-23 02:33:37,944 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7948026887395165, 'Total loss': 0.7948026887395165} | train loss {'Reaction outcome loss': 0.8131860588346759, 'Total loss': 0.8131860588346759}
2022-11-23 02:33:37,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:37,945 INFO:     Epoch: 49
2022-11-23 02:33:38,769 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8055450774051927, 'Total loss': 0.8055450774051927} | train loss {'Reaction outcome loss': 0.8143274209672405, 'Total loss': 0.8143274209672405}
2022-11-23 02:33:38,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:38,770 INFO:     Epoch: 50
2022-11-23 02:33:39,581 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8029811212962324, 'Total loss': 0.8029811212962324} | train loss {'Reaction outcome loss': 0.8179095189177221, 'Total loss': 0.8179095189177221}
2022-11-23 02:33:39,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:39,582 INFO:     Epoch: 51
2022-11-23 02:33:40,417 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.823846428909085, 'Total loss': 0.823846428909085} | train loss {'Reaction outcome loss': 0.8126872757509831, 'Total loss': 0.8126872757509831}
2022-11-23 02:33:40,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:40,417 INFO:     Epoch: 52
2022-11-23 02:33:41,219 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8268253403631124, 'Total loss': 0.8268253403631124} | train loss {'Reaction outcome loss': 0.8114822319438381, 'Total loss': 0.8114822319438381}
2022-11-23 02:33:41,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:41,219 INFO:     Epoch: 53
2022-11-23 02:33:42,018 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8024534630504522, 'Total loss': 0.8024534630504522} | train loss {'Reaction outcome loss': 0.8118691517701072, 'Total loss': 0.8118691517701072}
2022-11-23 02:33:42,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:42,019 INFO:     Epoch: 54
2022-11-23 02:33:42,858 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7873993949456648, 'Total loss': 0.7873993949456648} | train loss {'Reaction outcome loss': 0.8137728642792471, 'Total loss': 0.8137728642792471}
2022-11-23 02:33:42,859 INFO:     Found new best model at epoch 54
2022-11-23 02:33:42,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:42,859 INFO:     Epoch: 55
2022-11-23 02:33:43,703 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8025388108058409, 'Total loss': 0.8025388108058409} | train loss {'Reaction outcome loss': 0.810709256017881, 'Total loss': 0.810709256017881}
2022-11-23 02:33:43,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:43,704 INFO:     Epoch: 56
2022-11-23 02:33:44,485 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8010421307249502, 'Total loss': 0.8010421307249502} | train loss {'Reaction outcome loss': 0.8158573969717948, 'Total loss': 0.8158573969717948}
2022-11-23 02:33:44,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:44,485 INFO:     Epoch: 57
2022-11-23 02:33:45,327 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7915009009567174, 'Total loss': 0.7915009009567174} | train loss {'Reaction outcome loss': 0.816476815290028, 'Total loss': 0.816476815290028}
2022-11-23 02:33:45,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:45,328 INFO:     Epoch: 58
2022-11-23 02:33:46,124 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8198228478431702, 'Total loss': 0.8198228478431702} | train loss {'Reaction outcome loss': 0.8134841387791019, 'Total loss': 0.8134841387791019}
2022-11-23 02:33:46,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:46,124 INFO:     Epoch: 59
2022-11-23 02:33:46,944 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7969482446258719, 'Total loss': 0.7969482446258719} | train loss {'Reaction outcome loss': 0.8167864924236652, 'Total loss': 0.8167864924236652}
2022-11-23 02:33:46,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:46,944 INFO:     Epoch: 60
2022-11-23 02:33:47,703 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7949327108534899, 'Total loss': 0.7949327108534899} | train loss {'Reaction outcome loss': 0.8122903044906354, 'Total loss': 0.8122903044906354}
2022-11-23 02:33:47,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:47,703 INFO:     Epoch: 61
2022-11-23 02:33:48,516 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8238552470098842, 'Total loss': 0.8238552470098842} | train loss {'Reaction outcome loss': 0.8150901767996049, 'Total loss': 0.8150901767996049}
2022-11-23 02:33:48,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:48,516 INFO:     Epoch: 62
2022-11-23 02:33:49,329 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8021699833599004, 'Total loss': 0.8021699833599004} | train loss {'Reaction outcome loss': 0.8134433832620421, 'Total loss': 0.8134433832620421}
2022-11-23 02:33:49,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:49,329 INFO:     Epoch: 63
2022-11-23 02:33:50,171 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8117260126905008, 'Total loss': 0.8117260126905008} | train loss {'Reaction outcome loss': 0.8150979423474881, 'Total loss': 0.8150979423474881}
2022-11-23 02:33:50,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:50,172 INFO:     Epoch: 64
2022-11-23 02:33:50,969 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.821626984260299, 'Total loss': 0.821626984260299} | train loss {'Reaction outcome loss': 0.8182983390025554, 'Total loss': 0.8182983390025554}
2022-11-23 02:33:50,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:50,969 INFO:     Epoch: 65
2022-11-23 02:33:51,771 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7879636694084514, 'Total loss': 0.7879636694084514} | train loss {'Reaction outcome loss': 0.8100666729432922, 'Total loss': 0.8100666729432922}
2022-11-23 02:33:51,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:51,771 INFO:     Epoch: 66
2022-11-23 02:33:52,622 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7903834655880928, 'Total loss': 0.7903834655880928} | train loss {'Reaction outcome loss': 0.8130914616969324, 'Total loss': 0.8130914616969324}
2022-11-23 02:33:52,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:52,623 INFO:     Epoch: 67
2022-11-23 02:33:53,477 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8170498711141673, 'Total loss': 0.8170498711141673} | train loss {'Reaction outcome loss': 0.8142554391055338, 'Total loss': 0.8142554391055338}
2022-11-23 02:33:53,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:53,477 INFO:     Epoch: 68
2022-11-23 02:33:54,325 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.828481868586757, 'Total loss': 0.828481868586757} | train loss {'Reaction outcome loss': 0.8153327089403907, 'Total loss': 0.8153327089403907}
2022-11-23 02:33:54,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:54,326 INFO:     Epoch: 69
2022-11-23 02:33:55,136 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7935504493388262, 'Total loss': 0.7935504493388262} | train loss {'Reaction outcome loss': 0.8112634267778166, 'Total loss': 0.8112634267778166}
2022-11-23 02:33:55,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:55,137 INFO:     Epoch: 70
2022-11-23 02:33:55,949 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7911842147057707, 'Total loss': 0.7911842147057707} | train loss {'Reaction outcome loss': 0.8123038402728496, 'Total loss': 0.8123038402728496}
2022-11-23 02:33:55,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:55,949 INFO:     Epoch: 71
2022-11-23 02:33:56,797 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7981639335101302, 'Total loss': 0.7981639335101302} | train loss {'Reaction outcome loss': 0.8145259546656762, 'Total loss': 0.8145259546656762}
2022-11-23 02:33:56,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:56,798 INFO:     Epoch: 72
2022-11-23 02:33:57,617 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8016491986133836, 'Total loss': 0.8016491986133836} | train loss {'Reaction outcome loss': 0.8116834799368535, 'Total loss': 0.8116834799368535}
2022-11-23 02:33:57,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:57,618 INFO:     Epoch: 73
2022-11-23 02:33:58,435 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.796453480693427, 'Total loss': 0.796453480693427} | train loss {'Reaction outcome loss': 0.8186061704351056, 'Total loss': 0.8186061704351056}
2022-11-23 02:33:58,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:58,435 INFO:     Epoch: 74
2022-11-23 02:33:59,231 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7921830991452391, 'Total loss': 0.7921830991452391} | train loss {'Reaction outcome loss': 0.8162531700105436, 'Total loss': 0.8162531700105436}
2022-11-23 02:33:59,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:33:59,232 INFO:     Epoch: 75
2022-11-23 02:34:00,036 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8094473799521272, 'Total loss': 0.8094473799521272} | train loss {'Reaction outcome loss': 0.8123164068787329, 'Total loss': 0.8123164068787329}
2022-11-23 02:34:00,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:00,036 INFO:     Epoch: 76
2022-11-23 02:34:00,826 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7963716604492881, 'Total loss': 0.7963716604492881} | train loss {'Reaction outcome loss': 0.8121663908804616, 'Total loss': 0.8121663908804616}
2022-11-23 02:34:00,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:00,826 INFO:     Epoch: 77
2022-11-23 02:34:01,618 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7979029627008871, 'Total loss': 0.7979029627008871} | train loss {'Reaction outcome loss': 0.8114519446126877, 'Total loss': 0.8114519446126877}
2022-11-23 02:34:01,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:01,619 INFO:     Epoch: 78
2022-11-23 02:34:02,429 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.788763237270442, 'Total loss': 0.788763237270442} | train loss {'Reaction outcome loss': 0.812597206042659, 'Total loss': 0.812597206042659}
2022-11-23 02:34:02,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:02,429 INFO:     Epoch: 79
2022-11-23 02:34:03,219 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7982930568131533, 'Total loss': 0.7982930568131533} | train loss {'Reaction outcome loss': 0.8156695320240913, 'Total loss': 0.8156695320240913}
2022-11-23 02:34:03,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:03,219 INFO:     Epoch: 80
2022-11-23 02:34:04,040 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.839074967937036, 'Total loss': 0.839074967937036} | train loss {'Reaction outcome loss': 0.8163237343392065, 'Total loss': 0.8163237343392065}
2022-11-23 02:34:04,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:04,040 INFO:     Epoch: 81
2022-11-23 02:34:04,815 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7912164906209166, 'Total loss': 0.7912164906209166} | train loss {'Reaction outcome loss': 0.8200250985401292, 'Total loss': 0.8200250985401292}
2022-11-23 02:34:04,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:04,815 INFO:     Epoch: 82
2022-11-23 02:34:05,601 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7994134046814658, 'Total loss': 0.7994134046814658} | train loss {'Reaction outcome loss': 0.8151503240148867, 'Total loss': 0.8151503240148867}
2022-11-23 02:34:05,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:05,601 INFO:     Epoch: 83
2022-11-23 02:34:06,429 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8122151744636622, 'Total loss': 0.8122151744636622} | train loss {'Reaction outcome loss': 0.8148756272369816, 'Total loss': 0.8148756272369816}
2022-11-23 02:34:06,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:06,429 INFO:     Epoch: 84
2022-11-23 02:34:07,220 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7995366129008207, 'Total loss': 0.7995366129008207} | train loss {'Reaction outcome loss': 0.812827737701516, 'Total loss': 0.812827737701516}
2022-11-23 02:34:07,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:07,220 INFO:     Epoch: 85
2022-11-23 02:34:08,030 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.820760313082825, 'Total loss': 0.820760313082825} | train loss {'Reaction outcome loss': 0.813788257298931, 'Total loss': 0.813788257298931}
2022-11-23 02:34:08,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:08,031 INFO:     Epoch: 86
2022-11-23 02:34:08,867 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8015787736936049, 'Total loss': 0.8015787736936049} | train loss {'Reaction outcome loss': 0.8109652402420198, 'Total loss': 0.8109652402420198}
2022-11-23 02:34:08,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:08,868 INFO:     Epoch: 87
2022-11-23 02:34:09,660 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8053130182352933, 'Total loss': 0.8053130182352933} | train loss {'Reaction outcome loss': 0.8139432501648703, 'Total loss': 0.8139432501648703}
2022-11-23 02:34:09,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:09,660 INFO:     Epoch: 88
2022-11-23 02:34:10,475 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8215614394708113, 'Total loss': 0.8215614394708113} | train loss {'Reaction outcome loss': 0.8125012017065479, 'Total loss': 0.8125012017065479}
2022-11-23 02:34:10,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:10,476 INFO:     Epoch: 89
2022-11-23 02:34:11,283 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8027637499299917, 'Total loss': 0.8027637499299917} | train loss {'Reaction outcome loss': 0.8159742930964116, 'Total loss': 0.8159742930964116}
2022-11-23 02:34:11,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:11,283 INFO:     Epoch: 90
2022-11-23 02:34:12,101 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8180625892498277, 'Total loss': 0.8180625892498277} | train loss {'Reaction outcome loss': 0.8150319139803609, 'Total loss': 0.8150319139803609}
2022-11-23 02:34:12,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:12,101 INFO:     Epoch: 91
2022-11-23 02:34:12,900 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7870043922554363, 'Total loss': 0.7870043922554363} | train loss {'Reaction outcome loss': 0.8092364350393895, 'Total loss': 0.8092364350393895}
2022-11-23 02:34:12,900 INFO:     Found new best model at epoch 91
2022-11-23 02:34:12,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:12,901 INFO:     Epoch: 92
2022-11-23 02:34:13,743 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7847841883247549, 'Total loss': 0.7847841883247549} | train loss {'Reaction outcome loss': 0.8166995864481695, 'Total loss': 0.8166995864481695}
2022-11-23 02:34:13,743 INFO:     Found new best model at epoch 92
2022-11-23 02:34:13,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:13,744 INFO:     Epoch: 93
2022-11-23 02:34:14,546 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7949387580156326, 'Total loss': 0.7949387580156326} | train loss {'Reaction outcome loss': 0.8084083099759394, 'Total loss': 0.8084083099759394}
2022-11-23 02:34:14,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:14,547 INFO:     Epoch: 94
2022-11-23 02:34:15,377 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7963728667660193, 'Total loss': 0.7963728667660193} | train loss {'Reaction outcome loss': 0.8137523952511049, 'Total loss': 0.8137523952511049}
2022-11-23 02:34:15,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:15,377 INFO:     Epoch: 95
2022-11-23 02:34:16,185 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7970945713194934, 'Total loss': 0.7970945713194934} | train loss {'Reaction outcome loss': 0.8160744704786809, 'Total loss': 0.8160744704786809}
2022-11-23 02:34:16,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:16,185 INFO:     Epoch: 96
2022-11-23 02:34:17,005 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8006524951620535, 'Total loss': 0.8006524951620535} | train loss {'Reaction outcome loss': 0.8188203014433384, 'Total loss': 0.8188203014433384}
2022-11-23 02:34:17,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:17,005 INFO:     Epoch: 97
2022-11-23 02:34:17,809 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8151518357071009, 'Total loss': 0.8151518357071009} | train loss {'Reaction outcome loss': 0.8139801893022752, 'Total loss': 0.8139801893022752}
2022-11-23 02:34:17,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:17,810 INFO:     Epoch: 98
2022-11-23 02:34:18,666 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.79527401517738, 'Total loss': 0.79527401517738} | train loss {'Reaction outcome loss': 0.8163490392748387, 'Total loss': 0.8163490392748387}
2022-11-23 02:34:18,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:18,666 INFO:     Epoch: 99
2022-11-23 02:34:19,482 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8005239164287393, 'Total loss': 0.8005239164287393} | train loss {'Reaction outcome loss': 0.8100834307411025, 'Total loss': 0.8100834307411025}
2022-11-23 02:34:19,482 INFO:     Best model found after epoch 93 of 100.
2022-11-23 02:34:19,482 INFO:   Done with stage: TRAINING
2022-11-23 02:34:19,482 INFO:   Starting stage: EVALUATION
2022-11-23 02:34:19,603 INFO:   Done with stage: EVALUATION
2022-11-23 02:34:19,603 INFO:   Leaving out SEQ value Fold_5
2022-11-23 02:34:19,616 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 02:34:19,616 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:34:20,290 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:34:20,290 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:34:20,363 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:34:20,364 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:34:20,364 INFO:     No hyperparam tuning for this model
2022-11-23 02:34:20,364 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:34:20,364 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:34:20,365 INFO:     None feature selector for col prot
2022-11-23 02:34:20,365 INFO:     None feature selector for col prot
2022-11-23 02:34:20,365 INFO:     None feature selector for col prot
2022-11-23 02:34:20,366 INFO:     None feature selector for col chem
2022-11-23 02:34:20,366 INFO:     None feature selector for col chem
2022-11-23 02:34:20,366 INFO:     None feature selector for col chem
2022-11-23 02:34:20,366 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:34:20,366 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:34:20,368 INFO:     Number of params in model 168571
2022-11-23 02:34:20,371 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:34:20,371 INFO:   Starting stage: TRAINING
2022-11-23 02:34:20,433 INFO:     Val loss before train {'Reaction outcome loss': 0.9631637893617153, 'Total loss': 0.9631637893617153}
2022-11-23 02:34:20,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:20,433 INFO:     Epoch: 0
2022-11-23 02:34:21,234 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8082706670869481, 'Total loss': 0.8082706670869481} | train loss {'Reaction outcome loss': 0.88292122227805, 'Total loss': 0.88292122227805}
2022-11-23 02:34:21,234 INFO:     Found new best model at epoch 0
2022-11-23 02:34:21,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:21,235 INFO:     Epoch: 1
2022-11-23 02:34:22,045 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7975138425827026, 'Total loss': 0.7975138425827026} | train loss {'Reaction outcome loss': 0.8526519510210777, 'Total loss': 0.8526519510210777}
2022-11-23 02:34:22,046 INFO:     Found new best model at epoch 1
2022-11-23 02:34:22,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:22,047 INFO:     Epoch: 2
2022-11-23 02:34:22,814 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8121928152712908, 'Total loss': 0.8121928152712908} | train loss {'Reaction outcome loss': 0.8420951123140297, 'Total loss': 0.8420951123140297}
2022-11-23 02:34:22,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:22,814 INFO:     Epoch: 3
2022-11-23 02:34:23,594 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.800389139489694, 'Total loss': 0.800389139489694} | train loss {'Reaction outcome loss': 0.8423702184034854, 'Total loss': 0.8423702184034854}
2022-11-23 02:34:23,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:23,594 INFO:     Epoch: 4
2022-11-23 02:34:24,389 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7962595109235157, 'Total loss': 0.7962595109235157} | train loss {'Reaction outcome loss': 0.834274631981947, 'Total loss': 0.834274631981947}
2022-11-23 02:34:24,389 INFO:     Found new best model at epoch 4
2022-11-23 02:34:24,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:24,390 INFO:     Epoch: 5
2022-11-23 02:34:25,181 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7968769066713073, 'Total loss': 0.7968769066713073} | train loss {'Reaction outcome loss': 0.833856719245716, 'Total loss': 0.833856719245716}
2022-11-23 02:34:25,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:25,181 INFO:     Epoch: 6
2022-11-23 02:34:25,985 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.81365459615534, 'Total loss': 0.81365459615534} | train loss {'Reaction outcome loss': 0.8305089394656979, 'Total loss': 0.8305089394656979}
2022-11-23 02:34:25,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:25,985 INFO:     Epoch: 7
2022-11-23 02:34:26,791 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7803757854483344, 'Total loss': 0.7803757854483344} | train loss {'Reaction outcome loss': 0.8293548355297167, 'Total loss': 0.8293548355297167}
2022-11-23 02:34:26,791 INFO:     Found new best model at epoch 7
2022-11-23 02:34:26,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:26,792 INFO:     Epoch: 8
2022-11-23 02:34:27,605 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8066916994073174, 'Total loss': 0.8066916994073174} | train loss {'Reaction outcome loss': 0.831034973689488, 'Total loss': 0.831034973689488}
2022-11-23 02:34:27,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:27,605 INFO:     Epoch: 9
2022-11-23 02:34:28,404 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8013913482427597, 'Total loss': 0.8013913482427597} | train loss {'Reaction outcome loss': 0.8251569129982773, 'Total loss': 0.8251569129982773}
2022-11-23 02:34:28,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:28,405 INFO:     Epoch: 10
2022-11-23 02:34:29,209 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7898670990358699, 'Total loss': 0.7898670990358699} | train loss {'Reaction outcome loss': 0.8280445152399492, 'Total loss': 0.8280445152399492}
2022-11-23 02:34:29,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:29,209 INFO:     Epoch: 11
2022-11-23 02:34:30,027 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7905690432949499, 'Total loss': 0.7905690432949499} | train loss {'Reaction outcome loss': 0.8232660602550117, 'Total loss': 0.8232660602550117}
2022-11-23 02:34:30,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:30,027 INFO:     Epoch: 12
2022-11-23 02:34:30,801 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7814105735583738, 'Total loss': 0.7814105735583738} | train loss {'Reaction outcome loss': 0.8295509931992512, 'Total loss': 0.8295509931992512}
2022-11-23 02:34:30,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:30,801 INFO:     Epoch: 13
2022-11-23 02:34:31,584 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7919109849767252, 'Total loss': 0.7919109849767252} | train loss {'Reaction outcome loss': 0.8269727539043037, 'Total loss': 0.8269727539043037}
2022-11-23 02:34:31,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:31,585 INFO:     Epoch: 14
2022-11-23 02:34:32,376 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7986916202035818, 'Total loss': 0.7986916202035818} | train loss {'Reaction outcome loss': 0.8262035453806118, 'Total loss': 0.8262035453806118}
2022-11-23 02:34:32,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:32,376 INFO:     Epoch: 15
2022-11-23 02:34:33,181 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7775139957666397, 'Total loss': 0.7775139957666397} | train loss {'Reaction outcome loss': 0.8277143632879063, 'Total loss': 0.8277143632879063}
2022-11-23 02:34:33,181 INFO:     Found new best model at epoch 15
2022-11-23 02:34:33,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:33,182 INFO:     Epoch: 16
2022-11-23 02:34:33,990 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7728268483822996, 'Total loss': 0.7728268483822996} | train loss {'Reaction outcome loss': 0.8197256305996252, 'Total loss': 0.8197256305996252}
2022-11-23 02:34:33,990 INFO:     Found new best model at epoch 16
2022-11-23 02:34:33,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:33,991 INFO:     Epoch: 17
2022-11-23 02:34:34,833 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7831522849473086, 'Total loss': 0.7831522849473086} | train loss {'Reaction outcome loss': 0.8239633190388582, 'Total loss': 0.8239633190388582}
2022-11-23 02:34:34,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:34,833 INFO:     Epoch: 18
2022-11-23 02:34:35,638 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7793594928966328, 'Total loss': 0.7793594928966328} | train loss {'Reaction outcome loss': 0.8231619626891856, 'Total loss': 0.8231619626891856}
2022-11-23 02:34:35,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:35,639 INFO:     Epoch: 19
2022-11-23 02:34:36,415 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7797048958865079, 'Total loss': 0.7797048958865079} | train loss {'Reaction outcome loss': 0.8228052982262203, 'Total loss': 0.8228052982262203}
2022-11-23 02:34:36,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:36,415 INFO:     Epoch: 20
2022-11-23 02:34:37,190 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8001270578666166, 'Total loss': 0.8001270578666166} | train loss {'Reaction outcome loss': 0.82410994670829, 'Total loss': 0.82410994670829}
2022-11-23 02:34:37,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:37,191 INFO:     Epoch: 21
2022-11-23 02:34:38,014 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7911883104931224, 'Total loss': 0.7911883104931224} | train loss {'Reaction outcome loss': 0.8203541502660635, 'Total loss': 0.8203541502660635}
2022-11-23 02:34:38,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:38,015 INFO:     Epoch: 22
2022-11-23 02:34:38,848 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7760080403902314, 'Total loss': 0.7760080403902314} | train loss {'Reaction outcome loss': 0.8206784890622508, 'Total loss': 0.8206784890622508}
2022-11-23 02:34:38,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:38,849 INFO:     Epoch: 23
2022-11-23 02:34:39,623 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.796798433769833, 'Total loss': 0.796798433769833} | train loss {'Reaction outcome loss': 0.8140544710110645, 'Total loss': 0.8140544710110645}
2022-11-23 02:34:39,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:39,623 INFO:     Epoch: 24
2022-11-23 02:34:40,415 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7886169254779816, 'Total loss': 0.7886169254779816} | train loss {'Reaction outcome loss': 0.8209504948586833, 'Total loss': 0.8209504948586833}
2022-11-23 02:34:40,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:40,416 INFO:     Epoch: 25
2022-11-23 02:34:41,179 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.787487957965244, 'Total loss': 0.787487957965244} | train loss {'Reaction outcome loss': 0.8233403812865822, 'Total loss': 0.8233403812865822}
2022-11-23 02:34:41,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:41,179 INFO:     Epoch: 26
2022-11-23 02:34:41,969 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7823636355725202, 'Total loss': 0.7823636355725202} | train loss {'Reaction outcome loss': 0.8224759044695874, 'Total loss': 0.8224759044695874}
2022-11-23 02:34:41,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:41,969 INFO:     Epoch: 27
2022-11-23 02:34:42,743 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.785871028222821, 'Total loss': 0.785871028222821} | train loss {'Reaction outcome loss': 0.8188828070552981, 'Total loss': 0.8188828070552981}
2022-11-23 02:34:42,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:42,744 INFO:     Epoch: 28
2022-11-23 02:34:43,526 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7744703631509434, 'Total loss': 0.7744703631509434} | train loss {'Reaction outcome loss': 0.8220015275235079, 'Total loss': 0.8220015275235079}
2022-11-23 02:34:43,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:43,526 INFO:     Epoch: 29
2022-11-23 02:34:44,322 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7970832565968687, 'Total loss': 0.7970832565968687} | train loss {'Reaction outcome loss': 0.8197701176818536, 'Total loss': 0.8197701176818536}
2022-11-23 02:34:44,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:44,322 INFO:     Epoch: 30
2022-11-23 02:34:45,168 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8005655475638129, 'Total loss': 0.8005655475638129} | train loss {'Reaction outcome loss': 0.8233348753379316, 'Total loss': 0.8233348753379316}
2022-11-23 02:34:45,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:45,168 INFO:     Epoch: 31
2022-11-23 02:34:45,985 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.808189601383426, 'Total loss': 0.808189601383426} | train loss {'Reaction outcome loss': 0.8173657520693176, 'Total loss': 0.8173657520693176}
2022-11-23 02:34:45,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:45,985 INFO:     Epoch: 32
2022-11-23 02:34:46,738 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8009183007207784, 'Total loss': 0.8009183007207784} | train loss {'Reaction outcome loss': 0.8187780342539962, 'Total loss': 0.8187780342539962}
2022-11-23 02:34:46,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:46,738 INFO:     Epoch: 33
2022-11-23 02:34:47,537 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7818404828960245, 'Total loss': 0.7818404828960245} | train loss {'Reaction outcome loss': 0.8228604395778811, 'Total loss': 0.8228604395778811}
2022-11-23 02:34:47,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:47,538 INFO:     Epoch: 34
2022-11-23 02:34:48,325 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7837506194006313, 'Total loss': 0.7837506194006313} | train loss {'Reaction outcome loss': 0.8253935369910026, 'Total loss': 0.8253935369910026}
2022-11-23 02:34:48,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:48,325 INFO:     Epoch: 35
2022-11-23 02:34:49,150 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7884332700209185, 'Total loss': 0.7884332700209185} | train loss {'Reaction outcome loss': 0.8164574916265449, 'Total loss': 0.8164574916265449}
2022-11-23 02:34:49,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:49,150 INFO:     Epoch: 36
2022-11-23 02:34:49,976 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7720360092141412, 'Total loss': 0.7720360092141412} | train loss {'Reaction outcome loss': 0.8214962758580032, 'Total loss': 0.8214962758580032}
2022-11-23 02:34:49,977 INFO:     Found new best model at epoch 36
2022-11-23 02:34:49,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:49,977 INFO:     Epoch: 37
2022-11-23 02:34:50,808 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7950301983139731, 'Total loss': 0.7950301983139731} | train loss {'Reaction outcome loss': 0.8166331768035888, 'Total loss': 0.8166331768035888}
2022-11-23 02:34:50,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:50,808 INFO:     Epoch: 38
2022-11-23 02:34:51,605 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7784440456466242, 'Total loss': 0.7784440456466242} | train loss {'Reaction outcome loss': 0.8157880669953872, 'Total loss': 0.8157880669953872}
2022-11-23 02:34:51,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:51,606 INFO:     Epoch: 39
2022-11-23 02:34:52,473 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7683826285329732, 'Total loss': 0.7683826285329732} | train loss {'Reaction outcome loss': 0.8197357636325213, 'Total loss': 0.8197357636325213}
2022-11-23 02:34:52,474 INFO:     Found new best model at epoch 39
2022-11-23 02:34:52,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:52,475 INFO:     Epoch: 40
2022-11-23 02:34:53,284 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7962375737049363, 'Total loss': 0.7962375737049363} | train loss {'Reaction outcome loss': 0.8210310656197217, 'Total loss': 0.8210310656197217}
2022-11-23 02:34:53,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:53,284 INFO:     Epoch: 41
2022-11-23 02:34:54,130 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7884555093266747, 'Total loss': 0.7884555093266747} | train loss {'Reaction outcome loss': 0.8206529500533123, 'Total loss': 0.8206529500533123}
2022-11-23 02:34:54,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:54,130 INFO:     Epoch: 42
2022-11-23 02:34:54,939 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7703003686937419, 'Total loss': 0.7703003686937419} | train loss {'Reaction outcome loss': 0.8134399237681408, 'Total loss': 0.8134399237681408}
2022-11-23 02:34:54,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:54,939 INFO:     Epoch: 43
2022-11-23 02:34:55,751 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.792041964828968, 'Total loss': 0.792041964828968} | train loss {'Reaction outcome loss': 0.8182693707699679, 'Total loss': 0.8182693707699679}
2022-11-23 02:34:55,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:55,751 INFO:     Epoch: 44
2022-11-23 02:34:56,556 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7806484292853962, 'Total loss': 0.7806484292853962} | train loss {'Reaction outcome loss': 0.8171600352744667, 'Total loss': 0.8171600352744667}
2022-11-23 02:34:56,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:56,556 INFO:     Epoch: 45
2022-11-23 02:34:57,368 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7775121141563762, 'Total loss': 0.7775121141563762} | train loss {'Reaction outcome loss': 0.8180241891316005, 'Total loss': 0.8180241891316005}
2022-11-23 02:34:57,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:57,369 INFO:     Epoch: 46
2022-11-23 02:34:58,175 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.777887074784799, 'Total loss': 0.777887074784799} | train loss {'Reaction outcome loss': 0.8199815405874836, 'Total loss': 0.8199815405874836}
2022-11-23 02:34:58,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:58,175 INFO:     Epoch: 47
2022-11-23 02:34:58,996 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7769395736130801, 'Total loss': 0.7769395736130801} | train loss {'Reaction outcome loss': 0.8209395329562985, 'Total loss': 0.8209395329562985}
2022-11-23 02:34:58,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:58,997 INFO:     Epoch: 48
2022-11-23 02:34:59,782 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7703402760353956, 'Total loss': 0.7703402760353956} | train loss {'Reaction outcome loss': 0.8177238331765545, 'Total loss': 0.8177238331765545}
2022-11-23 02:34:59,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:34:59,782 INFO:     Epoch: 49
2022-11-23 02:35:00,608 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7767643461173231, 'Total loss': 0.7767643461173231} | train loss {'Reaction outcome loss': 0.8183048238559645, 'Total loss': 0.8183048238559645}
2022-11-23 02:35:00,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:00,609 INFO:     Epoch: 50
2022-11-23 02:35:01,377 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7734877067533407, 'Total loss': 0.7734877067533407} | train loss {'Reaction outcome loss': 0.8199862672358144, 'Total loss': 0.8199862672358144}
2022-11-23 02:35:01,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:01,377 INFO:     Epoch: 51
2022-11-23 02:35:02,173 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7534698694944382, 'Total loss': 0.7534698694944382} | train loss {'Reaction outcome loss': 0.8155377816180793, 'Total loss': 0.8155377816180793}
2022-11-23 02:35:02,173 INFO:     Found new best model at epoch 51
2022-11-23 02:35:02,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:02,174 INFO:     Epoch: 52
2022-11-23 02:35:02,981 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7717946835539558, 'Total loss': 0.7717946835539558} | train loss {'Reaction outcome loss': 0.8158324866878743, 'Total loss': 0.8158324866878743}
2022-11-23 02:35:02,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:02,981 INFO:     Epoch: 53
2022-11-23 02:35:03,783 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7632871940732002, 'Total loss': 0.7632871940732002} | train loss {'Reaction outcome loss': 0.8181826427274821, 'Total loss': 0.8181826427274821}
2022-11-23 02:35:03,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:03,783 INFO:     Epoch: 54
2022-11-23 02:35:04,584 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7780790559270165, 'Total loss': 0.7780790559270165} | train loss {'Reaction outcome loss': 0.8152053110453548, 'Total loss': 0.8152053110453548}
2022-11-23 02:35:04,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:04,585 INFO:     Epoch: 55
2022-11-23 02:35:05,379 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7730030647732995, 'Total loss': 0.7730030647732995} | train loss {'Reaction outcome loss': 0.8150553318918968, 'Total loss': 0.8150553318918968}
2022-11-23 02:35:05,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:05,379 INFO:     Epoch: 56
2022-11-23 02:35:06,144 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.789464804936539, 'Total loss': 0.789464804936539} | train loss {'Reaction outcome loss': 0.8157286361772187, 'Total loss': 0.8157286361772187}
2022-11-23 02:35:06,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:06,144 INFO:     Epoch: 57
2022-11-23 02:35:06,957 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7799354331059889, 'Total loss': 0.7799354331059889} | train loss {'Reaction outcome loss': 0.815079431509485, 'Total loss': 0.815079431509485}
2022-11-23 02:35:06,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:06,957 INFO:     Epoch: 58
2022-11-23 02:35:07,810 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7740788791667331, 'Total loss': 0.7740788791667331} | train loss {'Reaction outcome loss': 0.8160875181762539, 'Total loss': 0.8160875181762539}
2022-11-23 02:35:07,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:07,811 INFO:     Epoch: 59
2022-11-23 02:35:08,587 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7578803287311033, 'Total loss': 0.7578803287311033} | train loss {'Reaction outcome loss': 0.8143505626795243, 'Total loss': 0.8143505626795243}
2022-11-23 02:35:08,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:08,588 INFO:     Epoch: 60
2022-11-23 02:35:09,358 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7848487496376038, 'Total loss': 0.7848487496376038} | train loss {'Reaction outcome loss': 0.8186866980426165, 'Total loss': 0.8186866980426165}
2022-11-23 02:35:09,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:09,358 INFO:     Epoch: 61
2022-11-23 02:35:10,150 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7717845087701624, 'Total loss': 0.7717845087701624} | train loss {'Reaction outcome loss': 0.8191881644482515, 'Total loss': 0.8191881644482515}
2022-11-23 02:35:10,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:10,150 INFO:     Epoch: 62
2022-11-23 02:35:10,905 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7818380573933775, 'Total loss': 0.7818380573933775} | train loss {'Reaction outcome loss': 0.8179813575987913, 'Total loss': 0.8179813575987913}
2022-11-23 02:35:10,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:10,905 INFO:     Epoch: 63
2022-11-23 02:35:11,743 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7702990069308064, 'Total loss': 0.7702990069308064} | train loss {'Reaction outcome loss': 0.8124434293532858, 'Total loss': 0.8124434293532858}
2022-11-23 02:35:11,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:11,744 INFO:     Epoch: 64
2022-11-23 02:35:12,507 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7743161503564228, 'Total loss': 0.7743161503564228} | train loss {'Reaction outcome loss': 0.8181881933796162, 'Total loss': 0.8181881933796162}
2022-11-23 02:35:12,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:12,507 INFO:     Epoch: 65
2022-11-23 02:35:13,319 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7808664414015684, 'Total loss': 0.7808664414015684} | train loss {'Reaction outcome loss': 0.8135687033740842, 'Total loss': 0.8135687033740842}
2022-11-23 02:35:13,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:13,320 INFO:     Epoch: 66
2022-11-23 02:35:14,159 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7908978590911085, 'Total loss': 0.7908978590911085} | train loss {'Reaction outcome loss': 0.8126661536644916, 'Total loss': 0.8126661536644916}
2022-11-23 02:35:14,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:14,159 INFO:     Epoch: 67
2022-11-23 02:35:14,942 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7607382441108878, 'Total loss': 0.7607382441108878} | train loss {'Reaction outcome loss': 0.817856578924218, 'Total loss': 0.817856578924218}
2022-11-23 02:35:14,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:14,943 INFO:     Epoch: 68
2022-11-23 02:35:15,768 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7728698321364142, 'Total loss': 0.7728698321364142} | train loss {'Reaction outcome loss': 0.8154298770184419, 'Total loss': 0.8154298770184419}
2022-11-23 02:35:15,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:15,768 INFO:     Epoch: 69
2022-11-23 02:35:16,573 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7546307261694561, 'Total loss': 0.7546307261694561} | train loss {'Reaction outcome loss': 0.8140925912224517, 'Total loss': 0.8140925912224517}
2022-11-23 02:35:16,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:16,573 INFO:     Epoch: 70
2022-11-23 02:35:17,402 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7687928933988918, 'Total loss': 0.7687928933988918} | train loss {'Reaction outcome loss': 0.8136782287334909, 'Total loss': 0.8136782287334909}
2022-11-23 02:35:17,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:17,402 INFO:     Epoch: 71
2022-11-23 02:35:18,217 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7666594291275198, 'Total loss': 0.7666594291275198} | train loss {'Reaction outcome loss': 0.8150521693181019, 'Total loss': 0.8150521693181019}
2022-11-23 02:35:18,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:18,217 INFO:     Epoch: 72
2022-11-23 02:35:19,054 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7752741426229477, 'Total loss': 0.7752741426229477} | train loss {'Reaction outcome loss': 0.8188459927938423, 'Total loss': 0.8188459927938423}
2022-11-23 02:35:19,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:19,054 INFO:     Epoch: 73
2022-11-23 02:35:19,855 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7727450173009526, 'Total loss': 0.7727450173009526} | train loss {'Reaction outcome loss': 0.814296488372647, 'Total loss': 0.814296488372647}
2022-11-23 02:35:19,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:19,855 INFO:     Epoch: 74
2022-11-23 02:35:20,676 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7691223167560317, 'Total loss': 0.7691223167560317} | train loss {'Reaction outcome loss': 0.8126403761153318, 'Total loss': 0.8126403761153318}
2022-11-23 02:35:20,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:20,677 INFO:     Epoch: 75
2022-11-23 02:35:21,525 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7833125794475729, 'Total loss': 0.7833125794475729} | train loss {'Reaction outcome loss': 0.813449496517376, 'Total loss': 0.813449496517376}
2022-11-23 02:35:21,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:21,526 INFO:     Epoch: 76
2022-11-23 02:35:22,308 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7805750193921003, 'Total loss': 0.7805750193921003} | train loss {'Reaction outcome loss': 0.8125230413310381, 'Total loss': 0.8125230413310381}
2022-11-23 02:35:22,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:22,308 INFO:     Epoch: 77
2022-11-23 02:35:23,121 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.753950740464709, 'Total loss': 0.753950740464709} | train loss {'Reaction outcome loss': 0.8127496628128752, 'Total loss': 0.8127496628128752}
2022-11-23 02:35:23,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:23,121 INFO:     Epoch: 78
2022-11-23 02:35:23,922 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7641431364146146, 'Total loss': 0.7641431364146146} | train loss {'Reaction outcome loss': 0.8153050280955373, 'Total loss': 0.8153050280955373}
2022-11-23 02:35:23,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:23,924 INFO:     Epoch: 79
2022-11-23 02:35:24,687 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7709707482294603, 'Total loss': 0.7709707482294603} | train loss {'Reaction outcome loss': 0.8165980678431842, 'Total loss': 0.8165980678431842}
2022-11-23 02:35:24,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:24,687 INFO:     Epoch: 80
2022-11-23 02:35:25,460 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7756712551821362, 'Total loss': 0.7756712551821362} | train loss {'Reaction outcome loss': 0.815031716774921, 'Total loss': 0.815031716774921}
2022-11-23 02:35:25,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:25,461 INFO:     Epoch: 81
2022-11-23 02:35:26,268 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8056749274784868, 'Total loss': 0.8056749274784868} | train loss {'Reaction outcome loss': 0.8158096364566259, 'Total loss': 0.8158096364566259}
2022-11-23 02:35:26,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:26,268 INFO:     Epoch: 82
2022-11-23 02:35:27,064 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7837868956002322, 'Total loss': 0.7837868956002322} | train loss {'Reaction outcome loss': 0.8167939343014542, 'Total loss': 0.8167939343014542}
2022-11-23 02:35:27,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:27,064 INFO:     Epoch: 83
2022-11-23 02:35:27,867 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7759810503233563, 'Total loss': 0.7759810503233563} | train loss {'Reaction outcome loss': 0.8184240615489532, 'Total loss': 0.8184240615489532}
2022-11-23 02:35:27,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:27,868 INFO:     Epoch: 84
2022-11-23 02:35:28,662 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7705562202767893, 'Total loss': 0.7705562202767893} | train loss {'Reaction outcome loss': 0.814245932199517, 'Total loss': 0.814245932199517}
2022-11-23 02:35:28,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:28,662 INFO:     Epoch: 85
2022-11-23 02:35:29,476 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7663819369944659, 'Total loss': 0.7663819369944659} | train loss {'Reaction outcome loss': 0.8180663336296471, 'Total loss': 0.8180663336296471}
2022-11-23 02:35:29,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:29,476 INFO:     Epoch: 86
2022-11-23 02:35:30,263 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7701995779167522, 'Total loss': 0.7701995779167522} | train loss {'Reaction outcome loss': 0.8160939434353186, 'Total loss': 0.8160939434353186}
2022-11-23 02:35:30,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:30,264 INFO:     Epoch: 87
2022-11-23 02:35:31,126 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7708109759471633, 'Total loss': 0.7708109759471633} | train loss {'Reaction outcome loss': 0.8180486276441691, 'Total loss': 0.8180486276441691}
2022-11-23 02:35:31,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:31,127 INFO:     Epoch: 88
2022-11-23 02:35:31,938 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7887495458126068, 'Total loss': 0.7887495458126068} | train loss {'Reaction outcome loss': 0.8157133185133643, 'Total loss': 0.8157133185133643}
2022-11-23 02:35:31,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:31,938 INFO:     Epoch: 89
2022-11-23 02:35:32,727 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7759442444552075, 'Total loss': 0.7759442444552075} | train loss {'Reaction outcome loss': 0.8168589893652468, 'Total loss': 0.8168589893652468}
2022-11-23 02:35:32,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:32,727 INFO:     Epoch: 90
2022-11-23 02:35:33,522 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7842296490615065, 'Total loss': 0.7842296490615065} | train loss {'Reaction outcome loss': 0.8124951060937375, 'Total loss': 0.8124951060937375}
2022-11-23 02:35:33,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:33,522 INFO:     Epoch: 91
2022-11-23 02:35:34,354 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7826740016991441, 'Total loss': 0.7826740016991441} | train loss {'Reaction outcome loss': 0.811967135448845, 'Total loss': 0.811967135448845}
2022-11-23 02:35:34,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:34,355 INFO:     Epoch: 92
2022-11-23 02:35:35,162 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7859268256209113, 'Total loss': 0.7859268256209113} | train loss {'Reaction outcome loss': 0.8190406860137472, 'Total loss': 0.8190406860137472}
2022-11-23 02:35:35,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:35,162 INFO:     Epoch: 93
2022-11-23 02:35:35,952 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.757220293479887, 'Total loss': 0.757220293479887} | train loss {'Reaction outcome loss': 0.8136843045147097, 'Total loss': 0.8136843045147097}
2022-11-23 02:35:35,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:35,952 INFO:     Epoch: 94
2022-11-23 02:35:36,723 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7865842641754583, 'Total loss': 0.7865842641754583} | train loss {'Reaction outcome loss': 0.8136898235398896, 'Total loss': 0.8136898235398896}
2022-11-23 02:35:36,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:36,723 INFO:     Epoch: 95
2022-11-23 02:35:37,522 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7907671853899956, 'Total loss': 0.7907671853899956} | train loss {'Reaction outcome loss': 0.8118491805329615, 'Total loss': 0.8118491805329615}
2022-11-23 02:35:37,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:37,522 INFO:     Epoch: 96
2022-11-23 02:35:38,339 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7718170095573772, 'Total loss': 0.7718170095573772} | train loss {'Reaction outcome loss': 0.8122198901614365, 'Total loss': 0.8122198901614365}
2022-11-23 02:35:38,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:38,340 INFO:     Epoch: 97
2022-11-23 02:35:39,152 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7607193123549223, 'Total loss': 0.7607193123549223} | train loss {'Reaction outcome loss': 0.8186528173028206, 'Total loss': 0.8186528173028206}
2022-11-23 02:35:39,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:39,152 INFO:     Epoch: 98
2022-11-23 02:35:39,962 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7596032897179777, 'Total loss': 0.7596032897179777} | train loss {'Reaction outcome loss': 0.8131937265396119, 'Total loss': 0.8131937265396119}
2022-11-23 02:35:39,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:39,963 INFO:     Epoch: 99
2022-11-23 02:35:40,821 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7794061235406182, 'Total loss': 0.7794061235406182} | train loss {'Reaction outcome loss': 0.8144955180129226, 'Total loss': 0.8144955180129226}
2022-11-23 02:35:40,821 INFO:     Best model found after epoch 52 of 100.
2022-11-23 02:35:40,821 INFO:   Done with stage: TRAINING
2022-11-23 02:35:40,821 INFO:   Starting stage: EVALUATION
2022-11-23 02:35:40,952 INFO:   Done with stage: EVALUATION
2022-11-23 02:35:40,952 INFO:   Leaving out SEQ value Fold_6
2022-11-23 02:35:40,965 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 02:35:40,965 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:35:41,631 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:35:41,631 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:35:41,703 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:35:41,703 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:35:41,704 INFO:     No hyperparam tuning for this model
2022-11-23 02:35:41,704 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:35:41,704 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:35:41,705 INFO:     None feature selector for col prot
2022-11-23 02:35:41,705 INFO:     None feature selector for col prot
2022-11-23 02:35:41,705 INFO:     None feature selector for col prot
2022-11-23 02:35:41,706 INFO:     None feature selector for col chem
2022-11-23 02:35:41,706 INFO:     None feature selector for col chem
2022-11-23 02:35:41,706 INFO:     None feature selector for col chem
2022-11-23 02:35:41,706 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:35:41,706 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:35:41,708 INFO:     Number of params in model 168571
2022-11-23 02:35:41,711 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:35:41,711 INFO:   Starting stage: TRAINING
2022-11-23 02:35:41,768 INFO:     Val loss before train {'Reaction outcome loss': 1.0461075361384902, 'Total loss': 1.0461075361384902}
2022-11-23 02:35:41,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:41,769 INFO:     Epoch: 0
2022-11-23 02:35:42,583 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.870884494726048, 'Total loss': 0.870884494726048} | train loss {'Reaction outcome loss': 0.8638698965555331, 'Total loss': 0.8638698965555331}
2022-11-23 02:35:42,584 INFO:     Found new best model at epoch 0
2022-11-23 02:35:42,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:42,585 INFO:     Epoch: 1
2022-11-23 02:35:43,407 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8494961234026177, 'Total loss': 0.8494961234026177} | train loss {'Reaction outcome loss': 0.8344146321054364, 'Total loss': 0.8344146321054364}
2022-11-23 02:35:43,407 INFO:     Found new best model at epoch 1
2022-11-23 02:35:43,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:43,408 INFO:     Epoch: 2
2022-11-23 02:35:44,201 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8565851228181706, 'Total loss': 0.8565851228181706} | train loss {'Reaction outcome loss': 0.8279146754839382, 'Total loss': 0.8279146754839382}
2022-11-23 02:35:44,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:44,201 INFO:     Epoch: 3
2022-11-23 02:35:45,054 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8528756291367287, 'Total loss': 0.8528756291367287} | train loss {'Reaction outcome loss': 0.8301232681899774, 'Total loss': 0.8301232681899774}
2022-11-23 02:35:45,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:45,054 INFO:     Epoch: 4
2022-11-23 02:35:45,841 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.854038650213286, 'Total loss': 0.854038650213286} | train loss {'Reaction outcome loss': 0.8187284810376949, 'Total loss': 0.8187284810376949}
2022-11-23 02:35:45,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:45,841 INFO:     Epoch: 5
2022-11-23 02:35:46,628 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8394609121389167, 'Total loss': 0.8394609121389167} | train loss {'Reaction outcome loss': 0.8150165637985605, 'Total loss': 0.8150165637985605}
2022-11-23 02:35:46,628 INFO:     Found new best model at epoch 5
2022-11-23 02:35:46,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:46,629 INFO:     Epoch: 6
2022-11-23 02:35:47,396 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8760139623353648, 'Total loss': 0.8760139623353648} | train loss {'Reaction outcome loss': 0.8154554728601799, 'Total loss': 0.8154554728601799}
2022-11-23 02:35:47,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:47,396 INFO:     Epoch: 7
2022-11-23 02:35:48,169 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8372932506162066, 'Total loss': 0.8372932506162066} | train loss {'Reaction outcome loss': 0.8104735858372001, 'Total loss': 0.8104735858372001}
2022-11-23 02:35:48,169 INFO:     Found new best model at epoch 7
2022-11-23 02:35:48,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:48,170 INFO:     Epoch: 8
2022-11-23 02:35:48,958 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.838605925787327, 'Total loss': 0.838605925787327} | train loss {'Reaction outcome loss': 0.8079227998119886, 'Total loss': 0.8079227998119886}
2022-11-23 02:35:48,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:48,958 INFO:     Epoch: 9
2022-11-23 02:35:49,739 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8321371827014657, 'Total loss': 0.8321371827014657} | train loss {'Reaction outcome loss': 0.8087560644403833, 'Total loss': 0.8087560644403833}
2022-11-23 02:35:49,739 INFO:     Found new best model at epoch 9
2022-11-23 02:35:49,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:49,740 INFO:     Epoch: 10
2022-11-23 02:35:50,542 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8532026091287302, 'Total loss': 0.8532026091287302} | train loss {'Reaction outcome loss': 0.8060545230009517, 'Total loss': 0.8060545230009517}
2022-11-23 02:35:50,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:50,542 INFO:     Epoch: 11
2022-11-23 02:35:51,359 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.853635557169138, 'Total loss': 0.853635557169138} | train loss {'Reaction outcome loss': 0.8055603717927073, 'Total loss': 0.8055603717927073}
2022-11-23 02:35:51,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:51,359 INFO:     Epoch: 12
2022-11-23 02:35:52,122 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.847896472659222, 'Total loss': 0.847896472659222} | train loss {'Reaction outcome loss': 0.8031943740903355, 'Total loss': 0.8031943740903355}
2022-11-23 02:35:52,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:52,123 INFO:     Epoch: 13
2022-11-23 02:35:52,915 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8423744911371276, 'Total loss': 0.8423744911371276} | train loss {'Reaction outcome loss': 0.8044433102744525, 'Total loss': 0.8044433102744525}
2022-11-23 02:35:52,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:52,915 INFO:     Epoch: 14
2022-11-23 02:35:53,723 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8385302077892215, 'Total loss': 0.8385302077892215} | train loss {'Reaction outcome loss': 0.7988923706236433, 'Total loss': 0.7988923706236433}
2022-11-23 02:35:53,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:53,723 INFO:     Epoch: 15
2022-11-23 02:35:54,510 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8290204170138337, 'Total loss': 0.8290204170138337} | train loss {'Reaction outcome loss': 0.8068908449323451, 'Total loss': 0.8068908449323451}
2022-11-23 02:35:54,510 INFO:     Found new best model at epoch 15
2022-11-23 02:35:54,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:54,511 INFO:     Epoch: 16
2022-11-23 02:35:55,291 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8458140305308408, 'Total loss': 0.8458140305308408} | train loss {'Reaction outcome loss': 0.8022979667685071, 'Total loss': 0.8022979667685071}
2022-11-23 02:35:55,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:55,293 INFO:     Epoch: 17
2022-11-23 02:35:56,121 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8451847281566885, 'Total loss': 0.8451847281566885} | train loss {'Reaction outcome loss': 0.8077651568856395, 'Total loss': 0.8077651568856395}
2022-11-23 02:35:56,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:56,122 INFO:     Epoch: 18
2022-11-23 02:35:56,938 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8457160093063532, 'Total loss': 0.8457160093063532} | train loss {'Reaction outcome loss': 0.8013828612986158, 'Total loss': 0.8013828612986158}
2022-11-23 02:35:56,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:56,939 INFO:     Epoch: 19
2022-11-23 02:35:57,712 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8674046515032302, 'Total loss': 0.8674046515032302} | train loss {'Reaction outcome loss': 0.8014913896312479, 'Total loss': 0.8014913896312479}
2022-11-23 02:35:57,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:57,712 INFO:     Epoch: 20
2022-11-23 02:35:58,527 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8815797317859738, 'Total loss': 0.8815797317859738} | train loss {'Reaction outcome loss': 0.8046763330453732, 'Total loss': 0.8046763330453732}
2022-11-23 02:35:58,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:58,527 INFO:     Epoch: 21
2022-11-23 02:35:59,351 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8331394008425779, 'Total loss': 0.8331394008425779} | train loss {'Reaction outcome loss': 0.8039591236681235, 'Total loss': 0.8039591236681235}
2022-11-23 02:35:59,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:35:59,352 INFO:     Epoch: 22
2022-11-23 02:36:00,154 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8460776805877686, 'Total loss': 0.8460776805877686} | train loss {'Reaction outcome loss': 0.8048258121507089, 'Total loss': 0.8048258121507089}
2022-11-23 02:36:00,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:00,154 INFO:     Epoch: 23
2022-11-23 02:36:00,932 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8460437371287235, 'Total loss': 0.8460437371287235} | train loss {'Reaction outcome loss': 0.8009909870194607, 'Total loss': 0.8009909870194607}
2022-11-23 02:36:00,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:00,932 INFO:     Epoch: 24
2022-11-23 02:36:01,745 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8439074768576511, 'Total loss': 0.8439074768576511} | train loss {'Reaction outcome loss': 0.8049339126856601, 'Total loss': 0.8049339126856601}
2022-11-23 02:36:01,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:01,746 INFO:     Epoch: 25
2022-11-23 02:36:02,567 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8333103206268576, 'Total loss': 0.8333103206268576} | train loss {'Reaction outcome loss': 0.7970932426511265, 'Total loss': 0.7970932426511265}
2022-11-23 02:36:02,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:02,567 INFO:     Epoch: 26
2022-11-23 02:36:03,369 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8474884435187938, 'Total loss': 0.8474884435187938} | train loss {'Reaction outcome loss': 0.7993169025075241, 'Total loss': 0.7993169025075241}
2022-11-23 02:36:03,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:03,369 INFO:     Epoch: 27
2022-11-23 02:36:04,238 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8662999327792678, 'Total loss': 0.8662999327792678} | train loss {'Reaction outcome loss': 0.8000894632251536, 'Total loss': 0.8000894632251536}
2022-11-23 02:36:04,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:04,239 INFO:     Epoch: 28
2022-11-23 02:36:05,071 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8412772874499477, 'Total loss': 0.8412772874499477} | train loss {'Reaction outcome loss': 0.8005122669407578, 'Total loss': 0.8005122669407578}
2022-11-23 02:36:05,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:05,072 INFO:     Epoch: 29
2022-11-23 02:36:05,881 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8547058701515198, 'Total loss': 0.8547058701515198} | train loss {'Reaction outcome loss': 0.8012709722655719, 'Total loss': 0.8012709722655719}
2022-11-23 02:36:05,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:05,881 INFO:     Epoch: 30
2022-11-23 02:36:06,664 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8373263201048208, 'Total loss': 0.8373263201048208} | train loss {'Reaction outcome loss': 0.7979506924748421, 'Total loss': 0.7979506924748421}
2022-11-23 02:36:06,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:06,664 INFO:     Epoch: 31
2022-11-23 02:36:07,448 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8433390384496644, 'Total loss': 0.8433390384496644} | train loss {'Reaction outcome loss': 0.800815225013944, 'Total loss': 0.800815225013944}
2022-11-23 02:36:07,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:07,448 INFO:     Epoch: 32
2022-11-23 02:36:08,253 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8354795831580495, 'Total loss': 0.8354795831580495} | train loss {'Reaction outcome loss': 0.7989240678363159, 'Total loss': 0.7989240678363159}
2022-11-23 02:36:08,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:08,253 INFO:     Epoch: 33
2022-11-23 02:36:09,106 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8381683091784633, 'Total loss': 0.8381683091784633} | train loss {'Reaction outcome loss': 0.7974810507453856, 'Total loss': 0.7974810507453856}
2022-11-23 02:36:09,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:09,107 INFO:     Epoch: 34
2022-11-23 02:36:09,919 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8318273508271505, 'Total loss': 0.8318273508271505} | train loss {'Reaction outcome loss': 0.8032813991923802, 'Total loss': 0.8032813991923802}
2022-11-23 02:36:09,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:09,919 INFO:     Epoch: 35
2022-11-23 02:36:10,777 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8324844594611678, 'Total loss': 0.8324844594611678} | train loss {'Reaction outcome loss': 0.8007129987732309, 'Total loss': 0.8007129987732309}
2022-11-23 02:36:10,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:10,777 INFO:     Epoch: 36
2022-11-23 02:36:11,602 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.837215917054997, 'Total loss': 0.837215917054997} | train loss {'Reaction outcome loss': 0.7960914595693839, 'Total loss': 0.7960914595693839}
2022-11-23 02:36:11,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:11,602 INFO:     Epoch: 37
2022-11-23 02:36:12,363 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8388250906800114, 'Total loss': 0.8388250906800114} | train loss {'Reaction outcome loss': 0.795200671695295, 'Total loss': 0.795200671695295}
2022-11-23 02:36:12,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:12,363 INFO:     Epoch: 38
2022-11-23 02:36:13,163 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8486395076263783, 'Total loss': 0.8486395076263783} | train loss {'Reaction outcome loss': 0.7969364205100498, 'Total loss': 0.7969364205100498}
2022-11-23 02:36:13,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:13,164 INFO:     Epoch: 39
2022-11-23 02:36:13,991 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8296718320181203, 'Total loss': 0.8296718320181203} | train loss {'Reaction outcome loss': 0.7982236529227162, 'Total loss': 0.7982236529227162}
2022-11-23 02:36:13,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:13,992 INFO:     Epoch: 40
2022-11-23 02:36:14,800 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8293389095816501, 'Total loss': 0.8293389095816501} | train loss {'Reaction outcome loss': 0.799707823723066, 'Total loss': 0.799707823723066}
2022-11-23 02:36:14,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:14,801 INFO:     Epoch: 41
2022-11-23 02:36:15,649 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8459605158761491, 'Total loss': 0.8459605158761491} | train loss {'Reaction outcome loss': 0.7961299504901542, 'Total loss': 0.7961299504901542}
2022-11-23 02:36:15,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:15,650 INFO:     Epoch: 42
2022-11-23 02:36:16,457 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8392126463180365, 'Total loss': 0.8392126463180365} | train loss {'Reaction outcome loss': 0.7959309893309093, 'Total loss': 0.7959309893309093}
2022-11-23 02:36:16,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:16,458 INFO:     Epoch: 43
2022-11-23 02:36:17,307 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8585170784661936, 'Total loss': 0.8585170784661936} | train loss {'Reaction outcome loss': 0.7945999650925887, 'Total loss': 0.7945999650925887}
2022-11-23 02:36:17,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:17,307 INFO:     Epoch: 44
2022-11-23 02:36:18,129 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8442702529042266, 'Total loss': 0.8442702529042266} | train loss {'Reaction outcome loss': 0.8009119629859924, 'Total loss': 0.8009119629859924}
2022-11-23 02:36:18,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:18,129 INFO:     Epoch: 45
2022-11-23 02:36:18,903 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8379636538583178, 'Total loss': 0.8379636538583178} | train loss {'Reaction outcome loss': 0.8008860680656354, 'Total loss': 0.8008860680656354}
2022-11-23 02:36:18,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:18,903 INFO:     Epoch: 46
2022-11-23 02:36:19,687 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8485419195751811, 'Total loss': 0.8485419195751811} | train loss {'Reaction outcome loss': 0.7991348237532084, 'Total loss': 0.7991348237532084}
2022-11-23 02:36:19,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:19,687 INFO:     Epoch: 47
2022-11-23 02:36:20,483 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.9023616203041964, 'Total loss': 0.9023616203041964} | train loss {'Reaction outcome loss': 0.7887677467260205, 'Total loss': 0.7887677467260205}
2022-11-23 02:36:20,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:20,484 INFO:     Epoch: 48
2022-11-23 02:36:21,220 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8405906412490579, 'Total loss': 0.8405906412490579} | train loss {'Reaction outcome loss': 0.798574978577309, 'Total loss': 0.798574978577309}
2022-11-23 02:36:21,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:21,221 INFO:     Epoch: 49
2022-11-23 02:36:22,010 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8322863973850427, 'Total loss': 0.8322863973850427} | train loss {'Reaction outcome loss': 0.7958978409649896, 'Total loss': 0.7958978409649896}
2022-11-23 02:36:22,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:22,010 INFO:     Epoch: 50
2022-11-23 02:36:22,841 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8251385466997013, 'Total loss': 0.8251385466997013} | train loss {'Reaction outcome loss': 0.7956408155990429, 'Total loss': 0.7956408155990429}
2022-11-23 02:36:22,841 INFO:     Found new best model at epoch 50
2022-11-23 02:36:22,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:22,842 INFO:     Epoch: 51
2022-11-23 02:36:23,617 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8446723832640537, 'Total loss': 0.8446723832640537} | train loss {'Reaction outcome loss': 0.797355093428346, 'Total loss': 0.797355093428346}
2022-11-23 02:36:23,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:23,617 INFO:     Epoch: 52
2022-11-23 02:36:24,430 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8439684316169384, 'Total loss': 0.8439684316169384} | train loss {'Reaction outcome loss': 0.7940838722909083, 'Total loss': 0.7940838722909083}
2022-11-23 02:36:24,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:24,430 INFO:     Epoch: 53
2022-11-23 02:36:25,195 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8260270551193593, 'Total loss': 0.8260270551193593} | train loss {'Reaction outcome loss': 0.793765014434447, 'Total loss': 0.793765014434447}
2022-11-23 02:36:25,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:25,195 INFO:     Epoch: 54
2022-11-23 02:36:25,998 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8353370968685594, 'Total loss': 0.8353370968685594} | train loss {'Reaction outcome loss': 0.8008898545484073, 'Total loss': 0.8008898545484073}
2022-11-23 02:36:25,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:25,998 INFO:     Epoch: 55
2022-11-23 02:36:26,838 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8245129432789114, 'Total loss': 0.8245129432789114} | train loss {'Reaction outcome loss': 0.7967437116093323, 'Total loss': 0.7967437116093323}
2022-11-23 02:36:26,840 INFO:     Found new best model at epoch 55
2022-11-23 02:36:26,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:26,841 INFO:     Epoch: 56
2022-11-23 02:36:27,670 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8307112150414045, 'Total loss': 0.8307112150414045} | train loss {'Reaction outcome loss': 0.7923263721778745, 'Total loss': 0.7923263721778745}
2022-11-23 02:36:27,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:27,670 INFO:     Epoch: 57
2022-11-23 02:36:28,473 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8225454286087391, 'Total loss': 0.8225454286087391} | train loss {'Reaction outcome loss': 0.7976858565797571, 'Total loss': 0.7976858565797571}
2022-11-23 02:36:28,473 INFO:     Found new best model at epoch 57
2022-11-23 02:36:28,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:28,474 INFO:     Epoch: 58
2022-11-23 02:36:29,259 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8364426569883213, 'Total loss': 0.8364426569883213} | train loss {'Reaction outcome loss': 0.7897688547363046, 'Total loss': 0.7897688547363046}
2022-11-23 02:36:29,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:29,259 INFO:     Epoch: 59
2022-11-23 02:36:30,036 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8234831905642221, 'Total loss': 0.8234831905642221} | train loss {'Reaction outcome loss': 0.7936980972280268, 'Total loss': 0.7936980972280268}
2022-11-23 02:36:30,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:30,037 INFO:     Epoch: 60
2022-11-23 02:36:30,841 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8288888085720151, 'Total loss': 0.8288888085720151} | train loss {'Reaction outcome loss': 0.7956146331595593, 'Total loss': 0.7956146331595593}
2022-11-23 02:36:30,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:30,841 INFO:     Epoch: 61
2022-11-23 02:36:31,657 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8208183965017629, 'Total loss': 0.8208183965017629} | train loss {'Reaction outcome loss': 0.7945576823148571, 'Total loss': 0.7945576823148571}
2022-11-23 02:36:31,657 INFO:     Found new best model at epoch 61
2022-11-23 02:36:31,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:31,658 INFO:     Epoch: 62
2022-11-23 02:36:32,503 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8458510540252508, 'Total loss': 0.8458510540252508} | train loss {'Reaction outcome loss': 0.7950766631325737, 'Total loss': 0.7950766631325737}
2022-11-23 02:36:32,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:32,504 INFO:     Epoch: 63
2022-11-23 02:36:33,309 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8263774236967397, 'Total loss': 0.8263774236967397} | train loss {'Reaction outcome loss': 0.7941164358473215, 'Total loss': 0.7941164358473215}
2022-11-23 02:36:33,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:33,310 INFO:     Epoch: 64
2022-11-23 02:36:34,071 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8418150939220606, 'Total loss': 0.8418150939220606} | train loss {'Reaction outcome loss': 0.7937475104556709, 'Total loss': 0.7937475104556709}
2022-11-23 02:36:34,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:34,071 INFO:     Epoch: 65
2022-11-23 02:36:34,875 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8296733311442441, 'Total loss': 0.8296733311442441} | train loss {'Reaction outcome loss': 0.7975574653656756, 'Total loss': 0.7975574653656756}
2022-11-23 02:36:34,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:34,875 INFO:     Epoch: 66
2022-11-23 02:36:35,647 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8587137252785438, 'Total loss': 0.8587137252785438} | train loss {'Reaction outcome loss': 0.7918661251419881, 'Total loss': 0.7918661251419881}
2022-11-23 02:36:35,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:35,648 INFO:     Epoch: 67
2022-11-23 02:36:36,465 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8279363291208134, 'Total loss': 0.8279363291208134} | train loss {'Reaction outcome loss': 0.7917382962635306, 'Total loss': 0.7917382962635306}
2022-11-23 02:36:36,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:36,466 INFO:     Epoch: 68
2022-11-23 02:36:37,237 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8289573123288709, 'Total loss': 0.8289573123288709} | train loss {'Reaction outcome loss': 0.7969006299972534, 'Total loss': 0.7969006299972534}
2022-11-23 02:36:37,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:37,237 INFO:     Epoch: 69
2022-11-23 02:36:38,004 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8350803034250126, 'Total loss': 0.8350803034250126} | train loss {'Reaction outcome loss': 0.7924843165473859, 'Total loss': 0.7924843165473859}
2022-11-23 02:36:38,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:38,004 INFO:     Epoch: 70
2022-11-23 02:36:38,835 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8318758863349294, 'Total loss': 0.8318758863349294} | train loss {'Reaction outcome loss': 0.7910636262815507, 'Total loss': 0.7910636262815507}
2022-11-23 02:36:38,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:38,835 INFO:     Epoch: 71
2022-11-23 02:36:39,618 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8337297619775285, 'Total loss': 0.8337297619775285} | train loss {'Reaction outcome loss': 0.7945404288465859, 'Total loss': 0.7945404288465859}
2022-11-23 02:36:39,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:39,618 INFO:     Epoch: 72
2022-11-23 02:36:40,425 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8275360603665196, 'Total loss': 0.8275360603665196} | train loss {'Reaction outcome loss': 0.7891514229237057, 'Total loss': 0.7891514229237057}
2022-11-23 02:36:40,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:40,425 INFO:     Epoch: 73
2022-11-23 02:36:41,195 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8424942237000133, 'Total loss': 0.8424942237000133} | train loss {'Reaction outcome loss': 0.7968853488564491, 'Total loss': 0.7968853488564491}
2022-11-23 02:36:41,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:41,195 INFO:     Epoch: 74
2022-11-23 02:36:42,001 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8442993940309037, 'Total loss': 0.8442993940309037} | train loss {'Reaction outcome loss': 0.7924101298949757, 'Total loss': 0.7924101298949757}
2022-11-23 02:36:42,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:42,001 INFO:     Epoch: 75
2022-11-23 02:36:42,807 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8218956853068152, 'Total loss': 0.8218956853068152} | train loss {'Reaction outcome loss': 0.7947183898726448, 'Total loss': 0.7947183898726448}
2022-11-23 02:36:42,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:42,807 INFO:     Epoch: 76
2022-11-23 02:36:43,584 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8353280286456264, 'Total loss': 0.8353280286456264} | train loss {'Reaction outcome loss': 0.7872787681026537, 'Total loss': 0.7872787681026537}
2022-11-23 02:36:43,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:43,585 INFO:     Epoch: 77
2022-11-23 02:36:44,369 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8436166630234829, 'Total loss': 0.8436166630234829} | train loss {'Reaction outcome loss': 0.7877137158982089, 'Total loss': 0.7877137158982089}
2022-11-23 02:36:44,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:44,370 INFO:     Epoch: 78
2022-11-23 02:36:45,171 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8259273254594137, 'Total loss': 0.8259273254594137} | train loss {'Reaction outcome loss': 0.7877815120288583, 'Total loss': 0.7877815120288583}
2022-11-23 02:36:45,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:45,171 INFO:     Epoch: 79
2022-11-23 02:36:45,974 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8368403703667396, 'Total loss': 0.8368403703667396} | train loss {'Reaction outcome loss': 0.7965236684826554, 'Total loss': 0.7965236684826554}
2022-11-23 02:36:45,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:45,975 INFO:     Epoch: 80
2022-11-23 02:36:46,725 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8302545845508575, 'Total loss': 0.8302545845508575} | train loss {'Reaction outcome loss': 0.7887744419887418, 'Total loss': 0.7887744419887418}
2022-11-23 02:36:46,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:46,725 INFO:     Epoch: 81
2022-11-23 02:36:47,534 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8285934925079346, 'Total loss': 0.8285934925079346} | train loss {'Reaction outcome loss': 0.7890519954142023, 'Total loss': 0.7890519954142023}
2022-11-23 02:36:47,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:47,535 INFO:     Epoch: 82
2022-11-23 02:36:48,334 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8360390261162159, 'Total loss': 0.8360390261162159} | train loss {'Reaction outcome loss': 0.7852204488437684, 'Total loss': 0.7852204488437684}
2022-11-23 02:36:48,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:48,335 INFO:     Epoch: 83
2022-11-23 02:36:49,107 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8210856394712315, 'Total loss': 0.8210856394712315} | train loss {'Reaction outcome loss': 0.7926045509635425, 'Total loss': 0.7926045509635425}
2022-11-23 02:36:49,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:49,107 INFO:     Epoch: 84
2022-11-23 02:36:49,943 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.840116233326668, 'Total loss': 0.840116233326668} | train loss {'Reaction outcome loss': 0.7876416189504452, 'Total loss': 0.7876416189504452}
2022-11-23 02:36:49,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:49,943 INFO:     Epoch: 85
2022-11-23 02:36:50,747 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8321569693642993, 'Total loss': 0.8321569693642993} | train loss {'Reaction outcome loss': 0.7865836852398075, 'Total loss': 0.7865836852398075}
2022-11-23 02:36:50,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:50,747 INFO:     Epoch: 86
2022-11-23 02:36:51,537 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8298385843288066, 'Total loss': 0.8298385843288066} | train loss {'Reaction outcome loss': 0.7885302755920613, 'Total loss': 0.7885302755920613}
2022-11-23 02:36:51,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:51,537 INFO:     Epoch: 87
2022-11-23 02:36:52,305 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8566696588383165, 'Total loss': 0.8566696588383165} | train loss {'Reaction outcome loss': 0.7861671083774723, 'Total loss': 0.7861671083774723}
2022-11-23 02:36:52,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:52,305 INFO:     Epoch: 88
2022-11-23 02:36:53,112 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8304468032925628, 'Total loss': 0.8304468032925628} | train loss {'Reaction outcome loss': 0.7878347036779904, 'Total loss': 0.7878347036779904}
2022-11-23 02:36:53,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:53,113 INFO:     Epoch: 89
2022-11-23 02:36:53,910 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8433014646519063, 'Total loss': 0.8433014646519063} | train loss {'Reaction outcome loss': 0.7853006264958226, 'Total loss': 0.7853006264958226}
2022-11-23 02:36:53,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:53,910 INFO:     Epoch: 90
2022-11-23 02:36:54,689 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8409487327864004, 'Total loss': 0.8409487327864004} | train loss {'Reaction outcome loss': 0.7807111344987252, 'Total loss': 0.7807111344987252}
2022-11-23 02:36:54,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:54,690 INFO:     Epoch: 91
2022-11-23 02:36:55,497 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8243202740369842, 'Total loss': 0.8243202740369842} | train loss {'Reaction outcome loss': 0.7836318156514012, 'Total loss': 0.7836318156514012}
2022-11-23 02:36:55,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:55,497 INFO:     Epoch: 92
2022-11-23 02:36:56,349 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8212271221848422, 'Total loss': 0.8212271221848422} | train loss {'Reaction outcome loss': 0.7804678448888122, 'Total loss': 0.7804678448888122}
2022-11-23 02:36:56,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:56,350 INFO:     Epoch: 93
2022-11-23 02:36:57,194 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8340768322002056, 'Total loss': 0.8340768322002056} | train loss {'Reaction outcome loss': 0.7863678559660912, 'Total loss': 0.7863678559660912}
2022-11-23 02:36:57,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:57,194 INFO:     Epoch: 94
2022-11-23 02:36:57,957 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8461624480957208, 'Total loss': 0.8461624480957208} | train loss {'Reaction outcome loss': 0.7816599127454836, 'Total loss': 0.7816599127454836}
2022-11-23 02:36:57,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:57,957 INFO:     Epoch: 95
2022-11-23 02:36:58,766 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8219614929931108, 'Total loss': 0.8219614929931108} | train loss {'Reaction outcome loss': 0.7859996553571498, 'Total loss': 0.7859996553571498}
2022-11-23 02:36:58,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:58,767 INFO:     Epoch: 96
2022-11-23 02:36:59,547 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8240014127520627, 'Total loss': 0.8240014127520627} | train loss {'Reaction outcome loss': 0.7835911253436667, 'Total loss': 0.7835911253436667}
2022-11-23 02:36:59,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:36:59,547 INFO:     Epoch: 97
2022-11-23 02:37:00,315 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.818003001601197, 'Total loss': 0.818003001601197} | train loss {'Reaction outcome loss': 0.7791589841735168, 'Total loss': 0.7791589841735168}
2022-11-23 02:37:00,315 INFO:     Found new best model at epoch 97
2022-11-23 02:37:00,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:00,316 INFO:     Epoch: 98
2022-11-23 02:37:01,135 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.826788324256276, 'Total loss': 0.826788324256276} | train loss {'Reaction outcome loss': 0.7852220454665481, 'Total loss': 0.7852220454665481}
2022-11-23 02:37:01,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:01,135 INFO:     Epoch: 99
2022-11-23 02:37:01,922 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8205617416736691, 'Total loss': 0.8205617416736691} | train loss {'Reaction outcome loss': 0.7770257291735195, 'Total loss': 0.7770257291735195}
2022-11-23 02:37:01,922 INFO:     Best model found after epoch 98 of 100.
2022-11-23 02:37:01,922 INFO:   Done with stage: TRAINING
2022-11-23 02:37:01,922 INFO:   Starting stage: EVALUATION
2022-11-23 02:37:02,059 INFO:   Done with stage: EVALUATION
2022-11-23 02:37:02,059 INFO:   Leaving out SEQ value Fold_7
2022-11-23 02:37:02,072 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:37:02,072 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:37:02,745 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:37:02,746 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:37:02,819 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:37:02,819 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:37:02,819 INFO:     No hyperparam tuning for this model
2022-11-23 02:37:02,819 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:37:02,819 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:37:02,820 INFO:     None feature selector for col prot
2022-11-23 02:37:02,820 INFO:     None feature selector for col prot
2022-11-23 02:37:02,820 INFO:     None feature selector for col prot
2022-11-23 02:37:02,821 INFO:     None feature selector for col chem
2022-11-23 02:37:02,821 INFO:     None feature selector for col chem
2022-11-23 02:37:02,821 INFO:     None feature selector for col chem
2022-11-23 02:37:02,821 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:37:02,821 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:37:02,823 INFO:     Number of params in model 168571
2022-11-23 02:37:02,826 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:37:02,826 INFO:   Starting stage: TRAINING
2022-11-23 02:37:02,884 INFO:     Val loss before train {'Reaction outcome loss': 1.048336304046891, 'Total loss': 1.048336304046891}
2022-11-23 02:37:02,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:02,884 INFO:     Epoch: 0
2022-11-23 02:37:03,676 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9006385870955207, 'Total loss': 0.9006385870955207} | train loss {'Reaction outcome loss': 0.878615208090313, 'Total loss': 0.878615208090313}
2022-11-23 02:37:03,676 INFO:     Found new best model at epoch 0
2022-11-23 02:37:03,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:03,677 INFO:     Epoch: 1
2022-11-23 02:37:04,487 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9074061079458757, 'Total loss': 0.9074061079458757} | train loss {'Reaction outcome loss': 0.8431582322284099, 'Total loss': 0.8431582322284099}
2022-11-23 02:37:04,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:04,487 INFO:     Epoch: 2
2022-11-23 02:37:05,348 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8885732103477825, 'Total loss': 0.8885732103477825} | train loss {'Reaction outcome loss': 0.8363122795858691, 'Total loss': 0.8363122795858691}
2022-11-23 02:37:05,349 INFO:     Found new best model at epoch 2
2022-11-23 02:37:05,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:05,350 INFO:     Epoch: 3
2022-11-23 02:37:06,146 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8907562873580239, 'Total loss': 0.8907562873580239} | train loss {'Reaction outcome loss': 0.8445344892961364, 'Total loss': 0.8445344892961364}
2022-11-23 02:37:06,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:06,146 INFO:     Epoch: 4
2022-11-23 02:37:06,926 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8846222744746641, 'Total loss': 0.8846222744746641} | train loss {'Reaction outcome loss': 0.8293961315385757, 'Total loss': 0.8293961315385757}
2022-11-23 02:37:06,926 INFO:     Found new best model at epoch 4
2022-11-23 02:37:06,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:06,927 INFO:     Epoch: 5
2022-11-23 02:37:07,729 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8908213837580248, 'Total loss': 0.8908213837580248} | train loss {'Reaction outcome loss': 0.830081537486084, 'Total loss': 0.830081537486084}
2022-11-23 02:37:07,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:07,729 INFO:     Epoch: 6
2022-11-23 02:37:08,559 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9110477241602811, 'Total loss': 0.9110477241602811} | train loss {'Reaction outcome loss': 0.823252538519521, 'Total loss': 0.823252538519521}
2022-11-23 02:37:08,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:08,559 INFO:     Epoch: 7
2022-11-23 02:37:09,358 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8783766986294226, 'Total loss': 0.8783766986294226} | train loss {'Reaction outcome loss': 0.8252896541549314, 'Total loss': 0.8252896541549314}
2022-11-23 02:37:09,358 INFO:     Found new best model at epoch 7
2022-11-23 02:37:09,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:09,359 INFO:     Epoch: 8
2022-11-23 02:37:10,170 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8831167668104172, 'Total loss': 0.8831167668104172} | train loss {'Reaction outcome loss': 0.817301566562345, 'Total loss': 0.817301566562345}
2022-11-23 02:37:10,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:10,170 INFO:     Epoch: 9
2022-11-23 02:37:11,007 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8939970609816638, 'Total loss': 0.8939970609816638} | train loss {'Reaction outcome loss': 0.8203392898844134, 'Total loss': 0.8203392898844134}
2022-11-23 02:37:11,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:11,008 INFO:     Epoch: 10
2022-11-23 02:37:11,844 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8933992142027075, 'Total loss': 0.8933992142027075} | train loss {'Reaction outcome loss': 0.8184098311729969, 'Total loss': 0.8184098311729969}
2022-11-23 02:37:11,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:11,844 INFO:     Epoch: 11
2022-11-23 02:37:12,679 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8825615895065394, 'Total loss': 0.8825615895065394} | train loss {'Reaction outcome loss': 0.8179475064239194, 'Total loss': 0.8179475064239194}
2022-11-23 02:37:12,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:12,679 INFO:     Epoch: 12
2022-11-23 02:37:13,513 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8685324036262252, 'Total loss': 0.8685324036262252} | train loss {'Reaction outcome loss': 0.816410317656494, 'Total loss': 0.816410317656494}
2022-11-23 02:37:13,513 INFO:     Found new best model at epoch 12
2022-11-23 02:37:13,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:13,514 INFO:     Epoch: 13
2022-11-23 02:37:14,323 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8758179823105986, 'Total loss': 0.8758179823105986} | train loss {'Reaction outcome loss': 0.8139839714332935, 'Total loss': 0.8139839714332935}
2022-11-23 02:37:14,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:14,324 INFO:     Epoch: 14
2022-11-23 02:37:15,155 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8685839135538448, 'Total loss': 0.8685839135538448} | train loss {'Reaction outcome loss': 0.8153276296873246, 'Total loss': 0.8153276296873246}
2022-11-23 02:37:15,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:15,155 INFO:     Epoch: 15
2022-11-23 02:37:15,992 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.880145785483447, 'Total loss': 0.880145785483447} | train loss {'Reaction outcome loss': 0.8163010129524816, 'Total loss': 0.8163010129524816}
2022-11-23 02:37:15,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:15,992 INFO:     Epoch: 16
2022-11-23 02:37:16,811 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8713418746536429, 'Total loss': 0.8713418746536429} | train loss {'Reaction outcome loss': 0.8133742262519175, 'Total loss': 0.8133742262519175}
2022-11-23 02:37:16,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:16,811 INFO:     Epoch: 17
2022-11-23 02:37:17,641 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8749056370420889, 'Total loss': 0.8749056370420889} | train loss {'Reaction outcome loss': 0.8195772998996319, 'Total loss': 0.8195772998996319}
2022-11-23 02:37:17,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:17,642 INFO:     Epoch: 18
2022-11-23 02:37:18,480 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.879644280130213, 'Total loss': 0.879644280130213} | train loss {'Reaction outcome loss': 0.8130950614088966, 'Total loss': 0.8130950614088966}
2022-11-23 02:37:18,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:18,481 INFO:     Epoch: 19
2022-11-23 02:37:19,306 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8726956227963621, 'Total loss': 0.8726956227963621} | train loss {'Reaction outcome loss': 0.8131533007948629, 'Total loss': 0.8131533007948629}
2022-11-23 02:37:19,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:19,306 INFO:     Epoch: 20
2022-11-23 02:37:20,132 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8818224614316766, 'Total loss': 0.8818224614316766} | train loss {'Reaction outcome loss': 0.8103015439644936, 'Total loss': 0.8103015439644936}
2022-11-23 02:37:20,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:20,132 INFO:     Epoch: 21
2022-11-23 02:37:20,944 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.868130545724522, 'Total loss': 0.868130545724522} | train loss {'Reaction outcome loss': 0.8180952209138102, 'Total loss': 0.8180952209138102}
2022-11-23 02:37:20,944 INFO:     Found new best model at epoch 21
2022-11-23 02:37:20,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:20,945 INFO:     Epoch: 22
2022-11-23 02:37:21,756 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.9286166700449857, 'Total loss': 0.9286166700449857} | train loss {'Reaction outcome loss': 0.8132623429259946, 'Total loss': 0.8132623429259946}
2022-11-23 02:37:21,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:21,756 INFO:     Epoch: 23
2022-11-23 02:37:22,587 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8726652237502012, 'Total loss': 0.8726652237502012} | train loss {'Reaction outcome loss': 0.8144700843239984, 'Total loss': 0.8144700843239984}
2022-11-23 02:37:22,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:22,587 INFO:     Epoch: 24
2022-11-23 02:37:23,436 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8597526983781294, 'Total loss': 0.8597526983781294} | train loss {'Reaction outcome loss': 0.8143274543746826, 'Total loss': 0.8143274543746826}
2022-11-23 02:37:23,436 INFO:     Found new best model at epoch 24
2022-11-23 02:37:23,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:23,437 INFO:     Epoch: 25
2022-11-23 02:37:24,238 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8821355727585879, 'Total loss': 0.8821355727585879} | train loss {'Reaction outcome loss': 0.8129293505222567, 'Total loss': 0.8129293505222567}
2022-11-23 02:37:24,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:24,239 INFO:     Epoch: 26
2022-11-23 02:37:25,079 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8983933979814703, 'Total loss': 0.8983933979814703} | train loss {'Reaction outcome loss': 0.8120282470218597, 'Total loss': 0.8120282470218597}
2022-11-23 02:37:25,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:25,079 INFO:     Epoch: 27
2022-11-23 02:37:25,889 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.870583561333743, 'Total loss': 0.870583561333743} | train loss {'Reaction outcome loss': 0.806801597077039, 'Total loss': 0.806801597077039}
2022-11-23 02:37:25,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:25,889 INFO:     Epoch: 28
2022-11-23 02:37:26,680 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.9083352156660773, 'Total loss': 0.9083352156660773} | train loss {'Reaction outcome loss': 0.8119646856381048, 'Total loss': 0.8119646856381048}
2022-11-23 02:37:26,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:26,680 INFO:     Epoch: 29
2022-11-23 02:37:27,518 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.9218525710431013, 'Total loss': 0.9218525710431013} | train loss {'Reaction outcome loss': 0.812646557246485, 'Total loss': 0.812646557246485}
2022-11-23 02:37:27,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:27,518 INFO:     Epoch: 30
2022-11-23 02:37:28,336 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8607781780037013, 'Total loss': 0.8607781780037013} | train loss {'Reaction outcome loss': 0.8094603165743812, 'Total loss': 0.8094603165743812}
2022-11-23 02:37:28,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:28,336 INFO:     Epoch: 31
2022-11-23 02:37:29,159 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8783846226605502, 'Total loss': 0.8783846226605502} | train loss {'Reaction outcome loss': 0.8089090899354027, 'Total loss': 0.8089090899354027}
2022-11-23 02:37:29,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:29,161 INFO:     Epoch: 32
2022-11-23 02:37:29,953 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.980121211572127, 'Total loss': 0.980121211572127} | train loss {'Reaction outcome loss': 0.8119201676980141, 'Total loss': 0.8119201676980141}
2022-11-23 02:37:29,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:29,954 INFO:     Epoch: 33
2022-11-23 02:37:30,761 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8935125375335867, 'Total loss': 0.8935125375335867} | train loss {'Reaction outcome loss': 0.8178941418807353, 'Total loss': 0.8178941418807353}
2022-11-23 02:37:30,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:30,761 INFO:     Epoch: 34
2022-11-23 02:37:31,613 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8751115629618819, 'Total loss': 0.8751115629618819} | train loss {'Reaction outcome loss': 0.8151303565790576, 'Total loss': 0.8151303565790576}
2022-11-23 02:37:31,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:31,613 INFO:     Epoch: 35
2022-11-23 02:37:32,436 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8711537955836817, 'Total loss': 0.8711537955836817} | train loss {'Reaction outcome loss': 0.8105335748724399, 'Total loss': 0.8105335748724399}
2022-11-23 02:37:32,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:32,436 INFO:     Epoch: 36
2022-11-23 02:37:33,225 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.869135629047047, 'Total loss': 0.869135629047047} | train loss {'Reaction outcome loss': 0.8175467896846033, 'Total loss': 0.8175467896846033}
2022-11-23 02:37:33,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:33,226 INFO:     Epoch: 37
2022-11-23 02:37:34,046 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8715814988721501, 'Total loss': 0.8715814988721501} | train loss {'Reaction outcome loss': 0.8099371919468525, 'Total loss': 0.8099371919468525}
2022-11-23 02:37:34,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:34,046 INFO:     Epoch: 38
2022-11-23 02:37:34,838 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8789453228766267, 'Total loss': 0.8789453228766267} | train loss {'Reaction outcome loss': 0.8061235835475307, 'Total loss': 0.8061235835475307}
2022-11-23 02:37:34,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:34,838 INFO:     Epoch: 39
2022-11-23 02:37:35,656 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8745654130523856, 'Total loss': 0.8745654130523856} | train loss {'Reaction outcome loss': 0.814031413485927, 'Total loss': 0.814031413485927}
2022-11-23 02:37:35,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:35,657 INFO:     Epoch: 40
2022-11-23 02:37:36,486 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8700910251248967, 'Total loss': 0.8700910251248967} | train loss {'Reaction outcome loss': 0.8158347023831259, 'Total loss': 0.8158347023831259}
2022-11-23 02:37:36,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:36,486 INFO:     Epoch: 41
2022-11-23 02:37:37,328 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8654299608685754, 'Total loss': 0.8654299608685754} | train loss {'Reaction outcome loss': 0.8102625490076119, 'Total loss': 0.8102625490076119}
2022-11-23 02:37:37,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:37,329 INFO:     Epoch: 42
2022-11-23 02:37:38,169 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8799773224375464, 'Total loss': 0.8799773224375464} | train loss {'Reaction outcome loss': 0.8097618112881337, 'Total loss': 0.8097618112881337}
2022-11-23 02:37:38,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:38,169 INFO:     Epoch: 43
2022-11-23 02:37:38,961 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.858871001411568, 'Total loss': 0.858871001411568} | train loss {'Reaction outcome loss': 0.8077914839790713, 'Total loss': 0.8077914839790713}
2022-11-23 02:37:38,961 INFO:     Found new best model at epoch 43
2022-11-23 02:37:38,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:38,962 INFO:     Epoch: 44
2022-11-23 02:37:39,738 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8652147982608188, 'Total loss': 0.8652147982608188} | train loss {'Reaction outcome loss': 0.8140804306153329, 'Total loss': 0.8140804306153329}
2022-11-23 02:37:39,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:39,738 INFO:     Epoch: 45
2022-11-23 02:37:40,549 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8718254390087995, 'Total loss': 0.8718254390087995} | train loss {'Reaction outcome loss': 0.8107898791711177, 'Total loss': 0.8107898791711177}
2022-11-23 02:37:40,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:40,550 INFO:     Epoch: 46
2022-11-23 02:37:41,343 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8644797239791263, 'Total loss': 0.8644797239791263} | train loss {'Reaction outcome loss': 0.8055713871914533, 'Total loss': 0.8055713871914533}
2022-11-23 02:37:41,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:41,344 INFO:     Epoch: 47
2022-11-23 02:37:42,173 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8702073815194044, 'Total loss': 0.8702073815194044} | train loss {'Reaction outcome loss': 0.8096087979933908, 'Total loss': 0.8096087979933908}
2022-11-23 02:37:42,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:42,174 INFO:     Epoch: 48
2022-11-23 02:37:42,995 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8691359893842177, 'Total loss': 0.8691359893842177} | train loss {'Reaction outcome loss': 0.8116509315948333, 'Total loss': 0.8116509315948333}
2022-11-23 02:37:42,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:42,995 INFO:     Epoch: 49
2022-11-23 02:37:43,842 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8682416135614569, 'Total loss': 0.8682416135614569} | train loss {'Reaction outcome loss': 0.8120803065117328, 'Total loss': 0.8120803065117328}
2022-11-23 02:37:43,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:43,843 INFO:     Epoch: 50
2022-11-23 02:37:44,710 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.864177870479497, 'Total loss': 0.864177870479497} | train loss {'Reaction outcome loss': 0.8082970413229158, 'Total loss': 0.8082970413229158}
2022-11-23 02:37:44,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:44,711 INFO:     Epoch: 51
2022-11-23 02:37:45,635 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8919343230399218, 'Total loss': 0.8919343230399218} | train loss {'Reaction outcome loss': 0.8117433417468302, 'Total loss': 0.8117433417468302}
2022-11-23 02:37:45,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:45,635 INFO:     Epoch: 52
2022-11-23 02:37:46,513 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8661935505541888, 'Total loss': 0.8661935505541888} | train loss {'Reaction outcome loss': 0.8132478477012727, 'Total loss': 0.8132478477012727}
2022-11-23 02:37:46,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:46,513 INFO:     Epoch: 53
2022-11-23 02:37:47,407 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8801896599206057, 'Total loss': 0.8801896599206057} | train loss {'Reaction outcome loss': 0.8148816539154898, 'Total loss': 0.8148816539154898}
2022-11-23 02:37:47,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:47,407 INFO:     Epoch: 54
2022-11-23 02:37:48,306 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8711268346418034, 'Total loss': 0.8711268346418034} | train loss {'Reaction outcome loss': 0.8110516584448276, 'Total loss': 0.8110516584448276}
2022-11-23 02:37:48,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:48,307 INFO:     Epoch: 55
2022-11-23 02:37:49,244 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8647925650531595, 'Total loss': 0.8647925650531595} | train loss {'Reaction outcome loss': 0.807805075280128, 'Total loss': 0.807805075280128}
2022-11-23 02:37:49,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:49,244 INFO:     Epoch: 56
2022-11-23 02:37:50,184 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8629209954630245, 'Total loss': 0.8629209954630245} | train loss {'Reaction outcome loss': 0.8119469860628727, 'Total loss': 0.8119469860628727}
2022-11-23 02:37:50,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:50,184 INFO:     Epoch: 57
2022-11-23 02:37:51,110 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8649740801616148, 'Total loss': 0.8649740801616148} | train loss {'Reaction outcome loss': 0.8042131090356458, 'Total loss': 0.8042131090356458}
2022-11-23 02:37:51,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:51,110 INFO:     Epoch: 58
2022-11-23 02:37:52,060 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8609578060832891, 'Total loss': 0.8609578060832891} | train loss {'Reaction outcome loss': 0.8077184609588115, 'Total loss': 0.8077184609588115}
2022-11-23 02:37:52,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:52,060 INFO:     Epoch: 59
2022-11-23 02:37:52,957 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.861134185032411, 'Total loss': 0.861134185032411} | train loss {'Reaction outcome loss': 0.8109356735742861, 'Total loss': 0.8109356735742861}
2022-11-23 02:37:52,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:52,957 INFO:     Epoch: 60
2022-11-23 02:37:53,814 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8729474734176289, 'Total loss': 0.8729474734176289} | train loss {'Reaction outcome loss': 0.8135189910329157, 'Total loss': 0.8135189910329157}
2022-11-23 02:37:53,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:53,814 INFO:     Epoch: 61
2022-11-23 02:37:54,707 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8620287423784082, 'Total loss': 0.8620287423784082} | train loss {'Reaction outcome loss': 0.8088783756379159, 'Total loss': 0.8088783756379159}
2022-11-23 02:37:54,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:54,708 INFO:     Epoch: 62
2022-11-23 02:37:55,594 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8656824874607, 'Total loss': 0.8656824874607} | train loss {'Reaction outcome loss': 0.8103096647368323, 'Total loss': 0.8103096647368323}
2022-11-23 02:37:55,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:55,594 INFO:     Epoch: 63
2022-11-23 02:37:56,519 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8630589998581193, 'Total loss': 0.8630589998581193} | train loss {'Reaction outcome loss': 0.8078409148560416, 'Total loss': 0.8078409148560416}
2022-11-23 02:37:56,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:56,520 INFO:     Epoch: 64
2022-11-23 02:37:57,460 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8619752824306488, 'Total loss': 0.8619752824306488} | train loss {'Reaction outcome loss': 0.8111127006911463, 'Total loss': 0.8111127006911463}
2022-11-23 02:37:57,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:57,460 INFO:     Epoch: 65
2022-11-23 02:37:58,360 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.9025492586872794, 'Total loss': 0.9025492586872794} | train loss {'Reaction outcome loss': 0.8121973080260139, 'Total loss': 0.8121973080260139}
2022-11-23 02:37:58,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:58,360 INFO:     Epoch: 66
2022-11-23 02:37:59,285 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8701406649567864, 'Total loss': 0.8701406649567864} | train loss {'Reaction outcome loss': 0.8087063848731979, 'Total loss': 0.8087063848731979}
2022-11-23 02:37:59,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:37:59,285 INFO:     Epoch: 67
2022-11-23 02:38:00,199 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8567851985042746, 'Total loss': 0.8567851985042746} | train loss {'Reaction outcome loss': 0.8091664885080629, 'Total loss': 0.8091664885080629}
2022-11-23 02:38:00,200 INFO:     Found new best model at epoch 67
2022-11-23 02:38:00,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:00,201 INFO:     Epoch: 68
2022-11-23 02:38:01,060 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8692908950827338, 'Total loss': 0.8692908950827338} | train loss {'Reaction outcome loss': 0.8113727272758561, 'Total loss': 0.8113727272758561}
2022-11-23 02:38:01,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:01,061 INFO:     Epoch: 69
2022-11-23 02:38:02,024 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8712213703177192, 'Total loss': 0.8712213703177192} | train loss {'Reaction outcome loss': 0.8071041130010159, 'Total loss': 0.8071041130010159}
2022-11-23 02:38:02,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:02,024 INFO:     Epoch: 70
2022-11-23 02:38:02,975 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8539700812914155, 'Total loss': 0.8539700812914155} | train loss {'Reaction outcome loss': 0.8041678317371876, 'Total loss': 0.8041678317371876}
2022-11-23 02:38:02,975 INFO:     Found new best model at epoch 70
2022-11-23 02:38:02,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:02,976 INFO:     Epoch: 71
2022-11-23 02:38:03,888 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8618210764093832, 'Total loss': 0.8618210764093832} | train loss {'Reaction outcome loss': 0.8123954690752491, 'Total loss': 0.8123954690752491}
2022-11-23 02:38:03,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:03,888 INFO:     Epoch: 72
2022-11-23 02:38:04,808 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8744305588982322, 'Total loss': 0.8744305588982322} | train loss {'Reaction outcome loss': 0.8083693442806121, 'Total loss': 0.8083693442806121}
2022-11-23 02:38:04,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:04,809 INFO:     Epoch: 73
2022-11-23 02:38:05,770 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8895491632548246, 'Total loss': 0.8895491632548246} | train loss {'Reaction outcome loss': 0.8077321450316137, 'Total loss': 0.8077321450316137}
2022-11-23 02:38:05,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:05,770 INFO:     Epoch: 74
2022-11-23 02:38:06,710 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8786978220397775, 'Total loss': 0.8786978220397775} | train loss {'Reaction outcome loss': 0.8152562388849836, 'Total loss': 0.8152562388849836}
2022-11-23 02:38:06,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:06,711 INFO:     Epoch: 75
2022-11-23 02:38:07,655 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.865365591916171, 'Total loss': 0.865365591916171} | train loss {'Reaction outcome loss': 0.8078017380208738, 'Total loss': 0.8078017380208738}
2022-11-23 02:38:07,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:07,656 INFO:     Epoch: 76
2022-11-23 02:38:08,590 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8589536581527103, 'Total loss': 0.8589536581527103} | train loss {'Reaction outcome loss': 0.8024614056752574, 'Total loss': 0.8024614056752574}
2022-11-23 02:38:08,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:08,591 INFO:     Epoch: 77
2022-11-23 02:38:09,450 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8662687905810096, 'Total loss': 0.8662687905810096} | train loss {'Reaction outcome loss': 0.8134849691583265, 'Total loss': 0.8134849691583265}
2022-11-23 02:38:09,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:09,451 INFO:     Epoch: 78
2022-11-23 02:38:10,310 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8771945996717974, 'Total loss': 0.8771945996717974} | train loss {'Reaction outcome loss': 0.8120664514360889, 'Total loss': 0.8120664514360889}
2022-11-23 02:38:10,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:10,310 INFO:     Epoch: 79
2022-11-23 02:38:11,165 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8658892471681942, 'Total loss': 0.8658892471681942} | train loss {'Reaction outcome loss': 0.8066018145651587, 'Total loss': 0.8066018145651587}
2022-11-23 02:38:11,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:11,165 INFO:     Epoch: 80
2022-11-23 02:38:12,074 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8632857237349857, 'Total loss': 0.8632857237349857} | train loss {'Reaction outcome loss': 0.8044275589767964, 'Total loss': 0.8044275589767964}
2022-11-23 02:38:12,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:12,075 INFO:     Epoch: 81
2022-11-23 02:38:12,930 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8738169053738768, 'Total loss': 0.8738169053738768} | train loss {'Reaction outcome loss': 0.8079744184449795, 'Total loss': 0.8079744184449795}
2022-11-23 02:38:12,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:12,931 INFO:     Epoch: 82
2022-11-23 02:38:13,813 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8654814199967817, 'Total loss': 0.8654814199967817} | train loss {'Reaction outcome loss': 0.809718131658531, 'Total loss': 0.809718131658531}
2022-11-23 02:38:13,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:13,813 INFO:     Epoch: 83
2022-11-23 02:38:14,717 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8661313314329494, 'Total loss': 0.8661313314329494} | train loss {'Reaction outcome loss': 0.8070558638822648, 'Total loss': 0.8070558638822648}
2022-11-23 02:38:14,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:14,717 INFO:     Epoch: 84
2022-11-23 02:38:15,613 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8737309967929666, 'Total loss': 0.8737309967929666} | train loss {'Reaction outcome loss': 0.8087767689458786, 'Total loss': 0.8087767689458786}
2022-11-23 02:38:15,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:15,614 INFO:     Epoch: 85
2022-11-23 02:38:16,447 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8759633790362965, 'Total loss': 0.8759633790362965} | train loss {'Reaction outcome loss': 0.8080730789130733, 'Total loss': 0.8080730789130733}
2022-11-23 02:38:16,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:16,447 INFO:     Epoch: 86
2022-11-23 02:38:17,365 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8727871098301627, 'Total loss': 0.8727871098301627} | train loss {'Reaction outcome loss': 0.8110655441639885, 'Total loss': 0.8110655441639885}
2022-11-23 02:38:17,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:17,365 INFO:     Epoch: 87
2022-11-23 02:38:18,255 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8582245890389789, 'Total loss': 0.8582245890389789} | train loss {'Reaction outcome loss': 0.8091464328669733, 'Total loss': 0.8091464328669733}
2022-11-23 02:38:18,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:18,255 INFO:     Epoch: 88
2022-11-23 02:38:19,118 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8948895910924132, 'Total loss': 0.8948895910924132} | train loss {'Reaction outcome loss': 0.8083384867397047, 'Total loss': 0.8083384867397047}
2022-11-23 02:38:19,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:19,118 INFO:     Epoch: 89
2022-11-23 02:38:19,977 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8711105002598329, 'Total loss': 0.8711105002598329} | train loss {'Reaction outcome loss': 0.8099782173071177, 'Total loss': 0.8099782173071177}
2022-11-23 02:38:19,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:19,978 INFO:     Epoch: 90
2022-11-23 02:38:20,794 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8677503561431711, 'Total loss': 0.8677503561431711} | train loss {'Reaction outcome loss': 0.8144426356640554, 'Total loss': 0.8144426356640554}
2022-11-23 02:38:20,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:20,795 INFO:     Epoch: 91
2022-11-23 02:38:21,713 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8717349137772213, 'Total loss': 0.8717349137772213} | train loss {'Reaction outcome loss': 0.8108221645797452, 'Total loss': 0.8108221645797452}
2022-11-23 02:38:21,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:21,714 INFO:     Epoch: 92
2022-11-23 02:38:22,571 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8626533922823992, 'Total loss': 0.8626533922823992} | train loss {'Reaction outcome loss': 0.8046205631427227, 'Total loss': 0.8046205631427227}
2022-11-23 02:38:22,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:22,572 INFO:     Epoch: 93
2022-11-23 02:38:23,467 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.879808943380009, 'Total loss': 0.879808943380009} | train loss {'Reaction outcome loss': 0.8087214170204055, 'Total loss': 0.8087214170204055}
2022-11-23 02:38:23,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:23,467 INFO:     Epoch: 94
2022-11-23 02:38:24,325 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8831997364759445, 'Total loss': 0.8831997364759445} | train loss {'Reaction outcome loss': 0.8066285739262258, 'Total loss': 0.8066285739262258}
2022-11-23 02:38:24,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:24,325 INFO:     Epoch: 95
2022-11-23 02:38:25,157 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8645866702903401, 'Total loss': 0.8645866702903401} | train loss {'Reaction outcome loss': 0.8063225513023715, 'Total loss': 0.8063225513023715}
2022-11-23 02:38:25,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:25,157 INFO:     Epoch: 96
2022-11-23 02:38:25,993 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8691263727166436, 'Total loss': 0.8691263727166436} | train loss {'Reaction outcome loss': 0.8130666656840232, 'Total loss': 0.8130666656840232}
2022-11-23 02:38:25,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:25,994 INFO:     Epoch: 97
2022-11-23 02:38:26,880 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8756223449652846, 'Total loss': 0.8756223449652846} | train loss {'Reaction outcome loss': 0.8069087468808697, 'Total loss': 0.8069087468808697}
2022-11-23 02:38:26,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:26,880 INFO:     Epoch: 98
2022-11-23 02:38:27,768 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8739707077091391, 'Total loss': 0.8739707077091391} | train loss {'Reaction outcome loss': 0.8097207249412613, 'Total loss': 0.8097207249412613}
2022-11-23 02:38:27,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:27,769 INFO:     Epoch: 99
2022-11-23 02:38:28,642 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8731263252821836, 'Total loss': 0.8731263252821836} | train loss {'Reaction outcome loss': 0.8086900295269105, 'Total loss': 0.8086900295269105}
2022-11-23 02:38:28,642 INFO:     Best model found after epoch 71 of 100.
2022-11-23 02:38:28,642 INFO:   Done with stage: TRAINING
2022-11-23 02:38:28,643 INFO:   Starting stage: EVALUATION
2022-11-23 02:38:28,764 INFO:   Done with stage: EVALUATION
2022-11-23 02:38:28,764 INFO:   Leaving out SEQ value Fold_8
2022-11-23 02:38:28,778 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:38:28,778 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:38:29,462 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:38:29,462 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:38:29,539 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:38:29,539 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:38:29,539 INFO:     No hyperparam tuning for this model
2022-11-23 02:38:29,539 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:38:29,539 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:38:29,540 INFO:     None feature selector for col prot
2022-11-23 02:38:29,541 INFO:     None feature selector for col prot
2022-11-23 02:38:29,541 INFO:     None feature selector for col prot
2022-11-23 02:38:29,541 INFO:     None feature selector for col chem
2022-11-23 02:38:29,541 INFO:     None feature selector for col chem
2022-11-23 02:38:29,541 INFO:     None feature selector for col chem
2022-11-23 02:38:29,542 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:38:29,542 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:38:29,543 INFO:     Number of params in model 168571
2022-11-23 02:38:29,547 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:38:29,547 INFO:   Starting stage: TRAINING
2022-11-23 02:38:29,609 INFO:     Val loss before train {'Reaction outcome loss': 1.0820041339505801, 'Total loss': 1.0820041339505801}
2022-11-23 02:38:29,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:29,609 INFO:     Epoch: 0
2022-11-23 02:38:30,481 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8575429760596969, 'Total loss': 0.8575429760596969} | train loss {'Reaction outcome loss': 0.8602614669423354, 'Total loss': 0.8602614669423354}
2022-11-23 02:38:30,481 INFO:     Found new best model at epoch 0
2022-11-23 02:38:30,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:30,482 INFO:     Epoch: 1
2022-11-23 02:38:31,355 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8619767129421234, 'Total loss': 0.8619767129421234} | train loss {'Reaction outcome loss': 0.8343795374156493, 'Total loss': 0.8343795374156493}
2022-11-23 02:38:31,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:31,356 INFO:     Epoch: 2
2022-11-23 02:38:32,240 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8616425747221167, 'Total loss': 0.8616425747221167} | train loss {'Reaction outcome loss': 0.8274281984157408, 'Total loss': 0.8274281984157408}
2022-11-23 02:38:32,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:32,240 INFO:     Epoch: 3
2022-11-23 02:38:33,133 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8648155778646469, 'Total loss': 0.8648155778646469} | train loss {'Reaction outcome loss': 0.8274993500728839, 'Total loss': 0.8274993500728839}
2022-11-23 02:38:33,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:33,134 INFO:     Epoch: 4
2022-11-23 02:38:33,987 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8754693770950491, 'Total loss': 0.8754693770950491} | train loss {'Reaction outcome loss': 0.8272357562534239, 'Total loss': 0.8272357562534239}
2022-11-23 02:38:33,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:33,987 INFO:     Epoch: 5
2022-11-23 02:38:34,867 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8423948281190612, 'Total loss': 0.8423948281190612} | train loss {'Reaction outcome loss': 0.8234630826755092, 'Total loss': 0.8234630826755092}
2022-11-23 02:38:34,867 INFO:     Found new best model at epoch 5
2022-11-23 02:38:34,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:34,868 INFO:     Epoch: 6
2022-11-23 02:38:35,742 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8610591901974245, 'Total loss': 0.8610591901974245} | train loss {'Reaction outcome loss': 0.8170649779711657, 'Total loss': 0.8170649779711657}
2022-11-23 02:38:35,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:35,742 INFO:     Epoch: 7
2022-11-23 02:38:36,583 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8412529142065481, 'Total loss': 0.8412529142065481} | train loss {'Reaction outcome loss': 0.8130761360832555, 'Total loss': 0.8130761360832555}
2022-11-23 02:38:36,583 INFO:     Found new best model at epoch 7
2022-11-23 02:38:36,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:36,584 INFO:     Epoch: 8
2022-11-23 02:38:37,465 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8589164316654205, 'Total loss': 0.8589164316654205} | train loss {'Reaction outcome loss': 0.8156355931932627, 'Total loss': 0.8156355931932627}
2022-11-23 02:38:37,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:37,467 INFO:     Epoch: 9
2022-11-23 02:38:38,373 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8897362500429153, 'Total loss': 0.8897362500429153} | train loss {'Reaction outcome loss': 0.8159826744181907, 'Total loss': 0.8159826744181907}
2022-11-23 02:38:38,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:38,374 INFO:     Epoch: 10
2022-11-23 02:38:39,238 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8589116788723252, 'Total loss': 0.8589116788723252} | train loss {'Reaction outcome loss': 0.8074173089192223, 'Total loss': 0.8074173089192223}
2022-11-23 02:38:39,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:39,238 INFO:     Epoch: 11
2022-11-23 02:38:40,072 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8545733419331637, 'Total loss': 0.8545733419331637} | train loss {'Reaction outcome loss': 0.8090862503901184, 'Total loss': 0.8090862503901184}
2022-11-23 02:38:40,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:40,073 INFO:     Epoch: 12
2022-11-23 02:38:40,890 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8570811335336078, 'Total loss': 0.8570811335336078} | train loss {'Reaction outcome loss': 0.808266326724759, 'Total loss': 0.808266326724759}
2022-11-23 02:38:40,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:40,890 INFO:     Epoch: 13
2022-11-23 02:38:41,692 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8409121747721325, 'Total loss': 0.8409121747721325} | train loss {'Reaction outcome loss': 0.8110608533326431, 'Total loss': 0.8110608533326431}
2022-11-23 02:38:41,692 INFO:     Found new best model at epoch 13
2022-11-23 02:38:41,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:41,693 INFO:     Epoch: 14
2022-11-23 02:38:42,568 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8765763775868849, 'Total loss': 0.8765763775868849} | train loss {'Reaction outcome loss': 0.8032460043184187, 'Total loss': 0.8032460043184187}
2022-11-23 02:38:42,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:42,568 INFO:     Epoch: 15
2022-11-23 02:38:43,417 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8768640844659372, 'Total loss': 0.8768640844659372} | train loss {'Reaction outcome loss': 0.8093882429334316, 'Total loss': 0.8093882429334316}
2022-11-23 02:38:43,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:43,417 INFO:     Epoch: 16
2022-11-23 02:38:44,263 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.821403367952867, 'Total loss': 0.821403367952867} | train loss {'Reaction outcome loss': 0.8029558508532492, 'Total loss': 0.8029558508532492}
2022-11-23 02:38:44,263 INFO:     Found new best model at epoch 16
2022-11-23 02:38:44,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:44,264 INFO:     Epoch: 17
2022-11-23 02:38:45,150 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8739064146171917, 'Total loss': 0.8739064146171917} | train loss {'Reaction outcome loss': 0.8053123335908299, 'Total loss': 0.8053123335908299}
2022-11-23 02:38:45,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:45,151 INFO:     Epoch: 18
2022-11-23 02:38:46,000 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8415273008021441, 'Total loss': 0.8415273008021441} | train loss {'Reaction outcome loss': 0.8052064280519601, 'Total loss': 0.8052064280519601}
2022-11-23 02:38:46,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:46,001 INFO:     Epoch: 19
2022-11-23 02:38:46,875 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8421384272250262, 'Total loss': 0.8421384272250262} | train loss {'Reaction outcome loss': 0.8038385224487135, 'Total loss': 0.8038385224487135}
2022-11-23 02:38:46,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:46,875 INFO:     Epoch: 20
2022-11-23 02:38:47,718 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8491817861795425, 'Total loss': 0.8491817861795425} | train loss {'Reaction outcome loss': 0.8079626298385111, 'Total loss': 0.8079626298385111}
2022-11-23 02:38:47,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:47,719 INFO:     Epoch: 21
2022-11-23 02:38:48,636 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8805516416376288, 'Total loss': 0.8805516416376288} | train loss {'Reaction outcome loss': 0.8047620546721254, 'Total loss': 0.8047620546721254}
2022-11-23 02:38:48,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:48,637 INFO:     Epoch: 22
2022-11-23 02:38:49,493 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8377680961381305, 'Total loss': 0.8377680961381305} | train loss {'Reaction outcome loss': 0.8014396990117757, 'Total loss': 0.8014396990117757}
2022-11-23 02:38:49,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:49,494 INFO:     Epoch: 23
2022-11-23 02:38:50,328 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8399383100596342, 'Total loss': 0.8399383100596342} | train loss {'Reaction outcome loss': 0.8058446291004598, 'Total loss': 0.8058446291004598}
2022-11-23 02:38:50,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:50,328 INFO:     Epoch: 24
2022-11-23 02:38:51,130 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8435091931711544, 'Total loss': 0.8435091931711544} | train loss {'Reaction outcome loss': 0.8105049235859381, 'Total loss': 0.8105049235859381}
2022-11-23 02:38:51,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:51,130 INFO:     Epoch: 25
2022-11-23 02:38:51,953 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8254232928156853, 'Total loss': 0.8254232928156853} | train loss {'Reaction outcome loss': 0.8136111208301807, 'Total loss': 0.8136111208301807}
2022-11-23 02:38:51,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:51,953 INFO:     Epoch: 26
2022-11-23 02:38:52,749 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8536175367507067, 'Total loss': 0.8536175367507067} | train loss {'Reaction outcome loss': 0.8043782841338802, 'Total loss': 0.8043782841338802}
2022-11-23 02:38:52,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:52,749 INFO:     Epoch: 27
2022-11-23 02:38:53,591 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8641949770125475, 'Total loss': 0.8641949770125475} | train loss {'Reaction outcome loss': 0.8077273853877296, 'Total loss': 0.8077273853877296}
2022-11-23 02:38:53,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:53,591 INFO:     Epoch: 28
2022-11-23 02:38:54,387 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8886599256233736, 'Total loss': 0.8886599256233736} | train loss {'Reaction outcome loss': 0.8330536149291374, 'Total loss': 0.8330536149291374}
2022-11-23 02:38:54,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:54,387 INFO:     Epoch: 29
2022-11-23 02:38:55,245 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8484690230001103, 'Total loss': 0.8484690230001103} | train loss {'Reaction outcome loss': 0.8182398036182651, 'Total loss': 0.8182398036182651}
2022-11-23 02:38:55,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:55,245 INFO:     Epoch: 30
2022-11-23 02:38:56,054 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8483937877145681, 'Total loss': 0.8483937877145681} | train loss {'Reaction outcome loss': 0.8196880057273124, 'Total loss': 0.8196880057273124}
2022-11-23 02:38:56,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:56,055 INFO:     Epoch: 31
2022-11-23 02:38:56,852 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8689639771526511, 'Total loss': 0.8689639771526511} | train loss {'Reaction outcome loss': 0.8040662532151952, 'Total loss': 0.8040662532151952}
2022-11-23 02:38:56,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:56,852 INFO:     Epoch: 32
2022-11-23 02:38:57,661 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8978449329733849, 'Total loss': 0.8978449329733849} | train loss {'Reaction outcome loss': 0.8138142370501993, 'Total loss': 0.8138142370501993}
2022-11-23 02:38:57,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:57,661 INFO:     Epoch: 33
2022-11-23 02:38:58,469 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8290443853898481, 'Total loss': 0.8290443853898481} | train loss {'Reaction outcome loss': 0.8102579043522055, 'Total loss': 0.8102579043522055}
2022-11-23 02:38:58,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:58,470 INFO:     Epoch: 34
2022-11-23 02:38:59,298 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8400979705832221, 'Total loss': 0.8400979705832221} | train loss {'Reaction outcome loss': 0.8093208566850979, 'Total loss': 0.8093208566850979}
2022-11-23 02:38:59,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:38:59,298 INFO:     Epoch: 35
2022-11-23 02:39:00,087 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8257056325674057, 'Total loss': 0.8257056325674057} | train loss {'Reaction outcome loss': 0.810704490192506, 'Total loss': 0.810704490192506}
2022-11-23 02:39:00,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:00,088 INFO:     Epoch: 36
2022-11-23 02:39:00,867 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.851692380552942, 'Total loss': 0.851692380552942} | train loss {'Reaction outcome loss': 0.8172729318199853, 'Total loss': 0.8172729318199853}
2022-11-23 02:39:00,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:00,867 INFO:     Epoch: 37
2022-11-23 02:39:01,687 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8530647063797171, 'Total loss': 0.8530647063797171} | train loss {'Reaction outcome loss': 0.8158918498498708, 'Total loss': 0.8158918498498708}
2022-11-23 02:39:01,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:01,687 INFO:     Epoch: 38
2022-11-23 02:39:02,469 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8295469676906412, 'Total loss': 0.8295469676906412} | train loss {'Reaction outcome loss': 0.8059738146872656, 'Total loss': 0.8059738146872656}
2022-11-23 02:39:02,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:02,470 INFO:     Epoch: 39
2022-11-23 02:39:03,327 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8561393015763976, 'Total loss': 0.8561393015763976} | train loss {'Reaction outcome loss': 0.8045644293188566, 'Total loss': 0.8045644293188566}
2022-11-23 02:39:03,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:03,327 INFO:     Epoch: 40
2022-11-23 02:39:04,120 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.825280411676927, 'Total loss': 0.825280411676927} | train loss {'Reaction outcome loss': 0.8115879684566003, 'Total loss': 0.8115879684566003}
2022-11-23 02:39:04,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:04,120 INFO:     Epoch: 41
2022-11-23 02:39:04,930 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8355108729817651, 'Total loss': 0.8355108729817651} | train loss {'Reaction outcome loss': 0.8054950094898703, 'Total loss': 0.8054950094898703}
2022-11-23 02:39:04,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:04,930 INFO:     Epoch: 42
2022-11-23 02:39:05,743 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8533676144751635, 'Total loss': 0.8533676144751635} | train loss {'Reaction outcome loss': 0.8145839991839791, 'Total loss': 0.8145839991839791}
2022-11-23 02:39:05,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:05,743 INFO:     Epoch: 43
2022-11-23 02:39:06,560 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8399354449727319, 'Total loss': 0.8399354449727319} | train loss {'Reaction outcome loss': 0.8009329136566594, 'Total loss': 0.8009329136566594}
2022-11-23 02:39:06,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:06,560 INFO:     Epoch: 44
2022-11-23 02:39:07,360 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8713314858349887, 'Total loss': 0.8713314858349887} | train loss {'Reaction outcome loss': 0.8022681998337812, 'Total loss': 0.8022681998337812}
2022-11-23 02:39:07,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:07,360 INFO:     Epoch: 45
2022-11-23 02:39:08,159 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.843340968543833, 'Total loss': 0.843340968543833} | train loss {'Reaction outcome loss': 0.8123265609808779, 'Total loss': 0.8123265609808779}
2022-11-23 02:39:08,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:08,159 INFO:     Epoch: 46
2022-11-23 02:39:09,041 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8395791460167278, 'Total loss': 0.8395791460167278} | train loss {'Reaction outcome loss': 0.7996796140907264, 'Total loss': 0.7996796140907264}
2022-11-23 02:39:09,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:09,042 INFO:     Epoch: 47
2022-11-23 02:39:09,865 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8274228329008276, 'Total loss': 0.8274228329008276} | train loss {'Reaction outcome loss': 0.8018996150870072, 'Total loss': 0.8018996150870072}
2022-11-23 02:39:09,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:09,865 INFO:     Epoch: 48
2022-11-23 02:39:10,665 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8537584800611843, 'Total loss': 0.8537584800611843} | train loss {'Reaction outcome loss': 0.8035947633115387, 'Total loss': 0.8035947633115387}
2022-11-23 02:39:10,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:10,665 INFO:     Epoch: 49
2022-11-23 02:39:11,467 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8362197577953339, 'Total loss': 0.8362197577953339} | train loss {'Reaction outcome loss': 0.806489856619584, 'Total loss': 0.806489856619584}
2022-11-23 02:39:11,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:11,467 INFO:     Epoch: 50
2022-11-23 02:39:12,296 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.832820057191632, 'Total loss': 0.832820057191632} | train loss {'Reaction outcome loss': 0.8083216274074214, 'Total loss': 0.8083216274074214}
2022-11-23 02:39:12,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:12,297 INFO:     Epoch: 51
2022-11-23 02:39:13,084 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8287097703326832, 'Total loss': 0.8287097703326832} | train loss {'Reaction outcome loss': 0.8020074374762624, 'Total loss': 0.8020074374762624}
2022-11-23 02:39:13,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:13,084 INFO:     Epoch: 52
2022-11-23 02:39:13,841 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8474712283773855, 'Total loss': 0.8474712283773855} | train loss {'Reaction outcome loss': 0.8035631213593579, 'Total loss': 0.8035631213593579}
2022-11-23 02:39:13,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:13,841 INFO:     Epoch: 53
2022-11-23 02:39:14,662 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.831210044297305, 'Total loss': 0.831210044297305} | train loss {'Reaction outcome loss': 0.8026522261652387, 'Total loss': 0.8026522261652387}
2022-11-23 02:39:14,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:14,662 INFO:     Epoch: 54
2022-11-23 02:39:15,516 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8434911485422741, 'Total loss': 0.8434911485422741} | train loss {'Reaction outcome loss': 0.8016982085490034, 'Total loss': 0.8016982085490034}
2022-11-23 02:39:15,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:15,516 INFO:     Epoch: 55
2022-11-23 02:39:16,312 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8413913656364788, 'Total loss': 0.8413913656364788} | train loss {'Reaction outcome loss': 0.8017341842052907, 'Total loss': 0.8017341842052907}
2022-11-23 02:39:16,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:16,312 INFO:     Epoch: 56
2022-11-23 02:39:17,140 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8628331165422093, 'Total loss': 0.8628331165422093} | train loss {'Reaction outcome loss': 0.8011753328657343, 'Total loss': 0.8011753328657343}
2022-11-23 02:39:17,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:17,140 INFO:     Epoch: 57
2022-11-23 02:39:17,960 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8432052887298844, 'Total loss': 0.8432052887298844} | train loss {'Reaction outcome loss': 0.804012527711961, 'Total loss': 0.804012527711961}
2022-11-23 02:39:17,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:17,961 INFO:     Epoch: 58
2022-11-23 02:39:18,812 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8390313251452013, 'Total loss': 0.8390313251452013} | train loss {'Reaction outcome loss': 0.8063562348304008, 'Total loss': 0.8063562348304008}
2022-11-23 02:39:18,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:18,812 INFO:     Epoch: 59
2022-11-23 02:39:19,562 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8604029525410045, 'Total loss': 0.8604029525410045} | train loss {'Reaction outcome loss': 0.8000375847464148, 'Total loss': 0.8000375847464148}
2022-11-23 02:39:19,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:19,562 INFO:     Epoch: 60
2022-11-23 02:39:20,370 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8362087607383728, 'Total loss': 0.8362087607383728} | train loss {'Reaction outcome loss': 0.8057802272470374, 'Total loss': 0.8057802272470374}
2022-11-23 02:39:20,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:20,370 INFO:     Epoch: 61
2022-11-23 02:39:21,191 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8446771455082026, 'Total loss': 0.8446771455082026} | train loss {'Reaction outcome loss': 0.8025772809258357, 'Total loss': 0.8025772809258357}
2022-11-23 02:39:21,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:21,192 INFO:     Epoch: 62
2022-11-23 02:39:21,994 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8432515798644586, 'Total loss': 0.8432515798644586} | train loss {'Reaction outcome loss': 0.7993912195809457, 'Total loss': 0.7993912195809457}
2022-11-23 02:39:21,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:21,994 INFO:     Epoch: 63
2022-11-23 02:39:22,766 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8512523174285889, 'Total loss': 0.8512523174285889} | train loss {'Reaction outcome loss': 0.8007295877344696, 'Total loss': 0.8007295877344696}
2022-11-23 02:39:22,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:22,766 INFO:     Epoch: 64
2022-11-23 02:39:23,590 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8412705111232671, 'Total loss': 0.8412705111232671} | train loss {'Reaction outcome loss': 0.7976389081945062, 'Total loss': 0.7976389081945062}
2022-11-23 02:39:23,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:23,591 INFO:     Epoch: 65
2022-11-23 02:39:24,389 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.9002847468311136, 'Total loss': 0.9002847468311136} | train loss {'Reaction outcome loss': 0.7996283020326483, 'Total loss': 0.7996283020326483}
2022-11-23 02:39:24,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:24,389 INFO:     Epoch: 66
2022-11-23 02:39:25,195 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8557786352255128, 'Total loss': 0.8557786352255128} | train loss {'Reaction outcome loss': 0.8047696454714426, 'Total loss': 0.8047696454714426}
2022-11-23 02:39:25,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:25,196 INFO:     Epoch: 67
2022-11-23 02:39:25,983 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8661316897381436, 'Total loss': 0.8661316897381436} | train loss {'Reaction outcome loss': 0.802312321749776, 'Total loss': 0.802312321749776}
2022-11-23 02:39:25,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:25,983 INFO:     Epoch: 68
2022-11-23 02:39:26,788 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8264056274836714, 'Total loss': 0.8264056274836714} | train loss {'Reaction outcome loss': 0.8018589092772982, 'Total loss': 0.8018589092772982}
2022-11-23 02:39:26,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:26,788 INFO:     Epoch: 69
2022-11-23 02:39:27,589 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8585070859302174, 'Total loss': 0.8585070859302174} | train loss {'Reaction outcome loss': 0.7996079217084506, 'Total loss': 0.7996079217084506}
2022-11-23 02:39:27,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:27,589 INFO:     Epoch: 70
2022-11-23 02:39:28,378 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8643655160611327, 'Total loss': 0.8643655160611327} | train loss {'Reaction outcome loss': 0.8167032851622655, 'Total loss': 0.8167032851622655}
2022-11-23 02:39:28,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:28,378 INFO:     Epoch: 71
2022-11-23 02:39:29,217 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8358365554701198, 'Total loss': 0.8358365554701198} | train loss {'Reaction outcome loss': 0.8048412056587003, 'Total loss': 0.8048412056587003}
2022-11-23 02:39:29,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:29,217 INFO:     Epoch: 72
2022-11-23 02:39:30,014 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.843164021318609, 'Total loss': 0.843164021318609} | train loss {'Reaction outcome loss': 0.8003561926274164, 'Total loss': 0.8003561926274164}
2022-11-23 02:39:30,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:30,015 INFO:     Epoch: 73
2022-11-23 02:39:30,833 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8500557338649576, 'Total loss': 0.8500557338649576} | train loss {'Reaction outcome loss': 0.7960941972218545, 'Total loss': 0.7960941972218545}
2022-11-23 02:39:30,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:30,833 INFO:     Epoch: 74
2022-11-23 02:39:31,617 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8380694348703731, 'Total loss': 0.8380694348703731} | train loss {'Reaction outcome loss': 0.7995504945637244, 'Total loss': 0.7995504945637244}
2022-11-23 02:39:31,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:31,617 INFO:     Epoch: 75
2022-11-23 02:39:32,408 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.9336062832312151, 'Total loss': 0.9336062832312151} | train loss {'Reaction outcome loss': 0.8001201921387723, 'Total loss': 0.8001201921387723}
2022-11-23 02:39:32,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:32,408 INFO:     Epoch: 76
2022-11-23 02:39:33,253 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8540701419115067, 'Total loss': 0.8540701419115067} | train loss {'Reaction outcome loss': 0.8102771758067946, 'Total loss': 0.8102771758067946}
2022-11-23 02:39:33,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:33,254 INFO:     Epoch: 77
2022-11-23 02:39:34,062 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8500338941812515, 'Total loss': 0.8500338941812515} | train loss {'Reaction outcome loss': 0.805112757241195, 'Total loss': 0.805112757241195}
2022-11-23 02:39:34,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:34,064 INFO:     Epoch: 78
2022-11-23 02:39:34,891 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8325639163905924, 'Total loss': 0.8325639163905924} | train loss {'Reaction outcome loss': 0.8052249227458166, 'Total loss': 0.8052249227458166}
2022-11-23 02:39:34,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:34,892 INFO:     Epoch: 79
2022-11-23 02:39:35,677 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8296859013763341, 'Total loss': 0.8296859013763341} | train loss {'Reaction outcome loss': 0.8133082597361885, 'Total loss': 0.8133082597361885}
2022-11-23 02:39:35,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:35,677 INFO:     Epoch: 80
2022-11-23 02:39:36,496 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8230608349496668, 'Total loss': 0.8230608349496668} | train loss {'Reaction outcome loss': 0.8029584169146503, 'Total loss': 0.8029584169146503}
2022-11-23 02:39:36,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:36,497 INFO:     Epoch: 81
2022-11-23 02:39:37,298 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8483389453454451, 'Total loss': 0.8483389453454451} | train loss {'Reaction outcome loss': 0.8004694883466551, 'Total loss': 0.8004694883466551}
2022-11-23 02:39:37,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:37,298 INFO:     Epoch: 82
2022-11-23 02:39:38,122 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8290706866166808, 'Total loss': 0.8290706866166808} | train loss {'Reaction outcome loss': 0.8026947976365263, 'Total loss': 0.8026947976365263}
2022-11-23 02:39:38,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:38,122 INFO:     Epoch: 83
2022-11-23 02:39:38,910 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.834302925250747, 'Total loss': 0.834302925250747} | train loss {'Reaction outcome loss': 0.8012151566111607, 'Total loss': 0.8012151566111607}
2022-11-23 02:39:38,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:38,910 INFO:     Epoch: 84
2022-11-23 02:39:39,692 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8402040045369755, 'Total loss': 0.8402040045369755} | train loss {'Reaction outcome loss': 0.8070689518200723, 'Total loss': 0.8070689518200723}
2022-11-23 02:39:39,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:39,693 INFO:     Epoch: 85
2022-11-23 02:39:40,471 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.83519881489602, 'Total loss': 0.83519881489602} | train loss {'Reaction outcome loss': 0.8011118824243063, 'Total loss': 0.8011118824243063}
2022-11-23 02:39:40,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:40,472 INFO:     Epoch: 86
2022-11-23 02:39:41,285 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8315770544789054, 'Total loss': 0.8315770544789054} | train loss {'Reaction outcome loss': 0.7967615169491845, 'Total loss': 0.7967615169491845}
2022-11-23 02:39:41,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:41,285 INFO:     Epoch: 87
2022-11-23 02:39:42,059 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8538930063897913, 'Total loss': 0.8538930063897913} | train loss {'Reaction outcome loss': 0.8095269492763256, 'Total loss': 0.8095269492763256}
2022-11-23 02:39:42,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:42,059 INFO:     Epoch: 88
2022-11-23 02:39:42,830 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.841255246238275, 'Total loss': 0.841255246238275} | train loss {'Reaction outcome loss': 0.8019426993512915, 'Total loss': 0.8019426993512915}
2022-11-23 02:39:42,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:42,830 INFO:     Epoch: 89
2022-11-23 02:39:43,661 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8393353603102944, 'Total loss': 0.8393353603102944} | train loss {'Reaction outcome loss': 0.7963259489565846, 'Total loss': 0.7963259489565846}
2022-11-23 02:39:43,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:43,661 INFO:     Epoch: 90
2022-11-23 02:39:44,467 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8237105486067858, 'Total loss': 0.8237105486067858} | train loss {'Reaction outcome loss': 0.8003610393055055, 'Total loss': 0.8003610393055055}
2022-11-23 02:39:44,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:44,468 INFO:     Epoch: 91
2022-11-23 02:39:45,302 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8277197175405242, 'Total loss': 0.8277197175405242} | train loss {'Reaction outcome loss': 0.8062673758881295, 'Total loss': 0.8062673758881295}
2022-11-23 02:39:45,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:45,302 INFO:     Epoch: 92
2022-11-23 02:39:46,096 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8448702015660026, 'Total loss': 0.8448702015660026} | train loss {'Reaction outcome loss': 0.8037237066488999, 'Total loss': 0.8037237066488999}
2022-11-23 02:39:46,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:46,096 INFO:     Epoch: 93
2022-11-23 02:39:46,895 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8629721254110336, 'Total loss': 0.8629721254110336} | train loss {'Reaction outcome loss': 0.806902016192554, 'Total loss': 0.806902016192554}
2022-11-23 02:39:46,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:46,896 INFO:     Epoch: 94
2022-11-23 02:39:47,680 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8318983804095875, 'Total loss': 0.8318983804095875} | train loss {'Reaction outcome loss': 0.8004432365162532, 'Total loss': 0.8004432365162532}
2022-11-23 02:39:47,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:47,680 INFO:     Epoch: 95
2022-11-23 02:39:48,498 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8339594175869768, 'Total loss': 0.8339594175869768} | train loss {'Reaction outcome loss': 0.798833682891811, 'Total loss': 0.798833682891811}
2022-11-23 02:39:48,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:48,498 INFO:     Epoch: 96
2022-11-23 02:39:49,313 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8416278646750883, 'Total loss': 0.8416278646750883} | train loss {'Reaction outcome loss': 0.798142854878415, 'Total loss': 0.798142854878415}
2022-11-23 02:39:49,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:49,313 INFO:     Epoch: 97
2022-11-23 02:39:50,127 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.851904384791851, 'Total loss': 0.851904384791851} | train loss {'Reaction outcome loss': 0.8009941821638872, 'Total loss': 0.8009941821638872}
2022-11-23 02:39:50,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:50,127 INFO:     Epoch: 98
2022-11-23 02:39:50,922 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8389368721029975, 'Total loss': 0.8389368721029975} | train loss {'Reaction outcome loss': 0.8144381562707877, 'Total loss': 0.8144381562707877}
2022-11-23 02:39:50,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:50,922 INFO:     Epoch: 99
2022-11-23 02:39:51,715 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.84437461536039, 'Total loss': 0.84437461536039} | train loss {'Reaction outcome loss': 0.8021406628764592, 'Total loss': 0.8021406628764592}
2022-11-23 02:39:51,716 INFO:     Best model found after epoch 17 of 100.
2022-11-23 02:39:51,716 INFO:   Done with stage: TRAINING
2022-11-23 02:39:51,716 INFO:   Starting stage: EVALUATION
2022-11-23 02:39:51,840 INFO:   Done with stage: EVALUATION
2022-11-23 02:39:51,840 INFO:   Leaving out SEQ value Fold_9
2022-11-23 02:39:51,854 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:39:51,854 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:39:52,527 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:39:52,528 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:39:52,602 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:39:52,602 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:39:52,602 INFO:     No hyperparam tuning for this model
2022-11-23 02:39:52,602 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:39:52,602 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:39:52,603 INFO:     None feature selector for col prot
2022-11-23 02:39:52,603 INFO:     None feature selector for col prot
2022-11-23 02:39:52,603 INFO:     None feature selector for col prot
2022-11-23 02:39:52,604 INFO:     None feature selector for col chem
2022-11-23 02:39:52,604 INFO:     None feature selector for col chem
2022-11-23 02:39:52,604 INFO:     None feature selector for col chem
2022-11-23 02:39:52,604 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:39:52,604 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:39:52,606 INFO:     Number of params in model 168571
2022-11-23 02:39:52,609 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:39:52,609 INFO:   Starting stage: TRAINING
2022-11-23 02:39:52,668 INFO:     Val loss before train {'Reaction outcome loss': 0.9783876727927815, 'Total loss': 0.9783876727927815}
2022-11-23 02:39:52,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:52,668 INFO:     Epoch: 0
2022-11-23 02:39:53,498 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8320530023087155, 'Total loss': 0.8320530023087155} | train loss {'Reaction outcome loss': 0.8763182922717063, 'Total loss': 0.8763182922717063}
2022-11-23 02:39:53,498 INFO:     Found new best model at epoch 0
2022-11-23 02:39:53,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:53,499 INFO:     Epoch: 1
2022-11-23 02:39:54,315 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8742238980802622, 'Total loss': 0.8742238980802622} | train loss {'Reaction outcome loss': 0.8460316486175983, 'Total loss': 0.8460316486175983}
2022-11-23 02:39:54,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:54,315 INFO:     Epoch: 2
2022-11-23 02:39:55,121 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8262533301656897, 'Total loss': 0.8262533301656897} | train loss {'Reaction outcome loss': 0.8429548888196868, 'Total loss': 0.8429548888196868}
2022-11-23 02:39:55,121 INFO:     Found new best model at epoch 2
2022-11-23 02:39:55,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:55,122 INFO:     Epoch: 3
2022-11-23 02:39:55,921 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8254498263651674, 'Total loss': 0.8254498263651674} | train loss {'Reaction outcome loss': 0.8428392975080398, 'Total loss': 0.8428392975080398}
2022-11-23 02:39:55,921 INFO:     Found new best model at epoch 3
2022-11-23 02:39:55,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:55,922 INFO:     Epoch: 4
2022-11-23 02:39:56,763 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8361336067318916, 'Total loss': 0.8361336067318916} | train loss {'Reaction outcome loss': 0.8317375016068259, 'Total loss': 0.8317375016068259}
2022-11-23 02:39:56,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:56,763 INFO:     Epoch: 5
2022-11-23 02:39:57,608 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8203763636675748, 'Total loss': 0.8203763636675748} | train loss {'Reaction outcome loss': 0.8316483925427159, 'Total loss': 0.8316483925427159}
2022-11-23 02:39:57,609 INFO:     Found new best model at epoch 5
2022-11-23 02:39:57,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:57,610 INFO:     Epoch: 6
2022-11-23 02:39:58,431 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8146549761295319, 'Total loss': 0.8146549761295319} | train loss {'Reaction outcome loss': 0.8247637983051038, 'Total loss': 0.8247637983051038}
2022-11-23 02:39:58,431 INFO:     Found new best model at epoch 6
2022-11-23 02:39:58,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:58,432 INFO:     Epoch: 7
2022-11-23 02:39:59,233 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8066680607470599, 'Total loss': 0.8066680607470599} | train loss {'Reaction outcome loss': 0.828470854989944, 'Total loss': 0.828470854989944}
2022-11-23 02:39:59,234 INFO:     Found new best model at epoch 7
2022-11-23 02:39:59,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:39:59,234 INFO:     Epoch: 8
2022-11-23 02:40:00,057 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8196603560989554, 'Total loss': 0.8196603560989554} | train loss {'Reaction outcome loss': 0.8246552600495277, 'Total loss': 0.8246552600495277}
2022-11-23 02:40:00,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:00,058 INFO:     Epoch: 9
2022-11-23 02:40:00,893 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8080537007613615, 'Total loss': 0.8080537007613615} | train loss {'Reaction outcome loss': 0.8195214831540661, 'Total loss': 0.8195214831540661}
2022-11-23 02:40:00,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:00,894 INFO:     Epoch: 10
2022-11-23 02:40:01,714 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8295689550313082, 'Total loss': 0.8295689550313082} | train loss {'Reaction outcome loss': 0.8219660982008903, 'Total loss': 0.8219660982008903}
2022-11-23 02:40:01,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:01,714 INFO:     Epoch: 11
2022-11-23 02:40:02,539 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8352952348915014, 'Total loss': 0.8352952348915014} | train loss {'Reaction outcome loss': 0.8236583473701631, 'Total loss': 0.8236583473701631}
2022-11-23 02:40:02,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:02,539 INFO:     Epoch: 12
2022-11-23 02:40:03,337 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8123661103573713, 'Total loss': 0.8123661103573713} | train loss {'Reaction outcome loss': 0.8176054447408645, 'Total loss': 0.8176054447408645}
2022-11-23 02:40:03,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:03,337 INFO:     Epoch: 13
2022-11-23 02:40:04,135 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8106843551451509, 'Total loss': 0.8106843551451509} | train loss {'Reaction outcome loss': 0.8130454091775802, 'Total loss': 0.8130454091775802}
2022-11-23 02:40:04,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:04,135 INFO:     Epoch: 14
2022-11-23 02:40:04,971 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8036230822855776, 'Total loss': 0.8036230822855776} | train loss {'Reaction outcome loss': 0.8174105684363073, 'Total loss': 0.8174105684363073}
2022-11-23 02:40:04,972 INFO:     Found new best model at epoch 14
2022-11-23 02:40:04,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:04,973 INFO:     Epoch: 15
2022-11-23 02:40:05,806 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8417570001699708, 'Total loss': 0.8417570001699708} | train loss {'Reaction outcome loss': 0.8147521715971732, 'Total loss': 0.8147521715971732}
2022-11-23 02:40:05,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:05,806 INFO:     Epoch: 16
2022-11-23 02:40:06,591 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8115656037222255, 'Total loss': 0.8115656037222255} | train loss {'Reaction outcome loss': 0.8212541816455703, 'Total loss': 0.8212541816455703}
2022-11-23 02:40:06,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:06,591 INFO:     Epoch: 17
2022-11-23 02:40:07,426 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.814101675694639, 'Total loss': 0.814101675694639} | train loss {'Reaction outcome loss': 0.8176179793813536, 'Total loss': 0.8176179793813536}
2022-11-23 02:40:07,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:07,426 INFO:     Epoch: 18
2022-11-23 02:40:08,267 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8089383921839974, 'Total loss': 0.8089383921839974} | train loss {'Reaction outcome loss': 0.8150354711519133, 'Total loss': 0.8150354711519133}
2022-11-23 02:40:08,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:08,267 INFO:     Epoch: 19
2022-11-23 02:40:09,090 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8061862994324077, 'Total loss': 0.8061862994324077} | train loss {'Reaction outcome loss': 0.8197142085240733, 'Total loss': 0.8197142085240733}
2022-11-23 02:40:09,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:09,090 INFO:     Epoch: 20
2022-11-23 02:40:09,921 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8241554322567853, 'Total loss': 0.8241554322567853} | train loss {'Reaction outcome loss': 0.8191565634502519, 'Total loss': 0.8191565634502519}
2022-11-23 02:40:09,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:09,921 INFO:     Epoch: 21
2022-11-23 02:40:10,714 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8015918244015087, 'Total loss': 0.8015918244015087} | train loss {'Reaction outcome loss': 0.816150298041682, 'Total loss': 0.816150298041682}
2022-11-23 02:40:10,714 INFO:     Found new best model at epoch 21
2022-11-23 02:40:10,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:10,715 INFO:     Epoch: 22
2022-11-23 02:40:11,524 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8472009037028659, 'Total loss': 0.8472009037028659} | train loss {'Reaction outcome loss': 0.8133567620909983, 'Total loss': 0.8133567620909983}
2022-11-23 02:40:11,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:11,525 INFO:     Epoch: 23
2022-11-23 02:40:12,323 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8264249868013642, 'Total loss': 0.8264249868013642} | train loss {'Reaction outcome loss': 0.812066126975321, 'Total loss': 0.812066126975321}
2022-11-23 02:40:12,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:12,323 INFO:     Epoch: 24
2022-11-23 02:40:13,111 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7999061528931964, 'Total loss': 0.7999061528931964} | train loss {'Reaction outcome loss': 0.8130371931099123, 'Total loss': 0.8130371931099123}
2022-11-23 02:40:13,112 INFO:     Found new best model at epoch 24
2022-11-23 02:40:13,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:13,112 INFO:     Epoch: 25
2022-11-23 02:40:13,983 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8008560009978034, 'Total loss': 0.8008560009978034} | train loss {'Reaction outcome loss': 0.8130519450191529, 'Total loss': 0.8130519450191529}
2022-11-23 02:40:13,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:13,984 INFO:     Epoch: 26
2022-11-23 02:40:14,790 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8232666403055191, 'Total loss': 0.8232666403055191} | train loss {'Reaction outcome loss': 0.8138202265385659, 'Total loss': 0.8138202265385659}
2022-11-23 02:40:14,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:14,790 INFO:     Epoch: 27
2022-11-23 02:40:15,569 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8166070519523188, 'Total loss': 0.8166070519523188} | train loss {'Reaction outcome loss': 0.8174309759370743, 'Total loss': 0.8174309759370743}
2022-11-23 02:40:15,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:15,569 INFO:     Epoch: 28
2022-11-23 02:40:16,347 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8169763602993705, 'Total loss': 0.8169763602993705} | train loss {'Reaction outcome loss': 0.8124089956043228, 'Total loss': 0.8124089956043228}
2022-11-23 02:40:16,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:16,347 INFO:     Epoch: 29
2022-11-23 02:40:17,134 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.821955191140825, 'Total loss': 0.821955191140825} | train loss {'Reaction outcome loss': 0.8126409160754373, 'Total loss': 0.8126409160754373}
2022-11-23 02:40:17,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:17,135 INFO:     Epoch: 30
2022-11-23 02:40:17,938 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8066178885373202, 'Total loss': 0.8066178885373202} | train loss {'Reaction outcome loss': 0.8120669311573429, 'Total loss': 0.8120669311573429}
2022-11-23 02:40:17,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:17,938 INFO:     Epoch: 31
2022-11-23 02:40:18,751 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.820725098929622, 'Total loss': 0.820725098929622} | train loss {'Reaction outcome loss': 0.808557981925626, 'Total loss': 0.808557981925626}
2022-11-23 02:40:18,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:18,751 INFO:     Epoch: 32
2022-11-23 02:40:19,562 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8296685638752851, 'Total loss': 0.8296685638752851} | train loss {'Reaction outcome loss': 0.8144879741293769, 'Total loss': 0.8144879741293769}
2022-11-23 02:40:19,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:19,562 INFO:     Epoch: 33
2022-11-23 02:40:20,362 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8083138432015072, 'Total loss': 0.8083138432015072} | train loss {'Reaction outcome loss': 0.8136981004668821, 'Total loss': 0.8136981004668821}
2022-11-23 02:40:20,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:20,363 INFO:     Epoch: 34
2022-11-23 02:40:21,159 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8263145725835453, 'Total loss': 0.8263145725835453} | train loss {'Reaction outcome loss': 0.8127050437033176, 'Total loss': 0.8127050437033176}
2022-11-23 02:40:21,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:21,160 INFO:     Epoch: 35
2022-11-23 02:40:21,967 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8209148184819655, 'Total loss': 0.8209148184819655} | train loss {'Reaction outcome loss': 0.8165166100427028, 'Total loss': 0.8165166100427028}
2022-11-23 02:40:21,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:21,967 INFO:     Epoch: 36
2022-11-23 02:40:22,775 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8181799799203873, 'Total loss': 0.8181799799203873} | train loss {'Reaction outcome loss': 0.8151089968460221, 'Total loss': 0.8151089968460221}
2022-11-23 02:40:22,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:22,775 INFO:     Epoch: 37
2022-11-23 02:40:23,575 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8201356049288403, 'Total loss': 0.8201356049288403} | train loss {'Reaction outcome loss': 0.8094960251642812, 'Total loss': 0.8094960251642812}
2022-11-23 02:40:23,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:23,576 INFO:     Epoch: 38
2022-11-23 02:40:24,394 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8045495226979256, 'Total loss': 0.8045495226979256} | train loss {'Reaction outcome loss': 0.8136182972981084, 'Total loss': 0.8136182972981084}
2022-11-23 02:40:24,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:24,395 INFO:     Epoch: 39
2022-11-23 02:40:25,201 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8054021549495783, 'Total loss': 0.8054021549495783} | train loss {'Reaction outcome loss': 0.8079218757489035, 'Total loss': 0.8079218757489035}
2022-11-23 02:40:25,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:25,201 INFO:     Epoch: 40
2022-11-23 02:40:26,000 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8009089786898006, 'Total loss': 0.8009089786898006} | train loss {'Reaction outcome loss': 0.812101153236243, 'Total loss': 0.812101153236243}
2022-11-23 02:40:26,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:26,000 INFO:     Epoch: 41
2022-11-23 02:40:26,848 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.799389046701518, 'Total loss': 0.799389046701518} | train loss {'Reaction outcome loss': 0.8118894220960717, 'Total loss': 0.8118894220960717}
2022-11-23 02:40:26,848 INFO:     Found new best model at epoch 41
2022-11-23 02:40:26,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:26,849 INFO:     Epoch: 42
2022-11-23 02:40:27,643 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8466130258007483, 'Total loss': 0.8466130258007483} | train loss {'Reaction outcome loss': 0.8085711702944771, 'Total loss': 0.8085711702944771}
2022-11-23 02:40:27,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:27,644 INFO:     Epoch: 43
2022-11-23 02:40:28,429 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8144037357785485, 'Total loss': 0.8144037357785485} | train loss {'Reaction outcome loss': 0.8139315467448004, 'Total loss': 0.8139315467448004}
2022-11-23 02:40:28,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:28,430 INFO:     Epoch: 44
2022-11-23 02:40:29,274 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8210335333238948, 'Total loss': 0.8210335333238948} | train loss {'Reaction outcome loss': 0.813121146913017, 'Total loss': 0.813121146913017}
2022-11-23 02:40:29,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:29,274 INFO:     Epoch: 45
2022-11-23 02:40:30,087 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8116302876309915, 'Total loss': 0.8116302876309915} | train loss {'Reaction outcome loss': 0.8093644838419652, 'Total loss': 0.8093644838419652}
2022-11-23 02:40:30,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:30,087 INFO:     Epoch: 46
2022-11-23 02:40:30,887 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8256568366831, 'Total loss': 0.8256568366831} | train loss {'Reaction outcome loss': 0.8169025203153011, 'Total loss': 0.8169025203153011}
2022-11-23 02:40:30,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:30,888 INFO:     Epoch: 47
2022-11-23 02:40:31,689 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8115995756604455, 'Total loss': 0.8115995756604455} | train loss {'Reaction outcome loss': 0.8088911698470193, 'Total loss': 0.8088911698470193}
2022-11-23 02:40:31,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:31,689 INFO:     Epoch: 48
2022-11-23 02:40:32,552 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8018633384596218, 'Total loss': 0.8018633384596218} | train loss {'Reaction outcome loss': 0.8091026489292422, 'Total loss': 0.8091026489292422}
2022-11-23 02:40:32,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:32,553 INFO:     Epoch: 49
2022-11-23 02:40:33,377 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8009856336496093, 'Total loss': 0.8009856336496093} | train loss {'Reaction outcome loss': 0.8126065898085794, 'Total loss': 0.8126065898085794}
2022-11-23 02:40:33,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:33,377 INFO:     Epoch: 50
2022-11-23 02:40:34,169 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8115654614838687, 'Total loss': 0.8115654614838687} | train loss {'Reaction outcome loss': 0.8133452130902198, 'Total loss': 0.8133452130902198}
2022-11-23 02:40:34,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:34,170 INFO:     Epoch: 51
2022-11-23 02:40:34,968 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8104831671172922, 'Total loss': 0.8104831671172922} | train loss {'Reaction outcome loss': 0.811469008725497, 'Total loss': 0.811469008725497}
2022-11-23 02:40:34,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:34,968 INFO:     Epoch: 52
2022-11-23 02:40:35,784 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8105233243920587, 'Total loss': 0.8105233243920587} | train loss {'Reaction outcome loss': 0.813556298373207, 'Total loss': 0.813556298373207}
2022-11-23 02:40:35,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:35,785 INFO:     Epoch: 53
2022-11-23 02:40:36,662 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8050521490248767, 'Total loss': 0.8050521490248767} | train loss {'Reaction outcome loss': 0.8104329871073845, 'Total loss': 0.8104329871073845}
2022-11-23 02:40:36,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:36,663 INFO:     Epoch: 54
2022-11-23 02:40:37,476 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7997846772724931, 'Total loss': 0.7997846772724931} | train loss {'Reaction outcome loss': 0.8117435521055614, 'Total loss': 0.8117435521055614}
2022-11-23 02:40:37,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:37,476 INFO:     Epoch: 55
2022-11-23 02:40:38,289 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8185258771885525, 'Total loss': 0.8185258771885525} | train loss {'Reaction outcome loss': 0.8069993134948515, 'Total loss': 0.8069993134948515}
2022-11-23 02:40:38,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:38,289 INFO:     Epoch: 56
2022-11-23 02:40:39,082 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8119550787589767, 'Total loss': 0.8119550787589767} | train loss {'Reaction outcome loss': 0.812619142715008, 'Total loss': 0.812619142715008}
2022-11-23 02:40:39,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:39,083 INFO:     Epoch: 57
2022-11-23 02:40:39,896 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8163276118311015, 'Total loss': 0.8163276118311015} | train loss {'Reaction outcome loss': 0.8123108434580988, 'Total loss': 0.8123108434580988}
2022-11-23 02:40:39,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:39,896 INFO:     Epoch: 58
2022-11-23 02:40:40,712 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8272534087300301, 'Total loss': 0.8272534087300301} | train loss {'Reaction outcome loss': 0.8165674022128505, 'Total loss': 0.8165674022128505}
2022-11-23 02:40:40,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:40,712 INFO:     Epoch: 59
2022-11-23 02:40:41,512 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8129898390986703, 'Total loss': 0.8129898390986703} | train loss {'Reaction outcome loss': 0.8118187083351996, 'Total loss': 0.8118187083351996}
2022-11-23 02:40:41,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:41,512 INFO:     Epoch: 60
2022-11-23 02:40:42,364 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8052774992856112, 'Total loss': 0.8052774992856112} | train loss {'Reaction outcome loss': 0.808144299493682, 'Total loss': 0.808144299493682}
2022-11-23 02:40:42,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:42,365 INFO:     Epoch: 61
2022-11-23 02:40:43,214 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.798460413786498, 'Total loss': 0.798460413786498} | train loss {'Reaction outcome loss': 0.8076706235447237, 'Total loss': 0.8076706235447237}
2022-11-23 02:40:43,214 INFO:     Found new best model at epoch 61
2022-11-23 02:40:43,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:43,215 INFO:     Epoch: 62
2022-11-23 02:40:43,998 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7917149967767976, 'Total loss': 0.7917149967767976} | train loss {'Reaction outcome loss': 0.8102935387963249, 'Total loss': 0.8102935387963249}
2022-11-23 02:40:43,998 INFO:     Found new best model at epoch 62
2022-11-23 02:40:43,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:43,999 INFO:     Epoch: 63
2022-11-23 02:40:44,766 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8001824658025395, 'Total loss': 0.8001824658025395} | train loss {'Reaction outcome loss': 0.8108144471001241, 'Total loss': 0.8108144471001241}
2022-11-23 02:40:44,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:44,766 INFO:     Epoch: 64
2022-11-23 02:40:45,593 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8189704079519619, 'Total loss': 0.8189704079519619} | train loss {'Reaction outcome loss': 0.8164470230619754, 'Total loss': 0.8164470230619754}
2022-11-23 02:40:45,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:45,593 INFO:     Epoch: 65
2022-11-23 02:40:46,391 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8036484955386682, 'Total loss': 0.8036484955386682} | train loss {'Reaction outcome loss': 0.8140156228215464, 'Total loss': 0.8140156228215464}
2022-11-23 02:40:46,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:46,391 INFO:     Epoch: 66
2022-11-23 02:40:47,212 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8162454569881613, 'Total loss': 0.8162454569881613} | train loss {'Reaction outcome loss': 0.8168312051603871, 'Total loss': 0.8168312051603871}
2022-11-23 02:40:47,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:47,212 INFO:     Epoch: 67
2022-11-23 02:40:48,053 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8145702095194296, 'Total loss': 0.8145702095194296} | train loss {'Reaction outcome loss': 0.8127331868294747, 'Total loss': 0.8127331868294747}
2022-11-23 02:40:48,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:48,053 INFO:     Epoch: 68
2022-11-23 02:40:48,844 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.808107344264334, 'Total loss': 0.808107344264334} | train loss {'Reaction outcome loss': 0.809387979127707, 'Total loss': 0.809387979127707}
2022-11-23 02:40:48,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:48,844 INFO:     Epoch: 69
2022-11-23 02:40:49,641 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8067907108501955, 'Total loss': 0.8067907108501955} | train loss {'Reaction outcome loss': 0.8106779504206872, 'Total loss': 0.8106779504206872}
2022-11-23 02:40:49,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:49,642 INFO:     Epoch: 70
2022-11-23 02:40:50,434 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8206320357593623, 'Total loss': 0.8206320357593623} | train loss {'Reaction outcome loss': 0.81577103621056, 'Total loss': 0.81577103621056}
2022-11-23 02:40:50,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:50,434 INFO:     Epoch: 71
2022-11-23 02:40:51,283 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8070113496346907, 'Total loss': 0.8070113496346907} | train loss {'Reaction outcome loss': 0.8137641984128183, 'Total loss': 0.8137641984128183}
2022-11-23 02:40:51,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:51,284 INFO:     Epoch: 72
2022-11-23 02:40:52,103 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7938368049534884, 'Total loss': 0.7938368049534884} | train loss {'Reaction outcome loss': 0.8131876414821994, 'Total loss': 0.8131876414821994}
2022-11-23 02:40:52,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:52,104 INFO:     Epoch: 73
2022-11-23 02:40:52,880 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8101207288828763, 'Total loss': 0.8101207288828763} | train loss {'Reaction outcome loss': 0.8161502863851285, 'Total loss': 0.8161502863851285}
2022-11-23 02:40:52,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:52,880 INFO:     Epoch: 74
2022-11-23 02:40:53,693 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8099558278918266, 'Total loss': 0.8099558278918266} | train loss {'Reaction outcome loss': 0.8102920323369964, 'Total loss': 0.8102920323369964}
2022-11-23 02:40:53,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:53,693 INFO:     Epoch: 75
2022-11-23 02:40:54,505 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8029285967350006, 'Total loss': 0.8029285967350006} | train loss {'Reaction outcome loss': 0.8104271434487835, 'Total loss': 0.8104271434487835}
2022-11-23 02:40:54,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:54,506 INFO:     Epoch: 76
2022-11-23 02:40:55,312 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8025268018245697, 'Total loss': 0.8025268018245697} | train loss {'Reaction outcome loss': 0.8118534151825213, 'Total loss': 0.8118534151825213}
2022-11-23 02:40:55,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:55,312 INFO:     Epoch: 77
2022-11-23 02:40:56,124 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8151284767822786, 'Total loss': 0.8151284767822786} | train loss {'Reaction outcome loss': 0.812630987455768, 'Total loss': 0.812630987455768}
2022-11-23 02:40:56,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:56,125 INFO:     Epoch: 78
2022-11-23 02:40:56,930 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7991103976964951, 'Total loss': 0.7991103976964951} | train loss {'Reaction outcome loss': 0.813239402828678, 'Total loss': 0.813239402828678}
2022-11-23 02:40:56,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:56,930 INFO:     Epoch: 79
2022-11-23 02:40:57,788 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8146461045200174, 'Total loss': 0.8146461045200174} | train loss {'Reaction outcome loss': 0.8133028112351894, 'Total loss': 0.8133028112351894}
2022-11-23 02:40:57,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:57,789 INFO:     Epoch: 80
2022-11-23 02:40:58,700 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8073435466397892, 'Total loss': 0.8073435466397892} | train loss {'Reaction outcome loss': 0.8109771639348999, 'Total loss': 0.8109771639348999}
2022-11-23 02:40:58,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:58,700 INFO:     Epoch: 81
2022-11-23 02:40:59,584 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8065374276854775, 'Total loss': 0.8065374276854775} | train loss {'Reaction outcome loss': 0.8149197685021546, 'Total loss': 0.8149197685021546}
2022-11-23 02:40:59,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:40:59,585 INFO:     Epoch: 82
2022-11-23 02:41:00,440 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8095682155002247, 'Total loss': 0.8095682155002247} | train loss {'Reaction outcome loss': 0.8087145050446833, 'Total loss': 0.8087145050446833}
2022-11-23 02:41:00,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:00,440 INFO:     Epoch: 83
2022-11-23 02:41:01,353 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7975100258534605, 'Total loss': 0.7975100258534605} | train loss {'Reaction outcome loss': 0.811664289644649, 'Total loss': 0.811664289644649}
2022-11-23 02:41:01,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:01,354 INFO:     Epoch: 84
2022-11-23 02:41:02,279 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8079821447079832, 'Total loss': 0.8079821447079832} | train loss {'Reaction outcome loss': 0.8127709683631698, 'Total loss': 0.8127709683631698}
2022-11-23 02:41:02,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:02,280 INFO:     Epoch: 85
2022-11-23 02:41:03,158 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.799090757288716, 'Total loss': 0.799090757288716} | train loss {'Reaction outcome loss': 0.8175178394923287, 'Total loss': 0.8175178394923287}
2022-11-23 02:41:03,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:03,158 INFO:     Epoch: 86
2022-11-23 02:41:03,968 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.837272242388942, 'Total loss': 0.837272242388942} | train loss {'Reaction outcome loss': 0.8130518951483311, 'Total loss': 0.8130518951483311}
2022-11-23 02:41:03,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:03,969 INFO:     Epoch: 87
2022-11-23 02:41:04,761 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8143544772809203, 'Total loss': 0.8143544772809203} | train loss {'Reaction outcome loss': 0.8087489727524019, 'Total loss': 0.8087489727524019}
2022-11-23 02:41:04,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:04,761 INFO:     Epoch: 88
2022-11-23 02:41:05,523 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8021101829680529, 'Total loss': 0.8021101829680529} | train loss {'Reaction outcome loss': 0.809830911337368, 'Total loss': 0.809830911337368}
2022-11-23 02:41:05,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:05,523 INFO:     Epoch: 89
2022-11-23 02:41:06,297 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8161932243542238, 'Total loss': 0.8161932243542238} | train loss {'Reaction outcome loss': 0.8117899186909199, 'Total loss': 0.8117899186909199}
2022-11-23 02:41:06,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:06,298 INFO:     Epoch: 90
2022-11-23 02:41:07,099 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8035939904776487, 'Total loss': 0.8035939904776487} | train loss {'Reaction outcome loss': 0.8118260565303987, 'Total loss': 0.8118260565303987}
2022-11-23 02:41:07,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:07,099 INFO:     Epoch: 91
2022-11-23 02:41:07,897 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8345659117807042, 'Total loss': 0.8345659117807042} | train loss {'Reaction outcome loss': 0.8120090390645689, 'Total loss': 0.8120090390645689}
2022-11-23 02:41:07,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:07,897 INFO:     Epoch: 92
2022-11-23 02:41:08,668 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8166550384326414, 'Total loss': 0.8166550384326414} | train loss {'Reaction outcome loss': 0.8145263390916009, 'Total loss': 0.8145263390916009}
2022-11-23 02:41:08,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:08,668 INFO:     Epoch: 93
2022-11-23 02:41:09,452 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8170080530372533, 'Total loss': 0.8170080530372533} | train loss {'Reaction outcome loss': 0.8117419555783272, 'Total loss': 0.8117419555783272}
2022-11-23 02:41:09,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:09,452 INFO:     Epoch: 94
2022-11-23 02:41:10,249 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8028597269545902, 'Total loss': 0.8028597269545902} | train loss {'Reaction outcome loss': 0.8141917158519069, 'Total loss': 0.8141917158519069}
2022-11-23 02:41:10,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:10,249 INFO:     Epoch: 95
2022-11-23 02:41:11,049 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8117134401744063, 'Total loss': 0.8117134401744063} | train loss {'Reaction outcome loss': 0.8118463551565525, 'Total loss': 0.8118463551565525}
2022-11-23 02:41:11,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:11,050 INFO:     Epoch: 96
2022-11-23 02:41:11,847 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7999909614974802, 'Total loss': 0.7999909614974802} | train loss {'Reaction outcome loss': 0.8110704138394325, 'Total loss': 0.8110704138394325}
2022-11-23 02:41:11,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:11,847 INFO:     Epoch: 97
2022-11-23 02:41:12,643 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8245876079255884, 'Total loss': 0.8245876079255884} | train loss {'Reaction outcome loss': 0.8092221576840647, 'Total loss': 0.8092221576840647}
2022-11-23 02:41:12,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:12,644 INFO:     Epoch: 98
2022-11-23 02:41:13,419 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.829946218566461, 'Total loss': 0.829946218566461} | train loss {'Reaction outcome loss': 0.8086221695186631, 'Total loss': 0.8086221695186631}
2022-11-23 02:41:13,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:13,419 INFO:     Epoch: 99
2022-11-23 02:41:14,233 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8057170178402554, 'Total loss': 0.8057170178402554} | train loss {'Reaction outcome loss': 0.8141757517812713, 'Total loss': 0.8141757517812713}
2022-11-23 02:41:14,233 INFO:     Best model found after epoch 63 of 100.
2022-11-23 02:41:14,233 INFO:   Done with stage: TRAINING
2022-11-23 02:41:14,233 INFO:   Starting stage: EVALUATION
2022-11-23 02:41:14,351 INFO:   Done with stage: EVALUATION
2022-11-23 02:41:14,359 INFO:   Leaving out SEQ value Fold_0
2022-11-23 02:41:14,372 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:41:14,372 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:41:15,038 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:41:15,038 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:41:15,111 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:41:15,111 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:41:15,111 INFO:     No hyperparam tuning for this model
2022-11-23 02:41:15,111 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:41:15,111 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:41:15,112 INFO:     None feature selector for col prot
2022-11-23 02:41:15,112 INFO:     None feature selector for col prot
2022-11-23 02:41:15,112 INFO:     None feature selector for col prot
2022-11-23 02:41:15,113 INFO:     None feature selector for col chem
2022-11-23 02:41:15,113 INFO:     None feature selector for col chem
2022-11-23 02:41:15,113 INFO:     None feature selector for col chem
2022-11-23 02:41:15,113 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:41:15,113 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:41:15,115 INFO:     Number of params in model 168571
2022-11-23 02:41:15,118 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:41:15,118 INFO:   Starting stage: TRAINING
2022-11-23 02:41:15,176 INFO:     Val loss before train {'Reaction outcome loss': 1.011648866263303, 'Total loss': 1.011648866263303}
2022-11-23 02:41:15,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:15,176 INFO:     Epoch: 0
2022-11-23 02:41:16,023 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9110083200714805, 'Total loss': 0.9110083200714805} | train loss {'Reaction outcome loss': 0.8949882016490828, 'Total loss': 0.8949882016490828}
2022-11-23 02:41:16,023 INFO:     Found new best model at epoch 0
2022-11-23 02:41:16,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:16,024 INFO:     Epoch: 1
2022-11-23 02:41:16,806 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8768637071956288, 'Total loss': 0.8768637071956288} | train loss {'Reaction outcome loss': 0.8678529509889935, 'Total loss': 0.8678529509889935}
2022-11-23 02:41:16,806 INFO:     Found new best model at epoch 1
2022-11-23 02:41:16,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:16,807 INFO:     Epoch: 2
2022-11-23 02:41:17,621 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.86521523242647, 'Total loss': 0.86521523242647} | train loss {'Reaction outcome loss': 0.8556905825611069, 'Total loss': 0.8556905825611069}
2022-11-23 02:41:17,622 INFO:     Found new best model at epoch 2
2022-11-23 02:41:17,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:17,622 INFO:     Epoch: 3
2022-11-23 02:41:18,466 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8747874376448718, 'Total loss': 0.8747874376448718} | train loss {'Reaction outcome loss': 0.8595193169618908, 'Total loss': 0.8595193169618908}
2022-11-23 02:41:18,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:18,466 INFO:     Epoch: 4
2022-11-23 02:41:19,296 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.862992982972752, 'Total loss': 0.862992982972752} | train loss {'Reaction outcome loss': 0.8570592999458313, 'Total loss': 0.8570592999458313}
2022-11-23 02:41:19,296 INFO:     Found new best model at epoch 4
2022-11-23 02:41:19,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:19,297 INFO:     Epoch: 5
2022-11-23 02:41:20,084 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8746486482295123, 'Total loss': 0.8746486482295123} | train loss {'Reaction outcome loss': 0.8497273883356257, 'Total loss': 0.8497273883356257}
2022-11-23 02:41:20,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:20,085 INFO:     Epoch: 6
2022-11-23 02:41:20,926 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8679479943080382, 'Total loss': 0.8679479943080382} | train loss {'Reaction outcome loss': 0.8524459846890889, 'Total loss': 0.8524459846890889}
2022-11-23 02:41:20,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:20,926 INFO:     Epoch: 7
2022-11-23 02:41:21,715 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.881314448334954, 'Total loss': 0.881314448334954} | train loss {'Reaction outcome loss': 0.8438351262918851, 'Total loss': 0.8438351262918851}
2022-11-23 02:41:21,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:21,715 INFO:     Epoch: 8
2022-11-23 02:41:22,508 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8781133632768284, 'Total loss': 0.8781133632768284} | train loss {'Reaction outcome loss': 0.8487590596019498, 'Total loss': 0.8487590596019498}
2022-11-23 02:41:22,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:22,509 INFO:     Epoch: 9
2022-11-23 02:41:23,302 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8644168735905127, 'Total loss': 0.8644168735905127} | train loss {'Reaction outcome loss': 0.8437885482784225, 'Total loss': 0.8437885482784225}
2022-11-23 02:41:23,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:23,303 INFO:     Epoch: 10
2022-11-23 02:41:24,140 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8611308722333475, 'Total loss': 0.8611308722333475} | train loss {'Reaction outcome loss': 0.8363622919267971, 'Total loss': 0.8363622919267971}
2022-11-23 02:41:24,140 INFO:     Found new best model at epoch 10
2022-11-23 02:41:24,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:24,141 INFO:     Epoch: 11
2022-11-23 02:41:24,999 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8594530455090783, 'Total loss': 0.8594530455090783} | train loss {'Reaction outcome loss': 0.8477167707947102, 'Total loss': 0.8477167707947102}
2022-11-23 02:41:24,999 INFO:     Found new best model at epoch 11
2022-11-23 02:41:25,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:25,000 INFO:     Epoch: 12
2022-11-23 02:41:25,868 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8633683283220638, 'Total loss': 0.8633683283220638} | train loss {'Reaction outcome loss': 0.8435937518532942, 'Total loss': 0.8435937518532942}
2022-11-23 02:41:25,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:25,868 INFO:     Epoch: 13
2022-11-23 02:41:26,700 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.868115592409264, 'Total loss': 0.868115592409264} | train loss {'Reaction outcome loss': 0.8365842356734913, 'Total loss': 0.8365842356734913}
2022-11-23 02:41:26,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:26,701 INFO:     Epoch: 14
2022-11-23 02:41:27,508 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.9065028605136004, 'Total loss': 0.9065028605136004} | train loss {'Reaction outcome loss': 0.8415227666316245, 'Total loss': 0.8415227666316245}
2022-11-23 02:41:27,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:27,508 INFO:     Epoch: 15
2022-11-23 02:41:28,292 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.860062219879844, 'Total loss': 0.860062219879844} | train loss {'Reaction outcome loss': 0.838626105534403, 'Total loss': 0.838626105534403}
2022-11-23 02:41:28,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:28,292 INFO:     Epoch: 16
2022-11-23 02:41:29,132 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8681096204302527, 'Total loss': 0.8681096204302527} | train loss {'Reaction outcome loss': 0.8329498049942589, 'Total loss': 0.8329498049942589}
2022-11-23 02:41:29,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:29,132 INFO:     Epoch: 17
2022-11-23 02:41:29,914 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8602607155388052, 'Total loss': 0.8602607155388052} | train loss {'Reaction outcome loss': 0.8355810169266303, 'Total loss': 0.8355810169266303}
2022-11-23 02:41:29,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:29,915 INFO:     Epoch: 18
2022-11-23 02:41:30,722 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8591559014537118, 'Total loss': 0.8591559014537118} | train loss {'Reaction outcome loss': 0.8328576803448712, 'Total loss': 0.8328576803448712}
2022-11-23 02:41:30,722 INFO:     Found new best model at epoch 18
2022-11-23 02:41:30,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:30,723 INFO:     Epoch: 19
2022-11-23 02:41:31,541 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8512732467868112, 'Total loss': 0.8512732467868112} | train loss {'Reaction outcome loss': 0.8375766471571285, 'Total loss': 0.8375766471571285}
2022-11-23 02:41:31,541 INFO:     Found new best model at epoch 19
2022-11-23 02:41:31,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:31,542 INFO:     Epoch: 20
2022-11-23 02:41:32,379 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8665430830283598, 'Total loss': 0.8665430830283598} | train loss {'Reaction outcome loss': 0.8311994827469351, 'Total loss': 0.8311994827469351}
2022-11-23 02:41:32,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:32,379 INFO:     Epoch: 21
2022-11-23 02:41:33,163 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8622000508687713, 'Total loss': 0.8622000508687713} | train loss {'Reaction outcome loss': 0.837962199681201, 'Total loss': 0.837962199681201}
2022-11-23 02:41:33,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:33,164 INFO:     Epoch: 22
2022-11-23 02:41:33,951 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8527958528562025, 'Total loss': 0.8527958528562025} | train loss {'Reaction outcome loss': 0.8306397810759332, 'Total loss': 0.8306397810759332}
2022-11-23 02:41:33,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:33,951 INFO:     Epoch: 23
2022-11-23 02:41:34,728 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8848203881220384, 'Total loss': 0.8848203881220384} | train loss {'Reaction outcome loss': 0.8286194273380012, 'Total loss': 0.8286194273380012}
2022-11-23 02:41:34,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:34,729 INFO:     Epoch: 24
2022-11-23 02:41:35,530 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8372278396378864, 'Total loss': 0.8372278396378864} | train loss {'Reaction outcome loss': 0.8377961828882395, 'Total loss': 0.8377961828882395}
2022-11-23 02:41:35,530 INFO:     Found new best model at epoch 24
2022-11-23 02:41:35,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:35,531 INFO:     Epoch: 25
2022-11-23 02:41:36,318 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8569321551106193, 'Total loss': 0.8569321551106193} | train loss {'Reaction outcome loss': 0.8280726540004194, 'Total loss': 0.8280726540004194}
2022-11-23 02:41:36,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:36,318 INFO:     Epoch: 26
2022-11-23 02:41:37,192 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8476979597048326, 'Total loss': 0.8476979597048326} | train loss {'Reaction outcome loss': 0.8307871884903927, 'Total loss': 0.8307871884903927}
2022-11-23 02:41:37,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:37,193 INFO:     Epoch: 27
2022-11-23 02:41:38,008 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8715334575284611, 'Total loss': 0.8715334575284611} | train loss {'Reaction outcome loss': 0.8333928282202979, 'Total loss': 0.8333928282202979}
2022-11-23 02:41:38,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:38,009 INFO:     Epoch: 28
2022-11-23 02:41:38,829 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8536958132277835, 'Total loss': 0.8536958132277835} | train loss {'Reaction outcome loss': 0.8325945721705433, 'Total loss': 0.8325945721705433}
2022-11-23 02:41:38,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:38,829 INFO:     Epoch: 29
2022-11-23 02:41:39,603 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8804980055852369, 'Total loss': 0.8804980055852369} | train loss {'Reaction outcome loss': 0.8315701316966702, 'Total loss': 0.8315701316966702}
2022-11-23 02:41:39,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:39,603 INFO:     Epoch: 30
2022-11-23 02:41:40,396 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8519564494490623, 'Total loss': 0.8519564494490623} | train loss {'Reaction outcome loss': 0.8346157329767822, 'Total loss': 0.8346157329767822}
2022-11-23 02:41:40,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:40,396 INFO:     Epoch: 31
2022-11-23 02:41:41,220 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.858162755315954, 'Total loss': 0.858162755315954} | train loss {'Reaction outcome loss': 0.8388742026288499, 'Total loss': 0.8388742026288499}
2022-11-23 02:41:41,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:41,221 INFO:     Epoch: 32
2022-11-23 02:41:42,015 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8675710003484379, 'Total loss': 0.8675710003484379} | train loss {'Reaction outcome loss': 0.8338912838866354, 'Total loss': 0.8338912838866354}
2022-11-23 02:41:42,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:42,015 INFO:     Epoch: 33
2022-11-23 02:41:42,897 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8476356674324382, 'Total loss': 0.8476356674324382} | train loss {'Reaction outcome loss': 0.8359464162033097, 'Total loss': 0.8359464162033097}
2022-11-23 02:41:42,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:42,897 INFO:     Epoch: 34
2022-11-23 02:41:43,685 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.855635476383296, 'Total loss': 0.855635476383296} | train loss {'Reaction outcome loss': 0.8323013589449739, 'Total loss': 0.8323013589449739}
2022-11-23 02:41:43,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:43,685 INFO:     Epoch: 35
2022-11-23 02:41:44,478 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8516349135474726, 'Total loss': 0.8516349135474726} | train loss {'Reaction outcome loss': 0.8283092178072524, 'Total loss': 0.8283092178072524}
2022-11-23 02:41:44,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:44,479 INFO:     Epoch: 36
2022-11-23 02:41:45,315 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8550495512106202, 'Total loss': 0.8550495512106202} | train loss {'Reaction outcome loss': 0.8229894272470282, 'Total loss': 0.8229894272470282}
2022-11-23 02:41:45,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:45,315 INFO:     Epoch: 37
2022-11-23 02:41:46,132 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8703917143019763, 'Total loss': 0.8703917143019763} | train loss {'Reaction outcome loss': 0.8366281115091764, 'Total loss': 0.8366281115091764}
2022-11-23 02:41:46,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:46,133 INFO:     Epoch: 38
2022-11-23 02:41:46,964 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.866105973043225, 'Total loss': 0.866105973043225} | train loss {'Reaction outcome loss': 0.8343059408519915, 'Total loss': 0.8343059408519915}
2022-11-23 02:41:46,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:46,965 INFO:     Epoch: 39
2022-11-23 02:41:47,806 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.878934610973705, 'Total loss': 0.878934610973705} | train loss {'Reaction outcome loss': 0.8290975702557004, 'Total loss': 0.8290975702557004}
2022-11-23 02:41:47,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:47,806 INFO:     Epoch: 40
2022-11-23 02:41:48,637 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8975889018990777, 'Total loss': 0.8975889018990777} | train loss {'Reaction outcome loss': 0.8377581363023534, 'Total loss': 0.8377581363023534}
2022-11-23 02:41:48,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:48,637 INFO:     Epoch: 41
2022-11-23 02:41:49,433 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8452306708151643, 'Total loss': 0.8452306708151643} | train loss {'Reaction outcome loss': 0.8396232231908481, 'Total loss': 0.8396232231908481}
2022-11-23 02:41:49,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:49,434 INFO:     Epoch: 42
2022-11-23 02:41:50,256 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8415742022070017, 'Total loss': 0.8415742022070017} | train loss {'Reaction outcome loss': 0.8208017625548096, 'Total loss': 0.8208017625548096}
2022-11-23 02:41:50,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:50,256 INFO:     Epoch: 43
2022-11-23 02:41:51,072 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8487493470311165, 'Total loss': 0.8487493470311165} | train loss {'Reaction outcome loss': 0.8305373779433941, 'Total loss': 0.8305373779433941}
2022-11-23 02:41:51,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:51,072 INFO:     Epoch: 44
2022-11-23 02:41:51,889 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8545999432151968, 'Total loss': 0.8545999432151968} | train loss {'Reaction outcome loss': 0.8312479422883949, 'Total loss': 0.8312479422883949}
2022-11-23 02:41:51,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:51,889 INFO:     Epoch: 45
2022-11-23 02:41:52,678 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.865442544221878, 'Total loss': 0.865442544221878} | train loss {'Reaction outcome loss': 0.8327733634213205, 'Total loss': 0.8327733634213205}
2022-11-23 02:41:52,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:52,678 INFO:     Epoch: 46
2022-11-23 02:41:53,423 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8497348041696982, 'Total loss': 0.8497348041696982} | train loss {'Reaction outcome loss': 0.8255074902132213, 'Total loss': 0.8255074902132213}
2022-11-23 02:41:53,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:53,423 INFO:     Epoch: 47
2022-11-23 02:41:54,212 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8592834635214373, 'Total loss': 0.8592834635214373} | train loss {'Reaction outcome loss': 0.8233150334252037, 'Total loss': 0.8233150334252037}
2022-11-23 02:41:54,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:54,213 INFO:     Epoch: 48
2022-11-23 02:41:55,006 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8500487980517474, 'Total loss': 0.8500487980517474} | train loss {'Reaction outcome loss': 0.8202246852249269, 'Total loss': 0.8202246852249269}
2022-11-23 02:41:55,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:55,006 INFO:     Epoch: 49
2022-11-23 02:41:55,820 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.864823692901568, 'Total loss': 0.864823692901568} | train loss {'Reaction outcome loss': 0.82226105326945, 'Total loss': 0.82226105326945}
2022-11-23 02:41:55,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:55,820 INFO:     Epoch: 50
2022-11-23 02:41:56,644 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8583639372478832, 'Total loss': 0.8583639372478832} | train loss {'Reaction outcome loss': 0.8226386089073984, 'Total loss': 0.8226386089073984}
2022-11-23 02:41:56,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:56,645 INFO:     Epoch: 51
2022-11-23 02:41:57,452 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8440734053199942, 'Total loss': 0.8440734053199942} | train loss {'Reaction outcome loss': 0.827160329471233, 'Total loss': 0.827160329471233}
2022-11-23 02:41:57,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:57,452 INFO:     Epoch: 52
2022-11-23 02:41:58,194 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8589008565653454, 'Total loss': 0.8589008565653454} | train loss {'Reaction outcome loss': 0.8238779473521931, 'Total loss': 0.8238779473521931}
2022-11-23 02:41:58,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:58,194 INFO:     Epoch: 53
2022-11-23 02:41:58,990 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8521446362137794, 'Total loss': 0.8521446362137794} | train loss {'Reaction outcome loss': 0.8361358857347898, 'Total loss': 0.8361358857347898}
2022-11-23 02:41:58,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:58,990 INFO:     Epoch: 54
2022-11-23 02:41:59,860 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8583350858905099, 'Total loss': 0.8583350858905099} | train loss {'Reaction outcome loss': 0.8215346276036158, 'Total loss': 0.8215346276036158}
2022-11-23 02:41:59,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:41:59,860 INFO:     Epoch: 55
2022-11-23 02:42:00,729 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8460219908844341, 'Total loss': 0.8460219908844341} | train loss {'Reaction outcome loss': 0.827421140099163, 'Total loss': 0.827421140099163}
2022-11-23 02:42:00,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:00,730 INFO:     Epoch: 56
2022-11-23 02:42:01,573 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.83787244761532, 'Total loss': 0.83787244761532} | train loss {'Reaction outcome loss': 0.8244025777226035, 'Total loss': 0.8244025777226035}
2022-11-23 02:42:01,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:01,573 INFO:     Epoch: 57
2022-11-23 02:42:02,419 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8719142526388168, 'Total loss': 0.8719142526388168} | train loss {'Reaction outcome loss': 0.8191431406960796, 'Total loss': 0.8191431406960796}
2022-11-23 02:42:02,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:02,419 INFO:     Epoch: 58
2022-11-23 02:42:03,276 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8510263799266382, 'Total loss': 0.8510263799266382} | train loss {'Reaction outcome loss': 0.8261478875088788, 'Total loss': 0.8261478875088788}
2022-11-23 02:42:03,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:03,277 INFO:     Epoch: 59
2022-11-23 02:42:04,139 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.9002099497751757, 'Total loss': 0.9002099497751757} | train loss {'Reaction outcome loss': 0.8214657780853843, 'Total loss': 0.8214657780853843}
2022-11-23 02:42:04,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:04,139 INFO:     Epoch: 60
2022-11-23 02:42:05,062 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8422455482862212, 'Total loss': 0.8422455482862212} | train loss {'Reaction outcome loss': 0.8232892616557689, 'Total loss': 0.8232892616557689}
2022-11-23 02:42:05,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:05,062 INFO:     Epoch: 61
2022-11-23 02:42:05,977 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.859586582265117, 'Total loss': 0.859586582265117} | train loss {'Reaction outcome loss': 0.8281150443049577, 'Total loss': 0.8281150443049577}
2022-11-23 02:42:05,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:05,977 INFO:     Epoch: 62
2022-11-23 02:42:06,848 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8595774492079561, 'Total loss': 0.8595774492079561} | train loss {'Reaction outcome loss': 0.8260026203717298, 'Total loss': 0.8260026203717298}
2022-11-23 02:42:06,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:06,849 INFO:     Epoch: 63
2022-11-23 02:42:07,730 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.865154354409738, 'Total loss': 0.865154354409738} | train loss {'Reaction outcome loss': 0.8268537042051675, 'Total loss': 0.8268537042051675}
2022-11-23 02:42:07,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:07,730 INFO:     Epoch: 64
2022-11-23 02:42:08,630 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8505249924280427, 'Total loss': 0.8505249924280427} | train loss {'Reaction outcome loss': 0.8258522214435855, 'Total loss': 0.8258522214435855}
2022-11-23 02:42:08,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:08,631 INFO:     Epoch: 65
2022-11-23 02:42:09,517 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8566239286552776, 'Total loss': 0.8566239286552776} | train loss {'Reaction outcome loss': 0.8274469327347481, 'Total loss': 0.8274469327347481}
2022-11-23 02:42:09,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:09,517 INFO:     Epoch: 66
2022-11-23 02:42:10,458 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8414928608319976, 'Total loss': 0.8414928608319976} | train loss {'Reaction outcome loss': 0.8301185091980073, 'Total loss': 0.8301185091980073}
2022-11-23 02:42:10,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:10,458 INFO:     Epoch: 67
2022-11-23 02:42:11,381 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8507800969210538, 'Total loss': 0.8507800969210538} | train loss {'Reaction outcome loss': 0.8261898061946819, 'Total loss': 0.8261898061946819}
2022-11-23 02:42:11,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:11,381 INFO:     Epoch: 68
2022-11-23 02:42:12,327 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8460566841743209, 'Total loss': 0.8460566841743209} | train loss {'Reaction outcome loss': 0.8301478969423395, 'Total loss': 0.8301478969423395}
2022-11-23 02:42:12,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:12,328 INFO:     Epoch: 69
2022-11-23 02:42:13,230 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.862761564552784, 'Total loss': 0.862761564552784} | train loss {'Reaction outcome loss': 0.8241984846620907, 'Total loss': 0.8241984846620907}
2022-11-23 02:42:13,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:13,231 INFO:     Epoch: 70
2022-11-23 02:42:14,163 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8615356534719467, 'Total loss': 0.8615356534719467} | train loss {'Reaction outcome loss': 0.8276084206606212, 'Total loss': 0.8276084206606212}
2022-11-23 02:42:14,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:14,163 INFO:     Epoch: 71
2022-11-23 02:42:15,083 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8498415107076819, 'Total loss': 0.8498415107076819} | train loss {'Reaction outcome loss': 0.8319370828659428, 'Total loss': 0.8319370828659428}
2022-11-23 02:42:15,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:15,084 INFO:     Epoch: 72
2022-11-23 02:42:15,978 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8630233813415874, 'Total loss': 0.8630233813415874} | train loss {'Reaction outcome loss': 0.8247695600214274, 'Total loss': 0.8247695600214274}
2022-11-23 02:42:15,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:15,978 INFO:     Epoch: 73
2022-11-23 02:42:16,838 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8407647271047939, 'Total loss': 0.8407647271047939} | train loss {'Reaction outcome loss': 0.8183068586928159, 'Total loss': 0.8183068586928159}
2022-11-23 02:42:16,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:16,838 INFO:     Epoch: 74
2022-11-23 02:42:17,760 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.862000739032572, 'Total loss': 0.862000739032572} | train loss {'Reaction outcome loss': 0.8249324169236156, 'Total loss': 0.8249324169236156}
2022-11-23 02:42:17,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:17,760 INFO:     Epoch: 75
2022-11-23 02:42:18,601 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8602928126400168, 'Total loss': 0.8602928126400168} | train loss {'Reaction outcome loss': 0.8254146907734967, 'Total loss': 0.8254146907734967}
2022-11-23 02:42:18,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:18,602 INFO:     Epoch: 76
2022-11-23 02:42:19,508 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8425506820732896, 'Total loss': 0.8425506820732896} | train loss {'Reaction outcome loss': 0.8266988990277897, 'Total loss': 0.8266988990277897}
2022-11-23 02:42:19,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:19,509 INFO:     Epoch: 77
2022-11-23 02:42:20,410 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8533424992452968, 'Total loss': 0.8533424992452968} | train loss {'Reaction outcome loss': 0.8292784836852116, 'Total loss': 0.8292784836852116}
2022-11-23 02:42:20,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:20,410 INFO:     Epoch: 78
2022-11-23 02:42:21,282 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8514177535067905, 'Total loss': 0.8514177535067905} | train loss {'Reaction outcome loss': 0.8292472541090931, 'Total loss': 0.8292472541090931}
2022-11-23 02:42:21,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:21,282 INFO:     Epoch: 79
2022-11-23 02:42:22,105 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8552383604374799, 'Total loss': 0.8552383604374799} | train loss {'Reaction outcome loss': 0.8368307775572726, 'Total loss': 0.8368307775572726}
2022-11-23 02:42:22,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:22,105 INFO:     Epoch: 80
2022-11-23 02:42:22,923 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8530528369275007, 'Total loss': 0.8530528369275007} | train loss {'Reaction outcome loss': 0.8375067634862444, 'Total loss': 0.8375067634862444}
2022-11-23 02:42:22,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:22,924 INFO:     Epoch: 81
2022-11-23 02:42:23,772 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8583801727403294, 'Total loss': 0.8583801727403294} | train loss {'Reaction outcome loss': 0.8255506034804742, 'Total loss': 0.8255506034804742}
2022-11-23 02:42:23,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:23,773 INFO:     Epoch: 82
2022-11-23 02:42:24,678 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8445364399389788, 'Total loss': 0.8445364399389788} | train loss {'Reaction outcome loss': 0.8221757154957003, 'Total loss': 0.8221757154957003}
2022-11-23 02:42:24,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:24,679 INFO:     Epoch: 83
2022-11-23 02:42:25,547 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.879225688224489, 'Total loss': 0.879225688224489} | train loss {'Reaction outcome loss': 0.8258006279526452, 'Total loss': 0.8258006279526452}
2022-11-23 02:42:25,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:25,547 INFO:     Epoch: 84
2022-11-23 02:42:26,412 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8519018170508471, 'Total loss': 0.8519018170508471} | train loss {'Reaction outcome loss': 0.8261397313251186, 'Total loss': 0.8261397313251186}
2022-11-23 02:42:26,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:26,413 INFO:     Epoch: 85
2022-11-23 02:42:27,289 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8559435646642338, 'Total loss': 0.8559435646642338} | train loss {'Reaction outcome loss': 0.8301806963889705, 'Total loss': 0.8301806963889705}
2022-11-23 02:42:27,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:27,290 INFO:     Epoch: 86
2022-11-23 02:42:28,127 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8432662134820764, 'Total loss': 0.8432662134820764} | train loss {'Reaction outcome loss': 0.8238322238328486, 'Total loss': 0.8238322238328486}
2022-11-23 02:42:28,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:28,128 INFO:     Epoch: 87
2022-11-23 02:42:29,047 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8353168747641824, 'Total loss': 0.8353168747641824} | train loss {'Reaction outcome loss': 0.8240630071655459, 'Total loss': 0.8240630071655459}
2022-11-23 02:42:29,047 INFO:     Found new best model at epoch 87
2022-11-23 02:42:29,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:29,048 INFO:     Epoch: 88
2022-11-23 02:42:29,905 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8518968989903276, 'Total loss': 0.8518968989903276} | train loss {'Reaction outcome loss': 0.8213054765211908, 'Total loss': 0.8213054765211908}
2022-11-23 02:42:29,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:29,905 INFO:     Epoch: 89
2022-11-23 02:42:30,798 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8509190624410455, 'Total loss': 0.8509190624410455} | train loss {'Reaction outcome loss': 0.8258409010253938, 'Total loss': 0.8258409010253938}
2022-11-23 02:42:30,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:30,799 INFO:     Epoch: 90
2022-11-23 02:42:31,661 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8429777920246124, 'Total loss': 0.8429777920246124} | train loss {'Reaction outcome loss': 0.8221419296766582, 'Total loss': 0.8221419296766582}
2022-11-23 02:42:31,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:31,661 INFO:     Epoch: 91
2022-11-23 02:42:32,536 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8540031490000811, 'Total loss': 0.8540031490000811} | train loss {'Reaction outcome loss': 0.8220164068194054, 'Total loss': 0.8220164068194054}
2022-11-23 02:42:32,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:32,536 INFO:     Epoch: 92
2022-11-23 02:42:33,457 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8369114344770258, 'Total loss': 0.8369114344770258} | train loss {'Reaction outcome loss': 0.8201278766488981, 'Total loss': 0.8201278766488981}
2022-11-23 02:42:33,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:33,457 INFO:     Epoch: 93
2022-11-23 02:42:34,366 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.856875210323117, 'Total loss': 0.856875210323117} | train loss {'Reaction outcome loss': 0.8276926606048939, 'Total loss': 0.8276926606048939}
2022-11-23 02:42:34,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:34,366 INFO:     Epoch: 94
2022-11-23 02:42:35,236 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8560516820712523, 'Total loss': 0.8560516820712523} | train loss {'Reaction outcome loss': 0.8223646926252466, 'Total loss': 0.8223646926252466}
2022-11-23 02:42:35,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:35,236 INFO:     Epoch: 95
2022-11-23 02:42:36,055 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8604698316617445, 'Total loss': 0.8604698316617445} | train loss {'Reaction outcome loss': 0.824130728539185, 'Total loss': 0.824130728539185}
2022-11-23 02:42:36,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:36,055 INFO:     Epoch: 96
2022-11-23 02:42:36,886 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8372268121350895, 'Total loss': 0.8372268121350895} | train loss {'Reaction outcome loss': 0.8192019308596729, 'Total loss': 0.8192019308596729}
2022-11-23 02:42:36,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:36,886 INFO:     Epoch: 97
2022-11-23 02:42:37,726 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8610732745040547, 'Total loss': 0.8610732745040547} | train loss {'Reaction outcome loss': 0.8252705615541713, 'Total loss': 0.8252705615541713}
2022-11-23 02:42:37,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:37,726 INFO:     Epoch: 98
2022-11-23 02:42:38,613 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8508385833014142, 'Total loss': 0.8508385833014142} | train loss {'Reaction outcome loss': 0.8321299943846729, 'Total loss': 0.8321299943846729}
2022-11-23 02:42:38,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:38,613 INFO:     Epoch: 99
2022-11-23 02:42:39,496 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8630849380384792, 'Total loss': 0.8630849380384792} | train loss {'Reaction outcome loss': 0.8284040537741986, 'Total loss': 0.8284040537741986}
2022-11-23 02:42:39,497 INFO:     Best model found after epoch 88 of 100.
2022-11-23 02:42:39,497 INFO:   Done with stage: TRAINING
2022-11-23 02:42:39,497 INFO:   Starting stage: EVALUATION
2022-11-23 02:42:39,624 INFO:   Done with stage: EVALUATION
2022-11-23 02:42:39,624 INFO:   Leaving out SEQ value Fold_1
2022-11-23 02:42:39,637 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 02:42:39,638 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:42:40,317 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:42:40,319 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:42:40,395 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:42:40,395 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:42:40,395 INFO:     No hyperparam tuning for this model
2022-11-23 02:42:40,395 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:42:40,395 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:42:40,396 INFO:     None feature selector for col prot
2022-11-23 02:42:40,396 INFO:     None feature selector for col prot
2022-11-23 02:42:40,396 INFO:     None feature selector for col prot
2022-11-23 02:42:40,397 INFO:     None feature selector for col chem
2022-11-23 02:42:40,397 INFO:     None feature selector for col chem
2022-11-23 02:42:40,397 INFO:     None feature selector for col chem
2022-11-23 02:42:40,397 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:42:40,397 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:42:40,399 INFO:     Number of params in model 168571
2022-11-23 02:42:40,402 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:42:40,402 INFO:   Starting stage: TRAINING
2022-11-23 02:42:40,463 INFO:     Val loss before train {'Reaction outcome loss': 1.0073200992562554, 'Total loss': 1.0073200992562554}
2022-11-23 02:42:40,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:40,463 INFO:     Epoch: 0
2022-11-23 02:42:41,342 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8745101446455176, 'Total loss': 0.8745101446455176} | train loss {'Reaction outcome loss': 0.8740434762437334, 'Total loss': 0.8740434762437334}
2022-11-23 02:42:41,342 INFO:     Found new best model at epoch 0
2022-11-23 02:42:41,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:41,343 INFO:     Epoch: 1
2022-11-23 02:42:42,205 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8336527611721646, 'Total loss': 0.8336527611721646} | train loss {'Reaction outcome loss': 0.8485206672054554, 'Total loss': 0.8485206672054554}
2022-11-23 02:42:42,205 INFO:     Found new best model at epoch 1
2022-11-23 02:42:42,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:42,206 INFO:     Epoch: 2
2022-11-23 02:42:43,047 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8358652557839047, 'Total loss': 0.8358652557839047} | train loss {'Reaction outcome loss': 0.8385350228803843, 'Total loss': 0.8385350228803843}
2022-11-23 02:42:43,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:43,048 INFO:     Epoch: 3
2022-11-23 02:42:43,900 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8318838666785847, 'Total loss': 0.8318838666785847} | train loss {'Reaction outcome loss': 0.8390619764443834, 'Total loss': 0.8390619764443834}
2022-11-23 02:42:43,900 INFO:     Found new best model at epoch 3
2022-11-23 02:42:43,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:43,901 INFO:     Epoch: 4
2022-11-23 02:42:44,775 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.816966865550388, 'Total loss': 0.816966865550388} | train loss {'Reaction outcome loss': 0.8493044924156868, 'Total loss': 0.8493044924156868}
2022-11-23 02:42:44,775 INFO:     Found new best model at epoch 4
2022-11-23 02:42:44,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:44,776 INFO:     Epoch: 5
2022-11-23 02:42:45,645 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8301744901321151, 'Total loss': 0.8301744901321151} | train loss {'Reaction outcome loss': 0.8305952024348231, 'Total loss': 0.8305952024348231}
2022-11-23 02:42:45,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:45,646 INFO:     Epoch: 6
2022-11-23 02:42:46,514 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8075744651935317, 'Total loss': 0.8075744651935317} | train loss {'Reaction outcome loss': 0.8340546037504065, 'Total loss': 0.8340546037504065}
2022-11-23 02:42:46,515 INFO:     Found new best model at epoch 6
2022-11-23 02:42:46,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:46,516 INFO:     Epoch: 7
2022-11-23 02:42:47,369 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8282132202928717, 'Total loss': 0.8282132202928717} | train loss {'Reaction outcome loss': 0.8334375034701004, 'Total loss': 0.8334375034701004}
2022-11-23 02:42:47,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:47,369 INFO:     Epoch: 8
2022-11-23 02:42:48,228 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8060702173547312, 'Total loss': 0.8060702173547312} | train loss {'Reaction outcome loss': 0.8328157780081155, 'Total loss': 0.8328157780081155}
2022-11-23 02:42:48,228 INFO:     Found new best model at epoch 8
2022-11-23 02:42:48,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:48,229 INFO:     Epoch: 9
2022-11-23 02:42:49,098 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8161217854781584, 'Total loss': 0.8161217854781584} | train loss {'Reaction outcome loss': 0.8280735896968165, 'Total loss': 0.8280735896968165}
2022-11-23 02:42:49,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:49,099 INFO:     Epoch: 10
2022-11-23 02:42:49,959 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.82354551282796, 'Total loss': 0.82354551282796} | train loss {'Reaction outcome loss': 0.822649638541797, 'Total loss': 0.822649638541797}
2022-11-23 02:42:49,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:49,959 INFO:     Epoch: 11
2022-11-23 02:42:50,833 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7917084531350569, 'Total loss': 0.7917084531350569} | train loss {'Reaction outcome loss': 0.8352661016981612, 'Total loss': 0.8352661016981612}
2022-11-23 02:42:50,833 INFO:     Found new best model at epoch 11
2022-11-23 02:42:50,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:50,834 INFO:     Epoch: 12
2022-11-23 02:42:51,645 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8096159134398807, 'Total loss': 0.8096159134398807} | train loss {'Reaction outcome loss': 0.8242553508716074, 'Total loss': 0.8242553508716074}
2022-11-23 02:42:51,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:51,645 INFO:     Epoch: 13
2022-11-23 02:42:52,529 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8022050904956731, 'Total loss': 0.8022050904956731} | train loss {'Reaction outcome loss': 0.8201115560917719, 'Total loss': 0.8201115560917719}
2022-11-23 02:42:52,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:52,529 INFO:     Epoch: 14
2022-11-23 02:42:53,406 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8262801387093284, 'Total loss': 0.8262801387093284} | train loss {'Reaction outcome loss': 0.824033528928332, 'Total loss': 0.824033528928332}
2022-11-23 02:42:53,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:53,406 INFO:     Epoch: 15
2022-11-23 02:42:54,267 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8178639445792545, 'Total loss': 0.8178639445792545} | train loss {'Reaction outcome loss': 0.8246342604942167, 'Total loss': 0.8246342604942167}
2022-11-23 02:42:54,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:54,267 INFO:     Epoch: 16
2022-11-23 02:42:55,113 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8088593537157233, 'Total loss': 0.8088593537157233} | train loss {'Reaction outcome loss': 0.8221424756503781, 'Total loss': 0.8221424756503781}
2022-11-23 02:42:55,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:55,114 INFO:     Epoch: 17
2022-11-23 02:42:55,969 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8098374916748567, 'Total loss': 0.8098374916748567} | train loss {'Reaction outcome loss': 0.8209470245037002, 'Total loss': 0.8209470245037002}
2022-11-23 02:42:55,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:55,970 INFO:     Epoch: 18
2022-11-23 02:42:56,822 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8176840015433051, 'Total loss': 0.8176840015433051} | train loss {'Reaction outcome loss': 0.8227261219188752, 'Total loss': 0.8227261219188752}
2022-11-23 02:42:56,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:56,822 INFO:     Epoch: 19
2022-11-23 02:42:57,672 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7918217988176779, 'Total loss': 0.7918217988176779} | train loss {'Reaction outcome loss': 0.826840897441393, 'Total loss': 0.826840897441393}
2022-11-23 02:42:57,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:57,673 INFO:     Epoch: 20
2022-11-23 02:42:58,533 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8069195645776662, 'Total loss': 0.8069195645776662} | train loss {'Reaction outcome loss': 0.8193126292484492, 'Total loss': 0.8193126292484492}
2022-11-23 02:42:58,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:58,534 INFO:     Epoch: 21
2022-11-23 02:42:59,370 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8299763358452104, 'Total loss': 0.8299763358452104} | train loss {'Reaction outcome loss': 0.8134325659166464, 'Total loss': 0.8134325659166464}
2022-11-23 02:42:59,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:42:59,370 INFO:     Epoch: 22
2022-11-23 02:43:00,217 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8090819608081471, 'Total loss': 0.8090819608081471} | train loss {'Reaction outcome loss': 0.8160438747541142, 'Total loss': 0.8160438747541142}
2022-11-23 02:43:00,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:00,217 INFO:     Epoch: 23
2022-11-23 02:43:01,110 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8329379416324876, 'Total loss': 0.8329379416324876} | train loss {'Reaction outcome loss': 0.8145473003387451, 'Total loss': 0.8145473003387451}
2022-11-23 02:43:01,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:01,111 INFO:     Epoch: 24
2022-11-23 02:43:01,934 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8065686991268938, 'Total loss': 0.8065686991268938} | train loss {'Reaction outcome loss': 0.8199617180988373, 'Total loss': 0.8199617180988373}
2022-11-23 02:43:01,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:01,935 INFO:     Epoch: 25
2022-11-23 02:43:02,745 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8034468374469064, 'Total loss': 0.8034468374469064} | train loss {'Reaction outcome loss': 0.8177309170787633, 'Total loss': 0.8177309170787633}
2022-11-23 02:43:02,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:02,745 INFO:     Epoch: 26
2022-11-23 02:43:03,606 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.805694231255488, 'Total loss': 0.805694231255488} | train loss {'Reaction outcome loss': 0.8223325802005736, 'Total loss': 0.8223325802005736}
2022-11-23 02:43:03,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:03,606 INFO:     Epoch: 27
2022-11-23 02:43:04,417 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8279890221628275, 'Total loss': 0.8279890221628275} | train loss {'Reaction outcome loss': 0.8176073125499462, 'Total loss': 0.8176073125499462}
2022-11-23 02:43:04,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:04,417 INFO:     Epoch: 28
2022-11-23 02:43:05,273 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8039518648927862, 'Total loss': 0.8039518648927862} | train loss {'Reaction outcome loss': 0.8173653628179419, 'Total loss': 0.8173653628179419}
2022-11-23 02:43:05,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:05,274 INFO:     Epoch: 29
2022-11-23 02:43:06,065 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7986233938824047, 'Total loss': 0.7986233938824047} | train loss {'Reaction outcome loss': 0.8136578891200092, 'Total loss': 0.8136578891200092}
2022-11-23 02:43:06,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:06,065 INFO:     Epoch: 30
2022-11-23 02:43:06,923 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8091580413959243, 'Total loss': 0.8091580413959243} | train loss {'Reaction outcome loss': 0.8188619063450739, 'Total loss': 0.8188619063450739}
2022-11-23 02:43:06,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:06,924 INFO:     Epoch: 31
2022-11-23 02:43:07,765 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8837075585668738, 'Total loss': 0.8837075585668738} | train loss {'Reaction outcome loss': 0.8149756124688063, 'Total loss': 0.8149756124688063}
2022-11-23 02:43:07,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:07,766 INFO:     Epoch: 32
2022-11-23 02:43:08,542 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8032089783386751, 'Total loss': 0.8032089783386751} | train loss {'Reaction outcome loss': 0.811600544433362, 'Total loss': 0.811600544433362}
2022-11-23 02:43:08,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:08,542 INFO:     Epoch: 33
2022-11-23 02:43:09,352 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8496496331962672, 'Total loss': 0.8496496331962672} | train loss {'Reaction outcome loss': 0.8179865194718364, 'Total loss': 0.8179865194718364}
2022-11-23 02:43:09,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:09,352 INFO:     Epoch: 34
2022-11-23 02:43:10,146 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8015314164486799, 'Total loss': 0.8015314164486799} | train loss {'Reaction outcome loss': 0.8337568283563683, 'Total loss': 0.8337568283563683}
2022-11-23 02:43:10,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:10,146 INFO:     Epoch: 35
2022-11-23 02:43:10,956 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8547681719064713, 'Total loss': 0.8547681719064713} | train loss {'Reaction outcome loss': 0.8224674963999373, 'Total loss': 0.8224674963999373}
2022-11-23 02:43:10,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:10,957 INFO:     Epoch: 36
2022-11-23 02:43:11,800 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8058284243399446, 'Total loss': 0.8058284243399446} | train loss {'Reaction outcome loss': 0.820098491272463, 'Total loss': 0.820098491272463}
2022-11-23 02:43:11,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:11,801 INFO:     Epoch: 37
2022-11-23 02:43:12,612 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8128656419840726, 'Total loss': 0.8128656419840726} | train loss {'Reaction outcome loss': 0.8114643125579908, 'Total loss': 0.8114643125579908}
2022-11-23 02:43:12,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:12,612 INFO:     Epoch: 38
2022-11-23 02:43:13,432 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8132857951250944, 'Total loss': 0.8132857951250944} | train loss {'Reaction outcome loss': 0.8187470788415144, 'Total loss': 0.8187470788415144}
2022-11-23 02:43:13,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:13,432 INFO:     Epoch: 39
2022-11-23 02:43:14,225 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.827438088980588, 'Total loss': 0.827438088980588} | train loss {'Reaction outcome loss': 0.81298311057723, 'Total loss': 0.81298311057723}
2022-11-23 02:43:14,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:14,225 INFO:     Epoch: 40
2022-11-23 02:43:15,055 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.794553816318512, 'Total loss': 0.794553816318512} | train loss {'Reaction outcome loss': 0.8130091145664815, 'Total loss': 0.8130091145664815}
2022-11-23 02:43:15,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:15,056 INFO:     Epoch: 41
2022-11-23 02:43:15,858 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8093484782359817, 'Total loss': 0.8093484782359817} | train loss {'Reaction outcome loss': 0.8218232073523255, 'Total loss': 0.8218232073523255}
2022-11-23 02:43:15,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:15,859 INFO:     Epoch: 42
2022-11-23 02:43:16,663 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8083046051588926, 'Total loss': 0.8083046051588926} | train loss {'Reaction outcome loss': 0.834793639327833, 'Total loss': 0.834793639327833}
2022-11-23 02:43:16,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:16,663 INFO:     Epoch: 43
2022-11-23 02:43:17,462 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7979100773280318, 'Total loss': 0.7979100773280318} | train loss {'Reaction outcome loss': 0.8215639396958988, 'Total loss': 0.8215639396958988}
2022-11-23 02:43:17,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:17,462 INFO:     Epoch: 44
2022-11-23 02:43:18,292 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7887170714410868, 'Total loss': 0.7887170714410868} | train loss {'Reaction outcome loss': 0.8153260771471721, 'Total loss': 0.8153260771471721}
2022-11-23 02:43:18,292 INFO:     Found new best model at epoch 44
2022-11-23 02:43:18,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:18,293 INFO:     Epoch: 45
2022-11-23 02:43:19,072 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8130781217054888, 'Total loss': 0.8130781217054888} | train loss {'Reaction outcome loss': 0.8099156146952016, 'Total loss': 0.8099156146952016}
2022-11-23 02:43:19,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:19,073 INFO:     Epoch: 46
2022-11-23 02:43:19,954 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.808520486409014, 'Total loss': 0.808520486409014} | train loss {'Reaction outcome loss': 0.8149522491070905, 'Total loss': 0.8149522491070905}
2022-11-23 02:43:19,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:19,954 INFO:     Epoch: 47
2022-11-23 02:43:20,758 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7894164743748578, 'Total loss': 0.7894164743748578} | train loss {'Reaction outcome loss': 0.8179449242377571, 'Total loss': 0.8179449242377571}
2022-11-23 02:43:20,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:20,758 INFO:     Epoch: 48
2022-11-23 02:43:21,541 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8283679620786146, 'Total loss': 0.8283679620786146} | train loss {'Reaction outcome loss': 0.8113759169694383, 'Total loss': 0.8113759169694383}
2022-11-23 02:43:21,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:21,541 INFO:     Epoch: 49
2022-11-23 02:43:22,330 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7995151633566077, 'Total loss': 0.7995151633566077} | train loss {'Reaction outcome loss': 0.8157350302707811, 'Total loss': 0.8157350302707811}
2022-11-23 02:43:22,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:22,331 INFO:     Epoch: 50
2022-11-23 02:43:23,111 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8152308050881732, 'Total loss': 0.8152308050881732} | train loss {'Reaction outcome loss': 0.812762901488586, 'Total loss': 0.812762901488586}
2022-11-23 02:43:23,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:23,112 INFO:     Epoch: 51
2022-11-23 02:43:23,982 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.816121678460728, 'Total loss': 0.816121678460728} | train loss {'Reaction outcome loss': 0.8183514017325181, 'Total loss': 0.8183514017325181}
2022-11-23 02:43:23,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:23,982 INFO:     Epoch: 52
2022-11-23 02:43:24,795 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7970111735842444, 'Total loss': 0.7970111735842444} | train loss {'Reaction outcome loss': 0.8182603783211727, 'Total loss': 0.8182603783211727}
2022-11-23 02:43:24,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:24,795 INFO:     Epoch: 53
2022-11-23 02:43:25,601 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7991850132291968, 'Total loss': 0.7991850132291968} | train loss {'Reaction outcome loss': 0.8206035196781158, 'Total loss': 0.8206035196781158}
2022-11-23 02:43:25,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:25,602 INFO:     Epoch: 54
2022-11-23 02:43:26,412 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.808566271581433, 'Total loss': 0.808566271581433} | train loss {'Reaction outcome loss': 0.8115138196752139, 'Total loss': 0.8115138196752139}
2022-11-23 02:43:26,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:26,412 INFO:     Epoch: 55
2022-11-23 02:43:27,243 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8133167346770113, 'Total loss': 0.8133167346770113} | train loss {'Reaction outcome loss': 0.8128930740510887, 'Total loss': 0.8128930740510887}
2022-11-23 02:43:27,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:27,243 INFO:     Epoch: 56
2022-11-23 02:43:28,022 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8211782276630402, 'Total loss': 0.8211782276630402} | train loss {'Reaction outcome loss': 0.8191902151233271, 'Total loss': 0.8191902151233271}
2022-11-23 02:43:28,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:28,023 INFO:     Epoch: 57
2022-11-23 02:43:28,823 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8058859428221529, 'Total loss': 0.8058859428221529} | train loss {'Reaction outcome loss': 0.8212524250692684, 'Total loss': 0.8212524250692684}
2022-11-23 02:43:28,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:28,823 INFO:     Epoch: 58
2022-11-23 02:43:29,649 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8317909857088869, 'Total loss': 0.8317909857088869} | train loss {'Reaction outcome loss': 0.8212462240143826, 'Total loss': 0.8212462240143826}
2022-11-23 02:43:29,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:29,651 INFO:     Epoch: 59
2022-11-23 02:43:30,479 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8173200176520781, 'Total loss': 0.8173200176520781} | train loss {'Reaction outcome loss': 0.8172965422725147, 'Total loss': 0.8172965422725147}
2022-11-23 02:43:30,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:30,480 INFO:     Epoch: 60
2022-11-23 02:43:31,346 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8251305642453107, 'Total loss': 0.8251305642453107} | train loss {'Reaction outcome loss': 0.815875503472109, 'Total loss': 0.815875503472109}
2022-11-23 02:43:31,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:31,347 INFO:     Epoch: 61
2022-11-23 02:43:32,165 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8048313544555143, 'Total loss': 0.8048313544555143} | train loss {'Reaction outcome loss': 0.815163000935485, 'Total loss': 0.815163000935485}
2022-11-23 02:43:32,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:32,165 INFO:     Epoch: 62
2022-11-23 02:43:33,009 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8221462484110486, 'Total loss': 0.8221462484110486} | train loss {'Reaction outcome loss': 0.8111058305873562, 'Total loss': 0.8111058305873562}
2022-11-23 02:43:33,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:33,009 INFO:     Epoch: 63
2022-11-23 02:43:33,859 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8080818287350915, 'Total loss': 0.8080818287350915} | train loss {'Reaction outcome loss': 0.8168062372246252, 'Total loss': 0.8168062372246252}
2022-11-23 02:43:33,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:33,859 INFO:     Epoch: 64
2022-11-23 02:43:34,699 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8014551435004581, 'Total loss': 0.8014551435004581} | train loss {'Reaction outcome loss': 0.8142163981551583, 'Total loss': 0.8142163981551583}
2022-11-23 02:43:34,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:34,700 INFO:     Epoch: 65
2022-11-23 02:43:35,478 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8188692019744352, 'Total loss': 0.8188692019744352} | train loss {'Reaction outcome loss': 0.812333354398397, 'Total loss': 0.812333354398397}
2022-11-23 02:43:35,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:35,479 INFO:     Epoch: 66
2022-11-23 02:43:36,309 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8016739907589826, 'Total loss': 0.8016739907589826} | train loss {'Reaction outcome loss': 0.8112305313469428, 'Total loss': 0.8112305313469428}
2022-11-23 02:43:36,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:36,309 INFO:     Epoch: 67
2022-11-23 02:43:37,145 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8042286526073109, 'Total loss': 0.8042286526073109} | train loss {'Reaction outcome loss': 0.8215714999538685, 'Total loss': 0.8215714999538685}
2022-11-23 02:43:37,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:37,146 INFO:     Epoch: 68
2022-11-23 02:43:37,991 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8008674762465737, 'Total loss': 0.8008674762465737} | train loss {'Reaction outcome loss': 0.8200512754048414, 'Total loss': 0.8200512754048414}
2022-11-23 02:43:37,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:37,991 INFO:     Epoch: 69
2022-11-23 02:43:38,779 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8158787963065234, 'Total loss': 0.8158787963065234} | train loss {'Reaction outcome loss': 0.8244594790433583, 'Total loss': 0.8244594790433583}
2022-11-23 02:43:38,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:38,780 INFO:     Epoch: 70
2022-11-23 02:43:39,612 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8348808640783484, 'Total loss': 0.8348808640783484} | train loss {'Reaction outcome loss': 0.8171547912815322, 'Total loss': 0.8171547912815322}
2022-11-23 02:43:39,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:39,613 INFO:     Epoch: 71
2022-11-23 02:43:40,404 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.835341409526088, 'Total loss': 0.835341409526088} | train loss {'Reaction outcome loss': 0.8149287145630069, 'Total loss': 0.8149287145630069}
2022-11-23 02:43:40,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:40,405 INFO:     Epoch: 72
2022-11-23 02:43:41,205 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.804838087071072, 'Total loss': 0.804838087071072} | train loss {'Reaction outcome loss': 0.8203516398605547, 'Total loss': 0.8203516398605547}
2022-11-23 02:43:41,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:41,205 INFO:     Epoch: 73
2022-11-23 02:43:41,984 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8058814108371735, 'Total loss': 0.8058814108371735} | train loss {'Reaction outcome loss': 0.8109406107953685, 'Total loss': 0.8109406107953685}
2022-11-23 02:43:41,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:41,985 INFO:     Epoch: 74
2022-11-23 02:43:42,831 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8283769969235767, 'Total loss': 0.8283769969235767} | train loss {'Reaction outcome loss': 0.81274229638007, 'Total loss': 0.81274229638007}
2022-11-23 02:43:42,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:42,832 INFO:     Epoch: 75
2022-11-23 02:43:43,641 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8049866394563154, 'Total loss': 0.8049866394563154} | train loss {'Reaction outcome loss': 0.8131598124378606, 'Total loss': 0.8131598124378606}
2022-11-23 02:43:43,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:43,641 INFO:     Epoch: 76
2022-11-23 02:43:44,440 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8055306361480192, 'Total loss': 0.8055306361480192} | train loss {'Reaction outcome loss': 0.8239914431021764, 'Total loss': 0.8239914431021764}
2022-11-23 02:43:44,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:44,441 INFO:     Epoch: 77
2022-11-23 02:43:45,276 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7923960238695145, 'Total loss': 0.7923960238695145} | train loss {'Reaction outcome loss': 0.8128994196532708, 'Total loss': 0.8128994196532708}
2022-11-23 02:43:45,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:45,276 INFO:     Epoch: 78
2022-11-23 02:43:46,074 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7940779409625314, 'Total loss': 0.7940779409625314} | train loss {'Reaction outcome loss': 0.8195873494090339, 'Total loss': 0.8195873494090339}
2022-11-23 02:43:46,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:46,074 INFO:     Epoch: 79
2022-11-23 02:43:46,885 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8022285916588523, 'Total loss': 0.8022285916588523} | train loss {'Reaction outcome loss': 0.8129586984030148, 'Total loss': 0.8129586984030148}
2022-11-23 02:43:46,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:46,885 INFO:     Epoch: 80
2022-11-23 02:43:47,671 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8234735043211416, 'Total loss': 0.8234735043211416} | train loss {'Reaction outcome loss': 0.8127420395461895, 'Total loss': 0.8127420395461895}
2022-11-23 02:43:47,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:47,671 INFO:     Epoch: 81
2022-11-23 02:43:48,455 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8297792063518004, 'Total loss': 0.8297792063518004} | train loss {'Reaction outcome loss': 0.8075194936471912, 'Total loss': 0.8075194936471912}
2022-11-23 02:43:48,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:48,456 INFO:     Epoch: 82
2022-11-23 02:43:49,313 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8299988305026834, 'Total loss': 0.8299988305026834} | train loss {'Reaction outcome loss': 0.8172514169563648, 'Total loss': 0.8172514169563648}
2022-11-23 02:43:49,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:49,313 INFO:     Epoch: 83
2022-11-23 02:43:50,115 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7999631437388334, 'Total loss': 0.7999631437388334} | train loss {'Reaction outcome loss': 0.8270039527039779, 'Total loss': 0.8270039527039779}
2022-11-23 02:43:50,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:50,115 INFO:     Epoch: 84
2022-11-23 02:43:50,893 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8020962300625715, 'Total loss': 0.8020962300625715} | train loss {'Reaction outcome loss': 0.8209207935130548, 'Total loss': 0.8209207935130548}
2022-11-23 02:43:50,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:50,894 INFO:     Epoch: 85
2022-11-23 02:43:51,682 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8141921162605286, 'Total loss': 0.8141921162605286} | train loss {'Reaction outcome loss': 0.8157444691609758, 'Total loss': 0.8157444691609758}
2022-11-23 02:43:51,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:51,683 INFO:     Epoch: 86
2022-11-23 02:43:52,488 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8104233145713806, 'Total loss': 0.8104233145713806} | train loss {'Reaction outcome loss': 0.8133167385572364, 'Total loss': 0.8133167385572364}
2022-11-23 02:43:52,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:52,489 INFO:     Epoch: 87
2022-11-23 02:43:53,282 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8049450807950713, 'Total loss': 0.8049450807950713} | train loss {'Reaction outcome loss': 0.8181374613572712, 'Total loss': 0.8181374613572712}
2022-11-23 02:43:53,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:53,282 INFO:     Epoch: 88
2022-11-23 02:43:54,090 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7891350469805978, 'Total loss': 0.7891350469805978} | train loss {'Reaction outcome loss': 0.8157080040286909, 'Total loss': 0.8157080040286909}
2022-11-23 02:43:54,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:54,090 INFO:     Epoch: 89
2022-11-23 02:43:54,888 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.796208187260411, 'Total loss': 0.796208187260411} | train loss {'Reaction outcome loss': 0.815502475268445, 'Total loss': 0.815502475268445}
2022-11-23 02:43:54,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:54,888 INFO:     Epoch: 90
2022-11-23 02:43:55,714 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8079209395430305, 'Total loss': 0.8079209395430305} | train loss {'Reaction outcome loss': 0.8169965891823595, 'Total loss': 0.8169965891823595}
2022-11-23 02:43:55,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:55,714 INFO:     Epoch: 91
2022-11-23 02:43:56,522 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8120272681117058, 'Total loss': 0.8120272681117058} | train loss {'Reaction outcome loss': 0.8159117499585093, 'Total loss': 0.8159117499585093}
2022-11-23 02:43:56,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:56,522 INFO:     Epoch: 92
2022-11-23 02:43:57,329 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8046116199005734, 'Total loss': 0.8046116199005734} | train loss {'Reaction outcome loss': 0.8131300840783215, 'Total loss': 0.8131300840783215}
2022-11-23 02:43:57,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:57,330 INFO:     Epoch: 93
2022-11-23 02:43:58,110 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8266604149883444, 'Total loss': 0.8266604149883444} | train loss {'Reaction outcome loss': 0.8127513147800075, 'Total loss': 0.8127513147800075}
2022-11-23 02:43:58,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:58,110 INFO:     Epoch: 94
2022-11-23 02:43:58,952 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8113466900858012, 'Total loss': 0.8113466900858012} | train loss {'Reaction outcome loss': 0.813533280240862, 'Total loss': 0.813533280240862}
2022-11-23 02:43:58,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:58,952 INFO:     Epoch: 95
2022-11-23 02:43:59,784 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8025346127423373, 'Total loss': 0.8025346127423373} | train loss {'Reaction outcome loss': 0.8154125540603993, 'Total loss': 0.8154125540603993}
2022-11-23 02:43:59,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:43:59,784 INFO:     Epoch: 96
2022-11-23 02:44:00,600 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8052135340192101, 'Total loss': 0.8052135340192101} | train loss {'Reaction outcome loss': 0.8154549674707868, 'Total loss': 0.8154549674707868}
2022-11-23 02:44:00,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:00,601 INFO:     Epoch: 97
2022-11-23 02:44:01,411 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7958835268562491, 'Total loss': 0.7958835268562491} | train loss {'Reaction outcome loss': 0.8176650550925297, 'Total loss': 0.8176650550925297}
2022-11-23 02:44:01,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:01,411 INFO:     Epoch: 98
2022-11-23 02:44:02,199 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8078216923908754, 'Total loss': 0.8078216923908754} | train loss {'Reaction outcome loss': 0.8133517155039166, 'Total loss': 0.8133517155039166}
2022-11-23 02:44:02,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:02,200 INFO:     Epoch: 99
2022-11-23 02:44:02,971 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7945573837919668, 'Total loss': 0.7945573837919668} | train loss {'Reaction outcome loss': 0.8130723446728247, 'Total loss': 0.8130723446728247}
2022-11-23 02:44:02,971 INFO:     Best model found after epoch 45 of 100.
2022-11-23 02:44:02,971 INFO:   Done with stage: TRAINING
2022-11-23 02:44:02,971 INFO:   Starting stage: EVALUATION
2022-11-23 02:44:03,097 INFO:   Done with stage: EVALUATION
2022-11-23 02:44:03,097 INFO:   Leaving out SEQ value Fold_2
2022-11-23 02:44:03,110 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-23 02:44:03,110 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:44:03,769 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:44:03,769 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:44:03,841 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:44:03,841 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:44:03,841 INFO:     No hyperparam tuning for this model
2022-11-23 02:44:03,841 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:44:03,841 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:44:03,842 INFO:     None feature selector for col prot
2022-11-23 02:44:03,842 INFO:     None feature selector for col prot
2022-11-23 02:44:03,842 INFO:     None feature selector for col prot
2022-11-23 02:44:03,843 INFO:     None feature selector for col chem
2022-11-23 02:44:03,843 INFO:     None feature selector for col chem
2022-11-23 02:44:03,843 INFO:     None feature selector for col chem
2022-11-23 02:44:03,843 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:44:03,843 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:44:03,845 INFO:     Number of params in model 168571
2022-11-23 02:44:03,848 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:44:03,848 INFO:   Starting stage: TRAINING
2022-11-23 02:44:03,909 INFO:     Val loss before train {'Reaction outcome loss': 1.0133017551067263, 'Total loss': 1.0133017551067263}
2022-11-23 02:44:03,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:03,909 INFO:     Epoch: 0
2022-11-23 02:44:04,717 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.831217814323514, 'Total loss': 0.831217814323514} | train loss {'Reaction outcome loss': 0.8794494244296855, 'Total loss': 0.8794494244296855}
2022-11-23 02:44:04,717 INFO:     Found new best model at epoch 0
2022-11-23 02:44:04,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:04,718 INFO:     Epoch: 1
2022-11-23 02:44:05,509 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8511338136916937, 'Total loss': 0.8511338136916937} | train loss {'Reaction outcome loss': 0.8498101996050941, 'Total loss': 0.8498101996050941}
2022-11-23 02:44:05,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:05,509 INFO:     Epoch: 2
2022-11-23 02:44:06,318 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8067420776500258, 'Total loss': 0.8067420776500258} | train loss {'Reaction outcome loss': 0.8390781451399925, 'Total loss': 0.8390781451399925}
2022-11-23 02:44:06,318 INFO:     Found new best model at epoch 2
2022-11-23 02:44:06,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:06,319 INFO:     Epoch: 3
2022-11-23 02:44:07,109 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8260102590849233, 'Total loss': 0.8260102590849233} | train loss {'Reaction outcome loss': 0.8346498976519079, 'Total loss': 0.8346498976519079}
2022-11-23 02:44:07,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:07,110 INFO:     Epoch: 4
2022-11-23 02:44:07,895 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8374772473823192, 'Total loss': 0.8374772473823192} | train loss {'Reaction outcome loss': 0.8304039650738485, 'Total loss': 0.8304039650738485}
2022-11-23 02:44:07,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:07,895 INFO:     Epoch: 5
2022-11-23 02:44:08,673 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.816743922094966, 'Total loss': 0.816743922094966} | train loss {'Reaction outcome loss': 0.8239445550206267, 'Total loss': 0.8239445550206267}
2022-11-23 02:44:08,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:08,673 INFO:     Epoch: 6
2022-11-23 02:44:09,447 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8032477359439052, 'Total loss': 0.8032477359439052} | train loss {'Reaction outcome loss': 0.825825985812356, 'Total loss': 0.825825985812356}
2022-11-23 02:44:09,447 INFO:     Found new best model at epoch 6
2022-11-23 02:44:09,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:09,448 INFO:     Epoch: 7
2022-11-23 02:44:10,279 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8204956130925999, 'Total loss': 0.8204956130925999} | train loss {'Reaction outcome loss': 0.8239678404458757, 'Total loss': 0.8239678404458757}
2022-11-23 02:44:10,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:10,279 INFO:     Epoch: 8
2022-11-23 02:44:11,046 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8030135409776554, 'Total loss': 0.8030135409776554} | train loss {'Reaction outcome loss': 0.8259392152597875, 'Total loss': 0.8259392152597875}
2022-11-23 02:44:11,046 INFO:     Found new best model at epoch 8
2022-11-23 02:44:11,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:11,047 INFO:     Epoch: 9
2022-11-23 02:44:11,784 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8134178110333377, 'Total loss': 0.8134178110333377} | train loss {'Reaction outcome loss': 0.8227597575619388, 'Total loss': 0.8227597575619388}
2022-11-23 02:44:11,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:11,785 INFO:     Epoch: 10
2022-11-23 02:44:12,602 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8295834854591725, 'Total loss': 0.8295834854591725} | train loss {'Reaction outcome loss': 0.8215102646576524, 'Total loss': 0.8215102646576524}
2022-11-23 02:44:12,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:12,603 INFO:     Epoch: 11
2022-11-23 02:44:13,465 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8128580832204153, 'Total loss': 0.8128580832204153} | train loss {'Reaction outcome loss': 0.8211309081978269, 'Total loss': 0.8211309081978269}
2022-11-23 02:44:13,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:13,465 INFO:     Epoch: 12
2022-11-23 02:44:14,260 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.814820877341337, 'Total loss': 0.814820877341337} | train loss {'Reaction outcome loss': 0.8169417917237851, 'Total loss': 0.8169417917237851}
2022-11-23 02:44:14,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:14,260 INFO:     Epoch: 13
2022-11-23 02:44:15,065 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8557369916938072, 'Total loss': 0.8557369916938072} | train loss {'Reaction outcome loss': 0.813605913654767, 'Total loss': 0.813605913654767}
2022-11-23 02:44:15,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:15,065 INFO:     Epoch: 14
2022-11-23 02:44:15,850 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8100458196429319, 'Total loss': 0.8100458196429319} | train loss {'Reaction outcome loss': 0.8192456683504238, 'Total loss': 0.8192456683504238}
2022-11-23 02:44:15,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:15,851 INFO:     Epoch: 15
2022-11-23 02:44:16,662 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8284793211970218, 'Total loss': 0.8284793211970218} | train loss {'Reaction outcome loss': 0.8166849713143989, 'Total loss': 0.8166849713143989}
2022-11-23 02:44:16,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:16,662 INFO:     Epoch: 16
2022-11-23 02:44:17,449 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8474902926489364, 'Total loss': 0.8474902926489364} | train loss {'Reaction outcome loss': 0.8155603605042759, 'Total loss': 0.8155603605042759}
2022-11-23 02:44:17,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:17,449 INFO:     Epoch: 17
2022-11-23 02:44:18,203 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8418657765832058, 'Total loss': 0.8418657765832058} | train loss {'Reaction outcome loss': 0.8168631117530321, 'Total loss': 0.8168631117530321}
2022-11-23 02:44:18,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:18,204 INFO:     Epoch: 18
2022-11-23 02:44:19,003 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8330406151538672, 'Total loss': 0.8330406151538672} | train loss {'Reaction outcome loss': 0.817856904778461, 'Total loss': 0.817856904778461}
2022-11-23 02:44:19,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:19,004 INFO:     Epoch: 19
2022-11-23 02:44:19,740 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7978332125863363, 'Total loss': 0.7978332125863363} | train loss {'Reaction outcome loss': 0.8205759462750988, 'Total loss': 0.8205759462750988}
2022-11-23 02:44:19,740 INFO:     Found new best model at epoch 19
2022-11-23 02:44:19,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:19,741 INFO:     Epoch: 20
2022-11-23 02:44:20,551 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8114425262739492, 'Total loss': 0.8114425262739492} | train loss {'Reaction outcome loss': 0.8209465764187001, 'Total loss': 0.8209465764187001}
2022-11-23 02:44:20,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:20,551 INFO:     Epoch: 21
2022-11-23 02:44:21,366 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7822706990463789, 'Total loss': 0.7822706990463789} | train loss {'Reaction outcome loss': 0.8142487038800745, 'Total loss': 0.8142487038800745}
2022-11-23 02:44:21,367 INFO:     Found new best model at epoch 21
2022-11-23 02:44:21,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:21,367 INFO:     Epoch: 22
2022-11-23 02:44:22,181 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8098618512929872, 'Total loss': 0.8098618512929872} | train loss {'Reaction outcome loss': 0.8153053425221777, 'Total loss': 0.8153053425221777}
2022-11-23 02:44:22,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:22,182 INFO:     Epoch: 23
2022-11-23 02:44:22,984 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7905100778091786, 'Total loss': 0.7905100778091786} | train loss {'Reaction outcome loss': 0.8120276296334993, 'Total loss': 0.8120276296334993}
2022-11-23 02:44:22,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:22,984 INFO:     Epoch: 24
2022-11-23 02:44:23,797 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.820525508287341, 'Total loss': 0.820525508287341} | train loss {'Reaction outcome loss': 0.8145273096031613, 'Total loss': 0.8145273096031613}
2022-11-23 02:44:23,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:23,797 INFO:     Epoch: 25
2022-11-23 02:44:24,555 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8078095199063767, 'Total loss': 0.8078095199063767} | train loss {'Reaction outcome loss': 0.814989806202704, 'Total loss': 0.814989806202704}
2022-11-23 02:44:24,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:24,557 INFO:     Epoch: 26
2022-11-23 02:44:25,368 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7884033211441928, 'Total loss': 0.7884033211441928} | train loss {'Reaction outcome loss': 0.8157780779977885, 'Total loss': 0.8157780779977885}
2022-11-23 02:44:25,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:25,369 INFO:     Epoch: 27
2022-11-23 02:44:26,162 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8008106544960377, 'Total loss': 0.8008106544960377} | train loss {'Reaction outcome loss': 0.817071244795136, 'Total loss': 0.817071244795136}
2022-11-23 02:44:26,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:26,163 INFO:     Epoch: 28
2022-11-23 02:44:26,933 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7928107491759366, 'Total loss': 0.7928107491759366} | train loss {'Reaction outcome loss': 0.8129369583394792, 'Total loss': 0.8129369583394792}
2022-11-23 02:44:26,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:26,934 INFO:     Epoch: 29
2022-11-23 02:44:27,715 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8048996960007867, 'Total loss': 0.8048996960007867} | train loss {'Reaction outcome loss': 0.813323997788959, 'Total loss': 0.813323997788959}
2022-11-23 02:44:27,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:27,715 INFO:     Epoch: 30
2022-11-23 02:44:28,514 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.810547927091288, 'Total loss': 0.810547927091288} | train loss {'Reaction outcome loss': 0.813636241994277, 'Total loss': 0.813636241994277}
2022-11-23 02:44:28,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:28,514 INFO:     Epoch: 31
2022-11-23 02:44:29,320 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8079742006091184, 'Total loss': 0.8079742006091184} | train loss {'Reaction outcome loss': 0.8126748277817244, 'Total loss': 0.8126748277817244}
2022-11-23 02:44:29,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:29,320 INFO:     Epoch: 32
2022-11-23 02:44:30,124 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7922378723011461, 'Total loss': 0.7922378723011461} | train loss {'Reaction outcome loss': 0.810891934137776, 'Total loss': 0.810891934137776}
2022-11-23 02:44:30,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:30,125 INFO:     Epoch: 33
2022-11-23 02:44:30,946 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8038513854492543, 'Total loss': 0.8038513854492543} | train loss {'Reaction outcome loss': 0.8145021369427811, 'Total loss': 0.8145021369427811}
2022-11-23 02:44:30,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:30,947 INFO:     Epoch: 34
2022-11-23 02:44:31,778 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8445639319198076, 'Total loss': 0.8445639319198076} | train loss {'Reaction outcome loss': 0.8160656915034776, 'Total loss': 0.8160656915034776}
2022-11-23 02:44:31,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:31,778 INFO:     Epoch: 35
2022-11-23 02:44:32,613 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8000423395356466, 'Total loss': 0.8000423395356466} | train loss {'Reaction outcome loss': 0.8099189988134329, 'Total loss': 0.8099189988134329}
2022-11-23 02:44:32,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:32,613 INFO:     Epoch: 36
2022-11-23 02:44:33,429 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8125979408275249, 'Total loss': 0.8125979408275249} | train loss {'Reaction outcome loss': 0.8159283872985055, 'Total loss': 0.8159283872985055}
2022-11-23 02:44:33,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:33,430 INFO:     Epoch: 37
2022-11-23 02:44:34,239 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8080021849898404, 'Total loss': 0.8080021849898404} | train loss {'Reaction outcome loss': 0.8121331459210243, 'Total loss': 0.8121331459210243}
2022-11-23 02:44:34,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:34,239 INFO:     Epoch: 38
2022-11-23 02:44:35,026 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8200496726257857, 'Total loss': 0.8200496726257857} | train loss {'Reaction outcome loss': 0.8115632955920059, 'Total loss': 0.8115632955920059}
2022-11-23 02:44:35,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:35,027 INFO:     Epoch: 39
2022-11-23 02:44:35,830 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8026906418245893, 'Total loss': 0.8026906418245893} | train loss {'Reaction outcome loss': 0.8219281905963097, 'Total loss': 0.8219281905963097}
2022-11-23 02:44:35,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:35,831 INFO:     Epoch: 40
2022-11-23 02:44:36,662 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7956538740978685, 'Total loss': 0.7956538740978685} | train loss {'Reaction outcome loss': 0.810628966539485, 'Total loss': 0.810628966539485}
2022-11-23 02:44:36,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:36,662 INFO:     Epoch: 41
2022-11-23 02:44:37,446 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7905888779218807, 'Total loss': 0.7905888779218807} | train loss {'Reaction outcome loss': 0.8161314285586401, 'Total loss': 0.8161314285586401}
2022-11-23 02:44:37,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:37,447 INFO:     Epoch: 42
2022-11-23 02:44:38,249 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.826959375725236, 'Total loss': 0.826959375725236} | train loss {'Reaction outcome loss': 0.8110965888931918, 'Total loss': 0.8110965888931918}
2022-11-23 02:44:38,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:38,250 INFO:     Epoch: 43
2022-11-23 02:44:39,032 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7908655910990959, 'Total loss': 0.7908655910990959} | train loss {'Reaction outcome loss': 0.8091567336531823, 'Total loss': 0.8091567336531823}
2022-11-23 02:44:39,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:39,032 INFO:     Epoch: 44
2022-11-23 02:44:39,863 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7938016673853231, 'Total loss': 0.7938016673853231} | train loss {'Reaction outcome loss': 0.810094499784242, 'Total loss': 0.810094499784242}
2022-11-23 02:44:39,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:39,863 INFO:     Epoch: 45
2022-11-23 02:44:40,693 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8062404345634372, 'Total loss': 0.8062404345634372} | train loss {'Reaction outcome loss': 0.8143177393042011, 'Total loss': 0.8143177393042011}
2022-11-23 02:44:40,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:40,694 INFO:     Epoch: 46
2022-11-23 02:44:41,472 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.804854353499967, 'Total loss': 0.804854353499967} | train loss {'Reaction outcome loss': 0.813851487366751, 'Total loss': 0.813851487366751}
2022-11-23 02:44:41,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:41,473 INFO:     Epoch: 47
2022-11-23 02:44:42,249 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.804496802562891, 'Total loss': 0.804496802562891} | train loss {'Reaction outcome loss': 0.8149650703977656, 'Total loss': 0.8149650703977656}
2022-11-23 02:44:42,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:42,250 INFO:     Epoch: 48
2022-11-23 02:44:43,022 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8090879605260006, 'Total loss': 0.8090879605260006} | train loss {'Reaction outcome loss': 0.8177280286212026, 'Total loss': 0.8177280286212026}
2022-11-23 02:44:43,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:43,023 INFO:     Epoch: 49
2022-11-23 02:44:43,821 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.828747643980869, 'Total loss': 0.828747643980869} | train loss {'Reaction outcome loss': 0.8121747658453851, 'Total loss': 0.8121747658453851}
2022-11-23 02:44:43,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:43,822 INFO:     Epoch: 50
2022-11-23 02:44:44,634 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8003600738769354, 'Total loss': 0.8003600738769354} | train loss {'Reaction outcome loss': 0.8218049272097678, 'Total loss': 0.8218049272097678}
2022-11-23 02:44:44,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:44,634 INFO:     Epoch: 51
2022-11-23 02:44:45,435 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8079214498054149, 'Total loss': 0.8079214498054149} | train loss {'Reaction outcome loss': 0.8117419563448478, 'Total loss': 0.8117419563448478}
2022-11-23 02:44:45,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:45,435 INFO:     Epoch: 52
2022-11-23 02:44:46,227 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7973769625952077, 'Total loss': 0.7973769625952077} | train loss {'Reaction outcome loss': 0.809653912306813, 'Total loss': 0.809653912306813}
2022-11-23 02:44:46,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:46,227 INFO:     Epoch: 53
2022-11-23 02:44:47,029 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8017251124215681, 'Total loss': 0.8017251124215681} | train loss {'Reaction outcome loss': 0.8165167475678793, 'Total loss': 0.8165167475678793}
2022-11-23 02:44:47,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:47,030 INFO:     Epoch: 54
2022-11-23 02:44:47,807 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7921814350194709, 'Total loss': 0.7921814350194709} | train loss {'Reaction outcome loss': 0.8176968060893777, 'Total loss': 0.8176968060893777}
2022-11-23 02:44:47,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:47,808 INFO:     Epoch: 55
2022-11-23 02:44:48,587 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8279264638590258, 'Total loss': 0.8279264638590258} | train loss {'Reaction outcome loss': 0.8104180033805439, 'Total loss': 0.8104180033805439}
2022-11-23 02:44:48,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:48,587 INFO:     Epoch: 56
2022-11-23 02:44:49,363 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8291665634443594, 'Total loss': 0.8291665634443594} | train loss {'Reaction outcome loss': 0.8133397895858121, 'Total loss': 0.8133397895858121}
2022-11-23 02:44:49,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:49,364 INFO:     Epoch: 57
2022-11-23 02:44:50,142 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.794150843869808, 'Total loss': 0.794150843869808} | train loss {'Reaction outcome loss': 0.8154490568019725, 'Total loss': 0.8154490568019725}
2022-11-23 02:44:50,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:50,143 INFO:     Epoch: 58
2022-11-23 02:44:50,928 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8545460222765456, 'Total loss': 0.8545460222765456} | train loss {'Reaction outcome loss': 0.812493329062874, 'Total loss': 0.812493329062874}
2022-11-23 02:44:50,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:50,928 INFO:     Epoch: 59
2022-11-23 02:44:51,742 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7966123029243114, 'Total loss': 0.7966123029243114} | train loss {'Reaction outcome loss': 0.8188219689783246, 'Total loss': 0.8188219689783246}
2022-11-23 02:44:51,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:51,743 INFO:     Epoch: 60
2022-11-23 02:44:52,559 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8092102048008941, 'Total loss': 0.8092102048008941} | train loss {'Reaction outcome loss': 0.8092056883215414, 'Total loss': 0.8092056883215414}
2022-11-23 02:44:52,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:52,559 INFO:     Epoch: 61
2022-11-23 02:44:53,399 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.798036222541055, 'Total loss': 0.798036222541055} | train loss {'Reaction outcome loss': 0.814309043158229, 'Total loss': 0.814309043158229}
2022-11-23 02:44:53,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:53,400 INFO:     Epoch: 62
2022-11-23 02:44:54,148 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8048469632170921, 'Total loss': 0.8048469632170921} | train loss {'Reaction outcome loss': 0.8196684611432347, 'Total loss': 0.8196684611432347}
2022-11-23 02:44:54,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:54,148 INFO:     Epoch: 63
2022-11-23 02:44:54,960 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7945912923923758, 'Total loss': 0.7945912923923758} | train loss {'Reaction outcome loss': 0.8121750084951581, 'Total loss': 0.8121750084951581}
2022-11-23 02:44:54,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:54,960 INFO:     Epoch: 64
2022-11-23 02:44:55,742 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8076914784520172, 'Total loss': 0.8076914784520172} | train loss {'Reaction outcome loss': 0.8179076225669296, 'Total loss': 0.8179076225669296}
2022-11-23 02:44:55,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:55,742 INFO:     Epoch: 65
2022-11-23 02:44:56,551 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8005759473456893, 'Total loss': 0.8005759473456893} | train loss {'Reaction outcome loss': 0.8138742905585363, 'Total loss': 0.8138742905585363}
2022-11-23 02:44:56,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:56,551 INFO:     Epoch: 66
2022-11-23 02:44:57,364 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7911211584889611, 'Total loss': 0.7911211584889611} | train loss {'Reaction outcome loss': 0.8155872625578579, 'Total loss': 0.8155872625578579}
2022-11-23 02:44:57,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:57,364 INFO:     Epoch: 67
2022-11-23 02:44:58,145 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8038509855436724, 'Total loss': 0.8038509855436724} | train loss {'Reaction outcome loss': 0.8148380521638894, 'Total loss': 0.8148380521638894}
2022-11-23 02:44:58,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:58,145 INFO:     Epoch: 68
2022-11-23 02:44:58,975 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7924540368623512, 'Total loss': 0.7924540368623512} | train loss {'Reaction outcome loss': 0.813203390978982, 'Total loss': 0.813203390978982}
2022-11-23 02:44:58,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:58,975 INFO:     Epoch: 69
2022-11-23 02:44:59,772 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8205270185027012, 'Total loss': 0.8205270185027012} | train loss {'Reaction outcome loss': 0.8188850446738334, 'Total loss': 0.8188850446738334}
2022-11-23 02:44:59,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:44:59,773 INFO:     Epoch: 70
2022-11-23 02:45:00,532 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7974088351393855, 'Total loss': 0.7974088351393855} | train loss {'Reaction outcome loss': 0.8182363524849032, 'Total loss': 0.8182363524849032}
2022-11-23 02:45:00,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:00,532 INFO:     Epoch: 71
2022-11-23 02:45:01,340 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8241193571756052, 'Total loss': 0.8241193571756052} | train loss {'Reaction outcome loss': 0.8107377008646114, 'Total loss': 0.8107377008646114}
2022-11-23 02:45:01,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:01,340 INFO:     Epoch: 72
2022-11-23 02:45:02,162 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.837214415156564, 'Total loss': 0.837214415156564} | train loss {'Reaction outcome loss': 0.8162869147557781, 'Total loss': 0.8162869147557781}
2022-11-23 02:45:02,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:02,162 INFO:     Epoch: 73
2022-11-23 02:45:02,973 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.790716546912526, 'Total loss': 0.790716546912526} | train loss {'Reaction outcome loss': 0.814781955730768, 'Total loss': 0.814781955730768}
2022-11-23 02:45:02,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:02,973 INFO:     Epoch: 74
2022-11-23 02:45:03,750 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8232679408650065, 'Total loss': 0.8232679408650065} | train loss {'Reaction outcome loss': 0.80873427285579, 'Total loss': 0.80873427285579}
2022-11-23 02:45:03,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:03,750 INFO:     Epoch: 75
2022-11-23 02:45:04,534 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8238202222557955, 'Total loss': 0.8238202222557955} | train loss {'Reaction outcome loss': 0.8132799270221726, 'Total loss': 0.8132799270221726}
2022-11-23 02:45:04,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:04,535 INFO:     Epoch: 76
2022-11-23 02:45:05,342 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.796636028345241, 'Total loss': 0.796636028345241} | train loss {'Reaction outcome loss': 0.8117590591985993, 'Total loss': 0.8117590591985993}
2022-11-23 02:45:05,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:05,342 INFO:     Epoch: 77
2022-11-23 02:45:06,172 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7996217476767163, 'Total loss': 0.7996217476767163} | train loss {'Reaction outcome loss': 0.8159740818626106, 'Total loss': 0.8159740818626106}
2022-11-23 02:45:06,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:06,173 INFO:     Epoch: 78
2022-11-23 02:45:06,977 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7918991820756779, 'Total loss': 0.7918991820756779} | train loss {'Reaction outcome loss': 0.8151858126430355, 'Total loss': 0.8151858126430355}
2022-11-23 02:45:06,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:06,978 INFO:     Epoch: 79
2022-11-23 02:45:07,738 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8036258484041968, 'Total loss': 0.8036258484041968} | train loss {'Reaction outcome loss': 0.8159655266337924, 'Total loss': 0.8159655266337924}
2022-11-23 02:45:07,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:07,738 INFO:     Epoch: 80
2022-11-23 02:45:08,530 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7855485476726709, 'Total loss': 0.7855485476726709} | train loss {'Reaction outcome loss': 0.8130479565373173, 'Total loss': 0.8130479565373173}
2022-11-23 02:45:08,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:08,531 INFO:     Epoch: 81
2022-11-23 02:45:09,350 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7903105124484661, 'Total loss': 0.7903105124484661} | train loss {'Reaction outcome loss': 0.8135927356319663, 'Total loss': 0.8135927356319663}
2022-11-23 02:45:09,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:09,351 INFO:     Epoch: 82
2022-11-23 02:45:10,179 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.79250383931537, 'Total loss': 0.79250383931537} | train loss {'Reaction outcome loss': 0.8154070649617984, 'Total loss': 0.8154070649617984}
2022-11-23 02:45:10,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:10,179 INFO:     Epoch: 83
2022-11-23 02:45:11,030 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8186601448890775, 'Total loss': 0.8186601448890775} | train loss {'Reaction outcome loss': 0.8158179481088379, 'Total loss': 0.8158179481088379}
2022-11-23 02:45:11,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:11,030 INFO:     Epoch: 84
2022-11-23 02:45:11,847 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7953295451264049, 'Total loss': 0.7953295451264049} | train loss {'Reaction outcome loss': 0.8165286833366739, 'Total loss': 0.8165286833366739}
2022-11-23 02:45:11,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:11,848 INFO:     Epoch: 85
2022-11-23 02:45:12,661 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8141533129437025, 'Total loss': 0.8141533129437025} | train loss {'Reaction outcome loss': 0.8136213713712653, 'Total loss': 0.8136213713712653}
2022-11-23 02:45:12,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:12,662 INFO:     Epoch: 86
2022-11-23 02:45:13,476 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7968579211900401, 'Total loss': 0.7968579211900401} | train loss {'Reaction outcome loss': 0.807710595888856, 'Total loss': 0.807710595888856}
2022-11-23 02:45:13,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:13,477 INFO:     Epoch: 87
2022-11-23 02:45:14,254 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8130183282286622, 'Total loss': 0.8130183282286622} | train loss {'Reaction outcome loss': 0.8132979348608496, 'Total loss': 0.8132979348608496}
2022-11-23 02:45:14,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:14,254 INFO:     Epoch: 88
2022-11-23 02:45:15,062 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8128167182900184, 'Total loss': 0.8128167182900184} | train loss {'Reaction outcome loss': 0.8164701167448067, 'Total loss': 0.8164701167448067}
2022-11-23 02:45:15,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:15,062 INFO:     Epoch: 89
2022-11-23 02:45:15,823 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7889140580975732, 'Total loss': 0.7889140580975732} | train loss {'Reaction outcome loss': 0.8210872475502422, 'Total loss': 0.8210872475502422}
2022-11-23 02:45:15,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:15,823 INFO:     Epoch: 90
2022-11-23 02:45:16,617 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.807945639588112, 'Total loss': 0.807945639588112} | train loss {'Reaction outcome loss': 0.8112522212811458, 'Total loss': 0.8112522212811458}
2022-11-23 02:45:16,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:16,617 INFO:     Epoch: 91
2022-11-23 02:45:17,375 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8067824403906978, 'Total loss': 0.8067824403906978} | train loss {'Reaction outcome loss': 0.8115858699620506, 'Total loss': 0.8115858699620506}
2022-11-23 02:45:17,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:17,375 INFO:     Epoch: 92
2022-11-23 02:45:18,172 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.801859718422557, 'Total loss': 0.801859718422557} | train loss {'Reaction outcome loss': 0.8108019038973522, 'Total loss': 0.8108019038973522}
2022-11-23 02:45:18,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:18,174 INFO:     Epoch: 93
2022-11-23 02:45:18,923 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7908888965152031, 'Total loss': 0.7908888965152031} | train loss {'Reaction outcome loss': 0.8176328002670665, 'Total loss': 0.8176328002670665}
2022-11-23 02:45:18,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:18,924 INFO:     Epoch: 94
2022-11-23 02:45:19,728 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8131925151791684, 'Total loss': 0.8131925151791684} | train loss {'Reaction outcome loss': 0.8159174202891534, 'Total loss': 0.8159174202891534}
2022-11-23 02:45:19,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:19,728 INFO:     Epoch: 95
2022-11-23 02:45:20,529 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8112252188283343, 'Total loss': 0.8112252188283343} | train loss {'Reaction outcome loss': 0.8167563654758312, 'Total loss': 0.8167563654758312}
2022-11-23 02:45:20,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:20,530 INFO:     Epoch: 96
2022-11-23 02:45:21,366 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.809977995794873, 'Total loss': 0.809977995794873} | train loss {'Reaction outcome loss': 0.8099253478118912, 'Total loss': 0.8099253478118912}
2022-11-23 02:45:21,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:21,367 INFO:     Epoch: 97
2022-11-23 02:45:22,145 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8186676516089328, 'Total loss': 0.8186676516089328} | train loss {'Reaction outcome loss': 0.8133375685156128, 'Total loss': 0.8133375685156128}
2022-11-23 02:45:22,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:22,145 INFO:     Epoch: 98
2022-11-23 02:45:22,936 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7947024800056635, 'Total loss': 0.7947024800056635} | train loss {'Reaction outcome loss': 0.816727765793663, 'Total loss': 0.816727765793663}
2022-11-23 02:45:22,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:22,936 INFO:     Epoch: 99
2022-11-23 02:45:23,712 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8067726409712503, 'Total loss': 0.8067726409712503} | train loss {'Reaction outcome loss': 0.814252066146199, 'Total loss': 0.814252066146199}
2022-11-23 02:45:23,713 INFO:     Best model found after epoch 22 of 100.
2022-11-23 02:45:23,714 INFO:   Done with stage: TRAINING
2022-11-23 02:45:23,714 INFO:   Starting stage: EVALUATION
2022-11-23 02:45:23,867 INFO:   Done with stage: EVALUATION
2022-11-23 02:45:23,867 INFO:   Leaving out SEQ value Fold_3
2022-11-23 02:45:23,880 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-23 02:45:23,880 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:45:24,535 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:45:24,535 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:45:24,608 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:45:24,608 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:45:24,608 INFO:     No hyperparam tuning for this model
2022-11-23 02:45:24,608 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:45:24,608 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:45:24,609 INFO:     None feature selector for col prot
2022-11-23 02:45:24,609 INFO:     None feature selector for col prot
2022-11-23 02:45:24,609 INFO:     None feature selector for col prot
2022-11-23 02:45:24,610 INFO:     None feature selector for col chem
2022-11-23 02:45:24,610 INFO:     None feature selector for col chem
2022-11-23 02:45:24,610 INFO:     None feature selector for col chem
2022-11-23 02:45:24,610 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:45:24,610 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:45:24,612 INFO:     Number of params in model 168571
2022-11-23 02:45:24,615 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:45:24,615 INFO:   Starting stage: TRAINING
2022-11-23 02:45:24,672 INFO:     Val loss before train {'Reaction outcome loss': 1.0543182908102524, 'Total loss': 1.0543182908102524}
2022-11-23 02:45:24,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:24,672 INFO:     Epoch: 0
2022-11-23 02:45:25,477 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9194237409636031, 'Total loss': 0.9194237409636031} | train loss {'Reaction outcome loss': 0.8637742911591942, 'Total loss': 0.8637742911591942}
2022-11-23 02:45:25,477 INFO:     Found new best model at epoch 0
2022-11-23 02:45:25,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:25,478 INFO:     Epoch: 1
2022-11-23 02:45:26,257 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.887214528959851, 'Total loss': 0.887214528959851} | train loss {'Reaction outcome loss': 0.8265538067238811, 'Total loss': 0.8265538067238811}
2022-11-23 02:45:26,257 INFO:     Found new best model at epoch 1
2022-11-23 02:45:26,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:26,258 INFO:     Epoch: 2
2022-11-23 02:45:27,071 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8787477674872376, 'Total loss': 0.8787477674872376} | train loss {'Reaction outcome loss': 0.8262223506905905, 'Total loss': 0.8262223506905905}
2022-11-23 02:45:27,071 INFO:     Found new best model at epoch 2
2022-11-23 02:45:27,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:27,072 INFO:     Epoch: 3
2022-11-23 02:45:27,840 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8857206965601722, 'Total loss': 0.8857206965601722} | train loss {'Reaction outcome loss': 0.8180119998661088, 'Total loss': 0.8180119998661088}
2022-11-23 02:45:27,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:27,840 INFO:     Epoch: 4
2022-11-23 02:45:28,618 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8583377648231595, 'Total loss': 0.8583377648231595} | train loss {'Reaction outcome loss': 0.8177510881374893, 'Total loss': 0.8177510881374893}
2022-11-23 02:45:28,619 INFO:     Found new best model at epoch 4
2022-11-23 02:45:28,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:28,620 INFO:     Epoch: 5
2022-11-23 02:45:29,417 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8500236113404118, 'Total loss': 0.8500236113404118} | train loss {'Reaction outcome loss': 0.8139900213774339, 'Total loss': 0.8139900213774339}
2022-11-23 02:45:29,417 INFO:     Found new best model at epoch 5
2022-11-23 02:45:29,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:29,418 INFO:     Epoch: 6
2022-11-23 02:45:30,231 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.855847951977752, 'Total loss': 0.855847951977752} | train loss {'Reaction outcome loss': 0.8133849372834335, 'Total loss': 0.8133849372834335}
2022-11-23 02:45:30,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:30,231 INFO:     Epoch: 7
2022-11-23 02:45:31,026 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8556049279002256, 'Total loss': 0.8556049279002256} | train loss {'Reaction outcome loss': 0.8124851098767033, 'Total loss': 0.8124851098767033}
2022-11-23 02:45:31,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:31,026 INFO:     Epoch: 8
2022-11-23 02:45:31,794 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8603194681710975, 'Total loss': 0.8603194681710975} | train loss {'Reaction outcome loss': 0.8125603360894286, 'Total loss': 0.8125603360894286}
2022-11-23 02:45:31,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:31,794 INFO:     Epoch: 9
2022-11-23 02:45:32,611 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8373309463955635, 'Total loss': 0.8373309463955635} | train loss {'Reaction outcome loss': 0.8086584401719364, 'Total loss': 0.8086584401719364}
2022-11-23 02:45:32,611 INFO:     Found new best model at epoch 9
2022-11-23 02:45:32,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:32,612 INFO:     Epoch: 10
2022-11-23 02:45:33,417 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8406368390072224, 'Total loss': 0.8406368390072224} | train loss {'Reaction outcome loss': 0.8037328891793396, 'Total loss': 0.8037328891793396}
2022-11-23 02:45:33,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:33,417 INFO:     Epoch: 11
2022-11-23 02:45:34,207 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8318964236004408, 'Total loss': 0.8318964236004408} | train loss {'Reaction outcome loss': 0.8085666840949667, 'Total loss': 0.8085666840949667}
2022-11-23 02:45:34,208 INFO:     Found new best model at epoch 11
2022-11-23 02:45:34,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:34,209 INFO:     Epoch: 12
2022-11-23 02:45:34,986 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8727214149264402, 'Total loss': 0.8727214149264402} | train loss {'Reaction outcome loss': 0.8114212936579935, 'Total loss': 0.8114212936579935}
2022-11-23 02:45:34,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:34,988 INFO:     Epoch: 13
2022-11-23 02:45:35,756 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8410975593467092, 'Total loss': 0.8410975593467092} | train loss {'Reaction outcome loss': 0.803720804582898, 'Total loss': 0.803720804582898}
2022-11-23 02:45:35,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:35,756 INFO:     Epoch: 14
2022-11-23 02:45:36,529 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8300138434698415, 'Total loss': 0.8300138434698415} | train loss {'Reaction outcome loss': 0.8040880038414473, 'Total loss': 0.8040880038414473}
2022-11-23 02:45:36,529 INFO:     Found new best model at epoch 14
2022-11-23 02:45:36,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:36,530 INFO:     Epoch: 15
2022-11-23 02:45:37,362 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8554826815461003, 'Total loss': 0.8554826815461003} | train loss {'Reaction outcome loss': 0.8025915800543969, 'Total loss': 0.8025915800543969}
2022-11-23 02:45:37,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:37,362 INFO:     Epoch: 16
2022-11-23 02:45:38,169 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8396045565605164, 'Total loss': 0.8396045565605164} | train loss {'Reaction outcome loss': 0.8021580190570267, 'Total loss': 0.8021580190570267}
2022-11-23 02:45:38,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:38,169 INFO:     Epoch: 17
2022-11-23 02:45:38,985 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8543745029804318, 'Total loss': 0.8543745029804318} | train loss {'Reaction outcome loss': 0.8041398852695654, 'Total loss': 0.8041398852695654}
2022-11-23 02:45:38,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:38,986 INFO:     Epoch: 18
2022-11-23 02:45:39,744 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8389595733132473, 'Total loss': 0.8389595733132473} | train loss {'Reaction outcome loss': 0.8065891823896165, 'Total loss': 0.8065891823896165}
2022-11-23 02:45:39,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:39,744 INFO:     Epoch: 19
2022-11-23 02:45:40,557 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8402546893718631, 'Total loss': 0.8402546893718631} | train loss {'Reaction outcome loss': 0.8019730868162932, 'Total loss': 0.8019730868162932}
2022-11-23 02:45:40,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:40,559 INFO:     Epoch: 20
2022-11-23 02:45:41,366 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8434327535851057, 'Total loss': 0.8434327535851057} | train loss {'Reaction outcome loss': 0.804635010261104, 'Total loss': 0.804635010261104}
2022-11-23 02:45:41,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:41,366 INFO:     Epoch: 21
2022-11-23 02:45:42,200 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8430702499178953, 'Total loss': 0.8430702499178953} | train loss {'Reaction outcome loss': 0.8014196178304805, 'Total loss': 0.8014196178304805}
2022-11-23 02:45:42,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:42,200 INFO:     Epoch: 22
2022-11-23 02:45:43,074 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8611852221710737, 'Total loss': 0.8611852221710737} | train loss {'Reaction outcome loss': 0.8074264603632467, 'Total loss': 0.8074264603632467}
2022-11-23 02:45:43,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:43,075 INFO:     Epoch: 23
2022-11-23 02:45:43,899 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.837915254193683, 'Total loss': 0.837915254193683} | train loss {'Reaction outcome loss': 0.8051149272379071, 'Total loss': 0.8051149272379071}
2022-11-23 02:45:43,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:43,899 INFO:     Epoch: 24
2022-11-23 02:45:44,732 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8806116539378499, 'Total loss': 0.8806116539378499} | train loss {'Reaction outcome loss': 0.7976185890382209, 'Total loss': 0.7976185890382209}
2022-11-23 02:45:44,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:44,733 INFO:     Epoch: 25
2022-11-23 02:45:45,513 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8550393401190292, 'Total loss': 0.8550393401190292} | train loss {'Reaction outcome loss': 0.8043495460792824, 'Total loss': 0.8043495460792824}
2022-11-23 02:45:45,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:45,514 INFO:     Epoch: 26
2022-11-23 02:45:46,296 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8312245752922324, 'Total loss': 0.8312245752922324} | train loss {'Reaction outcome loss': 0.802062461160338, 'Total loss': 0.802062461160338}
2022-11-23 02:45:46,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:46,296 INFO:     Epoch: 27
2022-11-23 02:45:47,064 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8378554014272468, 'Total loss': 0.8378554014272468} | train loss {'Reaction outcome loss': 0.7975803015163406, 'Total loss': 0.7975803015163406}
2022-11-23 02:45:47,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:47,064 INFO:     Epoch: 28
2022-11-23 02:45:47,863 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8459373137285543, 'Total loss': 0.8459373137285543} | train loss {'Reaction outcome loss': 0.8022541171974606, 'Total loss': 0.8022541171974606}
2022-11-23 02:45:47,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:47,864 INFO:     Epoch: 29
2022-11-23 02:45:48,635 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8342659494211507, 'Total loss': 0.8342659494211507} | train loss {'Reaction outcome loss': 0.7964650402343812, 'Total loss': 0.7964650402343812}
2022-11-23 02:45:48,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:48,635 INFO:     Epoch: 30
2022-11-23 02:45:49,415 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8299626160499661, 'Total loss': 0.8299626160499661} | train loss {'Reaction outcome loss': 0.8054529341405311, 'Total loss': 0.8054529341405311}
2022-11-23 02:45:49,416 INFO:     Found new best model at epoch 30
2022-11-23 02:45:49,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:49,416 INFO:     Epoch: 31
2022-11-23 02:45:50,162 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8329872405806253, 'Total loss': 0.8329872405806253} | train loss {'Reaction outcome loss': 0.798503337328326, 'Total loss': 0.798503337328326}
2022-11-23 02:45:50,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:50,163 INFO:     Epoch: 32
2022-11-23 02:45:50,908 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8399967752223791, 'Total loss': 0.8399967752223791} | train loss {'Reaction outcome loss': 0.7990860255902686, 'Total loss': 0.7990860255902686}
2022-11-23 02:45:50,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:50,909 INFO:     Epoch: 33
2022-11-23 02:45:51,660 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8357094152029171, 'Total loss': 0.8357094152029171} | train loss {'Reaction outcome loss': 0.7992299795150757, 'Total loss': 0.7992299795150757}
2022-11-23 02:45:51,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:51,662 INFO:     Epoch: 34
2022-11-23 02:45:52,414 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8268288436324097, 'Total loss': 0.8268288436324097} | train loss {'Reaction outcome loss': 0.7996876865257452, 'Total loss': 0.7996876865257452}
2022-11-23 02:45:52,414 INFO:     Found new best model at epoch 34
2022-11-23 02:45:52,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:52,415 INFO:     Epoch: 35
2022-11-23 02:45:53,200 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8460041416245837, 'Total loss': 0.8460041416245837} | train loss {'Reaction outcome loss': 0.7966024375256197, 'Total loss': 0.7966024375256197}
2022-11-23 02:45:53,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:53,200 INFO:     Epoch: 36
2022-11-23 02:45:53,962 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.842941528835962, 'Total loss': 0.842941528835962} | train loss {'Reaction outcome loss': 0.8030358803125075, 'Total loss': 0.8030358803125075}
2022-11-23 02:45:53,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:53,962 INFO:     Epoch: 37
2022-11-23 02:45:54,713 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.835101492183153, 'Total loss': 0.835101492183153} | train loss {'Reaction outcome loss': 0.8004528840873467, 'Total loss': 0.8004528840873467}
2022-11-23 02:45:54,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:54,714 INFO:     Epoch: 38
2022-11-23 02:45:55,503 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8579564385635908, 'Total loss': 0.8579564385635908} | train loss {'Reaction outcome loss': 0.7996745240786438, 'Total loss': 0.7996745240786438}
2022-11-23 02:45:55,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:55,504 INFO:     Epoch: 39
2022-11-23 02:45:56,268 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8416184048319972, 'Total loss': 0.8416184048319972} | train loss {'Reaction outcome loss': 0.8038638403386246, 'Total loss': 0.8038638403386246}
2022-11-23 02:45:56,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:56,268 INFO:     Epoch: 40
2022-11-23 02:45:57,024 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8438604280006053, 'Total loss': 0.8438604280006053} | train loss {'Reaction outcome loss': 0.8017594367878917, 'Total loss': 0.8017594367878917}
2022-11-23 02:45:57,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:57,025 INFO:     Epoch: 41
2022-11-23 02:45:57,806 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8345857512119205, 'Total loss': 0.8345857512119205} | train loss {'Reaction outcome loss': 0.8007012611799279, 'Total loss': 0.8007012611799279}
2022-11-23 02:45:57,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:57,806 INFO:     Epoch: 42
2022-11-23 02:45:58,601 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8573424490385277, 'Total loss': 0.8573424490385277} | train loss {'Reaction outcome loss': 0.8020839482668496, 'Total loss': 0.8020839482668496}
2022-11-23 02:45:58,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:58,601 INFO:     Epoch: 43
2022-11-23 02:45:59,371 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8388065196747003, 'Total loss': 0.8388065196747003} | train loss {'Reaction outcome loss': 0.7970084906114963, 'Total loss': 0.7970084906114963}
2022-11-23 02:45:59,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:45:59,371 INFO:     Epoch: 44
2022-11-23 02:46:00,132 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8383889440880266, 'Total loss': 0.8383889440880266} | train loss {'Reaction outcome loss': 0.7964281807711096, 'Total loss': 0.7964281807711096}
2022-11-23 02:46:00,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:00,132 INFO:     Epoch: 45
2022-11-23 02:46:00,890 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8413271869337836, 'Total loss': 0.8413271869337836} | train loss {'Reaction outcome loss': 0.7983570049819633, 'Total loss': 0.7983570049819633}
2022-11-23 02:46:00,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:00,890 INFO:     Epoch: 46
2022-11-23 02:46:01,659 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8594955448494401, 'Total loss': 0.8594955448494401} | train loss {'Reaction outcome loss': 0.7996255004847491, 'Total loss': 0.7996255004847491}
2022-11-23 02:46:01,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:01,659 INFO:     Epoch: 47
2022-11-23 02:46:02,416 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.834093943584797, 'Total loss': 0.834093943584797} | train loss {'Reaction outcome loss': 0.8036280209390224, 'Total loss': 0.8036280209390224}
2022-11-23 02:46:02,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:02,417 INFO:     Epoch: 48
2022-11-23 02:46:03,236 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8569031191426654, 'Total loss': 0.8569031191426654} | train loss {'Reaction outcome loss': 0.800174431423101, 'Total loss': 0.800174431423101}
2022-11-23 02:46:03,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:03,236 INFO:     Epoch: 49
2022-11-23 02:46:04,042 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8457389667976735, 'Total loss': 0.8457389667976735} | train loss {'Reaction outcome loss': 0.7976444899545285, 'Total loss': 0.7976444899545285}
2022-11-23 02:46:04,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:04,042 INFO:     Epoch: 50
2022-11-23 02:46:04,886 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.847846657037735, 'Total loss': 0.847846657037735} | train loss {'Reaction outcome loss': 0.7978950016537811, 'Total loss': 0.7978950016537811}
2022-11-23 02:46:04,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:04,886 INFO:     Epoch: 51
2022-11-23 02:46:05,750 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.842971533536911, 'Total loss': 0.842971533536911} | train loss {'Reaction outcome loss': 0.7984840514237989, 'Total loss': 0.7984840514237989}
2022-11-23 02:46:05,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:05,750 INFO:     Epoch: 52
2022-11-23 02:46:06,620 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.854138009769972, 'Total loss': 0.854138009769972} | train loss {'Reaction outcome loss': 0.7981332065575898, 'Total loss': 0.7981332065575898}
2022-11-23 02:46:06,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:06,620 INFO:     Epoch: 53
2022-11-23 02:46:07,417 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8380000300185625, 'Total loss': 0.8380000300185625} | train loss {'Reaction outcome loss': 0.7951653056429246, 'Total loss': 0.7951653056429246}
2022-11-23 02:46:07,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:07,418 INFO:     Epoch: 54
2022-11-23 02:46:08,194 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8404494024986444, 'Total loss': 0.8404494024986444} | train loss {'Reaction outcome loss': 0.7986912984906891, 'Total loss': 0.7986912984906891}
2022-11-23 02:46:08,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:08,196 INFO:     Epoch: 55
2022-11-23 02:46:08,994 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8343516241672427, 'Total loss': 0.8343516241672427} | train loss {'Reaction outcome loss': 0.8009960104408578, 'Total loss': 0.8009960104408578}
2022-11-23 02:46:08,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:08,995 INFO:     Epoch: 56
2022-11-23 02:46:09,824 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8549274767554084, 'Total loss': 0.8549274767554084} | train loss {'Reaction outcome loss': 0.7972919124144094, 'Total loss': 0.7972919124144094}
2022-11-23 02:46:09,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:09,824 INFO:     Epoch: 57
2022-11-23 02:46:10,616 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.839315016602361, 'Total loss': 0.839315016602361} | train loss {'Reaction outcome loss': 0.7951385461008598, 'Total loss': 0.7951385461008598}
2022-11-23 02:46:10,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:10,616 INFO:     Epoch: 58
2022-11-23 02:46:11,432 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8429049627725468, 'Total loss': 0.8429049627725468} | train loss {'Reaction outcome loss': 0.8028656244277954, 'Total loss': 0.8028656244277954}
2022-11-23 02:46:11,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:11,432 INFO:     Epoch: 59
2022-11-23 02:46:12,245 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8314406442087751, 'Total loss': 0.8314406442087751} | train loss {'Reaction outcome loss': 0.799072560643463, 'Total loss': 0.799072560643463}
2022-11-23 02:46:12,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:12,245 INFO:     Epoch: 60
2022-11-23 02:46:13,038 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8693087946536929, 'Total loss': 0.8693087946536929} | train loss {'Reaction outcome loss': 0.7985772958998818, 'Total loss': 0.7985772958998818}
2022-11-23 02:46:13,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:13,039 INFO:     Epoch: 61
2022-11-23 02:46:13,870 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8424840160580569, 'Total loss': 0.8424840160580569} | train loss {'Reaction outcome loss': 0.8004345984615907, 'Total loss': 0.8004345984615907}
2022-11-23 02:46:13,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:13,870 INFO:     Epoch: 62
2022-11-23 02:46:14,670 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8356400360894758, 'Total loss': 0.8356400360894758} | train loss {'Reaction outcome loss': 0.7937317041703212, 'Total loss': 0.7937317041703212}
2022-11-23 02:46:14,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:14,671 INFO:     Epoch: 63
2022-11-23 02:46:15,440 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8412598690321279, 'Total loss': 0.8412598690321279} | train loss {'Reaction outcome loss': 0.8032430107456175, 'Total loss': 0.8032430107456175}
2022-11-23 02:46:15,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:15,440 INFO:     Epoch: 64
2022-11-23 02:46:16,250 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.840413971695789, 'Total loss': 0.840413971695789} | train loss {'Reaction outcome loss': 0.7991104723249444, 'Total loss': 0.7991104723249444}
2022-11-23 02:46:16,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:16,250 INFO:     Epoch: 65
2022-11-23 02:46:17,013 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8687599945900052, 'Total loss': 0.8687599945900052} | train loss {'Reaction outcome loss': 0.7957730068836684, 'Total loss': 0.7957730068836684}
2022-11-23 02:46:17,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:17,014 INFO:     Epoch: 66
2022-11-23 02:46:17,845 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8267042844794518, 'Total loss': 0.8267042844794518} | train loss {'Reaction outcome loss': 0.7983042163613402, 'Total loss': 0.7983042163613402}
2022-11-23 02:46:17,845 INFO:     Found new best model at epoch 66
2022-11-23 02:46:17,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:17,846 INFO:     Epoch: 67
2022-11-23 02:46:18,633 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8445982718190481, 'Total loss': 0.8445982718190481} | train loss {'Reaction outcome loss': 0.7982930716418435, 'Total loss': 0.7982930716418435}
2022-11-23 02:46:18,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:18,633 INFO:     Epoch: 68
2022-11-23 02:46:19,424 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8304478359776873, 'Total loss': 0.8304478359776873} | train loss {'Reaction outcome loss': 0.7969415878317484, 'Total loss': 0.7969415878317484}
2022-11-23 02:46:19,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:19,425 INFO:     Epoch: 69
2022-11-23 02:46:20,217 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8675095154795536, 'Total loss': 0.8675095154795536} | train loss {'Reaction outcome loss': 0.7965983181210702, 'Total loss': 0.7965983181210702}
2022-11-23 02:46:20,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:20,217 INFO:     Epoch: 70
2022-11-23 02:46:20,980 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8340351248896399, 'Total loss': 0.8340351248896399} | train loss {'Reaction outcome loss': 0.8004397686126301, 'Total loss': 0.8004397686126301}
2022-11-23 02:46:20,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:20,981 INFO:     Epoch: 71
2022-11-23 02:46:21,781 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8632053691287374, 'Total loss': 0.8632053691287374} | train loss {'Reaction outcome loss': 0.7997361978385674, 'Total loss': 0.7997361978385674}
2022-11-23 02:46:21,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:21,781 INFO:     Epoch: 72
2022-11-23 02:46:22,572 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8521549126436544, 'Total loss': 0.8521549126436544} | train loss {'Reaction outcome loss': 0.796525169669846, 'Total loss': 0.796525169669846}
2022-11-23 02:46:22,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:22,572 INFO:     Epoch: 73
2022-11-23 02:46:23,355 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8426416751950286, 'Total loss': 0.8426416751950286} | train loss {'Reaction outcome loss': 0.7952811170997933, 'Total loss': 0.7952811170997933}
2022-11-23 02:46:23,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:23,355 INFO:     Epoch: 74
2022-11-23 02:46:24,196 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.844309483849725, 'Total loss': 0.844309483849725} | train loss {'Reaction outcome loss': 0.8027270704875757, 'Total loss': 0.8027270704875757}
2022-11-23 02:46:24,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:24,196 INFO:     Epoch: 75
2022-11-23 02:46:24,986 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8552971010984376, 'Total loss': 0.8552971010984376} | train loss {'Reaction outcome loss': 0.7963851394722, 'Total loss': 0.7963851394722}
2022-11-23 02:46:24,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:24,988 INFO:     Epoch: 76
2022-11-23 02:46:25,807 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8352851950845053, 'Total loss': 0.8352851950845053} | train loss {'Reaction outcome loss': 0.7976466971660348, 'Total loss': 0.7976466971660348}
2022-11-23 02:46:25,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:25,807 INFO:     Epoch: 77
2022-11-23 02:46:26,659 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8548249117163724, 'Total loss': 0.8548249117163724} | train loss {'Reaction outcome loss': 0.796748266911801, 'Total loss': 0.796748266911801}
2022-11-23 02:46:26,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:26,660 INFO:     Epoch: 78
2022-11-23 02:46:27,467 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8373995256978412, 'Total loss': 0.8373995256978412} | train loss {'Reaction outcome loss': 0.7993749174070947, 'Total loss': 0.7993749174070947}
2022-11-23 02:46:27,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:27,468 INFO:     Epoch: 79
2022-11-23 02:46:28,217 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8348082705985668, 'Total loss': 0.8348082705985668} | train loss {'Reaction outcome loss': 0.7950448032023976, 'Total loss': 0.7950448032023976}
2022-11-23 02:46:28,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:28,218 INFO:     Epoch: 80
2022-11-23 02:46:29,007 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8330553354218949, 'Total loss': 0.8330553354218949} | train loss {'Reaction outcome loss': 0.798895760818764, 'Total loss': 0.798895760818764}
2022-11-23 02:46:29,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:29,007 INFO:     Epoch: 81
2022-11-23 02:46:29,816 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.837899154008821, 'Total loss': 0.837899154008821} | train loss {'Reaction outcome loss': 0.7966075033072091, 'Total loss': 0.7966075033072091}
2022-11-23 02:46:29,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:29,817 INFO:     Epoch: 82
2022-11-23 02:46:30,578 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8282968568247419, 'Total loss': 0.8282968568247419} | train loss {'Reaction outcome loss': 0.7983083461292486, 'Total loss': 0.7983083461292486}
2022-11-23 02:46:30,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:30,579 INFO:     Epoch: 83
2022-11-23 02:46:31,371 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8382101994614268, 'Total loss': 0.8382101994614268} | train loss {'Reaction outcome loss': 0.7979292002479725, 'Total loss': 0.7979292002479725}
2022-11-23 02:46:31,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:31,371 INFO:     Epoch: 84
2022-11-23 02:46:32,196 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8512960201086, 'Total loss': 0.8512960201086} | train loss {'Reaction outcome loss': 0.7982340148446981, 'Total loss': 0.7982340148446981}
2022-11-23 02:46:32,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:32,197 INFO:     Epoch: 85
2022-11-23 02:46:33,010 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8632759798404782, 'Total loss': 0.8632759798404782} | train loss {'Reaction outcome loss': 0.801753891225705, 'Total loss': 0.801753891225705}
2022-11-23 02:46:33,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:33,010 INFO:     Epoch: 86
2022-11-23 02:46:33,836 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8513258924317915, 'Total loss': 0.8513258924317915} | train loss {'Reaction outcome loss': 0.7939348870834696, 'Total loss': 0.7939348870834696}
2022-11-23 02:46:33,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:33,836 INFO:     Epoch: 87
2022-11-23 02:46:34,605 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8410269188326459, 'Total loss': 0.8410269188326459} | train loss {'Reaction outcome loss': 0.800860208125762, 'Total loss': 0.800860208125762}
2022-11-23 02:46:34,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:34,605 INFO:     Epoch: 88
2022-11-23 02:46:35,367 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8513296308905579, 'Total loss': 0.8513296308905579} | train loss {'Reaction outcome loss': 0.7973992726439801, 'Total loss': 0.7973992726439801}
2022-11-23 02:46:35,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:35,367 INFO:     Epoch: 89
2022-11-23 02:46:36,133 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8794079007104386, 'Total loss': 0.8794079007104386} | train loss {'Reaction outcome loss': 0.7946132222811381, 'Total loss': 0.7946132222811381}
2022-11-23 02:46:36,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:36,134 INFO:     Epoch: 90
2022-11-23 02:46:36,909 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8576879189458004, 'Total loss': 0.8576879189458004} | train loss {'Reaction outcome loss': 0.7994399281686225, 'Total loss': 0.7994399281686225}
2022-11-23 02:46:36,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:36,909 INFO:     Epoch: 91
2022-11-23 02:46:37,675 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.9198476270187733, 'Total loss': 0.9198476270187733} | train loss {'Reaction outcome loss': 0.7992193539446764, 'Total loss': 0.7992193539446764}
2022-11-23 02:46:37,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:37,675 INFO:     Epoch: 92
2022-11-23 02:46:38,479 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8319744703381561, 'Total loss': 0.8319744703381561} | train loss {'Reaction outcome loss': 0.8009529916469943, 'Total loss': 0.8009529916469943}
2022-11-23 02:46:38,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:38,479 INFO:     Epoch: 93
2022-11-23 02:46:39,245 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8409566033718198, 'Total loss': 0.8409566033718198} | train loss {'Reaction outcome loss': 0.7945003115836485, 'Total loss': 0.7945003115836485}
2022-11-23 02:46:39,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:39,245 INFO:     Epoch: 94
2022-11-23 02:46:40,071 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8305641385011895, 'Total loss': 0.8305641385011895} | train loss {'Reaction outcome loss': 0.7941211990613506, 'Total loss': 0.7941211990613506}
2022-11-23 02:46:40,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:40,071 INFO:     Epoch: 95
2022-11-23 02:46:40,824 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8242831465809844, 'Total loss': 0.8242831465809844} | train loss {'Reaction outcome loss': 0.7935633962291749, 'Total loss': 0.7935633962291749}
2022-11-23 02:46:40,824 INFO:     Found new best model at epoch 95
2022-11-23 02:46:40,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:40,825 INFO:     Epoch: 96
2022-11-23 02:46:41,635 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8537464696307515, 'Total loss': 0.8537464696307515} | train loss {'Reaction outcome loss': 0.7961261698002677, 'Total loss': 0.7961261698002677}
2022-11-23 02:46:41,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:41,637 INFO:     Epoch: 97
2022-11-23 02:46:42,451 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8295896261237389, 'Total loss': 0.8295896261237389} | train loss {'Reaction outcome loss': 0.798718312640249, 'Total loss': 0.798718312640249}
2022-11-23 02:46:42,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:42,451 INFO:     Epoch: 98
2022-11-23 02:46:43,242 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.828007350134295, 'Total loss': 0.828007350134295} | train loss {'Reaction outcome loss': 0.7943495927769461, 'Total loss': 0.7943495927769461}
2022-11-23 02:46:43,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:43,242 INFO:     Epoch: 99
2022-11-23 02:46:44,073 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8339984098146128, 'Total loss': 0.8339984098146128} | train loss {'Reaction outcome loss': 0.7962131507602739, 'Total loss': 0.7962131507602739}
2022-11-23 02:46:44,073 INFO:     Best model found after epoch 96 of 100.
2022-11-23 02:46:44,073 INFO:   Done with stage: TRAINING
2022-11-23 02:46:44,073 INFO:   Starting stage: EVALUATION
2022-11-23 02:46:44,215 INFO:   Done with stage: EVALUATION
2022-11-23 02:46:44,216 INFO:   Leaving out SEQ value Fold_4
2022-11-23 02:46:44,229 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:46:44,229 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:46:44,911 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:46:44,911 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:46:44,985 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:46:44,985 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:46:44,986 INFO:     No hyperparam tuning for this model
2022-11-23 02:46:44,986 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:46:44,986 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:46:44,986 INFO:     None feature selector for col prot
2022-11-23 02:46:44,987 INFO:     None feature selector for col prot
2022-11-23 02:46:44,987 INFO:     None feature selector for col prot
2022-11-23 02:46:44,987 INFO:     None feature selector for col chem
2022-11-23 02:46:44,987 INFO:     None feature selector for col chem
2022-11-23 02:46:44,987 INFO:     None feature selector for col chem
2022-11-23 02:46:44,988 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:46:44,988 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:46:44,989 INFO:     Number of params in model 168571
2022-11-23 02:46:44,993 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:46:44,993 INFO:   Starting stage: TRAINING
2022-11-23 02:46:45,052 INFO:     Val loss before train {'Reaction outcome loss': 0.996170163154602, 'Total loss': 0.996170163154602}
2022-11-23 02:46:45,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:45,052 INFO:     Epoch: 0
2022-11-23 02:46:45,876 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7850523326884616, 'Total loss': 0.7850523326884616} | train loss {'Reaction outcome loss': 0.8817673586308956, 'Total loss': 0.8817673586308956}
2022-11-23 02:46:45,876 INFO:     Found new best model at epoch 0
2022-11-23 02:46:45,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:45,877 INFO:     Epoch: 1
2022-11-23 02:46:46,706 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7980801618912003, 'Total loss': 0.7980801618912003} | train loss {'Reaction outcome loss': 0.8524133785357398, 'Total loss': 0.8524133785357398}
2022-11-23 02:46:46,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:46,708 INFO:     Epoch: 2
2022-11-23 02:46:47,534 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7953508868813515, 'Total loss': 0.7953508868813515} | train loss {'Reaction outcome loss': 0.8456365600708993, 'Total loss': 0.8456365600708993}
2022-11-23 02:46:47,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:47,535 INFO:     Epoch: 3
2022-11-23 02:46:48,355 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7822633588855917, 'Total loss': 0.7822633588855917} | train loss {'Reaction outcome loss': 0.8354387837311914, 'Total loss': 0.8354387837311914}
2022-11-23 02:46:48,355 INFO:     Found new best model at epoch 3
2022-11-23 02:46:48,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:48,356 INFO:     Epoch: 4
2022-11-23 02:46:49,143 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7776965072209184, 'Total loss': 0.7776965072209184} | train loss {'Reaction outcome loss': 0.8323755246256629, 'Total loss': 0.8323755246256629}
2022-11-23 02:46:49,143 INFO:     Found new best model at epoch 4
2022-11-23 02:46:49,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:49,144 INFO:     Epoch: 5
2022-11-23 02:46:49,963 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7909077209505168, 'Total loss': 0.7909077209505168} | train loss {'Reaction outcome loss': 0.826905811505933, 'Total loss': 0.826905811505933}
2022-11-23 02:46:49,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:49,964 INFO:     Epoch: 6
2022-11-23 02:46:50,782 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7892209277911619, 'Total loss': 0.7892209277911619} | train loss {'Reaction outcome loss': 0.8253810229080338, 'Total loss': 0.8253810229080338}
2022-11-23 02:46:50,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:50,782 INFO:     Epoch: 7
2022-11-23 02:46:51,551 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7757616314021024, 'Total loss': 0.7757616314021024} | train loss {'Reaction outcome loss': 0.822310209634804, 'Total loss': 0.822310209634804}
2022-11-23 02:46:51,552 INFO:     Found new best model at epoch 7
2022-11-23 02:46:51,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:51,553 INFO:     Epoch: 8
2022-11-23 02:46:52,330 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7665111693468961, 'Total loss': 0.7665111693468961} | train loss {'Reaction outcome loss': 0.8220577369774541, 'Total loss': 0.8220577369774541}
2022-11-23 02:46:52,331 INFO:     Found new best model at epoch 8
2022-11-23 02:46:52,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:52,331 INFO:     Epoch: 9
2022-11-23 02:46:53,103 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.780483989553018, 'Total loss': 0.780483989553018} | train loss {'Reaction outcome loss': 0.8204338899663379, 'Total loss': 0.8204338899663379}
2022-11-23 02:46:53,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:53,103 INFO:     Epoch: 10
2022-11-23 02:46:53,890 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7798622074452314, 'Total loss': 0.7798622074452314} | train loss {'Reaction outcome loss': 0.8227897816367687, 'Total loss': 0.8227897816367687}
2022-11-23 02:46:53,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:53,890 INFO:     Epoch: 11
2022-11-23 02:46:54,683 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7853633016347885, 'Total loss': 0.7853633016347885} | train loss {'Reaction outcome loss': 0.8196774194798162, 'Total loss': 0.8196774194798162}
2022-11-23 02:46:54,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:54,683 INFO:     Epoch: 12
2022-11-23 02:46:55,477 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7954838330095465, 'Total loss': 0.7954838330095465} | train loss {'Reaction outcome loss': 0.8175108895426796, 'Total loss': 0.8175108895426796}
2022-11-23 02:46:55,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:55,477 INFO:     Epoch: 13
2022-11-23 02:46:56,229 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7805181592702866, 'Total loss': 0.7805181592702866} | train loss {'Reaction outcome loss': 0.8190069893194784, 'Total loss': 0.8190069893194784}
2022-11-23 02:46:56,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:56,229 INFO:     Epoch: 14
2022-11-23 02:46:57,020 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7782956043427641, 'Total loss': 0.7782956043427641} | train loss {'Reaction outcome loss': 0.8202092093565772, 'Total loss': 0.8202092093565772}
2022-11-23 02:46:57,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:57,020 INFO:     Epoch: 15
2022-11-23 02:46:57,834 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7663985666903582, 'Total loss': 0.7663985666903582} | train loss {'Reaction outcome loss': 0.8187013410272137, 'Total loss': 0.8187013410272137}
2022-11-23 02:46:57,834 INFO:     Found new best model at epoch 15
2022-11-23 02:46:57,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:57,835 INFO:     Epoch: 16
2022-11-23 02:46:58,608 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7755549258806489, 'Total loss': 0.7755549258806489} | train loss {'Reaction outcome loss': 0.8234052857564341, 'Total loss': 0.8234052857564341}
2022-11-23 02:46:58,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:58,610 INFO:     Epoch: 17
2022-11-23 02:46:59,396 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7739436233585532, 'Total loss': 0.7739436233585532} | train loss {'Reaction outcome loss': 0.8166676477318809, 'Total loss': 0.8166676477318809}
2022-11-23 02:46:59,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:46:59,396 INFO:     Epoch: 18
2022-11-23 02:47:00,214 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7735374068672006, 'Total loss': 0.7735374068672006} | train loss {'Reaction outcome loss': 0.8197864118602968, 'Total loss': 0.8197864118602968}
2022-11-23 02:47:00,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:00,215 INFO:     Epoch: 19
2022-11-23 02:47:00,980 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7701524509625002, 'Total loss': 0.7701524509625002} | train loss {'Reaction outcome loss': 0.8154395297169685, 'Total loss': 0.8154395297169685}
2022-11-23 02:47:00,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:00,981 INFO:     Epoch: 20
2022-11-23 02:47:01,770 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7894408188082955, 'Total loss': 0.7894408188082955} | train loss {'Reaction outcome loss': 0.810445575944839, 'Total loss': 0.810445575944839}
2022-11-23 02:47:01,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:01,770 INFO:     Epoch: 21
2022-11-23 02:47:02,562 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7706405649130995, 'Total loss': 0.7706405649130995} | train loss {'Reaction outcome loss': 0.813499924035803, 'Total loss': 0.813499924035803}
2022-11-23 02:47:02,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:02,562 INFO:     Epoch: 22
2022-11-23 02:47:03,334 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7882557504556396, 'Total loss': 0.7882557504556396} | train loss {'Reaction outcome loss': 0.8190038574318732, 'Total loss': 0.8190038574318732}
2022-11-23 02:47:03,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:03,334 INFO:     Epoch: 23
2022-11-23 02:47:04,106 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7663995027542114, 'Total loss': 0.7663995027542114} | train loss {'Reaction outcome loss': 0.8157020260489756, 'Total loss': 0.8157020260489756}
2022-11-23 02:47:04,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:04,107 INFO:     Epoch: 24
2022-11-23 02:47:04,915 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7708814266053113, 'Total loss': 0.7708814266053113} | train loss {'Reaction outcome loss': 0.8095877642833418, 'Total loss': 0.8095877642833418}
2022-11-23 02:47:04,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:04,916 INFO:     Epoch: 25
2022-11-23 02:47:05,722 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7809399915012446, 'Total loss': 0.7809399915012446} | train loss {'Reaction outcome loss': 0.8139849598369291, 'Total loss': 0.8139849598369291}
2022-11-23 02:47:05,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:05,722 INFO:     Epoch: 26
2022-11-23 02:47:06,486 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7661734074354172, 'Total loss': 0.7661734074354172} | train loss {'Reaction outcome loss': 0.8137154124917523, 'Total loss': 0.8137154124917523}
2022-11-23 02:47:06,486 INFO:     Found new best model at epoch 26
2022-11-23 02:47:06,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:06,487 INFO:     Epoch: 27
2022-11-23 02:47:07,290 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.770427942276001, 'Total loss': 0.770427942276001} | train loss {'Reaction outcome loss': 0.8185738225377375, 'Total loss': 0.8185738225377375}
2022-11-23 02:47:07,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:07,291 INFO:     Epoch: 28
2022-11-23 02:47:08,073 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7875930572097952, 'Total loss': 0.7875930572097952} | train loss {'Reaction outcome loss': 0.8131541554485598, 'Total loss': 0.8131541554485598}
2022-11-23 02:47:08,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:08,073 INFO:     Epoch: 29
2022-11-23 02:47:08,865 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7612481652335688, 'Total loss': 0.7612481652335688} | train loss {'Reaction outcome loss': 0.8131382172146151, 'Total loss': 0.8131382172146151}
2022-11-23 02:47:08,865 INFO:     Found new best model at epoch 29
2022-11-23 02:47:08,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:08,866 INFO:     Epoch: 30
2022-11-23 02:47:09,636 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7653041800314729, 'Total loss': 0.7653041800314729} | train loss {'Reaction outcome loss': 0.8177340254187584, 'Total loss': 0.8177340254187584}
2022-11-23 02:47:09,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:09,637 INFO:     Epoch: 31
2022-11-23 02:47:10,425 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.770952349359339, 'Total loss': 0.770952349359339} | train loss {'Reaction outcome loss': 0.8093243464827538, 'Total loss': 0.8093243464827538}
2022-11-23 02:47:10,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:10,426 INFO:     Epoch: 32
2022-11-23 02:47:11,189 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7586981640620665, 'Total loss': 0.7586981640620665} | train loss {'Reaction outcome loss': 0.814245174368543, 'Total loss': 0.814245174368543}
2022-11-23 02:47:11,189 INFO:     Found new best model at epoch 32
2022-11-23 02:47:11,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:11,190 INFO:     Epoch: 33
2022-11-23 02:47:11,974 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7822120474143461, 'Total loss': 0.7822120474143461} | train loss {'Reaction outcome loss': 0.8121971395467559, 'Total loss': 0.8121971395467559}
2022-11-23 02:47:11,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:11,975 INFO:     Epoch: 34
2022-11-23 02:47:12,743 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7700476951219819, 'Total loss': 0.7700476951219819} | train loss {'Reaction outcome loss': 0.8186821970007112, 'Total loss': 0.8186821970007112}
2022-11-23 02:47:12,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:12,743 INFO:     Epoch: 35
2022-11-23 02:47:13,541 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7849836945533752, 'Total loss': 0.7849836945533752} | train loss {'Reaction outcome loss': 0.8135516601464441, 'Total loss': 0.8135516601464441}
2022-11-23 02:47:13,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:13,542 INFO:     Epoch: 36
2022-11-23 02:47:14,349 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7875938483259894, 'Total loss': 0.7875938483259894} | train loss {'Reaction outcome loss': 0.8110808625576957, 'Total loss': 0.8110808625576957}
2022-11-23 02:47:14,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:14,349 INFO:     Epoch: 37
2022-11-23 02:47:15,158 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7748209996656938, 'Total loss': 0.7748209996656938} | train loss {'Reaction outcome loss': 0.8158104261082988, 'Total loss': 0.8158104261082988}
2022-11-23 02:47:15,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:15,160 INFO:     Epoch: 38
2022-11-23 02:47:15,979 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7595841430804946, 'Total loss': 0.7595841430804946} | train loss {'Reaction outcome loss': 0.8148848826606427, 'Total loss': 0.8148848826606427}
2022-11-23 02:47:15,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:15,980 INFO:     Epoch: 39
2022-11-23 02:47:16,819 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7739765305410732, 'Total loss': 0.7739765305410732} | train loss {'Reaction outcome loss': 0.8143457759532237, 'Total loss': 0.8143457759532237}
2022-11-23 02:47:16,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:16,820 INFO:     Epoch: 40
2022-11-23 02:47:17,614 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7689105299386111, 'Total loss': 0.7689105299386111} | train loss {'Reaction outcome loss': 0.8099786532261679, 'Total loss': 0.8099786532261679}
2022-11-23 02:47:17,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:17,615 INFO:     Epoch: 41
2022-11-23 02:47:18,387 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7962360239841721, 'Total loss': 0.7962360239841721} | train loss {'Reaction outcome loss': 0.8093094691153495, 'Total loss': 0.8093094691153495}
2022-11-23 02:47:18,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:18,387 INFO:     Epoch: 42
2022-11-23 02:47:19,215 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7626901533115994, 'Total loss': 0.7626901533115994} | train loss {'Reaction outcome loss': 0.8126804662808296, 'Total loss': 0.8126804662808296}
2022-11-23 02:47:19,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:19,216 INFO:     Epoch: 43
2022-11-23 02:47:20,083 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7619539147073572, 'Total loss': 0.7619539147073572} | train loss {'Reaction outcome loss': 0.8133310133651379, 'Total loss': 0.8133310133651379}
2022-11-23 02:47:20,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:20,083 INFO:     Epoch: 44
2022-11-23 02:47:20,893 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7867067672989585, 'Total loss': 0.7867067672989585} | train loss {'Reaction outcome loss': 0.8136229720567504, 'Total loss': 0.8136229720567504}
2022-11-23 02:47:20,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:20,894 INFO:     Epoch: 45
2022-11-23 02:47:21,662 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.760778546333313, 'Total loss': 0.760778546333313} | train loss {'Reaction outcome loss': 0.8132337061387878, 'Total loss': 0.8132337061387878}
2022-11-23 02:47:21,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:21,662 INFO:     Epoch: 46
2022-11-23 02:47:22,427 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7723664451729167, 'Total loss': 0.7723664451729167} | train loss {'Reaction outcome loss': 0.8150292920970148, 'Total loss': 0.8150292920970148}
2022-11-23 02:47:22,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:22,428 INFO:     Epoch: 47
2022-11-23 02:47:23,278 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.763008526103063, 'Total loss': 0.763008526103063} | train loss {'Reaction outcome loss': 0.8142485843310433, 'Total loss': 0.8142485843310433}
2022-11-23 02:47:23,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:23,278 INFO:     Epoch: 48
2022-11-23 02:47:24,138 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7715017490766265, 'Total loss': 0.7715017490766265} | train loss {'Reaction outcome loss': 0.8119269155206219, 'Total loss': 0.8119269155206219}
2022-11-23 02:47:24,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:24,138 INFO:     Epoch: 49
2022-11-23 02:47:25,012 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7666638222607699, 'Total loss': 0.7666638222607699} | train loss {'Reaction outcome loss': 0.8094742108256586, 'Total loss': 0.8094742108256586}
2022-11-23 02:47:25,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:25,012 INFO:     Epoch: 50
2022-11-23 02:47:25,883 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7801855138757012, 'Total loss': 0.7801855138757012} | train loss {'Reaction outcome loss': 0.8045664251812042, 'Total loss': 0.8045664251812042}
2022-11-23 02:47:25,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:25,885 INFO:     Epoch: 51
2022-11-23 02:47:26,766 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7817326899279248, 'Total loss': 0.7817326899279248} | train loss {'Reaction outcome loss': 0.8172042193191666, 'Total loss': 0.8172042193191666}
2022-11-23 02:47:26,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:26,766 INFO:     Epoch: 52
2022-11-23 02:47:27,650 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7641658667813648, 'Total loss': 0.7641658667813648} | train loss {'Reaction outcome loss': 0.8162548070953738, 'Total loss': 0.8162548070953738}
2022-11-23 02:47:27,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:27,650 INFO:     Epoch: 53
2022-11-23 02:47:28,539 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.784744071689519, 'Total loss': 0.784744071689519} | train loss {'Reaction outcome loss': 0.8157629073867875, 'Total loss': 0.8157629073867875}
2022-11-23 02:47:28,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:28,539 INFO:     Epoch: 54
2022-11-23 02:47:29,419 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7675946652889252, 'Total loss': 0.7675946652889252} | train loss {'Reaction outcome loss': 0.8108886076558021, 'Total loss': 0.8108886076558021}
2022-11-23 02:47:29,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:29,419 INFO:     Epoch: 55
2022-11-23 02:47:30,326 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7630857893011787, 'Total loss': 0.7630857893011787} | train loss {'Reaction outcome loss': 0.8162912307006698, 'Total loss': 0.8162912307006698}
2022-11-23 02:47:30,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:30,327 INFO:     Epoch: 56
2022-11-23 02:47:31,189 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7816450135274366, 'Total loss': 0.7816450135274366} | train loss {'Reaction outcome loss': 0.8106020695019153, 'Total loss': 0.8106020695019153}
2022-11-23 02:47:31,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:31,190 INFO:     Epoch: 57
2022-11-23 02:47:32,017 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7716730684041977, 'Total loss': 0.7716730684041977} | train loss {'Reaction outcome loss': 0.8132890825790744, 'Total loss': 0.8132890825790744}
2022-11-23 02:47:32,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:32,019 INFO:     Epoch: 58
2022-11-23 02:47:32,960 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7578644468025728, 'Total loss': 0.7578644468025728} | train loss {'Reaction outcome loss': 0.8077035829905541, 'Total loss': 0.8077035829905541}
2022-11-23 02:47:32,961 INFO:     Found new best model at epoch 58
2022-11-23 02:47:32,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:32,962 INFO:     Epoch: 59
2022-11-23 02:47:33,835 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.773595894602212, 'Total loss': 0.773595894602212} | train loss {'Reaction outcome loss': 0.813897879613984, 'Total loss': 0.813897879613984}
2022-11-23 02:47:33,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:33,835 INFO:     Epoch: 60
2022-11-23 02:47:34,733 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7776684178547426, 'Total loss': 0.7776684178547426} | train loss {'Reaction outcome loss': 0.806293225817142, 'Total loss': 0.806293225817142}
2022-11-23 02:47:34,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:34,733 INFO:     Epoch: 61
2022-11-23 02:47:35,646 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7665500308979641, 'Total loss': 0.7665500308979641} | train loss {'Reaction outcome loss': 0.8116457649777012, 'Total loss': 0.8116457649777012}
2022-11-23 02:47:35,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:35,647 INFO:     Epoch: 62
2022-11-23 02:47:36,584 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7570597529411316, 'Total loss': 0.7570597529411316} | train loss {'Reaction outcome loss': 0.8097485875290248, 'Total loss': 0.8097485875290248}
2022-11-23 02:47:36,584 INFO:     Found new best model at epoch 62
2022-11-23 02:47:36,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:36,585 INFO:     Epoch: 63
2022-11-23 02:47:37,510 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.779478906230493, 'Total loss': 0.779478906230493} | train loss {'Reaction outcome loss': 0.8061903050589946, 'Total loss': 0.8061903050589946}
2022-11-23 02:47:37,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:37,511 INFO:     Epoch: 64
2022-11-23 02:47:38,362 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7584174512462183, 'Total loss': 0.7584174512462183} | train loss {'Reaction outcome loss': 0.8089473364093611, 'Total loss': 0.8089473364093611}
2022-11-23 02:47:38,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:38,362 INFO:     Epoch: 65
2022-11-23 02:47:39,222 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7561289850961078, 'Total loss': 0.7561289850961078} | train loss {'Reaction outcome loss': 0.8072653946376616, 'Total loss': 0.8072653946376616}
2022-11-23 02:47:39,222 INFO:     Found new best model at epoch 65
2022-11-23 02:47:39,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:39,223 INFO:     Epoch: 66
2022-11-23 02:47:40,087 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7588945593346249, 'Total loss': 0.7588945593346249} | train loss {'Reaction outcome loss': 0.8130235783755779, 'Total loss': 0.8130235783755779}
2022-11-23 02:47:40,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:40,087 INFO:     Epoch: 67
2022-11-23 02:47:40,974 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7622140740806406, 'Total loss': 0.7622140740806406} | train loss {'Reaction outcome loss': 0.8101656583528365, 'Total loss': 0.8101656583528365}
2022-11-23 02:47:40,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:40,974 INFO:     Epoch: 68
2022-11-23 02:47:41,930 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7651736011559312, 'Total loss': 0.7651736011559312} | train loss {'Reaction outcome loss': 0.8106305888823925, 'Total loss': 0.8106305888823925}
2022-11-23 02:47:41,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:41,931 INFO:     Epoch: 69
2022-11-23 02:47:42,849 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7650703970681537, 'Total loss': 0.7650703970681537} | train loss {'Reaction outcome loss': 0.8128723955202487, 'Total loss': 0.8128723955202487}
2022-11-23 02:47:42,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:42,851 INFO:     Epoch: 70
2022-11-23 02:47:43,769 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7802962193434889, 'Total loss': 0.7802962193434889} | train loss {'Reaction outcome loss': 0.8067533538466499, 'Total loss': 0.8067533538466499}
2022-11-23 02:47:43,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:43,769 INFO:     Epoch: 71
2022-11-23 02:47:44,684 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7720811583779075, 'Total loss': 0.7720811583779075} | train loss {'Reaction outcome loss': 0.8130044413189734, 'Total loss': 0.8130044413189734}
2022-11-23 02:47:44,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:44,684 INFO:     Epoch: 72
2022-11-23 02:47:45,543 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7660304985263131, 'Total loss': 0.7660304985263131} | train loss {'Reaction outcome loss': 0.8119125419086025, 'Total loss': 0.8119125419086025}
2022-11-23 02:47:45,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:45,543 INFO:     Epoch: 73
2022-11-23 02:47:46,440 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7520718384872783, 'Total loss': 0.7520718384872783} | train loss {'Reaction outcome loss': 0.8108868558079966, 'Total loss': 0.8108868558079966}
2022-11-23 02:47:46,440 INFO:     Found new best model at epoch 73
2022-11-23 02:47:46,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:46,441 INFO:     Epoch: 74
2022-11-23 02:47:47,326 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7630008140748198, 'Total loss': 0.7630008140748198} | train loss {'Reaction outcome loss': 0.8110073833696304, 'Total loss': 0.8110073833696304}
2022-11-23 02:47:47,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:47,327 INFO:     Epoch: 75
2022-11-23 02:47:48,200 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7586747326634147, 'Total loss': 0.7586747326634147} | train loss {'Reaction outcome loss': 0.8093496767743942, 'Total loss': 0.8093496767743942}
2022-11-23 02:47:48,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:48,201 INFO:     Epoch: 76
2022-11-23 02:47:49,115 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7650145407427441, 'Total loss': 0.7650145407427441} | train loss {'Reaction outcome loss': 0.8156803330827144, 'Total loss': 0.8156803330827144}
2022-11-23 02:47:49,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:49,116 INFO:     Epoch: 77
2022-11-23 02:47:49,988 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7562723857435313, 'Total loss': 0.7562723857435313} | train loss {'Reaction outcome loss': 0.811638054467978, 'Total loss': 0.811638054467978}
2022-11-23 02:47:49,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:49,988 INFO:     Epoch: 78
2022-11-23 02:47:50,903 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.767128505490043, 'Total loss': 0.767128505490043} | train loss {'Reaction outcome loss': 0.8125511767162431, 'Total loss': 0.8125511767162431}
2022-11-23 02:47:50,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:50,903 INFO:     Epoch: 79
2022-11-23 02:47:51,781 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7629478526386347, 'Total loss': 0.7629478526386347} | train loss {'Reaction outcome loss': 0.8112253356845148, 'Total loss': 0.8112253356845148}
2022-11-23 02:47:51,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:51,781 INFO:     Epoch: 80
2022-11-23 02:47:52,646 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7714284719391302, 'Total loss': 0.7714284719391302} | train loss {'Reaction outcome loss': 0.807635728750498, 'Total loss': 0.807635728750498}
2022-11-23 02:47:52,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:52,647 INFO:     Epoch: 81
2022-11-23 02:47:53,512 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7764785411682996, 'Total loss': 0.7764785411682996} | train loss {'Reaction outcome loss': 0.8132110063827807, 'Total loss': 0.8132110063827807}
2022-11-23 02:47:53,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:53,513 INFO:     Epoch: 82
2022-11-23 02:47:54,342 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.78351729972796, 'Total loss': 0.78351729972796} | train loss {'Reaction outcome loss': 0.8117825032001541, 'Total loss': 0.8117825032001541}
2022-11-23 02:47:54,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:54,342 INFO:     Epoch: 83
2022-11-23 02:47:55,172 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7840782478451729, 'Total loss': 0.7840782478451729} | train loss {'Reaction outcome loss': 0.8064040009292864, 'Total loss': 0.8064040009292864}
2022-11-23 02:47:55,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:55,172 INFO:     Epoch: 84
2022-11-23 02:47:56,075 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7621953697367148, 'Total loss': 0.7621953697367148} | train loss {'Reaction outcome loss': 0.8090811872914914, 'Total loss': 0.8090811872914914}
2022-11-23 02:47:56,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:56,075 INFO:     Epoch: 85
2022-11-23 02:47:56,954 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7890641384504058, 'Total loss': 0.7890641384504058} | train loss {'Reaction outcome loss': 0.8105973929407135, 'Total loss': 0.8105973929407135}
2022-11-23 02:47:56,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:56,954 INFO:     Epoch: 86
2022-11-23 02:47:57,861 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7721410610459067, 'Total loss': 0.7721410610459067} | train loss {'Reaction outcome loss': 0.8090313554050461, 'Total loss': 0.8090313554050461}
2022-11-23 02:47:57,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:57,861 INFO:     Epoch: 87
2022-11-23 02:47:58,737 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7628326402469114, 'Total loss': 0.7628326402469114} | train loss {'Reaction outcome loss': 0.8119228138558326, 'Total loss': 0.8119228138558326}
2022-11-23 02:47:58,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:58,739 INFO:     Epoch: 88
2022-11-23 02:47:59,610 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7818094844167883, 'Total loss': 0.7818094844167883} | train loss {'Reaction outcome loss': 0.8118618726730347, 'Total loss': 0.8118618726730347}
2022-11-23 02:47:59,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:47:59,610 INFO:     Epoch: 89
2022-11-23 02:48:00,468 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7825458964163606, 'Total loss': 0.7825458964163606} | train loss {'Reaction outcome loss': 0.8091708257073357, 'Total loss': 0.8091708257073357}
2022-11-23 02:48:00,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:00,469 INFO:     Epoch: 90
2022-11-23 02:48:01,345 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7753819802945311, 'Total loss': 0.7753819802945311} | train loss {'Reaction outcome loss': 0.8132969556796935, 'Total loss': 0.8132969556796935}
2022-11-23 02:48:01,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:01,345 INFO:     Epoch: 91
2022-11-23 02:48:02,187 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7661593928933144, 'Total loss': 0.7661593928933144} | train loss {'Reaction outcome loss': 0.8130698518887642, 'Total loss': 0.8130698518887642}
2022-11-23 02:48:02,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:02,188 INFO:     Epoch: 92
2022-11-23 02:48:03,081 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.759563219818202, 'Total loss': 0.759563219818202} | train loss {'Reaction outcome loss': 0.8062370986707749, 'Total loss': 0.8062370986707749}
2022-11-23 02:48:03,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:03,081 INFO:     Epoch: 93
2022-11-23 02:48:03,976 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7768265090205453, 'Total loss': 0.7768265090205453} | train loss {'Reaction outcome loss': 0.8074917745205664, 'Total loss': 0.8074917745205664}
2022-11-23 02:48:03,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:03,977 INFO:     Epoch: 94
2022-11-23 02:48:04,875 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7654850713231347, 'Total loss': 0.7654850713231347} | train loss {'Reaction outcome loss': 0.8030124688821454, 'Total loss': 0.8030124688821454}
2022-11-23 02:48:04,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:04,875 INFO:     Epoch: 95
2022-11-23 02:48:05,763 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7528755989941683, 'Total loss': 0.7528755989941683} | train loss {'Reaction outcome loss': 0.8129058423782548, 'Total loss': 0.8129058423782548}
2022-11-23 02:48:05,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:05,764 INFO:     Epoch: 96
2022-11-23 02:48:06,622 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7851080027493563, 'Total loss': 0.7851080027493563} | train loss {'Reaction outcome loss': 0.8083433976336833, 'Total loss': 0.8083433976336833}
2022-11-23 02:48:06,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:06,623 INFO:     Epoch: 97
2022-11-23 02:48:07,464 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.804567391899499, 'Total loss': 0.804567391899499} | train loss {'Reaction outcome loss': 0.8105758516298186, 'Total loss': 0.8105758516298186}
2022-11-23 02:48:07,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:07,465 INFO:     Epoch: 98
2022-11-23 02:48:08,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7689543874426321, 'Total loss': 0.7689543874426321} | train loss {'Reaction outcome loss': 0.8133458835223029, 'Total loss': 0.8133458835223029}
2022-11-23 02:48:08,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:08,338 INFO:     Epoch: 99
2022-11-23 02:48:09,256 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7799096723849123, 'Total loss': 0.7799096723849123} | train loss {'Reaction outcome loss': 0.8058767083191103, 'Total loss': 0.8058767083191103}
2022-11-23 02:48:09,257 INFO:     Best model found after epoch 74 of 100.
2022-11-23 02:48:09,257 INFO:   Done with stage: TRAINING
2022-11-23 02:48:09,257 INFO:   Starting stage: EVALUATION
2022-11-23 02:48:09,377 INFO:   Done with stage: EVALUATION
2022-11-23 02:48:09,377 INFO:   Leaving out SEQ value Fold_5
2022-11-23 02:48:09,391 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 02:48:09,391 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:48:10,070 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:48:10,070 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:48:10,146 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:48:10,146 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:48:10,147 INFO:     No hyperparam tuning for this model
2022-11-23 02:48:10,147 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:48:10,147 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:48:10,148 INFO:     None feature selector for col prot
2022-11-23 02:48:10,148 INFO:     None feature selector for col prot
2022-11-23 02:48:10,148 INFO:     None feature selector for col prot
2022-11-23 02:48:10,149 INFO:     None feature selector for col chem
2022-11-23 02:48:10,149 INFO:     None feature selector for col chem
2022-11-23 02:48:10,149 INFO:     None feature selector for col chem
2022-11-23 02:48:10,149 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:48:10,149 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:48:10,151 INFO:     Number of params in model 168571
2022-11-23 02:48:10,154 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:48:10,154 INFO:   Starting stage: TRAINING
2022-11-23 02:48:10,214 INFO:     Val loss before train {'Reaction outcome loss': 1.0636532760479234, 'Total loss': 1.0636532760479234}
2022-11-23 02:48:10,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:10,215 INFO:     Epoch: 0
2022-11-23 02:48:11,080 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8815907314419746, 'Total loss': 0.8815907314419746} | train loss {'Reaction outcome loss': 0.8879845469581837, 'Total loss': 0.8879845469581837}
2022-11-23 02:48:11,080 INFO:     Found new best model at epoch 0
2022-11-23 02:48:11,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:11,081 INFO:     Epoch: 1
2022-11-23 02:48:11,928 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8607388619672168, 'Total loss': 0.8607388619672168} | train loss {'Reaction outcome loss': 0.8546808999411913, 'Total loss': 0.8546808999411913}
2022-11-23 02:48:11,928 INFO:     Found new best model at epoch 1
2022-11-23 02:48:11,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:11,929 INFO:     Epoch: 2
2022-11-23 02:48:12,772 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8759801123629917, 'Total loss': 0.8759801123629917} | train loss {'Reaction outcome loss': 0.8471892496761011, 'Total loss': 0.8471892496761011}
2022-11-23 02:48:12,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:12,772 INFO:     Epoch: 3
2022-11-23 02:48:13,635 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8555929687890139, 'Total loss': 0.8555929687890139} | train loss {'Reaction outcome loss': 0.8426837613387984, 'Total loss': 0.8426837613387984}
2022-11-23 02:48:13,635 INFO:     Found new best model at epoch 3
2022-11-23 02:48:13,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:13,636 INFO:     Epoch: 4
2022-11-23 02:48:14,542 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8500518758188594, 'Total loss': 0.8500518758188594} | train loss {'Reaction outcome loss': 0.8400883398493942, 'Total loss': 0.8400883398493942}
2022-11-23 02:48:14,543 INFO:     Found new best model at epoch 4
2022-11-23 02:48:14,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:14,544 INFO:     Epoch: 5
2022-11-23 02:48:15,387 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8549371443011544, 'Total loss': 0.8549371443011544} | train loss {'Reaction outcome loss': 0.8324740604478486, 'Total loss': 0.8324740604478486}
2022-11-23 02:48:15,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:15,388 INFO:     Epoch: 6
2022-11-23 02:48:16,238 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8394170200282877, 'Total loss': 0.8394170200282877} | train loss {'Reaction outcome loss': 0.827952291649215, 'Total loss': 0.827952291649215}
2022-11-23 02:48:16,238 INFO:     Found new best model at epoch 6
2022-11-23 02:48:16,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:16,239 INFO:     Epoch: 7
2022-11-23 02:48:17,163 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.886413914913481, 'Total loss': 0.886413914913481} | train loss {'Reaction outcome loss': 0.8316731607427402, 'Total loss': 0.8316731607427402}
2022-11-23 02:48:17,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:17,163 INFO:     Epoch: 8
2022-11-23 02:48:18,024 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8620869815349579, 'Total loss': 0.8620869815349579} | train loss {'Reaction outcome loss': 0.832645183801651, 'Total loss': 0.832645183801651}
2022-11-23 02:48:18,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:18,025 INFO:     Epoch: 9
2022-11-23 02:48:18,859 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.846287110989744, 'Total loss': 0.846287110989744} | train loss {'Reaction outcome loss': 0.8275328509661616, 'Total loss': 0.8275328509661616}
2022-11-23 02:48:18,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:18,859 INFO:     Epoch: 10
2022-11-23 02:48:19,653 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8589157177643343, 'Total loss': 0.8589157177643343} | train loss {'Reaction outcome loss': 0.8251256118015368, 'Total loss': 0.8251256118015368}
2022-11-23 02:48:19,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:19,654 INFO:     Epoch: 11
2022-11-23 02:48:20,505 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8526497998020865, 'Total loss': 0.8526497998020865} | train loss {'Reaction outcome loss': 0.8299632230583502, 'Total loss': 0.8299632230583502}
2022-11-23 02:48:20,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:20,505 INFO:     Epoch: 12
2022-11-23 02:48:21,378 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8856337680058046, 'Total loss': 0.8856337680058046} | train loss {'Reaction outcome loss': 0.8251859262281535, 'Total loss': 0.8251859262281535}
2022-11-23 02:48:21,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:21,379 INFO:     Epoch: 13
2022-11-23 02:48:22,238 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8542759249156172, 'Total loss': 0.8542759249156172} | train loss {'Reaction outcome loss': 0.8249880197096844, 'Total loss': 0.8249880197096844}
2022-11-23 02:48:22,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:22,238 INFO:     Epoch: 14
2022-11-23 02:48:23,119 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8502786443992094, 'Total loss': 0.8502786443992094} | train loss {'Reaction outcome loss': 0.825979749098116, 'Total loss': 0.825979749098116}
2022-11-23 02:48:23,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:23,119 INFO:     Epoch: 15
2022-11-23 02:48:23,919 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8520287532698024, 'Total loss': 0.8520287532698024} | train loss {'Reaction outcome loss': 0.821574495033342, 'Total loss': 0.821574495033342}
2022-11-23 02:48:23,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:23,920 INFO:     Epoch: 16
2022-11-23 02:48:24,750 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8701617074283686, 'Total loss': 0.8701617074283686} | train loss {'Reaction outcome loss': 0.8235520339741998, 'Total loss': 0.8235520339741998}
2022-11-23 02:48:24,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:24,752 INFO:     Epoch: 17
2022-11-23 02:48:25,576 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8670903132720427, 'Total loss': 0.8670903132720427} | train loss {'Reaction outcome loss': 0.8230776882901484, 'Total loss': 0.8230776882901484}
2022-11-23 02:48:25,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:25,576 INFO:     Epoch: 18
2022-11-23 02:48:26,419 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8581566377119585, 'Total loss': 0.8581566377119585} | train loss {'Reaction outcome loss': 0.8235853948155228, 'Total loss': 0.8235853948155228}
2022-11-23 02:48:26,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:26,419 INFO:     Epoch: 19
2022-11-23 02:48:27,247 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8562740751288154, 'Total loss': 0.8562740751288154} | train loss {'Reaction outcome loss': 0.8243286893075826, 'Total loss': 0.8243286893075826}
2022-11-23 02:48:27,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:27,248 INFO:     Epoch: 20
2022-11-23 02:48:28,123 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8610339015722275, 'Total loss': 0.8610339015722275} | train loss {'Reaction outcome loss': 0.8185127265599309, 'Total loss': 0.8185127265599309}
2022-11-23 02:48:28,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:28,124 INFO:     Epoch: 21
2022-11-23 02:48:28,983 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8589268638329073, 'Total loss': 0.8589268638329073} | train loss {'Reaction outcome loss': 0.8260694334701616, 'Total loss': 0.8260694334701616}
2022-11-23 02:48:28,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:28,983 INFO:     Epoch: 22
2022-11-23 02:48:29,858 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8600030026652596, 'Total loss': 0.8600030026652596} | train loss {'Reaction outcome loss': 0.8250641644001007, 'Total loss': 0.8250641644001007}
2022-11-23 02:48:29,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:29,859 INFO:     Epoch: 23
2022-11-23 02:48:30,704 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8575922779061578, 'Total loss': 0.8575922779061578} | train loss {'Reaction outcome loss': 0.8209992408752441, 'Total loss': 0.8209992408752441}
2022-11-23 02:48:30,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:30,705 INFO:     Epoch: 24
2022-11-23 02:48:31,524 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8690408522432501, 'Total loss': 0.8690408522432501} | train loss {'Reaction outcome loss': 0.8200380444526673, 'Total loss': 0.8200380444526673}
2022-11-23 02:48:31,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:31,525 INFO:     Epoch: 25
2022-11-23 02:48:32,331 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8522356403144923, 'Total loss': 0.8522356403144923} | train loss {'Reaction outcome loss': 0.8208567889369264, 'Total loss': 0.8208567889369264}
2022-11-23 02:48:32,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:32,332 INFO:     Epoch: 26
2022-11-23 02:48:33,144 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8407283147627657, 'Total loss': 0.8407283147627657} | train loss {'Reaction outcome loss': 0.8262063039808857, 'Total loss': 0.8262063039808857}
2022-11-23 02:48:33,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:33,145 INFO:     Epoch: 27
2022-11-23 02:48:33,975 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.826974168419838, 'Total loss': 0.826974168419838} | train loss {'Reaction outcome loss': 0.8257444454699147, 'Total loss': 0.8257444454699147}
2022-11-23 02:48:33,975 INFO:     Found new best model at epoch 27
2022-11-23 02:48:33,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:33,976 INFO:     Epoch: 28
2022-11-23 02:48:34,778 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8636855137619105, 'Total loss': 0.8636855137619105} | train loss {'Reaction outcome loss': 0.8201833338153606, 'Total loss': 0.8201833338153606}
2022-11-23 02:48:34,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:34,779 INFO:     Epoch: 29
2022-11-23 02:48:35,619 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8466884575106881, 'Total loss': 0.8466884575106881} | train loss {'Reaction outcome loss': 0.822490366502684, 'Total loss': 0.822490366502684}
2022-11-23 02:48:35,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:35,619 INFO:     Epoch: 30
2022-11-23 02:48:36,441 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8416412350806323, 'Total loss': 0.8416412350806323} | train loss {'Reaction outcome loss': 0.8226583707089327, 'Total loss': 0.8226583707089327}
2022-11-23 02:48:36,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:36,442 INFO:     Epoch: 31
2022-11-23 02:48:37,210 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8470114036039873, 'Total loss': 0.8470114036039873} | train loss {'Reaction outcome loss': 0.8197663129592428, 'Total loss': 0.8197663129592428}
2022-11-23 02:48:37,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:37,211 INFO:     Epoch: 32
2022-11-23 02:48:38,052 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8580398336052895, 'Total loss': 0.8580398336052895} | train loss {'Reaction outcome loss': 0.8202061301591445, 'Total loss': 0.8202061301591445}
2022-11-23 02:48:38,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:38,052 INFO:     Epoch: 33
2022-11-23 02:48:38,844 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8445366346700625, 'Total loss': 0.8445366346700625} | train loss {'Reaction outcome loss': 0.8220265936486575, 'Total loss': 0.8220265936486575}
2022-11-23 02:48:38,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:38,844 INFO:     Epoch: 34
2022-11-23 02:48:39,645 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.851792806928808, 'Total loss': 0.851792806928808} | train loss {'Reaction outcome loss': 0.8203489359544248, 'Total loss': 0.8203489359544248}
2022-11-23 02:48:39,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:39,645 INFO:     Epoch: 35
2022-11-23 02:48:40,394 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8681030524047938, 'Total loss': 0.8681030524047938} | train loss {'Reaction outcome loss': 0.8221133440124745, 'Total loss': 0.8221133440124745}
2022-11-23 02:48:40,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:40,394 INFO:     Epoch: 36
2022-11-23 02:48:41,183 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8454199785535986, 'Total loss': 0.8454199785535986} | train loss {'Reaction outcome loss': 0.8208735801735703, 'Total loss': 0.8208735801735703}
2022-11-23 02:48:41,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:41,184 INFO:     Epoch: 37
2022-11-23 02:48:41,940 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.846328383142298, 'Total loss': 0.846328383142298} | train loss {'Reaction outcome loss': 0.8188055826693165, 'Total loss': 0.8188055826693165}
2022-11-23 02:48:41,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:41,940 INFO:     Epoch: 38
2022-11-23 02:48:42,713 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8451989509842612, 'Total loss': 0.8451989509842612} | train loss {'Reaction outcome loss': 0.8231707665385032, 'Total loss': 0.8231707665385032}
2022-11-23 02:48:42,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:42,714 INFO:     Epoch: 39
2022-11-23 02:48:43,499 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8726193322376772, 'Total loss': 0.8726193322376772} | train loss {'Reaction outcome loss': 0.8239999696916464, 'Total loss': 0.8239999696916464}
2022-11-23 02:48:43,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:43,499 INFO:     Epoch: 40
2022-11-23 02:48:44,270 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8404089747504755, 'Total loss': 0.8404089747504755} | train loss {'Reaction outcome loss': 0.8194826581040208, 'Total loss': 0.8194826581040208}
2022-11-23 02:48:44,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:44,270 INFO:     Epoch: 41
2022-11-23 02:48:45,059 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8391015719283711, 'Total loss': 0.8391015719283711} | train loss {'Reaction outcome loss': 0.8192528083616374, 'Total loss': 0.8192528083616374}
2022-11-23 02:48:45,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:45,059 INFO:     Epoch: 42
2022-11-23 02:48:45,822 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8385138254274022, 'Total loss': 0.8385138254274022} | train loss {'Reaction outcome loss': 0.8171006042130139, 'Total loss': 0.8171006042130139}
2022-11-23 02:48:45,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:45,822 INFO:     Epoch: 43
2022-11-23 02:48:46,589 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8565440015359358, 'Total loss': 0.8565440015359358} | train loss {'Reaction outcome loss': 0.8175440971948662, 'Total loss': 0.8175440971948662}
2022-11-23 02:48:46,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:46,590 INFO:     Epoch: 44
2022-11-23 02:48:47,368 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8359332165934823, 'Total loss': 0.8359332165934823} | train loss {'Reaction outcome loss': 0.8227748213982096, 'Total loss': 0.8227748213982096}
2022-11-23 02:48:47,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:47,369 INFO:     Epoch: 45
2022-11-23 02:48:48,222 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8428322049704465, 'Total loss': 0.8428322049704465} | train loss {'Reaction outcome loss': 0.8157883976187025, 'Total loss': 0.8157883976187025}
2022-11-23 02:48:48,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:48,223 INFO:     Epoch: 46
2022-11-23 02:48:48,992 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8243873329325155, 'Total loss': 0.8243873329325155} | train loss {'Reaction outcome loss': 0.8177240291420295, 'Total loss': 0.8177240291420295}
2022-11-23 02:48:48,992 INFO:     Found new best model at epoch 46
2022-11-23 02:48:48,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:48,993 INFO:     Epoch: 47
2022-11-23 02:48:49,770 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8516835394230756, 'Total loss': 0.8516835394230756} | train loss {'Reaction outcome loss': 0.8187870729942711, 'Total loss': 0.8187870729942711}
2022-11-23 02:48:49,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:49,770 INFO:     Epoch: 48
2022-11-23 02:48:50,570 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.844422543590719, 'Total loss': 0.844422543590719} | train loss {'Reaction outcome loss': 0.8204534248429902, 'Total loss': 0.8204534248429902}
2022-11-23 02:48:50,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:50,570 INFO:     Epoch: 49
2022-11-23 02:48:51,352 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8343215815045617, 'Total loss': 0.8343215815045617} | train loss {'Reaction outcome loss': 0.8193226583149968, 'Total loss': 0.8193226583149968}
2022-11-23 02:48:51,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:51,352 INFO:     Epoch: 50
2022-11-23 02:48:52,187 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8497465388341383, 'Total loss': 0.8497465388341383} | train loss {'Reaction outcome loss': 0.8151277436285603, 'Total loss': 0.8151277436285603}
2022-11-23 02:48:52,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:52,187 INFO:     Epoch: 51
2022-11-23 02:48:53,015 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8638729656284506, 'Total loss': 0.8638729656284506} | train loss {'Reaction outcome loss': 0.8183803660529, 'Total loss': 0.8183803660529}
2022-11-23 02:48:53,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:53,015 INFO:     Epoch: 52
2022-11-23 02:48:53,818 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8386570106853138, 'Total loss': 0.8386570106853138} | train loss {'Reaction outcome loss': 0.8190018052957496, 'Total loss': 0.8190018052957496}
2022-11-23 02:48:53,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:53,820 INFO:     Epoch: 53
2022-11-23 02:48:54,638 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8416902449997988, 'Total loss': 0.8416902449997988} | train loss {'Reaction outcome loss': 0.8216558861489198, 'Total loss': 0.8216558861489198}
2022-11-23 02:48:54,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:54,639 INFO:     Epoch: 54
2022-11-23 02:48:55,415 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8650396940383044, 'Total loss': 0.8650396940383044} | train loss {'Reaction outcome loss': 0.8179930772100176, 'Total loss': 0.8179930772100176}
2022-11-23 02:48:55,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:55,416 INFO:     Epoch: 55
2022-11-23 02:48:56,228 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8387639698657122, 'Total loss': 0.8387639698657122} | train loss {'Reaction outcome loss': 0.8205270457024477, 'Total loss': 0.8205270457024477}
2022-11-23 02:48:56,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:56,228 INFO:     Epoch: 56
2022-11-23 02:48:56,998 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8612378618933938, 'Total loss': 0.8612378618933938} | train loss {'Reaction outcome loss': 0.8170721799743419, 'Total loss': 0.8170721799743419}
2022-11-23 02:48:56,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:56,998 INFO:     Epoch: 57
2022-11-23 02:48:57,795 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8467598381367597, 'Total loss': 0.8467598381367597} | train loss {'Reaction outcome loss': 0.8177236359946581, 'Total loss': 0.8177236359946581}
2022-11-23 02:48:57,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:57,795 INFO:     Epoch: 58
2022-11-23 02:48:58,578 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8446933749047193, 'Total loss': 0.8446933749047193} | train loss {'Reaction outcome loss': 0.8161127746105195, 'Total loss': 0.8161127746105195}
2022-11-23 02:48:58,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:58,578 INFO:     Epoch: 59
2022-11-23 02:48:59,367 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8496868441050703, 'Total loss': 0.8496868441050703} | train loss {'Reaction outcome loss': 0.8170029418809074, 'Total loss': 0.8170029418809074}
2022-11-23 02:48:59,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:48:59,368 INFO:     Epoch: 60
2022-11-23 02:49:00,158 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8434391390870918, 'Total loss': 0.8434391390870918} | train loss {'Reaction outcome loss': 0.8157339767533905, 'Total loss': 0.8157339767533905}
2022-11-23 02:49:00,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:00,158 INFO:     Epoch: 61
2022-11-23 02:49:00,961 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8458464822985909, 'Total loss': 0.8458464822985909} | train loss {'Reaction outcome loss': 0.8245447652680533, 'Total loss': 0.8245447652680533}
2022-11-23 02:49:00,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:00,962 INFO:     Epoch: 62
2022-11-23 02:49:01,755 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8483333235437219, 'Total loss': 0.8483333235437219} | train loss {'Reaction outcome loss': 0.8210503064856237, 'Total loss': 0.8210503064856237}
2022-11-23 02:49:01,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:01,755 INFO:     Epoch: 63
2022-11-23 02:49:02,557 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8346611816774715, 'Total loss': 0.8346611816774715} | train loss {'Reaction outcome loss': 0.8228621733431913, 'Total loss': 0.8228621733431913}
2022-11-23 02:49:02,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:02,557 INFO:     Epoch: 64
2022-11-23 02:49:03,357 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8301203535361723, 'Total loss': 0.8301203535361723} | train loss {'Reaction outcome loss': 0.8191190750015025, 'Total loss': 0.8191190750015025}
2022-11-23 02:49:03,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:03,357 INFO:     Epoch: 65
2022-11-23 02:49:04,165 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8392355889081955, 'Total loss': 0.8392355889081955} | train loss {'Reaction outcome loss': 0.820923152505135, 'Total loss': 0.820923152505135}
2022-11-23 02:49:04,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:04,166 INFO:     Epoch: 66
2022-11-23 02:49:04,924 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8344096418639476, 'Total loss': 0.8344096418639476} | train loss {'Reaction outcome loss': 0.8177062928676605, 'Total loss': 0.8177062928676605}
2022-11-23 02:49:04,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:04,926 INFO:     Epoch: 67
2022-11-23 02:49:05,706 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8468790277838707, 'Total loss': 0.8468790277838707} | train loss {'Reaction outcome loss': 0.8243000058495269, 'Total loss': 0.8243000058495269}
2022-11-23 02:49:05,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:05,706 INFO:     Epoch: 68
2022-11-23 02:49:06,480 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8474282188849016, 'Total loss': 0.8474282188849016} | train loss {'Reaction outcome loss': 0.817532045378977, 'Total loss': 0.817532045378977}
2022-11-23 02:49:06,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:06,480 INFO:     Epoch: 69
2022-11-23 02:49:07,263 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8592403382062912, 'Total loss': 0.8592403382062912} | train loss {'Reaction outcome loss': 0.8170831848163994, 'Total loss': 0.8170831848163994}
2022-11-23 02:49:07,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:07,263 INFO:     Epoch: 70
2022-11-23 02:49:08,062 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8909949992190708, 'Total loss': 0.8909949992190708} | train loss {'Reaction outcome loss': 0.8183163673293834, 'Total loss': 0.8183163673293834}
2022-11-23 02:49:08,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:08,062 INFO:     Epoch: 71
2022-11-23 02:49:08,859 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8507830094207417, 'Total loss': 0.8507830094207417} | train loss {'Reaction outcome loss': 0.8237506120788808, 'Total loss': 0.8237506120788808}
2022-11-23 02:49:08,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:08,860 INFO:     Epoch: 72
2022-11-23 02:49:09,678 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8413206020539458, 'Total loss': 0.8413206020539458} | train loss {'Reaction outcome loss': 0.8161961157711185, 'Total loss': 0.8161961157711185}
2022-11-23 02:49:09,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:09,678 INFO:     Epoch: 73
2022-11-23 02:49:10,448 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8470272801139138, 'Total loss': 0.8470272801139138} | train loss {'Reaction outcome loss': 0.8242890846972563, 'Total loss': 0.8242890846972563}
2022-11-23 02:49:10,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:10,449 INFO:     Epoch: 74
2022-11-23 02:49:11,266 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8533462116664107, 'Total loss': 0.8533462116664107} | train loss {'Reaction outcome loss': 0.8220432540591882, 'Total loss': 0.8220432540591882}
2022-11-23 02:49:11,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:11,266 INFO:     Epoch: 75
2022-11-23 02:49:12,021 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8376834487373178, 'Total loss': 0.8376834487373178} | train loss {'Reaction outcome loss': 0.8211106910997508, 'Total loss': 0.8211106910997508}
2022-11-23 02:49:12,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:12,022 INFO:     Epoch: 76
2022-11-23 02:49:12,812 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8399783020669763, 'Total loss': 0.8399783020669763} | train loss {'Reaction outcome loss': 0.8176682107302607, 'Total loss': 0.8176682107302607}
2022-11-23 02:49:12,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:12,812 INFO:     Epoch: 77
2022-11-23 02:49:13,589 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8809644661166451, 'Total loss': 0.8809644661166451} | train loss {'Reaction outcome loss': 0.8156770681848331, 'Total loss': 0.8156770681848331}
2022-11-23 02:49:13,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:13,589 INFO:     Epoch: 78
2022-11-23 02:49:14,345 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8415727351199497, 'Total loss': 0.8415727351199497} | train loss {'Reaction outcome loss': 0.8169135874631454, 'Total loss': 0.8169135874631454}
2022-11-23 02:49:14,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:14,345 INFO:     Epoch: 79
2022-11-23 02:49:15,142 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8512565629048781, 'Total loss': 0.8512565629048781} | train loss {'Reaction outcome loss': 0.8207089197878935, 'Total loss': 0.8207089197878935}
2022-11-23 02:49:15,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:15,142 INFO:     Epoch: 80
2022-11-23 02:49:16,000 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8347417989915068, 'Total loss': 0.8347417989915068} | train loss {'Reaction outcome loss': 0.818505033059996, 'Total loss': 0.818505033059996}
2022-11-23 02:49:16,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:16,001 INFO:     Epoch: 81
2022-11-23 02:49:16,784 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8363210965286602, 'Total loss': 0.8363210965286602} | train loss {'Reaction outcome loss': 0.8196888007679765, 'Total loss': 0.8196888007679765}
2022-11-23 02:49:16,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:16,784 INFO:     Epoch: 82
2022-11-23 02:49:17,602 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8420144035057588, 'Total loss': 0.8420144035057588} | train loss {'Reaction outcome loss': 0.8177804258404946, 'Total loss': 0.8177804258404946}
2022-11-23 02:49:17,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:17,602 INFO:     Epoch: 83
2022-11-23 02:49:18,415 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8375294960357926, 'Total loss': 0.8375294960357926} | train loss {'Reaction outcome loss': 0.8225237014342327, 'Total loss': 0.8225237014342327}
2022-11-23 02:49:18,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:18,416 INFO:     Epoch: 84
2022-11-23 02:49:19,212 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8431014235724102, 'Total loss': 0.8431014235724102} | train loss {'Reaction outcome loss': 0.818495299499862, 'Total loss': 0.818495299499862}
2022-11-23 02:49:19,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:19,213 INFO:     Epoch: 85
2022-11-23 02:49:20,015 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8687580674886703, 'Total loss': 0.8687580674886703} | train loss {'Reaction outcome loss': 0.8162391882769916, 'Total loss': 0.8162391882769916}
2022-11-23 02:49:20,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:20,015 INFO:     Epoch: 86
2022-11-23 02:49:20,856 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8454433659260924, 'Total loss': 0.8454433659260924} | train loss {'Reaction outcome loss': 0.8201060018977341, 'Total loss': 0.8201060018977341}
2022-11-23 02:49:20,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:20,856 INFO:     Epoch: 87
2022-11-23 02:49:21,665 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8516947708346627, 'Total loss': 0.8516947708346627} | train loss {'Reaction outcome loss': 0.8209309262888772, 'Total loss': 0.8209309262888772}
2022-11-23 02:49:21,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:21,667 INFO:     Epoch: 88
2022-11-23 02:49:22,494 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8500133163549684, 'Total loss': 0.8500133163549684} | train loss {'Reaction outcome loss': 0.8189152521746499, 'Total loss': 0.8189152521746499}
2022-11-23 02:49:22,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:22,494 INFO:     Epoch: 89
2022-11-23 02:49:23,313 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8303750441832976, 'Total loss': 0.8303750441832976} | train loss {'Reaction outcome loss': 0.8168978446600389, 'Total loss': 0.8168978446600389}
2022-11-23 02:49:23,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:23,313 INFO:     Epoch: 90
2022-11-23 02:49:24,121 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8354434391314333, 'Total loss': 0.8354434391314333} | train loss {'Reaction outcome loss': 0.8162811235505707, 'Total loss': 0.8162811235505707}
2022-11-23 02:49:24,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:24,122 INFO:     Epoch: 91
2022-11-23 02:49:24,912 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8748193735426123, 'Total loss': 0.8748193735426123} | train loss {'Reaction outcome loss': 0.8186410652131451, 'Total loss': 0.8186410652131451}
2022-11-23 02:49:24,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:24,912 INFO:     Epoch: 92
2022-11-23 02:49:25,702 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8361069512638178, 'Total loss': 0.8361069512638178} | train loss {'Reaction outcome loss': 0.8186185245611229, 'Total loss': 0.8186185245611229}
2022-11-23 02:49:25,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:25,703 INFO:     Epoch: 93
2022-11-23 02:49:26,492 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.836071331392635, 'Total loss': 0.836071331392635} | train loss {'Reaction outcome loss': 0.8200059859120116, 'Total loss': 0.8200059859120116}
2022-11-23 02:49:26,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:26,493 INFO:     Epoch: 94
2022-11-23 02:49:27,294 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8590175015005198, 'Total loss': 0.8590175015005198} | train loss {'Reaction outcome loss': 0.8193795038121087, 'Total loss': 0.8193795038121087}
2022-11-23 02:49:27,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:27,295 INFO:     Epoch: 95
2022-11-23 02:49:28,102 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.851243869824843, 'Total loss': 0.851243869824843} | train loss {'Reaction outcome loss': 0.8209436738977627, 'Total loss': 0.8209436738977627}
2022-11-23 02:49:28,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:28,102 INFO:     Epoch: 96
2022-11-23 02:49:28,913 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8646663664416834, 'Total loss': 0.8646663664416834} | train loss {'Reaction outcome loss': 0.8233588555637671, 'Total loss': 0.8233588555637671}
2022-11-23 02:49:28,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:28,913 INFO:     Epoch: 97
2022-11-23 02:49:29,725 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8396443656899713, 'Total loss': 0.8396443656899713} | train loss {'Reaction outcome loss': 0.8226238531725747, 'Total loss': 0.8226238531725747}
2022-11-23 02:49:29,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:29,725 INFO:     Epoch: 98
2022-11-23 02:49:30,519 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8601524694399401, 'Total loss': 0.8601524694399401} | train loss {'Reaction outcome loss': 0.8166096812608291, 'Total loss': 0.8166096812608291}
2022-11-23 02:49:30,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:30,520 INFO:     Epoch: 99
2022-11-23 02:49:31,326 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8415984362363815, 'Total loss': 0.8415984362363815} | train loss {'Reaction outcome loss': 0.8152419923519602, 'Total loss': 0.8152419923519602}
2022-11-23 02:49:31,326 INFO:     Best model found after epoch 47 of 100.
2022-11-23 02:49:31,326 INFO:   Done with stage: TRAINING
2022-11-23 02:49:31,326 INFO:   Starting stage: EVALUATION
2022-11-23 02:49:31,456 INFO:   Done with stage: EVALUATION
2022-11-23 02:49:31,456 INFO:   Leaving out SEQ value Fold_6
2022-11-23 02:49:31,469 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:49:31,469 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:49:32,138 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:49:32,138 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:49:32,212 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:49:32,212 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:49:32,212 INFO:     No hyperparam tuning for this model
2022-11-23 02:49:32,212 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:49:32,212 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:49:32,213 INFO:     None feature selector for col prot
2022-11-23 02:49:32,213 INFO:     None feature selector for col prot
2022-11-23 02:49:32,213 INFO:     None feature selector for col prot
2022-11-23 02:49:32,213 INFO:     None feature selector for col chem
2022-11-23 02:49:32,214 INFO:     None feature selector for col chem
2022-11-23 02:49:32,214 INFO:     None feature selector for col chem
2022-11-23 02:49:32,214 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:49:32,214 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:49:32,215 INFO:     Number of params in model 168571
2022-11-23 02:49:32,218 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:49:32,219 INFO:   Starting stage: TRAINING
2022-11-23 02:49:32,277 INFO:     Val loss before train {'Reaction outcome loss': 1.0094014636494897, 'Total loss': 1.0094014636494897}
2022-11-23 02:49:32,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:32,277 INFO:     Epoch: 0
2022-11-23 02:49:33,096 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8640391630205241, 'Total loss': 0.8640391630205241} | train loss {'Reaction outcome loss': 0.8877533415873204, 'Total loss': 0.8877533415873204}
2022-11-23 02:49:33,097 INFO:     Found new best model at epoch 0
2022-11-23 02:49:33,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:33,098 INFO:     Epoch: 1
2022-11-23 02:49:33,894 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8052339188077233, 'Total loss': 0.8052339188077233} | train loss {'Reaction outcome loss': 0.8554992851230406, 'Total loss': 0.8554992851230406}
2022-11-23 02:49:33,895 INFO:     Found new best model at epoch 1
2022-11-23 02:49:33,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:33,896 INFO:     Epoch: 2
2022-11-23 02:49:34,719 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.816878039051186, 'Total loss': 0.816878039051186} | train loss {'Reaction outcome loss': 0.8398740136575314, 'Total loss': 0.8398740136575314}
2022-11-23 02:49:34,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:34,720 INFO:     Epoch: 3
2022-11-23 02:49:35,507 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8146674253723838, 'Total loss': 0.8146674253723838} | train loss {'Reaction outcome loss': 0.8428993804320213, 'Total loss': 0.8428993804320213}
2022-11-23 02:49:35,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:35,507 INFO:     Epoch: 4
2022-11-23 02:49:36,308 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8047099702737548, 'Total loss': 0.8047099702737548} | train loss {'Reaction outcome loss': 0.8378220925167683, 'Total loss': 0.8378220925167683}
2022-11-23 02:49:36,309 INFO:     Found new best model at epoch 4
2022-11-23 02:49:36,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:36,310 INFO:     Epoch: 5
2022-11-23 02:49:37,122 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.790201625702056, 'Total loss': 0.790201625702056} | train loss {'Reaction outcome loss': 0.8317054315440117, 'Total loss': 0.8317054315440117}
2022-11-23 02:49:37,122 INFO:     Found new best model at epoch 5
2022-11-23 02:49:37,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:37,123 INFO:     Epoch: 6
2022-11-23 02:49:37,909 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7979451445015994, 'Total loss': 0.7979451445015994} | train loss {'Reaction outcome loss': 0.8308968893702953, 'Total loss': 0.8308968893702953}
2022-11-23 02:49:37,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:37,910 INFO:     Epoch: 7
2022-11-23 02:49:38,760 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8008686188947071, 'Total loss': 0.8008686188947071} | train loss {'Reaction outcome loss': 0.8278871729008613, 'Total loss': 0.8278871729008613}
2022-11-23 02:49:38,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:38,761 INFO:     Epoch: 8
2022-11-23 02:49:39,573 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7917702733115717, 'Total loss': 0.7917702733115717} | train loss {'Reaction outcome loss': 0.822442177322603, 'Total loss': 0.822442177322603}
2022-11-23 02:49:39,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:39,574 INFO:     Epoch: 9
2022-11-23 02:49:40,345 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7930053201588717, 'Total loss': 0.7930053201588717} | train loss {'Reaction outcome loss': 0.8274710642233971, 'Total loss': 0.8274710642233971}
2022-11-23 02:49:40,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:40,345 INFO:     Epoch: 10
2022-11-23 02:49:41,202 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7945982874794439, 'Total loss': 0.7945982874794439} | train loss {'Reaction outcome loss': 0.8226039360367483, 'Total loss': 0.8226039360367483}
2022-11-23 02:49:41,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:41,202 INFO:     Epoch: 11
2022-11-23 02:49:42,058 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8044479631564834, 'Total loss': 0.8044479631564834} | train loss {'Reaction outcome loss': 0.8244263016648831, 'Total loss': 0.8244263016648831}
2022-11-23 02:49:42,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:42,058 INFO:     Epoch: 12
2022-11-23 02:49:42,892 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8048394661058079, 'Total loss': 0.8048394661058079} | train loss {'Reaction outcome loss': 0.8243807706861727, 'Total loss': 0.8243807706861727}
2022-11-23 02:49:42,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:42,892 INFO:     Epoch: 13
2022-11-23 02:49:43,708 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7888865078037436, 'Total loss': 0.7888865078037436} | train loss {'Reaction outcome loss': 0.8166540859928054, 'Total loss': 0.8166540859928054}
2022-11-23 02:49:43,708 INFO:     Found new best model at epoch 13
2022-11-23 02:49:43,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:43,709 INFO:     Epoch: 14
2022-11-23 02:49:44,528 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8135458251292055, 'Total loss': 0.8135458251292055} | train loss {'Reaction outcome loss': 0.8217954360429318, 'Total loss': 0.8217954360429318}
2022-11-23 02:49:44,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:44,529 INFO:     Epoch: 15
2022-11-23 02:49:45,337 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.805276476524093, 'Total loss': 0.805276476524093} | train loss {'Reaction outcome loss': 0.8234658598178818, 'Total loss': 0.8234658598178818}
2022-11-23 02:49:45,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:45,338 INFO:     Epoch: 16
2022-11-23 02:49:46,145 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8064021170139313, 'Total loss': 0.8064021170139313} | train loss {'Reaction outcome loss': 0.8241587614099826, 'Total loss': 0.8241587614099826}
2022-11-23 02:49:46,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:46,146 INFO:     Epoch: 17
2022-11-23 02:49:46,938 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.791080235757611, 'Total loss': 0.791080235757611} | train loss {'Reaction outcome loss': 0.8247805228156428, 'Total loss': 0.8247805228156428}
2022-11-23 02:49:46,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:46,938 INFO:     Epoch: 18
2022-11-23 02:49:47,745 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.791219258850271, 'Total loss': 0.791219258850271} | train loss {'Reaction outcome loss': 0.8198781603526685, 'Total loss': 0.8198781603526685}
2022-11-23 02:49:47,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:47,746 INFO:     Epoch: 19
2022-11-23 02:49:48,528 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8129486549984325, 'Total loss': 0.8129486549984325} | train loss {'Reaction outcome loss': 0.820394845979829, 'Total loss': 0.820394845979829}
2022-11-23 02:49:48,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:48,529 INFO:     Epoch: 20
2022-11-23 02:49:49,305 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7986070134422996, 'Total loss': 0.7986070134422996} | train loss {'Reaction outcome loss': 0.8220676145245952, 'Total loss': 0.8220676145245952}
2022-11-23 02:49:49,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:49,306 INFO:     Epoch: 21
2022-11-23 02:49:50,174 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7925464788621123, 'Total loss': 0.7925464788621123} | train loss {'Reaction outcome loss': 0.8177585512880357, 'Total loss': 0.8177585512880357}
2022-11-23 02:49:50,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:50,174 INFO:     Epoch: 22
2022-11-23 02:49:51,031 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8122569593516263, 'Total loss': 0.8122569593516263} | train loss {'Reaction outcome loss': 0.8191401807050551, 'Total loss': 0.8191401807050551}
2022-11-23 02:49:51,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:51,031 INFO:     Epoch: 23
2022-11-23 02:49:51,847 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8045686679807577, 'Total loss': 0.8045686679807577} | train loss {'Reaction outcome loss': 0.8222874154246622, 'Total loss': 0.8222874154246622}
2022-11-23 02:49:51,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:51,848 INFO:     Epoch: 24
2022-11-23 02:49:52,674 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.800431451336904, 'Total loss': 0.800431451336904} | train loss {'Reaction outcome loss': 0.8187745316855369, 'Total loss': 0.8187745316855369}
2022-11-23 02:49:52,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:52,674 INFO:     Epoch: 25
2022-11-23 02:49:53,508 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.787552607330409, 'Total loss': 0.787552607330409} | train loss {'Reaction outcome loss': 0.8184166404028093, 'Total loss': 0.8184166404028093}
2022-11-23 02:49:53,509 INFO:     Found new best model at epoch 25
2022-11-23 02:49:53,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:53,510 INFO:     Epoch: 26
2022-11-23 02:49:54,336 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7854850949211554, 'Total loss': 0.7854850949211554} | train loss {'Reaction outcome loss': 0.8199974592895277, 'Total loss': 0.8199974592895277}
2022-11-23 02:49:54,336 INFO:     Found new best model at epoch 26
2022-11-23 02:49:54,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:54,337 INFO:     Epoch: 27
2022-11-23 02:49:55,168 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7872560715133493, 'Total loss': 0.7872560715133493} | train loss {'Reaction outcome loss': 0.8221596048003242, 'Total loss': 0.8221596048003242}
2022-11-23 02:49:55,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:55,168 INFO:     Epoch: 28
2022-11-23 02:49:55,986 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8033595383167267, 'Total loss': 0.8033595383167267} | train loss {'Reaction outcome loss': 0.8159339907428911, 'Total loss': 0.8159339907428911}
2022-11-23 02:49:55,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:55,987 INFO:     Epoch: 29
2022-11-23 02:49:56,804 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7877024412155151, 'Total loss': 0.7877024412155151} | train loss {'Reaction outcome loss': 0.8186361736828281, 'Total loss': 0.8186361736828281}
2022-11-23 02:49:56,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:56,804 INFO:     Epoch: 30
2022-11-23 02:49:57,611 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7997378612106497, 'Total loss': 0.7997378612106497} | train loss {'Reaction outcome loss': 0.8189049578241764, 'Total loss': 0.8189049578241764}
2022-11-23 02:49:57,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:57,611 INFO:     Epoch: 31
2022-11-23 02:49:58,430 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8082432293079116, 'Total loss': 0.8082432293079116} | train loss {'Reaction outcome loss': 0.8169837848794076, 'Total loss': 0.8169837848794076}
2022-11-23 02:49:58,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:58,432 INFO:     Epoch: 32
2022-11-23 02:49:59,204 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7958240630951795, 'Total loss': 0.7958240630951795} | train loss {'Reaction outcome loss': 0.8158358466481009, 'Total loss': 0.8158358466481009}
2022-11-23 02:49:59,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:49:59,205 INFO:     Epoch: 33
2022-11-23 02:50:00,019 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7965457073666833, 'Total loss': 0.7965457073666833} | train loss {'Reaction outcome loss': 0.8148419436427855, 'Total loss': 0.8148419436427855}
2022-11-23 02:50:00,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:00,019 INFO:     Epoch: 34
2022-11-23 02:50:00,824 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7776092406023632, 'Total loss': 0.7776092406023632} | train loss {'Reaction outcome loss': 0.8191104492833537, 'Total loss': 0.8191104492833537}
2022-11-23 02:50:00,824 INFO:     Found new best model at epoch 34
2022-11-23 02:50:00,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:00,825 INFO:     Epoch: 35
2022-11-23 02:50:01,646 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7828231575814161, 'Total loss': 0.7828231575814161} | train loss {'Reaction outcome loss': 0.8225393866098696, 'Total loss': 0.8225393866098696}
2022-11-23 02:50:01,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:01,646 INFO:     Epoch: 36
2022-11-23 02:50:02,410 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8003758124329827, 'Total loss': 0.8003758124329827} | train loss {'Reaction outcome loss': 0.8142823397872909, 'Total loss': 0.8142823397872909}
2022-11-23 02:50:02,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:02,411 INFO:     Epoch: 37
2022-11-23 02:50:03,221 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7963518425822258, 'Total loss': 0.7963518425822258} | train loss {'Reaction outcome loss': 0.8174539189184865, 'Total loss': 0.8174539189184865}
2022-11-23 02:50:03,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:03,221 INFO:     Epoch: 38
2022-11-23 02:50:04,026 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7940924099900506, 'Total loss': 0.7940924099900506} | train loss {'Reaction outcome loss': 0.8206031306857063, 'Total loss': 0.8206031306857063}
2022-11-23 02:50:04,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:04,026 INFO:     Epoch: 39
2022-11-23 02:50:04,836 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7898844439874996, 'Total loss': 0.7898844439874996} | train loss {'Reaction outcome loss': 0.8174741181635088, 'Total loss': 0.8174741181635088}
2022-11-23 02:50:04,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:04,837 INFO:     Epoch: 40
2022-11-23 02:50:05,685 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7938065969131209, 'Total loss': 0.7938065969131209} | train loss {'Reaction outcome loss': 0.817125184401389, 'Total loss': 0.817125184401389}
2022-11-23 02:50:05,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:05,685 INFO:     Epoch: 41
2022-11-23 02:50:06,486 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7973083813082088, 'Total loss': 0.7973083813082088} | train loss {'Reaction outcome loss': 0.8183881623610374, 'Total loss': 0.8183881623610374}
2022-11-23 02:50:06,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:06,486 INFO:     Epoch: 42
2022-11-23 02:50:07,286 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7805807495659048, 'Total loss': 0.7805807495659048} | train loss {'Reaction outcome loss': 0.8215995005542233, 'Total loss': 0.8215995005542233}
2022-11-23 02:50:07,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:07,287 INFO:     Epoch: 43
2022-11-23 02:50:08,107 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7901637012308295, 'Total loss': 0.7901637012308295} | train loss {'Reaction outcome loss': 0.8128895042163711, 'Total loss': 0.8128895042163711}
2022-11-23 02:50:08,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:08,107 INFO:     Epoch: 44
2022-11-23 02:50:08,895 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8616273389621214, 'Total loss': 0.8616273389621214} | train loss {'Reaction outcome loss': 0.8207342979167739, 'Total loss': 0.8207342979167739}
2022-11-23 02:50:08,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:08,895 INFO:     Epoch: 45
2022-11-23 02:50:09,722 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7913901345296339, 'Total loss': 0.7913901345296339} | train loss {'Reaction outcome loss': 0.8210955269394382, 'Total loss': 0.8210955269394382}
2022-11-23 02:50:09,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:09,722 INFO:     Epoch: 46
2022-11-23 02:50:10,541 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8141487660733137, 'Total loss': 0.8141487660733137} | train loss {'Reaction outcome loss': 0.8194056065572847, 'Total loss': 0.8194056065572847}
2022-11-23 02:50:10,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:10,541 INFO:     Epoch: 47
2022-11-23 02:50:11,365 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8241246274926446, 'Total loss': 0.8241246274926446} | train loss {'Reaction outcome loss': 0.8169620726858416, 'Total loss': 0.8169620726858416}
2022-11-23 02:50:11,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:11,366 INFO:     Epoch: 48
2022-11-23 02:50:12,172 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7898533635518767, 'Total loss': 0.7898533635518767} | train loss {'Reaction outcome loss': 0.8161621186281404, 'Total loss': 0.8161621186281404}
2022-11-23 02:50:12,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:12,173 INFO:     Epoch: 49
2022-11-23 02:50:12,980 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7800100147724152, 'Total loss': 0.7800100147724152} | train loss {'Reaction outcome loss': 0.8220511023556033, 'Total loss': 0.8220511023556033}
2022-11-23 02:50:12,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:12,980 INFO:     Epoch: 50
2022-11-23 02:50:13,809 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7908902913331985, 'Total loss': 0.7908902913331985} | train loss {'Reaction outcome loss': 0.8227899206742164, 'Total loss': 0.8227899206742164}
2022-11-23 02:50:13,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:13,809 INFO:     Epoch: 51
2022-11-23 02:50:14,635 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7992506934837862, 'Total loss': 0.7992506934837862} | train loss {'Reaction outcome loss': 0.8143588886145623, 'Total loss': 0.8143588886145623}
2022-11-23 02:50:14,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:14,635 INFO:     Epoch: 52
2022-11-23 02:50:15,393 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8013629825277762, 'Total loss': 0.8013629825277762} | train loss {'Reaction outcome loss': 0.8169896647093757, 'Total loss': 0.8169896647093757}
2022-11-23 02:50:15,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:15,393 INFO:     Epoch: 53
2022-11-23 02:50:16,187 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8108646273612976, 'Total loss': 0.8108646273612976} | train loss {'Reaction outcome loss': 0.8153754942599805, 'Total loss': 0.8153754942599805}
2022-11-23 02:50:16,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:16,187 INFO:     Epoch: 54
2022-11-23 02:50:17,020 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.785358502106233, 'Total loss': 0.785358502106233} | train loss {'Reaction outcome loss': 0.8205641982776504, 'Total loss': 0.8205641982776504}
2022-11-23 02:50:17,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:17,021 INFO:     Epoch: 55
2022-11-23 02:50:17,821 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8044504814527251, 'Total loss': 0.8044504814527251} | train loss {'Reaction outcome loss': 0.8206378868029963, 'Total loss': 0.8206378868029963}
2022-11-23 02:50:17,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:17,821 INFO:     Epoch: 56
2022-11-23 02:50:18,602 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7935147095810283, 'Total loss': 0.7935147095810283} | train loss {'Reaction outcome loss': 0.8195818942641059, 'Total loss': 0.8195818942641059}
2022-11-23 02:50:18,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:18,602 INFO:     Epoch: 57
2022-11-23 02:50:19,384 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7898043644699183, 'Total loss': 0.7898043644699183} | train loss {'Reaction outcome loss': 0.8154102095192478, 'Total loss': 0.8154102095192478}
2022-11-23 02:50:19,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:19,385 INFO:     Epoch: 58
2022-11-23 02:50:20,244 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7834027402780273, 'Total loss': 0.7834027402780273} | train loss {'Reaction outcome loss': 0.821940474452511, 'Total loss': 0.821940474452511}
2022-11-23 02:50:20,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:20,244 INFO:     Epoch: 59
2022-11-23 02:50:21,069 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7829687642780218, 'Total loss': 0.7829687642780218} | train loss {'Reaction outcome loss': 0.8180317968851135, 'Total loss': 0.8180317968851135}
2022-11-23 02:50:21,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:21,069 INFO:     Epoch: 60
2022-11-23 02:50:21,911 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8020559153096243, 'Total loss': 0.8020559153096243} | train loss {'Reaction outcome loss': 0.8163824756779978, 'Total loss': 0.8163824756779978}
2022-11-23 02:50:21,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:21,911 INFO:     Epoch: 61
2022-11-23 02:50:22,746 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7986249564723535, 'Total loss': 0.7986249564723535} | train loss {'Reaction outcome loss': 0.819594157318915, 'Total loss': 0.819594157318915}
2022-11-23 02:50:22,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:22,747 INFO:     Epoch: 62
2022-11-23 02:50:23,528 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7977181002497673, 'Total loss': 0.7977181002497673} | train loss {'Reaction outcome loss': 0.8171030207266731, 'Total loss': 0.8171030207266731}
2022-11-23 02:50:23,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:23,528 INFO:     Epoch: 63
2022-11-23 02:50:24,349 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7780045758594166, 'Total loss': 0.7780045758594166} | train loss {'Reaction outcome loss': 0.8154649876298443, 'Total loss': 0.8154649876298443}
2022-11-23 02:50:24,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:24,350 INFO:     Epoch: 64
2022-11-23 02:50:25,178 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7914576124061238, 'Total loss': 0.7914576124061238} | train loss {'Reaction outcome loss': 0.8166991413360641, 'Total loss': 0.8166991413360641}
2022-11-23 02:50:25,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:25,178 INFO:     Epoch: 65
2022-11-23 02:50:26,009 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7929244637489319, 'Total loss': 0.7929244637489319} | train loss {'Reaction outcome loss': 0.8181912384686931, 'Total loss': 0.8181912384686931}
2022-11-23 02:50:26,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:26,009 INFO:     Epoch: 66
2022-11-23 02:50:26,854 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7933550212870945, 'Total loss': 0.7933550212870945} | train loss {'Reaction outcome loss': 0.8214361966857987, 'Total loss': 0.8214361966857987}
2022-11-23 02:50:26,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:26,855 INFO:     Epoch: 67
2022-11-23 02:50:27,669 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8011119521477006, 'Total loss': 0.8011119521477006} | train loss {'Reaction outcome loss': 0.8136956994571993, 'Total loss': 0.8136956994571993}
2022-11-23 02:50:27,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:27,669 INFO:     Epoch: 68
2022-11-23 02:50:28,466 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7865196039730852, 'Total loss': 0.7865196039730852} | train loss {'Reaction outcome loss': 0.8213713331328284, 'Total loss': 0.8213713331328284}
2022-11-23 02:50:28,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:28,467 INFO:     Epoch: 69
2022-11-23 02:50:29,286 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7879995263435624, 'Total loss': 0.7879995263435624} | train loss {'Reaction outcome loss': 0.8215831614309742, 'Total loss': 0.8215831614309742}
2022-11-23 02:50:29,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:29,288 INFO:     Epoch: 70
2022-11-23 02:50:30,080 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7836671688339927, 'Total loss': 0.7836671688339927} | train loss {'Reaction outcome loss': 0.8175429453051859, 'Total loss': 0.8175429453051859}
2022-11-23 02:50:30,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:30,080 INFO:     Epoch: 71
2022-11-23 02:50:30,869 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8019560446793382, 'Total loss': 0.8019560446793382} | train loss {'Reaction outcome loss': 0.8156957399220236, 'Total loss': 0.8156957399220236}
2022-11-23 02:50:30,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:30,869 INFO:     Epoch: 72
2022-11-23 02:50:31,646 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.78522127866745, 'Total loss': 0.78522127866745} | train loss {'Reaction outcome loss': 0.8203078878502692, 'Total loss': 0.8203078878502692}
2022-11-23 02:50:31,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:31,647 INFO:     Epoch: 73
2022-11-23 02:50:32,477 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7897036759690805, 'Total loss': 0.7897036759690805} | train loss {'Reaction outcome loss': 0.8187256612845005, 'Total loss': 0.8187256612845005}
2022-11-23 02:50:32,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:32,477 INFO:     Epoch: 74
2022-11-23 02:50:33,306 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7979523146694357, 'Total loss': 0.7979523146694357} | train loss {'Reaction outcome loss': 0.8159333852029615, 'Total loss': 0.8159333852029615}
2022-11-23 02:50:33,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:33,306 INFO:     Epoch: 75
2022-11-23 02:50:34,126 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7863725477998907, 'Total loss': 0.7863725477998907} | train loss {'Reaction outcome loss': 0.8174190277293805, 'Total loss': 0.8174190277293805}
2022-11-23 02:50:34,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:34,127 INFO:     Epoch: 76
2022-11-23 02:50:34,916 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7985754372044043, 'Total loss': 0.7985754372044043} | train loss {'Reaction outcome loss': 0.8168467559641407, 'Total loss': 0.8168467559641407}
2022-11-23 02:50:34,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:34,917 INFO:     Epoch: 77
2022-11-23 02:50:35,706 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8023152534257282, 'Total loss': 0.8023152534257282} | train loss {'Reaction outcome loss': 0.8209475871295698, 'Total loss': 0.8209475871295698}
2022-11-23 02:50:35,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:35,707 INFO:     Epoch: 78
2022-11-23 02:50:36,502 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7983054125850851, 'Total loss': 0.7983054125850851} | train loss {'Reaction outcome loss': 0.8145754900911162, 'Total loss': 0.8145754900911162}
2022-11-23 02:50:36,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:36,502 INFO:     Epoch: 79
2022-11-23 02:50:37,302 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7920672155239366, 'Total loss': 0.7920672155239366} | train loss {'Reaction outcome loss': 0.8188302071104127, 'Total loss': 0.8188302071104127}
2022-11-23 02:50:37,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:37,302 INFO:     Epoch: 80
2022-11-23 02:50:38,104 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7998259318145838, 'Total loss': 0.7998259318145838} | train loss {'Reaction outcome loss': 0.8148884462012399, 'Total loss': 0.8148884462012399}
2022-11-23 02:50:38,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:38,104 INFO:     Epoch: 81
2022-11-23 02:50:38,945 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.801169521429322, 'Total loss': 0.801169521429322} | train loss {'Reaction outcome loss': 0.812379862752653, 'Total loss': 0.812379862752653}
2022-11-23 02:50:38,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:38,945 INFO:     Epoch: 82
2022-11-23 02:50:39,785 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7960917211391709, 'Total loss': 0.7960917211391709} | train loss {'Reaction outcome loss': 0.8173313132457195, 'Total loss': 0.8173313132457195}
2022-11-23 02:50:39,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:39,786 INFO:     Epoch: 83
2022-11-23 02:50:40,586 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7988628961823203, 'Total loss': 0.7988628961823203} | train loss {'Reaction outcome loss': 0.8167050017584716, 'Total loss': 0.8167050017584716}
2022-11-23 02:50:40,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:40,586 INFO:     Epoch: 84
2022-11-23 02:50:41,398 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7878087674352255, 'Total loss': 0.7878087674352255} | train loss {'Reaction outcome loss': 0.8158880168151471, 'Total loss': 0.8158880168151471}
2022-11-23 02:50:41,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:41,399 INFO:     Epoch: 85
2022-11-23 02:50:42,201 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7967309653759003, 'Total loss': 0.7967309653759003} | train loss {'Reaction outcome loss': 0.8186390696754379, 'Total loss': 0.8186390696754379}
2022-11-23 02:50:42,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:42,201 INFO:     Epoch: 86
2022-11-23 02:50:42,988 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7908659401265058, 'Total loss': 0.7908659401265058} | train loss {'Reaction outcome loss': 0.8172080828057181, 'Total loss': 0.8172080828057181}
2022-11-23 02:50:42,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:42,989 INFO:     Epoch: 87
2022-11-23 02:50:43,799 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7831246162002737, 'Total loss': 0.7831246162002737} | train loss {'Reaction outcome loss': 0.8176042586565018, 'Total loss': 0.8176042586565018}
2022-11-23 02:50:43,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:43,800 INFO:     Epoch: 88
2022-11-23 02:50:44,587 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.792521433396773, 'Total loss': 0.792521433396773} | train loss {'Reaction outcome loss': 0.8154321786376738, 'Total loss': 0.8154321786376738}
2022-11-23 02:50:44,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:44,587 INFO:     Epoch: 89
2022-11-23 02:50:45,392 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7827644232999195, 'Total loss': 0.7827644232999195} | train loss {'Reaction outcome loss': 0.8145480505641429, 'Total loss': 0.8145480505641429}
2022-11-23 02:50:45,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:45,392 INFO:     Epoch: 90
2022-11-23 02:50:46,177 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8058770075440407, 'Total loss': 0.8058770075440407} | train loss {'Reaction outcome loss': 0.8139855232570441, 'Total loss': 0.8139855232570441}
2022-11-23 02:50:46,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:46,177 INFO:     Epoch: 91
2022-11-23 02:50:46,968 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7804353806105527, 'Total loss': 0.7804353806105527} | train loss {'Reaction outcome loss': 0.8179612102047089, 'Total loss': 0.8179612102047089}
2022-11-23 02:50:46,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:46,969 INFO:     Epoch: 92
2022-11-23 02:50:47,760 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.785663206468929, 'Total loss': 0.785663206468929} | train loss {'Reaction outcome loss': 0.8157014072902741, 'Total loss': 0.8157014072902741}
2022-11-23 02:50:47,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:47,761 INFO:     Epoch: 93
2022-11-23 02:50:48,579 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7988406352021478, 'Total loss': 0.7988406352021478} | train loss {'Reaction outcome loss': 0.814161989116861, 'Total loss': 0.814161989116861}
2022-11-23 02:50:48,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:48,579 INFO:     Epoch: 94
2022-11-23 02:50:49,375 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7853412614627318, 'Total loss': 0.7853412614627318} | train loss {'Reaction outcome loss': 0.8154584165782698, 'Total loss': 0.8154584165782698}
2022-11-23 02:50:49,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:49,375 INFO:     Epoch: 95
2022-11-23 02:50:50,174 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7827455631711266, 'Total loss': 0.7827455631711266} | train loss {'Reaction outcome loss': 0.818713967478083, 'Total loss': 0.818713967478083}
2022-11-23 02:50:50,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:50,175 INFO:     Epoch: 96
2022-11-23 02:50:50,970 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7920351346785371, 'Total loss': 0.7920351346785371} | train loss {'Reaction outcome loss': 0.8193943757684, 'Total loss': 0.8193943757684}
2022-11-23 02:50:50,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:50,970 INFO:     Epoch: 97
2022-11-23 02:50:51,774 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7789822864261541, 'Total loss': 0.7789822864261541} | train loss {'Reaction outcome loss': 0.8165253232563695, 'Total loss': 0.8165253232563695}
2022-11-23 02:50:51,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:51,774 INFO:     Epoch: 98
2022-11-23 02:50:52,557 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7904602438211441, 'Total loss': 0.7904602438211441} | train loss {'Reaction outcome loss': 0.8131740489794362, 'Total loss': 0.8131740489794362}
2022-11-23 02:50:52,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:52,558 INFO:     Epoch: 99
2022-11-23 02:50:53,418 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7948018393733285, 'Total loss': 0.7948018393733285} | train loss {'Reaction outcome loss': 0.8171012466472964, 'Total loss': 0.8171012466472964}
2022-11-23 02:50:53,418 INFO:     Best model found after epoch 35 of 100.
2022-11-23 02:50:53,418 INFO:   Done with stage: TRAINING
2022-11-23 02:50:53,419 INFO:   Starting stage: EVALUATION
2022-11-23 02:50:53,537 INFO:   Done with stage: EVALUATION
2022-11-23 02:50:53,538 INFO:   Leaving out SEQ value Fold_7
2022-11-23 02:50:53,551 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:50:53,551 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:50:54,219 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:50:54,219 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:50:54,292 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:50:54,292 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:50:54,292 INFO:     No hyperparam tuning for this model
2022-11-23 02:50:54,292 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:50:54,292 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:50:54,293 INFO:     None feature selector for col prot
2022-11-23 02:50:54,293 INFO:     None feature selector for col prot
2022-11-23 02:50:54,293 INFO:     None feature selector for col prot
2022-11-23 02:50:54,294 INFO:     None feature selector for col chem
2022-11-23 02:50:54,294 INFO:     None feature selector for col chem
2022-11-23 02:50:54,294 INFO:     None feature selector for col chem
2022-11-23 02:50:54,294 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:50:54,294 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:50:54,296 INFO:     Number of params in model 168571
2022-11-23 02:50:54,299 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:50:54,299 INFO:   Starting stage: TRAINING
2022-11-23 02:50:54,357 INFO:     Val loss before train {'Reaction outcome loss': 1.0237157222899524, 'Total loss': 1.0237157222899524}
2022-11-23 02:50:54,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:54,358 INFO:     Epoch: 0
2022-11-23 02:50:55,192 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8726691549474542, 'Total loss': 0.8726691549474542} | train loss {'Reaction outcome loss': 0.8703606783622696, 'Total loss': 0.8703606783622696}
2022-11-23 02:50:55,192 INFO:     Found new best model at epoch 0
2022-11-23 02:50:55,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:55,193 INFO:     Epoch: 1
2022-11-23 02:50:55,970 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8477366227995266, 'Total loss': 0.8477366227995266} | train loss {'Reaction outcome loss': 0.839348693167971, 'Total loss': 0.839348693167971}
2022-11-23 02:50:55,970 INFO:     Found new best model at epoch 1
2022-11-23 02:50:55,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:55,971 INFO:     Epoch: 2
2022-11-23 02:50:56,764 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8353367027911273, 'Total loss': 0.8353367027911273} | train loss {'Reaction outcome loss': 0.8417815998677285, 'Total loss': 0.8417815998677285}
2022-11-23 02:50:56,764 INFO:     Found new best model at epoch 2
2022-11-23 02:50:56,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:56,765 INFO:     Epoch: 3
2022-11-23 02:50:57,589 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8605164174329151, 'Total loss': 0.8605164174329151} | train loss {'Reaction outcome loss': 0.8345728207740092, 'Total loss': 0.8345728207740092}
2022-11-23 02:50:57,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:57,589 INFO:     Epoch: 4
2022-11-23 02:50:58,421 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8629584122787822, 'Total loss': 0.8629584122787822} | train loss {'Reaction outcome loss': 0.8314999388831277, 'Total loss': 0.8314999388831277}
2022-11-23 02:50:58,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:58,421 INFO:     Epoch: 5
2022-11-23 02:50:59,258 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8480231409723108, 'Total loss': 0.8480231409723108} | train loss {'Reaction outcome loss': 0.8240656989716715, 'Total loss': 0.8240656989716715}
2022-11-23 02:50:59,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:50:59,259 INFO:     Epoch: 6
2022-11-23 02:51:00,055 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8687974214553833, 'Total loss': 0.8687974214553833} | train loss {'Reaction outcome loss': 0.8260511882122485, 'Total loss': 0.8260511882122485}
2022-11-23 02:51:00,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:00,057 INFO:     Epoch: 7
2022-11-23 02:51:00,846 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.849565403027968, 'Total loss': 0.849565403027968} | train loss {'Reaction outcome loss': 0.8272757897934606, 'Total loss': 0.8272757897934606}
2022-11-23 02:51:00,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:00,846 INFO:     Epoch: 8
2022-11-23 02:51:01,663 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8267305818471041, 'Total loss': 0.8267305818471041} | train loss {'Reaction outcome loss': 0.8181465388305725, 'Total loss': 0.8181465388305725}
2022-11-23 02:51:01,664 INFO:     Found new best model at epoch 8
2022-11-23 02:51:01,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:01,665 INFO:     Epoch: 9
2022-11-23 02:51:02,451 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8449589596553282, 'Total loss': 0.8449589596553282} | train loss {'Reaction outcome loss': 0.8203976692691926, 'Total loss': 0.8203976692691926}
2022-11-23 02:51:02,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:02,451 INFO:     Epoch: 10
2022-11-23 02:51:03,305 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8517007109793749, 'Total loss': 0.8517007109793749} | train loss {'Reaction outcome loss': 0.8157088493387545, 'Total loss': 0.8157088493387545}
2022-11-23 02:51:03,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:03,305 INFO:     Epoch: 11
2022-11-23 02:51:04,155 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8326903656125069, 'Total loss': 0.8326903656125069} | train loss {'Reaction outcome loss': 0.8158435100509275, 'Total loss': 0.8158435100509275}
2022-11-23 02:51:04,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:04,155 INFO:     Epoch: 12
2022-11-23 02:51:05,002 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8180589770728891, 'Total loss': 0.8180589770728891} | train loss {'Reaction outcome loss': 0.8141039117209373, 'Total loss': 0.8141039117209373}
2022-11-23 02:51:05,002 INFO:     Found new best model at epoch 12
2022-11-23 02:51:05,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:05,003 INFO:     Epoch: 13
2022-11-23 02:51:05,824 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8377995450388301, 'Total loss': 0.8377995450388301} | train loss {'Reaction outcome loss': 0.8150406511079881, 'Total loss': 0.8150406511079881}
2022-11-23 02:51:05,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:05,824 INFO:     Epoch: 14
2022-11-23 02:51:06,715 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8106604530052706, 'Total loss': 0.8106604530052706} | train loss {'Reaction outcome loss': 0.8135664381327168, 'Total loss': 0.8135664381327168}
2022-11-23 02:51:06,716 INFO:     Found new best model at epoch 14
2022-11-23 02:51:06,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:06,717 INFO:     Epoch: 15
2022-11-23 02:51:07,550 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8318430659445849, 'Total loss': 0.8318430659445849} | train loss {'Reaction outcome loss': 0.8122310894391229, 'Total loss': 0.8122310894391229}
2022-11-23 02:51:07,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:07,551 INFO:     Epoch: 16
2022-11-23 02:51:08,375 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8151827217503027, 'Total loss': 0.8151827217503027} | train loss {'Reaction outcome loss': 0.8107701690206605, 'Total loss': 0.8107701690206605}
2022-11-23 02:51:08,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:08,376 INFO:     Epoch: 17
2022-11-23 02:51:09,154 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8208867460489273, 'Total loss': 0.8208867460489273} | train loss {'Reaction outcome loss': 0.8111406064802601, 'Total loss': 0.8111406064802601}
2022-11-23 02:51:09,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:09,155 INFO:     Epoch: 18
2022-11-23 02:51:09,994 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.825869695706801, 'Total loss': 0.825869695706801} | train loss {'Reaction outcome loss': 0.8142625712338956, 'Total loss': 0.8142625712338956}
2022-11-23 02:51:09,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:09,995 INFO:     Epoch: 19
2022-11-23 02:51:10,762 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8153977624394677, 'Total loss': 0.8153977624394677} | train loss {'Reaction outcome loss': 0.8106899260272903, 'Total loss': 0.8106899260272903}
2022-11-23 02:51:10,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:10,762 INFO:     Epoch: 20
2022-11-23 02:51:11,555 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8309101828119971, 'Total loss': 0.8309101828119971} | train loss {'Reaction outcome loss': 0.8138580441234573, 'Total loss': 0.8138580441234573}
2022-11-23 02:51:11,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:11,556 INFO:     Epoch: 21
2022-11-23 02:51:12,342 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8211809505115856, 'Total loss': 0.8211809505115856} | train loss {'Reaction outcome loss': 0.8124382089703314, 'Total loss': 0.8124382089703314}
2022-11-23 02:51:12,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:12,342 INFO:     Epoch: 22
2022-11-23 02:51:13,151 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8201754756949164, 'Total loss': 0.8201754756949164} | train loss {'Reaction outcome loss': 0.8065896852602882, 'Total loss': 0.8065896852602882}
2022-11-23 02:51:13,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:13,151 INFO:     Epoch: 23
2022-11-23 02:51:13,927 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8182362724434246, 'Total loss': 0.8182362724434246} | train loss {'Reaction outcome loss': 0.809773572029606, 'Total loss': 0.809773572029606}
2022-11-23 02:51:13,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:13,928 INFO:     Epoch: 24
2022-11-23 02:51:14,750 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8295436054468155, 'Total loss': 0.8295436054468155} | train loss {'Reaction outcome loss': 0.8092767333071078, 'Total loss': 0.8092767333071078}
2022-11-23 02:51:14,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:14,751 INFO:     Epoch: 25
2022-11-23 02:51:15,540 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8208438388325952, 'Total loss': 0.8208438388325952} | train loss {'Reaction outcome loss': 0.8064313111526351, 'Total loss': 0.8064313111526351}
2022-11-23 02:51:15,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:15,540 INFO:     Epoch: 26
2022-11-23 02:51:16,368 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8294425769285723, 'Total loss': 0.8294425769285723} | train loss {'Reaction outcome loss': 0.8115197704924692, 'Total loss': 0.8115197704924692}
2022-11-23 02:51:16,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:16,368 INFO:     Epoch: 27
2022-11-23 02:51:17,208 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8263633495027368, 'Total loss': 0.8263633495027368} | train loss {'Reaction outcome loss': 0.8167079393902132, 'Total loss': 0.8167079393902132}
2022-11-23 02:51:17,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:17,208 INFO:     Epoch: 28
2022-11-23 02:51:18,041 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8285067149183967, 'Total loss': 0.8285067149183967} | train loss {'Reaction outcome loss': 0.8063838886878183, 'Total loss': 0.8063838886878183}
2022-11-23 02:51:18,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:18,042 INFO:     Epoch: 29
2022-11-23 02:51:18,839 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8302664655176076, 'Total loss': 0.8302664655176076} | train loss {'Reaction outcome loss': 0.8078959240548073, 'Total loss': 0.8078959240548073}
2022-11-23 02:51:18,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:18,840 INFO:     Epoch: 30
2022-11-23 02:51:19,687 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8292460996996273, 'Total loss': 0.8292460996996273} | train loss {'Reaction outcome loss': 0.8059107023141077, 'Total loss': 0.8059107023141077}
2022-11-23 02:51:19,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:19,688 INFO:     Epoch: 31
2022-11-23 02:51:20,533 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8698836510831659, 'Total loss': 0.8698836510831659} | train loss {'Reaction outcome loss': 0.8088179079274977, 'Total loss': 0.8088179079274977}
2022-11-23 02:51:20,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:20,533 INFO:     Epoch: 32
2022-11-23 02:51:21,387 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8271719589829445, 'Total loss': 0.8271719589829445} | train loss {'Reaction outcome loss': 0.8077553055219112, 'Total loss': 0.8077553055219112}
2022-11-23 02:51:21,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:21,388 INFO:     Epoch: 33
2022-11-23 02:51:22,192 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8152386911890723, 'Total loss': 0.8152386911890723} | train loss {'Reaction outcome loss': 0.8080705175957372, 'Total loss': 0.8080705175957372}
2022-11-23 02:51:22,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:22,193 INFO:     Epoch: 34
2022-11-23 02:51:23,003 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8276532292366028, 'Total loss': 0.8276532292366028} | train loss {'Reaction outcome loss': 0.8068807391870406, 'Total loss': 0.8068807391870406}
2022-11-23 02:51:23,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:23,004 INFO:     Epoch: 35
2022-11-23 02:51:23,827 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8112697533585809, 'Total loss': 0.8112697533585809} | train loss {'Reaction outcome loss': 0.8089301390272956, 'Total loss': 0.8089301390272956}
2022-11-23 02:51:23,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:23,827 INFO:     Epoch: 36
2022-11-23 02:51:24,650 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8129193437370387, 'Total loss': 0.8129193437370387} | train loss {'Reaction outcome loss': 0.8110667800590876, 'Total loss': 0.8110667800590876}
2022-11-23 02:51:24,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:24,650 INFO:     Epoch: 37
2022-11-23 02:51:25,434 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8169157098640095, 'Total loss': 0.8169157098640095} | train loss {'Reaction outcome loss': 0.8067221035880427, 'Total loss': 0.8067221035880427}
2022-11-23 02:51:25,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:25,435 INFO:     Epoch: 38
2022-11-23 02:51:26,234 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8375285220417109, 'Total loss': 0.8375285220417109} | train loss {'Reaction outcome loss': 0.8093697035745266, 'Total loss': 0.8093697035745266}
2022-11-23 02:51:26,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:26,235 INFO:     Epoch: 39
2022-11-23 02:51:27,052 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8353720408948985, 'Total loss': 0.8353720408948985} | train loss {'Reaction outcome loss': 0.8021702731568967, 'Total loss': 0.8021702731568967}
2022-11-23 02:51:27,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:27,053 INFO:     Epoch: 40
2022-11-23 02:51:27,840 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8404194848103956, 'Total loss': 0.8404194848103956} | train loss {'Reaction outcome loss': 0.8113456411707786, 'Total loss': 0.8113456411707786}
2022-11-23 02:51:27,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:27,840 INFO:     Epoch: 41
2022-11-23 02:51:28,675 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8268798054619269, 'Total loss': 0.8268798054619269} | train loss {'Reaction outcome loss': 0.804689111007798, 'Total loss': 0.804689111007798}
2022-11-23 02:51:28,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:28,675 INFO:     Epoch: 42
2022-11-23 02:51:29,463 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8357282816009088, 'Total loss': 0.8357282816009088} | train loss {'Reaction outcome loss': 0.8130410997377288, 'Total loss': 0.8130410997377288}
2022-11-23 02:51:29,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:29,463 INFO:     Epoch: 43
2022-11-23 02:51:30,305 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8222080286253582, 'Total loss': 0.8222080286253582} | train loss {'Reaction outcome loss': 0.8059187542286611, 'Total loss': 0.8059187542286611}
2022-11-23 02:51:30,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:30,306 INFO:     Epoch: 44
2022-11-23 02:51:31,109 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8521255566315218, 'Total loss': 0.8521255566315218} | train loss {'Reaction outcome loss': 0.8076386898756027, 'Total loss': 0.8076386898756027}
2022-11-23 02:51:31,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:31,111 INFO:     Epoch: 45
2022-11-23 02:51:31,890 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8427023183215748, 'Total loss': 0.8427023183215748} | train loss {'Reaction outcome loss': 0.810055555835847, 'Total loss': 0.810055555835847}
2022-11-23 02:51:31,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:31,890 INFO:     Epoch: 46
2022-11-23 02:51:32,700 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8327940539880232, 'Total loss': 0.8327940539880232} | train loss {'Reaction outcome loss': 0.8084104379578945, 'Total loss': 0.8084104379578945}
2022-11-23 02:51:32,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:32,701 INFO:     Epoch: 47
2022-11-23 02:51:33,509 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8297791975465688, 'Total loss': 0.8297791975465688} | train loss {'Reaction outcome loss': 0.8123028541524564, 'Total loss': 0.8123028541524564}
2022-11-23 02:51:33,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:33,509 INFO:     Epoch: 48
2022-11-23 02:51:34,294 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8129732981324196, 'Total loss': 0.8129732981324196} | train loss {'Reaction outcome loss': 0.8060380356206048, 'Total loss': 0.8060380356206048}
2022-11-23 02:51:34,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:34,295 INFO:     Epoch: 49
2022-11-23 02:51:35,106 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.826824003322558, 'Total loss': 0.826824003322558} | train loss {'Reaction outcome loss': 0.8088417096484092, 'Total loss': 0.8088417096484092}
2022-11-23 02:51:35,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:35,106 INFO:     Epoch: 50
2022-11-23 02:51:35,904 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8231456212022088, 'Total loss': 0.8231456212022088} | train loss {'Reaction outcome loss': 0.8052473622224023, 'Total loss': 0.8052473622224023}
2022-11-23 02:51:35,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:35,904 INFO:     Epoch: 51
2022-11-23 02:51:36,712 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8227653476324949, 'Total loss': 0.8227653476324949} | train loss {'Reaction outcome loss': 0.8112288938174325, 'Total loss': 0.8112288938174325}
2022-11-23 02:51:36,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:36,713 INFO:     Epoch: 52
2022-11-23 02:51:37,566 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8258806047114459, 'Total loss': 0.8258806047114459} | train loss {'Reaction outcome loss': 0.8034019667294717, 'Total loss': 0.8034019667294717}
2022-11-23 02:51:37,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:37,567 INFO:     Epoch: 53
2022-11-23 02:51:38,422 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8140959387475794, 'Total loss': 0.8140959387475794} | train loss {'Reaction outcome loss': 0.803376947439486, 'Total loss': 0.803376947439486}
2022-11-23 02:51:38,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:38,422 INFO:     Epoch: 54
2022-11-23 02:51:39,239 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8180999559434977, 'Total loss': 0.8180999559434977} | train loss {'Reaction outcome loss': 0.8076288708515705, 'Total loss': 0.8076288708515705}
2022-11-23 02:51:39,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:39,239 INFO:     Epoch: 55
2022-11-23 02:51:40,037 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8183037828315388, 'Total loss': 0.8183037828315388} | train loss {'Reaction outcome loss': 0.8033946218389657, 'Total loss': 0.8033946218389657}
2022-11-23 02:51:40,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:40,037 INFO:     Epoch: 56
2022-11-23 02:51:40,823 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8093170726841147, 'Total loss': 0.8093170726841147} | train loss {'Reaction outcome loss': 0.8070067188912823, 'Total loss': 0.8070067188912823}
2022-11-23 02:51:40,823 INFO:     Found new best model at epoch 56
2022-11-23 02:51:40,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:40,824 INFO:     Epoch: 57
2022-11-23 02:51:41,653 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8349709111181173, 'Total loss': 0.8349709111181173} | train loss {'Reaction outcome loss': 0.80761837490624, 'Total loss': 0.80761837490624}
2022-11-23 02:51:41,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:41,653 INFO:     Epoch: 58
2022-11-23 02:51:42,478 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8093419941988859, 'Total loss': 0.8093419941988859} | train loss {'Reaction outcome loss': 0.8080005240776846, 'Total loss': 0.8080005240776846}
2022-11-23 02:51:42,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:42,479 INFO:     Epoch: 59
2022-11-23 02:51:43,291 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8209582296284762, 'Total loss': 0.8209582296284762} | train loss {'Reaction outcome loss': 0.8078503051111775, 'Total loss': 0.8078503051111775}
2022-11-23 02:51:43,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:43,291 INFO:     Epoch: 60
2022-11-23 02:51:44,104 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8189961219375784, 'Total loss': 0.8189961219375784} | train loss {'Reaction outcome loss': 0.8017710734519267, 'Total loss': 0.8017710734519267}
2022-11-23 02:51:44,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:44,105 INFO:     Epoch: 61
2022-11-23 02:51:44,892 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8168548724868081, 'Total loss': 0.8168548724868081} | train loss {'Reaction outcome loss': 0.8086587352858435, 'Total loss': 0.8086587352858435}
2022-11-23 02:51:44,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:44,892 INFO:     Epoch: 62
2022-11-23 02:51:45,698 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8502103740518744, 'Total loss': 0.8502103740518744} | train loss {'Reaction outcome loss': 0.8000995277637436, 'Total loss': 0.8000995277637436}
2022-11-23 02:51:45,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:45,698 INFO:     Epoch: 63
2022-11-23 02:51:46,505 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8222439587116241, 'Total loss': 0.8222439587116241} | train loss {'Reaction outcome loss': 0.8069745077481193, 'Total loss': 0.8069745077481193}
2022-11-23 02:51:46,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:46,505 INFO:     Epoch: 64
2022-11-23 02:51:47,331 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8236277631737969, 'Total loss': 0.8236277631737969} | train loss {'Reaction outcome loss': 0.8076682097969516, 'Total loss': 0.8076682097969516}
2022-11-23 02:51:47,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:47,331 INFO:     Epoch: 65
2022-11-23 02:51:48,114 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8353772894902662, 'Total loss': 0.8353772894902662} | train loss {'Reaction outcome loss': 0.8073197681336634, 'Total loss': 0.8073197681336634}
2022-11-23 02:51:48,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:48,114 INFO:     Epoch: 66
2022-11-23 02:51:48,921 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8250521888787096, 'Total loss': 0.8250521888787096} | train loss {'Reaction outcome loss': 0.8107317198188074, 'Total loss': 0.8107317198188074}
2022-11-23 02:51:48,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:48,921 INFO:     Epoch: 67
2022-11-23 02:51:49,753 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8133960708298467, 'Total loss': 0.8133960708298467} | train loss {'Reaction outcome loss': 0.8021536702590604, 'Total loss': 0.8021536702590604}
2022-11-23 02:51:49,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:49,754 INFO:     Epoch: 68
2022-11-23 02:51:50,555 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8332708782770417, 'Total loss': 0.8332708782770417} | train loss {'Reaction outcome loss': 0.809650000665457, 'Total loss': 0.809650000665457}
2022-11-23 02:51:50,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:50,555 INFO:     Epoch: 69
2022-11-23 02:51:51,413 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.831685676493428, 'Total loss': 0.831685676493428} | train loss {'Reaction outcome loss': 0.8055794458956488, 'Total loss': 0.8055794458956488}
2022-11-23 02:51:51,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:51,413 INFO:     Epoch: 70
2022-11-23 02:51:52,238 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8177663853222673, 'Total loss': 0.8177663853222673} | train loss {'Reaction outcome loss': 0.805286220244823, 'Total loss': 0.805286220244823}
2022-11-23 02:51:52,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:52,239 INFO:     Epoch: 71
2022-11-23 02:51:53,073 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8285617909648202, 'Total loss': 0.8285617909648202} | train loss {'Reaction outcome loss': 0.8015244675259436, 'Total loss': 0.8015244675259436}
2022-11-23 02:51:53,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:53,073 INFO:     Epoch: 72
2022-11-23 02:51:53,911 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8255608000538566, 'Total loss': 0.8255608000538566} | train loss {'Reaction outcome loss': 0.8059188081852852, 'Total loss': 0.8059188081852852}
2022-11-23 02:51:53,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:53,912 INFO:     Epoch: 73
2022-11-23 02:51:54,787 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8187033716927875, 'Total loss': 0.8187033716927875} | train loss {'Reaction outcome loss': 0.8056562243690414, 'Total loss': 0.8056562243690414}
2022-11-23 02:51:54,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:54,787 INFO:     Epoch: 74
2022-11-23 02:51:55,685 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8151487945155664, 'Total loss': 0.8151487945155664} | train loss {'Reaction outcome loss': 0.8091866812638698, 'Total loss': 0.8091866812638698}
2022-11-23 02:51:55,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:55,685 INFO:     Epoch: 75
2022-11-23 02:51:56,574 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8224378858100284, 'Total loss': 0.8224378858100284} | train loss {'Reaction outcome loss': 0.809418901560768, 'Total loss': 0.809418901560768}
2022-11-23 02:51:56,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:56,575 INFO:     Epoch: 76
2022-11-23 02:51:57,438 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8271490328691222, 'Total loss': 0.8271490328691222} | train loss {'Reaction outcome loss': 0.8066743591860417, 'Total loss': 0.8066743591860417}
2022-11-23 02:51:57,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:57,439 INFO:     Epoch: 77
2022-11-23 02:51:58,291 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8251348517157815, 'Total loss': 0.8251348517157815} | train loss {'Reaction outcome loss': 0.8072574476320897, 'Total loss': 0.8072574476320897}
2022-11-23 02:51:58,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:58,291 INFO:     Epoch: 78
2022-11-23 02:51:59,101 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8180862678722902, 'Total loss': 0.8180862678722902} | train loss {'Reaction outcome loss': 0.8112517042506125, 'Total loss': 0.8112517042506125}
2022-11-23 02:51:59,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:59,102 INFO:     Epoch: 79
2022-11-23 02:51:59,998 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8237919963218949, 'Total loss': 0.8237919963218949} | train loss {'Reaction outcome loss': 0.8108935487126151, 'Total loss': 0.8108935487126151}
2022-11-23 02:51:59,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:51:59,998 INFO:     Epoch: 80
2022-11-23 02:52:00,911 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8425551720640876, 'Total loss': 0.8425551720640876} | train loss {'Reaction outcome loss': 0.8058175167008754, 'Total loss': 0.8058175167008754}
2022-11-23 02:52:00,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:00,912 INFO:     Epoch: 81
2022-11-23 02:52:01,796 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8611929240551862, 'Total loss': 0.8611929240551862} | train loss {'Reaction outcome loss': 0.8109753473151115, 'Total loss': 0.8109753473151115}
2022-11-23 02:52:01,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:01,798 INFO:     Epoch: 82
2022-11-23 02:52:02,695 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8152896436777982, 'Total loss': 0.8152896436777982} | train loss {'Reaction outcome loss': 0.810625801523847, 'Total loss': 0.810625801523847}
2022-11-23 02:52:02,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:02,695 INFO:     Epoch: 83
2022-11-23 02:52:03,649 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8280746909705076, 'Total loss': 0.8280746909705076} | train loss {'Reaction outcome loss': 0.8071385844340248, 'Total loss': 0.8071385844340248}
2022-11-23 02:52:03,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:03,649 INFO:     Epoch: 84
2022-11-23 02:52:04,530 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8123602677475322, 'Total loss': 0.8123602677475322} | train loss {'Reaction outcome loss': 0.8033375223317454, 'Total loss': 0.8033375223317454}
2022-11-23 02:52:04,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:04,531 INFO:     Epoch: 85
2022-11-23 02:52:05,417 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8221249173987996, 'Total loss': 0.8221249173987996} | train loss {'Reaction outcome loss': 0.8079387987813642, 'Total loss': 0.8079387987813642}
2022-11-23 02:52:05,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:05,417 INFO:     Epoch: 86
2022-11-23 02:52:06,264 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8454672599380667, 'Total loss': 0.8454672599380667} | train loss {'Reaction outcome loss': 0.811036885986405, 'Total loss': 0.811036885986405}
2022-11-23 02:52:06,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:06,264 INFO:     Epoch: 87
2022-11-23 02:52:07,156 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8098923936486244, 'Total loss': 0.8098923936486244} | train loss {'Reaction outcome loss': 0.8066056511334835, 'Total loss': 0.8066056511334835}
2022-11-23 02:52:07,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:07,156 INFO:     Epoch: 88
2022-11-23 02:52:08,031 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8140409223058007, 'Total loss': 0.8140409223058007} | train loss {'Reaction outcome loss': 0.8095778205221699, 'Total loss': 0.8095778205221699}
2022-11-23 02:52:08,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:08,032 INFO:     Epoch: 89
2022-11-23 02:52:08,898 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8222608830441128, 'Total loss': 0.8222608830441128} | train loss {'Reaction outcome loss': 0.8072914466742547, 'Total loss': 0.8072914466742547}
2022-11-23 02:52:08,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:08,898 INFO:     Epoch: 90
2022-11-23 02:52:09,779 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8159303556789052, 'Total loss': 0.8159303556789052} | train loss {'Reaction outcome loss': 0.8037630373672131, 'Total loss': 0.8037630373672131}
2022-11-23 02:52:09,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:09,779 INFO:     Epoch: 91
2022-11-23 02:52:10,668 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8313103033737703, 'Total loss': 0.8313103033737703} | train loss {'Reaction outcome loss': 0.8027469389621289, 'Total loss': 0.8027469389621289}
2022-11-23 02:52:10,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:10,668 INFO:     Epoch: 92
2022-11-23 02:52:11,581 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.816518175331029, 'Total loss': 0.816518175331029} | train loss {'Reaction outcome loss': 0.8092081760687213, 'Total loss': 0.8092081760687213}
2022-11-23 02:52:11,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:11,582 INFO:     Epoch: 93
2022-11-23 02:52:12,501 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8246161199428819, 'Total loss': 0.8246161199428819} | train loss {'Reaction outcome loss': 0.8033554318451113, 'Total loss': 0.8033554318451113}
2022-11-23 02:52:12,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:12,501 INFO:     Epoch: 94
2022-11-23 02:52:13,402 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8318771909583699, 'Total loss': 0.8318771909583699} | train loss {'Reaction outcome loss': 0.802359388239922, 'Total loss': 0.802359388239922}
2022-11-23 02:52:13,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:13,403 INFO:     Epoch: 95
2022-11-23 02:52:14,302 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8308332765644247, 'Total loss': 0.8308332765644247} | train loss {'Reaction outcome loss': 0.8042133740119396, 'Total loss': 0.8042133740119396}
2022-11-23 02:52:14,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:14,303 INFO:     Epoch: 96
2022-11-23 02:52:15,180 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8286687569184736, 'Total loss': 0.8286687569184736} | train loss {'Reaction outcome loss': 0.802762838741464, 'Total loss': 0.802762838741464}
2022-11-23 02:52:15,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:15,180 INFO:     Epoch: 97
2022-11-23 02:52:16,054 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8188420601866462, 'Total loss': 0.8188420601866462} | train loss {'Reaction outcome loss': 0.8040570161275326, 'Total loss': 0.8040570161275326}
2022-11-23 02:52:16,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:16,054 INFO:     Epoch: 98
2022-11-23 02:52:16,929 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8191391094164415, 'Total loss': 0.8191391094164415} | train loss {'Reaction outcome loss': 0.8088480366333839, 'Total loss': 0.8088480366333839}
2022-11-23 02:52:16,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:16,929 INFO:     Epoch: 99
2022-11-23 02:52:17,811 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8244721124118025, 'Total loss': 0.8244721124118025} | train loss {'Reaction outcome loss': 0.8045550336039835, 'Total loss': 0.8045550336039835}
2022-11-23 02:52:17,811 INFO:     Best model found after epoch 57 of 100.
2022-11-23 02:52:17,811 INFO:   Done with stage: TRAINING
2022-11-23 02:52:17,811 INFO:   Starting stage: EVALUATION
2022-11-23 02:52:17,931 INFO:   Done with stage: EVALUATION
2022-11-23 02:52:17,931 INFO:   Leaving out SEQ value Fold_8
2022-11-23 02:52:17,944 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 02:52:17,945 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:52:18,623 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:52:18,623 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:52:18,699 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:52:18,699 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:52:18,699 INFO:     No hyperparam tuning for this model
2022-11-23 02:52:18,699 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:52:18,699 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:52:18,700 INFO:     None feature selector for col prot
2022-11-23 02:52:18,700 INFO:     None feature selector for col prot
2022-11-23 02:52:18,700 INFO:     None feature selector for col prot
2022-11-23 02:52:18,701 INFO:     None feature selector for col chem
2022-11-23 02:52:18,701 INFO:     None feature selector for col chem
2022-11-23 02:52:18,701 INFO:     None feature selector for col chem
2022-11-23 02:52:18,701 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:52:18,701 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:52:18,703 INFO:     Number of params in model 168571
2022-11-23 02:52:18,706 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:52:18,707 INFO:   Starting stage: TRAINING
2022-11-23 02:52:18,766 INFO:     Val loss before train {'Reaction outcome loss': 0.9841770380735397, 'Total loss': 0.9841770380735397}
2022-11-23 02:52:18,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:18,766 INFO:     Epoch: 0
2022-11-23 02:52:19,596 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8149549866264517, 'Total loss': 0.8149549866264517} | train loss {'Reaction outcome loss': 0.8686320986066546, 'Total loss': 0.8686320986066546}
2022-11-23 02:52:19,596 INFO:     Found new best model at epoch 0
2022-11-23 02:52:19,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:19,597 INFO:     Epoch: 1
2022-11-23 02:52:20,462 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8633508008312095, 'Total loss': 0.8633508008312095} | train loss {'Reaction outcome loss': 0.8355105293040372, 'Total loss': 0.8355105293040372}
2022-11-23 02:52:20,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:20,463 INFO:     Epoch: 2
2022-11-23 02:52:21,323 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8424499102614142, 'Total loss': 0.8424499102614142} | train loss {'Reaction outcome loss': 0.8328160989041231, 'Total loss': 0.8328160989041231}
2022-11-23 02:52:21,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:21,324 INFO:     Epoch: 3
2022-11-23 02:52:22,197 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.824578154493462, 'Total loss': 0.824578154493462} | train loss {'Reaction outcome loss': 0.8287506675233647, 'Total loss': 0.8287506675233647}
2022-11-23 02:52:22,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:22,197 INFO:     Epoch: 4
2022-11-23 02:52:23,037 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7916213131763719, 'Total loss': 0.7916213131763719} | train loss {'Reaction outcome loss': 0.8239455063732303, 'Total loss': 0.8239455063732303}
2022-11-23 02:52:23,037 INFO:     Found new best model at epoch 4
2022-11-23 02:52:23,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:23,038 INFO:     Epoch: 5
2022-11-23 02:52:23,880 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8182129196145318, 'Total loss': 0.8182129196145318} | train loss {'Reaction outcome loss': 0.8190781052015266, 'Total loss': 0.8190781052015266}
2022-11-23 02:52:23,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:23,880 INFO:     Epoch: 6
2022-11-23 02:52:24,742 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7866098630157384, 'Total loss': 0.7866098630157384} | train loss {'Reaction outcome loss': 0.8129031491522887, 'Total loss': 0.8129031491522887}
2022-11-23 02:52:24,742 INFO:     Found new best model at epoch 6
2022-11-23 02:52:24,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:24,743 INFO:     Epoch: 7
2022-11-23 02:52:25,585 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8069047236984427, 'Total loss': 0.8069047236984427} | train loss {'Reaction outcome loss': 0.8156058795598089, 'Total loss': 0.8156058795598089}
2022-11-23 02:52:25,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:25,585 INFO:     Epoch: 8
2022-11-23 02:52:26,432 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.804674472998489, 'Total loss': 0.804674472998489} | train loss {'Reaction outcome loss': 0.8115009108368232, 'Total loss': 0.8115009108368232}
2022-11-23 02:52:26,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:26,432 INFO:     Epoch: 9
2022-11-23 02:52:27,287 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7808145264332945, 'Total loss': 0.7808145264332945} | train loss {'Reaction outcome loss': 0.8104432303686531, 'Total loss': 0.8104432303686531}
2022-11-23 02:52:27,287 INFO:     Found new best model at epoch 9
2022-11-23 02:52:27,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:27,288 INFO:     Epoch: 10
2022-11-23 02:52:28,097 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8109463575211439, 'Total loss': 0.8109463575211439} | train loss {'Reaction outcome loss': 0.8132798922305204, 'Total loss': 0.8132798922305204}
2022-11-23 02:52:28,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:28,097 INFO:     Epoch: 11
2022-11-23 02:52:28,930 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7731310393322598, 'Total loss': 0.7731310393322598} | train loss {'Reaction outcome loss': 0.8059711585239488, 'Total loss': 0.8059711585239488}
2022-11-23 02:52:28,930 INFO:     Found new best model at epoch 11
2022-11-23 02:52:28,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:28,931 INFO:     Epoch: 12
2022-11-23 02:52:29,822 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7734170427376573, 'Total loss': 0.7734170427376573} | train loss {'Reaction outcome loss': 0.8087517349087462, 'Total loss': 0.8087517349087462}
2022-11-23 02:52:29,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:29,822 INFO:     Epoch: 13
2022-11-23 02:52:30,709 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7918012585829605, 'Total loss': 0.7918012585829605} | train loss {'Reaction outcome loss': 0.8080466365327641, 'Total loss': 0.8080466365327641}
2022-11-23 02:52:30,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:30,709 INFO:     Epoch: 14
2022-11-23 02:52:31,541 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7953434491699393, 'Total loss': 0.7953434491699393} | train loss {'Reaction outcome loss': 0.8108959430334519, 'Total loss': 0.8108959430334519}
2022-11-23 02:52:31,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:31,542 INFO:     Epoch: 15
2022-11-23 02:52:32,343 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7936352227221836, 'Total loss': 0.7936352227221836} | train loss {'Reaction outcome loss': 0.8049974164184259, 'Total loss': 0.8049974164184259}
2022-11-23 02:52:32,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:32,343 INFO:     Epoch: 16
2022-11-23 02:52:33,204 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7960942475633188, 'Total loss': 0.7960942475633188} | train loss {'Reaction outcome loss': 0.8051851411863249, 'Total loss': 0.8051851411863249}
2022-11-23 02:52:33,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:33,205 INFO:     Epoch: 17
2022-11-23 02:52:34,079 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8280373540791598, 'Total loss': 0.8280373540791598} | train loss {'Reaction outcome loss': 0.8042914525586732, 'Total loss': 0.8042914525586732}
2022-11-23 02:52:34,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:34,079 INFO:     Epoch: 18
2022-11-23 02:52:34,885 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7780067311091856, 'Total loss': 0.7780067311091856} | train loss {'Reaction outcome loss': 0.8015069937219426, 'Total loss': 0.8015069937219426}
2022-11-23 02:52:34,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:34,885 INFO:     Epoch: 19
2022-11-23 02:52:35,746 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8220840895717795, 'Total loss': 0.8220840895717795} | train loss {'Reaction outcome loss': 0.8035102720163306, 'Total loss': 0.8035102720163306}
2022-11-23 02:52:35,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:35,746 INFO:     Epoch: 20
2022-11-23 02:52:36,610 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8090512373230674, 'Total loss': 0.8090512373230674} | train loss {'Reaction outcome loss': 0.8106980298246657, 'Total loss': 0.8106980298246657}
2022-11-23 02:52:36,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:36,610 INFO:     Epoch: 21
2022-11-23 02:52:37,492 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.794898430054838, 'Total loss': 0.794898430054838} | train loss {'Reaction outcome loss': 0.8047261264859413, 'Total loss': 0.8047261264859413}
2022-11-23 02:52:37,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:37,492 INFO:     Epoch: 22
2022-11-23 02:52:38,391 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7593820067969236, 'Total loss': 0.7593820067969236} | train loss {'Reaction outcome loss': 0.799975069809933, 'Total loss': 0.799975069809933}
2022-11-23 02:52:38,391 INFO:     Found new best model at epoch 22
2022-11-23 02:52:38,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:38,392 INFO:     Epoch: 23
2022-11-23 02:52:39,220 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8125059496272694, 'Total loss': 0.8125059496272694} | train loss {'Reaction outcome loss': 0.8027309845904915, 'Total loss': 0.8027309845904915}
2022-11-23 02:52:39,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:39,222 INFO:     Epoch: 24
2022-11-23 02:52:40,003 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7831934615969658, 'Total loss': 0.7831934615969658} | train loss {'Reaction outcome loss': 0.8024758409480659, 'Total loss': 0.8024758409480659}
2022-11-23 02:52:40,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:40,003 INFO:     Epoch: 25
2022-11-23 02:52:40,830 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7831359151750803, 'Total loss': 0.7831359151750803} | train loss {'Reaction outcome loss': 0.8004094323333428, 'Total loss': 0.8004094323333428}
2022-11-23 02:52:40,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:40,830 INFO:     Epoch: 26
2022-11-23 02:52:41,714 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7893011861226775, 'Total loss': 0.7893011861226775} | train loss {'Reaction outcome loss': 0.804234496428042, 'Total loss': 0.804234496428042}
2022-11-23 02:52:41,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:41,714 INFO:     Epoch: 27
2022-11-23 02:52:42,574 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.799561006101695, 'Total loss': 0.799561006101695} | train loss {'Reaction outcome loss': 0.8001993246224461, 'Total loss': 0.8001993246224461}
2022-11-23 02:52:42,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:42,575 INFO:     Epoch: 28
2022-11-23 02:52:43,403 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7849577218294144, 'Total loss': 0.7849577218294144} | train loss {'Reaction outcome loss': 0.7999947474927318, 'Total loss': 0.7999947474927318}
2022-11-23 02:52:43,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:43,403 INFO:     Epoch: 29
2022-11-23 02:52:44,299 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7696629017591476, 'Total loss': 0.7696629017591476} | train loss {'Reaction outcome loss': 0.8006243730077938, 'Total loss': 0.8006243730077938}
2022-11-23 02:52:44,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:44,299 INFO:     Epoch: 30
2022-11-23 02:52:45,109 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.764569378034635, 'Total loss': 0.764569378034635} | train loss {'Reaction outcome loss': 0.8014030131758476, 'Total loss': 0.8014030131758476}
2022-11-23 02:52:45,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:45,109 INFO:     Epoch: 31
2022-11-23 02:52:45,996 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7762750617482446, 'Total loss': 0.7762750617482446} | train loss {'Reaction outcome loss': 0.8006292262855841, 'Total loss': 0.8006292262855841}
2022-11-23 02:52:45,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:45,997 INFO:     Epoch: 32
2022-11-23 02:52:46,797 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7779588374224576, 'Total loss': 0.7779588374224576} | train loss {'Reaction outcome loss': 0.7994163048510649, 'Total loss': 0.7994163048510649}
2022-11-23 02:52:46,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:46,797 INFO:     Epoch: 33
2022-11-23 02:52:47,613 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7877394651824777, 'Total loss': 0.7877394651824777} | train loss {'Reaction outcome loss': 0.7975238088442355, 'Total loss': 0.7975238088442355}
2022-11-23 02:52:47,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:47,613 INFO:     Epoch: 34
2022-11-23 02:52:48,467 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7685297802090645, 'Total loss': 0.7685297802090645} | train loss {'Reaction outcome loss': 0.8022900952368367, 'Total loss': 0.8022900952368367}
2022-11-23 02:52:48,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:48,467 INFO:     Epoch: 35
2022-11-23 02:52:49,293 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7719737447120927, 'Total loss': 0.7719737447120927} | train loss {'Reaction outcome loss': 0.8036547887082003, 'Total loss': 0.8036547887082003}
2022-11-23 02:52:49,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:49,293 INFO:     Epoch: 36
2022-11-23 02:52:50,135 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7720566838979721, 'Total loss': 0.7720566838979721} | train loss {'Reaction outcome loss': 0.8046053214949005, 'Total loss': 0.8046053214949005}
2022-11-23 02:52:50,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:50,135 INFO:     Epoch: 37
2022-11-23 02:52:50,949 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7854564237323675, 'Total loss': 0.7854564237323675} | train loss {'Reaction outcome loss': 0.7967145477022444, 'Total loss': 0.7967145477022444}
2022-11-23 02:52:50,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:50,949 INFO:     Epoch: 38
2022-11-23 02:52:51,810 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.786750855770978, 'Total loss': 0.786750855770978} | train loss {'Reaction outcome loss': 0.7963617853972377, 'Total loss': 0.7963617853972377}
2022-11-23 02:52:51,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:51,811 INFO:     Epoch: 39
2022-11-23 02:52:52,650 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7751792791214857, 'Total loss': 0.7751792791214857} | train loss {'Reaction outcome loss': 0.7964804112911225, 'Total loss': 0.7964804112911225}
2022-11-23 02:52:52,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:52,650 INFO:     Epoch: 40
2022-11-23 02:52:53,522 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8011659668250517, 'Total loss': 0.8011659668250517} | train loss {'Reaction outcome loss': 0.8012533606315145, 'Total loss': 0.8012533606315145}
2022-11-23 02:52:53,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:53,522 INFO:     Epoch: 41
2022-11-23 02:52:54,363 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7712028595534238, 'Total loss': 0.7712028595534238} | train loss {'Reaction outcome loss': 0.7972790400592649, 'Total loss': 0.7972790400592649}
2022-11-23 02:52:54,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:54,363 INFO:     Epoch: 42
2022-11-23 02:52:55,185 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7839136055924676, 'Total loss': 0.7839136055924676} | train loss {'Reaction outcome loss': 0.7994541486915276, 'Total loss': 0.7994541486915276}
2022-11-23 02:52:55,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:55,185 INFO:     Epoch: 43
2022-11-23 02:52:56,025 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7842824133959684, 'Total loss': 0.7842824133959684} | train loss {'Reaction outcome loss': 0.7990018435886928, 'Total loss': 0.7990018435886928}
2022-11-23 02:52:56,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:56,025 INFO:     Epoch: 44
2022-11-23 02:52:56,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7777951424094763, 'Total loss': 0.7777951424094763} | train loss {'Reaction outcome loss': 0.7999157299800795, 'Total loss': 0.7999157299800795}
2022-11-23 02:52:56,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:56,869 INFO:     Epoch: 45
2022-11-23 02:52:57,723 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7970999391241507, 'Total loss': 0.7970999391241507} | train loss {'Reaction outcome loss': 0.8034874348007903, 'Total loss': 0.8034874348007903}
2022-11-23 02:52:57,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:57,723 INFO:     Epoch: 46
2022-11-23 02:52:58,570 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8068756826899268, 'Total loss': 0.8068756826899268} | train loss {'Reaction outcome loss': 0.7979986003467014, 'Total loss': 0.7979986003467014}
2022-11-23 02:52:58,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:58,571 INFO:     Epoch: 47
2022-11-23 02:52:59,447 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7896049733866345, 'Total loss': 0.7896049733866345} | train loss {'Reaction outcome loss': 0.7976839043656174, 'Total loss': 0.7976839043656174}
2022-11-23 02:52:59,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:52:59,447 INFO:     Epoch: 48
2022-11-23 02:53:00,338 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7834103656086054, 'Total loss': 0.7834103656086054} | train loss {'Reaction outcome loss': 0.7992180790219988, 'Total loss': 0.7992180790219988}
2022-11-23 02:53:00,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:00,338 INFO:     Epoch: 49
2022-11-23 02:53:01,188 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7814235443418677, 'Total loss': 0.7814235443418677} | train loss {'Reaction outcome loss': 0.7970890331025027, 'Total loss': 0.7970890331025027}
2022-11-23 02:53:01,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:01,188 INFO:     Epoch: 50
2022-11-23 02:53:02,024 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7732366817918691, 'Total loss': 0.7732366817918691} | train loss {'Reaction outcome loss': 0.7977777916557934, 'Total loss': 0.7977777916557934}
2022-11-23 02:53:02,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:02,025 INFO:     Epoch: 51
2022-11-23 02:53:02,845 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7654639651829546, 'Total loss': 0.7654639651829546} | train loss {'Reaction outcome loss': 0.8012894249692255, 'Total loss': 0.8012894249692255}
2022-11-23 02:53:02,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:02,845 INFO:     Epoch: 52
2022-11-23 02:53:03,650 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7784857682206414, 'Total loss': 0.7784857682206414} | train loss {'Reaction outcome loss': 0.797907920394625, 'Total loss': 0.797907920394625}
2022-11-23 02:53:03,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:03,651 INFO:     Epoch: 53
2022-11-23 02:53:04,478 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8032084242864088, 'Total loss': 0.8032084242864088} | train loss {'Reaction outcome loss': 0.7943217586497872, 'Total loss': 0.7943217586497872}
2022-11-23 02:53:04,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:04,479 INFO:     Epoch: 54
2022-11-23 02:53:05,290 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7731390358372168, 'Total loss': 0.7731390358372168} | train loss {'Reaction outcome loss': 0.7977461634850015, 'Total loss': 0.7977461634850015}
2022-11-23 02:53:05,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:05,291 INFO:     Epoch: 55
2022-11-23 02:53:06,135 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8148205293850466, 'Total loss': 0.8148205293850466} | train loss {'Reaction outcome loss': 0.7928382822445461, 'Total loss': 0.7928382822445461}
2022-11-23 02:53:06,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:06,135 INFO:     Epoch: 56
2022-11-23 02:53:06,951 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.780525922097943, 'Total loss': 0.780525922097943} | train loss {'Reaction outcome loss': 0.7971413225543742, 'Total loss': 0.7971413225543742}
2022-11-23 02:53:06,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:06,951 INFO:     Epoch: 57
2022-11-23 02:53:07,747 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7911309471184557, 'Total loss': 0.7911309471184557} | train loss {'Reaction outcome loss': 0.7976835520900025, 'Total loss': 0.7976835520900025}
2022-11-23 02:53:07,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:07,747 INFO:     Epoch: 58
2022-11-23 02:53:08,545 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8157109320163727, 'Total loss': 0.8157109320163727} | train loss {'Reaction outcome loss': 0.7943625317544353, 'Total loss': 0.7943625317544353}
2022-11-23 02:53:08,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:08,546 INFO:     Epoch: 59
2022-11-23 02:53:09,316 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8148090703920885, 'Total loss': 0.8148090703920885} | train loss {'Reaction outcome loss': 0.7938491327422006, 'Total loss': 0.7938491327422006}
2022-11-23 02:53:09,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:09,316 INFO:     Epoch: 60
2022-11-23 02:53:10,082 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8085742674090646, 'Total loss': 0.8085742674090646} | train loss {'Reaction outcome loss': 0.7954895178882443, 'Total loss': 0.7954895178882443}
2022-11-23 02:53:10,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:10,083 INFO:     Epoch: 61
2022-11-23 02:53:10,843 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7750042880123312, 'Total loss': 0.7750042880123312} | train loss {'Reaction outcome loss': 0.791189374120868, 'Total loss': 0.791189374120868}
2022-11-23 02:53:10,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:10,843 INFO:     Epoch: 62
2022-11-23 02:53:11,609 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7938990911299532, 'Total loss': 0.7938990911299532} | train loss {'Reaction outcome loss': 0.790319760721557, 'Total loss': 0.790319760721557}
2022-11-23 02:53:11,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:11,609 INFO:     Epoch: 63
2022-11-23 02:53:12,366 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7766158316623081, 'Total loss': 0.7766158316623081} | train loss {'Reaction outcome loss': 0.7949270941165029, 'Total loss': 0.7949270941165029}
2022-11-23 02:53:12,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:12,366 INFO:     Epoch: 64
2022-11-23 02:53:13,144 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7626156705346975, 'Total loss': 0.7626156705346975} | train loss {'Reaction outcome loss': 0.7946023179560292, 'Total loss': 0.7946023179560292}
2022-11-23 02:53:13,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:13,144 INFO:     Epoch: 65
2022-11-23 02:53:13,916 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7932549952106043, 'Total loss': 0.7932549952106043} | train loss {'Reaction outcome loss': 0.7967132534299578, 'Total loss': 0.7967132534299578}
2022-11-23 02:53:13,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:13,916 INFO:     Epoch: 66
2022-11-23 02:53:14,689 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7647986533966932, 'Total loss': 0.7647986533966932} | train loss {'Reaction outcome loss': 0.7908761213020402, 'Total loss': 0.7908761213020402}
2022-11-23 02:53:14,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:14,689 INFO:     Epoch: 67
2022-11-23 02:53:15,466 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7521876076405699, 'Total loss': 0.7521876076405699} | train loss {'Reaction outcome loss': 0.7890379685528425, 'Total loss': 0.7890379685528425}
2022-11-23 02:53:15,466 INFO:     Found new best model at epoch 67
2022-11-23 02:53:15,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:15,467 INFO:     Epoch: 68
2022-11-23 02:53:16,245 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7749780463901433, 'Total loss': 0.7749780463901433} | train loss {'Reaction outcome loss': 0.7956374207321478, 'Total loss': 0.7956374207321478}
2022-11-23 02:53:16,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:16,245 INFO:     Epoch: 69
2022-11-23 02:53:17,095 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7762635858221487, 'Total loss': 0.7762635858221487} | train loss {'Reaction outcome loss': 0.7836673865512925, 'Total loss': 0.7836673865512925}
2022-11-23 02:53:17,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:17,096 INFO:     Epoch: 70
2022-11-23 02:53:17,872 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7739288542758335, 'Total loss': 0.7739288542758335} | train loss {'Reaction outcome loss': 0.7867752552032471, 'Total loss': 0.7867752552032471}
2022-11-23 02:53:17,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:17,872 INFO:     Epoch: 71
2022-11-23 02:53:18,667 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7718233506787907, 'Total loss': 0.7718233506787907} | train loss {'Reaction outcome loss': 0.7881887022329837, 'Total loss': 0.7881887022329837}
2022-11-23 02:53:18,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:18,667 INFO:     Epoch: 72
2022-11-23 02:53:19,445 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7885358970273625, 'Total loss': 0.7885358970273625} | train loss {'Reaction outcome loss': 0.7862405332983756, 'Total loss': 0.7862405332983756}
2022-11-23 02:53:19,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:19,446 INFO:     Epoch: 73
2022-11-23 02:53:20,223 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7792357118292288, 'Total loss': 0.7792357118292288} | train loss {'Reaction outcome loss': 0.7847222918150376, 'Total loss': 0.7847222918150376}
2022-11-23 02:53:20,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:20,223 INFO:     Epoch: 74
2022-11-23 02:53:20,981 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7774023596536029, 'Total loss': 0.7774023596536029} | train loss {'Reaction outcome loss': 0.7820161595636484, 'Total loss': 0.7820161595636484}
2022-11-23 02:53:20,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:20,982 INFO:     Epoch: 75
2022-11-23 02:53:21,753 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7510317171161826, 'Total loss': 0.7510317171161826} | train loss {'Reaction outcome loss': 0.7800035378154443, 'Total loss': 0.7800035378154443}
2022-11-23 02:53:21,753 INFO:     Found new best model at epoch 75
2022-11-23 02:53:21,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:21,754 INFO:     Epoch: 76
2022-11-23 02:53:22,502 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7758544581857595, 'Total loss': 0.7758544581857595} | train loss {'Reaction outcome loss': 0.7822245181823263, 'Total loss': 0.7822245181823263}
2022-11-23 02:53:22,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:22,503 INFO:     Epoch: 77
2022-11-23 02:53:23,246 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7619890347123146, 'Total loss': 0.7619890347123146} | train loss {'Reaction outcome loss': 0.7816166184386428, 'Total loss': 0.7816166184386428}
2022-11-23 02:53:23,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:23,246 INFO:     Epoch: 78
2022-11-23 02:53:24,031 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7544692890210585, 'Total loss': 0.7544692890210585} | train loss {'Reaction outcome loss': 0.7819556287356786, 'Total loss': 0.7819556287356786}
2022-11-23 02:53:24,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:24,031 INFO:     Epoch: 79
2022-11-23 02:53:24,787 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.781973847611384, 'Total loss': 0.781973847611384} | train loss {'Reaction outcome loss': 0.777885933189976, 'Total loss': 0.777885933189976}
2022-11-23 02:53:24,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:24,788 INFO:     Epoch: 80
2022-11-23 02:53:25,542 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7733746780590578, 'Total loss': 0.7733746780590578} | train loss {'Reaction outcome loss': 0.7772263897925007, 'Total loss': 0.7772263897925007}
2022-11-23 02:53:25,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:25,542 INFO:     Epoch: 81
2022-11-23 02:53:26,317 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.760845155201175, 'Total loss': 0.760845155201175} | train loss {'Reaction outcome loss': 0.7821839978500288, 'Total loss': 0.7821839978500288}
2022-11-23 02:53:26,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:26,317 INFO:     Epoch: 82
2022-11-23 02:53:27,108 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8021871772679415, 'Total loss': 0.8021871772679415} | train loss {'Reaction outcome loss': 0.7733401955390463, 'Total loss': 0.7733401955390463}
2022-11-23 02:53:27,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:27,108 INFO:     Epoch: 83
2022-11-23 02:53:27,887 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7672483494335954, 'Total loss': 0.7672483494335954} | train loss {'Reaction outcome loss': 0.7740599246657625, 'Total loss': 0.7740599246657625}
2022-11-23 02:53:27,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:27,887 INFO:     Epoch: 84
2022-11-23 02:53:28,655 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7579152076081797, 'Total loss': 0.7579152076081797} | train loss {'Reaction outcome loss': 0.7733844546639189, 'Total loss': 0.7733844546639189}
2022-11-23 02:53:28,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:28,655 INFO:     Epoch: 85
2022-11-23 02:53:29,395 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7393059493465857, 'Total loss': 0.7393059493465857} | train loss {'Reaction outcome loss': 0.7674245513215356, 'Total loss': 0.7674245513215356}
2022-11-23 02:53:29,396 INFO:     Found new best model at epoch 85
2022-11-23 02:53:29,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:29,397 INFO:     Epoch: 86
2022-11-23 02:53:30,154 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7560548836534674, 'Total loss': 0.7560548836534674} | train loss {'Reaction outcome loss': 0.7721495921514472, 'Total loss': 0.7721495921514472}
2022-11-23 02:53:30,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:30,154 INFO:     Epoch: 87
2022-11-23 02:53:30,937 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7628907947377725, 'Total loss': 0.7628907947377725} | train loss {'Reaction outcome loss': 0.7693291737108815, 'Total loss': 0.7693291737108815}
2022-11-23 02:53:30,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:30,938 INFO:     Epoch: 88
2022-11-23 02:53:31,722 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7456637817350301, 'Total loss': 0.7456637817350301} | train loss {'Reaction outcome loss': 0.7610914789900488, 'Total loss': 0.7610914789900488}
2022-11-23 02:53:31,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:31,723 INFO:     Epoch: 89
2022-11-23 02:53:32,493 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7552226483821869, 'Total loss': 0.7552226483821869} | train loss {'Reaction outcome loss': 0.7612530141460653, 'Total loss': 0.7612530141460653}
2022-11-23 02:53:32,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:32,493 INFO:     Epoch: 90
2022-11-23 02:53:33,269 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7158874293619936, 'Total loss': 0.7158874293619936} | train loss {'Reaction outcome loss': 0.7565507627263361, 'Total loss': 0.7565507627263361}
2022-11-23 02:53:33,270 INFO:     Found new best model at epoch 90
2022-11-23 02:53:33,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:33,270 INFO:     Epoch: 91
2022-11-23 02:53:34,030 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7458355616439473, 'Total loss': 0.7458355616439473} | train loss {'Reaction outcome loss': 0.7513075211826636, 'Total loss': 0.7513075211826636}
2022-11-23 02:53:34,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:34,031 INFO:     Epoch: 92
2022-11-23 02:53:34,812 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7767979272387244, 'Total loss': 0.7767979272387244} | train loss {'Reaction outcome loss': 0.7484797492319224, 'Total loss': 0.7484797492319224}
2022-11-23 02:53:34,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:34,813 INFO:     Epoch: 93
2022-11-23 02:53:35,578 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7653666030276906, 'Total loss': 0.7653666030276906} | train loss {'Reaction outcome loss': 0.7406523478274443, 'Total loss': 0.7406523478274443}
2022-11-23 02:53:35,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:35,579 INFO:     Epoch: 94
2022-11-23 02:53:36,351 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6985312917015769, 'Total loss': 0.6985312917015769} | train loss {'Reaction outcome loss': 0.7336218288966587, 'Total loss': 0.7336218288966587}
2022-11-23 02:53:36,351 INFO:     Found new best model at epoch 94
2022-11-23 02:53:36,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:36,352 INFO:     Epoch: 95
2022-11-23 02:53:37,145 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7012049250982024, 'Total loss': 0.7012049250982024} | train loss {'Reaction outcome loss': 0.7315451202343921, 'Total loss': 0.7315451202343921}
2022-11-23 02:53:37,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:37,145 INFO:     Epoch: 96
2022-11-23 02:53:37,922 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7260827022519979, 'Total loss': 0.7260827022519979} | train loss {'Reaction outcome loss': 0.7088158512602047, 'Total loss': 0.7088158512602047}
2022-11-23 02:53:37,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:37,923 INFO:     Epoch: 97
2022-11-23 02:53:38,725 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7186097055673599, 'Total loss': 0.7186097055673599} | train loss {'Reaction outcome loss': 0.7001131301023522, 'Total loss': 0.7001131301023522}
2022-11-23 02:53:38,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:38,726 INFO:     Epoch: 98
2022-11-23 02:53:39,530 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7220578105612234, 'Total loss': 0.7220578105612234} | train loss {'Reaction outcome loss': 0.6829288896857476, 'Total loss': 0.6829288896857476}
2022-11-23 02:53:39,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:39,531 INFO:     Epoch: 99
2022-11-23 02:53:40,329 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6401846219192852, 'Total loss': 0.6401846219192852} | train loss {'Reaction outcome loss': 0.6819915689984146, 'Total loss': 0.6819915689984146}
2022-11-23 02:53:40,329 INFO:     Found new best model at epoch 99
2022-11-23 02:53:40,330 INFO:     Best model found after epoch 100 of 100.
2022-11-23 02:53:40,331 INFO:   Done with stage: TRAINING
2022-11-23 02:53:40,331 INFO:   Starting stage: EVALUATION
2022-11-23 02:53:40,464 INFO:   Done with stage: EVALUATION
2022-11-23 02:53:40,464 INFO:   Leaving out SEQ value Fold_9
2022-11-23 02:53:40,477 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 02:53:40,477 INFO:   Starting stage: FEATURE SCALING
2022-11-23 02:53:41,154 INFO:   Done with stage: FEATURE SCALING
2022-11-23 02:53:41,154 INFO:   Starting stage: SCALING TARGETS
2022-11-23 02:53:41,227 INFO:   Done with stage: SCALING TARGETS
2022-11-23 02:53:41,227 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:53:41,227 INFO:     No hyperparam tuning for this model
2022-11-23 02:53:41,227 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 02:53:41,227 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 02:53:41,228 INFO:     None feature selector for col prot
2022-11-23 02:53:41,228 INFO:     None feature selector for col prot
2022-11-23 02:53:41,228 INFO:     None feature selector for col prot
2022-11-23 02:53:41,229 INFO:     None feature selector for col chem
2022-11-23 02:53:41,229 INFO:     None feature selector for col chem
2022-11-23 02:53:41,229 INFO:     None feature selector for col chem
2022-11-23 02:53:41,229 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 02:53:41,229 INFO:   Starting stage: BUILD MODEL
2022-11-23 02:53:41,231 INFO:     Number of params in model 168571
2022-11-23 02:53:41,234 INFO:   Done with stage: BUILD MODEL
2022-11-23 02:53:41,234 INFO:   Starting stage: TRAINING
2022-11-23 02:53:41,293 INFO:     Val loss before train {'Reaction outcome loss': 0.9505447758869692, 'Total loss': 0.9505447758869692}
2022-11-23 02:53:41,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:41,293 INFO:     Epoch: 0
2022-11-23 02:53:42,073 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.831013557585803, 'Total loss': 0.831013557585803} | train loss {'Reaction outcome loss': 0.8852118438770694, 'Total loss': 0.8852118438770694}
2022-11-23 02:53:42,074 INFO:     Found new best model at epoch 0
2022-11-23 02:53:42,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:42,075 INFO:     Epoch: 1
2022-11-23 02:53:42,841 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8246195939454165, 'Total loss': 0.8246195939454165} | train loss {'Reaction outcome loss': 0.8587795193156889, 'Total loss': 0.8587795193156889}
2022-11-23 02:53:42,842 INFO:     Found new best model at epoch 1
2022-11-23 02:53:42,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:42,842 INFO:     Epoch: 2
2022-11-23 02:53:43,610 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8321899385614828, 'Total loss': 0.8321899385614828} | train loss {'Reaction outcome loss': 0.8481712340106887, 'Total loss': 0.8481712340106887}
2022-11-23 02:53:43,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:43,611 INFO:     Epoch: 3
2022-11-23 02:53:44,406 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8147346221587874, 'Total loss': 0.8147346221587874} | train loss {'Reaction outcome loss': 0.8430478480314055, 'Total loss': 0.8430478480314055}
2022-11-23 02:53:44,407 INFO:     Found new best model at epoch 3
2022-11-23 02:53:44,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:44,407 INFO:     Epoch: 4
2022-11-23 02:53:45,193 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8208732036027041, 'Total loss': 0.8208732036027041} | train loss {'Reaction outcome loss': 0.8397390290854438, 'Total loss': 0.8397390290854438}
2022-11-23 02:53:45,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:45,194 INFO:     Epoch: 5
2022-11-23 02:53:46,019 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8229497535662218, 'Total loss': 0.8229497535662218} | train loss {'Reaction outcome loss': 0.8329595227635676, 'Total loss': 0.8329595227635676}
2022-11-23 02:53:46,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:46,019 INFO:     Epoch: 6
2022-11-23 02:53:46,805 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8193277323787863, 'Total loss': 0.8193277323787863} | train loss {'Reaction outcome loss': 0.8306862195172617, 'Total loss': 0.8306862195172617}
2022-11-23 02:53:46,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:46,805 INFO:     Epoch: 7
2022-11-23 02:53:47,580 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7940000559795987, 'Total loss': 0.7940000559795987} | train loss {'Reaction outcome loss': 0.8293999097039623, 'Total loss': 0.8293999097039623}
2022-11-23 02:53:47,581 INFO:     Found new best model at epoch 7
2022-11-23 02:53:47,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:47,582 INFO:     Epoch: 8
2022-11-23 02:53:48,374 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8327466784553095, 'Total loss': 0.8327466784553095} | train loss {'Reaction outcome loss': 0.8329245939610466, 'Total loss': 0.8329245939610466}
2022-11-23 02:53:48,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:48,374 INFO:     Epoch: 9
2022-11-23 02:53:49,142 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8064384047280658, 'Total loss': 0.8064384047280658} | train loss {'Reaction outcome loss': 0.8273040378285993, 'Total loss': 0.8273040378285993}
2022-11-23 02:53:49,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:49,142 INFO:     Epoch: 10
2022-11-23 02:53:49,930 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7846492569554936, 'Total loss': 0.7846492569554936} | train loss {'Reaction outcome loss': 0.8327043682577149, 'Total loss': 0.8327043682577149}
2022-11-23 02:53:49,931 INFO:     Found new best model at epoch 10
2022-11-23 02:53:49,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:49,931 INFO:     Epoch: 11
2022-11-23 02:53:50,704 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7971626858819615, 'Total loss': 0.7971626858819615} | train loss {'Reaction outcome loss': 0.8284980844586126, 'Total loss': 0.8284980844586126}
2022-11-23 02:53:50,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:50,704 INFO:     Epoch: 12
2022-11-23 02:53:51,468 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8052811629392884, 'Total loss': 0.8052811629392884} | train loss {'Reaction outcome loss': 0.829640737824863, 'Total loss': 0.829640737824863}
2022-11-23 02:53:51,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:51,468 INFO:     Epoch: 13
2022-11-23 02:53:52,249 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.81798881766471, 'Total loss': 0.81798881766471} | train loss {'Reaction outcome loss': 0.8278460495414273, 'Total loss': 0.8278460495414273}
2022-11-23 02:53:52,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:52,250 INFO:     Epoch: 14
2022-11-23 02:53:53,072 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7989647307179191, 'Total loss': 0.7989647307179191} | train loss {'Reaction outcome loss': 0.8237058954133142, 'Total loss': 0.8237058954133142}
2022-11-23 02:53:53,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:53,072 INFO:     Epoch: 15
2022-11-23 02:53:53,873 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.800092330033129, 'Total loss': 0.800092330033129} | train loss {'Reaction outcome loss': 0.8239349172480644, 'Total loss': 0.8239349172480644}
2022-11-23 02:53:53,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:53,874 INFO:     Epoch: 16
2022-11-23 02:53:54,643 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7943522212180224, 'Total loss': 0.7943522212180224} | train loss {'Reaction outcome loss': 0.8260629130226951, 'Total loss': 0.8260629130226951}
2022-11-23 02:53:54,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:54,644 INFO:     Epoch: 17
2022-11-23 02:53:55,432 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8100285313346169, 'Total loss': 0.8100285313346169} | train loss {'Reaction outcome loss': 0.8278083044194406, 'Total loss': 0.8278083044194406}
2022-11-23 02:53:55,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:55,432 INFO:     Epoch: 18
2022-11-23 02:53:56,204 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8055805238810453, 'Total loss': 0.8055805238810453} | train loss {'Reaction outcome loss': 0.8287771731134383, 'Total loss': 0.8287771731134383}
2022-11-23 02:53:56,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:56,204 INFO:     Epoch: 19
2022-11-23 02:53:56,977 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8091048469597643, 'Total loss': 0.8091048469597643} | train loss {'Reaction outcome loss': 0.8237467755473429, 'Total loss': 0.8237467755473429}
2022-11-23 02:53:56,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:56,977 INFO:     Epoch: 20
2022-11-23 02:53:57,785 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.793088627809828, 'Total loss': 0.793088627809828} | train loss {'Reaction outcome loss': 0.8232365298655725, 'Total loss': 0.8232365298655725}
2022-11-23 02:53:57,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:57,785 INFO:     Epoch: 21
2022-11-23 02:53:58,553 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8004394078796561, 'Total loss': 0.8004394078796561} | train loss {'Reaction outcome loss': 0.826684883765636, 'Total loss': 0.826684883765636}
2022-11-23 02:53:58,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:58,554 INFO:     Epoch: 22
2022-11-23 02:53:59,322 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8239099694923921, 'Total loss': 0.8239099694923921} | train loss {'Reaction outcome loss': 0.8175396145351471, 'Total loss': 0.8175396145351471}
2022-11-23 02:53:59,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:53:59,322 INFO:     Epoch: 23
2022-11-23 02:54:00,129 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8032735857096586, 'Total loss': 0.8032735857096586} | train loss {'Reaction outcome loss': 0.8264740812441995, 'Total loss': 0.8264740812441995}
2022-11-23 02:54:00,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:00,129 INFO:     Epoch: 24
2022-11-23 02:54:00,907 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8196828405965458, 'Total loss': 0.8196828405965458} | train loss {'Reaction outcome loss': 0.8246068215418246, 'Total loss': 0.8246068215418246}
2022-11-23 02:54:00,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:00,908 INFO:     Epoch: 25
2022-11-23 02:54:01,699 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8082643015818163, 'Total loss': 0.8082643015818163} | train loss {'Reaction outcome loss': 0.8207389229247647, 'Total loss': 0.8207389229247647}
2022-11-23 02:54:01,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:01,700 INFO:     Epoch: 26
2022-11-23 02:54:02,459 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7889666604724798, 'Total loss': 0.7889666604724798} | train loss {'Reaction outcome loss': 0.8254481598494514, 'Total loss': 0.8254481598494514}
2022-11-23 02:54:02,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:02,460 INFO:     Epoch: 27
2022-11-23 02:54:03,248 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8008691058917479, 'Total loss': 0.8008691058917479} | train loss {'Reaction outcome loss': 0.8211173257760463, 'Total loss': 0.8211173257760463}
2022-11-23 02:54:03,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:03,254 INFO:     Epoch: 28
2022-11-23 02:54:04,036 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7990204380317167, 'Total loss': 0.7990204380317167} | train loss {'Reaction outcome loss': 0.8222033590559037, 'Total loss': 0.8222033590559037}
2022-11-23 02:54:04,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:04,036 INFO:     Epoch: 29
2022-11-23 02:54:04,829 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8124202029271559, 'Total loss': 0.8124202029271559} | train loss {'Reaction outcome loss': 0.8260104185150515, 'Total loss': 0.8260104185150515}
2022-11-23 02:54:04,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:04,829 INFO:     Epoch: 30
2022-11-23 02:54:05,639 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8208497816866095, 'Total loss': 0.8208497816866095} | train loss {'Reaction outcome loss': 0.8210017931076788, 'Total loss': 0.8210017931076788}
2022-11-23 02:54:05,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:05,639 INFO:     Epoch: 31
2022-11-23 02:54:06,479 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7975366670976985, 'Total loss': 0.7975366670976985} | train loss {'Reaction outcome loss': 0.8196298403124656, 'Total loss': 0.8196298403124656}
2022-11-23 02:54:06,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:06,480 INFO:     Epoch: 32
2022-11-23 02:54:07,355 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8030879389155995, 'Total loss': 0.8030879389155995} | train loss {'Reaction outcome loss': 0.8218438709455151, 'Total loss': 0.8218438709455151}
2022-11-23 02:54:07,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:07,356 INFO:     Epoch: 33
2022-11-23 02:54:08,193 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8008306487040087, 'Total loss': 0.8008306487040087} | train loss {'Reaction outcome loss': 0.8230024506488154, 'Total loss': 0.8230024506488154}
2022-11-23 02:54:08,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:08,194 INFO:     Epoch: 34
2022-11-23 02:54:09,015 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7981853038072586, 'Total loss': 0.7981853038072586} | train loss {'Reaction outcome loss': 0.8233617762884786, 'Total loss': 0.8233617762884786}
2022-11-23 02:54:09,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:09,015 INFO:     Epoch: 35
2022-11-23 02:54:09,838 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.799084487286481, 'Total loss': 0.799084487286481} | train loss {'Reaction outcome loss': 0.8231073437679198, 'Total loss': 0.8231073437679198}
2022-11-23 02:54:09,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:09,839 INFO:     Epoch: 36
2022-11-23 02:54:10,646 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7891028455712579, 'Total loss': 0.7891028455712579} | train loss {'Reaction outcome loss': 0.8241661424117703, 'Total loss': 0.8241661424117703}
2022-11-23 02:54:10,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:10,647 INFO:     Epoch: 37
2022-11-23 02:54:11,477 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7914396808906035, 'Total loss': 0.7914396808906035} | train loss {'Reaction outcome loss': 0.823158992514495, 'Total loss': 0.823158992514495}
2022-11-23 02:54:11,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:11,477 INFO:     Epoch: 38
2022-11-23 02:54:12,265 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.781181275844574, 'Total loss': 0.781181275844574} | train loss {'Reaction outcome loss': 0.8231112159067585, 'Total loss': 0.8231112159067585}
2022-11-23 02:54:12,265 INFO:     Found new best model at epoch 38
2022-11-23 02:54:12,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:12,266 INFO:     Epoch: 39
2022-11-23 02:54:13,059 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.816650768572634, 'Total loss': 0.816650768572634} | train loss {'Reaction outcome loss': 0.8218437612297074, 'Total loss': 0.8218437612297074}
2022-11-23 02:54:13,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:13,060 INFO:     Epoch: 40
2022-11-23 02:54:13,863 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8201095705682581, 'Total loss': 0.8201095705682581} | train loss {'Reaction outcome loss': 0.8255416369966923, 'Total loss': 0.8255416369966923}
2022-11-23 02:54:13,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:13,864 INFO:     Epoch: 41
2022-11-23 02:54:14,638 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8011810826984319, 'Total loss': 0.8011810826984319} | train loss {'Reaction outcome loss': 0.8243108519142673, 'Total loss': 0.8243108519142673}
2022-11-23 02:54:14,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:14,638 INFO:     Epoch: 42
2022-11-23 02:54:15,440 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8011099208484996, 'Total loss': 0.8011099208484996} | train loss {'Reaction outcome loss': 0.8259120756579984, 'Total loss': 0.8259120756579984}
2022-11-23 02:54:15,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:15,440 INFO:     Epoch: 43
2022-11-23 02:54:16,215 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8048000444065441, 'Total loss': 0.8048000444065441} | train loss {'Reaction outcome loss': 0.8255488552874134, 'Total loss': 0.8255488552874134}
2022-11-23 02:54:16,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:16,216 INFO:     Epoch: 44
2022-11-23 02:54:17,048 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8022867481816899, 'Total loss': 0.8022867481816899} | train loss {'Reaction outcome loss': 0.8190701374363515, 'Total loss': 0.8190701374363515}
2022-11-23 02:54:17,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:17,048 INFO:     Epoch: 45
2022-11-23 02:54:17,866 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7854776470498606, 'Total loss': 0.7854776470498606} | train loss {'Reaction outcome loss': 0.820109086291444, 'Total loss': 0.820109086291444}
2022-11-23 02:54:17,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:17,866 INFO:     Epoch: 46
2022-11-23 02:54:18,698 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8086940591985529, 'Total loss': 0.8086940591985529} | train loss {'Reaction outcome loss': 0.8187025412316283, 'Total loss': 0.8187025412316283}
2022-11-23 02:54:18,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:18,698 INFO:     Epoch: 47
2022-11-23 02:54:19,495 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7966664440252564, 'Total loss': 0.7966664440252564} | train loss {'Reaction outcome loss': 0.822224045592931, 'Total loss': 0.822224045592931}
2022-11-23 02:54:19,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:19,495 INFO:     Epoch: 48
2022-11-23 02:54:20,307 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7937668975103985, 'Total loss': 0.7937668975103985} | train loss {'Reaction outcome loss': 0.8222953258983551, 'Total loss': 0.8222953258983551}
2022-11-23 02:54:20,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:20,308 INFO:     Epoch: 49
2022-11-23 02:54:21,102 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.800114358690652, 'Total loss': 0.800114358690652} | train loss {'Reaction outcome loss': 0.8227986034847075, 'Total loss': 0.8227986034847075}
2022-11-23 02:54:21,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:21,102 INFO:     Epoch: 50
2022-11-23 02:54:21,916 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7917830971154299, 'Total loss': 0.7917830971154299} | train loss {'Reaction outcome loss': 0.8229990453729706, 'Total loss': 0.8229990453729706}
2022-11-23 02:54:21,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:21,916 INFO:     Epoch: 51
2022-11-23 02:54:22,704 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7900834009051323, 'Total loss': 0.7900834009051323} | train loss {'Reaction outcome loss': 0.8224630885787548, 'Total loss': 0.8224630885787548}
2022-11-23 02:54:22,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:22,704 INFO:     Epoch: 52
2022-11-23 02:54:23,492 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.790956283157522, 'Total loss': 0.790956283157522} | train loss {'Reaction outcome loss': 0.8227637551965252, 'Total loss': 0.8227637551965252}
2022-11-23 02:54:23,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:23,492 INFO:     Epoch: 53
2022-11-23 02:54:24,332 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8047348626635291, 'Total loss': 0.8047348626635291} | train loss {'Reaction outcome loss': 0.8208695437398649, 'Total loss': 0.8208695437398649}
2022-11-23 02:54:24,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:24,332 INFO:     Epoch: 54
2022-11-23 02:54:25,126 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7978545359589837, 'Total loss': 0.7978545359589837} | train loss {'Reaction outcome loss': 0.8218229232776549, 'Total loss': 0.8218229232776549}
2022-11-23 02:54:25,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:25,127 INFO:     Epoch: 55
2022-11-23 02:54:25,926 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8176783065904271, 'Total loss': 0.8176783065904271} | train loss {'Reaction outcome loss': 0.8225201203698113, 'Total loss': 0.8225201203698113}
2022-11-23 02:54:25,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:25,926 INFO:     Epoch: 56
2022-11-23 02:54:26,763 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7953417768532579, 'Total loss': 0.7953417768532579} | train loss {'Reaction outcome loss': 0.8195030998078084, 'Total loss': 0.8195030998078084}
2022-11-23 02:54:26,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:26,763 INFO:     Epoch: 57
2022-11-23 02:54:27,572 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7965450774539601, 'Total loss': 0.7965450774539601} | train loss {'Reaction outcome loss': 0.8198283432472137, 'Total loss': 0.8198283432472137}
2022-11-23 02:54:27,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:27,572 INFO:     Epoch: 58
2022-11-23 02:54:28,392 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7968605932864276, 'Total loss': 0.7968605932864276} | train loss {'Reaction outcome loss': 0.8249375978785176, 'Total loss': 0.8249375978785176}
2022-11-23 02:54:28,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:28,393 INFO:     Epoch: 59
2022-11-23 02:54:29,241 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7866861298680305, 'Total loss': 0.7866861298680305} | train loss {'Reaction outcome loss': 0.8195670694112778, 'Total loss': 0.8195670694112778}
2022-11-23 02:54:29,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:29,241 INFO:     Epoch: 60
2022-11-23 02:54:30,093 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7873367795890028, 'Total loss': 0.7873367795890028} | train loss {'Reaction outcome loss': 0.8190585717318519, 'Total loss': 0.8190585717318519}
2022-11-23 02:54:30,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:30,094 INFO:     Epoch: 61
2022-11-23 02:54:30,918 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7883835665204308, 'Total loss': 0.7883835665204308} | train loss {'Reaction outcome loss': 0.8257695218968776, 'Total loss': 0.8257695218968776}
2022-11-23 02:54:30,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:30,918 INFO:     Epoch: 62
2022-11-23 02:54:31,775 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8056233085014604, 'Total loss': 0.8056233085014604} | train loss {'Reaction outcome loss': 0.8190101805113016, 'Total loss': 0.8190101805113016}
2022-11-23 02:54:31,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:31,775 INFO:     Epoch: 63
2022-11-23 02:54:32,588 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7981530712409453, 'Total loss': 0.7981530712409453} | train loss {'Reaction outcome loss': 0.8227062958382791, 'Total loss': 0.8227062958382791}
2022-11-23 02:54:32,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:32,588 INFO:     Epoch: 64
2022-11-23 02:54:33,412 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8286215012723749, 'Total loss': 0.8286215012723749} | train loss {'Reaction outcome loss': 0.8175675271739883, 'Total loss': 0.8175675271739883}
2022-11-23 02:54:33,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:33,412 INFO:     Epoch: 65
2022-11-23 02:54:34,205 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7962630458853461, 'Total loss': 0.7962630458853461} | train loss {'Reaction outcome loss': 0.8203888179794434, 'Total loss': 0.8203888179794434}
2022-11-23 02:54:34,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:34,205 INFO:     Epoch: 66
2022-11-23 02:54:34,988 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8080263341015036, 'Total loss': 0.8080263341015036} | train loss {'Reaction outcome loss': 0.8200541988255516, 'Total loss': 0.8200541988255516}
2022-11-23 02:54:34,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:34,988 INFO:     Epoch: 67
2022-11-23 02:54:35,785 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7915553017096086, 'Total loss': 0.7915553017096086} | train loss {'Reaction outcome loss': 0.8219730479101981, 'Total loss': 0.8219730479101981}
2022-11-23 02:54:35,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:35,785 INFO:     Epoch: 68
2022-11-23 02:54:36,564 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7896364825693044, 'Total loss': 0.7896364825693044} | train loss {'Reaction outcome loss': 0.8209027530204865, 'Total loss': 0.8209027530204865}
2022-11-23 02:54:36,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:36,564 INFO:     Epoch: 69
2022-11-23 02:54:37,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8201514374126088, 'Total loss': 0.8201514374126088} | train loss {'Reaction outcome loss': 0.8215793788192733, 'Total loss': 0.8215793788192733}
2022-11-23 02:54:37,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:37,383 INFO:     Epoch: 70
2022-11-23 02:54:38,174 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7991845540025018, 'Total loss': 0.7991845540025018} | train loss {'Reaction outcome loss': 0.8241649705075449, 'Total loss': 0.8241649705075449}
2022-11-23 02:54:38,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:38,174 INFO:     Epoch: 71
2022-11-23 02:54:38,981 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7912716350772164, 'Total loss': 0.7912716350772164} | train loss {'Reaction outcome loss': 0.8184750957354423, 'Total loss': 0.8184750957354423}
2022-11-23 02:54:38,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:38,981 INFO:     Epoch: 72
2022-11-23 02:54:39,769 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7865092720497738, 'Total loss': 0.7865092720497738} | train loss {'Reaction outcome loss': 0.8196339293593361, 'Total loss': 0.8196339293593361}
2022-11-23 02:54:39,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:39,769 INFO:     Epoch: 73
2022-11-23 02:54:40,553 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8108632943846963, 'Total loss': 0.8108632943846963} | train loss {'Reaction outcome loss': 0.8182140949272341, 'Total loss': 0.8182140949272341}
2022-11-23 02:54:40,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:40,553 INFO:     Epoch: 74
2022-11-23 02:54:41,340 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7959374826062809, 'Total loss': 0.7959374826062809} | train loss {'Reaction outcome loss': 0.823146594267699, 'Total loss': 0.823146594267699}
2022-11-23 02:54:41,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:41,340 INFO:     Epoch: 75
2022-11-23 02:54:42,131 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7957789125767621, 'Total loss': 0.7957789125767621} | train loss {'Reaction outcome loss': 0.8216392186380201, 'Total loss': 0.8216392186380201}
2022-11-23 02:54:42,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:42,131 INFO:     Epoch: 76
2022-11-23 02:54:42,916 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8568614233623851, 'Total loss': 0.8568614233623851} | train loss {'Reaction outcome loss': 0.8253776769964926, 'Total loss': 0.8253776769964926}
2022-11-23 02:54:42,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:42,917 INFO:     Epoch: 77
2022-11-23 02:54:43,700 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7866658968004313, 'Total loss': 0.7866658968004313} | train loss {'Reaction outcome loss': 0.8280846153295809, 'Total loss': 0.8280846153295809}
2022-11-23 02:54:43,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:43,701 INFO:     Epoch: 78
2022-11-23 02:54:44,469 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7922738912430677, 'Total loss': 0.7922738912430677} | train loss {'Reaction outcome loss': 0.8235832814487719, 'Total loss': 0.8235832814487719}
2022-11-23 02:54:44,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:44,470 INFO:     Epoch: 79
2022-11-23 02:54:45,234 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8019598180597479, 'Total loss': 0.8019598180597479} | train loss {'Reaction outcome loss': 0.8184387655027451, 'Total loss': 0.8184387655027451}
2022-11-23 02:54:45,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:45,235 INFO:     Epoch: 80
2022-11-23 02:54:45,983 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8150304664265026, 'Total loss': 0.8150304664265026} | train loss {'Reaction outcome loss': 0.8229575248495224, 'Total loss': 0.8229575248495224}
2022-11-23 02:54:45,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:45,983 INFO:     Epoch: 81
2022-11-23 02:54:46,808 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7909899448806589, 'Total loss': 0.7909899448806589} | train loss {'Reaction outcome loss': 0.822900964127433, 'Total loss': 0.822900964127433}
2022-11-23 02:54:46,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:46,809 INFO:     Epoch: 82
2022-11-23 02:54:47,593 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8213954066688364, 'Total loss': 0.8213954066688364} | train loss {'Reaction outcome loss': 0.8193601643846881, 'Total loss': 0.8193601643846881}
2022-11-23 02:54:47,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:47,593 INFO:     Epoch: 83
2022-11-23 02:54:48,409 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8046499375592578, 'Total loss': 0.8046499375592578} | train loss {'Reaction outcome loss': 0.823235442922, 'Total loss': 0.823235442922}
2022-11-23 02:54:48,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:48,409 INFO:     Epoch: 84
2022-11-23 02:54:49,215 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8085223910483447, 'Total loss': 0.8085223910483447} | train loss {'Reaction outcome loss': 0.8239103723918239, 'Total loss': 0.8239103723918239}
2022-11-23 02:54:49,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:49,215 INFO:     Epoch: 85
2022-11-23 02:54:50,001 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7962631515481255, 'Total loss': 0.7962631515481255} | train loss {'Reaction outcome loss': 0.8210705016409198, 'Total loss': 0.8210705016409198}
2022-11-23 02:54:50,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:50,001 INFO:     Epoch: 86
2022-11-23 02:54:50,790 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.802908333865079, 'Total loss': 0.802908333865079} | train loss {'Reaction outcome loss': 0.8279606657883813, 'Total loss': 0.8279606657883813}
2022-11-23 02:54:50,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:50,790 INFO:     Epoch: 87
2022-11-23 02:54:51,600 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7982472032308578, 'Total loss': 0.7982472032308578} | train loss {'Reaction outcome loss': 0.8184233673157231, 'Total loss': 0.8184233673157231}
2022-11-23 02:54:51,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:51,600 INFO:     Epoch: 88
2022-11-23 02:54:52,420 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8009251044555143, 'Total loss': 0.8009251044555143} | train loss {'Reaction outcome loss': 0.8278926155499874, 'Total loss': 0.8278926155499874}
2022-11-23 02:54:52,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:52,420 INFO:     Epoch: 89
2022-11-23 02:54:53,222 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8031132837588136, 'Total loss': 0.8031132837588136} | train loss {'Reaction outcome loss': 0.8206908838643182, 'Total loss': 0.8206908838643182}
2022-11-23 02:54:53,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:53,222 INFO:     Epoch: 90
2022-11-23 02:54:54,038 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7853745682673021, 'Total loss': 0.7853745682673021} | train loss {'Reaction outcome loss': 0.8243612842934747, 'Total loss': 0.8243612842934747}
2022-11-23 02:54:54,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:54,039 INFO:     Epoch: 91
2022-11-23 02:54:54,820 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7878671898083254, 'Total loss': 0.7878671898083254} | train loss {'Reaction outcome loss': 0.8240234905913952, 'Total loss': 0.8240234905913952}
2022-11-23 02:54:54,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:54,820 INFO:     Epoch: 92
2022-11-23 02:54:55,649 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7958755486390807, 'Total loss': 0.7958755486390807} | train loss {'Reaction outcome loss': 0.8213360013981019, 'Total loss': 0.8213360013981019}
2022-11-23 02:54:55,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:55,649 INFO:     Epoch: 93
2022-11-23 02:54:56,460 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7995176051150669, 'Total loss': 0.7995176051150669} | train loss {'Reaction outcome loss': 0.8203574575243457, 'Total loss': 0.8203574575243457}
2022-11-23 02:54:56,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:56,461 INFO:     Epoch: 94
2022-11-23 02:54:57,256 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7987026680599559, 'Total loss': 0.7987026680599559} | train loss {'Reaction outcome loss': 0.819985911730797, 'Total loss': 0.819985911730797}
2022-11-23 02:54:57,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:57,256 INFO:     Epoch: 95
2022-11-23 02:54:58,054 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8122141259637746, 'Total loss': 0.8122141259637746} | train loss {'Reaction outcome loss': 0.8290094116762761, 'Total loss': 0.8290094116762761}
2022-11-23 02:54:58,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:58,054 INFO:     Epoch: 96
2022-11-23 02:54:58,898 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7964128411628983, 'Total loss': 0.7964128411628983} | train loss {'Reaction outcome loss': 0.8235385116309889, 'Total loss': 0.8235385116309889}
2022-11-23 02:54:58,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:58,898 INFO:     Epoch: 97
2022-11-23 02:54:59,673 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.794081773608923, 'Total loss': 0.794081773608923} | train loss {'Reaction outcome loss': 0.8194872263458467, 'Total loss': 0.8194872263458467}
2022-11-23 02:54:59,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:54:59,673 INFO:     Epoch: 98
2022-11-23 02:55:00,453 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8065028055147692, 'Total loss': 0.8065028055147692} | train loss {'Reaction outcome loss': 0.8227484452147638, 'Total loss': 0.8227484452147638}
2022-11-23 02:55:00,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 02:55:00,453 INFO:     Epoch: 99
2022-11-23 02:55:01,310 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8004155118357051, 'Total loss': 0.8004155118357051} | train loss {'Reaction outcome loss': 0.819058000801071, 'Total loss': 0.819058000801071}
2022-11-23 02:55:01,310 INFO:     Best model found after epoch 39 of 100.
2022-11-23 02:55:01,310 INFO:   Done with stage: TRAINING
2022-11-23 02:55:01,310 INFO:   Starting stage: EVALUATION
2022-11-23 02:55:01,429 INFO:   Done with stage: EVALUATION
2022-11-23 02:55:01,430 INFO: Done with stage: RUNNING SPLITS
2022-11-23 02:55:01,430 INFO: Starting stage: COMPUTE METRICS
2022-11-23 02:55:02,651 INFO: Done with stage: COMPUTE METRICS
2022-11-23 02:55:02,651 INFO: Starting stage: EXPORT RESULTS
2022-11-23 02:55:02,669 INFO:   Final results averaged over 50 folds: 
2022-11-23 02:55:02,673 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.251086           NaN  0.343153       NaN
2022-11-23 02:55:04,328 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-23 02:55:04,336 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-23 02:55:04,337 DEBUG:   interactive is False
2022-11-23 02:55:04,337 DEBUG:   platform is linux
2022-11-23 02:55:04,338 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-23 02:55:04,522 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-23 02:55:04,525 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-23 02:55:04,979 DEBUG:   Loaded backend agg version unknown.
2022-11-23 02:55:04,981 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-23 02:55:04,981 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,981 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:04,982 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,983 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 02:55:04,984 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,985 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,985 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:04,985 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 02:55:04,985 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:04,985 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 02:55:05,023 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-23 02:55:05,023 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,023 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,023 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,023 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,024 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,025 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,026 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 02:55:05,027 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,027 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 02:55:05,036 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,037 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,038 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,039 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,040 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 02:55:05,041 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 02:55:05,041 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 02:55:05,041 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 02:55:05,651 INFO: Done with stage: EXPORT RESULTS
2022-11-23 02:55:05,651 INFO: Starting stage: SAVE MODEL
2022-11-23 02:55:05,706 INFO: Done with stage: SAVE MODEL
2022-11-23 02:55:05,707 INFO: Wall time for program:  4333.07 seconds
